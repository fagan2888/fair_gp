[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.7720091024404188,
            "auditor_fn_violation": 0.0021326866044949567,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5440182048808375,
            "fpr": 0.0,
            "logloss": 0.688754089170941,
            "mae": 0.4968428520257013,
            "precision": 1.0,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.685874181343523,
            "auditor_fn_violation": 0.0018468774967816065,
            "auditor_fp_violation": 0.0005708993257017407,
            "ave_precision_score": 0.5127542250751979,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6925407810475788,
            "mae": 0.4973434085510957,
            "precision": 0.8571428571428571,
            "recall": 0.012958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.7720091024404188,
            "auditor_fn_violation": 0.0021326866044949567,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5440182048808375,
            "fpr": 0.0,
            "logloss": 0.688754089170941,
            "mae": 0.4968428520257013,
            "precision": 1.0,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.685874181343523,
            "auditor_fn_violation": 0.0018468774967816065,
            "auditor_fp_violation": 0.0005708993257017407,
            "ave_precision_score": 0.5127542250751979,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6925407810475788,
            "mae": 0.4973434085510957,
            "precision": 0.8571428571428571,
            "recall": 0.012958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.62386596577353,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5582956605444037,
            "fpr": 0.4616228070175439,
            "logloss": 0.6886512963407163,
            "mae": 0.4967908240985452,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5474237884750988,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.521276195396653,
            "fpr": 0.49176728869374314,
            "logloss": 0.7100304774569809,
            "mae": 0.49787767808863936,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6863365310941846,
            "auditor_fn_violation": 0.010605370350519885,
            "auditor_fp_violation": 0.027164853940075846,
            "ave_precision_score": 0.6843483559362145,
            "fpr": 0.17105263157894737,
            "logloss": 1.3842800381736005,
            "mae": 0.3536579911323012,
            "precision": 0.687374749498998,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6499096546061874,
            "auditor_fn_violation": 0.0035325384726631274,
            "auditor_fp_violation": 0.01866081229418222,
            "ave_precision_score": 0.6475954234289122,
            "fpr": 0.1734357848518112,
            "logloss": 1.5278186955615551,
            "mae": 0.367654590747652,
            "precision": 0.6687631027253669,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7900011715017973,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.6826569843639066,
            "fpr": 0.0021929824561403508,
            "logloss": 0.8012905739872795,
            "mae": 0.4550658544819606,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7496557855010533,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6329260087557724,
            "fpr": 0.006586169045005488,
            "logloss": 0.7967619798604239,
            "mae": 0.4492739792974537,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6350211999648947,
            "auditor_fn_violation": 0.0079970164719334,
            "auditor_fp_violation": 0.005711651456432065,
            "ave_precision_score": 0.6350398086806985,
            "fpr": 0.39035087719298245,
            "logloss": 0.6756217134713597,
            "mae": 0.48064392682557044,
            "precision": 0.555,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5803520715845474,
            "auditor_fn_violation": 0.0025652393472627567,
            "auditor_fp_violation": 0.007713266426219246,
            "ave_precision_score": 0.5813519828580678,
            "fpr": 0.3907793633369923,
            "logloss": 0.6790457206658582,
            "mae": 0.47868072948164003,
            "precision": 0.538860103626943,
            "recall": 0.8984881209503239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.683579424862549,
            "auditor_fn_violation": 0.014185157394504598,
            "auditor_fp_violation": 0.02544849356169521,
            "ave_precision_score": 0.6815957143172723,
            "fpr": 0.17543859649122806,
            "logloss": 1.396612495365273,
            "mae": 0.35553684810056807,
            "precision": 0.6825396825396826,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6468364386169969,
            "auditor_fn_violation": 0.009021012676834379,
            "auditor_fp_violation": 0.020032930845225033,
            "ave_precision_score": 0.6445226283484409,
            "fpr": 0.17672886937431395,
            "logloss": 1.5380759564882687,
            "mae": 0.36974365941233683,
            "precision": 0.6694045174537988,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5968568431282224,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5941880405815728,
            "fpr": 0.4616228070175439,
            "logloss": 0.6918014694362568,
            "mae": 0.499298899254778,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5126940670310227,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5096800643459928,
            "fpr": 0.49176728869374314,
            "logloss": 0.6928426452881946,
            "mae": 0.4998168556017619,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6832284958751104,
            "auditor_fn_violation": 0.014004269839568375,
            "auditor_fp_violation": 0.020671854815185232,
            "ave_precision_score": 0.6814812155947552,
            "fpr": 0.19188596491228072,
            "logloss": 1.3959234193114711,
            "mae": 0.3522501888868885,
            "precision": 0.6806569343065694,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6457305085579921,
            "auditor_fn_violation": 0.009011529352075545,
            "auditor_fp_violation": 0.024394307668182534,
            "ave_precision_score": 0.6436426382607774,
            "fpr": 0.20417124039517015,
            "logloss": 1.5434986309584078,
            "mae": 0.36933885892777346,
            "precision": 0.6477272727272727,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8275372535096497,
            "mae": 0.493022938128234,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8024867762062105,
            "mae": 0.47940323543535496,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6846860520318554,
            "auditor_fn_violation": 0.011297656054596782,
            "auditor_fp_violation": 0.023112264033004135,
            "ave_precision_score": 0.6829882703914054,
            "fpr": 0.17982456140350878,
            "logloss": 1.3945608259001714,
            "mae": 0.3558755272094512,
            "precision": 0.6821705426356589,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6472368632337587,
            "auditor_fn_violation": 0.0056022741012771715,
            "auditor_fp_violation": 0.018526050650776223,
            "ave_precision_score": 0.6450210115482065,
            "fpr": 0.18551042810098792,
            "logloss": 1.5407902674504097,
            "mae": 0.3701262783243086,
            "precision": 0.662,
            "recall": 0.714902807775378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6837523498367397,
            "auditor_fn_violation": 0.014004269839568375,
            "auditor_fp_violation": 0.020671854815185232,
            "ave_precision_score": 0.6820905671123609,
            "fpr": 0.19188596491228072,
            "logloss": 1.3955088514619292,
            "mae": 0.3524893125980394,
            "precision": 0.6806569343065694,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6451866251815973,
            "auditor_fn_violation": 0.009011529352075545,
            "auditor_fp_violation": 0.024394307668182534,
            "ave_precision_score": 0.6431686009676199,
            "fpr": 0.20417124039517015,
            "logloss": 1.5430308733390494,
            "mae": 0.3696933817947783,
            "precision": 0.6477272727272727,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7556926575528751,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.7457115281958085,
            "fpr": 0.0021929824561403508,
            "logloss": 0.7585857695628345,
            "mae": 0.44996637011175616,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6928984085743786,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6861732367934933,
            "fpr": 0.006586169045005488,
            "logloss": 0.7582708476155385,
            "mae": 0.44650710250622094,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5875657100727393,
            "auditor_fn_violation": 0.007583878229177838,
            "auditor_fp_violation": 0.0057246739175730475,
            "ave_precision_score": 0.5882365026261112,
            "fpr": 0.39364035087719296,
            "logloss": 0.6934151543725269,
            "mae": 0.49830235619294017,
            "precision": 0.5325520833333334,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5390934431399474,
            "auditor_fn_violation": 0.0035870675900263925,
            "auditor_fp_violation": 0.0065592167163243,
            "ave_precision_score": 0.5400488804526844,
            "fpr": 0.40504939626783754,
            "logloss": 0.692024326963156,
            "mae": 0.4961898755425287,
            "precision": 0.5066844919786097,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6683891123123805,
            "auditor_fn_violation": 0.0011858184156930246,
            "auditor_fp_violation": 0.0007917656373713382,
            "ave_precision_score": 0.6355849984450248,
            "fpr": 0.006578947368421052,
            "logloss": 0.9134582814755813,
            "mae": 0.49975141882896423,
            "precision": 0.7272727272727273,
            "recall": 0.032586558044806514
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.66119610161095,
            "auditor_fn_violation": 0.00597686542925084,
            "auditor_fp_violation": 0.0017641524227693273,
            "ave_precision_score": 0.6174365171457189,
            "fpr": 0.0043907793633369925,
            "logloss": 0.8860101387705483,
            "mae": 0.48285101754866894,
            "precision": 0.8095238095238095,
            "recall": 0.0367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6845634302354835,
            "auditor_fn_violation": 0.014004269839568375,
            "auditor_fp_violation": 0.020671854815185232,
            "ave_precision_score": 0.68310113757175,
            "fpr": 0.19188596491228072,
            "logloss": 1.393649495403102,
            "mae": 0.35249324161462375,
            "precision": 0.6806569343065694,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6466886318939148,
            "auditor_fn_violation": 0.009011529352075545,
            "auditor_fp_violation": 0.024394307668182534,
            "ave_precision_score": 0.6450883339265868,
            "fpr": 0.20417124039517015,
            "logloss": 1.540959648412358,
            "mae": 0.3695424847844093,
            "precision": 0.6477272727272727,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7462305930844101,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.7465554959403939,
            "fpr": 0.0021929824561403508,
            "logloss": 0.8015493053586634,
            "mae": 0.455369549362283,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6847513235235461,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6856831058244324,
            "fpr": 0.006586169045005488,
            "logloss": 0.7973853657824693,
            "mae": 0.44965813072596633,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.762909048843178,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.6978377258548819,
            "fpr": 0.0021929824561403508,
            "logloss": 0.8017594990588436,
            "mae": 0.4552874010579105,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.722229260823726,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.65266577207332,
            "fpr": 0.006586169045005488,
            "logloss": 0.797080720865609,
            "mae": 0.4495480925041025,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8266443150139094,
            "mae": 0.4930539849263273,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8017427855605113,
            "mae": 0.47950524678934286,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7068642302360745,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7007871081685739,
            "fpr": 0.01425438596491228,
            "logloss": 0.8454007031607471,
            "mae": 0.49400549112377984,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6899132167072156,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.684140523405969,
            "fpr": 0.013172338090010977,
            "logloss": 0.8229025339631741,
            "mae": 0.4800420660447865,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.702597278345576,
            "auditor_fn_violation": 0.011364651445313899,
            "auditor_fp_violation": 0.028977580530899705,
            "ave_precision_score": 0.6751801632815024,
            "fpr": 0.20394736842105263,
            "logloss": 2.8280479290020826,
            "mae": 0.2911860099654242,
            "precision": 0.6935749588138386,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6719345511561227,
            "auditor_fn_violation": 0.003499346836007241,
            "auditor_fp_violation": 0.03589315116826094,
            "ave_precision_score": 0.6444732918090041,
            "fpr": 0.20087815587266739,
            "logloss": 2.971695253932052,
            "mae": 0.3099554843223273,
            "precision": 0.6743772241992882,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7540817659501547,
            "auditor_fn_violation": 0.021360363740308,
            "auditor_fp_violation": 0.03602794099262408,
            "ave_precision_score": 0.7514870301212586,
            "fpr": 0.1787280701754386,
            "logloss": 0.9877296153368492,
            "mae": 0.29439072582702414,
            "precision": 0.7104795737122558,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7537786207409625,
            "auditor_fn_violation": 0.016704876562674113,
            "auditor_fp_violation": 0.04376078093147249,
            "ave_precision_score": 0.7533128419191145,
            "fpr": 0.16245883644346873,
            "logloss": 0.899377989780425,
            "mae": 0.30777392250393837,
            "precision": 0.705765407554672,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7915329243646855,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.6833723207262707,
            "fpr": 0.0021929824561403508,
            "logloss": 0.801164988427268,
            "mae": 0.4551676339551545,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7496557855010533,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6329260087557724,
            "fpr": 0.006586169045005488,
            "logloss": 0.7968077893614265,
            "mae": 0.4495516255514289,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.6955709551103171,
            "auditor_fn_violation": 0.013957373066066389,
            "auditor_fp_violation": 0.030014168437721388,
            "ave_precision_score": 0.6726852558013874,
            "fpr": 0.2324561403508772,
            "logloss": 2.48758464183091,
            "mae": 0.3005825988070421,
            "precision": 0.6802413273001509,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6709698969751952,
            "auditor_fn_violation": 0.0036842716688043667,
            "auditor_fp_violation": 0.02976762192253413,
            "ave_precision_score": 0.6470549165960051,
            "fpr": 0.24698133918770582,
            "logloss": 2.5061121880906327,
            "mae": 0.3324761769622239,
            "precision": 0.64,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7181769346220113,
            "auditor_fn_violation": 0.02453371208060886,
            "auditor_fp_violation": 0.045331187231737305,
            "ave_precision_score": 0.7159072304115766,
            "fpr": 0.17653508771929824,
            "logloss": 1.1231718308644891,
            "mae": 0.3063089977514289,
            "precision": 0.7067395264116576,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6964705446369749,
            "auditor_fn_violation": 0.02425123223951086,
            "auditor_fp_violation": 0.053189195546495226,
            "ave_precision_score": 0.6954724889396763,
            "fpr": 0.18660812294182216,
            "logloss": 1.1216273090690603,
            "mae": 0.33267529495051235,
            "precision": 0.6711798839458414,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8030139826004851,
            "auditor_fn_violation": 0.011293189695215639,
            "auditor_fp_violation": 0.0211797307996833,
            "ave_precision_score": 0.8008951638809487,
            "fpr": 0.1425438596491228,
            "logloss": 1.3609900693084709,
            "mae": 0.2875292872484392,
            "precision": 0.7425742574257426,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.764028090259554,
            "auditor_fn_violation": 0.01294473829579912,
            "auditor_fp_violation": 0.016587933197428264,
            "ave_precision_score": 0.7627303578728304,
            "fpr": 0.14709110867178923,
            "logloss": 1.4279357315197703,
            "mae": 0.312231225956227,
            "precision": 0.7124463519313304,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7800403393315298,
            "auditor_fn_violation": 0.012479008110908638,
            "auditor_fp_violation": 0.031009084468891952,
            "ave_precision_score": 0.7760578286674849,
            "fpr": 0.2324561403508772,
            "logloss": 1.0974248557095254,
            "mae": 0.2946107665004097,
            "precision": 0.6797583081570997,
            "recall": 0.9164969450101833
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.777699661227754,
            "auditor_fn_violation": 0.005068837083593141,
            "auditor_fp_violation": 0.02325740944017564,
            "ave_precision_score": 0.7763421374372217,
            "fpr": 0.2327113062568606,
            "logloss": 0.9815545499724135,
            "mae": 0.31075368730613256,
            "precision": 0.6608,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7073825987859972,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7005129825030239,
            "fpr": 0.01425438596491228,
            "logloss": 0.8453093156525774,
            "mae": 0.49399741126322433,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6910381433520225,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6842433686994648,
            "fpr": 0.013172338090010977,
            "logloss": 0.8228174025930353,
            "mae": 0.48003745337479986,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8005185537162738,
            "auditor_fn_violation": 0.01659252510093972,
            "auditor_fp_violation": 0.019036233695878656,
            "ave_precision_score": 0.7992699721522373,
            "fpr": 0.12828947368421054,
            "logloss": 1.3129995392870824,
            "mae": 0.29125740486439367,
            "precision": 0.7552301255230126,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7590992088642619,
            "auditor_fn_violation": 0.02211985499996444,
            "auditor_fp_violation": 0.018700015681354872,
            "ave_precision_score": 0.7578537750786777,
            "fpr": 0.13721185510428102,
            "logloss": 1.4265636637143198,
            "mae": 0.31827802687347695,
            "precision": 0.7178329571106095,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5881029914659165,
            "auditor_fn_violation": 0.007583878229177838,
            "auditor_fp_violation": 0.0057246739175730475,
            "ave_precision_score": 0.5888595549748191,
            "fpr": 0.39364035087719296,
            "logloss": 0.6934151322575237,
            "mae": 0.4983023153617978,
            "precision": 0.5325520833333334,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5391829681340811,
            "auditor_fn_violation": 0.0035870675900263925,
            "auditor_fp_violation": 0.0065592167163243,
            "ave_precision_score": 0.540309428385783,
            "fpr": 0.40504939626783754,
            "logloss": 0.6920242537524968,
            "mae": 0.49618982172823634,
            "precision": 0.5066844919786097,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7177880228336315,
            "auditor_fn_violation": 0.02801077285882732,
            "auditor_fp_violation": 0.04421906905029795,
            "ave_precision_score": 0.7155446446061926,
            "fpr": 0.17324561403508773,
            "logloss": 1.1275353501327514,
            "mae": 0.30550004279971876,
            "precision": 0.7116788321167883,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6959761606219811,
            "auditor_fn_violation": 0.023018400020863316,
            "auditor_fp_violation": 0.05360573153520464,
            "ave_precision_score": 0.6949497928319996,
            "fpr": 0.18660812294182216,
            "logloss": 1.1267142322025887,
            "mae": 0.3323202890584309,
            "precision": 0.6705426356589147,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7849482926692251,
            "auditor_fn_violation": 0.01746793153964341,
            "auditor_fp_violation": 0.017226111597282996,
            "ave_precision_score": 0.7820395937662893,
            "fpr": 0.11842105263157894,
            "logloss": 1.8461970955275278,
            "mae": 0.296448054013822,
            "precision": 0.7610619469026548,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7546995629647781,
            "auditor_fn_violation": 0.018686891437269,
            "auditor_fp_violation": 0.023855261094558575,
            "ave_precision_score": 0.7492559556484901,
            "fpr": 0.11855104281009879,
            "logloss": 1.8620265774929063,
            "mae": 0.3020722170578828,
            "precision": 0.7452830188679245,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7989482036797999,
            "auditor_fn_violation": 0.01771581448529675,
            "auditor_fp_violation": 0.01810382547818477,
            "ave_precision_score": 0.7977403863778977,
            "fpr": 0.13048245614035087,
            "logloss": 1.2864230130896486,
            "mae": 0.2918791767080428,
            "precision": 0.7525987525987526,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7574804957416316,
            "auditor_fn_violation": 0.020678389636622708,
            "auditor_fp_violation": 0.019038144895718992,
            "ave_precision_score": 0.7562416601754158,
            "fpr": 0.13830954994511527,
            "logloss": 1.360920077043376,
            "mae": 0.3196335357528775,
            "precision": 0.7162162162162162,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6900418258681749,
            "auditor_fn_violation": 0.013932808089470112,
            "auditor_fp_violation": 0.02315133141642706,
            "ave_precision_score": 0.6671824611442014,
            "fpr": 0.23903508771929824,
            "logloss": 2.584725747294912,
            "mae": 0.30396711404502375,
            "precision": 0.6706948640483383,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6689781237362857,
            "auditor_fn_violation": 0.004933699705779855,
            "auditor_fp_violation": 0.024955406147091113,
            "ave_precision_score": 0.6444118883882883,
            "fpr": 0.2535675082327113,
            "logloss": 2.6298820696029694,
            "mae": 0.33579636097622273,
            "precision": 0.631578947368421,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.702563334314149,
            "auditor_fn_violation": 0.010138635795190625,
            "auditor_fp_violation": 0.028977580530899705,
            "ave_precision_score": 0.6756465994265791,
            "fpr": 0.20394736842105263,
            "logloss": 2.8002758044721703,
            "mae": 0.291511187296329,
            "precision": 0.693069306930693,
            "recall": 0.8553971486761711
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6713626180746937,
            "auditor_fn_violation": 0.0002939830675236449,
            "auditor_fp_violation": 0.03610631958601224,
            "ave_precision_score": 0.6447285548359213,
            "fpr": 0.1986827661909989,
            "logloss": 2.9364726144307793,
            "mae": 0.3094657636314045,
            "precision": 0.6767857142857143,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.724761215808322,
            "auditor_fn_violation": 0.012454443134312362,
            "auditor_fp_violation": 0.001494978538984041,
            "ave_precision_score": 0.6586655218177889,
            "fpr": 0.03179824561403509,
            "logloss": 0.8147540636727645,
            "mae": 0.4916005884869057,
            "precision": 0.7851851851851852,
            "recall": 0.2158859470468432
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7144882625300836,
            "auditor_fn_violation": 0.007031885308670379,
            "auditor_fp_violation": 0.007512349066959386,
            "ave_precision_score": 0.6497711565627782,
            "fpr": 0.02305159165751921,
            "logloss": 0.7900452351289937,
            "mae": 0.4782408987684124,
            "precision": 0.8055555555555556,
            "recall": 0.1879049676025918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8028804274052062,
            "auditor_fn_violation": 0.01664165505413228,
            "auditor_fp_violation": 0.02102085677376339,
            "ave_precision_score": 0.8016828752475771,
            "fpr": 0.12390350877192982,
            "logloss": 1.3227212594807716,
            "mae": 0.2879660799480981,
            "precision": 0.7600849256900213,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7646760793792495,
            "auditor_fn_violation": 0.017771750598042178,
            "auditor_fp_violation": 0.018383938372275366,
            "ave_precision_score": 0.7634265053604685,
            "fpr": 0.12184412733260154,
            "logloss": 1.4403838334177501,
            "mae": 0.3118233474743543,
            "precision": 0.7382075471698113,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.6991628514737972,
            "auditor_fn_violation": 0.019529156394040088,
            "auditor_fp_violation": 0.03443920073342501,
            "ave_precision_score": 0.6850728978153797,
            "fpr": 0.21820175438596492,
            "logloss": 2.0765655589022876,
            "mae": 0.2994827934144605,
            "precision": 0.6885758998435054,
            "recall": 0.8961303462321792
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6779184677387631,
            "auditor_fn_violation": 0.008975966884229946,
            "auditor_fp_violation": 0.03917888505566881,
            "ave_precision_score": 0.6623991880836203,
            "fpr": 0.21624588364434688,
            "logloss": 1.9958016301573467,
            "mae": 0.31900781351005797,
            "precision": 0.6677908937605397,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7073992453769663,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7010243345528421,
            "fpr": 0.01425438596491228,
            "logloss": 0.8451215113028326,
            "mae": 0.49398064124806407,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6869930239554912,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6799348232256398,
            "fpr": 0.013172338090010977,
            "logloss": 0.8226424988686376,
            "mae": 0.4800278171651581,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.707833367351807,
            "auditor_fn_violation": 0.013180226533747811,
            "auditor_fp_violation": 0.028566070758844854,
            "ave_precision_score": 0.6820829124717689,
            "fpr": 0.25877192982456143,
            "logloss": 2.554562631957045,
            "mae": 0.31016286539475013,
            "precision": 0.659942363112392,
            "recall": 0.9327902240325866
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6833602819859219,
            "auditor_fn_violation": 0.00025842059967804223,
            "auditor_fp_violation": 0.03399668731378392,
            "ave_precision_score": 0.6575820959589702,
            "fpr": 0.27771679473106475,
            "logloss": 2.5849837680435255,
            "mae": 0.3432887174448836,
            "precision": 0.6212574850299402,
            "recall": 0.896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6956840750546194,
            "auditor_fn_violation": 0.013957373066066389,
            "auditor_fp_violation": 0.03101950243780473,
            "ave_precision_score": 0.6727890719477234,
            "fpr": 0.23135964912280702,
            "logloss": 2.48307872487372,
            "mae": 0.30051983082250683,
            "precision": 0.6812688821752266,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6713937496389201,
            "auditor_fn_violation": 0.0035017176671969454,
            "auditor_fp_violation": 0.030186608122941827,
            "ave_precision_score": 0.6477639511928115,
            "fpr": 0.24588364434687157,
            "logloss": 2.482398328700601,
            "mae": 0.3322881939485905,
            "precision": 0.6404494382022472,
            "recall": 0.8617710583153347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7055774351975734,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.6994465099651275,
            "fpr": 0.01425438596491228,
            "logloss": 0.8452906263603716,
            "mae": 0.4939957491138525,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6893747642039957,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6832413145524311,
            "fpr": 0.013172338090010977,
            "logloss": 0.8227999965879036,
            "mae": 0.4800365016469579,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7533873465972746,
            "auditor_fn_violation": 0.022820863257941186,
            "auditor_fp_violation": 0.03862982872859109,
            "ave_precision_score": 0.7507463271412751,
            "fpr": 0.17543859649122806,
            "logloss": 1.0028228551000138,
            "mae": 0.29626154057377446,
            "precision": 0.7142857142857143,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7512790023936624,
            "auditor_fn_violation": 0.019962398617331248,
            "auditor_fp_violation": 0.04529951387799907,
            "ave_precision_score": 0.7508696602145446,
            "fpr": 0.17014270032930845,
            "logloss": 0.9160147642634597,
            "mae": 0.3106177879822189,
            "precision": 0.6936758893280632,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7540724901497503,
            "auditor_fn_violation": 0.021360363740308,
            "auditor_fp_violation": 0.03602794099262408,
            "ave_precision_score": 0.7514777732442438,
            "fpr": 0.1787280701754386,
            "logloss": 0.9877352875131639,
            "mae": 0.2943922405011878,
            "precision": 0.7104795737122558,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7537644342236618,
            "auditor_fn_violation": 0.016704876562674113,
            "auditor_fp_violation": 0.04376078093147249,
            "ave_precision_score": 0.7533039546147214,
            "fpr": 0.16245883644346873,
            "logloss": 0.8993815409201321,
            "mae": 0.30777528171429164,
            "precision": 0.705765407554672,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 21924,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.6296981629289861,
            "auditor_fn_violation": 0.0009334691106585376,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6305888274843188,
            "fpr": 0.0,
            "logloss": 0.9449800985172282,
            "mae": 0.5075184262373991,
            "precision": 1.0,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.611628379723689,
            "auditor_fn_violation": 0.0005334370176840329,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6123506070655179,
            "fpr": 0.0,
            "logloss": 0.914342574211024,
            "mae": 0.4901019456161495,
            "precision": 1.0,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7988956742351678,
            "auditor_fn_violation": 0.01771581448529675,
            "auditor_fp_violation": 0.017546464141351,
            "ave_precision_score": 0.7976866585507343,
            "fpr": 0.13157894736842105,
            "logloss": 1.2834988505207297,
            "mae": 0.2918740361628318,
            "precision": 0.7510373443983402,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7574546506545065,
            "auditor_fn_violation": 0.020678389636622708,
            "auditor_fp_violation": 0.019038144895718992,
            "ave_precision_score": 0.7562163296801152,
            "fpr": 0.13830954994511527,
            "logloss": 1.3544745312946191,
            "mae": 0.3196854704048367,
            "precision": 0.7162162162162162,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7041684442501024,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.6983949752076231,
            "fpr": 0.01425438596491228,
            "logloss": 0.8452643330462365,
            "mae": 0.49399341556259935,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6905595527906057,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6845637919492114,
            "fpr": 0.013172338090010977,
            "logloss": 0.8227755026722521,
            "mae": 0.48003516656179984,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8042872553981932,
            "auditor_fn_violation": 0.011793421945903463,
            "auditor_fp_violation": 0.023130495478601496,
            "ave_precision_score": 0.8021671160381076,
            "fpr": 0.12609649122807018,
            "logloss": 1.411535948023147,
            "mae": 0.2850901569919344,
            "precision": 0.7547974413646056,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7653735978941765,
            "auditor_fn_violation": 0.015521831799010425,
            "auditor_fp_violation": 0.01653892896346245,
            "ave_precision_score": 0.7641635083171753,
            "fpr": 0.11964873765093303,
            "logloss": 1.5277447373141058,
            "mae": 0.30774171334133565,
            "precision": 0.7392344497607656,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6897630211909234,
            "auditor_fn_violation": 0.013932808089470112,
            "auditor_fp_violation": 0.02315133141642706,
            "ave_precision_score": 0.6668762613491626,
            "fpr": 0.23903508771929824,
            "logloss": 2.5868583357041497,
            "mae": 0.30409564424536634,
            "precision": 0.6706948640483383,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6686010909579778,
            "auditor_fn_violation": 0.004933699705779855,
            "auditor_fp_violation": 0.024955406147091113,
            "ave_precision_score": 0.644038071904129,
            "fpr": 0.2535675082327113,
            "logloss": 2.631894395486178,
            "mae": 0.33594748966135224,
            "precision": 0.631578947368421,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6975926276293141,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.6980536395096661,
            "fpr": 0.01425438596491228,
            "logloss": 0.8443426655689994,
            "mae": 0.4938417538804443,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6700826913129587,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6709815318466015,
            "fpr": 0.013172338090010977,
            "logloss": 0.8224125163940221,
            "mae": 0.47999650774815994,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7065471982391335,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7001789521793049,
            "fpr": 0.01425438596491228,
            "logloss": 0.8453059539936462,
            "mae": 0.49399711011925285,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6901367323035503,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6838856309472676,
            "fpr": 0.013172338090010977,
            "logloss": 0.8228142727820424,
            "mae": 0.48003728092371045,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8025212595372209,
            "auditor_fn_violation": 0.014412941722942798,
            "auditor_fp_violation": 0.02135683627120057,
            "ave_precision_score": 0.8012506619083748,
            "fpr": 0.12171052631578948,
            "logloss": 1.4011457382977128,
            "mae": 0.28919092718169953,
            "precision": 0.758695652173913,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.765034743086951,
            "auditor_fn_violation": 0.016275756117337187,
            "auditor_fp_violation": 0.015228065704876902,
            "ave_precision_score": 0.763781030662072,
            "fpr": 0.11745334796926454,
            "logloss": 1.5647590053404106,
            "mae": 0.3123384733960822,
            "precision": 0.7390243902439024,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.6949727000207748,
            "auditor_fn_violation": 0.015203487333404795,
            "auditor_fp_violation": 0.02652935783639622,
            "ave_precision_score": 0.6720837058574705,
            "fpr": 0.23026315789473684,
            "logloss": 2.49565582607178,
            "mae": 0.3001119119777365,
            "precision": 0.6813353566009105,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6690849918993507,
            "auditor_fn_violation": 0.002377943683275923,
            "auditor_fp_violation": 0.028819389995295593,
            "ave_precision_score": 0.6449018181844322,
            "fpr": 0.24368825466520308,
            "logloss": 2.5376866365359425,
            "mae": 0.3329197226643941,
            "precision": 0.6436597110754414,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8005159433717418,
            "auditor_fn_violation": 0.01659252510093972,
            "auditor_fp_violation": 0.019036233695878656,
            "ave_precision_score": 0.7992673632185195,
            "fpr": 0.12828947368421054,
            "logloss": 1.3130929462043694,
            "mae": 0.29126048197510596,
            "precision": 0.7552301255230126,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7590824006435999,
            "auditor_fn_violation": 0.02211985499996444,
            "auditor_fp_violation": 0.018700015681354872,
            "ave_precision_score": 0.7578370456936586,
            "fpr": 0.13721185510428102,
            "logloss": 1.4268113878671411,
            "mae": 0.3182801202508213,
            "precision": 0.7178329571106095,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7915329243646855,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.6833723207262707,
            "fpr": 0.0021929824561403508,
            "logloss": 0.7955652812549983,
            "mae": 0.454699876897952,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7496557855010533,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6329260087557724,
            "fpr": 0.006586169045005488,
            "logloss": 0.7915984455070343,
            "mae": 0.4493336134664837,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7540097612769607,
            "auditor_fn_violation": 0.021360363740308,
            "auditor_fp_violation": 0.040518085594032596,
            "ave_precision_score": 0.75141560490498,
            "fpr": 0.1787280701754386,
            "logloss": 0.9880522350264036,
            "mae": 0.2943602159492219,
            "precision": 0.7104795737122558,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7539460430012147,
            "auditor_fn_violation": 0.01804439618485845,
            "auditor_fp_violation": 0.04376078093147249,
            "ave_precision_score": 0.7534803150703682,
            "fpr": 0.16245883644346873,
            "logloss": 0.8994549391866851,
            "mae": 0.30768855535354317,
            "precision": 0.7051792828685259,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7156235405092137,
            "auditor_fn_violation": 0.02640511666130704,
            "auditor_fp_violation": 0.04149737467183399,
            "ave_precision_score": 0.7133614257413063,
            "fpr": 0.19407894736842105,
            "logloss": 1.1528053033740653,
            "mae": 0.30713628232526907,
            "precision": 0.6910994764397905,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6938059097314164,
            "auditor_fn_violation": 0.02456418195655216,
            "auditor_fp_violation": 0.05235857378077466,
            "ave_precision_score": 0.692723941038009,
            "fpr": 0.20087815587266739,
            "logloss": 1.1500687075660245,
            "mae": 0.33358008238796827,
            "precision": 0.6611111111111111,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7808043078999677,
            "auditor_fn_violation": 0.012950209025619039,
            "auditor_fp_violation": 0.031009084468891952,
            "ave_precision_score": 0.7768620759547353,
            "fpr": 0.2324561403508772,
            "logloss": 1.0961529497723663,
            "mae": 0.29464562293507585,
            "precision": 0.6802413273001509,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7784437802681895,
            "auditor_fn_violation": 0.005068837083593141,
            "auditor_fp_violation": 0.02325740944017564,
            "ave_precision_score": 0.7770841904242397,
            "fpr": 0.2327113062568606,
            "logloss": 0.9799665876474654,
            "mae": 0.31075672124185133,
            "precision": 0.6608,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6832284958751104,
            "auditor_fn_violation": 0.014004269839568375,
            "auditor_fp_violation": 0.020671854815185232,
            "ave_precision_score": 0.6814812155947552,
            "fpr": 0.19188596491228072,
            "logloss": 1.3959232646788813,
            "mae": 0.35225021564369263,
            "precision": 0.6806569343065694,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6457305085579921,
            "auditor_fn_violation": 0.009011529352075545,
            "auditor_fp_violation": 0.024394307668182534,
            "ave_precision_score": 0.6436426382607774,
            "fpr": 0.20417124039517015,
            "logloss": 1.5434984301245096,
            "mae": 0.3693387896510972,
            "precision": 0.6477272727272727,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7465824493402067,
            "auditor_fn_violation": 0.022159842069532282,
            "auditor_fp_violation": 0.03854388048506064,
            "ave_precision_score": 0.7435738493810186,
            "fpr": 0.17434210526315788,
            "logloss": 1.0262907224440099,
            "mae": 0.2964597540476036,
            "precision": 0.7135135135135136,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.746247494606388,
            "auditor_fn_violation": 0.02080404368967717,
            "auditor_fp_violation": 0.04529706366630077,
            "ave_precision_score": 0.7458297004717858,
            "fpr": 0.16136114160263446,
            "logloss": 0.9207292973375938,
            "mae": 0.3113727048603231,
            "precision": 0.7036290322580645,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6971686523941085,
            "auditor_fn_violation": 0.013957373066066389,
            "auditor_fp_violation": 0.027558132266533333,
            "ave_precision_score": 0.6747846397176014,
            "fpr": 0.23903508771929824,
            "logloss": 2.491172031399564,
            "mae": 0.29972339058747605,
            "precision": 0.6741405082212257,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6745331388445464,
            "auditor_fn_violation": 0.0021456022266846553,
            "auditor_fp_violation": 0.0300101928806649,
            "ave_precision_score": 0.6517620563510313,
            "fpr": 0.25466520307354557,
            "logloss": 2.4866955987423918,
            "mae": 0.33048315277726203,
            "precision": 0.6329113924050633,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6878388534466786,
            "auditor_fn_violation": 0.015922571193768536,
            "auditor_fp_violation": 0.030373588365212322,
            "ave_precision_score": 0.6644497420041648,
            "fpr": 0.23684210526315788,
            "logloss": 2.6258913382889744,
            "mae": 0.30414924431184437,
            "precision": 0.6746987951807228,
            "recall": 0.9124236252545825
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.665932706129832,
            "auditor_fn_violation": 0.006574314889056955,
            "auditor_fp_violation": 0.023352967696408974,
            "ave_precision_score": 0.6410424106117265,
            "fpr": 0.2491767288693743,
            "logloss": 2.6454465442373083,
            "mae": 0.3349433237642527,
            "precision": 0.635048231511254,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6940900820545582,
            "auditor_fn_violation": 0.013957373066066389,
            "auditor_fp_violation": 0.02924844772263201,
            "ave_precision_score": 0.6712066188369583,
            "fpr": 0.23684210526315788,
            "logloss": 2.510395549500786,
            "mae": 0.302527362218482,
            "precision": 0.6761619190404797,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6702299333459831,
            "auditor_fn_violation": 0.00729030590834841,
            "auditor_fp_violation": 0.02753057864199468,
            "ave_precision_score": 0.6463671444382499,
            "fpr": 0.2513721185510428,
            "logloss": 2.527784578166696,
            "mae": 0.33370916993485,
            "precision": 0.6376582278481012,
            "recall": 0.8704103671706264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7468685475834926,
            "auditor_fn_violation": 0.023991049415800193,
            "auditor_fp_violation": 0.037908384381381,
            "ave_precision_score": 0.7438596632371983,
            "fpr": 0.17324561403508773,
            "logloss": 1.0216559839144859,
            "mae": 0.2967181309001456,
            "precision": 0.7122040072859745,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7464529345037483,
            "auditor_fn_violation": 0.014056658123771616,
            "auditor_fp_violation": 0.04614238670221107,
            "ave_precision_score": 0.7460227822653096,
            "fpr": 0.15916575192096596,
            "logloss": 0.916771824978687,
            "mae": 0.3116559613327397,
            "precision": 0.7034764826175869,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6945140659193039,
            "auditor_fn_violation": 0.01310429842426841,
            "auditor_fp_violation": 0.0270841146810018,
            "ave_precision_score": 0.671649170123417,
            "fpr": 0.23684210526315788,
            "logloss": 2.5614531258635536,
            "mae": 0.3017404539949436,
            "precision": 0.675187969924812,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6749814019091436,
            "auditor_fn_violation": 0.0016975151318300717,
            "auditor_fp_violation": 0.024725086247451792,
            "ave_precision_score": 0.6509866787499798,
            "fpr": 0.2513721185510428,
            "logloss": 2.5654211884038562,
            "mae": 0.3335585778789868,
            "precision": 0.6324237560192616,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8000363192852483,
            "auditor_fn_violation": 0.013964072605138107,
            "auditor_fp_violation": 0.023604513064133022,
            "ave_precision_score": 0.798738205582647,
            "fpr": 0.12280701754385964,
            "logloss": 1.4188113472132668,
            "mae": 0.2908229278873482,
            "precision": 0.7591397849462366,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7628856262024852,
            "auditor_fn_violation": 0.018094183639842304,
            "auditor_fp_violation": 0.01573770973812138,
            "ave_precision_score": 0.7616213242921602,
            "fpr": 0.11964873765093303,
            "logloss": 1.5841584717401656,
            "mae": 0.3135261326079314,
            "precision": 0.7379807692307693,
            "recall": 0.6630669546436285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7078255886558263,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7000658559127143,
            "fpr": 0.01425438596491228,
            "logloss": 0.8452538389058727,
            "mae": 0.49399247984483574,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6900356521494808,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6821097843961651,
            "fpr": 0.013172338090010977,
            "logloss": 0.8227657332677928,
            "mae": 0.48003463116684025,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6974462821747078,
            "auditor_fn_violation": 0.018542090970807876,
            "auditor_fp_violation": 0.041200462557819735,
            "ave_precision_score": 0.6837989890847261,
            "fpr": 0.18201754385964913,
            "logloss": 1.9550378151446026,
            "mae": 0.29978711123946367,
            "precision": 0.7082601054481547,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6742974328351423,
            "auditor_fn_violation": 0.0207803353777801,
            "auditor_fp_violation": 0.049479575035283045,
            "ave_precision_score": 0.6607591294430704,
            "fpr": 0.18660812294182216,
            "logloss": 1.8107633005897705,
            "mae": 0.3209093596198488,
            "precision": 0.6822429906542056,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.693032094707047,
            "auditor_fn_violation": 0.014580430199735593,
            "auditor_fp_violation": 0.02983445847397592,
            "ave_precision_score": 0.670412227823803,
            "fpr": 0.23026315789473684,
            "logloss": 2.5039851431594475,
            "mae": 0.29992380821166936,
            "precision": 0.6818181818181818,
            "recall": 0.9164969450101833
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.669095499685594,
            "auditor_fn_violation": 0.0037553966044955693,
            "auditor_fp_violation": 0.028745883644346878,
            "ave_precision_score": 0.6449128180736458,
            "fpr": 0.24807903402854006,
            "logloss": 2.540664645163613,
            "mae": 0.3316358696090354,
            "precision": 0.6401273885350318,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8005318130839315,
            "auditor_fn_violation": 0.01659252510093972,
            "auditor_fp_violation": 0.019036233695878656,
            "ave_precision_score": 0.7992831987134841,
            "fpr": 0.12828947368421054,
            "logloss": 1.3131606677756416,
            "mae": 0.2912632405785603,
            "precision": 0.7552301255230126,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7590538971361968,
            "auditor_fn_violation": 0.02211985499996444,
            "auditor_fp_violation": 0.018700015681354872,
            "ave_precision_score": 0.7578086734131841,
            "fpr": 0.13721185510428102,
            "logloss": 1.4269922735971357,
            "mae": 0.3182822497650901,
            "precision": 0.7178329571106095,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8042772471915853,
            "auditor_fn_violation": 0.011793421945903463,
            "auditor_fp_violation": 0.023130495478601496,
            "ave_precision_score": 0.8021533462870732,
            "fpr": 0.12609649122807018,
            "logloss": 1.4115894118280647,
            "mae": 0.28509112424764554,
            "precision": 0.7547974413646056,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7653730341920574,
            "auditor_fn_violation": 0.015521831799010425,
            "auditor_fp_violation": 0.01653892896346245,
            "ave_precision_score": 0.7641629497717065,
            "fpr": 0.11964873765093303,
            "logloss": 1.5278293550886948,
            "mae": 0.3077426781521035,
            "precision": 0.7392344497607656,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7018913840380611,
            "auditor_fn_violation": 0.01087335191338836,
            "auditor_fp_violation": 0.03440013335000208,
            "ave_precision_score": 0.6754073417268532,
            "fpr": 0.20285087719298245,
            "logloss": 2.656858516931934,
            "mae": 0.29283282359859614,
            "precision": 0.6986970684039088,
            "recall": 0.8737270875763747
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6712430971814815,
            "auditor_fn_violation": 0.00664781065593787,
            "auditor_fp_violation": 0.041531088286027924,
            "ave_precision_score": 0.6437539497858732,
            "fpr": 0.20417124039517015,
            "logloss": 2.7672298963492157,
            "mae": 0.3117452340806616,
            "precision": 0.6770833333333334,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7026797413169368,
            "auditor_fn_violation": 0.010138635795190625,
            "auditor_fp_violation": 0.028977580530899705,
            "ave_precision_score": 0.6757800752296899,
            "fpr": 0.20394736842105263,
            "logloss": 2.7975643852733403,
            "mae": 0.29135892307224437,
            "precision": 0.693069306930693,
            "recall": 0.8553971486761711
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6715322470762772,
            "auditor_fn_violation": 0.0020033523553022463,
            "auditor_fp_violation": 0.03522914379802415,
            "ave_precision_score": 0.6448970199181876,
            "fpr": 0.19978046103183314,
            "logloss": 2.932985883661692,
            "mae": 0.30935809224477406,
            "precision": 0.6761565836298933,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7568832405522856,
            "auditor_fn_violation": 0.021083449458677246,
            "auditor_fp_violation": 0.035142413635037714,
            "ave_precision_score": 0.7542814684872416,
            "fpr": 0.17982456140350878,
            "logloss": 0.976607856468333,
            "mae": 0.2935070553631007,
            "precision": 0.7102473498233216,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7559787423243706,
            "auditor_fn_violation": 0.016704876562674113,
            "auditor_fp_violation": 0.041567841461502275,
            "ave_precision_score": 0.7555560645992084,
            "fpr": 0.16794731064763996,
            "logloss": 0.8873906883365326,
            "mae": 0.3069811236110352,
            "precision": 0.6988188976377953,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5968009981474398,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.594132331008467,
            "fpr": 0.4616228070175439,
            "logloss": 0.691814382460982,
            "mae": 0.4993057455540749,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5126747711540736,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5096736935025693,
            "fpr": 0.49176728869374314,
            "logloss": 0.6928460466731537,
            "mae": 0.49981900084555214,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6974430778707899,
            "auditor_fn_violation": 0.018542090970807876,
            "auditor_fp_violation": 0.041200462557819735,
            "ave_precision_score": 0.683795798175373,
            "fpr": 0.18201754385964913,
            "logloss": 1.954743779251489,
            "mae": 0.29982234559929233,
            "precision": 0.7082601054481547,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6743139704617511,
            "auditor_fn_violation": 0.01801594621058197,
            "auditor_fp_violation": 0.04882046808844284,
            "ave_precision_score": 0.6607755701499581,
            "fpr": 0.18551042810098792,
            "logloss": 1.8102663170141464,
            "mae": 0.320952879552729,
            "precision": 0.6829268292682927,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7172727627162401,
            "auditor_fn_violation": 0.029960338728695465,
            "auditor_fp_violation": 0.045315560278368125,
            "ave_precision_score": 0.7150829648587571,
            "fpr": 0.17324561403508773,
            "logloss": 1.130218311241748,
            "mae": 0.30584921720189767,
            "precision": 0.7095588235294118,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.69469146210055,
            "auditor_fn_violation": 0.024549956969413905,
            "auditor_fp_violation": 0.05379684804767132,
            "ave_precision_score": 0.6937312207184381,
            "fpr": 0.18660812294182216,
            "logloss": 1.1318797893103296,
            "mae": 0.3340634184919513,
            "precision": 0.6699029126213593,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6940078584853916,
            "auditor_fn_violation": 0.013633562010933646,
            "auditor_fp_violation": 0.026912218193940914,
            "ave_precision_score": 0.6711079910447083,
            "fpr": 0.23684210526315788,
            "logloss": 2.524773415110712,
            "mae": 0.3008432171168013,
            "precision": 0.6746987951807228,
            "recall": 0.9124236252545825
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.67013952155929,
            "auditor_fn_violation": 0.0009649282942106679,
            "auditor_fp_violation": 0.030789360200721344,
            "ave_precision_score": 0.646519218642186,
            "fpr": 0.2524698133918771,
            "logloss": 2.5449355234137006,
            "mae": 0.3327165185856952,
            "precision": 0.637223974763407,
            "recall": 0.8725701943844493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6955759930327218,
            "auditor_fn_violation": 0.015826544467074,
            "auditor_fp_violation": 0.030014168437721388,
            "ave_precision_score": 0.6729639122879219,
            "fpr": 0.2324561403508772,
            "logloss": 2.462521358828951,
            "mae": 0.30270710842905363,
            "precision": 0.6787878787878788,
            "recall": 0.9124236252545825
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6711791413982556,
            "auditor_fn_violation": 0.006024282053044979,
            "auditor_fp_violation": 0.029537302022894785,
            "ave_precision_score": 0.6478331952833617,
            "fpr": 0.24478594950603733,
            "logloss": 2.4754592796731867,
            "mae": 0.33280583765885297,
            "precision": 0.6426282051282052,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7076834633447289,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.7012198537928804,
            "fpr": 0.01425438596491228,
            "logloss": 0.845156458577916,
            "mae": 0.49398377238723795,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6873270618328752,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6803361109415018,
            "fpr": 0.013172338090010977,
            "logloss": 0.8226750420453932,
            "mae": 0.48002962624136886,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6830833505388323,
            "auditor_fn_violation": 0.011052006288634007,
            "auditor_fp_violation": 0.023781618535650296,
            "ave_precision_score": 0.6811049851008872,
            "fpr": 0.17543859649122806,
            "logloss": 1.3782904219171004,
            "mae": 0.3570785082318087,
            "precision": 0.6844181459566075,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6460787215550303,
            "auditor_fn_violation": 0.01376741671862739,
            "auditor_fp_violation": 0.021650070566096916,
            "ave_precision_score": 0.6438278611575711,
            "fpr": 0.1778265642151482,
            "logloss": 1.5237291883279254,
            "mae": 0.37067387303454735,
            "precision": 0.6673511293634496,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7024420808530718,
            "auditor_fn_violation": 0.03456962161003325,
            "auditor_fp_violation": 0.007753573363337082,
            "ave_precision_score": 0.6978200431836884,
            "fpr": 0.01425438596491228,
            "logloss": 0.845296947328947,
            "mae": 0.4939963116490266,
            "precision": 0.8470588235294118,
            "recall": 0.14663951120162932
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6888082651160925,
            "auditor_fn_violation": 0.02549117695172752,
            "auditor_fp_violation": 0.007321232554492707,
            "ave_precision_score": 0.6839705206827001,
            "fpr": 0.013172338090010977,
            "logloss": 0.8228058830041964,
            "mae": 0.4800368240910749,
            "precision": 0.8,
            "recall": 0.10367170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7810313935632114,
            "auditor_fn_violation": 0.012479008110908638,
            "auditor_fp_violation": 0.03098564403883819,
            "ave_precision_score": 0.7770502967784182,
            "fpr": 0.23135964912280702,
            "logloss": 1.089657775681794,
            "mae": 0.29404620918971414,
            "precision": 0.680786686838124,
            "recall": 0.9164969450101833
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7779888117706995,
            "auditor_fn_violation": 0.005068837083593141,
            "auditor_fp_violation": 0.02325740944017564,
            "ave_precision_score": 0.7766280740007807,
            "fpr": 0.2327113062568606,
            "logloss": 0.975708950075112,
            "mae": 0.3102827042639756,
            "precision": 0.6608,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.717112032423276,
            "auditor_fn_violation": 0.029591864079751316,
            "auditor_fp_violation": 0.044224278034754344,
            "ave_precision_score": 0.7148404056635469,
            "fpr": 0.17543859649122806,
            "logloss": 1.129499314028168,
            "mae": 0.30714787311675307,
            "precision": 0.7074954296160878,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6950616315100748,
            "auditor_fn_violation": 0.02425123223951086,
            "auditor_fp_violation": 0.05515916575192097,
            "ave_precision_score": 0.6940524762888656,
            "fpr": 0.18441273326015367,
            "logloss": 1.1271938363163752,
            "mae": 0.3335451578409744,
            "precision": 0.6737864077669903,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7556926575528751,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.7457115281958085,
            "fpr": 0.0021929824561403508,
            "logloss": 0.7585855514548812,
            "mae": 0.4499664766910045,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6928987827648176,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6861642562229576,
            "fpr": 0.006586169045005488,
            "logloss": 0.7582705677679744,
            "mae": 0.44650719649312787,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.692946019296785,
            "auditor_fn_violation": 0.013633562010933646,
            "auditor_fp_violation": 0.026912218193940914,
            "ave_precision_score": 0.670053803253849,
            "fpr": 0.23684210526315788,
            "logloss": 2.534326007660432,
            "mae": 0.30116448767969745,
            "precision": 0.6746987951807228,
            "recall": 0.9124236252545825
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6696093068027236,
            "auditor_fn_violation": 0.0009649282942106679,
            "auditor_fp_violation": 0.030789360200721344,
            "ave_precision_score": 0.6455375170190829,
            "fpr": 0.2524698133918771,
            "logloss": 2.574423751654903,
            "mae": 0.3331670027334525,
            "precision": 0.637223974763407,
            "recall": 0.8725701943844493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6898499653418488,
            "auditor_fn_violation": 0.013932808089470112,
            "auditor_fp_violation": 0.023299787473434187,
            "ave_precision_score": 0.6669824171431904,
            "fpr": 0.24013157894736842,
            "logloss": 2.5855394908103007,
            "mae": 0.3038943619822897,
            "precision": 0.669683257918552,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6697180614474361,
            "auditor_fn_violation": 0.004933699705779855,
            "auditor_fp_violation": 0.022456190214834564,
            "ave_precision_score": 0.6448801017385108,
            "fpr": 0.2513721185510428,
            "logloss": 2.631997144725605,
            "mae": 0.3360846720260836,
            "precision": 0.6336,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6955412756374678,
            "auditor_fn_violation": 0.015203487333404795,
            "auditor_fp_violation": 0.03019387840146686,
            "ave_precision_score": 0.6729137346095154,
            "fpr": 0.23464912280701755,
            "logloss": 2.462074517513423,
            "mae": 0.3027592832710362,
            "precision": 0.6772247360482655,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6711221124589042,
            "auditor_fn_violation": 0.004976374667194572,
            "auditor_fp_violation": 0.030605594323349545,
            "ave_precision_score": 0.6478205517722417,
            "fpr": 0.24478594950603733,
            "logloss": 2.476675420756805,
            "mae": 0.3333744086202099,
            "precision": 0.6420545746388443,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7039579628750524,
            "auditor_fn_violation": 0.011264158359238222,
            "auditor_fp_violation": 0.0301704379714131,
            "ave_precision_score": 0.6770376681862685,
            "fpr": 0.20175438596491227,
            "logloss": 2.783157031395372,
            "mae": 0.28882903538988236,
            "precision": 0.6963696369636964,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.672220983683265,
            "auditor_fn_violation": 0.006052732027321463,
            "auditor_fp_violation": 0.03535165438293869,
            "ave_precision_score": 0.6452920939868194,
            "fpr": 0.20636663007683864,
            "logloss": 2.927064926989752,
            "mae": 0.30952934403349724,
            "precision": 0.6713286713286714,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7064359302574593,
            "auditor_fn_violation": 0.010145335334262337,
            "auditor_fp_violation": 0.027089323665458184,
            "ave_precision_score": 0.6811449779336827,
            "fpr": 0.26206140350877194,
            "logloss": 2.5520109390239227,
            "mae": 0.31192657765963694,
            "precision": 0.6595441595441596,
            "recall": 0.9429735234215886
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6828622695297906,
            "auditor_fn_violation": 0.0018682149774889576,
            "auditor_fp_violation": 0.03315626470127019,
            "ave_precision_score": 0.6570954469930632,
            "fpr": 0.278814489571899,
            "logloss": 2.5848533166514938,
            "mae": 0.34633738145851684,
            "precision": 0.6197604790419161,
            "recall": 0.8941684665226782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6961323859972721,
            "auditor_fn_violation": 0.015203487333404795,
            "auditor_fp_violation": 0.03019387840146686,
            "ave_precision_score": 0.6735183582844214,
            "fpr": 0.23464912280701755,
            "logloss": 2.459602355900943,
            "mae": 0.3027565396257115,
            "precision": 0.6772247360482655,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6713059604674102,
            "auditor_fn_violation": 0.006024282053044979,
            "auditor_fp_violation": 0.029537302022894785,
            "ave_precision_score": 0.6485258462537715,
            "fpr": 0.24478594950603733,
            "logloss": 2.4519511367570748,
            "mae": 0.332696203259351,
            "precision": 0.6426282051282052,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7900011715017973,
            "auditor_fn_violation": 0.004488691178046948,
            "auditor_fp_violation": 0.0011876484560570072,
            "ave_precision_score": 0.6826569843639066,
            "fpr": 0.0021929824561403508,
            "logloss": 0.8014905155399926,
            "mae": 0.4553980574730718,
            "precision": 0.9797979797979798,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7496557855010533,
            "auditor_fn_violation": 0.0022238396559449785,
            "auditor_fp_violation": 0.0012594088129214366,
            "ave_precision_score": 0.6329260087557724,
            "fpr": 0.006586169045005488,
            "logloss": 0.7968077893614265,
            "mae": 0.4495516255514289,
            "precision": 0.9318181818181818,
            "recall": 0.1771058315334773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7033543706637053,
            "auditor_fn_violation": 0.010545074498874476,
            "auditor_fp_violation": 0.03326717923073718,
            "ave_precision_score": 0.6766587256943304,
            "fpr": 0.20833333333333334,
            "logloss": 2.6474954882191843,
            "mae": 0.29473813408547367,
            "precision": 0.6940418679549114,
            "recall": 0.8778004073319755
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6732564914212598,
            "auditor_fn_violation": 0.0027952099726643188,
            "auditor_fp_violation": 0.04165604908264074,
            "ave_precision_score": 0.6454789807733201,
            "fpr": 0.20965971459934138,
            "logloss": 2.755924109469417,
            "mae": 0.3146795491981619,
            "precision": 0.6746166950596252,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7076760587803472,
            "auditor_fn_violation": 0.015203487333404795,
            "auditor_fp_violation": 0.025177626369962923,
            "ave_precision_score": 0.686299794058371,
            "fpr": 0.22807017543859648,
            "logloss": 2.345365753759452,
            "mae": 0.2968497775737729,
            "precision": 0.6834094368340944,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6793116379004362,
            "auditor_fn_violation": 0.002885301557873175,
            "auditor_fp_violation": 0.028900246981339188,
            "ave_precision_score": 0.6576335313736557,
            "fpr": 0.23819978046103182,
            "logloss": 2.3673357271512847,
            "mae": 0.3276197413811514,
            "precision": 0.6482982171799028,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8030136994090027,
            "auditor_fn_violation": 0.011293189695215639,
            "auditor_fp_violation": 0.0211797307996833,
            "ave_precision_score": 0.8008948793138373,
            "fpr": 0.1425438596491228,
            "logloss": 1.3610827040047724,
            "mae": 0.2875301586371896,
            "precision": 0.7425742574257426,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7640281928416564,
            "auditor_fn_violation": 0.01294473829579912,
            "auditor_fp_violation": 0.016587933197428264,
            "ave_precision_score": 0.7627304620610352,
            "fpr": 0.14709110867178923,
            "logloss": 1.4282050509739337,
            "mae": 0.3122327706926193,
            "precision": 0.7124463519313304,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8022251934496252,
            "auditor_fn_violation": 0.01475461821560011,
            "auditor_fp_violation": 0.020908863607951,
            "ave_precision_score": 0.8017683926248143,
            "fpr": 0.13267543859649122,
            "logloss": 1.188753351021078,
            "mae": 0.28838889640676413,
            "precision": 0.7489626556016598,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7646246240143858,
            "auditor_fn_violation": 0.02155796800800393,
            "auditor_fp_violation": 0.027189999215932258,
            "ave_precision_score": 0.7641273391092936,
            "fpr": 0.132821075740944,
            "logloss": 1.1708234371488218,
            "mae": 0.3128205945768952,
            "precision": 0.7274774774774775,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.6970055979750319,
            "auditor_fn_violation": 0.015826544467074,
            "auditor_fp_violation": 0.024740071675626116,
            "ave_precision_score": 0.6744114283091711,
            "fpr": 0.22916666666666666,
            "logloss": 2.4517838813890003,
            "mae": 0.3015614140842059,
            "precision": 0.6818873668188736,
            "recall": 0.9124236252545825
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6723995168457462,
            "auditor_fn_violation": 0.0036842716688043667,
            "auditor_fp_violation": 0.028819389995295593,
            "ave_precision_score": 0.6496007140856512,
            "fpr": 0.24368825466520308,
            "logloss": 2.4441847629693925,
            "mae": 0.3323932746801749,
            "precision": 0.6430868167202572,
            "recall": 0.8639308855291576
        }
    }
]