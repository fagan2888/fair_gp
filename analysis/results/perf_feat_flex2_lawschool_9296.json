[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7882760531992064,
            "auditor_fn_violation": 0.015969826786840256,
            "auditor_fp_violation": 0.020885785077728487,
            "ave_precision_score": 0.7840034376721163,
            "fpr": 0.16557017543859648,
            "logloss": 1.1408644192425796,
            "mae": 0.28066092561338474,
            "precision": 0.7172284644194756,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8248010234994625,
            "auditor_fn_violation": 0.010406420944291415,
            "auditor_fp_violation": 0.017506956321956455,
            "ave_precision_score": 0.8221464210475056,
            "fpr": 0.14709110867178923,
            "logloss": 0.9635179536757208,
            "mae": 0.25302574210819734,
            "precision": 0.75,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 9296,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7845956796877785,
            "auditor_fn_violation": 0.0012100812284410816,
            "auditor_fp_violation": 0.006301702433760951,
            "ave_precision_score": 0.7478926664078809,
            "fpr": 0.4418859649122807,
            "logloss": 3.09527573720849,
            "mae": 0.41040239883191115,
            "precision": 0.5389016018306636,
            "recall": 0.9957716701902748
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.8128413672526936,
            "auditor_fn_violation": 0.00118441501537001,
            "auditor_fp_violation": 0.005616113139151969,
            "ave_precision_score": 0.7807793778513828,
            "fpr": 0.41931942919868276,
            "logloss": 2.8273150286866673,
            "mae": 0.397674249724457,
            "precision": 0.5552968568102444,
            "recall": 0.9916839916839917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 9296,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6672595476017406,
            "auditor_fn_violation": 0.02162150884611107,
            "auditor_fp_violation": 0.014404248091755587,
            "ave_precision_score": 0.6754607417409061,
            "fpr": 0.07017543859649122,
            "logloss": 5.93387284333953,
            "mae": 0.40492809650459716,
            "precision": 0.7470355731225297,
            "recall": 0.39957716701902746
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6907656425626909,
            "auditor_fn_violation": 0.0011570296970955692,
            "auditor_fp_violation": 0.011638118091542644,
            "ave_precision_score": 0.6993900454297322,
            "fpr": 0.05598243688254665,
            "logloss": 6.10736014251771,
            "mae": 0.40930268766717526,
            "precision": 0.7866108786610879,
            "recall": 0.3908523908523909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7752499566251316,
            "auditor_fn_violation": 0.010526779422128266,
            "auditor_fp_violation": 0.016974383567118258,
            "ave_precision_score": 0.7704166204381473,
            "fpr": 0.13925438596491227,
            "logloss": 1.1920095227300127,
            "mae": 0.29505482934449223,
            "precision": 0.7320675105485233,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8079266228204014,
            "auditor_fn_violation": 0.014402395302505075,
            "auditor_fp_violation": 0.015561738952850181,
            "ave_precision_score": 0.8036460007393619,
            "fpr": 0.11964873765093303,
            "logloss": 1.066499483425023,
            "mae": 0.2678407855691342,
            "precision": 0.7680851063829788,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8378491795493176,
            "auditor_fn_violation": 0.01183885983457587,
            "auditor_fp_violation": 0.0188451624505455,
            "ave_precision_score": 0.8381657490063834,
            "fpr": 0.13596491228070176,
            "logloss": 0.5816248205674274,
            "mae": 0.28674130538128156,
            "precision": 0.7432712215320911,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8752397894144086,
            "auditor_fn_violation": 0.00792348542074119,
            "auditor_fp_violation": 0.015298802746789887,
            "ave_precision_score": 0.8754074842997215,
            "fpr": 0.11964873765093303,
            "logloss": 0.5228997144246104,
            "mae": 0.264924305118235,
            "precision": 0.7780040733197556,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7982701933038008,
            "auditor_fn_violation": 0.011507362486554654,
            "auditor_fp_violation": 0.013190364864324825,
            "ave_precision_score": 0.7987026946047745,
            "fpr": 0.08662280701754387,
            "logloss": 0.6060622748470703,
            "mae": 0.34677703412195604,
            "precision": 0.7942708333333334,
            "recall": 0.6448202959830867
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8679413401242335,
            "auditor_fn_violation": 0.0034710890912866884,
            "auditor_fp_violation": 0.012049115462180586,
            "ave_precision_score": 0.8681014982002333,
            "fpr": 0.06586169045005488,
            "logloss": 0.5241685647906429,
            "mae": 0.319716032674402,
            "precision": 0.8457583547557841,
            "recall": 0.683991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7885815721282314,
            "auditor_fn_violation": 0.01620859760394644,
            "auditor_fp_violation": 0.021048135715142077,
            "ave_precision_score": 0.7845897642787083,
            "fpr": 0.16447368421052633,
            "logloss": 1.094274610658543,
            "mae": 0.281389545900799,
            "precision": 0.7191011235955056,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8264612668537744,
            "auditor_fn_violation": 0.008870561011065953,
            "auditor_fp_violation": 0.019171368034105126,
            "ave_precision_score": 0.8239458757714471,
            "fpr": 0.14270032930845225,
            "logloss": 0.9209949084831973,
            "mae": 0.25238225115635426,
            "precision": 0.7560975609756098,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8043814714911159,
            "auditor_fn_violation": 0.008778884314380031,
            "auditor_fp_violation": 0.022644167366023267,
            "ave_precision_score": 0.8045441582633004,
            "fpr": 0.36951754385964913,
            "logloss": 2.371305283435547,
            "mae": 0.3800893613085853,
            "precision": 0.5739570164348925,
            "recall": 0.959830866807611
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.8469406648008064,
            "auditor_fn_violation": 0.003722121175469145,
            "auditor_fp_violation": 0.016271411431343027,
            "ave_precision_score": 0.8467436104319532,
            "fpr": 0.3589462129527991,
            "logloss": 2.1589766191714204,
            "mae": 0.3638961907273085,
            "precision": 0.59125,
            "recall": 0.9833679833679834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7870342557768826,
            "auditor_fn_violation": 0.007241942064463486,
            "auditor_fp_violation": 0.016637193781720825,
            "ave_precision_score": 0.7830210214661066,
            "fpr": 0.13925438596491227,
            "logloss": 1.0349460574357696,
            "mae": 0.2810011136899256,
            "precision": 0.7465069860279441,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8161812617879747,
            "auditor_fn_violation": 0.006634093351985781,
            "auditor_fp_violation": 0.013733949403926174,
            "ave_precision_score": 0.8135725751723633,
            "fpr": 0.12952799121844127,
            "logloss": 0.9275188413689919,
            "mae": 0.26283070178639284,
            "precision": 0.7635270541082164,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7876965833581652,
            "auditor_fn_violation": 0.008959701049664329,
            "auditor_fp_violation": 0.018892618790712544,
            "ave_precision_score": 0.783839051091171,
            "fpr": 0.14364035087719298,
            "logloss": 1.021983351014447,
            "mae": 0.28169514302606624,
            "precision": 0.733739837398374,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8217510367778681,
            "auditor_fn_violation": 0.010242109034644708,
            "auditor_fp_violation": 0.013887116125903052,
            "ave_precision_score": 0.8191930610070643,
            "fpr": 0.1207464324917673,
            "logloss": 0.8848016416852907,
            "mae": 0.2544752707603211,
            "precision": 0.7791164658634538,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.823102702050975,
            "auditor_fn_violation": 0.009446515336968216,
            "auditor_fp_violation": 0.02277654557806819,
            "ave_precision_score": 0.8233977544742763,
            "fpr": 0.14583333333333334,
            "logloss": 0.7441604738849364,
            "mae": 0.28274050387207944,
            "precision": 0.7323943661971831,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8618628086942995,
            "auditor_fn_violation": 0.006367086498809884,
            "auditor_fp_violation": 0.011878079289306412,
            "ave_precision_score": 0.8620483790817506,
            "fpr": 0.12403951701427003,
            "logloss": 0.6591467274900227,
            "mae": 0.2576687564862231,
            "precision": 0.7703252032520326,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7300676108530123,
            "auditor_fn_violation": 0.030395756833945336,
            "auditor_fp_violation": 0.023858050593454028,
            "ave_precision_score": 0.719393767672755,
            "fpr": 0.1524122807017544,
            "logloss": 1.9531289689876494,
            "mae": 0.30359379112904333,
            "precision": 0.7169042769857433,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8038257457880136,
            "auditor_fn_violation": 0.02064852997893613,
            "auditor_fp_violation": 0.027552140504939624,
            "ave_precision_score": 0.7987617884397177,
            "fpr": 0.141602634467618,
            "logloss": 1.2544680791676115,
            "mae": 0.274334065403635,
            "precision": 0.7383367139959433,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8472441433366615,
            "auditor_fn_violation": 0.005913634509105749,
            "auditor_fp_violation": 0.019252287895136475,
            "ave_precision_score": 0.847500719814108,
            "fpr": 0.13486842105263158,
            "logloss": 0.5499560781812054,
            "mae": 0.2772786335444196,
            "precision": 0.7515151515151515,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8757145318419962,
            "auditor_fn_violation": 0.006638657571698193,
            "auditor_fp_violation": 0.011990401552089452,
            "ave_precision_score": 0.8759193789914821,
            "fpr": 0.11964873765093303,
            "logloss": 0.5073642166350653,
            "mae": 0.26256293583273865,
            "precision": 0.7784552845528455,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7875183602445593,
            "auditor_fn_violation": 0.008352342272170918,
            "auditor_fp_violation": 0.018800203812492505,
            "ave_precision_score": 0.7838890298906086,
            "fpr": 0.14035087719298245,
            "logloss": 0.9941704572347914,
            "mae": 0.2836895602205482,
            "precision": 0.7387755102040816,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8236211002039765,
            "auditor_fn_violation": 0.010285469121912593,
            "auditor_fp_violation": 0.015490261149260977,
            "ave_precision_score": 0.8220001496649972,
            "fpr": 0.12184412733260154,
            "logloss": 0.8402698895084599,
            "mae": 0.2539491168451461,
            "precision": 0.7775551102204409,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7805062083006851,
            "auditor_fn_violation": 0.009033882274396355,
            "auditor_fp_violation": 0.017096770970706953,
            "ave_precision_score": 0.7753452676127568,
            "fpr": 0.15021929824561403,
            "logloss": 1.1926470655469765,
            "mae": 0.28578809288817614,
            "precision": 0.7254509018036072,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.81224443657312,
            "auditor_fn_violation": 0.011243955261518382,
            "auditor_fp_violation": 0.015982947438286585,
            "ave_precision_score": 0.8077948298777653,
            "fpr": 0.132821075740944,
            "logloss": 1.0759324325426587,
            "mae": 0.26263862948180866,
            "precision": 0.7570281124497992,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7816579271007913,
            "auditor_fn_violation": 0.0048032343013983195,
            "auditor_fp_violation": 0.017326559565200024,
            "ave_precision_score": 0.7776654539958515,
            "fpr": 0.14583333333333334,
            "logloss": 1.088050740364394,
            "mae": 0.2885866513870863,
            "precision": 0.7268993839835729,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8160577609880688,
            "auditor_fn_violation": 0.008642350025445531,
            "auditor_fp_violation": 0.014887805376151943,
            "ave_precision_score": 0.8126180589862194,
            "fpr": 0.1163556531284303,
            "logloss": 0.9611920384006785,
            "mae": 0.2586030255581289,
            "precision": 0.7796257796257796,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 9296,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7917615149449567,
            "auditor_fn_violation": 0.009970420236638107,
            "auditor_fp_violation": 0.01805339088039006,
            "ave_precision_score": 0.7873031194080256,
            "fpr": 0.35964912280701755,
            "logloss": 2.3771189905319217,
            "mae": 0.3709104268934432,
            "precision": 0.5800256081946222,
            "recall": 0.9577167019027484
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8257298758308391,
            "auditor_fn_violation": 0.004304059188801231,
            "auditor_fp_violation": 0.016705383810277495,
            "ave_precision_score": 0.8221474426231028,
            "fpr": 0.34906695938529086,
            "logloss": 2.059191608442082,
            "mae": 0.3511718796449547,
            "precision": 0.5974683544303797,
            "recall": 0.9812889812889813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8337826580966938,
            "auditor_fn_violation": 0.008890156151478062,
            "auditor_fp_violation": 0.012088878232026545,
            "ave_precision_score": 0.8340603695965862,
            "fpr": 0.11293859649122807,
            "logloss": 0.5840204961551746,
            "mae": 0.3149010030327847,
            "precision": 0.775599128540305,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8953975124186309,
            "auditor_fn_violation": 0.004566501822264728,
            "auditor_fp_violation": 0.010846756694662141,
            "ave_precision_score": 0.8955243088937631,
            "fpr": 0.09549945115257959,
            "logloss": 0.46847681263201746,
            "mae": 0.28404224870850764,
            "precision": 0.8148936170212766,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7717688390305534,
            "auditor_fn_violation": 0.003444790623493199,
            "auditor_fp_violation": 0.016657175398633255,
            "ave_precision_score": 0.7673810241606503,
            "fpr": 0.15570175438596492,
            "logloss": 1.1332300728621534,
            "mae": 0.29536023213440055,
            "precision": 0.7171314741035857,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8071054086072106,
            "auditor_fn_violation": 0.012163645533568695,
            "auditor_fp_violation": 0.01619227529165497,
            "ave_precision_score": 0.8035742473829135,
            "fpr": 0.13062568605927552,
            "logloss": 0.9820735956938155,
            "mae": 0.26715281040096844,
            "precision": 0.7600806451612904,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 9296,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7960634322586096,
            "auditor_fn_violation": 0.00937928860205482,
            "auditor_fp_violation": 0.014923770131479051,
            "ave_precision_score": 0.7970536630675614,
            "fpr": 0.17434210526315788,
            "logloss": 0.7955079586792001,
            "mae": 0.29606358301914,
            "precision": 0.7175843694493783,
            "recall": 0.854122621564482
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8348450947103716,
            "auditor_fn_violation": 0.009037155030568863,
            "auditor_fp_violation": 0.018035381512776665,
            "ave_precision_score": 0.8351306688234517,
            "fpr": 0.15916575192096596,
            "logloss": 0.7158413009678652,
            "mae": 0.276733651462194,
            "precision": 0.7424511545293073,
            "recall": 0.8690228690228691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7876989572257356,
            "auditor_fn_violation": 0.011729906160750715,
            "auditor_fp_violation": 0.022351936218678817,
            "ave_precision_score": 0.7835436157799556,
            "fpr": 0.19736842105263158,
            "logloss": 1.1393413021927201,
            "mae": 0.28318514192406047,
            "precision": 0.6943972835314092,
            "recall": 0.864693446088795
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8202412333835991,
            "auditor_fn_violation": 0.012070079029464326,
            "auditor_fp_violation": 0.020386490695121644,
            "ave_precision_score": 0.8174465265011605,
            "fpr": 0.17892425905598244,
            "logloss": 1.0090916766524358,
            "mae": 0.26297225458008494,
            "precision": 0.7237288135593221,
            "recall": 0.8877338877338877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8042502534742618,
            "auditor_fn_violation": 0.01425438596491228,
            "auditor_fp_violation": 0.013919693881628902,
            "ave_precision_score": 0.8049659598425547,
            "fpr": 0.12828947368421054,
            "logloss": 0.873186765429393,
            "mae": 0.28450973290418197,
            "precision": 0.7462039045553145,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8476777711132893,
            "auditor_fn_violation": 0.010703095225597977,
            "auditor_fp_violation": 0.012360554463533556,
            "ave_precision_score": 0.84790428228349,
            "fpr": 0.11745334796926454,
            "logloss": 0.7722417586483051,
            "mae": 0.26240203147389096,
            "precision": 0.7703862660944206,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7824414491772038,
            "auditor_fn_violation": 0.00835466043544379,
            "auditor_fp_violation": 0.01793100347680135,
            "ave_precision_score": 0.7812686648759124,
            "fpr": 0.14035087719298245,
            "logloss": 1.0589278114811245,
            "mae": 0.28862994514497875,
            "precision": 0.7344398340248963,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.821387971770521,
            "auditor_fn_violation": 0.00654737317745002,
            "auditor_fp_violation": 0.015076710999923422,
            "ave_precision_score": 0.8217069234596885,
            "fpr": 0.11855104281009879,
            "logloss": 0.899176788305057,
            "mae": 0.26398106936632987,
            "precision": 0.7735849056603774,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7873350313815914,
            "auditor_fn_violation": 0.020712788843143804,
            "auditor_fp_violation": 0.0156156336170723,
            "ave_precision_score": 0.7877071659230401,
            "fpr": 0.14473684210526316,
            "logloss": 0.9413734026670888,
            "mae": 0.29130920417065187,
            "precision": 0.7283950617283951,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8236183939598771,
            "auditor_fn_violation": 0.014185594866165668,
            "auditor_fp_violation": 0.02436371990912108,
            "ave_precision_score": 0.8239634583882358,
            "fpr": 0.12952799121844127,
            "logloss": 0.8245366713271307,
            "mae": 0.2662094008201185,
            "precision": 0.7581967213114754,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7863102688441348,
            "auditor_fn_violation": 0.015079652090056008,
            "auditor_fp_violation": 0.018765235982895742,
            "ave_precision_score": 0.781268580862146,
            "fpr": 0.16776315789473684,
            "logloss": 1.190961645381829,
            "mae": 0.2812162894779849,
            "precision": 0.7140186915887851,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8231880175560657,
            "auditor_fn_violation": 0.009797097612684885,
            "auditor_fp_violation": 0.017333367370382664,
            "ave_precision_score": 0.8204021735569649,
            "fpr": 0.14818880351262348,
            "logloss": 0.9992739767490516,
            "mae": 0.25460882285563724,
            "precision": 0.75,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8144969293800606,
            "auditor_fn_violation": 0.010582415340677281,
            "auditor_fp_violation": 0.015280941533788915,
            "ave_precision_score": 0.8149822568242304,
            "fpr": 0.15679824561403508,
            "logloss": 0.9261197147056114,
            "mae": 0.27879767585316056,
            "precision": 0.723404255319149,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.853467057201001,
            "auditor_fn_violation": 0.014224390733721141,
            "auditor_fp_violation": 0.015342199984683336,
            "ave_precision_score": 0.8536907802679868,
            "fpr": 0.14270032930845225,
            "logloss": 0.7748110027111906,
            "mae": 0.2574041300001107,
            "precision": 0.7509578544061303,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8238886493837739,
            "auditor_fn_violation": 0.008897110641296693,
            "auditor_fp_violation": 0.023435938936178725,
            "ave_precision_score": 0.8241798693792635,
            "fpr": 0.14692982456140352,
            "logloss": 0.7368279057521573,
            "mae": 0.282733366671317,
            "precision": 0.7314629258517034,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8627969809895362,
            "auditor_fn_violation": 0.0055341164012953315,
            "auditor_fp_violation": 0.013121282516018693,
            "ave_precision_score": 0.8629635412363933,
            "fpr": 0.12733260153677278,
            "logloss": 0.6510252532933949,
            "mae": 0.2573327351572248,
            "precision": 0.7670682730923695,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7890091615088115,
            "auditor_fn_violation": 0.01585391862319647,
            "auditor_fp_violation": 0.02162260720137474,
            "ave_precision_score": 0.7849942207606012,
            "fpr": 0.15570175438596492,
            "logloss": 1.0993197535753718,
            "mae": 0.28026162902649543,
            "precision": 0.727447216890595,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8274845330547568,
            "auditor_fn_violation": 0.010064104465860783,
            "auditor_fp_violation": 0.016970872795037402,
            "ave_precision_score": 0.8250393991359316,
            "fpr": 0.13391877058177826,
            "logloss": 0.9166935624292031,
            "mae": 0.2510782624889091,
            "precision": 0.7640232108317214,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7891192380281905,
            "auditor_fn_violation": 0.013904343310708063,
            "auditor_fp_violation": 0.02032879750629421,
            "ave_precision_score": 0.7848480259688568,
            "fpr": 0.16228070175438597,
            "logloss": 1.128305646207001,
            "mae": 0.28039120571347415,
            "precision": 0.720226843100189,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8260838932275456,
            "auditor_fn_violation": 0.010406420944291415,
            "auditor_fp_violation": 0.0193602736578766,
            "ave_precision_score": 0.823581221512858,
            "fpr": 0.14709110867178923,
            "logloss": 0.9538752432707361,
            "mae": 0.25254913983194344,
            "precision": 0.75,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8221641313232821,
            "auditor_fn_violation": 0.008646749007826124,
            "auditor_fp_violation": 0.019519542021340375,
            "ave_precision_score": 0.822615919453022,
            "fpr": 0.14583333333333334,
            "logloss": 0.7184758878873114,
            "mae": 0.28082637740960326,
            "precision": 0.7329317269076305,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8643803942637905,
            "auditor_fn_violation": 0.00885915046178493,
            "auditor_fp_violation": 0.01418579123375795,
            "ave_precision_score": 0.8645643971920072,
            "fpr": 0.11964873765093303,
            "logloss": 0.633246261265593,
            "mae": 0.2534487465517812,
            "precision": 0.7780040733197556,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8218674376997709,
            "auditor_fn_violation": 0.010582415340677274,
            "auditor_fp_violation": 0.019334712064900294,
            "ave_precision_score": 0.8222779012831041,
            "fpr": 0.14364035087719298,
            "logloss": 0.7308576647288669,
            "mae": 0.28339358038621804,
            "precision": 0.7348178137651822,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8623705644909501,
            "auditor_fn_violation": 0.009331547202019215,
            "auditor_fp_violation": 0.014877594261353492,
            "ave_precision_score": 0.8625502652321239,
            "fpr": 0.1251372118551043,
            "logloss": 0.6505646699642899,
            "mae": 0.2593942469435699,
            "precision": 0.7668711656441718,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7856163996544623,
            "auditor_fn_violation": 0.008192389006342497,
            "auditor_fp_violation": 0.01825570475162851,
            "ave_precision_score": 0.7804949352854309,
            "fpr": 0.15021929824561403,
            "logloss": 1.166914558015045,
            "mae": 0.2803478115146492,
            "precision": 0.7313725490196078,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8180961661833217,
            "auditor_fn_violation": 0.01410343891134232,
            "auditor_fp_violation": 0.015255405508896435,
            "ave_precision_score": 0.8136780597485219,
            "fpr": 0.13830954994511527,
            "logloss": 1.0470402553466425,
            "mae": 0.2554318682531556,
            "precision": 0.7567567567567568,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8224832219283649,
            "auditor_fn_violation": 0.0062034049182152036,
            "auditor_fp_violation": 0.015877892339048082,
            "ave_precision_score": 0.8228160682109179,
            "fpr": 0.13925438596491227,
            "logloss": 0.7447262624140478,
            "mae": 0.28254323366631423,
            "precision": 0.741869918699187,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8609748401815922,
            "auditor_fn_violation": 0.006996948819122258,
            "auditor_fp_violation": 0.01459423582569627,
            "ave_precision_score": 0.8611605954822327,
            "fpr": 0.12403951701427003,
            "logloss": 0.6628929371435087,
            "mae": 0.2580085065041299,
            "precision": 0.77079107505071,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7888557093266999,
            "auditor_fn_violation": 0.013276121063758767,
            "auditor_fp_violation": 0.01553320944730848,
            "ave_precision_score": 0.7873613913200086,
            "fpr": 0.13486842105263158,
            "logloss": 1.0002240255322665,
            "mae": 0.28187552812528177,
            "precision": 0.7426778242677824,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8272758807962273,
            "auditor_fn_violation": 0.008911638988477633,
            "auditor_fp_violation": 0.01610803359456769,
            "ave_precision_score": 0.8275596243665375,
            "fpr": 0.1207464324917673,
            "logloss": 0.8482086809849725,
            "mae": 0.25989594801117455,
            "precision": 0.7713097713097713,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.79523275250456,
            "auditor_fn_violation": 0.008804384110381664,
            "auditor_fp_violation": 0.021148043799704273,
            "ave_precision_score": 0.7957826708786238,
            "fpr": 0.14583333333333334,
            "logloss": 1.0187230635243973,
            "mae": 0.2846841456516551,
            "precision": 0.7334669338677354,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8382884917286602,
            "auditor_fn_violation": 0.006027052130235451,
            "auditor_fp_violation": 0.018068567635871655,
            "ave_precision_score": 0.8385342468111108,
            "fpr": 0.13391877058177826,
            "logloss": 0.8812516517306909,
            "mae": 0.2621102536441997,
            "precision": 0.7525354969574036,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6144189445974908,
            "auditor_fn_violation": 0.00930742554059568,
            "auditor_fp_violation": 0.006953602685529327,
            "ave_precision_score": 0.5735074856004869,
            "fpr": 0.24451754385964913,
            "logloss": 4.445781074699114,
            "mae": 0.3527284718062666,
            "precision": 0.6350245499181669,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6395890653704489,
            "auditor_fn_violation": 0.013457601822036511,
            "auditor_fp_violation": 0.00862839200469711,
            "ave_precision_score": 0.5989620462898383,
            "fpr": 0.2261251372118551,
            "logloss": 4.162358448398058,
            "mae": 0.3345542930801098,
            "precision": 0.6606260296540363,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6493859477402599,
            "auditor_fn_violation": 0.014458384332925367,
            "auditor_fp_violation": 0.01097240538704392,
            "ave_precision_score": 0.6578986263720876,
            "fpr": 0.0581140350877193,
            "logloss": 6.6584784916799435,
            "mae": 0.41993635666216966,
            "precision": 0.7568807339449541,
            "recall": 0.3488372093023256
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6597616500494828,
            "auditor_fn_violation": 0.009582579286201686,
            "auditor_fp_violation": 0.00811273070737498,
            "ave_precision_score": 0.6687388613750433,
            "fpr": 0.04610318331503842,
            "logloss": 7.079399717496764,
            "mae": 0.4361966413641962,
            "precision": 0.772972972972973,
            "recall": 0.2972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7977770046238201,
            "auditor_fn_violation": 0.008389432884536925,
            "auditor_fp_violation": 0.01860538304759622,
            "ave_precision_score": 0.7986940533125821,
            "fpr": 0.15021929824561403,
            "logloss": 0.9492757239668641,
            "mae": 0.2871826900014348,
            "precision": 0.726,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8440963409402188,
            "auditor_fn_violation": 0.011184620405257074,
            "auditor_fp_violation": 0.01763970081433641,
            "ave_precision_score": 0.8443282559109971,
            "fpr": 0.13830954994511527,
            "logloss": 0.8323322837820021,
            "mae": 0.2689295655508615,
            "precision": 0.7449392712550608,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7887306462574715,
            "auditor_fn_violation": 0.01884203108193317,
            "auditor_fp_violation": 0.020601047036726217,
            "ave_precision_score": 0.7847442835881988,
            "fpr": 0.16447368421052633,
            "logloss": 1.114282382262981,
            "mae": 0.2790421785652775,
            "precision": 0.7185741088180112,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.825415356095994,
            "auditor_fn_violation": 0.013087900025331424,
            "auditor_fp_violation": 0.023166466699001867,
            "ave_precision_score": 0.8228516399885386,
            "fpr": 0.14818880351262348,
            "logloss": 0.9402023735346393,
            "mae": 0.25210703012690855,
            "precision": 0.7509225092250923,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7757469610520864,
            "auditor_fn_violation": 0.010788731871963213,
            "auditor_fp_violation": 0.01770121488230828,
            "ave_precision_score": 0.7709527990268935,
            "fpr": 0.14035087719298245,
            "logloss": 1.190359123189942,
            "mae": 0.2943171997658283,
            "precision": 0.7310924369747899,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8085414711506604,
            "auditor_fn_violation": 0.013008026180364273,
            "auditor_fp_violation": 0.014244505143849081,
            "ave_precision_score": 0.8042671136543857,
            "fpr": 0.11855104281009879,
            "logloss": 1.063648420711624,
            "mae": 0.2674221294879206,
            "precision": 0.7702127659574468,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7877630992066257,
            "auditor_fn_violation": 0.01807935536515708,
            "auditor_fp_violation": 0.021063121927826407,
            "ave_precision_score": 0.7835483270952345,
            "fpr": 0.16337719298245615,
            "logloss": 1.1178621087873326,
            "mae": 0.2792878992260885,
            "precision": 0.7188679245283018,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8221960820187983,
            "auditor_fn_violation": 0.01241239550789496,
            "auditor_fp_violation": 0.021042554820922578,
            "ave_precision_score": 0.8194971154765021,
            "fpr": 0.145993413830955,
            "logloss": 0.9673025314124186,
            "mae": 0.2532922212507991,
            "precision": 0.7537037037037037,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7993398659327833,
            "auditor_fn_violation": 0.009629650235525396,
            "auditor_fp_violation": 0.014541621708028616,
            "ave_precision_score": 0.8002276252057624,
            "fpr": 0.13048245614035087,
            "logloss": 0.8592181761806672,
            "mae": 0.28996542284607024,
            "precision": 0.7451820128479657,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8399460415040247,
            "auditor_fn_violation": 0.011659299255347559,
            "auditor_fp_violation": 0.017757128634518674,
            "ave_precision_score": 0.8402123851150292,
            "fpr": 0.11964873765093303,
            "logloss": 0.7541966893715659,
            "mae": 0.26482756397022633,
            "precision": 0.7695560253699789,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8002972212230967,
            "auditor_fn_violation": 0.00780525573977227,
            "auditor_fp_violation": 0.020128981337169807,
            "ave_precision_score": 0.801152461923905,
            "fpr": 0.1513157894736842,
            "logloss": 0.8964672998892028,
            "mae": 0.28649241556786736,
            "precision": 0.7234468937875751,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8465765831051317,
            "auditor_fn_violation": 0.00824754502032219,
            "auditor_fp_violation": 0.01654200597350216,
            "ave_precision_score": 0.8468046517415917,
            "fpr": 0.13830954994511527,
            "logloss": 0.7821258554665959,
            "mae": 0.267328153238274,
            "precision": 0.748,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8082552096515916,
            "auditor_fn_violation": 0.009954193093727977,
            "auditor_fp_violation": 0.020044059465291936,
            "ave_precision_score": 0.8088108189787535,
            "fpr": 0.19956140350877194,
            "logloss": 0.9297947135784033,
            "mae": 0.2833395581077273,
            "precision": 0.6904761904761905,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8450003936651651,
            "auditor_fn_violation": 0.012638324383659184,
            "auditor_fp_violation": 0.024659842238276365,
            "ave_precision_score": 0.8452408548124626,
            "fpr": 0.18660812294182216,
            "logloss": 0.841243349606201,
            "mae": 0.2675110377412165,
            "precision": 0.7098976109215017,
            "recall": 0.8648648648648649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7867710881153186,
            "auditor_fn_violation": 0.014486202292199848,
            "auditor_fp_violation": 0.019179854533828877,
            "ave_precision_score": 0.7827509306091237,
            "fpr": 0.1600877192982456,
            "logloss": 1.0884798489275866,
            "mae": 0.28148176362562105,
            "precision": 0.7234848484848485,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8244888084281927,
            "auditor_fn_violation": 0.012759276206038011,
            "auditor_fp_violation": 0.02085620197585072,
            "ave_precision_score": 0.8219341265541129,
            "fpr": 0.141602634467618,
            "logloss": 0.9283006867505388,
            "mae": 0.2524472606384124,
            "precision": 0.7579737335834896,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7955736911319751,
            "auditor_fn_violation": 0.00989392084863321,
            "auditor_fp_violation": 0.013087959077648564,
            "ave_precision_score": 0.7959012913708301,
            "fpr": 0.10635964912280702,
            "logloss": 0.629255970874353,
            "mae": 0.35125890161676904,
            "precision": 0.7616707616707616,
            "recall": 0.6553911205073996
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.852499210569589,
            "auditor_fn_violation": 0.001449139758689712,
            "auditor_fp_violation": 0.010211114798458123,
            "ave_precision_score": 0.8527164535507119,
            "fpr": 0.07574094401756312,
            "logloss": 0.5300074398337573,
            "mae": 0.31886631519008457,
            "precision": 0.8287841191066998,
            "recall": 0.6943866943866944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.833276536452531,
            "auditor_fn_violation": 0.011588498201105305,
            "auditor_fp_violation": 0.01969438116932422,
            "ave_precision_score": 0.833560517470591,
            "fpr": 0.12719298245614036,
            "logloss": 0.6829546399501478,
            "mae": 0.28533098961093184,
            "precision": 0.7505376344086021,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8637624801026059,
            "auditor_fn_violation": 0.009963691632187795,
            "auditor_fp_violation": 0.018750159548668734,
            "ave_precision_score": 0.8640091069009417,
            "fpr": 0.11525795828759605,
            "logloss": 0.6208858842432732,
            "mae": 0.26741841077289596,
            "precision": 0.7737068965517241,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8015157642536399,
            "auditor_fn_violation": 0.012854215348095398,
            "auditor_fp_violation": 0.014049574391559771,
            "ave_precision_score": 0.8020234363974721,
            "fpr": 0.1118421052631579,
            "logloss": 0.9117476664463787,
            "mae": 0.2949340425305995,
            "precision": 0.7616822429906542,
            "recall": 0.6892177589852009
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8392142917838359,
            "auditor_fn_violation": 0.012022154722484035,
            "auditor_fp_violation": 0.010440864881423434,
            "ave_precision_score": 0.8394681481103856,
            "fpr": 0.09879253567508232,
            "logloss": 0.8126892501938207,
            "mae": 0.2734616249239019,
            "precision": 0.7911832946635731,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7848317709859494,
            "auditor_fn_violation": 0.008519250027817959,
            "auditor_fp_violation": 0.020848319546017666,
            "ave_precision_score": 0.735802221949431,
            "fpr": 0.15350877192982457,
            "logloss": 2.8782492182532753,
            "mae": 0.2850726771862141,
            "precision": 0.7348484848484849,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8117638406767618,
            "auditor_fn_violation": 0.011335239655766549,
            "auditor_fp_violation": 0.023766369693411286,
            "ave_precision_score": 0.761582499824274,
            "fpr": 0.14270032930845225,
            "logloss": 2.814321870162474,
            "mae": 0.2712888098382797,
            "precision": 0.7533206831119544,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7860353063191667,
            "auditor_fn_violation": 0.005904361856014247,
            "auditor_fp_violation": 0.019304739639531634,
            "ave_precision_score": 0.782279356464968,
            "fpr": 0.14912280701754385,
            "logloss": 1.0306721368880236,
            "mae": 0.28332163663707394,
            "precision": 0.728,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8203798202613728,
            "auditor_fn_violation": 0.009810790271822106,
            "auditor_fp_violation": 0.014566155260000518,
            "ave_precision_score": 0.8178044625622785,
            "fpr": 0.12294182217343579,
            "logloss": 0.8925086167688155,
            "mae": 0.2557169408840547,
            "precision": 0.7764471057884231,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8005354199660502,
            "auditor_fn_violation": 0.011078502281072666,
            "auditor_fp_violation": 0.016802042121248455,
            "ave_precision_score": 0.8014233395885733,
            "fpr": 0.13157894736842105,
            "logloss": 0.8561559664036129,
            "mae": 0.29012762859042146,
            "precision": 0.7435897435897436,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8413123873067161,
            "auditor_fn_violation": 0.01169124879333442,
            "auditor_fp_violation": 0.015107344344318792,
            "ave_precision_score": 0.8415692945300967,
            "fpr": 0.11745334796926454,
            "logloss": 0.749499493696487,
            "mae": 0.2645867125092088,
            "precision": 0.7742616033755274,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6688297702388831,
            "auditor_fn_violation": 0.007128352064092577,
            "auditor_fp_violation": 0.012063901210885986,
            "ave_precision_score": 0.6702890920066241,
            "fpr": 0.06469298245614036,
            "logloss": 5.113990366988047,
            "mae": 0.4109305705980427,
            "precision": 0.7551867219917012,
            "recall": 0.38477801268498946
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6824129929989126,
            "auditor_fn_violation": 0.009641914142462987,
            "auditor_fp_violation": 0.009133842187220789,
            "ave_precision_score": 0.6841775664196235,
            "fpr": 0.052689352360043906,
            "logloss": 5.283735405028911,
            "mae": 0.4187705915199515,
            "precision": 0.7788018433179723,
            "recall": 0.35135135135135137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8037689836687381,
            "auditor_fn_violation": 0.010598642483587408,
            "auditor_fp_violation": 0.018617871558166493,
            "ave_precision_score": 0.8043132423665859,
            "fpr": 0.14035087719298245,
            "logloss": 0.9106911291104393,
            "mae": 0.2858586352733582,
            "precision": 0.7305263157894737,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8432055333357525,
            "auditor_fn_violation": 0.008409574820112693,
            "auditor_fp_violation": 0.01641181425982182,
            "ave_precision_score": 0.843456444757385,
            "fpr": 0.11964873765093303,
            "logloss": 0.8092497476222069,
            "mae": 0.2660284731020953,
            "precision": 0.770042194092827,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.827268162063693,
            "auditor_fn_violation": 0.013997069841623092,
            "auditor_fp_violation": 0.017269112416576752,
            "ave_precision_score": 0.8275403986198596,
            "fpr": 0.11403508771929824,
            "logloss": 0.5862406208503002,
            "mae": 0.3031990402609664,
            "precision": 0.7625570776255708,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8600935929853664,
            "auditor_fn_violation": 0.014799482417484616,
            "auditor_fp_violation": 0.012049115462180583,
            "ave_precision_score": 0.8602845556165346,
            "fpr": 0.10428100987925357,
            "logloss": 0.5382013207285351,
            "mae": 0.28419443515174225,
            "precision": 0.7845804988662132,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7996642621699424,
            "auditor_fn_violation": 0.011736860650569341,
            "auditor_fp_violation": 0.011481936618311154,
            "ave_precision_score": 0.8000332894020297,
            "fpr": 0.08333333333333333,
            "logloss": 0.5973961455219311,
            "mae": 0.34352687330730836,
            "precision": 0.798941798941799,
            "recall": 0.638477801268499
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8761695873036264,
            "auditor_fn_violation": 0.0008443806467955891,
            "auditor_fp_violation": 0.010165164781865063,
            "ave_precision_score": 0.8763219997622619,
            "fpr": 0.06147091108671789,
            "logloss": 0.4980673761731412,
            "mae": 0.3110503879505924,
            "precision": 0.8537859007832899,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8063473494859843,
            "auditor_fn_violation": 0.005953043284744636,
            "auditor_fp_violation": 0.02020141469847741,
            "ave_precision_score": 0.8069042496373592,
            "fpr": 0.14802631578947367,
            "logloss": 0.8904069220491552,
            "mae": 0.28262634749329973,
            "precision": 0.7321428571428571,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8471955353255595,
            "auditor_fn_violation": 0.0054565246661843845,
            "auditor_fp_violation": 0.02146886886375821,
            "ave_precision_score": 0.8474543623911941,
            "fpr": 0.13721185510428102,
            "logloss": 0.7915429682850056,
            "mae": 0.26406995686280704,
            "precision": 0.748995983935743,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7942653396617583,
            "auditor_fn_violation": 0.00921701717295353,
            "auditor_fp_violation": 0.019219817767653764,
            "ave_precision_score": 0.7951459712058682,
            "fpr": 0.15021929824561403,
            "logloss": 1.0198173963816004,
            "mae": 0.2887646244546119,
            "precision": 0.7226720647773279,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8390791814997706,
            "auditor_fn_violation": 0.014003026077669335,
            "auditor_fp_violation": 0.01763970081433641,
            "ave_precision_score": 0.83930891801803,
            "fpr": 0.13830954994511527,
            "logloss": 0.9016721728562376,
            "mae": 0.27255052695999,
            "precision": 0.7418032786885246,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7875565951571888,
            "auditor_fn_violation": 0.015552557397722643,
            "auditor_fp_violation": 0.018727770451184917,
            "ave_precision_score": 0.7833192985637757,
            "fpr": 0.16557017543859648,
            "logloss": 1.1546548472285305,
            "mae": 0.2806495444542559,
            "precision": 0.7172284644194756,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8233958380391041,
            "auditor_fn_violation": 0.009968255851900202,
            "auditor_fp_violation": 0.01675133382687055,
            "ave_precision_score": 0.8205920786693907,
            "fpr": 0.14709110867178923,
            "logloss": 0.9825166705951587,
            "mae": 0.25378816444841384,
            "precision": 0.750465549348231,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7925579263961706,
            "auditor_fn_violation": 0.008600385742368606,
            "auditor_fp_violation": 0.016829516844503067,
            "ave_precision_score": 0.793078721064981,
            "fpr": 0.14583333333333334,
            "logloss": 0.9741812159553608,
            "mae": 0.2877951768724694,
            "precision": 0.7296747967479674,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8323862054127119,
            "auditor_fn_violation": 0.007081386883801817,
            "auditor_fp_violation": 0.018104306537666256,
            "ave_precision_score": 0.8326775142549029,
            "fpr": 0.12733260153677278,
            "logloss": 0.8447843057782489,
            "mae": 0.26357912241231596,
            "precision": 0.7622950819672131,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8032493783319339,
            "auditor_fn_violation": 0.008389432884536925,
            "auditor_fp_violation": 0.01860538304759622,
            "ave_precision_score": 0.8041196651700421,
            "fpr": 0.15021929824561403,
            "logloss": 0.8886220369240485,
            "mae": 0.28642381438506964,
            "precision": 0.726,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8503526135292858,
            "auditor_fn_violation": 0.007665607006990105,
            "auditor_fp_violation": 0.01763970081433641,
            "ave_precision_score": 0.8505674352372233,
            "fpr": 0.13830954994511527,
            "logloss": 0.7818508662275927,
            "mae": 0.2681385305205389,
            "precision": 0.7469879518072289,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7878090758781418,
            "auditor_fn_violation": 0.00778902859686214,
            "auditor_fp_violation": 0.016734604164168974,
            "ave_precision_score": 0.7841342977469818,
            "fpr": 0.14364035087719298,
            "logloss": 1.013184989090763,
            "mae": 0.28133260471952126,
            "precision": 0.741106719367589,
            "recall": 0.7928118393234672
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8174676493622467,
            "auditor_fn_violation": 0.007601707931016386,
            "auditor_fp_violation": 0.014341510734434437,
            "ave_precision_score": 0.8148782339212645,
            "fpr": 0.12733260153677278,
            "logloss": 0.9076865903562628,
            "mae": 0.2623609369499921,
            "precision": 0.7665995975855131,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7790051957348733,
            "auditor_fn_violation": 0.01120600126108082,
            "auditor_fp_violation": 0.02025386644287256,
            "ave_precision_score": 0.7749091637809813,
            "fpr": 0.15021929824561403,
            "logloss": 1.144282849659718,
            "mae": 0.28688611926177815,
            "precision": 0.7265469061876247,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8093885485005308,
            "auditor_fn_violation": 0.005954024614836914,
            "auditor_fp_violation": 0.019000331861230953,
            "ave_precision_score": 0.8058118813305479,
            "fpr": 0.132821075740944,
            "logloss": 1.032623747758392,
            "mae": 0.26497301992466754,
            "precision": 0.7584830339321357,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.84320770907669,
            "auditor_fn_violation": 0.009671377174437154,
            "auditor_fp_violation": 0.011966490828437837,
            "ave_precision_score": 0.8434708509482394,
            "fpr": 0.13267543859649122,
            "logloss": 0.5366527732395923,
            "mae": 0.3007394053826775,
            "precision": 0.7589641434262948,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8890237050800025,
            "auditor_fn_violation": 0.004776455929035512,
            "auditor_fp_violation": 0.012809843514665714,
            "ave_precision_score": 0.8891756626770259,
            "fpr": 0.11964873765093303,
            "logloss": 0.4528345916987227,
            "mae": 0.27509000706960873,
            "precision": 0.7858546168958742,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7976868445972094,
            "auditor_fn_violation": 0.009988965542821117,
            "auditor_fp_violation": 0.01727660552291892,
            "ave_precision_score": 0.7985508343199785,
            "fpr": 0.14144736842105263,
            "logloss": 0.9412522330074534,
            "mae": 0.2896555265898668,
            "precision": 0.7306889352818372,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8435250371464387,
            "auditor_fn_violation": 0.012311982674221978,
            "auditor_fp_violation": 0.017711178617925618,
            "ave_precision_score": 0.843755892753197,
            "fpr": 0.12294182217343579,
            "logloss": 0.8294697024257751,
            "mae": 0.26980753817604386,
            "precision": 0.7627118644067796,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.35502714060261104,
            "auditor_fn_violation": 0.00300202143837395,
            "auditor_fp_violation": 0.001860788074971027,
            "ave_precision_score": 0.5105975438271982,
            "fpr": 0.005482456140350877,
            "logloss": 17.253659031251427,
            "mae": 0.521461812415679,
            "precision": 0.5,
            "recall": 0.010570824524312896
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.3604046900318092,
            "auditor_fn_violation": 0.001891869070793343,
            "auditor_fp_violation": 0.0010466392668419574,
            "ave_precision_score": 0.527656171351826,
            "fpr": 0.0021953896816684962,
            "logloss": 17.642861945418545,
            "mae": 0.5252047572750117,
            "precision": 0.7142857142857143,
            "recall": 0.010395010395010396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7799956298217301,
            "auditor_fn_violation": 0.007879436964504286,
            "auditor_fp_violation": 0.01810334492267115,
            "ave_precision_score": 0.7762366831963349,
            "fpr": 0.14692982456140352,
            "logloss": 1.0678894691392384,
            "mae": 0.29009540077845924,
            "precision": 0.7242798353909465,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8158950369286474,
            "auditor_fn_violation": 0.009133003644529444,
            "auditor_fp_violation": 0.014272585709544842,
            "ave_precision_score": 0.8124833976386928,
            "fpr": 0.11745334796926454,
            "logloss": 0.9388322844837921,
            "mae": 0.2585504548010548,
            "precision": 0.7793814432989691,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7813906096298412,
            "auditor_fn_violation": 0.008665294314009128,
            "auditor_fp_violation": 0.01704431922631179,
            "ave_precision_score": 0.7801849019219321,
            "fpr": 0.14364035087719298,
            "logloss": 1.0981025968140645,
            "mae": 0.2886072602387837,
            "precision": 0.7293388429752066,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8210723300906697,
            "auditor_fn_violation": 0.008742762859118514,
            "auditor_fp_violation": 0.015612794526842472,
            "ave_precision_score": 0.8213459742899473,
            "fpr": 0.12733260153677278,
            "logloss": 0.9318031333581294,
            "mae": 0.2650780082339594,
            "precision": 0.7608247422680412,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8251073496081491,
            "auditor_fn_violation": 0.008602703905641483,
            "auditor_fp_violation": 0.020383746952803428,
            "ave_precision_score": 0.8253951082629762,
            "fpr": 0.1425438596491228,
            "logloss": 0.7425557440706991,
            "mae": 0.28204611662403567,
            "precision": 0.7368421052631579,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8627359120804029,
            "auditor_fn_violation": 0.006775584163070445,
            "auditor_fp_violation": 0.013800321650116153,
            "ave_precision_score": 0.8629197001700133,
            "fpr": 0.12294182217343579,
            "logloss": 0.6573570343572362,
            "mae": 0.25662381990081595,
            "precision": 0.7728194726166329,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7880636983498058,
            "auditor_fn_violation": 0.011175865138533444,
            "auditor_fp_violation": 0.022164608560124685,
            "ave_precision_score": 0.788599486772144,
            "fpr": 0.19736842105263158,
            "logloss": 0.6438052756199233,
            "mae": 0.35405026308338466,
            "precision": 0.6802841918294849,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8485990199212512,
            "auditor_fn_violation": 0.008900228439196611,
            "auditor_fp_violation": 0.021009368697827595,
            "ave_precision_score": 0.8489663099075525,
            "fpr": 0.19099890230515917,
            "logloss": 0.5647367416349028,
            "mae": 0.3362361432874062,
            "precision": 0.6914893617021277,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8232275861035776,
            "auditor_fn_violation": 0.023459812321501426,
            "auditor_fp_violation": 0.01957449146784958,
            "ave_precision_score": 0.8236911899110224,
            "fpr": 0.1206140350877193,
            "logloss": 0.6019633026612266,
            "mae": 0.29264938497953363,
            "precision": 0.7619047619047619,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8643759770968176,
            "auditor_fn_violation": 0.023097233854643295,
            "auditor_fp_violation": 0.017210833992801162,
            "ave_precision_score": 0.8645686696867865,
            "fpr": 0.11306256860592755,
            "logloss": 0.557666497404552,
            "mae": 0.2796716502610828,
            "precision": 0.775599128540305,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8442234269133753,
            "auditor_fn_violation": 0.011029820852342272,
            "auditor_fp_violation": 0.011966490828437837,
            "ave_precision_score": 0.8444881938616322,
            "fpr": 0.13267543859649122,
            "logloss": 0.5284999570274683,
            "mae": 0.2986959552218252,
            "precision": 0.7594433399602386,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8888717433371748,
            "auditor_fn_violation": 0.008514551873498089,
            "auditor_fp_violation": 0.009343170040589184,
            "ave_precision_score": 0.8890274358165027,
            "fpr": 0.11855104281009879,
            "logloss": 0.45249429857645684,
            "mae": 0.2737929662222316,
            "precision": 0.7869822485207101,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7567704430229412,
            "auditor_fn_violation": 0.01966497904380402,
            "auditor_fp_violation": 0.023118730767693725,
            "ave_precision_score": 0.7485907270723464,
            "fpr": 0.15350877192982457,
            "logloss": 1.5712180157033901,
            "mae": 0.29523366136697865,
            "precision": 0.714867617107943,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8116363292059403,
            "auditor_fn_violation": 0.010504551668108207,
            "auditor_fp_violation": 0.0235238557169479,
            "ave_precision_score": 0.8079550400613572,
            "fpr": 0.12623490669593854,
            "logloss": 1.0939112956966004,
            "mae": 0.264203310242923,
            "precision": 0.7614107883817427,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8000121290233844,
            "auditor_fn_violation": 0.009870739215904457,
            "auditor_fp_violation": 0.016802042121248455,
            "ave_precision_score": 0.8009006666956666,
            "fpr": 0.13157894736842105,
            "logloss": 0.8559342750222011,
            "mae": 0.2905390349443932,
            "precision": 0.7430406852248393,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.841131131772461,
            "auditor_fn_violation": 0.01169124879333442,
            "auditor_fp_violation": 0.016450105940316036,
            "ave_precision_score": 0.8413878241901813,
            "fpr": 0.11855104281009879,
            "logloss": 0.7489569450430941,
            "mae": 0.2650971293253297,
            "precision": 0.7726315789473684,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.791952368615349,
            "auditor_fn_violation": 0.010292644931567825,
            "auditor_fp_violation": 0.01839557607001559,
            "ave_precision_score": 0.7925285000571689,
            "fpr": 0.15021929824561403,
            "logloss": 1.0182352216283543,
            "mae": 0.2911151293803606,
            "precision": 0.7226720647773279,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8363405867796431,
            "auditor_fn_violation": 0.01314951699144894,
            "auditor_fp_violation": 0.020942996451637615,
            "ave_precision_score": 0.836600593517287,
            "fpr": 0.12952799121844127,
            "logloss": 0.8448618987502361,
            "mae": 0.26358328734718434,
            "precision": 0.757700205338809,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7794521476814714,
            "auditor_fn_violation": 0.01800517414042506,
            "auditor_fp_violation": 0.01857790832434161,
            "ave_precision_score": 0.7746880797214754,
            "fpr": 0.15350877192982457,
            "logloss": 1.174508641873505,
            "mae": 0.28755367741370763,
            "precision": 0.7227722772277227,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8139250039541074,
            "auditor_fn_violation": 0.014580399871289009,
            "auditor_fp_violation": 0.020483496285706993,
            "ave_precision_score": 0.8103904305863805,
            "fpr": 0.1394072447859495,
            "logloss": 1.0149021771776012,
            "mae": 0.26090050334148307,
            "precision": 0.751953125,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8217720097462758,
            "auditor_fn_violation": 0.005531137569081269,
            "auditor_fp_violation": 0.019869220317308083,
            "ave_precision_score": 0.8220615744709956,
            "fpr": 0.14692982456140352,
            "logloss": 0.7360435973696097,
            "mae": 0.28291666636186275,
            "precision": 0.7341269841269841,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8556891445571517,
            "auditor_fn_violation": 0.004737660061480047,
            "auditor_fp_violation": 0.014009649503484548,
            "ave_precision_score": 0.855921262601054,
            "fpr": 0.12733260153677278,
            "logloss": 0.6641569242788407,
            "mae": 0.2612085766691876,
            "precision": 0.7656565656565657,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8442756010203021,
            "auditor_fn_violation": 0.010186009421015545,
            "auditor_fp_violation": 0.013127922311473443,
            "ave_precision_score": 0.8445402320453979,
            "fpr": 0.1337719298245614,
            "logloss": 0.528359740001195,
            "mae": 0.29844637925149287,
            "precision": 0.7579365079365079,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8892730757111357,
            "auditor_fn_violation": 0.008514551873498089,
            "auditor_fp_violation": 0.009343170040589184,
            "ave_precision_score": 0.8894269286105478,
            "fpr": 0.11855104281009879,
            "logloss": 0.45199222751671275,
            "mae": 0.27317088141927415,
            "precision": 0.7869822485207101,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6104452273342981,
            "auditor_fn_violation": 0.0032964281740291562,
            "auditor_fp_violation": 0.01344513047995845,
            "ave_precision_score": 0.5737762815622718,
            "fpr": 0.24451754385964913,
            "logloss": 4.176185813585961,
            "mae": 0.3604494945565213,
            "precision": 0.6289517470881864,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6377391223567075,
            "auditor_fn_violation": 0.007891535882754328,
            "auditor_fp_violation": 0.0025017231256222387,
            "ave_precision_score": 0.6015372571672886,
            "fpr": 0.22502744237102085,
            "logloss": 3.8608545381134474,
            "mae": 0.3401980966317383,
            "precision": 0.6548821548821548,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7871362346410715,
            "auditor_fn_violation": 0.006551129409146547,
            "auditor_fp_violation": 0.01892508891819527,
            "ave_precision_score": 0.7832696889083366,
            "fpr": 0.1425438596491228,
            "logloss": 1.011201472993438,
            "mae": 0.28397913576265355,
            "precision": 0.7357723577235772,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8218391097790383,
            "auditor_fn_violation": 0.01178253318758259,
            "auditor_fp_violation": 0.01304469915503025,
            "ave_precision_score": 0.8193561478184987,
            "fpr": 0.1207464324917673,
            "logloss": 0.8722632194726889,
            "mae": 0.2547470419217656,
            "precision": 0.7782258064516129,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7439604500811199,
            "auditor_fn_violation": 0.020831015170060467,
            "auditor_fp_violation": 0.0187952084082644,
            "ave_precision_score": 0.7394302670837458,
            "fpr": 0.1524122807017544,
            "logloss": 1.5708932078885458,
            "mae": 0.2987563391286937,
            "precision": 0.7139917695473251,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8098043226171399,
            "auditor_fn_violation": 0.011599964399086247,
            "auditor_fp_violation": 0.0213616521583744,
            "ave_precision_score": 0.8071985338322711,
            "fpr": 0.12733260153677278,
            "logloss": 1.0961563011308324,
            "mae": 0.2669303669498599,
            "precision": 0.7583333333333333,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7844206861281202,
            "auditor_fn_violation": 0.008057935536515707,
            "auditor_fp_violation": 0.01763627462734285,
            "ave_precision_score": 0.7831070022734244,
            "fpr": 0.14912280701754385,
            "logloss": 1.0499563072826676,
            "mae": 0.28595361048056367,
            "precision": 0.7274549098196392,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8235043728016939,
            "auditor_fn_violation": 0.007754609291382072,
            "auditor_fp_violation": 0.013402088172976284,
            "ave_precision_score": 0.8237613051598164,
            "fpr": 0.13172338090010977,
            "logloss": 0.8897484318897564,
            "mae": 0.2635589595630073,
            "precision": 0.757085020242915,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8248361920348317,
            "auditor_fn_violation": 0.008894792478023812,
            "auditor_fp_violation": 0.020790872397394407,
            "ave_precision_score": 0.8251204832228503,
            "fpr": 0.14473684210526316,
            "logloss": 0.7447123417084643,
            "mae": 0.2821799107610116,
            "precision": 0.7354709418837675,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.862949723850928,
            "auditor_fn_violation": 0.006775584163070445,
            "auditor_fp_violation": 0.013197865877007128,
            "ave_precision_score": 0.8631332316858541,
            "fpr": 0.1251372118551043,
            "logloss": 0.6582438261165737,
            "mae": 0.25653773202515506,
            "precision": 0.7696969696969697,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8224687809180704,
            "auditor_fn_violation": 0.008037072067059826,
            "auditor_fp_violation": 0.018812692323062787,
            "ave_precision_score": 0.8228339397300315,
            "fpr": 0.14473684210526316,
            "logloss": 0.7586309407547602,
            "mae": 0.27924776454860795,
            "precision": 0.7365269461077845,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8638987297460252,
            "auditor_fn_violation": 0.00885915046178493,
            "auditor_fp_violation": 0.01370842161693003,
            "ave_precision_score": 0.8640821097057675,
            "fpr": 0.12623490669593854,
            "logloss": 0.6711732761350768,
            "mae": 0.25477722880573017,
            "precision": 0.7695390781563126,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.852699046048289,
            "auditor_fn_violation": 0.02698110233299952,
            "auditor_fp_violation": 0.019552012148823083,
            "ave_precision_score": 0.8529209179549628,
            "fpr": 0.14144736842105263,
            "logloss": 0.5899888845468655,
            "mae": 0.3083745400920622,
            "precision": 0.7504835589941973,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8758765893184345,
            "auditor_fn_violation": 0.0221866720220178,
            "auditor_fp_violation": 0.019013095754729026,
            "ave_precision_score": 0.8761546526551163,
            "fpr": 0.12733260153677278,
            "logloss": 0.5606179303771359,
            "mae": 0.2924676089649842,
            "precision": 0.7747572815533981,
            "recall": 0.8295218295218295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7851387079951404,
            "auditor_fn_violation": 0.013208894328845373,
            "auditor_fp_violation": 0.018115833433241416,
            "ave_precision_score": 0.7811559081223831,
            "fpr": 0.1425438596491228,
            "logloss": 1.1219087872233398,
            "mae": 0.28554428998855474,
            "precision": 0.7363083164300203,
            "recall": 0.7674418604651163
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8181328159371459,
            "auditor_fn_violation": 0.008183645944348476,
            "auditor_fp_violation": 0.01624077808694764,
            "ave_precision_score": 0.8147547834948812,
            "fpr": 0.1251372118551043,
            "logloss": 0.985009146109709,
            "mae": 0.2573381497739019,
            "precision": 0.7701612903225806,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 9296,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7998317252532091,
            "auditor_fn_violation": 0.008118207781610475,
            "auditor_fp_violation": 0.025898673220637033,
            "ave_precision_score": 0.7998513092374521,
            "fpr": 0.3574561403508772,
            "logloss": 2.1935762166817048,
            "mae": 0.36960787408505424,
            "precision": 0.5836526181353767,
            "recall": 0.9661733615221987
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8421383444124477,
            "auditor_fn_violation": 0.003797430800723886,
            "auditor_fp_violation": 0.012054221019579824,
            "ave_precision_score": 0.8419118190788152,
            "fpr": 0.3446761800219539,
            "logloss": 1.9889852674213726,
            "mae": 0.3516134441146031,
            "precision": 0.59846547314578,
            "recall": 0.972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6704509826831089,
            "auditor_fn_violation": 0.01549460331590074,
            "auditor_fp_violation": 0.01458658034608161,
            "ave_precision_score": 0.6786140435108823,
            "fpr": 0.07346491228070176,
            "logloss": 5.869685943769223,
            "mae": 0.4029611872179887,
            "precision": 0.7432950191570882,
            "recall": 0.41014799154334036
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6880292076720051,
            "auditor_fn_violation": 0.0019283828284926083,
            "auditor_fp_violation": 0.012309498889541266,
            "ave_precision_score": 0.6967254145940031,
            "fpr": 0.07025246981339188,
            "logloss": 6.032200994363487,
            "mae": 0.40937005820757427,
            "precision": 0.7480314960629921,
            "recall": 0.39501039501039503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8266613317515827,
            "auditor_fn_violation": 0.013229757798301251,
            "auditor_fp_violation": 0.018705291132158422,
            "ave_precision_score": 0.8280434792088786,
            "fpr": 0.14035087719298245,
            "logloss": 0.5896717579953037,
            "mae": 0.2853056537042313,
            "precision": 0.7387755102040816,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8740404273639156,
            "auditor_fn_violation": 0.011107028670146131,
            "auditor_fp_violation": 0.020820463074056106,
            "ave_precision_score": 0.8741870289502368,
            "fpr": 0.132821075740944,
            "logloss": 0.5472824846488852,
            "mae": 0.2708423313315197,
            "precision": 0.7540650406504065,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 9296,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7992138753991502,
            "auditor_fn_violation": 0.009891602685360337,
            "auditor_fp_violation": 0.026762878152100072,
            "ave_precision_score": 0.7996123470719636,
            "fpr": 0.2598684210526316,
            "logloss": 1.296672764065345,
            "mae": 0.3126974419850285,
            "precision": 0.6452095808383234,
            "recall": 0.9112050739957717
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8397142708787992,
            "auditor_fn_violation": 0.010789815400133733,
            "auditor_fp_violation": 0.02392464197278739,
            "ave_precision_score": 0.8399218579327047,
            "fpr": 0.24807903402854006,
            "logloss": 1.1510514504128555,
            "mae": 0.29767298085840327,
            "precision": 0.6621823617339312,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 9296,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8172932429105553,
            "auditor_fn_violation": 0.00929815288750418,
            "auditor_fp_violation": 0.009406346161531394,
            "ave_precision_score": 0.817650580344957,
            "fpr": 0.0800438596491228,
            "logloss": 0.6094014630614343,
            "mae": 0.32831369519849873,
            "precision": 0.8103896103896104,
            "recall": 0.6596194503171248
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8705973454761496,
            "auditor_fn_violation": 0.002795584573850227,
            "auditor_fp_violation": 0.011816812600515664,
            "ave_precision_score": 0.8707830760595523,
            "fpr": 0.06256860592755215,
            "logloss": 0.5108374752022381,
            "mae": 0.298841911292425,
            "precision": 0.8560606060606061,
            "recall": 0.7047817047817048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7726477046947807,
            "auditor_fn_violation": 0.00946042431660547,
            "auditor_fp_violation": 0.016359948847060705,
            "ave_precision_score": 0.743898033503537,
            "fpr": 0.13596491228070176,
            "logloss": 2.153510643759292,
            "mae": 0.29552412287650215,
            "precision": 0.7333333333333333,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8100215464663787,
            "auditor_fn_violation": 0.006606708033711329,
            "auditor_fp_violation": 0.015574502846348252,
            "ave_precision_score": 0.78717788077717,
            "fpr": 0.11306256860592755,
            "logloss": 1.8309206551249608,
            "mae": 0.2648877755210218,
            "precision": 0.7770562770562771,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7811999561743005,
            "auditor_fn_violation": 0.006177905122213564,
            "auditor_fp_violation": 0.01792101266834513,
            "ave_precision_score": 0.7775697670091193,
            "fpr": 0.15021929824561403,
            "logloss": 1.0745497288217718,
            "mae": 0.28875565112294876,
            "precision": 0.7221095334685599,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8167749056189078,
            "auditor_fn_violation": 0.011362624974041,
            "auditor_fp_violation": 0.012462665611518143,
            "ave_precision_score": 0.8133800369371693,
            "fpr": 0.12403951701427003,
            "logloss": 0.94252152536877,
            "mae": 0.2571514130615593,
            "precision": 0.771255060728745,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 9296,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.786910894941176,
            "auditor_fn_violation": 0.01466006453766552,
            "auditor_fp_violation": 0.020601047036726217,
            "ave_precision_score": 0.7737991673706883,
            "fpr": 0.16447368421052633,
            "logloss": 1.4758644031895716,
            "mae": 0.2801392015577474,
            "precision": 0.7217068645640075,
            "recall": 0.8224101479915433
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8208502373065638,
            "auditor_fn_violation": 0.011798507956576018,
            "auditor_fp_violation": 0.022581880376790136,
            "ave_precision_score": 0.8092747189852479,
            "fpr": 0.14709110867178923,
            "logloss": 1.2952683368557387,
            "mae": 0.25281044170106237,
            "precision": 0.7541284403669725,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8077499218270945,
            "auditor_fn_violation": 0.009590241459886512,
            "auditor_fp_violation": 0.013482596011669267,
            "ave_precision_score": 0.8080564103092192,
            "fpr": 0.10526315789473684,
            "logloss": 0.6264188629408011,
            "mae": 0.34641585312349676,
            "precision": 0.7635467980295566,
            "recall": 0.6553911205073996
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8630391009689781,
            "auditor_fn_violation": 0.001519885164232036,
            "auditor_fp_violation": 0.007405611007581753,
            "ave_precision_score": 0.8632149474116437,
            "fpr": 0.07354555433589462,
            "logloss": 0.5208945151395769,
            "mae": 0.31467357276009567,
            "precision": 0.8337468982630273,
            "recall": 0.6985446985446986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6667952069068,
            "auditor_fn_violation": 0.020557471903861143,
            "auditor_fp_violation": 0.015942832594013513,
            "ave_precision_score": 0.6751274378088934,
            "fpr": 0.0712719298245614,
            "logloss": 5.83061340651739,
            "mae": 0.40305497119862477,
            "precision": 0.749034749034749,
            "recall": 0.41014799154334036
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6891084156644316,
            "auditor_fn_violation": 0.0032588528746596915,
            "auditor_fp_violation": 0.013504199320960869,
            "ave_precision_score": 0.6977822561100595,
            "fpr": 0.06915477497255763,
            "logloss": 5.971909975655119,
            "mae": 0.40776657263738947,
            "precision": 0.754863813229572,
            "recall": 0.40332640332640335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7783403259034443,
            "auditor_fn_violation": 0.0003848151032973564,
            "auditor_fp_violation": 0.018418055389042082,
            "ave_precision_score": 0.7746999033076697,
            "fpr": 0.15350877192982457,
            "logloss": 1.0833152897382015,
            "mae": 0.2903595777776308,
            "precision": 0.7188755020080321,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8146645718228132,
            "auditor_fn_violation": 0.01015310675025275,
            "auditor_fp_violation": 0.015561738952850184,
            "ave_precision_score": 0.8111398166954475,
            "fpr": 0.12733260153677278,
            "logloss": 0.9456488222330132,
            "mae": 0.2595463632057103,
            "precision": 0.7670682730923695,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8342754736282806,
            "auditor_fn_violation": 0.008241070435072887,
            "auditor_fp_violation": 0.018530451984174565,
            "ave_precision_score": 0.834618585668701,
            "fpr": 0.12828947368421054,
            "logloss": 0.6165574439265092,
            "mae": 0.2910067168151011,
            "precision": 0.7439824945295405,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8774466806695704,
            "auditor_fn_violation": 0.008683428002857204,
            "auditor_fp_violation": 0.008383325249534123,
            "ave_precision_score": 0.8776135732400324,
            "fpr": 0.10098792535675083,
            "logloss": 0.5216464543501995,
            "mae": 0.26029467246529,
            "precision": 0.8004338394793926,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8436093048685018,
            "auditor_fn_violation": 0.011201364934535066,
            "auditor_fp_violation": 0.014746433281381132,
            "ave_precision_score": 0.84386365366707,
            "fpr": 0.13048245614035087,
            "logloss": 0.5309899299922345,
            "mae": 0.2995771280593185,
            "precision": 0.7595959595959596,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8880503305169215,
            "auditor_fn_violation": 0.005422293018341321,
            "auditor_fp_violation": 0.00908023383452889,
            "ave_precision_score": 0.888206265227573,
            "fpr": 0.11306256860592755,
            "logloss": 0.4534840172239534,
            "mae": 0.2736456789009436,
            "precision": 0.7944111776447106,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7987105169915718,
            "auditor_fn_violation": 0.009455787990059715,
            "auditor_fp_violation": 0.01903249010909963,
            "ave_precision_score": 0.7994301954827984,
            "fpr": 0.13706140350877194,
            "logloss": 0.8653781529347019,
            "mae": 0.2890403615337128,
            "precision": 0.7395833333333334,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8370882079362362,
            "auditor_fn_violation": 0.01356714309513432,
            "auditor_fp_violation": 0.016215250299951498,
            "ave_precision_score": 0.8373673535322084,
            "fpr": 0.11745334796926454,
            "logloss": 0.7571449415796089,
            "mae": 0.26614126111311026,
            "precision": 0.7713675213675214,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8141639527567968,
            "auditor_fn_violation": 0.007506212677571305,
            "auditor_fp_violation": 0.020383746952803428,
            "ave_precision_score": 0.8155248674909201,
            "fpr": 0.1425438596491228,
            "logloss": 0.7488448113351487,
            "mae": 0.28109483207369695,
            "precision": 0.7368421052631579,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8611639994883479,
            "auditor_fn_violation": 0.007631375359147042,
            "auditor_fp_violation": 0.013320399254588618,
            "ave_precision_score": 0.8613493507970031,
            "fpr": 0.12294182217343579,
            "logloss": 0.6652336805702519,
            "mae": 0.2582305352031035,
            "precision": 0.7718940936863544,
            "recall": 0.7879417879417879
        }
    }
]