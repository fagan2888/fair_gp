[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8413130869048129,
            "auditor_fn_violation": 0.0008676779759315678,
            "auditor_fp_violation": 0.005328742416789641,
            "ave_precision_score": 0.8416817969776317,
            "fpr": 0.12828947368421054,
            "logloss": 0.8639818685996036,
            "mae": 0.2582443883920873,
            "precision": 0.7641129032258065,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8445410118619748,
            "auditor_fn_violation": 0.00973912231123152,
            "auditor_fp_violation": 0.018332250573116188,
            "ave_precision_score": 0.8447554384738296,
            "fpr": 0.12184412733260154,
            "logloss": 0.7794585806335729,
            "mae": 0.26264922191601325,
            "precision": 0.7633262260127932,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8441072007244244,
            "auditor_fn_violation": 0.008139861534000288,
            "auditor_fp_violation": 0.013987948844072798,
            "ave_precision_score": 0.8444096578757615,
            "fpr": 0.11403508771929824,
            "logloss": 0.5389302776031212,
            "mae": 0.3295547592610921,
            "precision": 0.7791932059447984,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8356230706726684,
            "auditor_fn_violation": 0.0064553798724805685,
            "auditor_fp_violation": 0.006892328830544294,
            "ave_precision_score": 0.8358952936349224,
            "fpr": 0.1119648737650933,
            "logloss": 0.5338700422957613,
            "mae": 0.33564232570465763,
            "precision": 0.7655172413793103,
            "recall": 0.7085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8273090171744616,
            "auditor_fn_violation": 0.009671324488908225,
            "auditor_fp_violation": 0.005374856533858015,
            "ave_precision_score": 0.827722193484705,
            "fpr": 0.1118421052631579,
            "logloss": 1.0505226432298274,
            "mae": 0.26070546981792114,
            "precision": 0.7796976241900648,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8263766906102433,
            "auditor_fn_violation": 0.014695097741551262,
            "auditor_fp_violation": 0.021132492514019878,
            "ave_precision_score": 0.8266670363838448,
            "fpr": 0.10208562019758508,
            "logloss": 1.0322732934303864,
            "mae": 0.26499109426125933,
            "precision": 0.7822014051522248,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8476979472117621,
            "auditor_fn_violation": 0.0006887052341597835,
            "auditor_fp_violation": 0.006171606000983767,
            "ave_precision_score": 0.8480453926134246,
            "fpr": 0.11293859649122807,
            "logloss": 0.5289416642289239,
            "mae": 0.32222049417645104,
            "precision": 0.774617067833698,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8336001335462785,
            "auditor_fn_violation": 0.003853609547609604,
            "auditor_fp_violation": 0.016271272504611065,
            "ave_precision_score": 0.8338345609881447,
            "fpr": 0.10428100987925357,
            "logloss": 0.5420856370560816,
            "mae": 0.33119119516585094,
            "precision": 0.7710843373493976,
            "recall": 0.6808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8599909335123717,
            "auditor_fn_violation": 0.008821770334928229,
            "auditor_fp_violation": 0.008715568125922285,
            "ave_precision_score": 0.8602721502770865,
            "fpr": 0.14364035087719298,
            "logloss": 0.4922415201548407,
            "mae": 0.28980730813642014,
            "precision": 0.7565055762081785,
            "recall": 0.8409090909090909
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8560900373290568,
            "auditor_fn_violation": 0.005516500455426587,
            "auditor_fp_violation": 0.016801451645422166,
            "ave_precision_score": 0.8562922332617846,
            "fpr": 0.13391877058177826,
            "logloss": 0.5030544318674349,
            "mae": 0.29768190536052647,
            "precision": 0.7535353535353535,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8250521712790588,
            "auditor_fn_violation": 0.008173843700159493,
            "auditor_fp_violation": 0.013808616166584683,
            "ave_precision_score": 0.8255236941760705,
            "fpr": 0.12828947368421054,
            "logloss": 0.7866407965914173,
            "mae": 0.26869612858444536,
            "precision": 0.7621951219512195,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8225948011837435,
            "auditor_fn_violation": 0.009454188756802205,
            "auditor_fp_violation": 0.022289925849593408,
            "ave_precision_score": 0.8228553117983695,
            "fpr": 0.12843029637760703,
            "logloss": 0.8414970029772973,
            "mae": 0.28217510170151955,
            "precision": 0.7478448275862069,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8441782158875734,
            "auditor_fn_violation": 0.0038127990430622044,
            "auditor_fp_violation": 0.009981144449909819,
            "ave_precision_score": 0.8449662586580465,
            "fpr": 0.09868421052631579,
            "logloss": 0.7748799356929192,
            "mae": 0.2565019225947724,
            "precision": 0.8030634573304157,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8473706547040566,
            "auditor_fn_violation": 0.010231917229137967,
            "auditor_fp_violation": 0.014924667269029829,
            "ave_precision_score": 0.8475739177706312,
            "fpr": 0.10318331503841932,
            "logloss": 0.7529520117335368,
            "mae": 0.2656948470007463,
            "precision": 0.7829099307159353,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8191575648080741,
            "auditor_fn_violation": 0.010085906916050458,
            "auditor_fp_violation": 0.018691588785046735,
            "ave_precision_score": 0.8183730386784659,
            "fpr": 0.15570175438596492,
            "logloss": 0.8029471958041338,
            "mae": 0.26304742086754807,
            "precision": 0.7394495412844037,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8126850573285284,
            "auditor_fn_violation": 0.01359740290071701,
            "auditor_fp_violation": 0.025386371160246026,
            "ave_precision_score": 0.8122739251747308,
            "fpr": 0.16245883644346873,
            "logloss": 0.8489128918271741,
            "mae": 0.2735110838859569,
            "precision": 0.7153846153846154,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8329355828958186,
            "auditor_fn_violation": 0.007385457445266059,
            "auditor_fp_violation": 0.028621495327102807,
            "ave_precision_score": 0.8333563880965594,
            "fpr": 0.3157894736842105,
            "logloss": 1.374119749637437,
            "mae": 0.34152167494034746,
            "precision": 0.6149732620320856,
            "recall": 0.9504132231404959
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8297675340706258,
            "auditor_fn_violation": 0.006539458626246584,
            "auditor_fp_violation": 0.021836908931153864,
            "ave_precision_score": 0.8300021439387054,
            "fpr": 0.31394072447859495,
            "logloss": 1.3754595765301623,
            "mae": 0.3486284234801855,
            "precision": 0.6114130434782609,
            "recall": 0.9574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8317899689243587,
            "auditor_fn_violation": 0.006137179208351463,
            "auditor_fp_violation": 0.010724094113789146,
            "ave_precision_score": 0.8323059933495086,
            "fpr": 0.10635964912280702,
            "logloss": 0.6884316671711853,
            "mae": 0.26996425528723345,
            "precision": 0.79004329004329,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8268287103306227,
            "auditor_fn_violation": 0.01454095335964687,
            "auditor_fp_violation": 0.013398846549230741,
            "ave_precision_score": 0.8270838202134222,
            "fpr": 0.10976948408342481,
            "logloss": 0.7394656329674093,
            "mae": 0.2798073524060284,
            "precision": 0.7737556561085973,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7887616417112604,
            "auditor_fn_violation": 0.013117116137451071,
            "auditor_fp_violation": 0.017077594687653727,
            "ave_precision_score": 0.7827283530139044,
            "fpr": 0.13815789473684212,
            "logloss": 2.0892690784049655,
            "mae": 0.2858932731875846,
            "precision": 0.7347368421052631,
            "recall": 0.7210743801652892
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7880565632964688,
            "auditor_fn_violation": 0.01319569329939043,
            "auditor_fp_violation": 0.020766594233741796,
            "ave_precision_score": 0.7846257751123951,
            "fpr": 0.1350164654226125,
            "logloss": 2.117473838423088,
            "mae": 0.29482932118728933,
            "precision": 0.7266666666666667,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7467534862718284,
            "auditor_fn_violation": 0.0013864723792953468,
            "auditor_fp_violation": 0.015719790129529457,
            "ave_precision_score": 0.7453688749134133,
            "fpr": 0.27631578947368424,
            "logloss": 1.2799729280312067,
            "mae": 0.33548168866429096,
            "precision": 0.6337209302325582,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7204926220249388,
            "auditor_fn_violation": 0.008258402036574257,
            "auditor_fp_violation": 0.014506497805854885,
            "ave_precision_score": 0.7219949476132372,
            "fpr": 0.287596048298573,
            "logloss": 1.3628708635836966,
            "mae": 0.34334091444320813,
            "precision": 0.6152716593245228,
            "recall": 0.8914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.5597491920468876,
            "auditor_fn_violation": 0.005733924169928958,
            "auditor_fp_violation": 0.0230263157894737,
            "ave_precision_score": 0.527451869555865,
            "fpr": 0.29385964912280704,
            "logloss": 5.393355352212349,
            "mae": 0.4050528090638916,
            "precision": 0.5933232169954477,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5393291941956447,
            "auditor_fn_violation": 0.0029661115911904182,
            "auditor_fp_violation": 0.004699428252823273,
            "ave_precision_score": 0.501947354873182,
            "fpr": 0.32711306256860595,
            "logloss": 6.1213911726326105,
            "mae": 0.4201828519471961,
            "precision": 0.5636896046852123,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8187054688760171,
            "auditor_fn_violation": 0.004499238799478033,
            "auditor_fp_violation": 0.012204869650762422,
            "ave_precision_score": 0.8191711887976926,
            "fpr": 0.13486842105263158,
            "logloss": 0.834085634013478,
            "mae": 0.2724498733755451,
            "precision": 0.7544910179640718,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8203457662218919,
            "auditor_fn_violation": 0.009528925426816456,
            "auditor_fp_violation": 0.018496531433649207,
            "ave_precision_score": 0.8205968735741114,
            "fpr": 0.141602634467618,
            "logloss": 0.872582609775693,
            "mae": 0.28451304854343706,
            "precision": 0.7278481012658228,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8360928927925668,
            "auditor_fn_violation": 0.005989923154994924,
            "auditor_fp_violation": 0.009479012952943108,
            "ave_precision_score": 0.8365872783022512,
            "fpr": 0.14692982456140352,
            "logloss": 0.6664739250033561,
            "mae": 0.2680573327853496,
            "precision": 0.7481203007518797,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8330661471265386,
            "auditor_fn_violation": 0.011434710512179744,
            "auditor_fp_violation": 0.023845615816762124,
            "ave_precision_score": 0.8332987779192513,
            "fpr": 0.1525795828759605,
            "logloss": 0.7119268264999609,
            "mae": 0.27896644512318386,
            "precision": 0.7290448343079922,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8561105319534816,
            "auditor_fn_violation": 0.011411211396259249,
            "auditor_fp_violation": 0.012194622069191672,
            "ave_precision_score": 0.8563319926098825,
            "fpr": 0.13157894736842105,
            "logloss": 0.7120222192867083,
            "mae": 0.2790609951378173,
            "precision": 0.7642436149312377,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.847741711019801,
            "auditor_fn_violation": 0.00811126421748371,
            "auditor_fp_violation": 0.015377684187469362,
            "ave_precision_score": 0.8478663849497878,
            "fpr": 0.13391877058177826,
            "logloss": 0.682691875519574,
            "mae": 0.2881731539081338,
            "precision": 0.7505112474437627,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8397537915761568,
            "auditor_fn_violation": 0.006230063795853274,
            "auditor_fp_violation": 0.003561034595835388,
            "ave_precision_score": 0.8401461168491173,
            "fpr": 0.1162280701754386,
            "logloss": 0.653665181753656,
            "mae": 0.267497167874265,
            "precision": 0.7791666666666667,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8345566148576963,
            "auditor_fn_violation": 0.008823598103557002,
            "auditor_fp_violation": 0.02200616799958183,
            "ave_precision_score": 0.8347874798437771,
            "fpr": 0.12403951701427003,
            "logloss": 0.7042739905032277,
            "mae": 0.27926725127365065,
            "precision": 0.7569892473118279,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8167786788092773,
            "auditor_fn_violation": 0.00726085616934899,
            "auditor_fp_violation": 0.008577225774717177,
            "ave_precision_score": 0.8172869838044958,
            "fpr": 0.13815789473684212,
            "logloss": 0.7936846562501594,
            "mae": 0.2715158132120803,
            "precision": 0.7504950495049505,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8228192628433877,
            "auditor_fn_violation": 0.0065908400868813855,
            "auditor_fp_violation": 0.017249490355966755,
            "ave_precision_score": 0.823083870610869,
            "fpr": 0.13830954994511527,
            "logloss": 0.8312257844086396,
            "mae": 0.28088072162613337,
            "precision": 0.7385892116182573,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8305237768113891,
            "auditor_fn_violation": 0.00830977236479629,
            "auditor_fp_violation": 0.008866719954090836,
            "ave_precision_score": 0.8310319146159235,
            "fpr": 0.13267543859649122,
            "logloss": 0.8005094837440295,
            "mae": 0.2641914567443536,
            "precision": 0.7584830339321357,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.82580386795522,
            "auditor_fn_violation": 0.007637153467080835,
            "auditor_fp_violation": 0.024811388148380468,
            "ave_precision_score": 0.8260493762122258,
            "fpr": 0.13721185510428102,
            "logloss": 0.8800210821736801,
            "mae": 0.27895738536648207,
            "precision": 0.7368421052631579,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8360517376337271,
            "auditor_fn_violation": 0.009367750471219372,
            "auditor_fp_violation": 0.015814580259058863,
            "ave_precision_score": 0.8366002478725558,
            "fpr": 0.12171052631578948,
            "logloss": 0.7065981204463189,
            "mae": 0.2614755775447317,
            "precision": 0.7725409836065574,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8337888925979043,
            "auditor_fn_violation": 0.013546021440082212,
            "auditor_fp_violation": 0.01942247810210803,
            "ave_precision_score": 0.8340169704331499,
            "fpr": 0.11855104281009879,
            "logloss": 0.7725146974197105,
            "mae": 0.27399787299959466,
            "precision": 0.7652173913043478,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8296458373446732,
            "auditor_fn_violation": 0.006411302015369,
            "auditor_fp_violation": 0.012576344482702086,
            "ave_precision_score": 0.830130414288629,
            "fpr": 0.12609649122807018,
            "logloss": 0.737025669632952,
            "mae": 0.2672656340108332,
            "precision": 0.7667342799188641,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8276169139691547,
            "auditor_fn_violation": 0.008094915570918097,
            "auditor_fp_violation": 0.020833800040323484,
            "ave_precision_score": 0.8278657568396385,
            "fpr": 0.12733260153677278,
            "logloss": 0.788213302908573,
            "mae": 0.2800359035253429,
            "precision": 0.7516059957173448,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8376020734718541,
            "auditor_fn_violation": 0.011721581847179932,
            "auditor_fp_violation": 0.013731759304804065,
            "ave_precision_score": 0.838253317169549,
            "fpr": 0.12390350877192982,
            "logloss": 0.6708575339248963,
            "mae": 0.2636409049927168,
            "precision": 0.7693877551020408,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8354405143344747,
            "auditor_fn_violation": 0.014550295443398652,
            "auditor_fp_violation": 0.019636541041590436,
            "ave_precision_score": 0.8356712772111858,
            "fpr": 0.1207464324917673,
            "logloss": 0.7270527521893613,
            "mae": 0.27384007901960683,
            "precision": 0.7634408602150538,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.837477739887508,
            "auditor_fn_violation": 0.010955850369725972,
            "auditor_fp_violation": 0.017420888670273815,
            "ave_precision_score": 0.8380395767720267,
            "fpr": 0.12280701754385964,
            "logloss": 0.7520506652605774,
            "mae": 0.25926645201322973,
            "precision": 0.7728194726166329,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8365673924164749,
            "auditor_fn_violation": 0.013489968937571522,
            "auditor_fp_violation": 0.021466032442980863,
            "ave_precision_score": 0.8367809375747504,
            "fpr": 0.12294182217343579,
            "logloss": 0.824016890780563,
            "mae": 0.2744318081604332,
            "precision": 0.7554585152838428,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8396501401311341,
            "auditor_fn_violation": 0.01034190590111643,
            "auditor_fp_violation": 0.011221101819970488,
            "ave_precision_score": 0.8401559536048935,
            "fpr": 0.1118421052631579,
            "logloss": 0.7612734459355337,
            "mae": 0.25430014471986145,
            "precision": 0.7879417879417879,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8397035946323587,
            "auditor_fn_violation": 0.013177009131886871,
            "auditor_fp_violation": 0.01506156798614067,
            "ave_precision_score": 0.8399398301722968,
            "fpr": 0.11086717892425905,
            "logloss": 0.7763458932419001,
            "mae": 0.26351569347836346,
            "precision": 0.7730337078651686,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8462563772313988,
            "auditor_fn_violation": 0.00971436856604321,
            "auditor_fp_violation": 0.010780455812428274,
            "ave_precision_score": 0.846998178355401,
            "fpr": 0.11842105263157894,
            "logloss": 0.6012562741426399,
            "mae": 0.2680364798632605,
            "precision": 0.775,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8421976160452169,
            "auditor_fn_violation": 0.010542541513884672,
            "auditor_fp_violation": 0.022023591727214135,
            "ave_precision_score": 0.8424031013101987,
            "fpr": 0.13062568605927552,
            "logloss": 0.6598073164512299,
            "mae": 0.2803982472316745,
            "precision": 0.7451820128479657,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8413527015892083,
            "auditor_fn_violation": 0.010126685515441497,
            "auditor_fp_violation": 0.009960649286768325,
            "ave_precision_score": 0.8418251600263651,
            "fpr": 0.11074561403508772,
            "logloss": 0.8691258969018878,
            "mae": 0.2528723250440239,
            "precision": 0.7841880341880342,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8416214466342995,
            "auditor_fn_violation": 0.013975757292664138,
            "auditor_fp_violation": 0.016998090857272295,
            "ave_precision_score": 0.8418496091396777,
            "fpr": 0.10098792535675083,
            "logloss": 0.8653106600512822,
            "mae": 0.2625955360518346,
            "precision": 0.7865429234338747,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8416337613790288,
            "auditor_fn_violation": 0.009811784109032917,
            "auditor_fp_violation": 0.01799475323823579,
            "ave_precision_score": 0.8422705823109656,
            "fpr": 0.125,
            "logloss": 0.65308532190765,
            "mae": 0.2607148898556568,
            "precision": 0.7696969696969697,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8400617501600272,
            "auditor_fn_violation": 0.012658523483663035,
            "auditor_fp_violation": 0.015457335513788393,
            "ave_precision_score": 0.8402829581994835,
            "fpr": 0.1251372118551043,
            "logloss": 0.7072481947397851,
            "mae": 0.27115085299855557,
            "precision": 0.7579617834394905,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8339129890114336,
            "auditor_fn_violation": 0.012170146440481372,
            "auditor_fp_violation": 0.019301319888506318,
            "ave_precision_score": 0.8344955403884836,
            "fpr": 0.18640350877192982,
            "logloss": 0.7268265415925739,
            "mae": 0.2673176478043799,
            "precision": 0.7138047138047138,
            "recall": 0.8760330578512396
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8246538291621578,
            "auditor_fn_violation": 0.00869747997290796,
            "auditor_fp_violation": 0.024410642412837812,
            "ave_precision_score": 0.825159414545287,
            "fpr": 0.18441273326015367,
            "logloss": 0.7712711505733897,
            "mae": 0.27604183980278196,
            "precision": 0.7047451669595782,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8448161821945046,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.0049752008525987945,
            "ave_precision_score": 0.8461494613854739,
            "fpr": 0.125,
            "logloss": 0.5015315750876067,
            "mae": 0.2928548023901704,
            "precision": 0.7738095238095238,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8510080694525405,
            "auditor_fn_violation": 0.0033397949412616507,
            "auditor_fp_violation": 0.017879233654676658,
            "ave_precision_score": 0.8512178789967343,
            "fpr": 0.1141602634467618,
            "logloss": 0.5090705507219517,
            "mae": 0.30035044145779727,
            "precision": 0.7758620689655172,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8409513765060561,
            "auditor_fn_violation": 0.007643721908075975,
            "auditor_fp_violation": 0.01278898180029513,
            "ave_precision_score": 0.8423679907342908,
            "fpr": 0.12719298245614036,
            "logloss": 0.5244532732536019,
            "mae": 0.28062873498537666,
            "precision": 0.7689243027888446,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8448766548289723,
            "auditor_fn_violation": 0.012023261788541939,
            "auditor_fp_violation": 0.020896027639010238,
            "ave_precision_score": 0.845093029115253,
            "fpr": 0.13721185510428102,
            "logloss": 0.5446901213656851,
            "mae": 0.290276685278724,
            "precision": 0.7406639004149378,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8542996672657935,
            "auditor_fn_violation": 0.021667029143105705,
            "auditor_fp_violation": 0.014669413018527628,
            "ave_precision_score": 0.8546692907082739,
            "fpr": 0.06907894736842106,
            "logloss": 0.5250011257279803,
            "mae": 0.3074935532409728,
            "precision": 0.8425,
            "recall": 0.6962809917355371
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8505313216191894,
            "auditor_fn_violation": 0.023607445640750173,
            "auditor_fp_violation": 0.01156686604389286,
            "ave_precision_score": 0.8507240795022548,
            "fpr": 0.07244785949506037,
            "logloss": 0.568510464098669,
            "mae": 0.3154559606394719,
            "precision": 0.8235294117647058,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8477910238468576,
            "auditor_fn_violation": 0.008948637088589248,
            "auditor_fp_violation": 0.012568658796524024,
            "ave_precision_score": 0.8481150934086452,
            "fpr": 0.12171052631578948,
            "logloss": 0.5243299825243972,
            "mae": 0.3345193267440456,
            "precision": 0.7706611570247934,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8352043172495023,
            "auditor_fn_violation": 0.012611813064904134,
            "auditor_fp_violation": 0.010210304392521744,
            "ave_precision_score": 0.8354652130306186,
            "fpr": 0.15367727771679474,
            "logloss": 0.5392996864962671,
            "mae": 0.34649766222231343,
            "precision": 0.714867617107943,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8373610372394998,
            "auditor_fn_violation": 0.01769338118022329,
            "auditor_fp_violation": 0.017636087883259554,
            "ave_precision_score": 0.8378927261385504,
            "fpr": 0.16666666666666666,
            "logloss": 0.6550317574410627,
            "mae": 0.2751223337213001,
            "precision": 0.738831615120275,
            "recall": 0.8884297520661157
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8294196512713854,
            "auditor_fn_violation": 0.01463904523904057,
            "auditor_fp_violation": 0.015865548561173472,
            "ave_precision_score": 0.8296782031948818,
            "fpr": 0.17014270032930845,
            "logloss": 0.6960209590127427,
            "mae": 0.293105611232665,
            "precision": 0.7186932849364791,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8262424456823089,
            "auditor_fn_violation": 0.00498178555893867,
            "auditor_fp_violation": 0.00906142400393507,
            "ave_precision_score": 0.8267378569471157,
            "fpr": 0.11951754385964912,
            "logloss": 0.7574225526368674,
            "mae": 0.26927885683672326,
            "precision": 0.7710084033613446,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8242665442688872,
            "auditor_fn_violation": 0.009951654716584539,
            "auditor_fp_violation": 0.02055004219031191,
            "ave_precision_score": 0.8245189675117406,
            "fpr": 0.1251372118551043,
            "logloss": 0.8021890254691155,
            "mae": 0.2812164044995054,
            "precision": 0.75054704595186,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8430421827807726,
            "auditor_fn_violation": 0.011116699289546178,
            "auditor_fp_violation": 0.012143384161337936,
            "ave_precision_score": 0.844295132099631,
            "fpr": 0.13157894736842105,
            "logloss": 0.6590371456508659,
            "mae": 0.2696002606540145,
            "precision": 0.7556008146639511,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8411147894367244,
            "auditor_fn_violation": 0.013113950066562347,
            "auditor_fp_violation": 0.019041645198145128,
            "ave_precision_score": 0.8413114060862199,
            "fpr": 0.12733260153677278,
            "logloss": 0.7099463602939838,
            "mae": 0.28253658663316294,
            "precision": 0.7483731019522777,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 32400,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.7710500057961789,
            "auditor_fn_violation": 0.0007747933884297494,
            "auditor_fp_violation": 0.006087063453025086,
            "ave_precision_score": 0.767899800081571,
            "fpr": 0.01206140350877193,
            "logloss": 18.519156198117386,
            "mae": 0.5361842105263158,
            "precision": 0.35294117647058826,
            "recall": 0.012396694214876033
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.7352474806059832,
            "auditor_fn_violation": 0.0035359787000490534,
            "auditor_fp_violation": 0.0042563677501736156,
            "ave_precision_score": 0.7302211020082426,
            "fpr": 0.019758507135016465,
            "logloss": 18.19827339441369,
            "mae": 0.5268935236004391,
            "precision": 0.3076923076923077,
            "recall": 0.01702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8370409779379082,
            "auditor_fn_violation": 0.005881180223285485,
            "auditor_fp_violation": 0.007388506312510255,
            "ave_precision_score": 0.8383671551799377,
            "fpr": 0.1206140350877193,
            "logloss": 0.5328072632591832,
            "mae": 0.2851516663745554,
            "precision": 0.7727272727272727,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.835887035454314,
            "auditor_fn_violation": 0.007331200224210011,
            "auditor_fp_violation": 0.023370196962795364,
            "ave_precision_score": 0.8361187457137442,
            "fpr": 0.12952799121844127,
            "logloss": 0.5735538643592896,
            "mae": 0.29725689736401506,
            "precision": 0.7473233404710921,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 32400,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8347500536729779,
            "auditor_fn_violation": 0.005636508626939253,
            "auditor_fp_violation": 0.013739444990982126,
            "ave_precision_score": 0.8355032855847737,
            "fpr": 0.09100877192982457,
            "logloss": 0.6756446692366008,
            "mae": 0.26943753581266117,
            "precision": 0.8109339407744874,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8295063756606649,
            "auditor_fn_violation": 0.01299717401966509,
            "auditor_fp_violation": 0.012363379307083242,
            "ave_precision_score": 0.8297492513786341,
            "fpr": 0.10098792535675083,
            "logloss": 0.7597511455083023,
            "mae": 0.28536463512009874,
            "precision": 0.7793764988009593,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7559264365627085,
            "auditor_fn_violation": 0.005067873713208645,
            "auditor_fp_violation": 0.0067429086735530455,
            "ave_precision_score": 0.7546223820047504,
            "fpr": 0.16228070175438597,
            "logloss": 1.0877344450982172,
            "mae": 0.2910207734413518,
            "precision": 0.7243947858472998,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7471111603813625,
            "auditor_fn_violation": 0.010862507882383169,
            "auditor_fp_violation": 0.013515834434761835,
            "ave_precision_score": 0.7446147048977294,
            "fpr": 0.1734357848518112,
            "logloss": 1.1404647951831914,
            "mae": 0.3051065496777745,
            "precision": 0.699047619047619,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 32400,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7198567585044788,
            "auditor_fn_violation": 0.00031263592866464276,
            "auditor_fp_violation": 0.014418347270044289,
            "ave_precision_score": 0.7193548210010757,
            "fpr": 0.25,
            "logloss": 1.204679383388063,
            "mae": 0.3376769777718167,
            "precision": 0.6426332288401254,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7241813467782461,
            "auditor_fn_violation": 0.003652754746946307,
            "auditor_fp_violation": 0.0077137331332093875,
            "ave_precision_score": 0.7250460414516929,
            "fpr": 0.270032930845225,
            "logloss": 1.142321989492773,
            "mae": 0.3476651589727761,
            "precision": 0.6197836166924265,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8374317171498915,
            "auditor_fn_violation": 0.009718899521531101,
            "auditor_fp_violation": 0.0002561895392687363,
            "ave_precision_score": 0.8380095374517218,
            "fpr": 0.11842105263157894,
            "logloss": 0.7543818188203332,
            "mae": 0.2582302073604375,
            "precision": 0.7759336099585062,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8328021613139299,
            "auditor_fn_violation": 0.010159516080061659,
            "auditor_fp_violation": 0.020360870290304194,
            "ave_precision_score": 0.8330273156961181,
            "fpr": 0.12623490669593854,
            "logloss": 0.8395998544910863,
            "mae": 0.27649756761978017,
            "precision": 0.7489082969432315,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.82206335917514,
            "auditor_fn_violation": 0.004947803392779471,
            "auditor_fp_violation": 0.011095568945728811,
            "ave_precision_score": 0.823495222009698,
            "fpr": 0.12828947368421054,
            "logloss": 0.6953597783614124,
            "mae": 0.26629653776369416,
            "precision": 0.7678571428571429,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8309852128271139,
            "auditor_fn_violation": 0.004727094378401104,
            "auditor_fp_violation": 0.021120046994282528,
            "ave_precision_score": 0.8312428503950419,
            "fpr": 0.13721185510428102,
            "logloss": 0.7192612661261609,
            "mae": 0.27757960307345747,
            "precision": 0.7443762781186094,
            "recall": 0.774468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8334943390143623,
            "auditor_fn_violation": 0.012378570392924462,
            "auditor_fp_violation": 0.01954469995081161,
            "ave_precision_score": 0.8340735202232574,
            "fpr": 0.13267543859649122,
            "logloss": 0.7158413550736682,
            "mae": 0.26376370514784203,
            "precision": 0.7613412228796844,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8334171224442471,
            "auditor_fn_violation": 0.013452600602564403,
            "auditor_fp_violation": 0.02533409997734916,
            "ave_precision_score": 0.8336478663883162,
            "fpr": 0.13611416026344675,
            "logloss": 0.7749120739763788,
            "mae": 0.27512578517841113,
            "precision": 0.7411273486430062,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 32400,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7446211529593846,
            "auditor_fn_violation": 0.01587420255183413,
            "auditor_fp_violation": 0.020167240531234636,
            "ave_precision_score": 0.7457268190396659,
            "fpr": 0.12719298245614036,
            "logloss": 1.1170953408389137,
            "mae": 0.3325663530447133,
            "precision": 0.7270588235294118,
            "recall": 0.6384297520661157
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7430079711288213,
            "auditor_fn_violation": 0.014115888548940839,
            "auditor_fp_violation": 0.023395088002270064,
            "ave_precision_score": 0.7435225759083676,
            "fpr": 0.1163556531284303,
            "logloss": 1.1215642311467493,
            "mae": 0.3432288034794805,
            "precision": 0.7188328912466844,
            "recall": 0.5765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.786155221535455,
            "auditor_fn_violation": 0.016551580397274182,
            "auditor_fp_violation": 0.016032341367437287,
            "ave_precision_score": 0.7768576784900241,
            "fpr": 0.14144736842105263,
            "logloss": 2.3125572985387235,
            "mae": 0.28676874894116267,
            "precision": 0.73125,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7841980503369947,
            "auditor_fn_violation": 0.01319569329939043,
            "auditor_fp_violation": 0.019561867923166342,
            "ave_precision_score": 0.777437915994348,
            "fpr": 0.132821075740944,
            "logloss": 2.32107282959827,
            "mae": 0.2948770458369863,
            "precision": 0.7299107142857143,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8008933954803756,
            "auditor_fn_violation": 0.007945030448020887,
            "auditor_fp_violation": 0.011520843580914908,
            "ave_precision_score": 0.8017929767791563,
            "fpr": 0.15679824561403508,
            "logloss": 1.0205875458127491,
            "mae": 0.2873642955955986,
            "precision": 0.7270992366412213,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8129070517784915,
            "auditor_fn_violation": 0.009580306887451248,
            "auditor_fp_violation": 0.022471630437758714,
            "ave_precision_score": 0.813177404958606,
            "fpr": 0.15916575192096596,
            "logloss": 0.8523665028877062,
            "mae": 0.2897765480031915,
            "precision": 0.7145669291338582,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8283093251369458,
            "auditor_fn_violation": 0.01196625344352617,
            "auditor_fp_violation": 0.0182739998360387,
            "ave_precision_score": 0.8288429737281762,
            "fpr": 0.13048245614035087,
            "logloss": 0.781046407201626,
            "mae": 0.2637540250249664,
            "precision": 0.7610441767068273,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.827189839469261,
            "auditor_fn_violation": 0.014307401265852353,
            "auditor_fp_violation": 0.021625335095618932,
            "ave_precision_score": 0.8274405086945037,
            "fpr": 0.1251372118551043,
            "logloss": 0.8441042949662015,
            "mae": 0.27705643344397474,
            "precision": 0.7527114967462039,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8619556550264019,
            "auditor_fn_violation": 0.01030112730172539,
            "auditor_fp_violation": 0.007068269388424335,
            "ave_precision_score": 0.8621896500129489,
            "fpr": 0.10635964912280702,
            "logloss": 0.5263987129946208,
            "mae": 0.3200583703591997,
            "precision": 0.7927350427350427,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.841485866423215,
            "auditor_fn_violation": 0.009374781044912073,
            "auditor_fp_violation": 0.007126304601606467,
            "ave_precision_score": 0.8428174039350848,
            "fpr": 0.11306256860592755,
            "logloss": 0.49642960041397427,
            "mae": 0.3236996623496067,
            "precision": 0.7736263736263737,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8301515123468316,
            "auditor_fn_violation": 0.006207409018413804,
            "auditor_fp_violation": 0.01123134940154125,
            "ave_precision_score": 0.830603663188071,
            "fpr": 0.12280701754385964,
            "logloss": 0.731886798542284,
            "mae": 0.26795491887504946,
            "precision": 0.7723577235772358,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8293628102341525,
            "auditor_fn_violation": 0.007356890954527407,
            "auditor_fp_violation": 0.020393228641621318,
            "ave_precision_score": 0.8296115484825346,
            "fpr": 0.1350164654226125,
            "logloss": 0.7745278407553187,
            "mae": 0.2794026612931763,
            "precision": 0.7399577167019028,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8412272875857993,
            "auditor_fn_violation": 0.007276714513556621,
            "auditor_fp_violation": 0.01118011149368749,
            "ave_precision_score": 0.8416765198508843,
            "fpr": 0.11074561403508772,
            "logloss": 0.8737105199355302,
            "mae": 0.2520408028244774,
            "precision": 0.7864693446088795,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8410528092323992,
            "auditor_fn_violation": 0.01059158745358153,
            "auditor_fp_violation": 0.01621402311381926,
            "ave_precision_score": 0.8412767715322267,
            "fpr": 0.10647639956092206,
            "logloss": 0.8692788130383673,
            "mae": 0.2637793943216201,
            "precision": 0.7764976958525346,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 32400,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8293086263996561,
            "auditor_fn_violation": 0.006714876033057852,
            "auditor_fp_violation": 0.011876947040498454,
            "ave_precision_score": 0.829707916084313,
            "fpr": 0.13157894736842105,
            "logloss": 0.7570295630814651,
            "mae": 0.26982848468131854,
            "precision": 0.7580645161290323,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8254045948897528,
            "auditor_fn_violation": 0.00940280729616741,
            "auditor_fp_violation": 0.02097816806927675,
            "ave_precision_score": 0.8256489567945098,
            "fpr": 0.13062568605927552,
            "logloss": 0.8107642843542259,
            "mae": 0.2836291217566566,
            "precision": 0.7446351931330472,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8231185375374725,
            "auditor_fn_violation": 0.007326555023923445,
            "auditor_fp_violation": 0.00948669863912117,
            "ave_precision_score": 0.823586026409069,
            "fpr": 0.13267543859649122,
            "logloss": 0.8988491876847022,
            "mae": 0.2731807283327812,
            "precision": 0.7555555555555555,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8243421118522508,
            "auditor_fn_violation": 0.0066375505056402865,
            "auditor_fp_violation": 0.024734225926008904,
            "ave_precision_score": 0.8246072330167835,
            "fpr": 0.1394072447859495,
            "logloss": 0.7699373394013435,
            "mae": 0.2811229064921042,
            "precision": 0.7381443298969073,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8338308356661819,
            "auditor_fn_violation": 0.014535305205161667,
            "auditor_fp_violation": 0.042445482866043625,
            "ave_precision_score": 0.8342114780439653,
            "fpr": 0.2719298245614035,
            "logloss": 0.6271527695263248,
            "mae": 0.3527603601513986,
            "precision": 0.6405797101449275,
            "recall": 0.9132231404958677
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8118925612774766,
            "auditor_fn_violation": 0.023485998551977024,
            "auditor_fp_violation": 0.04764891686641727,
            "ave_precision_score": 0.8122172502268956,
            "fpr": 0.28210757409440174,
            "logloss": 0.6530658297872886,
            "mae": 0.37046167290330945,
            "precision": 0.6215022091310751,
            "recall": 0.8978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8282449213591461,
            "auditor_fn_violation": 0.010124420037697552,
            "auditor_fp_violation": 0.009320175438596489,
            "ave_precision_score": 0.8287871034458155,
            "fpr": 0.11732456140350878,
            "logloss": 0.7113979662594206,
            "mae": 0.26938915080826414,
            "precision": 0.7770833333333333,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8245860510138298,
            "auditor_fn_violation": 0.01361141602634468,
            "auditor_fp_violation": 0.013779679453193645,
            "ave_precision_score": 0.824844130873448,
            "fpr": 0.11086717892425905,
            "logloss": 0.7690859157202277,
            "mae": 0.28166176799805104,
            "precision": 0.7714932126696833,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.828061231676936,
            "auditor_fn_violation": 0.012650427722198059,
            "auditor_fp_violation": 0.016931566650270544,
            "ave_precision_score": 0.8286950291884105,
            "fpr": 0.11513157894736842,
            "logloss": 0.7484367489935022,
            "mae": 0.2686578845736709,
            "precision": 0.7780126849894292,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8249080873082999,
            "auditor_fn_violation": 0.02196790994231263,
            "auditor_fp_violation": 0.024408153308890335,
            "ave_precision_score": 0.8251542081016477,
            "fpr": 0.1163556531284303,
            "logloss": 0.8200367252846736,
            "mae": 0.28048440657320783,
            "precision": 0.7579908675799086,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7834816884684507,
            "auditor_fn_violation": 0.005557216905901122,
            "auditor_fp_violation": 0.005000819806525665,
            "ave_precision_score": 0.7849585742291182,
            "fpr": 0.16228070175438597,
            "logloss": 0.7459481661175051,
            "mae": 0.3084361942192759,
            "precision": 0.7159309021113244,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7996646441783897,
            "auditor_fn_violation": 0.010860172361445224,
            "auditor_fp_violation": 0.015716202324325277,
            "ave_precision_score": 0.8000282545399716,
            "fpr": 0.1690450054884742,
            "logloss": 0.7368189271921235,
            "mae": 0.31018600407854885,
            "precision": 0.7003891050583657,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7931444613861078,
            "auditor_fn_violation": 0.012315137016093963,
            "auditor_fp_violation": 0.015402115100836212,
            "ave_precision_score": 0.7673366842522052,
            "fpr": 0.13815789473684212,
            "logloss": 3.609258773573466,
            "mae": 0.29451401663389953,
            "precision": 0.7319148936170212,
            "recall": 0.7107438016528925
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7794270922591501,
            "auditor_fn_violation": 0.005754723591097005,
            "auditor_fp_violation": 0.02123454577586615,
            "ave_precision_score": 0.7546140366280867,
            "fpr": 0.132821075740944,
            "logloss": 3.7550621872366152,
            "mae": 0.29946118487403517,
            "precision": 0.725,
            "recall": 0.6787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 32400,
        "test": {
            "accuracy": 0.3475877192982456,
            "auc_prc": 0.4190368154963616,
            "auditor_fn_violation": 0.013563415253008554,
            "auditor_fp_violation": 0.014423471060829642,
            "ave_precision_score": 0.4020594686490993,
            "fpr": 0.29605263157894735,
            "logloss": 9.539667296848908,
            "mae": 0.6485260658823653,
            "precision": 0.3706293706293706,
            "recall": 0.3285123966942149
        },
        "train": {
            "accuracy": 0.3534577387486279,
            "auc_prc": 0.40806878106163896,
            "auditor_fn_violation": 0.01169628885722961,
            "auditor_fp_violation": 0.023454826497009352,
            "ave_precision_score": 0.38921858818800414,
            "fpr": 0.3018660812294182,
            "logloss": 9.626436874268713,
            "mae": 0.6456043011587851,
            "precision": 0.3619489559164733,
            "recall": 0.33191489361702126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.829792249488161,
            "auditor_fn_violation": 0.008074162679425838,
            "auditor_fp_violation": 0.02123811280537793,
            "ave_precision_score": 0.8298803460976713,
            "fpr": 0.3300438596491228,
            "logloss": 1.506643518129455,
            "mae": 0.35196560816050854,
            "precision": 0.6065359477124183,
            "recall": 0.9586776859504132
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.8264413506623572,
            "auditor_fn_violation": 0.005880841721746036,
            "auditor_fp_violation": 0.02562283603525568,
            "ave_precision_score": 0.8266772599878667,
            "fpr": 0.33150384193194293,
            "logloss": 1.4783063404112011,
            "mae": 0.34990534459677847,
            "precision": 0.6,
            "recall": 0.9638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8647134427590176,
            "auditor_fn_violation": 0.01122091126576773,
            "auditor_fp_violation": 0.014546442039678639,
            "ave_precision_score": 0.8649951654844633,
            "fpr": 0.09320175438596491,
            "logloss": 0.5351399589842702,
            "mae": 0.289414764199759,
            "precision": 0.8144104803493449,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8485638533370633,
            "auditor_fn_violation": 0.013905691664525778,
            "auditor_fp_violation": 0.02110013416270277,
            "ave_precision_score": 0.8487879037801176,
            "fpr": 0.10757409440175632,
            "logloss": 0.6011826804602777,
            "mae": 0.3039888512552378,
            "precision": 0.7715617715617715,
            "recall": 0.7042553191489361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8153089719687141,
            "auditor_fn_violation": 0.00744435986660867,
            "auditor_fp_violation": 0.013854730283653069,
            "ave_precision_score": 0.815790511958899,
            "fpr": 0.11842105263157894,
            "logloss": 0.8660708154407457,
            "mae": 0.2734910873748157,
            "precision": 0.7702127659574468,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8176769495955628,
            "auditor_fn_violation": 0.01003806899128851,
            "auditor_fp_violation": 0.020211524053455995,
            "ave_precision_score": 0.8179427988613078,
            "fpr": 0.13062568605927552,
            "logloss": 0.9027843467608728,
            "mae": 0.2854274644226629,
            "precision": 0.7396061269146609,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.8514849708930217,
            "auditor_fn_violation": 0.01162190082644628,
            "auditor_fp_violation": 0.026300418101328087,
            "ave_precision_score": 0.8518208845748876,
            "fpr": 0.3442982456140351,
            "logloss": 0.7496337213483072,
            "mae": 0.3558602641048645,
            "precision": 0.590612777053455,
            "recall": 0.9359504132231405
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.840894498722312,
            "auditor_fn_violation": 0.006312913095265901,
            "auditor_fp_violation": 0.033222070386881436,
            "ave_precision_score": 0.841107850340002,
            "fpr": 0.3358946212952799,
            "logloss": 0.7527460207127132,
            "mae": 0.36402045491142054,
            "precision": 0.5914552736982643,
            "recall": 0.9425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8349562106563123,
            "auditor_fn_violation": 0.011259424387414823,
            "auditor_fp_violation": 0.018558370224626995,
            "ave_precision_score": 0.8357905585086981,
            "fpr": 0.10307017543859649,
            "logloss": 0.6860397315115607,
            "mae": 0.26628710490224455,
            "precision": 0.7952069716775599,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8346892535234525,
            "auditor_fn_violation": 0.01819137258565524,
            "auditor_fp_violation": 0.01773984383361834,
            "ave_precision_score": 0.834922211080944,
            "fpr": 0.10428100987925357,
            "logloss": 0.7503501838710604,
            "mae": 0.2768469352963421,
            "precision": 0.7800925925925926,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8350297023401883,
            "auditor_fn_violation": 0.008065100768450056,
            "auditor_fp_violation": 0.0060307017543859654,
            "ave_precision_score": 0.8358010867715389,
            "fpr": 0.12171052631578948,
            "logloss": 0.6384068323158733,
            "mae": 0.27502951210419724,
            "precision": 0.7720739219712526,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8314890808524317,
            "auditor_fn_violation": 0.00819767849218769,
            "auditor_fp_violation": 0.019148676667886326,
            "ave_precision_score": 0.8317203336365605,
            "fpr": 0.13062568605927552,
            "logloss": 0.6717758255650796,
            "mae": 0.2856799814407249,
            "precision": 0.7451820128479657,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8554138355221218,
            "auditor_fn_violation": 0.003493366681165733,
            "auditor_fp_violation": 0.008218560419740943,
            "ave_precision_score": 0.8556555587388264,
            "fpr": 0.08114035087719298,
            "logloss": 0.5501232059672753,
            "mae": 0.3313442043074083,
            "precision": 0.8221153846153846,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8348633770370768,
            "auditor_fn_violation": 0.005593572646378782,
            "auditor_fp_violation": 0.00357684237251432,
            "ave_precision_score": 0.8362450928671812,
            "fpr": 0.08122941822173436,
            "logloss": 0.5124308761872196,
            "mae": 0.3322293285319873,
            "precision": 0.8145363408521303,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8300696910075278,
            "auditor_fn_violation": 0.0060737458315209564,
            "auditor_fp_violation": 0.012829972126578132,
            "ave_precision_score": 0.8309278104844752,
            "fpr": 0.11842105263157894,
            "logloss": 0.7153941034540324,
            "mae": 0.2661565373264499,
            "precision": 0.7745302713987474,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8298066587078754,
            "auditor_fn_violation": 0.00817198776187029,
            "auditor_fp_violation": 0.021192231008759162,
            "ave_precision_score": 0.8300428175274933,
            "fpr": 0.12843029637760703,
            "logloss": 0.7785488813850111,
            "mae": 0.28022714127350906,
            "precision": 0.7478448275862069,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8361092690378074,
            "auditor_fn_violation": 0.004014426562273455,
            "auditor_fp_violation": 0.007654943433349727,
            "ave_precision_score": 0.8365506821993138,
            "fpr": 0.1162280701754386,
            "logloss": 0.6670697188412699,
            "mae": 0.267740999616773,
            "precision": 0.7796257796257796,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8322416921552309,
            "auditor_fn_violation": 0.007539061587687143,
            "auditor_fp_violation": 0.021498390794297967,
            "ave_precision_score": 0.8324769403234464,
            "fpr": 0.12403951701427003,
            "logloss": 0.7188547256199916,
            "mae": 0.2800236602825678,
            "precision": 0.7564655172413793,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8520557211922817,
            "auditor_fn_violation": 0.0119141474554154,
            "auditor_fp_violation": 0.019993031644531898,
            "ave_precision_score": 0.8524115161146003,
            "fpr": 0.14035087719298245,
            "logloss": 0.6374194874848841,
            "mae": 0.25828343414028243,
            "precision": 0.7598499061913696,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.846145932330209,
            "auditor_fn_violation": 0.013700165821986592,
            "auditor_fp_violation": 0.01679398433357976,
            "ave_precision_score": 0.8463568272491545,
            "fpr": 0.13611416026344675,
            "logloss": 0.6861907026319133,
            "mae": 0.26864407607843077,
            "precision": 0.751004016064257,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8565525967012727,
            "auditor_fn_violation": 0.006606133101348416,
            "auditor_fp_violation": 0.012806915068043944,
            "ave_precision_score": 0.8567713726183834,
            "fpr": 0.08442982456140351,
            "logloss": 0.5337224903999219,
            "mae": 0.31990043332355034,
            "precision": 0.8162291169451074,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8489092352837132,
            "auditor_fn_violation": 0.003874629236051102,
            "auditor_fp_violation": 0.0063322804423635555,
            "ave_precision_score": 0.8491045460014619,
            "fpr": 0.07574094401756312,
            "logloss": 0.533528270760267,
            "mae": 0.32172833159894343,
            "precision": 0.8184210526315789,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.5855892423492197,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.032346491228070186,
            "ave_precision_score": 0.5860543226722498,
            "fpr": 0.22916666666666666,
            "logloss": 1.7080560905765445,
            "mae": 0.3895502399542689,
            "precision": 0.6294326241134752,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6007082821586669,
            "auditor_fn_violation": 0.00824438891094659,
            "auditor_fp_violation": 0.014023611640045704,
            "ave_precision_score": 0.6006101040369914,
            "fpr": 0.23929747530186607,
            "logloss": 1.6659460465486309,
            "mae": 0.38996111749160417,
            "precision": 0.6188811188811189,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8358631069097843,
            "auditor_fn_violation": 0.014249855009424392,
            "auditor_fp_violation": 0.018379037547138877,
            "ave_precision_score": 0.8364525033537801,
            "fpr": 0.19517543859649122,
            "logloss": 0.7651483635562578,
            "mae": 0.2694413149281562,
            "precision": 0.7105691056910569,
            "recall": 0.9028925619834711
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8297993916728772,
            "auditor_fn_violation": 0.008898334773571246,
            "auditor_fp_violation": 0.022192850795642087,
            "ave_precision_score": 0.830199059200219,
            "fpr": 0.19319429198682767,
            "logloss": 0.805615102033028,
            "mae": 0.27789487930958506,
            "precision": 0.6996587030716723,
            "recall": 0.8723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.845941083640238,
            "auditor_fn_violation": 0.00902792880962738,
            "auditor_fp_violation": 0.009458517789801611,
            "ave_precision_score": 0.8465003033219356,
            "fpr": 0.14035087719298245,
            "logloss": 0.7384651233040163,
            "mae": 0.24774923467352392,
            "precision": 0.7616387337057728,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8394118790526351,
            "auditor_fn_violation": 0.009552280636195903,
            "auditor_fp_violation": 0.012522681959721327,
            "ave_precision_score": 0.8398216895633499,
            "fpr": 0.141602634467618,
            "logloss": 0.7267650109142507,
            "mae": 0.2576476650370924,
            "precision": 0.7455621301775148,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.8374225898586303,
            "auditor_fn_violation": 0.004558141220820646,
            "auditor_fp_violation": 0.01801012461059191,
            "ave_precision_score": 0.8381833608331655,
            "fpr": 0.3475877192982456,
            "logloss": 1.3528654400590254,
            "mae": 0.3568408665913878,
            "precision": 0.5961783439490446,
            "recall": 0.9669421487603306
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8333209033506185,
            "auditor_fn_violation": 0.00637597216059042,
            "auditor_fp_violation": 0.022999320474622345,
            "ave_precision_score": 0.8335493672326295,
            "fpr": 0.34796926454445665,
            "logloss": 1.3659186595316697,
            "mae": 0.36434423566925084,
            "precision": 0.5893782383419689,
            "recall": 0.9680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8233335526554348,
            "auditor_fn_violation": 0.005917427867188635,
            "auditor_fp_violation": 0.014592556156747009,
            "ave_precision_score": 0.8238399263695189,
            "fpr": 0.1337719298245614,
            "logloss": 0.7541673944787549,
            "mae": 0.2719816735725954,
            "precision": 0.7550200803212851,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.811345627704745,
            "auditor_fn_violation": 0.0116028680197118,
            "auditor_fp_violation": 0.017478487919133995,
            "ave_precision_score": 0.8116594596415616,
            "fpr": 0.13611416026344675,
            "logloss": 0.8347534328856268,
            "mae": 0.28280013387570185,
            "precision": 0.7378435517970402,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8307895136852217,
            "auditor_fn_violation": 0.009009804987675802,
            "auditor_fp_violation": 0.011415805869814732,
            "ave_precision_score": 0.8315070091524497,
            "fpr": 0.12719298245614036,
            "logloss": 0.7166486959297838,
            "mae": 0.26479936696173373,
            "precision": 0.7647058823529411,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.829810049277903,
            "auditor_fn_violation": 0.014260690847093442,
            "auditor_fp_violation": 0.020057199608712866,
            "ave_precision_score": 0.8300496459460491,
            "fpr": 0.12403951701427003,
            "logloss": 0.7807871021443923,
            "mae": 0.2769246441923778,
            "precision": 0.7527352297592997,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8499638420709653,
            "auditor_fn_violation": 0.013520371175873569,
            "auditor_fp_violation": 0.015256087063453033,
            "ave_precision_score": 0.8504038054080794,
            "fpr": 0.11513157894736842,
            "logloss": 0.73526263428877,
            "mae": 0.25244642719374744,
            "precision": 0.784394250513347,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8446160980210551,
            "auditor_fn_violation": 0.020211598196977834,
            "auditor_fp_violation": 0.018180415232320522,
            "ave_precision_score": 0.844833752197919,
            "fpr": 0.1141602634467618,
            "logloss": 0.7290764156228488,
            "mae": 0.26281866238148893,
            "precision": 0.7704194260485652,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8498743421699801,
            "auditor_fn_violation": 0.013126178048426857,
            "auditor_fp_violation": 0.01488973602229874,
            "ave_precision_score": 0.8503114341540914,
            "fpr": 0.1162280701754386,
            "logloss": 0.7137552757672798,
            "mae": 0.25379204042395126,
            "precision": 0.7823408624229979,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8440375866911403,
            "auditor_fn_violation": 0.020211598196977834,
            "auditor_fp_violation": 0.01860854111128536,
            "ave_precision_score": 0.8442553431523461,
            "fpr": 0.11525795828759605,
            "logloss": 0.7172762660382906,
            "mae": 0.2643892310817328,
            "precision": 0.7687224669603524,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.815405664353525,
            "auditor_fn_violation": 0.006542699724517905,
            "auditor_fp_violation": 0.012609649122807019,
            "ave_precision_score": 0.8158958782749515,
            "fpr": 0.11732456140350878,
            "logloss": 0.8646533820836602,
            "mae": 0.2734263424360283,
            "precision": 0.772823779193206,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8177696453057262,
            "auditor_fn_violation": 0.009902608776887688,
            "auditor_fp_violation": 0.020211524053455995,
            "ave_precision_score": 0.8180347534021167,
            "fpr": 0.13062568605927552,
            "logloss": 0.9021609026022075,
            "mae": 0.2855576360471917,
            "precision": 0.7407407407407407,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 32400,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8083261631497051,
            "auditor_fn_violation": 0.01022636653617515,
            "auditor_fp_violation": 0.011144244958189865,
            "ave_precision_score": 0.7880668068529249,
            "fpr": 0.1337719298245614,
            "logloss": 1.6367307239267357,
            "mae": 0.2633096340583094,
            "precision": 0.7640232108317214,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7923459783116626,
            "auditor_fn_violation": 0.011724315108484947,
            "auditor_fp_violation": 0.019915320683707074,
            "ave_precision_score": 0.7726149560167218,
            "fpr": 0.13830954994511527,
            "logloss": 1.7432082398636415,
            "mae": 0.2762417089054629,
            "precision": 0.7418032786885246,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8374304380176474,
            "auditor_fn_violation": 0.014607800492967959,
            "auditor_fp_violation": 0.01816896212493852,
            "ave_precision_score": 0.8380040640627423,
            "fpr": 0.15789473684210525,
            "logloss": 0.6877259330223418,
            "mae": 0.26088724542884095,
            "precision": 0.7428571428571429,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8307426102018491,
            "auditor_fn_violation": 0.011663591564098373,
            "auditor_fp_violation": 0.01939260885473838,
            "ave_precision_score": 0.831187004710464,
            "fpr": 0.16136114160263446,
            "logloss": 0.7361048854423791,
            "mae": 0.27080095376603935,
            "precision": 0.7231638418079096,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 32400,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8453255330696743,
            "auditor_fn_violation": 0.010493692909960857,
            "auditor_fp_violation": 0.01256353500573865,
            "ave_precision_score": 0.8465634685117465,
            "fpr": 0.12719298245614036,
            "logloss": 0.6712797328113299,
            "mae": 0.26810078184920416,
            "precision": 0.7622950819672131,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.841753829564833,
            "auditor_fn_violation": 0.010084779410047411,
            "auditor_fp_violation": 0.019118807420516696,
            "ave_precision_score": 0.8419497501454016,
            "fpr": 0.12623490669593854,
            "logloss": 0.721309590112379,
            "mae": 0.28231475240057574,
            "precision": 0.7494553376906318,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.85814756646128,
            "auditor_fn_violation": 0.003405013049151808,
            "auditor_fp_violation": 0.009089604853254636,
            "ave_precision_score": 0.8583569848615885,
            "fpr": 0.08333333333333333,
            "logloss": 0.5302178156570431,
            "mae": 0.31812637363531904,
            "precision": 0.8203309692671394,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8491032371749918,
            "auditor_fn_violation": 0.005745381507345216,
            "auditor_fp_violation": 0.01104664331887164,
            "ave_precision_score": 0.849305128494219,
            "fpr": 0.07793633369923161,
            "logloss": 0.5298766519143238,
            "mae": 0.32055258214226195,
            "precision": 0.8160621761658031,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.730412919270985,
            "auditor_fn_violation": 0.009986225895316805,
            "auditor_fp_violation": 0.03235930070503364,
            "ave_precision_score": 0.7307860446192778,
            "fpr": 0.36293859649122806,
            "logloss": 1.200905966403477,
            "mae": 0.378481876454609,
            "precision": 0.5772669220945083,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6690347966280145,
            "auditor_fn_violation": 0.008886657168881519,
            "auditor_fp_violation": 0.03541746006854993,
            "ave_precision_score": 0.670496792533139,
            "fpr": 0.37102085620197583,
            "logloss": 1.270329920043757,
            "mae": 0.39690662368205465,
            "precision": 0.564993564993565,
            "recall": 0.9340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8647925471182688,
            "auditor_fn_violation": 0.007167971581847184,
            "auditor_fp_violation": 0.008256988850631256,
            "ave_precision_score": 0.8650082798821803,
            "fpr": 0.06907894736842106,
            "logloss": 0.592842610186975,
            "mae": 0.31000152264244124,
            "precision": 0.8485576923076923,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8593904319894525,
            "auditor_fn_violation": 0.01745334796926455,
            "auditor_fp_violation": 0.004813927034406887,
            "ave_precision_score": 0.8595731060845095,
            "fpr": 0.07464324917672886,
            "logloss": 0.5401147222866798,
            "mae": 0.3156182434038407,
            "precision": 0.8287153652392947,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 32400,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.842224553384155,
            "auditor_fn_violation": 0.00906644193127447,
            "auditor_fp_violation": 0.012084460567306119,
            "ave_precision_score": 0.8435882711964341,
            "fpr": 0.11951754385964912,
            "logloss": 0.5233469614009014,
            "mae": 0.27919231440089215,
            "precision": 0.7780040733197556,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8461039283488967,
            "auditor_fn_violation": 0.00827241516220194,
            "auditor_fp_violation": 0.019479727492899838,
            "ave_precision_score": 0.8463153672566299,
            "fpr": 0.12294182217343579,
            "logloss": 0.5462510869987355,
            "mae": 0.28934431216494816,
            "precision": 0.7586206896551724,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8268072726428761,
            "auditor_fn_violation": 0.004716724662896916,
            "auditor_fp_violation": 0.0073987538940809994,
            "ave_precision_score": 0.8273004398050772,
            "fpr": 0.11842105263157894,
            "logloss": 0.7453336410205973,
            "mae": 0.27000743753973133,
            "precision": 0.7726315789473684,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8251434131129254,
            "auditor_fn_violation": 0.009951654716584539,
            "auditor_fp_violation": 0.019967591866603948,
            "ave_precision_score": 0.8253935637310529,
            "fpr": 0.12294182217343579,
            "logloss": 0.7881106603441506,
            "mae": 0.2813387303804571,
            "precision": 0.7538461538461538,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8313809017657917,
            "auditor_fn_violation": 0.008173843700159491,
            "auditor_fp_violation": 0.011461919986883097,
            "ave_precision_score": 0.8318834582517598,
            "fpr": 0.12609649122807018,
            "logloss": 0.672854695325476,
            "mae": 0.275183659561043,
            "precision": 0.7648261758691206,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8321247805758158,
            "auditor_fn_violation": 0.00761846929957727,
            "auditor_fp_violation": 0.021625335095618932,
            "ave_precision_score": 0.8323674173812212,
            "fpr": 0.1251372118551043,
            "logloss": 0.6959176826863575,
            "mae": 0.2794140435255072,
            "precision": 0.7532467532467533,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8236897253603966,
            "auditor_fn_violation": 0.0052105988110772794,
            "auditor_fp_violation": 0.009632726676504357,
            "ave_precision_score": 0.8241434250608302,
            "fpr": 0.12280701754385964,
            "logloss": 0.7922243586771275,
            "mae": 0.27340089481743945,
            "precision": 0.7661795407098121,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8249716708289171,
            "auditor_fn_violation": 0.006660905715019735,
            "auditor_fp_violation": 0.021714942837727853,
            "ave_precision_score": 0.8252392819505328,
            "fpr": 0.13172338090010977,
            "logloss": 0.768103587111316,
            "mae": 0.2823851178995098,
            "precision": 0.7424892703862661,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8249938551311722,
            "auditor_fn_violation": 0.00455814122082065,
            "auditor_fp_violation": 0.010831693720282025,
            "ave_precision_score": 0.8254164317819401,
            "fpr": 0.12719298245614036,
            "logloss": 0.7424477044202121,
            "mae": 0.2694596578962407,
            "precision": 0.7637474541751528,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8218738926184267,
            "auditor_fn_violation": 0.003797557045098914,
            "auditor_fp_violation": 0.019243262617890194,
            "ave_precision_score": 0.8221560151973186,
            "fpr": 0.1350164654226125,
            "logloss": 0.7715575183835056,
            "mae": 0.28030619838730275,
            "precision": 0.7432150313152401,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8118087862567551,
            "auditor_fn_violation": 0.01038948093373931,
            "auditor_fp_violation": 0.009079357271683883,
            "ave_precision_score": 0.8124666047917745,
            "fpr": 0.1118421052631579,
            "logloss": 1.0397842247260423,
            "mae": 0.27430196324104145,
            "precision": 0.7763157894736842,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8093367722846132,
            "auditor_fn_violation": 0.019688441506878117,
            "auditor_fp_violation": 0.017349054513865557,
            "ave_precision_score": 0.8096888815711336,
            "fpr": 0.10976948408342481,
            "logloss": 0.996351572694213,
            "mae": 0.2781956227520862,
            "precision": 0.7674418604651163,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.848146962830839,
            "auditor_fn_violation": 0.022423698709583877,
            "auditor_fp_violation": 0.005846245286112481,
            "ave_precision_score": 0.8482418045399457,
            "fpr": 0.08662280701754387,
            "logloss": 1.5464720051371454,
            "mae": 0.3175940664113023,
            "precision": 0.8105515587529976,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8267328913370686,
            "auditor_fn_violation": 0.027416680290538807,
            "auditor_fp_violation": 0.014603572859806195,
            "ave_precision_score": 0.8266354975669415,
            "fpr": 0.09001097694840834,
            "logloss": 1.7722881697755077,
            "mae": 0.32830655059409836,
            "precision": 0.7913486005089059,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8381836457238665,
            "auditor_fn_violation": 0.0062685769175003635,
            "auditor_fp_violation": 0.012363707165109037,
            "ave_precision_score": 0.8389700371220047,
            "fpr": 0.1162280701754386,
            "logloss": 0.6697425706777704,
            "mae": 0.2678882769372473,
            "precision": 0.7768421052631579,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8367979182786567,
            "auditor_fn_violation": 0.00929770885395988,
            "auditor_fp_violation": 0.02145856513113844,
            "ave_precision_score": 0.8370102821323495,
            "fpr": 0.12623490669593854,
            "logloss": 0.7275883671214128,
            "mae": 0.28113587017105546,
            "precision": 0.7489082969432315,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8409466028821408,
            "auditor_fn_violation": 0.008336958097723649,
            "auditor_fp_violation": 0.0161706837186424,
            "ave_precision_score": 0.8412618088027579,
            "fpr": 0.1337719298245614,
            "logloss": 0.7568306083411254,
            "mae": 0.25640366027767,
            "precision": 0.761252446183953,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8370158498831276,
            "auditor_fn_violation": 0.012583786813648792,
            "auditor_fp_violation": 0.02069938842716011,
            "ave_precision_score": 0.8372294868739385,
            "fpr": 0.13830954994511527,
            "logloss": 0.8336818048350717,
            "mae": 0.2730470114338461,
            "precision": 0.7385892116182573,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8105714890717723,
            "auditor_fn_violation": 0.00782042917210381,
            "auditor_fp_violation": 0.0076575053287424215,
            "ave_precision_score": 0.811257093238772,
            "fpr": 0.13925438596491227,
            "logloss": 0.8001537833265241,
            "mae": 0.27799834120094413,
            "precision": 0.7485148514851485,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8208217033993397,
            "auditor_fn_violation": 0.006726300301282206,
            "auditor_fp_violation": 0.023805790153602607,
            "ave_precision_score": 0.8210869505513263,
            "fpr": 0.1437980241492865,
            "logloss": 0.8102142338574128,
            "mae": 0.2808013324816716,
            "precision": 0.7315573770491803,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 32400,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8404899703143546,
            "auditor_fn_violation": 0.0011961722488038303,
            "auditor_fp_violation": 0.006163920314805707,
            "ave_precision_score": 0.8408835107082351,
            "fpr": 0.12938596491228072,
            "logloss": 0.8692310194553808,
            "mae": 0.2587980041396259,
            "precision": 0.7630522088353414,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8435838003897712,
            "auditor_fn_violation": 0.005558539832309601,
            "auditor_fp_violation": 0.01872801810076391,
            "ave_precision_score": 0.8437994889772784,
            "fpr": 0.12623490669593854,
            "logloss": 0.7857436606803706,
            "mae": 0.2642341358371095,
            "precision": 0.7578947368421053,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8588614727918328,
            "auditor_fn_violation": 0.0024829636073655233,
            "auditor_fp_violation": 0.011344072798819483,
            "ave_precision_score": 0.8590784086408279,
            "fpr": 0.08114035087719298,
            "logloss": 0.5309000438133209,
            "mae": 0.31579277064453815,
            "precision": 0.8233890214797136,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.847028341693043,
            "auditor_fn_violation": 0.0011117079664619252,
            "auditor_fp_violation": 0.006153064958145717,
            "ave_precision_score": 0.847229665524035,
            "fpr": 0.07793633369923161,
            "logloss": 0.5502254000690564,
            "mae": 0.3212681150955005,
            "precision": 0.8141361256544503,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7241573796601315,
            "auditor_fn_violation": 0.005144899956502828,
            "auditor_fp_violation": 0.0024158673553041497,
            "ave_precision_score": 0.7190644557874547,
            "fpr": 0.12171052631578948,
            "logloss": 1.6203982129015662,
            "mae": 0.31726921529106467,
            "precision": 0.75,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7251311006010002,
            "auditor_fn_violation": 0.003769530793843566,
            "auditor_fp_violation": 0.01011074023462294,
            "ave_precision_score": 0.7186465683877749,
            "fpr": 0.132821075740944,
            "logloss": 1.7445732721695313,
            "mae": 0.3278520326054622,
            "precision": 0.7152941176470589,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8243044685213019,
            "auditor_fn_violation": 0.004646494852834571,
            "auditor_fp_violation": 0.012468744876209217,
            "ave_precision_score": 0.8248919522902444,
            "fpr": 0.10197368421052631,
            "logloss": 0.949504984666997,
            "mae": 0.2622271686950961,
            "precision": 0.7886363636363637,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8295201644251635,
            "auditor_fn_violation": 0.011140434873998644,
            "auditor_fp_violation": 0.016022362109864074,
            "ave_precision_score": 0.8297854680217912,
            "fpr": 0.10318331503841932,
            "logloss": 0.9254057247624297,
            "mae": 0.27346371899855454,
            "precision": 0.7767220902612827,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 32400,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8442929578901646,
            "auditor_fn_violation": 0.010162933159344648,
            "auditor_fp_violation": 0.013004181013280866,
            "ave_precision_score": 0.8456539951834734,
            "fpr": 0.11951754385964912,
            "logloss": 0.5152906367154585,
            "mae": 0.278986412421019,
            "precision": 0.7780040733197556,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8483289876332214,
            "auditor_fn_violation": 0.007193404488871251,
            "auditor_fp_violation": 0.018287446702061734,
            "ave_precision_score": 0.8485365995065797,
            "fpr": 0.12403951701427003,
            "logloss": 0.5395456395870323,
            "mae": 0.28957944313872724,
            "precision": 0.7569892473118279,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7882026133179085,
            "auditor_fn_violation": 0.014009714368566044,
            "auditor_fp_violation": 0.015627561895392696,
            "ave_precision_score": 0.7777094648339117,
            "fpr": 0.14035087719298245,
            "logloss": 2.3761298108122473,
            "mae": 0.2881621042631697,
            "precision": 0.7310924369747899,
            "recall": 0.71900826446281
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7839370562766962,
            "auditor_fn_violation": 0.01319569329939043,
            "auditor_fp_violation": 0.020766594233741796,
            "ave_precision_score": 0.7762144223629656,
            "fpr": 0.1350164654226125,
            "logloss": 2.408784071862487,
            "mae": 0.2962280425450746,
            "precision": 0.7266666666666667,
            "recall": 0.6957446808510638
        }
    }
]