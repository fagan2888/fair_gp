[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8235441037981392,
            "auditor_fn_violation": 0.012483483814137861,
            "auditor_fp_violation": 0.01640947125879215,
            "ave_precision_score": 0.8241546112246665,
            "fpr": 0.11951754385964912,
            "logloss": 0.8252888667468269,
            "mae": 0.27067938760524096,
            "precision": 0.7660944206008584,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8332406386883939,
            "auditor_fn_violation": 0.01176101615179552,
            "auditor_fp_violation": 0.026397668344751882,
            "ave_precision_score": 0.8335391593368006,
            "fpr": 0.1437980241492865,
            "logloss": 0.8357192439895543,
            "mae": 0.27378382278087254,
            "precision": 0.7364185110663984,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7937666596960508,
            "auditor_fn_violation": 0.007439165382074446,
            "auditor_fp_violation": 0.005078219742905654,
            "ave_precision_score": 0.7586917835518545,
            "fpr": 0.03289473684210526,
            "logloss": 0.7308934971251729,
            "mae": 0.4016878979215235,
            "precision": 0.8429319371727748,
            "recall": 0.3368200836820084
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7578194922362833,
            "auditor_fn_violation": 0.01800588512023911,
            "auditor_fp_violation": 0.005084724377657494,
            "ave_precision_score": 0.7255410892564639,
            "fpr": 0.03732162458836443,
            "logloss": 0.8140183851681819,
            "mae": 0.42165048124368837,
            "precision": 0.8034682080924855,
            "recall": 0.2920168067226891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8510941119034039,
            "auditor_fn_violation": 0.009579387800044041,
            "auditor_fp_violation": 0.011447469480151998,
            "ave_precision_score": 0.8513879982232752,
            "fpr": 0.10635964912280702,
            "logloss": 0.4944053255434133,
            "mae": 0.3435602538622589,
            "precision": 0.79004329004329,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8649963979394804,
            "auditor_fn_violation": 0.001660378750841721,
            "auditor_fp_violation": 0.008466129174710124,
            "ave_precision_score": 0.8651572862242563,
            "fpr": 0.10428100987925357,
            "logloss": 0.4901573156025707,
            "mae": 0.34462661792970906,
            "precision": 0.7916666666666666,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8412664770562935,
            "auditor_fn_violation": 0.006216508845335097,
            "auditor_fp_violation": 0.009873474007599648,
            "ave_precision_score": 0.8413497443266924,
            "fpr": 0.08881578947368421,
            "logloss": 0.5171006630899745,
            "mae": 0.34876600507516087,
            "precision": 0.8133640552995391,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8461849203960116,
            "auditor_fn_violation": 0.009574850796520585,
            "auditor_fp_violation": 0.0103334721223362,
            "ave_precision_score": 0.8459822610374663,
            "fpr": 0.0867178924259056,
            "logloss": 0.5175284061590764,
            "mae": 0.3565782051774725,
            "precision": 0.8020050125313283,
            "recall": 0.6722689075630253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6592836519542435,
            "auditor_fn_violation": 0.015412812889965509,
            "auditor_fp_violation": 0.007018554450642736,
            "ave_precision_score": 0.6629633345917947,
            "fpr": 0.03508771929824561,
            "logloss": 1.0252749100827154,
            "mae": 0.45403482661206734,
            "precision": 0.8012422360248447,
            "recall": 0.2698744769874477
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6101276364732786,
            "auditor_fn_violation": 0.0012291414919425585,
            "auditor_fp_violation": 0.002558764525530869,
            "ave_precision_score": 0.6243628479888497,
            "fpr": 0.03512623490669594,
            "logloss": 1.1127625614026078,
            "mae": 0.47019733110305767,
            "precision": 0.762962962962963,
            "recall": 0.21638655462184875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8531998820923687,
            "auditor_fn_violation": 0.03204598840196726,
            "auditor_fp_violation": 0.023182957393483715,
            "ave_precision_score": 0.8535517384402449,
            "fpr": 0.13596491228070176,
            "logloss": 0.4928544027243776,
            "mae": 0.318585687583101,
            "precision": 0.7559055118110236,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.845238634964147,
            "auditor_fn_violation": 0.02639079781198978,
            "auditor_fp_violation": 0.02952420606381772,
            "ave_precision_score": 0.8454392383480511,
            "fpr": 0.141602634467618,
            "logloss": 0.5137996492493087,
            "mae": 0.3266160345951818,
            "precision": 0.7485380116959064,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8599482680516242,
            "auditor_fn_violation": 0.010111576011157601,
            "auditor_fp_violation": 0.006836648071792384,
            "ave_precision_score": 0.8575568555534073,
            "fpr": 0.08552631578947369,
            "logloss": 0.47719483131510726,
            "mae": 0.308002350663995,
            "precision": 0.821917808219178,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8499562733359531,
            "auditor_fn_violation": 0.0015496868341189501,
            "auditor_fp_violation": 0.007479465536167153,
            "ave_precision_score": 0.8455707108148767,
            "fpr": 0.09220636663007684,
            "logloss": 0.49469060471078097,
            "mae": 0.3161951529493905,
            "precision": 0.8037383177570093,
            "recall": 0.7226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7597043999816177,
            "auditor_fn_violation": 0.0006239447992365852,
            "auditor_fp_violation": 0.001523465922871701,
            "ave_precision_score": 0.5243897641061305,
            "fpr": 0.4725877192982456,
            "logloss": 16.256727171824277,
            "mae": 0.4760531177907659,
            "precision": 0.5242825607064018,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7614601683482872,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012869525720125643,
            "ave_precision_score": 0.5249178167297086,
            "fpr": 0.47530186608122943,
            "logloss": 16.27427305990954,
            "mae": 0.47511138239493095,
            "precision": 0.5236523652365237,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8266082624608354,
            "auditor_fn_violation": 0.005851776407546065,
            "auditor_fp_violation": 0.01014128062090711,
            "ave_precision_score": 0.8256787655779412,
            "fpr": 0.16776315789473684,
            "logloss": 0.5107299175183221,
            "mae": 0.34426276368846304,
            "precision": 0.7306338028169014,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8294534694048593,
            "auditor_fn_violation": 0.007370236788458525,
            "auditor_fp_violation": 0.012942705376181285,
            "ave_precision_score": 0.8339387853820187,
            "fpr": 0.18331503841931943,
            "logloss": 0.5290641295169918,
            "mae": 0.3471384843787966,
            "precision": 0.7105719237435009,
            "recall": 0.8613445378151261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6965258871368807,
            "auditor_fn_violation": 0.006234860162959701,
            "auditor_fp_violation": 0.007804288948176905,
            "ave_precision_score": 0.6098455326240401,
            "fpr": 0.38048245614035087,
            "logloss": 0.7070596129305308,
            "mae": 0.45078231060158525,
            "precision": 0.5422163588390502,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6978476538882541,
            "auditor_fn_violation": 0.0021308193969135415,
            "auditor_fp_violation": 0.004087966993451692,
            "ave_precision_score": 0.6066536337800692,
            "fpr": 0.38419319429198684,
            "logloss": 0.7061090248038807,
            "mae": 0.45151562734407863,
            "precision": 0.5512820512820513,
            "recall": 0.9033613445378151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7697073961643184,
            "auditor_fn_violation": 0.014323203406004554,
            "auditor_fp_violation": 0.010131174710970976,
            "ave_precision_score": 0.7729651667009103,
            "fpr": 0.08223684210526316,
            "logloss": 0.5852199180353845,
            "mae": 0.3808106148305039,
            "precision": 0.7933884297520661,
            "recall": 0.602510460251046
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.75590153176666,
            "auditor_fn_violation": 0.005571493141713329,
            "auditor_fp_violation": 0.008440894810553011,
            "ave_precision_score": 0.7555963425137249,
            "fpr": 0.08232711306256861,
            "logloss": 0.615111119774442,
            "mae": 0.3923060328880597,
            "precision": 0.7787610619469026,
            "recall": 0.5546218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.464733568883792,
            "auditor_fn_violation": 0.005064963664391111,
            "auditor_fp_violation": 0.02589134125636672,
            "ave_precision_score": 0.6039907345982971,
            "fpr": 0.23026315789473684,
            "logloss": 0.6884617133997852,
            "mae": 0.4647611213537554,
            "precision": 0.5816733067729084,
            "recall": 0.6108786610878661
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.453223486067493,
            "auditor_fn_violation": 0.017014270032930844,
            "auditor_fp_violation": 0.029872440289185818,
            "ave_precision_score": 0.5874254973821212,
            "fpr": 0.2349066959385291,
            "logloss": 0.7106469723699802,
            "mae": 0.47268555235653364,
            "precision": 0.5641547861507128,
            "recall": 0.5819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8061276901249275,
            "auditor_fn_violation": 0.00669364310357484,
            "auditor_fp_violation": 0.01663938070983912,
            "ave_precision_score": 0.8075867795395827,
            "fpr": 0.20065789473684212,
            "logloss": 0.9223611094901837,
            "mae": 0.2937665627760476,
            "precision": 0.6898305084745763,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.821499641913637,
            "auditor_fn_violation": 0.012252211532252859,
            "auditor_fp_violation": 0.021219576819713086,
            "ave_precision_score": 0.8217440928544286,
            "fpr": 0.2239297475301866,
            "logloss": 0.9885460257555594,
            "mae": 0.3037277331434737,
            "precision": 0.6693679092382496,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8099658776157751,
            "auditor_fn_violation": 0.016162922997871247,
            "auditor_fp_violation": 0.012773870159269146,
            "ave_precision_score": 0.8043951435905088,
            "fpr": 0.1118421052631579,
            "logloss": 0.571954155439529,
            "mae": 0.34624986681196707,
            "precision": 0.7524271844660194,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.808304142335914,
            "auditor_fn_violation": 0.010229777970463708,
            "auditor_fp_violation": 0.02525959852126626,
            "ave_precision_score": 0.8009945633839884,
            "fpr": 0.1141602634467618,
            "logloss": 0.558056638828431,
            "mae": 0.3406120159281939,
            "precision": 0.7581395348837209,
            "recall": 0.6848739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7393256302181352,
            "auditor_fn_violation": 0.0016217976950745076,
            "auditor_fp_violation": 0.016869290160886084,
            "ave_precision_score": 0.7460512469542252,
            "fpr": 0.10416666666666667,
            "logloss": 0.5852812493512365,
            "mae": 0.3696656071074438,
            "precision": 0.7916666666666666,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8101240520684927,
            "auditor_fn_violation": 0.0043907793633369925,
            "auditor_fp_violation": 0.015579696430599194,
            "ave_precision_score": 0.7616044523285287,
            "fpr": 0.10318331503841932,
            "logloss": 0.5904216032952391,
            "mae": 0.3697382894096207,
            "precision": 0.7882882882882883,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7766226015364573,
            "auditor_fn_violation": 0.009047199588930483,
            "auditor_fp_violation": 0.013049256205028708,
            "ave_precision_score": 0.7781594881018179,
            "fpr": 0.13486842105263158,
            "logloss": 0.5732376615024979,
            "mae": 0.3717788368577889,
            "precision": 0.7442827442827443,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7985832189934847,
            "auditor_fn_violation": 0.01859393592782887,
            "auditor_fp_violation": 0.014345736023316551,
            "ave_precision_score": 0.7913497416251597,
            "fpr": 0.12843029637760703,
            "logloss": 0.565885370596683,
            "mae": 0.36715355272579664,
            "precision": 0.7521186440677966,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7643984361462438,
            "auditor_fn_violation": 0.00818468766057403,
            "auditor_fp_violation": 0.027589134125636676,
            "ave_precision_score": 0.6707936963972744,
            "fpr": 0.23026315789473684,
            "logloss": 2.3004427841771777,
            "mae": 0.4073705733421016,
            "precision": 0.6601941747572816,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.772220720545779,
            "auditor_fn_violation": 0.008490992445276685,
            "auditor_fp_violation": 0.023124771313574835,
            "ave_precision_score": 0.6743805036123736,
            "fpr": 0.25466520307354557,
            "logloss": 1.9953903880015418,
            "mae": 0.41609876985105826,
            "precision": 0.6363636363636364,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7116474587962871,
            "auditor_fn_violation": 0.03636313587315569,
            "auditor_fp_violation": 0.02011328725038403,
            "ave_precision_score": 0.7069971172219858,
            "fpr": 0.15679824561403508,
            "logloss": 0.6255835071699035,
            "mae": 0.4193871188010171,
            "precision": 0.6963906581740976,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7130385598460168,
            "auditor_fn_violation": 0.031916169321735285,
            "auditor_fp_violation": 0.03676646857690804,
            "ave_precision_score": 0.7114008213961162,
            "fpr": 0.1690450054884742,
            "logloss": 0.6133715243060726,
            "mae": 0.41796233428133045,
            "precision": 0.6895161290322581,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.5883787349709707,
            "auditor_fn_violation": 0.01748651178154591,
            "auditor_fp_violation": 0.018463497453310697,
            "ave_precision_score": 0.5894983752046079,
            "fpr": 0.16776315789473684,
            "logloss": 0.6954577311803944,
            "mae": 0.4840867368569761,
            "precision": 0.6212871287128713,
            "recall": 0.5251046025104602
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.590968736198884,
            "auditor_fn_violation": 0.019013642778736087,
            "auditor_fp_violation": 0.015531751138700683,
            "ave_precision_score": 0.5930185465612361,
            "fpr": 0.16245883644346873,
            "logloss": 0.6929601235997566,
            "mae": 0.4826094236656601,
            "precision": 0.6327543424317618,
            "recall": 0.5357142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.627902141537745,
            "auditor_fn_violation": 0.0886093371504074,
            "auditor_fp_violation": 0.09938151831190882,
            "ave_precision_score": 0.6291446714534824,
            "fpr": 0.2894736842105263,
            "logloss": 1.3467590055044216,
            "mae": 0.4252563184459443,
            "precision": 0.5782747603833865,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6183895173774474,
            "auditor_fn_violation": 0.08938602883524431,
            "auditor_fp_violation": 0.10035958968923882,
            "ave_precision_score": 0.6196255750968515,
            "fpr": 0.27661909989023054,
            "logloss": 1.3308905939984235,
            "mae": 0.4239188114603193,
            "precision": 0.5834710743801653,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7662716855318449,
            "auditor_fn_violation": 0.003200011010790576,
            "auditor_fp_violation": 0.03160118037028054,
            "ave_precision_score": 0.7717971254615235,
            "fpr": 0.14144736842105263,
            "logloss": 0.5651490659219015,
            "mae": 0.3789700187840744,
            "precision": 0.742,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7889648498328502,
            "auditor_fn_violation": 0.003569814314309693,
            "auditor_fp_violation": 0.013316173965706498,
            "ave_precision_score": 0.786638024323318,
            "fpr": 0.141602634467618,
            "logloss": 0.5737215665381525,
            "mae": 0.3847086061237934,
            "precision": 0.734020618556701,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8460177114880433,
            "auditor_fn_violation": 0.014199332012038464,
            "auditor_fp_violation": 0.009347966690920858,
            "ave_precision_score": 0.8405236615881516,
            "fpr": 0.11074561403508772,
            "logloss": 0.501771369371918,
            "mae": 0.3104594269269064,
            "precision": 0.7841880341880342,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.844390937830732,
            "auditor_fn_violation": 0.012462064957706463,
            "auditor_fp_violation": 0.019660093114803746,
            "ave_precision_score": 0.8374104113190046,
            "fpr": 0.11855104281009879,
            "logloss": 0.5014608680493416,
            "mae": 0.30890674106817606,
            "precision": 0.7745302713987474,
            "recall": 0.7794117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 30132,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7589577502077964,
            "auditor_fn_violation": 0.003229831901930559,
            "auditor_fp_violation": 0.007533955857385396,
            "ave_precision_score": 0.7595514538238064,
            "fpr": 0.33771929824561403,
            "logloss": 0.9493940844075297,
            "mae": 0.38384479825515627,
            "precision": 0.5936675461741425,
            "recall": 0.9414225941422594
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7585721551254978,
            "auditor_fn_violation": 0.006092667582949757,
            "auditor_fp_violation": 0.015839610381417433,
            "ave_precision_score": 0.7591060427777817,
            "fpr": 0.3468715697036224,
            "logloss": 0.9811281633908979,
            "mae": 0.39125105917748193,
            "precision": 0.5858453473132372,
            "recall": 0.9390756302521008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6790631127167849,
            "auditor_fn_violation": 0.019186302576524997,
            "auditor_fp_violation": 0.016495371493249252,
            "ave_precision_score": 0.6550519689552281,
            "fpr": 0.08662280701754387,
            "logloss": 1.541403180990403,
            "mae": 0.4509548435823187,
            "precision": 0.7030075187969925,
            "recall": 0.3912133891213389
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6780353510707178,
            "auditor_fn_violation": 0.0015473807525205677,
            "auditor_fp_violation": 0.009626909925937142,
            "ave_precision_score": 0.6571359989686899,
            "fpr": 0.08122941822173436,
            "logloss": 1.6280533253845446,
            "mae": 0.45450909931546063,
            "precision": 0.7004048582995951,
            "recall": 0.3634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 30132,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.705234861883475,
            "auditor_fn_violation": 0.011407637818395362,
            "auditor_fp_violation": 0.021363893604980196,
            "ave_precision_score": 0.6481774078399398,
            "fpr": 0.24890350877192982,
            "logloss": 0.6213635084234513,
            "mae": 0.43849705261782856,
            "precision": 0.6396825396825396,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7242874027016362,
            "auditor_fn_violation": 0.010395815845547881,
            "auditor_fp_violation": 0.03144958804900514,
            "ave_precision_score": 0.6529798009233401,
            "fpr": 0.24807903402854006,
            "logloss": 0.6240446598187404,
            "mae": 0.43779228967087985,
            "precision": 0.6384,
            "recall": 0.8382352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8269620250148089,
            "auditor_fn_violation": 0.003186247522572126,
            "auditor_fp_violation": 0.014603039857708791,
            "ave_precision_score": 0.8283793999595106,
            "fpr": 0.09539473684210527,
            "logloss": 0.5833563013950668,
            "mae": 0.3225378039320233,
            "precision": 0.8040540540540541,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8486031521760671,
            "auditor_fn_violation": 0.002663524246141933,
            "auditor_fp_violation": 0.009525972469308705,
            "ave_precision_score": 0.8490522888566898,
            "fpr": 0.08781558726673985,
            "logloss": 0.5437668963035777,
            "mae": 0.32911509847400106,
            "precision": 0.8090692124105012,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7109261765293708,
            "auditor_fn_violation": 0.10320781032078102,
            "auditor_fp_violation": 0.09398496240601503,
            "ave_precision_score": 0.5558305841342077,
            "fpr": 0.2719298245614035,
            "logloss": 0.6847796493230097,
            "mae": 0.49048428678591,
            "precision": 0.5701906412478336,
            "recall": 0.6882845188284519
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7058355187092192,
            "auditor_fn_violation": 0.1085518729994742,
            "auditor_fp_violation": 0.09569880262942075,
            "ave_precision_score": 0.5549142806616817,
            "fpr": 0.26125137211855104,
            "logloss": 0.6848515232348866,
            "mae": 0.49058126533070723,
            "precision": 0.5711711711711712,
            "recall": 0.6659663865546218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8414726968822416,
            "auditor_fn_violation": 0.010056522058283788,
            "auditor_fp_violation": 0.019448823672083438,
            "ave_precision_score": 0.841887971062113,
            "fpr": 0.11842105263157894,
            "logloss": 0.6077291515717298,
            "mae": 0.3153887854632717,
            "precision": 0.7759336099585062,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8447881206058203,
            "auditor_fn_violation": 0.01481888035126235,
            "auditor_fp_violation": 0.022451013790580013,
            "ave_precision_score": 0.8450344365645259,
            "fpr": 0.10757409440175632,
            "logloss": 0.7667667749588706,
            "mae": 0.3275784913432078,
            "precision": 0.78125,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6222944788119149,
            "auditor_fn_violation": 0.0018580709094913018,
            "auditor_fp_violation": 0.0054824561403508856,
            "ave_precision_score": 0.6224042959766218,
            "fpr": 0.4418859649122807,
            "logloss": 0.7380340456244484,
            "mae": 0.4746338002743167,
            "precision": 0.5367816091954023,
            "recall": 0.9769874476987448
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6198454362457326,
            "auditor_fn_violation": 0.004586796299200251,
            "auditor_fp_violation": 0.004865185409490644,
            "ave_precision_score": 0.6201055180315664,
            "fpr": 0.4489571899012075,
            "logloss": 0.815899793568979,
            "mae": 0.48213513986776263,
            "precision": 0.5288018433179723,
            "recall": 0.9642857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8448906354449807,
            "auditor_fn_violation": 0.011359465609630769,
            "auditor_fp_violation": 0.013236215538847119,
            "ave_precision_score": 0.8453255180331836,
            "fpr": 0.10416666666666667,
            "logloss": 0.4941712602579312,
            "mae": 0.32658298601388214,
            "precision": 0.7916666666666666,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8583840033018555,
            "auditor_fn_violation": 0.005903568891881677,
            "auditor_fp_violation": 0.018693616967586462,
            "ave_precision_score": 0.8585982086678476,
            "fpr": 0.09110867178924259,
            "logloss": 0.4951944431202883,
            "mae": 0.3310512841314192,
            "precision": 0.8074245939675174,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.7696050357315628,
            "auditor_fn_violation": 0.007127192982456137,
            "auditor_fp_violation": 0.008205998868138088,
            "ave_precision_score": 0.7877584474958301,
            "fpr": 0.07456140350877193,
            "logloss": 0.5230619189873479,
            "mae": 0.33313218976387327,
            "precision": 0.8329238329238329,
            "recall": 0.7092050209205021
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8364126288177985,
            "auditor_fn_violation": 0.00451300168805173,
            "auditor_fp_violation": 0.013992454925117024,
            "ave_precision_score": 0.7818260821907668,
            "fpr": 0.07025246981339188,
            "logloss": 0.5565914660204055,
            "mae": 0.3474108986720099,
            "precision": 0.8284182305630027,
            "recall": 0.6491596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8366960761146455,
            "auditor_fn_violation": 0.003709260074873377,
            "auditor_fp_violation": 0.0331296992481203,
            "ave_precision_score": 0.8369580686695693,
            "fpr": 0.3059210526315789,
            "logloss": 1.1875466490385385,
            "mae": 0.3580085615639722,
            "precision": 0.6167582417582418,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.8341381640064246,
            "auditor_fn_violation": 0.009761643405990277,
            "auditor_fp_violation": 0.03457360233165527,
            "ave_precision_score": 0.8344647423267044,
            "fpr": 0.3172338090010977,
            "logloss": 1.1812662393060454,
            "mae": 0.37018017648293333,
            "precision": 0.6019283746556474,
            "recall": 0.9180672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6905122165369406,
            "auditor_fn_violation": 0.03144039492035528,
            "auditor_fp_violation": 0.012783976069205269,
            "ave_precision_score": 0.6753084936938667,
            "fpr": 0.14802631578947367,
            "logloss": 0.6283256601145777,
            "mae": 0.4474485301036845,
            "precision": 0.7084233261339092,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6838101167469989,
            "auditor_fn_violation": 0.023277587654161557,
            "auditor_fp_violation": 0.02520912979295204,
            "ave_precision_score": 0.672822513070968,
            "fpr": 0.13172338090010977,
            "logloss": 0.6272289933450061,
            "mae": 0.44432704903095405,
            "precision": 0.7285067873303167,
            "recall": 0.6764705882352942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7483107751783609,
            "auditor_fn_violation": 0.0006010056522058283,
            "auditor_fp_violation": 0.0036431805319750914,
            "ave_precision_score": 0.6790878802019713,
            "fpr": 0.4649122807017544,
            "logloss": 0.6715828173465572,
            "mae": 0.4211706309007448,
            "precision": 0.5294117647058824,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7319627916365989,
            "auditor_fn_violation": 0.0003205453421763876,
            "auditor_fp_violation": 0.003020553389605967,
            "ave_precision_score": 0.664931910466235,
            "fpr": 0.4544456641053787,
            "logloss": 0.7070779636929241,
            "mae": 0.42362353169695605,
            "precision": 0.5332581736189402,
            "recall": 0.9936974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8088627278222398,
            "auditor_fn_violation": 0.005225537693606403,
            "auditor_fp_violation": 0.020322984881558735,
            "ave_precision_score": 0.8091722898865996,
            "fpr": 0.17763157894736842,
            "logloss": 0.9500359096236796,
            "mae": 0.28316597462863674,
            "precision": 0.7011070110701108,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8153673075666024,
            "auditor_fn_violation": 0.011170659262607355,
            "auditor_fp_violation": 0.026483465182886065,
            "ave_precision_score": 0.815691610124744,
            "fpr": 0.18551042810098792,
            "logloss": 0.9919254291377904,
            "mae": 0.28810434361403,
            "precision": 0.7008849557522124,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6602040292129425,
            "auditor_fn_violation": 0.12772975849666007,
            "auditor_fp_violation": 0.11312302934756245,
            "ave_precision_score": 0.5311752339088248,
            "fpr": 0.25109649122807015,
            "logloss": 0.6910553861522408,
            "mae": 0.49800225634846773,
            "precision": 0.5336048879837068,
            "recall": 0.5481171548117155
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6724589875453871,
            "auditor_fn_violation": 0.12300639245819074,
            "auditor_fp_violation": 0.11641621560240735,
            "ave_precision_score": 0.5337937722052974,
            "fpr": 0.2601536772777168,
            "logloss": 0.691594590145655,
            "mae": 0.498258461216802,
            "precision": 0.5415860735009671,
            "recall": 0.5882352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6656851876899698,
            "auditor_fn_violation": 0.01748880569624899,
            "auditor_fp_violation": 0.014643463497453314,
            "ave_precision_score": 0.6408148167441242,
            "fpr": 0.3618421052631579,
            "logloss": 0.6668579280883165,
            "mae": 0.46708154812324465,
            "precision": 0.5623342175066313,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6810915773295635,
            "auditor_fn_violation": 0.00976856165078545,
            "auditor_fp_violation": 0.014211993893283868,
            "ave_precision_score": 0.6541383533448383,
            "fpr": 0.3633369923161361,
            "logloss": 0.655771627660353,
            "mae": 0.46113900819018433,
            "precision": 0.5627476882430648,
            "recall": 0.8949579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.6308879518985296,
            "auditor_fn_violation": 0.0017020847096821687,
            "auditor_fp_violation": 0.0020717115369067833,
            "ave_precision_score": 0.6475724060238167,
            "fpr": 0.005482456140350877,
            "logloss": 0.7667812742810792,
            "mae": 0.4392237207819626,
            "precision": 0.5,
            "recall": 0.010460251046025104
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.6481042009893984,
            "auditor_fn_violation": 0.001178407696777949,
            "auditor_fp_violation": 0.0009084371096559296,
            "ave_precision_score": 0.6524613027893438,
            "fpr": 0.005488474204171241,
            "logloss": 0.7491876966881218,
            "mae": 0.43840014497809826,
            "precision": 0.5833333333333334,
            "recall": 0.014705882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7942255249192379,
            "auditor_fn_violation": 0.01739934302282903,
            "auditor_fp_violation": 0.00969662058371736,
            "ave_precision_score": 0.7477336102301928,
            "fpr": 0.05701754385964912,
            "logloss": 1.1547222645460362,
            "mae": 0.38852996009875806,
            "precision": 0.838006230529595,
            "recall": 0.5627615062761506
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7617634600782079,
            "auditor_fn_violation": 0.002391406617531755,
            "auditor_fp_violation": 0.014807524887391654,
            "ave_precision_score": 0.7057276996416534,
            "fpr": 0.06147091108671789,
            "logloss": 1.3478931266469525,
            "mae": 0.40204633410885093,
            "precision": 0.819935691318328,
            "recall": 0.5357142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.5984560056936352,
            "auditor_fn_violation": 0.008707700212875284,
            "auditor_fp_violation": 0.010636470207777514,
            "ave_precision_score": 0.5791524861193207,
            "fpr": 0.37280701754385964,
            "logloss": 2.4559192920719086,
            "mae": 0.44210346572901726,
            "precision": 0.5685279187817259,
            "recall": 0.9372384937238494
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.5919028594658368,
            "auditor_fn_violation": 0.002656606001346753,
            "auditor_fp_violation": 0.013611416026344683,
            "ave_precision_score": 0.5737795452304191,
            "fpr": 0.38199780461031835,
            "logloss": 2.6881035542136114,
            "mae": 0.4380549113301951,
            "precision": 0.5677018633540373,
            "recall": 0.9600840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.725813805292369,
            "auditor_fn_violation": 0.01719977244366146,
            "auditor_fp_violation": 0.0020792909693588824,
            "ave_precision_score": 0.7394440432604453,
            "fpr": 0.0712719298245614,
            "logloss": 0.6204905530534738,
            "mae": 0.39544416136484134,
            "precision": 0.7962382445141066,
            "recall": 0.5313807531380753
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7368729462448336,
            "auditor_fn_violation": 0.007213423239767916,
            "auditor_fp_violation": 0.005927552140504943,
            "ave_precision_score": 0.7483856177049926,
            "fpr": 0.06366630076838639,
            "logloss": 0.6137516316658989,
            "mae": 0.38784572839916864,
            "precision": 0.8242424242424242,
            "recall": 0.5714285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8278344653223104,
            "auditor_fn_violation": 0.0010735520810394208,
            "auditor_fp_violation": 0.0001490621715579366,
            "ave_precision_score": 0.8201218534535203,
            "fpr": 0.15021929824561403,
            "logloss": 0.5283585929274099,
            "mae": 0.3369345415318221,
            "precision": 0.7410207939508506,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8557595984234247,
            "auditor_fn_violation": 0.0068767353264027895,
            "auditor_fp_violation": 0.011961088610469734,
            "ave_precision_score": 0.849874176252926,
            "fpr": 0.13172338090010977,
            "logloss": 0.4947603184367628,
            "mae": 0.32468519834177945,
            "precision": 0.7623762376237624,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 30132,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.86646892773425,
            "auditor_fn_violation": 0.017440633487484404,
            "auditor_fp_violation": 0.008233790120462447,
            "ave_precision_score": 0.8635315576344504,
            "fpr": 0.0800438596491228,
            "logloss": 0.48828412447018466,
            "mae": 0.3192360703384079,
            "precision": 0.8325688073394495,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8591492048789531,
            "auditor_fn_violation": 0.016670663874770553,
            "auditor_fp_violation": 0.021514818880351266,
            "ave_precision_score": 0.8564974804901938,
            "fpr": 0.09549945115257959,
            "logloss": 0.49461322218447046,
            "mae": 0.323209000086876,
            "precision": 0.7986111111111112,
            "recall": 0.7247899159663865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8096718930645485,
            "auditor_fn_violation": 0.007074432944285403,
            "auditor_fp_violation": 0.020964710162503036,
            "ave_precision_score": 0.7690107746440146,
            "fpr": 0.18311403508771928,
            "logloss": 2.34827815211286,
            "mae": 0.29607372014097083,
            "precision": 0.7155025553662692,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7885678012583266,
            "auditor_fn_violation": 0.006962060345543267,
            "auditor_fp_violation": 0.021499678261856992,
            "ave_precision_score": 0.7303950831656512,
            "fpr": 0.19758507135016465,
            "logloss": 3.28357595266076,
            "mae": 0.3049958924201658,
            "precision": 0.6984924623115578,
            "recall": 0.8760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5833335383247307,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5074767663983398,
            "fpr": 0.4758771929824561,
            "logloss": 0.6923334902568112,
            "mae": 0.4994645004993991,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5823055103821255,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5090531085564604,
            "fpr": 0.4774972557628979,
            "logloss": 0.6923814319144657,
            "mae": 0.49948892425888847,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.8471277597342478,
            "auditor_fn_violation": 0.0016722638185421715,
            "auditor_fp_violation": 0.0015057805804834826,
            "ave_precision_score": 0.8479412680732378,
            "fpr": 0.46381578947368424,
            "logloss": 3.4411800835237516,
            "mae": 0.46586047439562034,
            "precision": 0.5289532293986637,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.855996454514248,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0024149286498353576,
            "ave_precision_score": 0.8561406199174072,
            "fpr": 0.47091108671789245,
            "logloss": 3.570272757440682,
            "mae": 0.4707892886308021,
            "precision": 0.5259668508287293,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.723713984912842,
            "auditor_fn_violation": 0.014203919841444616,
            "auditor_fp_violation": 0.012003294526639174,
            "ave_precision_score": 0.7248938069333895,
            "fpr": 0.35635964912280704,
            "logloss": 2.018624256344232,
            "mae": 0.4107783730838845,
            "precision": 0.5560109289617486,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7346757640248542,
            "auditor_fn_violation": 0.014984918226346523,
            "auditor_fp_violation": 0.011443784145249011,
            "ave_precision_score": 0.7364051271998309,
            "fpr": 0.3402854006586169,
            "logloss": 1.8640608210755263,
            "mae": 0.3989805139240336,
            "precision": 0.5646067415730337,
            "recall": 0.8445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7101859424659319,
            "auditor_fn_violation": 0.037482566248256625,
            "auditor_fp_violation": 0.02829654782116581,
            "ave_precision_score": 0.5749026060351172,
            "fpr": 0.2149122807017544,
            "logloss": 0.6785423746902637,
            "mae": 0.48677986912560045,
            "precision": 0.6,
            "recall": 0.6150627615062761
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.71087654974778,
            "auditor_fn_violation": 0.03476648617734691,
            "auditor_fp_violation": 0.0267231916423786,
            "ave_precision_score": 0.5654514951562317,
            "fpr": 0.24368825466520308,
            "logloss": 0.6811523268010468,
            "mae": 0.48889714754242797,
            "precision": 0.5842696629213483,
            "recall": 0.6554621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6117273527866083,
            "auditor_fn_violation": 0.0025003670263524925,
            "auditor_fp_violation": 0.004562818336162996,
            "ave_precision_score": 0.6133983492635049,
            "fpr": 0.4605263157894737,
            "logloss": 1.5740433674722203,
            "mae": 0.46020691964383187,
            "precision": 0.5296752519596865,
            "recall": 0.9895397489539749
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6475738715564323,
            "auditor_fn_violation": 0.0016096449556771118,
            "auditor_fp_violation": 0.005046872831421834,
            "ave_precision_score": 0.6492281441564273,
            "fpr": 0.4621295279912184,
            "logloss": 1.5536137563879253,
            "mae": 0.45936674624681473,
            "precision": 0.5274971941638609,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8130346529978086,
            "auditor_fn_violation": 0.0002982089113998518,
            "auditor_fp_violation": 0.007736074056108015,
            "ave_precision_score": 0.806946486333462,
            "fpr": 0.10087719298245613,
            "logloss": 0.5059157698144852,
            "mae": 0.33716166532484065,
            "precision": 0.7927927927927928,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8067319134085611,
            "auditor_fn_violation": 0.001231447573540946,
            "auditor_fp_violation": 0.010484878307278851,
            "ave_precision_score": 0.8016004866991676,
            "fpr": 0.09440175631174534,
            "logloss": 0.5262774722161028,
            "mae": 0.34464345205039537,
            "precision": 0.7947494033412887,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7533528238795121,
            "auditor_fn_violation": 0.029224473317184183,
            "auditor_fp_violation": 0.021586223623575068,
            "ave_precision_score": 0.7096071788300099,
            "fpr": 0.15789473684210525,
            "logloss": 5.091590459230883,
            "mae": 0.3304583777704951,
            "precision": 0.7024793388429752,
            "recall": 0.7112970711297071
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.775465411072814,
            "auditor_fn_violation": 0.020431882961746722,
            "auditor_fp_violation": 0.03440705552821832,
            "ave_precision_score": 0.7225005812770247,
            "fpr": 0.16794731064763996,
            "logloss": 5.311373984137903,
            "mae": 0.3170758503382623,
            "precision": 0.7023346303501945,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7864208016117338,
            "auditor_fn_violation": 0.01600464288335903,
            "auditor_fp_violation": 0.010553096450804433,
            "ave_precision_score": 0.7460228986121382,
            "fpr": 0.09320175438596491,
            "logloss": 4.260765315146385,
            "mae": 0.3141285769695158,
            "precision": 0.7638888888888888,
            "recall": 0.5753138075313807
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7801191014329966,
            "auditor_fn_violation": 0.015254729773358303,
            "auditor_fp_violation": 0.018638101366440823,
            "ave_precision_score": 0.7286751418049401,
            "fpr": 0.1251372118551043,
            "logloss": 4.719478886513255,
            "mae": 0.31405213562122675,
            "precision": 0.7253012048192771,
            "recall": 0.6323529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5284245183963108,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5317812794213385,
            "fpr": 0.4758771929824561,
            "logloss": 0.7614467264044749,
            "mae": 0.49192968507607776,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.48450663719806586,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.48747110242718816,
            "fpr": 0.4774972557628979,
            "logloss": 0.7762274525893725,
            "mae": 0.49911079330842134,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 30132,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.4928135100467241,
            "auditor_fn_violation": 0.0004931916611612871,
            "auditor_fp_violation": 0.0029231344490257905,
            "ave_precision_score": 0.540402239042607,
            "fpr": 0.009868421052631578,
            "logloss": 0.8819751401479682,
            "mae": 0.5114436578332332,
            "precision": 0.1,
            "recall": 0.0020920502092050207
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5172912675806436,
            "auditor_fn_violation": 0.0023752640463430346,
            "auditor_fp_violation": 0.0035630922189838123,
            "ave_precision_score": 0.5306145797625916,
            "fpr": 0.014270032930845226,
            "logloss": 0.8811021763961988,
            "mae": 0.5113890668628768,
            "precision": 0.3157894736842105,
            "recall": 0.012605042016806723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8128927284810545,
            "auditor_fn_violation": 0.0034041694193643157,
            "auditor_fp_violation": 0.01626293556471825,
            "ave_precision_score": 0.8128706449101389,
            "fpr": 0.12828947368421054,
            "logloss": 0.5674421386022928,
            "mae": 0.301699793596319,
            "precision": 0.7683168316831683,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8189398189896867,
            "auditor_fn_violation": 0.002223062660849194,
            "auditor_fp_violation": 0.010156831573236437,
            "ave_precision_score": 0.8193599758310577,
            "fpr": 0.12952799121844127,
            "logloss": 0.5545539810616438,
            "mae": 0.3156538352137176,
            "precision": 0.756198347107438,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8290569666881392,
            "auditor_fn_violation": 0.015057256110988773,
            "auditor_fp_violation": 0.021889400921658985,
            "ave_precision_score": 0.8196525368394154,
            "fpr": 0.1600877192982456,
            "logloss": 0.7482314398463391,
            "mae": 0.3228893915911989,
            "precision": 0.7316176470588235,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8405919700197231,
            "auditor_fn_violation": 0.012090785820365473,
            "auditor_fp_violation": 0.015771477598193227,
            "ave_precision_score": 0.8309539960116288,
            "fpr": 0.16575192096597147,
            "logloss": 0.647180205408503,
            "mae": 0.3147849876520887,
            "precision": 0.7254545454545455,
            "recall": 0.8382352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5638957752716586,
            "auditor_fn_violation": 0.004697937311898998,
            "auditor_fp_violation": 0.006023122321933867,
            "ave_precision_score": 0.5538161565275617,
            "fpr": 0.05921052631578947,
            "logloss": 0.816387107221455,
            "mae": 0.4996613100203767,
            "precision": 0.5537190082644629,
            "recall": 0.1401673640167364
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5456356496275353,
            "auditor_fn_violation": 0.007988266656827378,
            "auditor_fp_violation": 0.007335629660471632,
            "ave_precision_score": 0.5362278018936858,
            "fpr": 0.05598243688254665,
            "logloss": 0.8319319466233875,
            "mae": 0.5051953176079415,
            "precision": 0.5363636363636364,
            "recall": 0.12394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 30132,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6589919805941022,
            "auditor_fn_violation": 0.007597445496586655,
            "auditor_fp_violation": 0.02389542404398092,
            "ave_precision_score": 0.6506030808801284,
            "fpr": 0.22149122807017543,
            "logloss": 1.9270293270978796,
            "mae": 0.34138729126680756,
            "precision": 0.6517241379310345,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6807702540416064,
            "auditor_fn_violation": 0.01622097796308425,
            "auditor_fp_violation": 0.023157575986979085,
            "ave_precision_score": 0.6734015585521951,
            "fpr": 0.23380900109769484,
            "logloss": 1.761400126111087,
            "mae": 0.3378479028535694,
            "precision": 0.6485148514851485,
            "recall": 0.8256302521008403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.5640623640375519,
            "auditor_fn_violation": 0.003518865154518097,
            "auditor_fp_violation": 0.007321731748726656,
            "ave_precision_score": 0.565631849688448,
            "fpr": 0.02631578947368421,
            "logloss": 1.2114829166138419,
            "mae": 0.5164378494692644,
            "precision": 0.29411764705882354,
            "recall": 0.02092050209205021
        },
        "train": {
            "accuracy": 0.4610318331503842,
            "auc_prc": 0.5668732666648617,
            "auditor_fn_violation": 0.0011761016151795474,
            "auditor_fp_violation": 0.005188185270701642,
            "ave_precision_score": 0.5684737385398726,
            "fpr": 0.03512623490669594,
            "logloss": 1.211895074993079,
            "mae": 0.5141094799105458,
            "precision": 0.3469387755102041,
            "recall": 0.03571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5477608505988019,
            "auditor_fn_violation": 0.0027412280701754454,
            "auditor_fp_violation": 0.017516068396798458,
            "ave_precision_score": 0.5499137771459734,
            "fpr": 0.24451754385964913,
            "logloss": 0.6934371182023938,
            "mae": 0.49781171003716035,
            "precision": 0.5173160173160173,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5744803815548094,
            "auditor_fn_violation": 0.00435849422095952,
            "auditor_fp_violation": 0.0016654680343692243,
            "ave_precision_score": 0.5759911209718513,
            "fpr": 0.24698133918770582,
            "logloss": 0.6891486338836651,
            "mae": 0.4956694383718049,
            "precision": 0.506578947368421,
            "recall": 0.4852941176470588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5804341006799737,
            "auditor_fn_violation": 0.007803897819863474,
            "auditor_fp_violation": 0.006957918991025955,
            "ave_precision_score": 0.5813989125359565,
            "fpr": 0.0712719298245614,
            "logloss": 0.8309018868876894,
            "mae": 0.49174536410065595,
            "precision": 0.5911949685534591,
            "recall": 0.19665271966527198
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5477000747842571,
            "auditor_fn_violation": 0.00689518397918992,
            "auditor_fp_violation": 0.011395838853350495,
            "ave_precision_score": 0.5489407094650677,
            "fpr": 0.06476399560922064,
            "logloss": 0.8604579722966939,
            "mae": 0.5015711759909186,
            "precision": 0.5815602836879432,
            "recall": 0.1722689075630252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6289850693373364,
            "auditor_fn_violation": 0.007441459296777507,
            "auditor_fp_violation": 0.04969581211092248,
            "ave_precision_score": 0.61731339142128,
            "fpr": 0.2993421052631579,
            "logloss": 3.5164124452432235,
            "mae": 0.3432785799093974,
            "precision": 0.6171107994389902,
            "recall": 0.9205020920502092
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6086565313064114,
            "auditor_fn_violation": 0.012079255412373514,
            "auditor_fp_violation": 0.02985225279786013,
            "ave_precision_score": 0.597090596897556,
            "fpr": 0.3336992316136114,
            "logloss": 3.9284048159341,
            "mae": 0.3711812531466483,
            "precision": 0.5902964959568733,
            "recall": 0.9201680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8733839550270442,
            "auditor_fn_violation": 0.009308705865081118,
            "auditor_fp_violation": 0.008216104778074216,
            "ave_precision_score": 0.8735771923994755,
            "fpr": 0.11842105263157894,
            "logloss": 0.46587875458732814,
            "mae": 0.2991403826602261,
            "precision": 0.7857142857142857,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8665531610102404,
            "auditor_fn_violation": 0.011530407991956386,
            "auditor_fp_violation": 0.01631653986398678,
            "ave_precision_score": 0.8667912321305953,
            "fpr": 0.11964873765093303,
            "logloss": 0.4747090560358754,
            "mae": 0.306020292756071,
            "precision": 0.7766393442622951,
            "recall": 0.7962184873949579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8445670190348781,
            "auditor_fn_violation": 0.006402315936284235,
            "auditor_fp_violation": 0.012920405853343036,
            "ave_precision_score": 0.8449647825102402,
            "fpr": 0.08552631578947369,
            "logloss": 0.49834863438821425,
            "mae": 0.33260954411602334,
            "precision": 0.8190255220417634,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8574404973688593,
            "auditor_fn_violation": 0.0006641515003366888,
            "auditor_fp_violation": 0.013631603517670364,
            "ave_precision_score": 0.8576034581290481,
            "fpr": 0.08342480790340286,
            "logloss": 0.5033923013172658,
            "mae": 0.33958893031307164,
            "precision": 0.8109452736318408,
            "recall": 0.6848739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8079138494926661,
            "auditor_fn_violation": 0.002750403728987747,
            "auditor_fp_violation": 0.012528801843317977,
            "ave_precision_score": 0.8069370812488371,
            "fpr": 0.09320175438596491,
            "logloss": 0.5180603040920015,
            "mae": 0.3408598075865915,
            "precision": 0.8085585585585585,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8206755100494051,
            "auditor_fn_violation": 0.0008532501914047757,
            "auditor_fp_violation": 0.011802112116279951,
            "ave_precision_score": 0.8179604317475462,
            "fpr": 0.0889132821075741,
            "logloss": 0.5238293573989046,
            "mae": 0.345871949104263,
            "precision": 0.8048192771084337,
            "recall": 0.7016806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8092731176008567,
            "auditor_fn_violation": 0.005854070322249139,
            "auditor_fp_violation": 0.016083555663351935,
            "ave_precision_score": 0.8095965105359421,
            "fpr": 0.17434210526315788,
            "logloss": 0.7214644510810121,
            "mae": 0.2819644265682799,
            "precision": 0.7234782608695652,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7967603359852063,
            "auditor_fn_violation": 0.010312796908005793,
            "auditor_fp_violation": 0.01672533656333195,
            "ave_precision_score": 0.7971282654115417,
            "fpr": 0.1964873765093304,
            "logloss": 0.8010305461576369,
            "mae": 0.3011120358833,
            "precision": 0.6934931506849316,
            "recall": 0.8508403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8206119677154916,
            "auditor_fn_violation": 0.00014910445569992213,
            "auditor_fp_violation": 0.012053824076319832,
            "ave_precision_score": 0.8159029684983161,
            "fpr": 0.10855263157894737,
            "logloss": 0.5162793908825514,
            "mae": 0.33463247420200914,
            "precision": 0.7866379310344828,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8381078004511205,
            "auditor_fn_violation": 0.0034130007656190922,
            "auditor_fp_violation": 0.009425035012680272,
            "ave_precision_score": 0.825484459535825,
            "fpr": 0.10428100987925357,
            "logloss": 0.5218686853561734,
            "mae": 0.33830200930859006,
            "precision": 0.7874720357941835,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8054368459426285,
            "auditor_fn_violation": 0.00410610731850547,
            "auditor_fp_violation": 0.013552025224351205,
            "ave_precision_score": 0.8059951606431093,
            "fpr": 0.18859649122807018,
            "logloss": 0.733683561903601,
            "mae": 0.31401528447882776,
            "precision": 0.7114093959731543,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8188275617110045,
            "auditor_fn_violation": 0.006521598760250534,
            "auditor_fp_violation": 0.017812937658503357,
            "ave_precision_score": 0.8191583497152153,
            "fpr": 0.20417124039517015,
            "logloss": 0.7666079735856642,
            "mae": 0.32066493974559,
            "precision": 0.693069306930693,
            "recall": 0.8823529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7855806137138162,
            "auditor_fn_violation": 0.005624678851941577,
            "auditor_fp_violation": 0.011240298326461314,
            "ave_precision_score": 0.812008040923815,
            "fpr": 0.09320175438596491,
            "logloss": 0.5182983519192713,
            "mae": 0.3301332238244644,
            "precision": 0.8032407407407407,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8070051332037871,
            "auditor_fn_violation": 0.005197907922773946,
            "auditor_fp_violation": 0.008529215085102897,
            "ave_precision_score": 0.8239962479625441,
            "fpr": 0.08122941822173436,
            "logloss": 0.5015980452882275,
            "mae": 0.31911199639472626,
            "precision": 0.8238095238095238,
            "recall": 0.726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8366276505459052,
            "auditor_fn_violation": 0.013795603024297144,
            "auditor_fp_violation": 0.006968024900962081,
            "ave_precision_score": 0.8368988088781477,
            "fpr": 0.0537280701754386,
            "logloss": 0.8441974324476545,
            "mae": 0.33955818431639817,
            "precision": 0.8528528528528528,
            "recall": 0.5941422594142259
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8395701798282703,
            "auditor_fn_violation": 0.02510861644328424,
            "auditor_fp_violation": 0.009160074189030625,
            "ave_precision_score": 0.8397846247497678,
            "fpr": 0.05378704720087816,
            "logloss": 0.704820334746505,
            "mae": 0.34016385295813745,
            "precision": 0.8515151515151516,
            "recall": 0.5903361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7855106402241874,
            "auditor_fn_violation": 0.006867980621008591,
            "auditor_fp_violation": 0.03118431158541516,
            "ave_precision_score": 0.6178659828057054,
            "fpr": 0.2883771929824561,
            "logloss": 0.6449369176725948,
            "mae": 0.45788044381167803,
            "precision": 0.6182873730043541,
            "recall": 0.891213389121339
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7738451840817593,
            "auditor_fn_violation": 0.012051582433192817,
            "auditor_fp_violation": 0.0393454205937646,
            "ave_precision_score": 0.603996496316802,
            "fpr": 0.29418221734357847,
            "logloss": 0.6554616978439269,
            "mae": 0.4626617455194601,
            "precision": 0.6087591240875913,
            "recall": 0.8760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6956467344343757,
            "auditor_fn_violation": 0.006420667253908835,
            "auditor_fp_violation": 0.003537068477645727,
            "ave_precision_score": 0.7005810815175829,
            "fpr": 0.01864035087719298,
            "logloss": 5.449049578233261,
            "mae": 0.49334004611705173,
            "precision": 0.7976190476190477,
            "recall": 0.1401673640167364
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7026426988755708,
            "auditor_fn_violation": 0.004745915929489248,
            "auditor_fp_violation": 0.0019985616412430446,
            "ave_precision_score": 0.7054037362143533,
            "fpr": 0.009879253567508232,
            "logloss": 5.582341489507464,
            "mae": 0.4873446379269899,
            "precision": 0.875,
            "recall": 0.1323529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7589830507034373,
            "auditor_fn_violation": 0.02486603538134041,
            "auditor_fp_violation": 0.001189970894979384,
            "ave_precision_score": 0.7278658574049023,
            "fpr": 0.009868421052631578,
            "logloss": 0.6657382959874687,
            "mae": 0.4259216391109747,
            "precision": 0.90625,
            "recall": 0.18200836820083682
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7754165409000324,
            "auditor_fn_violation": 0.02042265863535315,
            "auditor_fp_violation": 0.001741171126840532,
            "ave_precision_score": 0.7408661794605967,
            "fpr": 0.008781558726673985,
            "logloss": 0.6396142875336455,
            "mae": 0.4177556262974158,
            "precision": 0.9166666666666666,
            "recall": 0.18487394957983194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7623490669593853,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005558250464871967,
            "ave_precision_score": 0.5246981339187706,
            "fpr": 0.47478070175438597,
            "logloss": 0.6931502890340442,
            "mae": 0.4969993509973089,
            "precision": 0.5246981339187706,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.761251372118551,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5225027442371021,
            "fpr": 0.4774972557628979,
            "logloss": 0.6941461966796159,
            "mae": 0.4975653462823476,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7763445031258052,
            "auditor_fn_violation": 0.013630441165675702,
            "auditor_fp_violation": 0.01038887541434231,
            "ave_precision_score": 0.7729763718106673,
            "fpr": 0.08771929824561403,
            "logloss": 0.660412284928776,
            "mae": 0.3956543998921618,
            "precision": 0.7727272727272727,
            "recall": 0.5690376569037657
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7820182576848902,
            "auditor_fn_violation": 0.0013836489590347714,
            "auditor_fp_violation": 0.003684217166937939,
            "ave_precision_score": 0.7751987421846018,
            "fpr": 0.07464324917672886,
            "logloss": 0.6432951368077865,
            "mae": 0.3948184257437204,
            "precision": 0.7951807228915663,
            "recall": 0.5546218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8603922271864077,
            "auditor_fn_violation": 0.007115723408940766,
            "auditor_fp_violation": 0.018898051580564318,
            "ave_precision_score": 0.8605939020407262,
            "fpr": 0.15570175438596492,
            "logloss": 1.133265204915389,
            "mae": 0.2723201197692181,
            "precision": 0.73992673992674,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8675121229409986,
            "auditor_fn_violation": 0.013255357027553066,
            "auditor_fp_violation": 0.022932990145980794,
            "ave_precision_score": 0.8677391477716574,
            "fpr": 0.1800219538968167,
            "logloss": 0.9810369930692456,
            "mae": 0.27403270515012756,
            "precision": 0.7152777777777778,
            "recall": 0.865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6710908471888026,
            "auditor_fn_violation": 0.05170483740732585,
            "auditor_fp_violation": 0.03014845581696177,
            "ave_precision_score": 0.6285321464821334,
            "fpr": 0.19846491228070176,
            "logloss": 0.662897997306682,
            "mae": 0.47417636287578363,
            "precision": 0.6082251082251082,
            "recall": 0.5878661087866108
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6744699460023533,
            "auditor_fn_violation": 0.03567969449030986,
            "auditor_fp_violation": 0.02915326091070821,
            "ave_precision_score": 0.6299960984316729,
            "fpr": 0.20197585071350166,
            "logloss": 0.6617703671051445,
            "mae": 0.4728638886194983,
            "precision": 0.6198347107438017,
            "recall": 0.6302521008403361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8393071282340374,
            "auditor_fn_violation": 0.007189128679439189,
            "auditor_fp_violation": 0.006490520656479911,
            "ave_precision_score": 0.8390702004094002,
            "fpr": 0.09978070175438597,
            "logloss": 0.5001655880696663,
            "mae": 0.3289963844019854,
            "precision": 0.7986725663716814,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8275440682373932,
            "auditor_fn_violation": 0.0014943408757575507,
            "auditor_fp_violation": 0.011123307720453718,
            "ave_precision_score": 0.8259399141720494,
            "fpr": 0.09440175631174534,
            "logloss": 0.49886786482594425,
            "mae": 0.3280977654699175,
            "precision": 0.8018433179723502,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7592150220651755,
            "auditor_fn_violation": 0.018027875651471778,
            "auditor_fp_violation": 0.013905732072115781,
            "ave_precision_score": 0.7598315163262869,
            "fpr": 0.13486842105263158,
            "logloss": 0.6989063974519683,
            "mae": 0.3334875272815688,
            "precision": 0.722972972972973,
            "recall": 0.6715481171548117
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7524010877382945,
            "auditor_fn_violation": 0.017295611987934577,
            "auditor_fp_violation": 0.020603858334279627,
            "ave_precision_score": 0.7530676418348157,
            "fpr": 0.15367727771679474,
            "logloss": 0.715313095816222,
            "mae": 0.3341709108702209,
            "precision": 0.7095435684647303,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8093641471344282,
            "auditor_fn_violation": 0.009322469353299572,
            "auditor_fp_violation": 0.01667222491713155,
            "ave_precision_score": 0.8098478650761296,
            "fpr": 0.22916666666666666,
            "logloss": 0.5926163251592548,
            "mae": 0.3698102078122789,
            "precision": 0.6666666666666666,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8244821195484275,
            "auditor_fn_violation": 0.00797443016723704,
            "auditor_fp_violation": 0.01868352322192363,
            "ave_precision_score": 0.8247432960804197,
            "fpr": 0.2217343578485181,
            "logloss": 0.5741309728018824,
            "mae": 0.3718759832672701,
            "precision": 0.6715447154471544,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5833292254017817,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5155094508425934,
            "fpr": 0.4758771929824561,
            "logloss": 0.6921978091451297,
            "mae": 0.4993405210082991,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6070378478135648,
            "auditor_fn_violation": 0.0006249481131640361,
            "auditor_fp_violation": 0.0006207653582648963,
            "ave_precision_score": 0.5252089774351507,
            "fpr": 0.47639956092206365,
            "logloss": 0.6922916354127083,
            "mae": 0.4993874422150831,
            "precision": 0.5225522552255225,
            "recall": 0.9978991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7635064450089246,
            "auditor_fn_violation": 0.005165895911326434,
            "auditor_fp_violation": 0.01786219581211092,
            "ave_precision_score": 0.7299629459084893,
            "fpr": 0.12280701754385964,
            "logloss": 0.5519511806118976,
            "mae": 0.37274830443621204,
            "precision": 0.7671517671517671,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7687239882485837,
            "auditor_fn_violation": 0.0024167735151140557,
            "auditor_fp_violation": 0.01208221355842386,
            "ave_precision_score": 0.7409299870171155,
            "fpr": 0.1119648737650933,
            "logloss": 0.5489595666868992,
            "mae": 0.3732896969131267,
            "precision": 0.7792207792207793,
            "recall": 0.7563025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7620614035087719,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5241228070175439,
            "fpr": 0.4758771929824561,
            "logloss": 0.6924957609433937,
            "mae": 0.4980655014514923,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.761251372118551,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5225027442371021,
            "fpr": 0.4774972557628979,
            "logloss": 0.6927561579568489,
            "mae": 0.49819542037406944,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6862186458611218,
            "auditor_fn_violation": 0.004459370182779124,
            "auditor_fp_violation": 0.022707979626485582,
            "ave_precision_score": 0.5936131773198347,
            "fpr": 0.42214912280701755,
            "logloss": 6.983610721898278,
            "mae": 0.4331796969973335,
            "precision": 0.5491803278688525,
            "recall": 0.9811715481171548
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6853643985494368,
            "auditor_fn_violation": 0.0026704424909370994,
            "auditor_fp_violation": 0.02141135798730712,
            "ave_precision_score": 0.5855144798706002,
            "fpr": 0.42041712403951703,
            "logloss": 7.493456468855595,
            "mae": 0.4387446884495236,
            "precision": 0.5488810365135454,
            "recall": 0.9789915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7489430998145552,
            "auditor_fn_violation": 0.00989594802906849,
            "auditor_fp_violation": 0.014643463497453315,
            "ave_precision_score": 0.7369374811298108,
            "fpr": 0.13815789473684212,
            "logloss": 0.6084654562124369,
            "mae": 0.39824120412793074,
            "precision": 0.7162162162162162,
            "recall": 0.6652719665271967
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7280394717749377,
            "auditor_fn_violation": 0.012540471732051766,
            "auditor_fp_violation": 0.02561287961946579,
            "ave_precision_score": 0.7165398885102556,
            "fpr": 0.15916575192096596,
            "logloss": 0.6276015225578039,
            "mae": 0.40371073543632857,
            "precision": 0.697286012526096,
            "recall": 0.7016806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8618129091214297,
            "auditor_fn_violation": 0.026999376055200763,
            "auditor_fp_violation": 0.012591963780418798,
            "ave_precision_score": 0.8541742604579918,
            "fpr": 0.13706140350877194,
            "logloss": 0.4916517376194398,
            "mae": 0.3349525385062423,
            "precision": 0.7539370078740157,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8302075152723919,
            "auditor_fn_violation": 0.026990379027571513,
            "auditor_fp_violation": 0.026485988619301768,
            "ave_precision_score": 0.8311181835381636,
            "fpr": 0.13391877058177826,
            "logloss": 0.49999235044483703,
            "mae": 0.33586354408940683,
            "precision": 0.7598425196850394,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6899103949741969,
            "auditor_fn_violation": 0.02061311752183807,
            "auditor_fp_violation": 0.01953725038402458,
            "ave_precision_score": 0.6533927823424519,
            "fpr": 0.15899122807017543,
            "logloss": 0.6264554789515595,
            "mae": 0.435230185326777,
            "precision": 0.6940928270042194,
            "recall": 0.6882845188284519
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6993482373900323,
            "auditor_fn_violation": 0.014685127618555656,
            "auditor_fp_violation": 0.027916777067009867,
            "ave_precision_score": 0.6545775534720656,
            "fpr": 0.17672886937431395,
            "logloss": 0.6241049644096848,
            "mae": 0.4330987632601766,
            "precision": 0.685546875,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7818211148311006,
            "auditor_fn_violation": 0.010416666666666673,
            "auditor_fp_violation": 0.0012026032823995506,
            "ave_precision_score": 0.7700228973494141,
            "fpr": 0.17324561403508773,
            "logloss": 0.6005678427941274,
            "mae": 0.3777156022046448,
            "precision": 0.6895874263261297,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7834993880451642,
            "auditor_fn_violation": 0.012090785820365473,
            "auditor_fp_violation": 0.010363753359324731,
            "ave_precision_score": 0.7755664554930841,
            "fpr": 0.15477497255762898,
            "logloss": 0.5987407013694527,
            "mae": 0.3769076341102728,
            "precision": 0.7025316455696202,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.8333413624322524,
            "auditor_fn_violation": 0.001124018204507093,
            "auditor_fp_violation": 0.0005482456140350877,
            "ave_precision_score": 0.8340699436332824,
            "fpr": 0.0010964912280701754,
            "logloss": 5.607136325134135,
            "mae": 0.5205514590432676,
            "precision": 0.8,
            "recall": 0.008368200836820083
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.8135198320419419,
            "auditor_fn_violation": 0.0019186598898615643,
            "auditor_fp_violation": 0.0008832027454988205,
            "ave_precision_score": 0.8143726676045098,
            "fpr": 0.0021953896816684962,
            "logloss": 5.618054255611497,
            "mae": 0.5204271626630095,
            "precision": 0.6666666666666666,
            "recall": 0.008403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5884299368148953,
            "auditor_fn_violation": 0.010457957131322037,
            "auditor_fp_violation": 0.010148860053359207,
            "ave_precision_score": 0.590247200308532,
            "fpr": 0.044956140350877194,
            "logloss": 0.8976071289458482,
            "mae": 0.4862567847590789,
            "precision": 0.59,
            "recall": 0.12343096234309624
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5938311971031487,
            "auditor_fn_violation": 0.013467516534605078,
            "auditor_fp_violation": 0.006159708290750343,
            "ave_precision_score": 0.594605499147428,
            "fpr": 0.030735455543358946,
            "logloss": 0.936539623651438,
            "mae": 0.4949666446655131,
            "precision": 0.65,
            "recall": 0.1092436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.6978635255896352,
            "auditor_fn_violation": 0.006666116127137926,
            "auditor_fp_violation": 0.009408602150537638,
            "ave_precision_score": 0.7131620124117461,
            "fpr": 0.08114035087719298,
            "logloss": 0.6240567153152181,
            "mae": 0.39602791944829124,
            "precision": 0.8159203980099502,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6743991178955429,
            "auditor_fn_violation": 0.008032082207196822,
            "auditor_fp_violation": 0.018032476626670197,
            "ave_precision_score": 0.6842321254051258,
            "fpr": 0.08562019758507135,
            "logloss": 0.6650180366564679,
            "mae": 0.4104066740202132,
            "precision": 0.7952755905511811,
            "recall": 0.6365546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.619121116353601,
            "auditor_fn_violation": 0.004349262277031504,
            "auditor_fp_violation": 0.005664362519201232,
            "ave_precision_score": 0.5396577049764089,
            "fpr": 0.10855263157894737,
            "logloss": 0.6904797944238498,
            "mae": 0.49797651518070907,
            "precision": 0.5787234042553191,
            "recall": 0.28451882845188287
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6209075557667237,
            "auditor_fn_violation": 0.0009916150873082509,
            "auditor_fp_violation": 0.003999646718901806,
            "ave_precision_score": 0.5389032090675431,
            "fpr": 0.11306256860592755,
            "logloss": 0.6903651710161643,
            "mae": 0.49789321291721483,
            "precision": 0.5778688524590164,
            "recall": 0.296218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 30132,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5725257739295608,
            "auditor_fn_violation": 0.018897269323937472,
            "auditor_fp_violation": 0.02538099280459213,
            "ave_precision_score": 0.495214616877839,
            "fpr": 0.24890350877192982,
            "logloss": 7.038181653793141,
            "mae": 0.5106208164095797,
            "precision": 0.4988962472406181,
            "recall": 0.47280334728033474
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5911405095033105,
            "auditor_fn_violation": 0.012388270346557947,
            "auditor_fp_violation": 0.01686917243902747,
            "ave_precision_score": 0.5207933963350806,
            "fpr": 0.2579582875960483,
            "logloss": 5.951172250082625,
            "mae": 0.5085211130698405,
            "precision": 0.4924406047516199,
            "recall": 0.4789915966386555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7233158492769343,
            "auditor_fn_violation": 0.013185421713279017,
            "auditor_fp_violation": 0.018731304066618156,
            "ave_precision_score": 0.7252859621023213,
            "fpr": 0.4199561403508772,
            "logloss": 1.4395460258769062,
            "mae": 0.4298180531069591,
            "precision": 0.5379975874547648,
            "recall": 0.9330543933054394
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7388282240971182,
            "auditor_fn_violation": 0.00805053085998395,
            "auditor_fp_violation": 0.016578977251220716,
            "ave_precision_score": 0.7397325539699103,
            "fpr": 0.4083424807903403,
            "logloss": 1.2829302646580198,
            "mae": 0.41479132523362044,
            "precision": 0.5479951397326853,
            "recall": 0.9474789915966386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.712180853448951,
            "auditor_fn_violation": 0.0408247999706379,
            "auditor_fp_violation": 0.03736912846632711,
            "ave_precision_score": 0.7128223200824,
            "fpr": 0.37609649122807015,
            "logloss": 1.289529411879419,
            "mae": 0.4158441562025824,
            "precision": 0.5510471204188482,
            "recall": 0.8807531380753139
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6917492718460875,
            "auditor_fn_violation": 0.040605484784473615,
            "auditor_fp_violation": 0.03666805455669532,
            "ave_precision_score": 0.6925284481988446,
            "fpr": 0.36443468715697036,
            "logloss": 1.310495815410923,
            "mae": 0.4196842052942115,
            "precision": 0.5573333333333333,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.4994608322332761,
            "auditor_fn_violation": 0.0005757725904719961,
            "auditor_fp_violation": 0.0010358557684534107,
            "ave_precision_score": 0.5009547976775597,
            "fpr": 0.47149122807017546,
            "logloss": 0.6928849914056451,
            "mae": 0.4996175923172319,
            "precision": 0.525909592061742,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5190030044073233,
            "auditor_fn_violation": 0.0015081773653478955,
            "auditor_fp_violation": 0.001544343086415083,
            "ave_precision_score": 0.5206477942749338,
            "fpr": 0.47420417124039516,
            "logloss": 0.692444050281431,
            "mae": 0.4993842843138949,
            "precision": 0.5226519337016574,
            "recall": 0.9936974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7859749101215335,
            "auditor_fn_violation": 0.006867980621008591,
            "auditor_fp_violation": 0.033283814374646295,
            "ave_precision_score": 0.6128841672354769,
            "fpr": 0.2817982456140351,
            "logloss": 0.6326286816392094,
            "mae": 0.4489786951198128,
            "precision": 0.623718887262079,
            "recall": 0.891213389121339
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7745511212168732,
            "auditor_fn_violation": 0.01062411792378862,
            "auditor_fp_violation": 0.04101845893738094,
            "ave_precision_score": 0.5990435424831779,
            "fpr": 0.29088913282107576,
            "logloss": 0.6463181240952225,
            "mae": 0.45520313990299316,
            "precision": 0.6102941176470589,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7797503935522644,
            "auditor_fn_violation": 0.004954855758643473,
            "auditor_fp_violation": 0.012417636834020538,
            "ave_precision_score": 0.7886783552414094,
            "fpr": 0.09539473684210527,
            "logloss": 0.5375258220724688,
            "mae": 0.33594690301565844,
            "precision": 0.8009153318077803,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8118573614219862,
            "auditor_fn_violation": 0.005866671586307418,
            "auditor_fp_violation": 0.01160780751227021,
            "ave_precision_score": 0.7978058460499571,
            "fpr": 0.09330406147091108,
            "logloss": 0.5490251226635045,
            "mae": 0.3432233145687439,
            "precision": 0.7931873479318735,
            "recall": 0.6848739495798319
        }
    }
]