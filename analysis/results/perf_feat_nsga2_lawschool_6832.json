[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.794064029545572,
            "auditor_fn_violation": 0.006218047739894812,
            "auditor_fp_violation": 0.006684815486993346,
            "ave_precision_score": 0.7944017511410798,
            "fpr": 0.14912280701754385,
            "logloss": 0.6265303415754646,
            "mae": 0.46083624938731654,
            "precision": 0.7235772357723578,
            "recall": 0.7463312368972747
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.821929327682417,
            "auditor_fn_violation": 0.000372802021415423,
            "auditor_fp_violation": 0.008301001077460839,
            "ave_precision_score": 0.8216536437655804,
            "fpr": 0.13391877058177826,
            "logloss": 0.6220330261662249,
            "mae": 0.4585685853638843,
            "precision": 0.7415254237288136,
            "recall": 0.7337526205450734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7945105753663129,
            "auditor_fn_violation": 0.008008753540034576,
            "auditor_fp_violation": 0.007259528130671506,
            "ave_precision_score": 0.7948471696177235,
            "fpr": 0.14144736842105263,
            "logloss": 0.6111069536247336,
            "mae": 0.4495505504473521,
            "precision": 0.7301255230125523,
            "recall": 0.7316561844863732
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8215001544610275,
            "auditor_fn_violation": 0.0015878604615841307,
            "auditor_fp_violation": 0.005650346254432523,
            "ave_precision_score": 0.8212269961492163,
            "fpr": 0.13172338090010977,
            "logloss": 0.6062632484744509,
            "mae": 0.4471243877704005,
            "precision": 0.7419354838709677,
            "recall": 0.7232704402515723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.064688969706573,
            "mae": 0.5230263157894737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.084518485589896,
            "mae": 0.5236004390779363,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.064688969706573,
            "mae": 0.5230263157894737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.084518485589896,
            "mae": 0.5236004390779363,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7919056419870149,
            "auditor_fn_violation": 0.007898414800102989,
            "auditor_fp_violation": 0.00959114740875178,
            "ave_precision_score": 0.7921338929059205,
            "fpr": 0.2412280701754386,
            "logloss": 0.6713297073719715,
            "mae": 0.488466181383844,
            "precision": 0.6518987341772152,
            "recall": 0.8637316561844863
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8059978701416741,
            "auditor_fn_violation": 0.005778431331938777,
            "auditor_fp_violation": 0.0006727807088984148,
            "ave_precision_score": 0.8058219983017916,
            "fpr": 0.2261251372118551,
            "logloss": 0.6718202206034902,
            "mae": 0.4887209833976859,
            "precision": 0.6578073089700996,
            "recall": 0.8301886792452831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7940230906755634,
            "auditor_fn_violation": 0.006983522748170216,
            "auditor_fp_violation": 0.0061857229280096815,
            "ave_precision_score": 0.7943605958289741,
            "fpr": 0.15021929824561403,
            "logloss": 0.6284259344306014,
            "mae": 0.46214731763068,
            "precision": 0.7232323232323232,
            "recall": 0.750524109014675
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8219622622996177,
            "auditor_fn_violation": 0.0009665237592251306,
            "auditor_fp_violation": 0.009985482100492193,
            "ave_precision_score": 0.8216864082597521,
            "fpr": 0.13830954994511527,
            "logloss": 0.6239993193182924,
            "mae": 0.45991442464578297,
            "precision": 0.7364016736401674,
            "recall": 0.7379454926624738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6218740674758241,
            "auditor_fn_violation": 0.013350987531722407,
            "auditor_fp_violation": 0.01166817906836056,
            "ave_precision_score": 0.6228984941909275,
            "fpr": 0.08881578947368421,
            "logloss": 0.6895212672844933,
            "mae": 0.49806316709962856,
            "precision": 0.6197183098591549,
            "recall": 0.27672955974842767
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5860440283735919,
            "auditor_fn_violation": 0.012682172469261092,
            "auditor_fp_violation": 0.011991177973260764,
            "ave_precision_score": 0.5879181551196939,
            "fpr": 0.10647639956092206,
            "logloss": 0.6909429665566632,
            "mae": 0.4987747735956236,
            "precision": 0.555045871559633,
            "recall": 0.25366876310272535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 6832,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7975642749852614,
            "auditor_fn_violation": 0.00747085218286808,
            "auditor_fp_violation": 0.01264115749142973,
            "ave_precision_score": 0.7980535193826221,
            "fpr": 0.14912280701754385,
            "logloss": 0.6228751126312531,
            "mae": 0.4584762639970633,
            "precision": 0.7301587301587301,
            "recall": 0.7714884696016772
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8301248607573826,
            "auditor_fn_violation": 0.005203119570495253,
            "auditor_fp_violation": 0.0016743640198900254,
            "ave_precision_score": 0.8300023432253345,
            "fpr": 0.12733260153677278,
            "logloss": 0.6177767361706277,
            "mae": 0.45588483264757695,
            "precision": 0.7542372881355932,
            "recall": 0.7463312368972747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7975114184073233,
            "auditor_fn_violation": 0.004006675493765859,
            "auditor_fp_violation": 0.01264115749142973,
            "ave_precision_score": 0.7980010577935004,
            "fpr": 0.14912280701754385,
            "logloss": 0.6213513628343131,
            "mae": 0.4573940284092698,
            "precision": 0.7296222664015904,
            "recall": 0.7693920335429769
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8306131211724941,
            "auditor_fn_violation": 0.005203119570495253,
            "auditor_fp_violation": 0.0022560917005164808,
            "ave_precision_score": 0.8304885476979926,
            "fpr": 0.12623490669593854,
            "logloss": 0.6159935817787529,
            "mae": 0.4546693396947779,
            "precision": 0.7558386411889597,
            "recall": 0.7463312368972747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7946911997745986,
            "auditor_fn_violation": 0.007234083636764868,
            "auditor_fp_violation": 0.007683000604960681,
            "ave_precision_score": 0.7950288507641738,
            "fpr": 0.14473684210526316,
            "logloss": 0.6232720211749101,
            "mae": 0.4586509866476582,
            "precision": 0.7283950617283951,
            "recall": 0.7421383647798742
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8209073824210711,
            "auditor_fn_violation": 4.142244682393242e-05,
            "auditor_fp_violation": 0.011472681562267627,
            "ave_precision_score": 0.820638112374535,
            "fpr": 0.132821075740944,
            "logloss": 0.6198612296847043,
            "mae": 0.4569323902007123,
            "precision": 0.7436440677966102,
            "recall": 0.7358490566037735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 6832,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6420592305939421,
            "auditor_fn_violation": 0.00916960903306484,
            "auditor_fp_violation": 0.0012124420246017356,
            "ave_precision_score": 0.6430256835311783,
            "fpr": 0.02850877192982456,
            "logloss": 2.5989691687104814,
            "mae": 0.48183645095693955,
            "precision": 0.7903225806451613,
            "recall": 0.20545073375262055
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6316541094131628,
            "auditor_fn_violation": 0.00891272980828312,
            "auditor_fp_violation": 0.005276017138203323,
            "ave_precision_score": 0.6322456566782237,
            "fpr": 0.038419319429198684,
            "logloss": 2.6732859657047334,
            "mae": 0.4862462672512768,
            "precision": 0.7131147540983607,
            "recall": 0.18238993710691823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7534540742422029,
            "auditor_fn_violation": 0.006601934605906803,
            "auditor_fp_violation": 0.004827082072998589,
            "ave_precision_score": 0.7549966816018556,
            "fpr": 0.015350877192982455,
            "logloss": 0.6801215670739412,
            "mae": 0.49130472004936454,
            "precision": 0.8352941176470589,
            "recall": 0.1488469601677149
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7188615652965803,
            "auditor_fn_violation": 0.0023955981746508486,
            "auditor_fp_violation": 0.0022485039481604766,
            "ave_precision_score": 0.7197298371991814,
            "fpr": 0.02305159165751921,
            "logloss": 0.6852686135953775,
            "mae": 0.49538479841893907,
            "precision": 0.7613636363636364,
            "recall": 0.14046121593291405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7986587605099034,
            "auditor_fn_violation": 0.0065812460921696285,
            "auditor_fp_violation": 0.005248033877797948,
            "ave_precision_score": 0.7991484024803619,
            "fpr": 0.20175438596491227,
            "logloss": 0.6118922222511955,
            "mae": 0.4494668645294089,
            "precision": 0.684931506849315,
            "recall": 0.8385744234800838
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8260538021050858,
            "auditor_fn_violation": 0.0054677629807592725,
            "auditor_fp_violation": 0.006232073935058957,
            "ave_precision_score": 0.8259547638604796,
            "fpr": 0.18880351262349068,
            "logloss": 0.6070886626023054,
            "mae": 0.44729944023290397,
            "precision": 0.69009009009009,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7946704150162586,
            "auditor_fn_violation": 0.009466144396630991,
            "auditor_fp_violation": 0.0061857229280096815,
            "ave_precision_score": 0.795006634819004,
            "fpr": 0.15021929824561403,
            "logloss": 0.6313794887317622,
            "mae": 0.46424866108256474,
            "precision": 0.7248995983935743,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8211970168932912,
            "auditor_fn_violation": 0.00170522406091861,
            "auditor_fp_violation": 0.008687976447616687,
            "ave_precision_score": 0.8209256560443058,
            "fpr": 0.1394072447859495,
            "logloss": 0.6282153110383474,
            "mae": 0.4626531387330672,
            "precision": 0.7354166666666667,
            "recall": 0.740041928721174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6827192718593795,
            "auditor_fn_violation": 0.10505627275736512,
            "auditor_fp_violation": 0.06704728775962895,
            "ave_precision_score": 0.6839667858847536,
            "fpr": 0.14035087719298245,
            "logloss": 0.7805577455971806,
            "mae": 0.47453318163752556,
            "precision": 0.6073619631901841,
            "recall": 0.41509433962264153
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7129532856215602,
            "auditor_fn_violation": 0.10555129824852089,
            "auditor_fp_violation": 0.060818364384102146,
            "ave_precision_score": 0.7142243682789318,
            "fpr": 0.12184412733260154,
            "logloss": 0.7283759668385406,
            "mae": 0.45503126796330895,
            "precision": 0.6686567164179105,
            "recall": 0.469601677148847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7945213065110664,
            "auditor_fn_violation": 0.005785887675162746,
            "auditor_fp_violation": 0.007017543859649123,
            "ave_precision_score": 0.7948581779438881,
            "fpr": 0.1611842105263158,
            "logloss": 0.639922532457632,
            "mae": 0.4698582037695144,
            "precision": 0.7123287671232876,
            "recall": 0.7631027253668763
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8214278716629196,
            "auditor_fn_violation": 0.0017328390254679042,
            "auditor_fp_violation": 0.009765437282168284,
            "ave_precision_score": 0.8211549483956382,
            "fpr": 0.1437980241492865,
            "logloss": 0.6370038584759768,
            "mae": 0.46838751742790086,
            "precision": 0.7321063394683026,
            "recall": 0.750524109014675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7591791963698018,
            "auditor_fn_violation": 0.006087020486226062,
            "auditor_fp_violation": 0.0071662633595482965,
            "ave_precision_score": 0.7607062357337381,
            "fpr": 0.02850877192982456,
            "logloss": 0.6780148424697808,
            "mae": 0.4902052517588201,
            "precision": 0.8169014084507042,
            "recall": 0.2431865828092243
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7276695067764952,
            "auditor_fn_violation": 0.0047290626790657785,
            "auditor_fp_violation": 0.00795196446908497,
            "ave_precision_score": 0.7284975954340249,
            "fpr": 0.03293084522502744,
            "logloss": 0.683306520052003,
            "mae": 0.4943594055170547,
            "precision": 0.7887323943661971,
            "recall": 0.2348008385744235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7824533446426054,
            "auditor_fn_violation": 0.01555776233035419,
            "auditor_fp_violation": 0.01955283323250655,
            "ave_precision_score": 0.7839869124873411,
            "fpr": 0.23135964912280702,
            "logloss": 2.3195607884639906,
            "mae": 0.3198207981705363,
            "precision": 0.6580226904376013,
            "recall": 0.8511530398322851
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7726947019213323,
            "auditor_fn_violation": 0.01637567397772853,
            "auditor_fp_violation": 0.02544426290044364,
            "ave_precision_score": 0.7729733683718647,
            "fpr": 0.2524698133918771,
            "logloss": 2.1383276722701985,
            "mae": 0.3356595529230929,
            "precision": 0.6360759493670886,
            "recall": 0.8427672955974843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7937880130700388,
            "auditor_fn_violation": 0.0009401780131670935,
            "auditor_fp_violation": 0.012426900584795328,
            "ave_precision_score": 0.7941256867586857,
            "fpr": 0.2412280701754386,
            "logloss": 0.6726883170666317,
            "mae": 0.48919521925742165,
            "precision": 0.6557120500782473,
            "recall": 0.8784067085953878
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.8223320116939972,
            "auditor_fn_violation": 0.003808563860756145,
            "auditor_fp_violation": 0.007135016465422621,
            "ave_precision_score": 0.8220536466027125,
            "fpr": 0.23819978046103182,
            "logloss": 0.6711876762071937,
            "mae": 0.4884486431020806,
            "precision": 0.6539074960127592,
            "recall": 0.859538784067086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7189221646544606,
            "auditor_fn_violation": 0.016137040714995048,
            "auditor_fp_violation": 0.009452510586811857,
            "ave_precision_score": 0.7197074189990347,
            "fpr": 0.10526315789473684,
            "logloss": 0.6829791104557038,
            "mae": 0.49470940996941765,
            "precision": 0.7159763313609467,
            "recall": 0.5073375262054507
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6806888900569421,
            "auditor_fn_violation": 0.0027960151606155345,
            "auditor_fp_violation": 0.015848285420892623,
            "ave_precision_score": 0.6820312891250261,
            "fpr": 0.1163556531284303,
            "logloss": 0.685059068318516,
            "mae": 0.4957478573437449,
            "precision": 0.6936416184971098,
            "recall": 0.5031446540880503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7942797946802443,
            "auditor_fn_violation": 0.004146897642428923,
            "auditor_fp_violation": 0.0069116757410768335,
            "ave_precision_score": 0.7946168275193997,
            "fpr": 0.17434210526315788,
            "logloss": 0.649209369126871,
            "mae": 0.47566241983389645,
            "precision": 0.702803738317757,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8217092506134918,
            "auditor_fn_violation": 0.00014037606979222552,
            "auditor_fp_violation": 0.01441420022560918,
            "ave_precision_score": 0.8214348214734726,
            "fpr": 0.150384193194292,
            "logloss": 0.6465731217380565,
            "mae": 0.47433678257871015,
            "precision": 0.7281746031746031,
            "recall": 0.7693920335429769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7945272240911013,
            "auditor_fn_violation": 0.004385964912280702,
            "auditor_fp_violation": 0.007902298850574719,
            "ave_precision_score": 0.7948635081279595,
            "fpr": 0.16447368421052633,
            "logloss": 0.6434224444981232,
            "mae": 0.4720791916836772,
            "precision": 0.7120921305182342,
            "recall": 0.7777777777777778
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8215449455987235,
            "auditor_fn_violation": 0.002754592713791608,
            "auditor_fp_violation": 0.010516624765411996,
            "ave_precision_score": 0.8212715951455339,
            "fpr": 0.145993413830955,
            "logloss": 0.64060066793776,
            "mae": 0.47065821361986654,
            "precision": 0.7302231237322515,
            "recall": 0.7547169811320755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7312257895369093,
            "auditor_fn_violation": 0.011040770164404726,
            "auditor_fp_violation": 0.025736035491026422,
            "ave_precision_score": 0.7324786665434789,
            "fpr": 0.1524122807017544,
            "logloss": 0.6192267489334214,
            "mae": 0.39005737682608316,
            "precision": 0.7036247334754797,
            "recall": 0.6918238993710691
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7616589176116821,
            "auditor_fn_violation": 0.005944121119234516,
            "auditor_fp_violation": 0.029458183896766108,
            "ave_precision_score": 0.7625390852918047,
            "fpr": 0.1437980241492865,
            "logloss": 0.5919114801978936,
            "mae": 0.3791395604434606,
            "precision": 0.7176724137931034,
            "recall": 0.6981132075471698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7945272240911013,
            "auditor_fn_violation": 0.009466144396630991,
            "auditor_fp_violation": 0.0061857229280096815,
            "ave_precision_score": 0.7948635081279595,
            "fpr": 0.15021929824561403,
            "logloss": 0.6097146579365466,
            "mae": 0.44838846347441796,
            "precision": 0.7248995983935743,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8215449455987235,
            "auditor_fn_violation": 0.0009665237592251306,
            "auditor_fp_violation": 0.008687976447616687,
            "ave_precision_score": 0.8212715951455339,
            "fpr": 0.1394072447859495,
            "logloss": 0.604636497092504,
            "mae": 0.44589732163693063,
            "precision": 0.7348643006263048,
            "recall": 0.7379454926624738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7234621856634111,
            "auditor_fn_violation": 0.007461657287873775,
            "auditor_fp_violation": 0.020666969147005443,
            "ave_precision_score": 0.7170744762730795,
            "fpr": 0.36622807017543857,
            "logloss": 3.8609901036750394,
            "mae": 0.4104837139568026,
            "precision": 0.5656697009102731,
            "recall": 0.9119496855345912
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6536655702550979,
            "auditor_fn_violation": 0.012044727037581667,
            "auditor_fp_violation": 0.020577984389464152,
            "ave_precision_score": 0.6516483293067205,
            "fpr": 0.3567508232711306,
            "logloss": 4.091946974421784,
            "mae": 0.3933321592460759,
            "precision": 0.5784695201037614,
            "recall": 0.9350104821802935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7946911997745986,
            "auditor_fn_violation": 0.004289418514840563,
            "auditor_fp_violation": 0.007902298850574719,
            "ave_precision_score": 0.7950288507641738,
            "fpr": 0.16447368421052633,
            "logloss": 0.6452728654718617,
            "mae": 0.4732602976197213,
            "precision": 0.7126436781609196,
            "recall": 0.779874213836478
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8209073824210711,
            "auditor_fn_violation": 0.0031250934881612348,
            "auditor_fp_violation": 0.011599144101534247,
            "ave_precision_score": 0.820638112374535,
            "fpr": 0.14818880351262348,
            "logloss": 0.6430178822999378,
            "mae": 0.47212751335684217,
            "precision": 0.7278225806451613,
            "recall": 0.7568134171907757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7965558190167703,
            "auditor_fn_violation": 0.00476295560704697,
            "auditor_fp_violation": 0.010359951603145798,
            "ave_precision_score": 0.7970473612461928,
            "fpr": 0.14802631578947367,
            "logloss": 0.6297948414519384,
            "mae": 0.46323764693449465,
            "precision": 0.73,
            "recall": 0.7651991614255765
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8261181122289156,
            "auditor_fn_violation": 0.0017190315431932566,
            "auditor_fp_violation": 0.008103719516204907,
            "ave_precision_score": 0.8260071958694388,
            "fpr": 0.1350164654226125,
            "logloss": 0.6258349459021025,
            "mae": 0.4612317631260362,
            "precision": 0.7415966386554622,
            "recall": 0.740041928721174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7301185181701808,
            "auditor_fn_violation": 0.015992221118834818,
            "auditor_fp_violation": 0.009868421052631584,
            "ave_precision_score": 0.7308804175500447,
            "fpr": 0.10416666666666667,
            "logloss": 0.6816962970848128,
            "mae": 0.4940393980134997,
            "precision": 0.7331460674157303,
            "recall": 0.5471698113207547
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6921196002381957,
            "auditor_fn_violation": 0.00372802021415405,
            "auditor_fp_violation": 0.016204909781624484,
            "ave_precision_score": 0.6934190596924319,
            "fpr": 0.11745334796926454,
            "logloss": 0.6838857085773973,
            "mae": 0.49513203811828704,
            "precision": 0.7019498607242339,
            "recall": 0.5283018867924528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7974615682075755,
            "auditor_fn_violation": 0.0035860090477766765,
            "auditor_fp_violation": 0.008787053841500298,
            "ave_precision_score": 0.797951677015243,
            "fpr": 0.14473684210526316,
            "logloss": 0.6183625377128753,
            "mae": 0.4552328593113966,
            "precision": 0.7349397590361446,
            "recall": 0.7672955974842768
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8317602499314805,
            "auditor_fn_violation": 0.0064181780106639845,
            "auditor_fp_violation": 0.003434722566481361,
            "ave_precision_score": 0.8316324345851571,
            "fpr": 0.1207464324917673,
            "logloss": 0.6124857809797817,
            "mae": 0.4522418720007728,
            "precision": 0.7649572649572649,
            "recall": 0.750524109014675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7940520988694176,
            "auditor_fn_violation": 0.005151439920556109,
            "auditor_fp_violation": 0.00585299455535391,
            "ave_precision_score": 0.7943897697840083,
            "fpr": 0.1875,
            "logloss": 0.6541505967744183,
            "mae": 0.478635343902728,
            "precision": 0.6902173913043478,
            "recall": 0.7987421383647799
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8219424899099007,
            "auditor_fn_violation": 0.0030261398651929487,
            "auditor_fp_violation": 0.009687030507822976,
            "ave_precision_score": 0.821666698394134,
            "fpr": 0.15916575192096596,
            "logloss": 0.6516140444403732,
            "mae": 0.47736139279819867,
            "precision": 0.7216890595009597,
            "recall": 0.7882599580712788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.777297243398032,
            "auditor_fn_violation": 0.023660763544080334,
            "auditor_fp_violation": 0.008842508570276266,
            "ave_precision_score": 0.7779156450465611,
            "fpr": 0.09429824561403509,
            "logloss": 3.257670065177737,
            "mae": 0.3226793104807011,
            "precision": 0.7681940700808625,
            "recall": 0.5974842767295597
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.762473291357761,
            "auditor_fn_violation": 0.01924532904380884,
            "auditor_fp_violation": 0.013969052087390672,
            "ave_precision_score": 0.7626517766334099,
            "fpr": 0.11086717892425905,
            "logloss": 3.766897799477122,
            "mae": 0.3484649570873118,
            "precision": 0.7349081364829396,
            "recall": 0.5870020964360587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7946538360037638,
            "auditor_fn_violation": 0.0061215013424546815,
            "auditor_fp_violation": 0.007428412986489223,
            "ave_precision_score": 0.7949913226032372,
            "fpr": 0.14692982456140352,
            "logloss": 0.6269352862732586,
            "mae": 0.4612156912161593,
            "precision": 0.726530612244898,
            "recall": 0.7463312368972747
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8210363738434312,
            "auditor_fn_violation": 4.142244682393242e-05,
            "auditor_fp_violation": 0.006105611395792343,
            "ave_precision_score": 0.8207664514407903,
            "fpr": 0.13391877058177826,
            "logloss": 0.6236377421392105,
            "mae": 0.45955326606884483,
            "precision": 0.7420718816067653,
            "recall": 0.7358490566037735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7945822936016783,
            "auditor_fn_violation": 0.009932785317591678,
            "auditor_fp_violation": 0.008293002621496268,
            "ave_precision_score": 0.7949192983667428,
            "fpr": 0.15350877192982457,
            "logloss": 0.6360538632297663,
            "mae": 0.4673522432383738,
            "precision": 0.7211155378486056,
            "recall": 0.7589098532494759
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8213163294707257,
            "auditor_fn_violation": 0.00035209079800343986,
            "auditor_fp_violation": 0.009775554285309605,
            "ave_precision_score": 0.8210441751374353,
            "fpr": 0.141602634467618,
            "logloss": 0.6330256696869141,
            "mae": 0.4658256393298098,
            "precision": 0.7329192546583851,
            "recall": 0.7421383647798742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.79466029161411,
            "auditor_fn_violation": 0.009466144396630991,
            "auditor_fp_violation": 0.0061857229280096815,
            "ave_precision_score": 0.79499744758851,
            "fpr": 0.15021929824561403,
            "logloss": 0.6332178394082251,
            "mae": 0.4654794708221105,
            "precision": 0.7248995983935743,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8212387700361239,
            "auditor_fn_violation": 0.0009665237592251306,
            "auditor_fp_violation": 0.008687976447616687,
            "ave_precision_score": 0.8209671593478949,
            "fpr": 0.1394072447859495,
            "logloss": 0.630107642076909,
            "mae": 0.4639112297384197,
            "precision": 0.7348643006263048,
            "recall": 0.7379454926624738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7762122387356534,
            "auditor_fn_violation": 0.02161260068410019,
            "auditor_fp_violation": 0.008686227061907645,
            "ave_precision_score": 0.7768355388814562,
            "fpr": 0.08991228070175439,
            "logloss": 3.2950804282700967,
            "mae": 0.32172387139742953,
            "precision": 0.7747252747252747,
            "recall": 0.5911949685534591
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7571857354376101,
            "auditor_fn_violation": 0.018076295544555594,
            "auditor_fp_violation": 0.015377844774820805,
            "ave_precision_score": 0.7574032718067041,
            "fpr": 0.1119648737650933,
            "logloss": 3.819562448725087,
            "mae": 0.3491327879751164,
            "precision": 0.7308707124010554,
            "recall": 0.5807127882599581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 6832,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7389793118950254,
            "auditor_fn_violation": 0.014084280407517757,
            "auditor_fp_violation": 0.018564730792498492,
            "ave_precision_score": 0.7399929765619543,
            "fpr": 0.10416666666666667,
            "logloss": 0.6213825889396037,
            "mae": 0.40007215519842265,
            "precision": 0.7473404255319149,
            "recall": 0.589098532494759
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7744215338606121,
            "auditor_fn_violation": 0.01252108517605691,
            "auditor_fp_violation": 0.017100264559632147,
            "ave_precision_score": 0.7750141080214832,
            "fpr": 0.0889132821075741,
            "logloss": 0.5894680103938508,
            "mae": 0.38460595610640474,
            "precision": 0.7780821917808219,
            "recall": 0.5953878406708596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.690884349210898,
            "auditor_fn_violation": 0.01861966236345582,
            "auditor_fp_violation": 0.016195301472070985,
            "ave_precision_score": 0.6917367893595477,
            "fpr": 0.10416666666666667,
            "logloss": 0.685432517863562,
            "mae": 0.4959795427949805,
            "precision": 0.6854304635761589,
            "recall": 0.4339622641509434
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.650290727948408,
            "auditor_fn_violation": 0.00928323058265275,
            "auditor_fp_violation": 0.014201743159641251,
            "ave_precision_score": 0.6520372664906644,
            "fpr": 0.11306256860592755,
            "logloss": 0.6872876130106866,
            "mae": 0.4969065007145397,
            "precision": 0.6698717948717948,
            "recall": 0.4381551362683438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7314264601836796,
            "auditor_fn_violation": 0.012755618080841519,
            "auditor_fp_violation": 0.016074309336559796,
            "ave_precision_score": 0.7269424222026362,
            "fpr": 0.33114035087719296,
            "logloss": 3.382535304761422,
            "mae": 0.39089637207677863,
            "precision": 0.5805555555555556,
            "recall": 0.8763102725366876
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6576155850620768,
            "auditor_fn_violation": 0.0009711262533166738,
            "auditor_fp_violation": 0.019540991567477888,
            "ave_precision_score": 0.6580190644370433,
            "fpr": 0.3205268935236004,
            "logloss": 3.915534133365692,
            "mae": 0.39198880374338946,
            "precision": 0.5869872701555869,
            "recall": 0.870020964360587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7945467294706289,
            "auditor_fn_violation": 0.006351373717312148,
            "auditor_fp_violation": 0.008151845130066542,
            "ave_precision_score": 0.7948836051691172,
            "fpr": 0.15789473684210525,
            "logloss": 0.6382700039231213,
            "mae": 0.4687944745416181,
            "precision": 0.7159763313609467,
            "recall": 0.7610062893081762
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.821399250788975,
            "auditor_fn_violation": 0.0016154754261334258,
            "auditor_fp_violation": 0.011634553612528903,
            "ave_precision_score": 0.8211264672326353,
            "fpr": 0.14270032930845225,
            "logloss": 0.635304866766075,
            "mae": 0.46730002626760336,
            "precision": 0.7325102880658436,
            "recall": 0.7463312368972747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6617476519730929,
            "auditor_fn_violation": 0.006176670712420467,
            "auditor_fp_violation": 0.004839685420447672,
            "ave_precision_score": 0.6558563470076056,
            "fpr": 0.4243421052631579,
            "logloss": 6.815328322092635,
            "mae": 0.4639619456342699,
            "precision": 0.532043530834341,
            "recall": 0.9224318658280922
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6309301083687265,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.010506507762270682,
            "ave_precision_score": 0.6322163833029216,
            "fpr": 0.4083424807903403,
            "logloss": 6.669768711475396,
            "mae": 0.4378750620636799,
            "precision": 0.5479951397326853,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 6832,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7762977481034102,
            "auditor_fn_violation": 0.023132057081908124,
            "auditor_fp_violation": 0.008033373664045173,
            "ave_precision_score": 0.7769192665462956,
            "fpr": 0.09649122807017543,
            "logloss": 3.268187569092358,
            "mae": 0.322487740253113,
            "precision": 0.7647058823529411,
            "recall": 0.59958071278826
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7610371107116096,
            "auditor_fn_violation": 0.01924532904380884,
            "auditor_fp_violation": 0.013969052087390672,
            "ave_precision_score": 0.7612222537341747,
            "fpr": 0.11086717892425905,
            "logloss": 3.780257732643593,
            "mae": 0.3485802225442662,
            "precision": 0.7349081364829396,
            "recall": 0.5870020964360587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 6832,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7940029688272934,
            "auditor_fn_violation": 0.006751351649564165,
            "auditor_fp_violation": 0.005263157894736853,
            "ave_precision_score": 0.7943402167211214,
            "fpr": 0.19078947368421054,
            "logloss": 0.6561895023402985,
            "mae": 0.47984125095893415,
            "precision": 0.6876122082585279,
            "recall": 0.8029350104821803
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8220596144264789,
            "auditor_fn_violation": 0.002621120385136708,
            "auditor_fp_violation": 0.012686721939227166,
            "ave_precision_score": 0.8217830981318569,
            "fpr": 0.16794731064763996,
            "logloss": 0.653705269663302,
            "mae": 0.47859430002328723,
            "precision": 0.7124060150375939,
            "recall": 0.7945492662473794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7944703589890051,
            "auditor_fn_violation": 0.00492616499319578,
            "auditor_fp_violation": 0.010334744908247631,
            "ave_precision_score": 0.794806536441728,
            "fpr": 0.16885964912280702,
            "logloss": 0.6450005200530667,
            "mae": 0.4730668684565707,
            "precision": 0.7077798861480076,
            "recall": 0.7819706498951782
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8215986082371052,
            "auditor_fn_violation": 0.0018847213304889934,
            "auditor_fp_violation": 0.013306388381633599,
            "ave_precision_score": 0.8213249202173003,
            "fpr": 0.14818880351262348,
            "logloss": 0.6422217788414567,
            "mae": 0.47166802226253973,
            "precision": 0.7289156626506024,
            "recall": 0.7610062893081762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7427428411122741,
            "auditor_fn_violation": 0.006309996689837803,
            "auditor_fp_violation": 0.006894031054648125,
            "ave_precision_score": 0.7295412684832293,
            "fpr": 0.42214912280701755,
            "logloss": 4.540667709375644,
            "mae": 0.4481576203106446,
            "precision": 0.5355850422195416,
            "recall": 0.9308176100628931
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6866061410255326,
            "auditor_fn_violation": 0.010314189259159539,
            "auditor_fp_violation": 0.01265637092980318,
            "ave_precision_score": 0.6668124539696823,
            "fpr": 0.40175631174533477,
            "logloss": 5.105495091440938,
            "mae": 0.4277777843034043,
            "precision": 0.5514705882352942,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7422006588189886,
            "auditor_fn_violation": 0.00957188568906544,
            "auditor_fp_violation": 0.023815285339786246,
            "ave_precision_score": 0.7430961002226324,
            "fpr": 0.13267543859649122,
            "logloss": 0.6082525849667225,
            "mae": 0.3888454102429533,
            "precision": 0.7286995515695067,
            "recall": 0.6813417190775681
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7722055816699456,
            "auditor_fn_violation": 0.009952893472973002,
            "auditor_fp_violation": 0.029324133605143493,
            "ave_precision_score": 0.772900963414374,
            "fpr": 0.13611416026344675,
            "logloss": 0.581578998434654,
            "mae": 0.37782998819059554,
            "precision": 0.7225950782997763,
            "recall": 0.6771488469601677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.717876315145389,
            "auditor_fn_violation": 0.017573743057854283,
            "auditor_fp_violation": 0.03360556563823352,
            "ave_precision_score": 0.7191408558521933,
            "fpr": 0.13486842105263158,
            "logloss": 0.6433262533081315,
            "mae": 0.40138859644166425,
            "precision": 0.7105882352941176,
            "recall": 0.6331236897274634
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7659573731406931,
            "auditor_fn_violation": 0.012240333036472475,
            "auditor_fp_violation": 0.02263173602715404,
            "ave_precision_score": 0.766743559109704,
            "fpr": 0.1141602634467618,
            "logloss": 0.5906282346989926,
            "mae": 0.37782433528083037,
            "precision": 0.7517899761336515,
            "recall": 0.660377358490566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7349481092717711,
            "auditor_fn_violation": 0.011040770164404726,
            "auditor_fp_violation": 0.025736035491026422,
            "ave_precision_score": 0.7361681032086531,
            "fpr": 0.1524122807017544,
            "logloss": 0.6185807284196548,
            "mae": 0.38612057438144964,
            "precision": 0.7036247334754797,
            "recall": 0.6918238993710691
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.765419788172246,
            "auditor_fn_violation": 0.005944121119234516,
            "auditor_fp_violation": 0.029458183896766108,
            "ave_precision_score": 0.7662263928830841,
            "fpr": 0.1437980241492865,
            "logloss": 0.591350626938248,
            "mae": 0.3752304474106539,
            "precision": 0.7176724137931034,
            "recall": 0.6981132075471698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7945105753663129,
            "auditor_fn_violation": 0.007500735591599549,
            "auditor_fp_violation": 0.007183908045977016,
            "ave_precision_score": 0.7948471696177235,
            "fpr": 0.16228070175438597,
            "logloss": 0.6418294415445431,
            "mae": 0.47107358257237236,
            "precision": 0.7131782945736435,
            "recall": 0.7714884696016772
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8215001544610275,
            "auditor_fn_violation": 0.002754592713791608,
            "auditor_fp_violation": 0.011073059938185121,
            "ave_precision_score": 0.8212269961492163,
            "fpr": 0.14489571899012074,
            "logloss": 0.63896381009636,
            "mae": 0.46963008374597315,
            "precision": 0.7317073170731707,
            "recall": 0.7547169811320755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.77647375268678,
            "auditor_fn_violation": 0.024446927066092906,
            "auditor_fp_violation": 0.010952308933252676,
            "ave_precision_score": 0.777327953652282,
            "fpr": 0.09758771929824561,
            "logloss": 3.2212922904648336,
            "mae": 0.3217454066268512,
            "precision": 0.7657894736842106,
            "recall": 0.610062893081761
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7626890578204001,
            "auditor_fn_violation": 0.01681751341051716,
            "auditor_fp_violation": 0.01493269663660231,
            "ave_precision_score": 0.7628722279231949,
            "fpr": 0.1207464324917673,
            "logloss": 3.716994027617417,
            "mae": 0.3479911376271128,
            "precision": 0.7208121827411168,
            "recall": 0.5953878406708596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.794663837042496,
            "auditor_fn_violation": 0.009629353782779806,
            "auditor_fp_violation": 0.006684815486993346,
            "ave_precision_score": 0.7950004696353019,
            "fpr": 0.14912280701754385,
            "logloss": 0.6303917325312209,
            "mae": 0.46358170056421505,
            "precision": 0.7252525252525253,
            "recall": 0.7526205450733753
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8211590983852285,
            "auditor_fn_violation": 4.142244682393242e-05,
            "auditor_fp_violation": 0.010610207044469286,
            "ave_precision_score": 0.8208883571376053,
            "fpr": 0.1350164654226125,
            "logloss": 0.6271982726000453,
            "mae": 0.4619714256568222,
            "precision": 0.740506329113924,
            "recall": 0.7358490566037735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7669624774394681,
            "auditor_fn_violation": 0.0019033432638199202,
            "auditor_fp_violation": 0.0026996370235934665,
            "ave_precision_score": 0.7681276668783756,
            "fpr": 0.006578947368421052,
            "logloss": 0.6822586159599738,
            "mae": 0.4926055249218878,
            "precision": 0.8823529411764706,
            "recall": 0.09433962264150944
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7336947871738229,
            "auditor_fn_violation": 0.005854372484449322,
            "auditor_fp_violation": 0.0019272890984232656,
            "ave_precision_score": 0.7345018073697744,
            "fpr": 0.013172338090010977,
            "logloss": 0.6865814309818216,
            "mae": 0.4961387712332603,
            "precision": 0.7647058823529411,
            "recall": 0.08176100628930817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7114028282496827,
            "auditor_fn_violation": 0.006215749016146236,
            "auditor_fp_violation": 0.000693184109699545,
            "ave_precision_score": 0.70396373787683,
            "fpr": 0.41885964912280704,
            "logloss": 5.058736004353226,
            "mae": 0.46049610876504804,
            "precision": 0.5347137637028014,
            "recall": 0.9203354297693921
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6500194329612973,
            "auditor_fn_violation": 0.011322135465208596,
            "auditor_fp_violation": 0.01343538017168555,
            "ave_precision_score": 0.6480670901714298,
            "fpr": 0.4039517014270033,
            "logloss": 5.156413657712142,
            "mae": 0.4353924698876698,
            "precision": 0.5490196078431373,
            "recall": 0.939203354297694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7947989813379475,
            "auditor_fn_violation": 0.008316782522343604,
            "auditor_fp_violation": 0.007259528130671506,
            "ave_precision_score": 0.7951377139098077,
            "fpr": 0.14144736842105263,
            "logloss": 0.6106397110343157,
            "mae": 0.4492955853868472,
            "precision": 0.73125,
            "recall": 0.7358490566037735
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8206209113539717,
            "auditor_fn_violation": 0.0024531293507952016,
            "auditor_fp_violation": 0.005650346254432523,
            "ave_precision_score": 0.8203531398634836,
            "fpr": 0.13172338090010977,
            "logloss": 0.6068101245210692,
            "mae": 0.44737566068654006,
            "precision": 0.7424892703862661,
            "recall": 0.7253668763102725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7030974249321446,
            "auditor_fn_violation": 0.0050479973518702415,
            "auditor_fp_violation": 0.0031886469046178848,
            "ave_precision_score": 0.6379040917984764,
            "fpr": 0.42543859649122806,
            "logloss": 8.747480822247509,
            "mae": 0.46415416235947443,
            "precision": 0.53309265944645,
            "recall": 0.9287211740041929
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6979128903918611,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.009737615523529631,
            "ave_precision_score": 0.6295594587190853,
            "fpr": 0.4149286498353458,
            "logloss": 8.624783709903445,
            "mae": 0.44214197826438006,
            "precision": 0.5440289505428226,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7766572668903349,
            "auditor_fn_violation": 0.0050342050093787945,
            "auditor_fp_violation": 0.004171708005646313,
            "ave_precision_score": 0.7776468454530476,
            "fpr": 0.17324561403508773,
            "logloss": 0.6523575576709431,
            "mae": 0.44253572497696597,
            "precision": 0.6984732824427481,
            "recall": 0.7672955974842768
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8137470728775154,
            "auditor_fn_violation": 0.00552299290985786,
            "auditor_fp_violation": 0.012628549171164528,
            "ave_precision_score": 0.8132905947985153,
            "fpr": 0.15477497255762898,
            "logloss": 0.6615910074100195,
            "mae": 0.4413789546098785,
            "precision": 0.7104722792607803,
            "recall": 0.7253668763102725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7942057754322142,
            "auditor_fn_violation": 0.005172128434293283,
            "auditor_fp_violation": 0.007602339181286548,
            "ave_precision_score": 0.794543329999621,
            "fpr": 0.1787280701754386,
            "logloss": 0.650760885869705,
            "mae": 0.4766029969445969,
            "precision": 0.6987060998151571,
            "recall": 0.7924528301886793
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8218414807563073,
            "auditor_fn_violation": 0.0010562723940103146,
            "auditor_fp_violation": 0.010514095514626657,
            "ave_precision_score": 0.8215663212771409,
            "fpr": 0.1525795828759605,
            "logloss": 0.6481360441029103,
            "mae": 0.47528347759032225,
            "precision": 0.7263779527559056,
            "recall": 0.7735849056603774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7895858980444116,
            "auditor_fn_violation": 0.006344477546066424,
            "auditor_fp_violation": 0.0022358338374672414,
            "ave_precision_score": 0.7174599569511523,
            "fpr": 0.42872807017543857,
            "logloss": 8.572570414708078,
            "mae": 0.46239375571409863,
            "precision": 0.5334128878281623,
            "recall": 0.9371069182389937
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7617178356890172,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.009851431808869597,
            "ave_precision_score": 0.6740635692806256,
            "fpr": 0.4138309549945115,
            "logloss": 8.94716555151952,
            "mae": 0.440787460444123,
            "precision": 0.5446859903381642,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8018445981980185,
            "auditor_fn_violation": 0.021757420280260398,
            "auditor_fp_violation": 0.014829098608590443,
            "ave_precision_score": 0.8021418490861338,
            "fpr": 0.18859649122807018,
            "logloss": 2.1160660112513456,
            "mae": 0.3050527514606661,
            "precision": 0.69009009009009,
            "recall": 0.8029350104821803
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7966448871916305,
            "auditor_fn_violation": 0.011197868124736797,
            "auditor_fp_violation": 0.02339556976432441,
            "ave_precision_score": 0.7964912371478061,
            "fpr": 0.20197585071350166,
            "logloss": 1.8844494832012462,
            "mae": 0.31167906015624036,
            "precision": 0.6754850088183422,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7789771618137593,
            "auditor_fn_violation": 0.02363317885909743,
            "auditor_fp_violation": 0.009565940713853605,
            "ave_precision_score": 0.7795115342591517,
            "fpr": 0.09320175438596491,
            "logloss": 3.2611315830091305,
            "mae": 0.3204570379973078,
            "precision": 0.7702702702702703,
            "recall": 0.5974842767295597
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7590704345931867,
            "auditor_fn_violation": 0.020980469316322522,
            "auditor_fp_violation": 0.015319672006758156,
            "ave_precision_score": 0.7592903940231865,
            "fpr": 0.11306256860592755,
            "logloss": 3.782106527995941,
            "mae": 0.3483689057198204,
            "precision": 0.7324675324675325,
            "recall": 0.5911949685534591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7380915235859071,
            "auditor_fn_violation": 0.013927967192614663,
            "auditor_fp_violation": 0.0187941117160718,
            "ave_precision_score": 0.7352124398630755,
            "fpr": 0.31469298245614036,
            "logloss": 3.207124220736279,
            "mae": 0.3824547705029131,
            "precision": 0.5894134477825465,
            "recall": 0.8637316561844863
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6705427568465914,
            "auditor_fn_violation": 0.0031527084527105255,
            "auditor_fp_violation": 0.02220176339364754,
            "ave_precision_score": 0.6713406530515867,
            "fpr": 0.30735455543358947,
            "logloss": 3.723669658851439,
            "mae": 0.38667027637024676,
            "precision": 0.5906432748538012,
            "recall": 0.8469601677148847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.621876046703014,
            "auditor_fn_violation": 0.013350987531722407,
            "auditor_fp_violation": 0.01166817906836056,
            "ave_precision_score": 0.6229024526453075,
            "fpr": 0.08881578947368421,
            "logloss": 0.689521257127011,
            "mae": 0.49806316507359344,
            "precision": 0.6197183098591549,
            "recall": 0.27672955974842767
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5860440283735919,
            "auditor_fn_violation": 0.012682172469261092,
            "auditor_fp_violation": 0.011991177973260764,
            "ave_precision_score": 0.5879181551196939,
            "fpr": 0.10647639956092206,
            "logloss": 0.6909429482018709,
            "mae": 0.4987747674127049,
            "precision": 0.555045871559633,
            "recall": 0.25366876310272535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8032567160879812,
            "auditor_fn_violation": 0.021757420280260398,
            "auditor_fp_violation": 0.015494555353902,
            "ave_precision_score": 0.8036234776643157,
            "fpr": 0.1875,
            "logloss": 2.0921203618934343,
            "mae": 0.30496341270109,
            "precision": 0.6913357400722022,
            "recall": 0.8029350104821803
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7981205281666939,
            "auditor_fn_violation": 0.011197868124736797,
            "auditor_fp_violation": 0.023694021356993635,
            "ave_precision_score": 0.7980768036865725,
            "fpr": 0.20087815587266739,
            "logloss": 1.8577411402867579,
            "mae": 0.3114540839393231,
            "precision": 0.676678445229682,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7949185244754413,
            "auditor_fn_violation": 0.0020803449924601883,
            "auditor_fp_violation": 0.007146098003629767,
            "ave_precision_score": 0.7951002810451022,
            "fpr": 0.17982456140350878,
            "logloss": 0.6540640145717728,
            "mae": 0.47863410838079035,
            "precision": 0.6979742173112339,
            "recall": 0.7945492662473794
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8147256661360783,
            "auditor_fn_violation": 0.0003866095036900542,
            "auditor_fp_violation": 0.013971581338176012,
            "ave_precision_score": 0.8144962738085103,
            "fpr": 0.16245883644346873,
            "logloss": 0.6539216002767312,
            "mae": 0.47857252483048635,
            "precision": 0.7131782945736435,
            "recall": 0.7714884696016772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7266688151662285,
            "auditor_fn_violation": 0.009006399646916047,
            "auditor_fp_violation": 0.003554143980641259,
            "ave_precision_score": 0.7282743176125102,
            "fpr": 0.01644736842105263,
            "logloss": 0.6814100766877398,
            "mae": 0.49208691036492064,
            "precision": 0.8,
            "recall": 0.12578616352201258
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7017173344310188,
            "auditor_fn_violation": 0.006496420410220302,
            "auditor_fp_violation": 0.004593119426163582,
            "ave_precision_score": 0.7025086221181536,
            "fpr": 0.026344676180021953,
            "logloss": 0.6856470106334361,
            "mae": 0.4955843139100415,
            "precision": 0.68,
            "recall": 0.1069182389937107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7006472670565537,
            "auditor_fn_violation": 0.003857258450108502,
            "auditor_fp_violation": 0.005815184513006653,
            "ave_precision_score": 0.6558029557640689,
            "fpr": 0.4243421052631579,
            "logloss": 7.56226413929438,
            "mae": 0.4629998385677456,
            "precision": 0.5331724969843185,
            "recall": 0.9266247379454927
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6894669534216041,
            "auditor_fn_violation": 0.010376322929395441,
            "auditor_fp_violation": 0.011604202603104918,
            "ave_precision_score": 0.6365222999970952,
            "fpr": 0.4083424807903403,
            "logloss": 7.647250207216425,
            "mae": 0.43989971994895705,
            "precision": 0.5474452554744526,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7784257896952382,
            "auditor_fn_violation": 0.020313821766155437,
            "auditor_fp_violation": 0.010188546077838275,
            "ave_precision_score": 0.7789622146146742,
            "fpr": 0.09649122807017543,
            "logloss": 3.2760100733602258,
            "mae": 0.32036002361170546,
            "precision": 0.76657824933687,
            "recall": 0.6058700209643606
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7586317665535526,
            "auditor_fn_violation": 0.020980469316322522,
            "auditor_fp_violation": 0.014641832796289087,
            "ave_precision_score": 0.7588520703588149,
            "fpr": 0.11525795828759605,
            "logloss": 3.8042487195074277,
            "mae": 0.3486686424472691,
            "precision": 0.7286821705426356,
            "recall": 0.5911949685534591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7048510093216542,
            "auditor_fn_violation": 0.013881992717643165,
            "auditor_fp_violation": 0.03006654567453116,
            "ave_precision_score": 0.7066894131032185,
            "fpr": 0.13815789473684212,
            "logloss": 0.6461291914540561,
            "mae": 0.4083389323070107,
            "precision": 0.7103448275862069,
            "recall": 0.6477987421383647
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.751731422634503,
            "auditor_fn_violation": 0.014571496293841633,
            "auditor_fp_violation": 0.03146387976953467,
            "ave_precision_score": 0.7526929006431519,
            "fpr": 0.12952799121844127,
            "logloss": 0.5988059506810397,
            "mae": 0.38690540318619604,
            "precision": 0.728735632183908,
            "recall": 0.6645702306079665
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7008603141522932,
            "auditor_fn_violation": 0.003857258450108502,
            "auditor_fp_violation": 0.0031886469046178848,
            "ave_precision_score": 0.6389703347227531,
            "fpr": 0.42543859649122806,
            "logloss": 8.564161406790896,
            "mae": 0.46391501985945316,
            "precision": 0.5325301204819277,
            "recall": 0.9266247379454927
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6981367398930892,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.009737615523529631,
            "ave_precision_score": 0.6325446080259237,
            "fpr": 0.4149286498353458,
            "logloss": 8.437135724213325,
            "mae": 0.4417607409370458,
            "precision": 0.5440289505428226,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.794664272997248,
            "auditor_fn_violation": 0.004344587884806359,
            "auditor_fp_violation": 0.004413692276668685,
            "ave_precision_score": 0.7950011528106634,
            "fpr": 0.18530701754385964,
            "logloss": 0.6541767061843394,
            "mae": 0.47867557432567864,
            "precision": 0.6943942133815552,
            "recall": 0.8050314465408805
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8210783957745081,
            "auditor_fn_violation": 0.0017052240609186137,
            "auditor_fp_violation": 0.010238407179025428,
            "ave_precision_score": 0.8208084534449146,
            "fpr": 0.1602634467618002,
            "logloss": 0.6522729789523246,
            "mae": 0.4777229411934393,
            "precision": 0.7208413001912046,
            "recall": 0.790356394129979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7436173898189673,
            "auditor_fn_violation": 0.012631486998418482,
            "auditor_fp_violation": 0.016923774954627956,
            "ave_precision_score": 0.7445326075888474,
            "fpr": 0.10197368421052631,
            "logloss": 0.6166148164462811,
            "mae": 0.3994917934533237,
            "precision": 0.7526595744680851,
            "recall": 0.5932914046121593
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7801328858681478,
            "auditor_fn_violation": 0.013358739100718692,
            "auditor_fp_violation": 0.014846702109901008,
            "ave_precision_score": 0.7806330292520032,
            "fpr": 0.08562019758507135,
            "logloss": 0.585693451752299,
            "mae": 0.3843434065903417,
            "precision": 0.7851239669421488,
            "recall": 0.5974842767295597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6722241673263493,
            "auditor_fn_violation": 0.009689120600242745,
            "auditor_fp_violation": 0.008759326477112321,
            "ave_precision_score": 0.6738372396578582,
            "fpr": 0.05482456140350877,
            "logloss": 0.6798244675204402,
            "mae": 0.4909637350131545,
            "precision": 0.7382198952879581,
            "recall": 0.29559748427672955
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6778217470827503,
            "auditor_fn_violation": 0.011819204827095796,
            "auditor_fp_violation": 0.005759104038201804,
            "ave_precision_score": 0.6784703832620074,
            "fpr": 0.06256860592755215,
            "logloss": 0.6841711639389674,
            "mae": 0.4946971035160689,
            "precision": 0.7106598984771574,
            "recall": 0.29350104821802936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.794664272997248,
            "auditor_fn_violation": 0.008316782522343604,
            "auditor_fp_violation": 0.007259528130671506,
            "ave_precision_score": 0.7950011528106634,
            "fpr": 0.14144736842105263,
            "logloss": 0.6094201239120021,
            "mae": 0.4482986282132435,
            "precision": 0.73125,
            "recall": 0.7358490566037735
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8210783957745081,
            "auditor_fn_violation": 0.0015878604615841307,
            "auditor_fp_violation": 0.005650346254432523,
            "ave_precision_score": 0.8208084534449146,
            "fpr": 0.13172338090010977,
            "logloss": 0.605079012742222,
            "mae": 0.44612511112451814,
            "precision": 0.7419354838709677,
            "recall": 0.7232704402515723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7600223968491029,
            "auditor_fn_violation": 0.006344477546066424,
            "auditor_fp_violation": 0.0009754990925589939,
            "ave_precision_score": 0.558322069110275,
            "fpr": 0.4309210526315789,
            "logloss": 14.93228682609506,
            "mae": 0.46381522120352375,
            "precision": 0.5321428571428571,
            "recall": 0.9371069182389937
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7691126837830533,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.008634862181124721,
            "ave_precision_score": 0.5675766467255996,
            "fpr": 0.41602634467618005,
            "logloss": 14.411837238786568,
            "mae": 0.44443440070921714,
            "precision": 0.5433734939759036,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7061072886229476,
            "auditor_fn_violation": 0.01195796094008607,
            "auditor_fp_violation": 0.039125831820931635,
            "ave_precision_score": 0.7079907881093663,
            "fpr": 0.15789473684210525,
            "logloss": 0.643843679787224,
            "mae": 0.4007502840909123,
            "precision": 0.6981132075471698,
            "recall": 0.6981132075471698
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7470577709248587,
            "auditor_fn_violation": 0.010141595730726484,
            "auditor_fp_violation": 0.029351955363782146,
            "ave_precision_score": 0.7482379478962309,
            "fpr": 0.1394072447859495,
            "logloss": 0.6015615233385525,
            "mae": 0.3833602741253322,
            "precision": 0.728051391862955,
            "recall": 0.7127882599580713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7312564517193479,
            "auditor_fn_violation": 0.01173498473647431,
            "auditor_fp_violation": 0.015615547489413212,
            "ave_precision_score": 0.7270638110712205,
            "fpr": 0.32894736842105265,
            "logloss": 3.438738811750938,
            "mae": 0.39206061518647517,
            "precision": 0.5810055865921788,
            "recall": 0.8721174004192872
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.657788848654175,
            "auditor_fn_violation": 0.0012564808869926615,
            "auditor_fp_violation": 0.020744914941296096,
            "ave_precision_score": 0.6583434845566436,
            "fpr": 0.3194291986827662,
            "logloss": 3.9609748733697465,
            "mae": 0.39263045768602495,
            "precision": 0.5854700854700855,
            "recall": 0.8616352201257862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7895795290037768,
            "auditor_fn_violation": 0.021414910441722772,
            "auditor_fp_violation": 0.014254385964912283,
            "ave_precision_score": 0.7900074731936284,
            "fpr": 0.08223684210526316,
            "logloss": 3.1618081084351704,
            "mae": 0.32253183395813134,
            "precision": 0.7887323943661971,
            "recall": 0.5870020964360587
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7813535575222171,
            "auditor_fn_violation": 0.02586831804154673,
            "auditor_fp_violation": 0.021964013819826298,
            "ave_precision_score": 0.7814518930683193,
            "fpr": 0.10976948408342481,
            "logloss": 3.680762421716242,
            "mae": 0.3388645066157533,
            "precision": 0.7422680412371134,
            "recall": 0.6037735849056604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 6832,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7424398876967496,
            "auditor_fn_violation": 0.006309996689837803,
            "auditor_fp_violation": 0.007872050816696915,
            "ave_precision_score": 0.7300024237282785,
            "fpr": 0.4199561403508772,
            "logloss": 4.498354722505355,
            "mae": 0.44733041841411997,
            "precision": 0.5368802902055623,
            "recall": 0.9308176100628931
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6850119620033186,
            "auditor_fn_violation": 0.010314189259159539,
            "auditor_fp_violation": 0.013197630597864305,
            "ave_precision_score": 0.6658839305113814,
            "fpr": 0.40065861690450055,
            "logloss": 5.067863219452432,
            "mae": 0.42694882577619336,
            "precision": 0.5521472392638037,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7470231505965619,
            "auditor_fn_violation": 0.0050479973518702415,
            "auditor_fp_violation": 0.003690260133091372,
            "ave_precision_score": 0.6942082156659664,
            "fpr": 0.42543859649122806,
            "logloss": 8.28461041915955,
            "mae": 0.4636704069970731,
            "precision": 0.53309265944645,
            "recall": 0.9287211740041929
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7338779508051266,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.01107811843975579,
            "ave_precision_score": 0.6761570161371625,
            "fpr": 0.411635565312843,
            "logloss": 8.109316061903579,
            "mae": 0.4394025524053825,
            "precision": 0.5460048426150121,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7053792937177574,
            "auditor_fn_violation": 0.022876898745816335,
            "auditor_fp_violation": 0.014065335753176051,
            "ave_precision_score": 0.706197817837517,
            "fpr": 0.10526315789473684,
            "logloss": 0.6843018555282916,
            "mae": 0.4953960380271861,
            "precision": 0.6990595611285266,
            "recall": 0.46750524109014674
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6648066630450503,
            "auditor_fn_violation": 0.005265253240731151,
            "auditor_fp_violation": 0.011260224496299707,
            "ave_precision_score": 0.6667013824684056,
            "fpr": 0.11525795828759605,
            "logloss": 0.6862633125908899,
            "mae": 0.4963757556369354,
            "precision": 0.6779141104294478,
            "recall": 0.46331236897274636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7298325482014016,
            "auditor_fn_violation": 0.006475504799735189,
            "auditor_fp_violation": 0.0196057672917927,
            "ave_precision_score": 0.7174121387101997,
            "fpr": 0.36293859649122806,
            "logloss": 4.45885225017568,
            "mae": 0.40843193287387974,
            "precision": 0.5673202614379085,
            "recall": 0.909853249475891
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6815994083976749,
            "auditor_fn_violation": 0.011522343958190944,
            "auditor_fp_violation": 0.02053751637689884,
            "ave_precision_score": 0.6617523191502064,
            "fpr": 0.3534577387486279,
            "logloss": 4.799319154164245,
            "mae": 0.39172206595456754,
            "precision": 0.5801825293350718,
            "recall": 0.9329140461215933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 6832,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.73877210478874,
            "auditor_fn_violation": 0.014084280407517757,
            "auditor_fp_violation": 0.018564730792498492,
            "ave_precision_score": 0.7397864213932581,
            "fpr": 0.10416666666666667,
            "logloss": 0.6215855894294869,
            "mae": 0.4000961221479469,
            "precision": 0.7473404255319149,
            "recall": 0.589098532494759
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7743547394300956,
            "auditor_fn_violation": 0.01252108517605691,
            "auditor_fp_violation": 0.017100264559632147,
            "ave_precision_score": 0.774947515451759,
            "fpr": 0.0889132821075741,
            "logloss": 0.5896291634666136,
            "mae": 0.38461680784330804,
            "precision": 0.7780821917808219,
            "recall": 0.5953878406708596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7282393983005104,
            "auditor_fn_violation": 0.007013406156901692,
            "auditor_fp_violation": 0.02041742286751363,
            "ave_precision_score": 0.7157558775870418,
            "fpr": 0.3618421052631579,
            "logloss": 4.461049904517186,
            "mae": 0.40813000816142486,
            "precision": 0.5686274509803921,
            "recall": 0.9119496855345912
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6806655845277175,
            "auditor_fn_violation": 0.011522343958190944,
            "auditor_fp_violation": 0.022221997399930207,
            "ave_precision_score": 0.6607647733401912,
            "fpr": 0.3545554335894621,
            "logloss": 4.800292475388898,
            "mae": 0.3915508361492035,
            "precision": 0.5794270833333334,
            "recall": 0.9329140461215933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7760068062665699,
            "auditor_fn_violation": 0.015571554672845642,
            "auditor_fp_violation": 0.021382839282113323,
            "ave_precision_score": 0.7758632733189785,
            "fpr": 0.24890350877192982,
            "logloss": 2.527035584613944,
            "mae": 0.34187158123571293,
            "precision": 0.6338709677419355,
            "recall": 0.8238993710691824
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7775877867785067,
            "auditor_fn_violation": 0.006590771539097035,
            "auditor_fp_violation": 0.02744237102085621,
            "ave_precision_score": 0.7777666226631259,
            "fpr": 0.23819978046103182,
            "logloss": 2.791799990211719,
            "mae": 0.3395251320549885,
            "precision": 0.6436781609195402,
            "recall": 0.8218029350104822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7946148878135744,
            "auditor_fn_violation": 0.004737669645812651,
            "auditor_fp_violation": 0.007562008469449493,
            "ave_precision_score": 0.7949519763676637,
            "fpr": 0.19188596491228072,
            "logloss": 0.6586853517990966,
            "mae": 0.4813252903455705,
            "precision": 0.6886120996441281,
            "recall": 0.8113207547169812
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.821283992437257,
            "auditor_fn_violation": 0.003527811721171707,
            "auditor_fp_violation": 0.011578910095251596,
            "ave_precision_score": 0.8210121694895618,
            "fpr": 0.1734357848518112,
            "logloss": 0.6569360973304527,
            "mae": 0.48045181099460366,
            "precision": 0.7068645640074211,
            "recall": 0.7987421383647799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7257726788684039,
            "auditor_fn_violation": 0.006215749016146236,
            "auditor_fp_violation": 0.000693184109699545,
            "ave_precision_score": 0.7098497617952645,
            "fpr": 0.41885964912280704,
            "logloss": 5.460357314638316,
            "mae": 0.460367971781715,
            "precision": 0.5347137637028014,
            "recall": 0.9203354297693921
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6855698124276708,
            "auditor_fn_violation": 0.010818162362184068,
            "auditor_fp_violation": 0.01343538017168555,
            "ave_precision_score": 0.661666031675814,
            "fpr": 0.4039517014270033,
            "logloss": 5.643088230942079,
            "mae": 0.43514250635545015,
            "precision": 0.5495716034271726,
            "recall": 0.9412997903563941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7600188716113607,
            "auditor_fn_violation": 0.006344477546066424,
            "auditor_fp_violation": 0.0009754990925589939,
            "ave_precision_score": 0.5583207668826358,
            "fpr": 0.4309210526315789,
            "logloss": 14.929746428741055,
            "mae": 0.4638151844081126,
            "precision": 0.5321428571428571,
            "recall": 0.9371069182389937
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7687356913111072,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.008634862181124721,
            "ave_precision_score": 0.5677219662000343,
            "fpr": 0.41602634467618005,
            "logloss": 14.389918366819733,
            "mae": 0.44442695261487325,
            "precision": 0.5433734939759036,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7263089038285078,
            "auditor_fn_violation": 0.006909963588215822,
            "auditor_fp_violation": 0.021516434765073613,
            "ave_precision_score": 0.7201378762756319,
            "fpr": 0.3574561403508772,
            "logloss": 3.1579421732976876,
            "mae": 0.40056765060367083,
            "precision": 0.5732984293193717,
            "recall": 0.9182389937106918
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6547689589341902,
            "auditor_fn_violation": 0.011161048172004409,
            "auditor_fp_violation": 0.019389236520357955,
            "ave_precision_score": 0.6542120280723281,
            "fpr": 0.34906695938529086,
            "logloss": 3.6477133172362897,
            "mae": 0.38769796529906764,
            "precision": 0.5837696335078534,
            "recall": 0.9350104821802935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7113007978294392,
            "auditor_fn_violation": 0.006215749016146236,
            "auditor_fp_violation": 0.000693184109699545,
            "ave_precision_score": 0.7039100018388436,
            "fpr": 0.41885964912280704,
            "logloss": 5.064305821378533,
            "mae": 0.46051084606542164,
            "precision": 0.5347137637028014,
            "recall": 0.9203354297693921
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6499061271841269,
            "auditor_fn_violation": 0.011322135465208596,
            "auditor_fp_violation": 0.01343538017168555,
            "ave_precision_score": 0.6479934333687136,
            "fpr": 0.4039517014270033,
            "logloss": 5.161733819670536,
            "mae": 0.4354026046664373,
            "precision": 0.5490196078431373,
            "recall": 0.939203354297694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6697158989725077,
            "auditor_fn_violation": 0.004785942844532715,
            "auditor_fp_violation": 0.00225347852389596,
            "ave_precision_score": 0.6548979272436332,
            "fpr": 0.4298245614035088,
            "logloss": 7.918598766267562,
            "mae": 0.4656035664180906,
            "precision": 0.5311004784688995,
            "recall": 0.9308176100628931
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6665998215796208,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.009737615523529631,
            "ave_precision_score": 0.6480925742311152,
            "fpr": 0.4149286498353458,
            "logloss": 7.636257687067187,
            "mae": 0.4425426968889624,
            "precision": 0.5440289505428226,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6711365276459271,
            "auditor_fn_violation": 0.004785942844532715,
            "auditor_fp_violation": 0.00225347852389596,
            "ave_precision_score": 0.6585709342210372,
            "fpr": 0.4298245614035088,
            "logloss": 7.7884782153540915,
            "mae": 0.46557424021394517,
            "precision": 0.5311004784688995,
            "recall": 0.9308176100628931
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6555540685552402,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.009737615523529631,
            "ave_precision_score": 0.6434187143655137,
            "fpr": 0.4149286498353458,
            "logloss": 7.574980472444746,
            "mae": 0.44247512511181136,
            "precision": 0.5440289505428226,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.791664682313892,
            "auditor_fn_violation": 0.023768803560263344,
            "auditor_fp_violation": 0.024364791288566244,
            "ave_precision_score": 0.7920299490904472,
            "fpr": 0.16228070175438597,
            "logloss": 3.0412197967996266,
            "mae": 0.33552753686988873,
            "precision": 0.701010101010101,
            "recall": 0.7274633123689728
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7891863437712267,
            "auditor_fn_violation": 0.023672928359878224,
            "auditor_fp_violation": 0.030338363170061767,
            "ave_precision_score": 0.7892759965448717,
            "fpr": 0.17453347969264543,
            "logloss": 3.5340714909191373,
            "mae": 0.34846548206633393,
            "precision": 0.6826347305389222,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7774320797010579,
            "auditor_fn_violation": 0.0174174298429512,
            "auditor_fp_violation": 0.01626335954829604,
            "ave_precision_score": 0.7776834403334478,
            "fpr": 0.21271929824561403,
            "logloss": 2.404408608239441,
            "mae": 0.3270518350165625,
            "precision": 0.6655172413793103,
            "recall": 0.8092243186582809
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7780627227961472,
            "auditor_fn_violation": 0.008277585623649455,
            "auditor_fp_violation": 0.027351317992584244,
            "ave_precision_score": 0.7782404122864914,
            "fpr": 0.22502744237102085,
            "logloss": 2.6700828786927824,
            "mae": 0.33284144219871176,
            "precision": 0.6507666098807495,
            "recall": 0.80083857442348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6606754839612521,
            "auditor_fn_violation": 0.005896226415094342,
            "auditor_fp_violation": 0.004048195200645298,
            "ave_precision_score": 0.6550585628379886,
            "fpr": 0.42543859649122806,
            "logloss": 6.951483881493993,
            "mae": 0.46434482788307624,
            "precision": 0.5319662243667069,
            "recall": 0.9245283018867925
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6298819602250195,
            "auditor_fn_violation": 0.009870048579325138,
            "auditor_fp_violation": 0.011467623060696973,
            "ave_precision_score": 0.633452986448312,
            "fpr": 0.4105378704720088,
            "logloss": 6.797024864995857,
            "mae": 0.43870712749651836,
            "precision": 0.5466666666666666,
            "recall": 0.9454926624737946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8057876544964296,
            "auditor_fn_violation": 0.021325260215528344,
            "auditor_fp_violation": 0.014637527727364387,
            "ave_precision_score": 0.8062933558032761,
            "fpr": 0.18201754385964913,
            "logloss": 2.0846685257390525,
            "mae": 0.3019917739921693,
            "precision": 0.6959706959706959,
            "recall": 0.7966457023060797
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8015367524365862,
            "auditor_fn_violation": 0.014389697777225482,
            "auditor_fp_violation": 0.022669674788934023,
            "ave_precision_score": 0.8017022888531264,
            "fpr": 0.1986827661909989,
            "logloss": 1.8479922946244753,
            "mae": 0.3070454174498114,
            "precision": 0.6807760141093474,
            "recall": 0.8092243186582809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7916998284646546,
            "auditor_fn_violation": 0.026170969877524004,
            "auditor_fp_violation": 0.023585904416212944,
            "ave_precision_score": 0.7920637523625165,
            "fpr": 0.17653508771929824,
            "logloss": 3.0414005866529434,
            "mae": 0.339583378667765,
            "precision": 0.685546875,
            "recall": 0.7358490566037735
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7891777897669335,
            "auditor_fn_violation": 0.023672928359878224,
            "auditor_fp_violation": 0.03085938883184023,
            "ave_precision_score": 0.7892682655827692,
            "fpr": 0.18331503841931943,
            "logloss": 3.529974885080982,
            "mae": 0.35204014700316555,
            "precision": 0.6719056974459725,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7916998284646546,
            "auditor_fn_violation": 0.026170969877524004,
            "auditor_fp_violation": 0.023585904416212944,
            "ave_precision_score": 0.7920637523625165,
            "fpr": 0.17653508771929824,
            "logloss": 3.041402059413707,
            "mae": 0.33958402541663163,
            "precision": 0.685546875,
            "recall": 0.7358490566037735
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7891777897669335,
            "auditor_fn_violation": 0.023672928359878224,
            "auditor_fp_violation": 0.03085938883184023,
            "ave_precision_score": 0.7892682655827692,
            "fpr": 0.18331503841931943,
            "logloss": 3.529975926973483,
            "mae": 0.3520407584171226,
            "precision": 0.6719056974459725,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7762100351342551,
            "auditor_fn_violation": 0.023102173673176653,
            "auditor_fp_violation": 0.010052429925388186,
            "ave_precision_score": 0.7768336271843284,
            "fpr": 0.09100877192982457,
            "logloss": 3.2941483691073836,
            "mae": 0.32175784161482823,
            "precision": 0.773224043715847,
            "recall": 0.5932914046121593
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7575887130078335,
            "auditor_fn_violation": 0.019438633795653866,
            "auditor_fp_violation": 0.01465953755178641,
            "ave_precision_score": 0.7578003373602598,
            "fpr": 0.11086717892425905,
            "logloss": 3.817972729647723,
            "mae": 0.3489410343185668,
            "precision": 0.7335092348284961,
            "recall": 0.5828092243186582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7496544946840573,
            "auditor_fn_violation": 0.010318970907352249,
            "auditor_fp_violation": 0.023101935874168186,
            "ave_precision_score": 0.7505119949987583,
            "fpr": 0.1524122807017544,
            "logloss": 0.5998443544045953,
            "mae": 0.3884648294169573,
            "precision": 0.7048832271762208,
            "recall": 0.6960167714884696
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7817532073052673,
            "auditor_fn_violation": 0.006178848317903473,
            "auditor_fp_violation": 0.027624477077400136,
            "ave_precision_score": 0.7822985763891785,
            "fpr": 0.14270032930845225,
            "logloss": 0.5753436624569689,
            "mae": 0.3783040034424199,
            "precision": 0.721030042918455,
            "recall": 0.7044025157232704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6982780869055073,
            "auditor_fn_violation": 0.016576096950972823,
            "auditor_fp_violation": 0.03585148215366001,
            "ave_precision_score": 0.7001832640287953,
            "fpr": 0.14144736842105263,
            "logloss": 0.6501235182018439,
            "mae": 0.41205985621612645,
            "precision": 0.7048054919908466,
            "recall": 0.6457023060796646
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7473264324815796,
            "auditor_fn_violation": 0.011082805772448093,
            "auditor_fp_violation": 0.01947523104705924,
            "ave_precision_score": 0.7483534421929878,
            "fpr": 0.12294182217343579,
            "logloss": 0.601391382788463,
            "mae": 0.39034916011925325,
            "precision": 0.7454545454545455,
            "recall": 0.6876310272536688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7886553453655587,
            "auditor_fn_violation": 0.020688513737173134,
            "auditor_fp_violation": 0.01689604759023997,
            "ave_precision_score": 0.7890002160269777,
            "fpr": 0.08114035087719298,
            "logloss": 3.153010871906785,
            "mae": 0.332000775769305,
            "precision": 0.7867435158501441,
            "recall": 0.5723270440251572
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7834581088491508,
            "auditor_fn_violation": 0.02442083364975481,
            "auditor_fp_violation": 0.018111964873765096,
            "ave_precision_score": 0.7835526665377498,
            "fpr": 0.10208562019758508,
            "logloss": 3.6686692929942515,
            "mae": 0.3450840792420456,
            "precision": 0.7526595744680851,
            "recall": 0.5932914046121593
        }
    }
]