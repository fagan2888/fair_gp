[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6081745340887655,
            "auditor_fn_violation": 0.0026365322958319818,
            "auditor_fp_violation": 0.004664602683178535,
            "ave_precision_score": 0.6162635664836493,
            "fpr": 0.02850877192982456,
            "logloss": 0.7013848695557156,
            "mae": 0.4998930240452497,
            "precision": 0.5517241379310345,
            "recall": 0.06570841889117043
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5674946556792646,
            "auditor_fn_violation": 0.0027924228499166697,
            "auditor_fp_violation": 0.0023733942504524314,
            "ave_precision_score": 0.5815651184512467,
            "fpr": 0.03732162458836443,
            "logloss": 0.6903987448262632,
            "mae": 0.49734591208709505,
            "precision": 0.4603174603174603,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7767995288829421,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.66388404867969,
            "fpr": 0.10307017543859649,
            "logloss": 0.6432423794955815,
            "mae": 0.43174777706072,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7482878875789296,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.02207256652920759,
            "ave_precision_score": 0.6282973167357525,
            "fpr": 0.11855104281009879,
            "logloss": 0.6665918055076031,
            "mae": 0.4414745059220118,
            "precision": 0.7096774193548387,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7654618208600694,
            "auditor_fn_violation": 0.0211620555495515,
            "auditor_fp_violation": 0.014600103199174404,
            "ave_precision_score": 0.7109873163892193,
            "fpr": 0.10855263157894737,
            "logloss": 0.6200360247988645,
            "mae": 0.4112045674575303,
            "precision": 0.7518796992481203,
            "recall": 0.6160164271047228
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.726717202680483,
            "auditor_fn_violation": 0.007965926799972732,
            "auditor_fp_violation": 0.013624766369003477,
            "ave_precision_score": 0.6784652292572453,
            "fpr": 0.12843029637760703,
            "logloss": 0.6277523866026947,
            "mae": 0.41896516929540745,
            "precision": 0.7111111111111111,
            "recall": 0.6167023554603854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6950819134155263,
            "mae": 0.5008212350831743,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940492145618171,
            "mae": 0.5003049861390295,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7859395771585943,
            "auditor_fn_violation": 0.019511689902374004,
            "auditor_fp_violation": 0.020485036119711045,
            "ave_precision_score": 0.7416797030244242,
            "fpr": 0.12719298245614036,
            "logloss": 1.0890366933193036,
            "mae": 0.352016275610487,
            "precision": 0.7257683215130024,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7513923880057375,
            "auditor_fn_violation": 0.007197305358960318,
            "auditor_fp_violation": 0.014504900070212922,
            "ave_precision_score": 0.7117542729476392,
            "fpr": 0.145993413830955,
            "logloss": 1.09315464307502,
            "mae": 0.3517061757878071,
            "precision": 0.691415313225058,
            "recall": 0.6381156316916489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7859395771585943,
            "auditor_fn_violation": 0.019511689902374004,
            "auditor_fp_violation": 0.020485036119711045,
            "ave_precision_score": 0.7416797030244242,
            "fpr": 0.12719298245614036,
            "logloss": 1.0955377143655183,
            "mae": 0.3511425104113163,
            "precision": 0.7257683215130024,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7513923880057375,
            "auditor_fn_violation": 0.007197305358960318,
            "auditor_fp_violation": 0.014504900070212922,
            "ave_precision_score": 0.7117542729476392,
            "fpr": 0.145993413830955,
            "logloss": 1.1000864469576004,
            "mae": 0.3509695869273192,
            "precision": 0.691415313225058,
            "recall": 0.6381156316916489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 5740,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6982971657169036,
            "auditor_fn_violation": 0.023172664721351634,
            "auditor_fp_violation": 0.014024767801857588,
            "ave_precision_score": 0.682282011057526,
            "fpr": 0.10526315789473684,
            "logloss": 0.6480300343290167,
            "mae": 0.42847326991886003,
            "precision": 0.7453580901856764,
            "recall": 0.5770020533880903
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6644884614340703,
            "auditor_fn_violation": 0.008224484471261322,
            "auditor_fp_violation": 0.01466559863925397,
            "ave_precision_score": 0.6428936397557,
            "fpr": 0.12294182217343579,
            "logloss": 0.6609341422429812,
            "mae": 0.43638426371718836,
            "precision": 0.7044854881266491,
            "recall": 0.5717344753747323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7905089936180234,
            "auditor_fn_violation": 0.01908615223891351,
            "auditor_fp_violation": 0.02062693498452013,
            "ave_precision_score": 0.7210500262925988,
            "fpr": 0.1425438596491228,
            "logloss": 0.9792245675884242,
            "mae": 0.3529084575958111,
            "precision": 0.7155361050328227,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.761203840292065,
            "auditor_fn_violation": 0.011841941345017004,
            "auditor_fp_violation": 0.02026779798459273,
            "ave_precision_score": 0.6879415343501369,
            "fpr": 0.15697036223929747,
            "logloss": 0.989643028840594,
            "mae": 0.3531126560405373,
            "precision": 0.6898047722342733,
            "recall": 0.6809421841541756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7736601918703495,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.6557635622971452,
            "fpr": 0.10307017543859649,
            "logloss": 0.6354593141357282,
            "mae": 0.4361651008458514,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7489099822747722,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.02207256652920759,
            "ave_precision_score": 0.6240201441447644,
            "fpr": 0.11855104281009879,
            "logloss": 0.6551748280129822,
            "mae": 0.44467243781204935,
            "precision": 0.7096774193548387,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.4229622069708354,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10148348813209496,
            "ave_precision_score": 0.5531685337262798,
            "fpr": 0.30701754385964913,
            "logloss": 0.6950193914701683,
            "mae": 0.49616130251352414,
            "precision": 0.5618153364632238,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5238773417072734,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.1067953244133266,
            "ave_precision_score": 0.554090763845119,
            "fpr": 0.28869374313940727,
            "logloss": 0.6825987383525919,
            "mae": 0.4932092819025198,
            "precision": 0.5695581014729951,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.718350246879745,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5541324670060306,
            "fpr": 0.3092105263157895,
            "logloss": 0.6885581035088905,
            "mae": 0.49681075838835614,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7192522734903336,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5539749869369395,
            "fpr": 0.2897914379802415,
            "logloss": 0.6866398692430355,
            "mae": 0.495888856907184,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8508052562467147,
            "auditor_fn_violation": 0.02845698692316006,
            "auditor_fp_violation": 0.025825593395252838,
            "ave_precision_score": 0.8512257261360172,
            "fpr": 0.14802631578947367,
            "logloss": 0.6224351712601568,
            "mae": 0.27555975429417184,
            "precision": 0.7462406015037594,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8517734451451371,
            "auditor_fn_violation": 0.026840636804039145,
            "auditor_fp_violation": 0.03806331029163083,
            "ave_precision_score": 0.8520839062876173,
            "fpr": 0.15806805708013172,
            "logloss": 0.596390860057064,
            "mae": 0.2691585820266622,
            "precision": 0.7298311444652908,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.6098952307119136,
            "auditor_fn_violation": 0.005493713750495352,
            "auditor_fp_violation": 0.006470588235294118,
            "ave_precision_score": 0.6193288990899459,
            "fpr": 0.01206140350877193,
            "logloss": 0.6965212426468356,
            "mae": 0.5006413326126551,
            "precision": 0.47619047619047616,
            "recall": 0.02053388090349076
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5662067628935865,
            "auditor_fn_violation": 0.006181878868081541,
            "auditor_fp_violation": 0.006422998190286884,
            "ave_precision_score": 0.5824197783431351,
            "fpr": 0.014270032930845226,
            "logloss": 0.6955121305912505,
            "mae": 0.5003033030807925,
            "precision": 0.43478260869565216,
            "recall": 0.021413276231263382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6949622645590837,
            "mae": 0.5007768061600233,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939854548636208,
            "mae": 0.5002884863498575,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7787396042836292,
            "auditor_fn_violation": 0.01875067545660867,
            "auditor_fp_violation": 0.019174406604747167,
            "ave_precision_score": 0.7189618259965278,
            "fpr": 0.13486842105263158,
            "logloss": 1.01073794733986,
            "mae": 0.3560634576142388,
            "precision": 0.7172413793103448,
            "recall": 0.6406570841889117
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7551172030266449,
            "auditor_fn_violation": 0.012413118746136334,
            "auditor_fp_violation": 0.014789212923131697,
            "ave_precision_score": 0.691486119408599,
            "fpr": 0.15148188803512624,
            "logloss": 1.018194549375333,
            "mae": 0.3550180252292577,
            "precision": 0.6905829596412556,
            "recall": 0.6595289079229122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7902966655050807,
            "auditor_fn_violation": 0.022121203933859288,
            "auditor_fp_violation": 0.015291537667698661,
            "ave_precision_score": 0.7218694589143227,
            "fpr": 0.10855263157894737,
            "logloss": 0.9990883361259126,
            "mae": 0.35587713781105296,
            "precision": 0.7474489795918368,
            "recall": 0.6016427104722792
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7610985743378905,
            "auditor_fn_violation": 0.006005589546748412,
            "auditor_fp_violation": 0.016771986036530497,
            "ave_precision_score": 0.6882057130297361,
            "fpr": 0.12733260153677278,
            "logloss": 1.007101252610494,
            "mae": 0.35566951775535277,
            "precision": 0.7092731829573935,
            "recall": 0.6059957173447538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.6392898739164968,
            "auditor_fn_violation": 0.0026365322958319818,
            "auditor_fp_violation": 0.0010319917440660472,
            "ave_precision_score": 0.6661890293807826,
            "fpr": 0.027412280701754384,
            "logloss": 0.6956914825372589,
            "mae": 0.5003848172920704,
            "precision": 0.5614035087719298,
            "recall": 0.06570841889117043
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.5978855456856548,
            "auditor_fn_violation": 0.0027924228499166697,
            "auditor_fp_violation": 0.0037282068017523567,
            "ave_precision_score": 0.6369521317988346,
            "fpr": 0.038419319429198684,
            "logloss": 0.6950198857878818,
            "mae": 0.5002137423870385,
            "precision": 0.453125,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.6908652006604521,
            "mae": 0.4986832115080273,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6892300065656989,
            "mae": 0.49786432815304704,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.691884218646494,
            "auditor_fn_violation": 0.003989697035195824,
            "auditor_fp_violation": 0.001566047471620227,
            "ave_precision_score": 0.6725076046144743,
            "fpr": 0.0043859649122807015,
            "logloss": 1.326954868847841,
            "mae": 0.4888664118255276,
            "precision": 0.8787878787878788,
            "recall": 0.059548254620123205
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.661157772440839,
            "auditor_fn_violation": 0.0006393426053681379,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.6502687380101848,
            "fpr": 0.0021953896816684962,
            "logloss": 1.2657734746535985,
            "mae": 0.473792544871765,
            "precision": 0.9285714285714286,
            "recall": 0.055674518201284794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7567747510194256,
            "auditor_fn_violation": 0.010564141359559074,
            "auditor_fp_violation": 0.007835397316821464,
            "ave_precision_score": 0.7573024443936829,
            "fpr": 0.09539473684210527,
            "logloss": 1.2203097449375402,
            "mae": 0.38148790249878256,
            "precision": 0.7238095238095238,
            "recall": 0.4681724845995893
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7699621577112552,
            "auditor_fn_violation": 0.016122246066985244,
            "auditor_fp_violation": 0.015474036055814322,
            "ave_precision_score": 0.7704151565152708,
            "fpr": 0.09330406147091108,
            "logloss": 1.1218303482786645,
            "mae": 0.34779330567608063,
            "precision": 0.7368421052631579,
            "recall": 0.5096359743040685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.4229622069708354,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10148348813209496,
            "ave_precision_score": 0.5531685337262798,
            "fpr": 0.30701754385964913,
            "logloss": 0.694988166611846,
            "mae": 0.49616114172162623,
            "precision": 0.5618153364632238,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5238773417072734,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.1067953244133266,
            "ave_precision_score": 0.554090763845119,
            "fpr": 0.28869374313940727,
            "logloss": 0.6826251680058544,
            "mae": 0.4932259872537395,
            "precision": 0.5695581014729951,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8553797288010737,
            "auditor_fn_violation": 0.01487355452285745,
            "auditor_fp_violation": 0.01921310629514965,
            "ave_precision_score": 0.8556953488792189,
            "fpr": 0.16228070175438597,
            "logloss": 0.7011546947291366,
            "mae": 0.2610663357891395,
            "precision": 0.7328519855595668,
            "recall": 0.8336755646817249
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8505514701593506,
            "auditor_fn_violation": 0.010520946697160805,
            "auditor_fp_violation": 0.02346693565134839,
            "ave_precision_score": 0.850828141359024,
            "fpr": 0.1668496158068057,
            "logloss": 0.7171238606197261,
            "mae": 0.2607822582495327,
            "precision": 0.7190388170055453,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7859395771585943,
            "auditor_fn_violation": 0.021835260636190065,
            "auditor_fp_violation": 0.015291537667698661,
            "ave_precision_score": 0.7416797030244242,
            "fpr": 0.10855263157894737,
            "logloss": 1.189910888087001,
            "mae": 0.3810236410239121,
            "precision": 0.7512562814070352,
            "recall": 0.6139630390143738
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7513923880057375,
            "auditor_fn_violation": 0.007143243300418163,
            "auditor_fp_violation": 0.016858516035244908,
            "ave_precision_score": 0.7117542729476392,
            "fpr": 0.12843029637760703,
            "logloss": 1.1795230391704954,
            "mae": 0.37867989667482826,
            "precision": 0.7111111111111111,
            "recall": 0.6167023554603854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.600062510706063,
            "auditor_fn_violation": 0.010071058035231823,
            "auditor_fp_violation": 0.005430856553147575,
            "ave_precision_score": 0.6136998958784927,
            "fpr": 0.01644736842105263,
            "logloss": 0.6960734924741071,
            "mae": 0.4994051207505268,
            "precision": 0.5833333333333334,
            "recall": 0.043121149897330596
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5779959032741523,
            "auditor_fn_violation": 0.009110632126495809,
            "auditor_fp_violation": 0.010442934701990685,
            "ave_precision_score": 0.5977768161303505,
            "fpr": 0.026344676180021953,
            "logloss": 0.6914927104006552,
            "mae": 0.49710853321112397,
            "precision": 0.4418604651162791,
            "recall": 0.04068522483940043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6436947373568367,
            "auditor_fn_violation": 0.022091934147483703,
            "auditor_fp_violation": 0.01519349845201238,
            "ave_precision_score": 0.6550830265959942,
            "fpr": 0.1337719298245614,
            "logloss": 0.6779947362041095,
            "mae": 0.42619069227785394,
            "precision": 0.7122641509433962,
            "recall": 0.6201232032854209
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6450209129945115,
            "auditor_fn_violation": 0.008600568356771981,
            "auditor_fp_violation": 0.016870877463632677,
            "ave_precision_score": 0.6334084126888432,
            "fpr": 0.14928649835345773,
            "logloss": 0.6863773887279935,
            "mae": 0.4290879597779032,
            "precision": 0.682983682983683,
            "recall": 0.6274089935760171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7905089936180234,
            "auditor_fn_violation": 0.01908615223891351,
            "auditor_fp_violation": 0.02062693498452013,
            "ave_precision_score": 0.7210500262925988,
            "fpr": 0.1425438596491228,
            "logloss": 1.0103632880103832,
            "mae": 0.35360417853058734,
            "precision": 0.7155361050328227,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.761203840292065,
            "auditor_fn_violation": 0.011841941345017004,
            "auditor_fp_violation": 0.02026779798459273,
            "ave_precision_score": 0.6879415343501369,
            "fpr": 0.15697036223929747,
            "logloss": 1.0199768852106186,
            "mae": 0.35366519255893053,
            "precision": 0.6898047722342733,
            "recall": 0.6809421841541756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005598555211558308,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6952694474306873,
            "mae": 0.5009134652648579,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939198778050633,
            "mae": 0.5002722736247677,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 5740,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.601252989092296,
            "auditor_fn_violation": 0.0035529017615908488,
            "auditor_fp_violation": 3.3539731682147405e-05,
            "ave_precision_score": 0.6155928788356422,
            "fpr": 0.02850877192982456,
            "logloss": 0.6953346454967737,
            "mae": 0.49917509445356045,
            "precision": 0.543859649122807,
            "recall": 0.06365503080082136
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.578257993938268,
            "auditor_fn_violation": 0.0027924228499166697,
            "auditor_fp_violation": 0.004123772510161096,
            "ave_precision_score": 0.5988733265969559,
            "fpr": 0.03951701427003293,
            "logloss": 0.6910288748100623,
            "mae": 0.4970148485564953,
            "precision": 0.4461538461538462,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005598555211558308,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6955934768361934,
            "mae": 0.5010349153492012,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940826885206357,
            "mae": 0.500315191913253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.691011345728949,
            "mae": 0.4987851738799037,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6895655280307096,
            "mae": 0.49806173585772384,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7271318186837856,
            "auditor_fn_violation": 0.008949800064843841,
            "auditor_fp_violation": 0.012850877192982458,
            "ave_precision_score": 0.6898614647899287,
            "fpr": 0.09429824561403509,
            "logloss": 1.0213538939089815,
            "mae": 0.39620786632791316,
            "precision": 0.696113074204947,
            "recall": 0.40451745379876797
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6984115796736592,
            "auditor_fn_violation": 0.0025902777614546894,
            "auditor_fp_violation": 0.008403299018008127,
            "ave_precision_score": 0.6541937371747029,
            "fpr": 0.11964873765093303,
            "logloss": 1.0188090417671898,
            "mae": 0.39704894720039735,
            "precision": 0.6472491909385113,
            "recall": 0.4282655246252677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7821248797144148,
            "auditor_fn_violation": 0.017726232933463024,
            "auditor_fp_violation": 0.02078947368421053,
            "ave_precision_score": 0.72762498842243,
            "fpr": 0.14912280701754385,
            "logloss": 3.170336346291318,
            "mae": 0.32756289460640153,
            "precision": 0.7100213219616205,
            "recall": 0.6837782340862423
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7688070702323165,
            "auditor_fn_violation": 0.006219487256632599,
            "auditor_fp_violation": 0.014121695790191957,
            "ave_precision_score": 0.7057326777740168,
            "fpr": 0.1712403951701427,
            "logloss": 3.543813066077687,
            "mae": 0.327791459205578,
            "precision": 0.6829268292682927,
            "recall": 0.7194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8463115321703432,
            "auditor_fn_violation": 0.009568968622789008,
            "auditor_fp_violation": 0.018588751289989682,
            "ave_precision_score": 0.8466226319151952,
            "fpr": 0.1699561403508772,
            "logloss": 0.7351611370451426,
            "mae": 0.26627021630509723,
            "precision": 0.7309027777777778,
            "recall": 0.864476386036961
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.836266379905376,
            "auditor_fn_violation": 0.009312777214957801,
            "auditor_fp_violation": 0.021484162537949592,
            "ave_precision_score": 0.836581271428432,
            "fpr": 0.18660812294182216,
            "logloss": 0.7722737111443785,
            "mae": 0.27538433008829194,
            "precision": 0.702276707530648,
            "recall": 0.8586723768736617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5379720971898799,
            "auditor_fn_violation": 0.010071058035231823,
            "auditor_fp_violation": 0.005430856553147575,
            "ave_precision_score": 0.5418603035312197,
            "fpr": 0.01644736842105263,
            "logloss": 0.696135848130604,
            "mae": 0.4994353515698994,
            "precision": 0.5833333333333334,
            "recall": 0.043121149897330596
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.4890267671529116,
            "auditor_fn_violation": 0.009110632126495809,
            "auditor_fp_violation": 0.010383599845729376,
            "ave_precision_score": 0.5178352816836679,
            "fpr": 0.026344676180021953,
            "logloss": 0.6915855052756964,
            "mae": 0.49716302107340427,
            "precision": 0.4418604651162791,
            "recall": 0.04068522483940043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7860308102029391,
            "auditor_fn_violation": 0.019511689902374004,
            "auditor_fp_violation": 0.020485036119711045,
            "ave_precision_score": 0.742063382901324,
            "fpr": 0.12719298245614036,
            "logloss": 0.9506048206488168,
            "mae": 0.35386105240646876,
            "precision": 0.7257683215130024,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7517355582340907,
            "auditor_fn_violation": 0.007197305358960318,
            "auditor_fp_violation": 0.014504900070212922,
            "ave_precision_score": 0.7123326825283082,
            "fpr": 0.145993413830955,
            "logloss": 0.9549059314874802,
            "mae": 0.3534612745366981,
            "precision": 0.691415313225058,
            "recall": 0.6381156316916489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 5740,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6123348814720029,
            "auditor_fn_violation": 0.11824768543535431,
            "auditor_fp_violation": 0.10280443756449949,
            "ave_precision_score": 0.6267730428254021,
            "fpr": 0.21820175438596492,
            "logloss": 0.7269404578678228,
            "mae": 0.4941860122901399,
            "precision": 0.5350467289719626,
            "recall": 0.4702258726899384
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5955788049443609,
            "auditor_fn_violation": 0.11452694523513472,
            "auditor_fp_violation": 0.09965289109087135,
            "ave_precision_score": 0.6102614284913256,
            "fpr": 0.2349066959385291,
            "logloss": 0.7339707831821469,
            "mae": 0.4976825699776833,
            "precision": 0.5057736720554272,
            "recall": 0.4689507494646681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6950513816700163,
            "mae": 0.5008099581719491,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940328688814844,
            "mae": 0.5003007981766723,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8502486183876123,
            "auditor_fn_violation": 0.016384325804243673,
            "auditor_fp_violation": 0.020975232198142423,
            "ave_precision_score": 0.8505658117943119,
            "fpr": 0.14802631578947367,
            "logloss": 0.9451793584719509,
            "mae": 0.26843957088507664,
            "precision": 0.7423664122137404,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8461659789009168,
            "auditor_fn_violation": 0.006313508228010258,
            "auditor_fp_violation": 0.01958297485191009,
            "ave_precision_score": 0.8464431340471279,
            "fpr": 0.1525795828759605,
            "logloss": 0.9518914397697432,
            "mae": 0.26746813907456557,
            "precision": 0.7295719844357976,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.718350246879745,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.5541324670060306,
            "fpr": 0.3092105263157895,
            "logloss": 0.6881373217382581,
            "mae": 0.49626878910420236,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7192522734903336,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5539749869369395,
            "fpr": 0.2897914379802415,
            "logloss": 0.6856128680322786,
            "mae": 0.4950531466601316,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8484512543854841,
            "auditor_fn_violation": 0.03348238409164595,
            "auditor_fp_violation": 0.02745098039215687,
            "ave_precision_score": 0.8488251391121676,
            "fpr": 0.15350877192982457,
            "logloss": 0.6381793817219171,
            "mae": 0.28033760950167635,
            "precision": 0.7378277153558053,
            "recall": 0.8090349075975359
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8469821781616133,
            "auditor_fn_violation": 0.030044401403733104,
            "auditor_fp_violation": 0.04004361111935208,
            "ave_precision_score": 0.84734456249153,
            "fpr": 0.15477497255762898,
            "logloss": 0.6114857394152241,
            "mae": 0.27316914972357825,
            "precision": 0.7324478178368121,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8606705028400905,
            "auditor_fn_violation": 0.012835927086710618,
            "auditor_fp_violation": 0.021627966976264193,
            "ave_precision_score": 0.8610505427044606,
            "fpr": 0.14692982456140352,
            "logloss": 0.5297688514556831,
            "mae": 0.2809187865467832,
            "precision": 0.7462121212121212,
            "recall": 0.8090349075975359
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8630769550579567,
            "auditor_fn_violation": 0.010229481685890034,
            "auditor_fp_violation": 0.02147427339523937,
            "ave_precision_score": 0.8633703802526884,
            "fpr": 0.15916575192096596,
            "logloss": 0.5153089247268101,
            "mae": 0.2750460752389526,
            "precision": 0.7304832713754646,
            "recall": 0.841541755888651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6868810656118802,
            "auditor_fn_violation": 0.005786411614251243,
            "auditor_fp_violation": 0.016901444788441695,
            "ave_precision_score": 0.6783916691685806,
            "fpr": 0.11842105263157894,
            "logloss": 9.269060926923443,
            "mae": 0.43732030675665845,
            "precision": 0.6504854368932039,
            "recall": 0.4127310061601643
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6647439828201696,
            "auditor_fn_violation": 0.011724415130794934,
            "auditor_fp_violation": 0.01605996776139476,
            "ave_precision_score": 0.655272254645934,
            "fpr": 0.1141602634467618,
            "logloss": 8.981221282146883,
            "mae": 0.4269970229391744,
            "precision": 0.6298932384341637,
            "recall": 0.37901498929336186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7628427363480188,
            "auditor_fn_violation": 0.007612395979682285,
            "auditor_fp_violation": 0.00023219814241486075,
            "ave_precision_score": 0.7597523142740361,
            "fpr": 0.007675438596491228,
            "logloss": 1.215688824768315,
            "mae": 0.4292438781622127,
            "precision": 0.9345794392523364,
            "recall": 0.2053388090349076
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7825789575594434,
            "auditor_fn_violation": 0.0016406659505402866,
            "auditor_fp_violation": 0.0011520851257404495,
            "ave_precision_score": 0.7529557594672204,
            "fpr": 0.005488474204171241,
            "logloss": 1.1795526423702243,
            "mae": 0.4201038280929137,
            "precision": 0.9404761904761905,
            "recall": 0.16916488222698073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7723288438355458,
            "auditor_fn_violation": 0.0211620555495515,
            "auditor_fp_violation": 0.014600103199174404,
            "ave_precision_score": 0.6979525356493765,
            "fpr": 0.10855263157894737,
            "logloss": 0.60757886313521,
            "mae": 0.4130038529667169,
            "precision": 0.7518796992481203,
            "recall": 0.6160164271047228
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7382352525977166,
            "auditor_fn_violation": 0.007965926799972732,
            "auditor_fp_violation": 0.014808991208552133,
            "ave_precision_score": 0.6691924505166791,
            "fpr": 0.12952799121844127,
            "logloss": 0.6297939182038171,
            "mae": 0.42162738254643506,
            "precision": 0.7093596059113301,
            "recall": 0.6167023554603854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7340580782264385,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.6798599964440175,
            "fpr": 0.10307017543859649,
            "logloss": 0.6470604374561547,
            "mae": 0.4347368707414972,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6907473103228357,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.02207256652920759,
            "ave_precision_score": 0.637629475864901,
            "fpr": 0.11855104281009879,
            "logloss": 0.6572514625488426,
            "mae": 0.44166071559630926,
            "precision": 0.7096774193548387,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.7021194152601673,
            "auditor_fn_violation": 0.0050118880363125545,
            "auditor_fp_violation": 0.0006527347781217751,
            "ave_precision_score": 0.6984581953765151,
            "fpr": 0.003289473684210526,
            "logloss": 1.38082216819825,
            "mae": 0.4923676588662426,
            "precision": 0.9032258064516129,
            "recall": 0.057494866529774126
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.665426962543627,
            "auditor_fn_violation": 0.0018898215246911025,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.6677160901119243,
            "fpr": 0.0021953896816684962,
            "logloss": 1.319965156697407,
            "mae": 0.4787998375008049,
            "precision": 0.92,
            "recall": 0.04925053533190578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 5740,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6900042315659409,
            "auditor_fn_violation": 0.004590853416909842,
            "auditor_fp_violation": 0.001566047471620227,
            "ave_precision_score": 0.6667106507808797,
            "fpr": 0.0043859649122807015,
            "logloss": 1.4199445535094124,
            "mae": 0.49838714182413624,
            "precision": 0.8709677419354839,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.658130333004685,
            "auditor_fn_violation": 0.00047950695402612447,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.6456760626158514,
            "fpr": 0.0021953896816684962,
            "logloss": 1.3569515689916516,
            "mae": 0.4820696779786236,
            "precision": 0.9230769230769231,
            "recall": 0.05139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8545896843650866,
            "auditor_fn_violation": 0.014670917540257214,
            "auditor_fp_violation": 0.021357069143446858,
            "ave_precision_score": 0.8549073492887251,
            "fpr": 0.16228070175438597,
            "logloss": 0.7055963267468713,
            "mae": 0.2614105579931421,
            "precision": 0.7318840579710145,
            "recall": 0.8295687885010267
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.850988148383043,
            "auditor_fn_violation": 0.006195982013788175,
            "auditor_fp_violation": 0.0218920896747461,
            "ave_precision_score": 0.8512632045999357,
            "fpr": 0.16355653128430298,
            "logloss": 0.7181241683751987,
            "mae": 0.26053662826073676,
            "precision": 0.7225325884543762,
            "recall": 0.8308351177730193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.6910946229829589,
            "mae": 0.4988416148382321,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6897548719286805,
            "mae": 0.4981715830306714,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.6908056081710578,
            "mae": 0.49864032975675765,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6890894018955919,
            "mae": 0.497780564064252,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.606456485628649,
            "auditor_fn_violation": 0.0026365322958319818,
            "auditor_fp_violation": 0.004664602683178535,
            "ave_precision_score": 0.6196330063667104,
            "fpr": 0.02850877192982456,
            "logloss": 0.7025830034877252,
            "mae": 0.5000067660354321,
            "precision": 0.5517241379310345,
            "recall": 0.06570841889117043
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5618751877464859,
            "auditor_fn_violation": 0.0027924228499166697,
            "auditor_fp_violation": 0.0023733942504524314,
            "ave_precision_score": 0.5820790131923181,
            "fpr": 0.03732162458836443,
            "logloss": 0.6906020619556134,
            "mae": 0.4973937495399383,
            "precision": 0.4603174603174603,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6660328429119529,
            "auditor_fn_violation": 0.009251504016715302,
            "auditor_fp_violation": 0.018209494324045415,
            "ave_precision_score": 0.6674913972102698,
            "fpr": 0.25877192982456143,
            "logloss": 0.9658569234373898,
            "mae": 0.33730945948990954,
            "precision": 0.6445783132530121,
            "recall": 0.8788501026694046
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6378160056945541,
            "auditor_fn_violation": 0.004954905191602987,
            "auditor_fp_violation": 0.020841368261785388,
            "ave_precision_score": 0.6396227875569447,
            "fpr": 0.2645444566410538,
            "logloss": 1.0418923105342945,
            "mae": 0.3399291660577031,
            "precision": 0.6314984709480123,
            "recall": 0.8843683083511777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.6116532685981309,
            "auditor_fn_violation": 0.0051942613206527695,
            "auditor_fp_violation": 0.006470588235294118,
            "ave_precision_score": 0.6248699128096764,
            "fpr": 0.01206140350877193,
            "logloss": 0.6957615391366384,
            "mae": 0.5004158720114656,
            "precision": 0.5,
            "recall": 0.022587268993839837
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5650582877949912,
            "auditor_fn_violation": 0.006181878868081541,
            "auditor_fp_violation": 0.007001513038834665,
            "ave_precision_score": 0.5842670752978727,
            "fpr": 0.015367727771679473,
            "logloss": 0.6950351825502872,
            "mae": 0.5002175243900766,
            "precision": 0.4166666666666667,
            "recall": 0.021413276231263382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8494515403851046,
            "auditor_fn_violation": 0.015540005043409348,
            "auditor_fp_violation": 0.024716202270381845,
            "ave_precision_score": 0.8497706128299494,
            "fpr": 0.15350877192982457,
            "logloss": 0.962201995090929,
            "mae": 0.26889235465287226,
            "precision": 0.7358490566037735,
            "recall": 0.8008213552361396
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.845271734468813,
            "auditor_fn_violation": 0.006313508228010258,
            "auditor_fp_violation": 0.021716557391639732,
            "ave_precision_score": 0.8455528790796598,
            "fpr": 0.1602634467618002,
            "logloss": 0.9708232302450943,
            "mae": 0.2681838856067286,
            "precision": 0.7197696737044146,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005598555211558308,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6955934768361934,
            "mae": 0.5010349153492012,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940826885206357,
            "mae": 0.500315191913253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8441606419709728,
            "auditor_fn_violation": 0.022992542959040317,
            "auditor_fp_violation": 0.014349845201238394,
            "ave_precision_score": 0.8109925229587265,
            "fpr": 0.125,
            "logloss": 1.3897920068636442,
            "mae": 0.3063397719758523,
            "precision": 0.7558886509635975,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.832940112399345,
            "auditor_fn_violation": 0.014173661435183123,
            "auditor_fp_violation": 0.02127896282671255,
            "ave_precision_score": 0.7981463320230489,
            "fpr": 0.1437980241492865,
            "logloss": 1.3743548966145982,
            "mae": 0.3062117465673599,
            "precision": 0.7253668763102725,
            "recall": 0.7408993576017131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 5740,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6900042315659409,
            "auditor_fn_violation": 0.004590853416909842,
            "auditor_fp_violation": 0.001566047471620227,
            "ave_precision_score": 0.6667106507808797,
            "fpr": 0.0043859649122807015,
            "logloss": 1.4199445848665884,
            "mae": 0.4983871429086369,
            "precision": 0.8709677419354839,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6580207276395058,
            "auditor_fn_violation": 0.00047950695402612447,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.6454715620206088,
            "fpr": 0.0021953896816684962,
            "logloss": 1.3569817965463935,
            "mae": 0.48209946522638447,
            "precision": 0.9230769230769231,
            "recall": 0.05139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.845612654890841,
            "auditor_fn_violation": 0.014463777513599197,
            "auditor_fp_violation": 0.022561919504643965,
            "ave_precision_score": 0.845966673189865,
            "fpr": 0.14802631578947367,
            "logloss": 0.6793756881993107,
            "mae": 0.26873416702699343,
            "precision": 0.7462406015037594,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8395136073935813,
            "auditor_fn_violation": 0.002935804831267617,
            "auditor_fp_violation": 0.022262932526379293,
            "ave_precision_score": 0.8398219723612809,
            "fpr": 0.15697036223929747,
            "logloss": 0.6955288857436399,
            "mae": 0.2667544632803727,
            "precision": 0.7286527514231499,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7561182272820156,
            "auditor_fn_violation": 0.009917954537267189,
            "auditor_fp_violation": 0.010536635706914349,
            "ave_precision_score": 0.7566445885405652,
            "fpr": 0.09978070175438597,
            "logloss": 1.221097250754885,
            "mae": 0.38081402542459847,
            "precision": 0.715625,
            "recall": 0.4702258726899384
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7702721717264004,
            "auditor_fn_violation": 0.016655815079553504,
            "auditor_fp_violation": 0.015540787769108295,
            "ave_precision_score": 0.7707125951695023,
            "fpr": 0.09440175631174534,
            "logloss": 1.1222071552421613,
            "mae": 0.3464403465381682,
            "precision": 0.7353846153846154,
            "recall": 0.5117773019271948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 5740,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6982971657169036,
            "auditor_fn_violation": 0.023172664721351634,
            "auditor_fp_violation": 0.014024767801857588,
            "ave_precision_score": 0.682282011057526,
            "fpr": 0.10526315789473684,
            "logloss": 0.6475548468788983,
            "mae": 0.42856485067314726,
            "precision": 0.7453580901856764,
            "recall": 0.5770020533880903
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6644884614340703,
            "auditor_fn_violation": 0.008224484471261322,
            "auditor_fp_violation": 0.01466559863925397,
            "ave_precision_score": 0.6428936397557,
            "fpr": 0.12294182217343579,
            "logloss": 0.6610481451841896,
            "mae": 0.4364847074828965,
            "precision": 0.7044854881266491,
            "recall": 0.5717344753747323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8441606419709728,
            "auditor_fn_violation": 0.022992542959040317,
            "auditor_fp_violation": 0.014349845201238394,
            "ave_precision_score": 0.8109925229587265,
            "fpr": 0.125,
            "logloss": 1.3914549815182555,
            "mae": 0.3061833618120879,
            "precision": 0.7558886509635975,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8326815345232117,
            "auditor_fn_violation": 0.014173661435183123,
            "auditor_fp_violation": 0.022369240810514144,
            "ave_precision_score": 0.7977362753289194,
            "fpr": 0.14489571899012074,
            "logloss": 1.3768548023330902,
            "mae": 0.306398630186446,
            "precision": 0.7238493723849372,
            "recall": 0.7408993576017131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 5740,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8459595902735726,
            "auditor_fn_violation": 0.01551974134514932,
            "auditor_fp_violation": 0.021292569659442723,
            "ave_precision_score": 0.8463649400857725,
            "fpr": 0.12938596491228072,
            "logloss": 0.7059915145435942,
            "mae": 0.26914196278603386,
            "precision": 0.7644710578842315,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8394697756027827,
            "auditor_fn_violation": 0.0032719298039427707,
            "auditor_fp_violation": 0.017273860029074082,
            "ave_precision_score": 0.8397621656189813,
            "fpr": 0.141602634467618,
            "logloss": 0.7182962317900439,
            "mae": 0.2660848102763751,
            "precision": 0.7435387673956262,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 5740,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5257924864265102,
            "auditor_fn_violation": 0.11824768543535431,
            "auditor_fp_violation": 0.10280443756449949,
            "ave_precision_score": 0.5310631146896247,
            "fpr": 0.21820175438596492,
            "logloss": 0.7267416697981712,
            "mae": 0.4942212793729219,
            "precision": 0.5350467289719626,
            "recall": 0.4702258726899384
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5033472825077189,
            "auditor_fn_violation": 0.11452694523513472,
            "auditor_fp_violation": 0.09965289109087135,
            "ave_precision_score": 0.5109468624241985,
            "fpr": 0.2349066959385291,
            "logloss": 0.7338197835986565,
            "mae": 0.4977272767979723,
            "precision": 0.5057736720554272,
            "recall": 0.4689507494646681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7307193406851136,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.7395894023290621,
            "fpr": 0.10307017543859649,
            "logloss": 0.6436918926996581,
            "mae": 0.43441016534501486,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.695563163301149,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.023271625082821577,
            "ave_precision_score": 0.7015322082558585,
            "fpr": 0.11964873765093303,
            "logloss": 0.6528587289666496,
            "mae": 0.44111492333417734,
            "precision": 0.707774798927614,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.77263653615953,
            "auditor_fn_violation": 0.01875067545660867,
            "auditor_fp_violation": 0.019174406604747167,
            "ave_precision_score": 0.7258603617486019,
            "fpr": 0.13486842105263158,
            "logloss": 1.0094096008567344,
            "mae": 0.35269819549597614,
            "precision": 0.7172413793103448,
            "recall": 0.6406570841889117
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7505349835705539,
            "auditor_fn_violation": 0.012413118746136334,
            "auditor_fp_violation": 0.014789212923131697,
            "ave_precision_score": 0.6970905247487997,
            "fpr": 0.15148188803512624,
            "logloss": 1.0188347284648642,
            "mae": 0.3519633902721713,
            "precision": 0.6905829596412556,
            "recall": 0.6595289079229122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6882499677489258,
            "auditor_fn_violation": 0.004716938650527777,
            "auditor_fp_violation": 0.007678018575851394,
            "ave_precision_score": 0.6797565524528586,
            "fpr": 0.05921052631578947,
            "logloss": 9.267139513206427,
            "mae": 0.4279080395999542,
            "precision": 0.76,
            "recall": 0.351129363449692
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6648820264011648,
            "auditor_fn_violation": 0.011534022663755148,
            "auditor_fp_violation": 0.006447721047062429,
            "ave_precision_score": 0.6554099198351674,
            "fpr": 0.0570801317233809,
            "logloss": 8.991201364221714,
            "mae": 0.4193945114557961,
            "precision": 0.7412935323383084,
            "recall": 0.31905781584582443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6892839095892194,
            "auditor_fn_violation": 0.004253125112576106,
            "auditor_fp_violation": 0.013101135190918477,
            "ave_precision_score": 0.6807817033257633,
            "fpr": 0.07894736842105263,
            "logloss": 9.22870996694209,
            "mae": 0.4284472824372694,
            "precision": 0.7209302325581395,
            "recall": 0.38193018480492813
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6657072964080393,
            "auditor_fn_violation": 0.012528294436073976,
            "auditor_fp_violation": 0.008025039309342273,
            "ave_precision_score": 0.6562302513862933,
            "fpr": 0.07244785949506037,
            "logloss": 8.945775679693488,
            "mae": 0.420019292324238,
            "precision": 0.7130434782608696,
            "recall": 0.3511777301927195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 5740,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6982971657169036,
            "auditor_fn_violation": 0.023172664721351634,
            "auditor_fp_violation": 0.014024767801857588,
            "ave_precision_score": 0.682282011057526,
            "fpr": 0.10526315789473684,
            "logloss": 0.6515766589962586,
            "mae": 0.42628607275895647,
            "precision": 0.7453580901856764,
            "recall": 0.5770020533880903
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6644884614340703,
            "auditor_fn_violation": 0.008224484471261322,
            "auditor_fp_violation": 0.01466559863925397,
            "ave_precision_score": 0.6428936397557,
            "fpr": 0.12294182217343579,
            "logloss": 0.6671678793590108,
            "mae": 0.4345067486494859,
            "precision": 0.7044854881266491,
            "recall": 0.5717344753747323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.850455122468116,
            "auditor_fn_violation": 0.016384325804243673,
            "auditor_fp_violation": 0.02405830753353973,
            "ave_precision_score": 0.850788878442769,
            "fpr": 0.1513157894736842,
            "logloss": 0.9437084667304632,
            "mae": 0.26881020104169817,
            "precision": 0.7381404174573055,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8466067779297581,
            "auditor_fn_violation": 0.006313508228010258,
            "auditor_fp_violation": 0.01958297485191009,
            "ave_precision_score": 0.8468806851744766,
            "fpr": 0.1525795828759605,
            "logloss": 0.9506305370419772,
            "mae": 0.2675046532509674,
            "precision": 0.7295719844357976,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 5740,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005598555211558308,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6950398090721646,
            "mae": 0.5008248308706179,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6938092045332575,
            "mae": 0.5002412776392194,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7476068628698311,
            "auditor_fn_violation": 0.010751017687957063,
            "auditor_fp_violation": 0.025673374613003095,
            "ave_precision_score": 0.7484833891234999,
            "fpr": 0.21600877192982457,
            "logloss": 0.9449181260642993,
            "mae": 0.3318496345146804,
            "precision": 0.66890756302521,
            "recall": 0.8172484599589322
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7255706218267238,
            "auditor_fn_violation": 0.010351708948681003,
            "auditor_fp_violation": 0.020663363693001462,
            "ave_precision_score": 0.7273646621363681,
            "fpr": 0.23380900109769484,
            "logloss": 1.0045398912665915,
            "mae": 0.33182094230980846,
            "precision": 0.6455906821963394,
            "recall": 0.8308351177730193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6963711061580224,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.6797123442547705,
            "fpr": 0.10307017543859649,
            "logloss": 0.6426798410883084,
            "mae": 0.4333266063650674,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6642067269556381,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.02207256652920759,
            "ave_precision_score": 0.6420043051022111,
            "fpr": 0.11855104281009879,
            "logloss": 0.6515761932497444,
            "mae": 0.44009623569898965,
            "precision": 0.7096774193548387,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.6909503124548985,
            "mae": 0.4987430575777564,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6894259373728264,
            "mae": 0.49798004085486336,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6877701673372585,
            "auditor_fn_violation": 0.006295255592780717,
            "auditor_fp_violation": 0.01609649122807018,
            "ave_precision_score": 0.6792799036336545,
            "fpr": 0.11951754385964912,
            "logloss": 9.233368127178146,
            "mae": 0.4361316773795989,
            "precision": 0.6495176848874598,
            "recall": 0.41478439425051333
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.665653476770317,
            "auditor_fn_violation": 0.010765401222742747,
            "auditor_fp_violation": 0.017785623164327895,
            "ave_precision_score": 0.6561895028691507,
            "fpr": 0.11525795828759605,
            "logloss": 8.942255711067538,
            "mae": 0.425228027772787,
            "precision": 0.6302816901408451,
            "recall": 0.38329764453961457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8514833939453123,
            "auditor_fn_violation": 0.028765445441118198,
            "auditor_fp_violation": 0.02749226006191951,
            "ave_precision_score": 0.8518660616143726,
            "fpr": 0.14473684210526316,
            "logloss": 0.6252011799811213,
            "mae": 0.275222867922115,
            "precision": 0.75,
            "recall": 0.813141683778234
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8520788760035319,
            "auditor_fn_violation": 0.02613547951870665,
            "auditor_fp_violation": 0.03586792060996233,
            "ave_precision_score": 0.8523884692305675,
            "fpr": 0.15806805708013172,
            "logloss": 0.59996793329838,
            "mae": 0.2686914528538813,
            "precision": 0.7293233082706767,
            "recall": 0.8308351177730193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6883685507528947,
            "auditor_fn_violation": 0.004716938650527777,
            "auditor_fp_violation": 0.005952012383900929,
            "ave_precision_score": 0.6798749926835513,
            "fpr": 0.0581140350877193,
            "logloss": 9.262845698475305,
            "mae": 0.4277679926506155,
            "precision": 0.7633928571428571,
            "recall": 0.351129363449692
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6649914633727685,
            "auditor_fn_violation": 0.011534022663755148,
            "auditor_fp_violation": 0.006447721047062429,
            "ave_precision_score": 0.6555191754621776,
            "fpr": 0.0570801317233809,
            "logloss": 8.986546479922138,
            "mae": 0.41928150315706875,
            "precision": 0.7412935323383084,
            "recall": 0.31905781584582443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8443991159299503,
            "auditor_fn_violation": 0.012867448395115099,
            "auditor_fp_violation": 0.02363777089783282,
            "ave_precision_score": 0.8447521347016786,
            "fpr": 0.16885964912280702,
            "logloss": 0.7135553789806447,
            "mae": 0.2708161489533891,
            "precision": 0.725,
            "recall": 0.8336755646817249
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.838442166433562,
            "auditor_fn_violation": 0.009912160907490416,
            "auditor_fp_violation": 0.02498986362872203,
            "ave_precision_score": 0.8387509348631523,
            "fpr": 0.1756311745334797,
            "logloss": 0.7340601987166268,
            "mae": 0.2693704888137532,
            "precision": 0.7106690777576854,
            "recall": 0.841541755888651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7814416989551323,
            "auditor_fn_violation": 0.016213210130047912,
            "auditor_fp_violation": 0.021155830753353973,
            "ave_precision_score": 0.7269422860620035,
            "fpr": 0.14802631578947367,
            "logloss": 3.1835709574672943,
            "mae": 0.3283397553061345,
            "precision": 0.7096774193548387,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7688491996592397,
            "auditor_fn_violation": 0.007293676854622424,
            "auditor_fp_violation": 0.013310786087954036,
            "ave_precision_score": 0.7057746245708267,
            "fpr": 0.1668496158068057,
            "logloss": 3.545278506331854,
            "mae": 0.3269328702490973,
            "precision": 0.6859504132231405,
            "recall": 0.7109207708779444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6053155067486086,
            "auditor_fn_violation": 0.10994632371483122,
            "auditor_fp_violation": 0.07488390092879257,
            "ave_precision_score": 0.5860515098412648,
            "fpr": 0.14144736842105263,
            "logloss": 0.6912052774912344,
            "mae": 0.49844816431664585,
            "precision": 0.6282420749279539,
            "recall": 0.44763860369609854
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.626366457528688,
            "auditor_fn_violation": 0.1118520485994401,
            "auditor_fp_violation": 0.06775051670770663,
            "ave_precision_score": 0.5877713264567693,
            "fpr": 0.13611416026344675,
            "logloss": 0.6884108416665151,
            "mae": 0.4971714809487863,
            "precision": 0.6242424242424243,
            "recall": 0.4411134903640257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6963711061580224,
            "auditor_fn_violation": 0.02288221837962464,
            "auditor_fp_violation": 0.013511351909184729,
            "ave_precision_score": 0.6797123442547705,
            "fpr": 0.10307017543859649,
            "logloss": 0.6429817928851983,
            "mae": 0.43365496720981245,
            "precision": 0.7473118279569892,
            "recall": 0.5708418891170431
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6642067269556381,
            "auditor_fn_violation": 0.007227862174658059,
            "auditor_fp_violation": 0.02207256652920759,
            "ave_precision_score": 0.6420043051022111,
            "fpr": 0.11855104281009879,
            "logloss": 0.6515310926736666,
            "mae": 0.44038931650240765,
            "precision": 0.7096774193548387,
            "recall": 0.5653104925053534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6949264710948979,
            "mae": 0.5007633897557593,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939665378376376,
            "mae": 0.5002835038333772,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.694902930559887,
            "mae": 0.5007545339564482,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939541368108055,
            "mae": 0.5002802150113391,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7860320192233932,
            "auditor_fn_violation": 0.019511689902374004,
            "auditor_fp_violation": 0.020485036119711045,
            "ave_precision_score": 0.7420645865140881,
            "fpr": 0.12719298245614036,
            "logloss": 0.9390455550943926,
            "mae": 0.35157929732971144,
            "precision": 0.7257683215130024,
            "recall": 0.6303901437371663
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7516479791452629,
            "auditor_fn_violation": 0.007197305358960318,
            "auditor_fp_violation": 0.014504900070212922,
            "ave_precision_score": 0.7122654552266899,
            "fpr": 0.145993413830955,
            "logloss": 0.945582684113649,
            "mae": 0.3513139563982396,
            "precision": 0.691415313225058,
            "recall": 0.6381156316916489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6948278203232275,
            "mae": 0.5007261046322814,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939147863096579,
            "mae": 0.5002696570724608,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6951408017451294,
            "mae": 0.500842871111736,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940808846824611,
            "mae": 0.5003130212180832,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 5740,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6907508804791065,
            "auditor_fn_violation": 0.004590853416909842,
            "auditor_fp_violation": 0.001566047471620227,
            "ave_precision_score": 0.6685504668983678,
            "fpr": 0.0043859649122807015,
            "logloss": 1.4121204060966408,
            "mae": 0.49798438576225745,
            "precision": 0.8709677419354839,
            "recall": 0.055441478439425054
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6585726178278029,
            "auditor_fn_violation": 0.00047950695402612447,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.6464665488968989,
            "fpr": 0.0021953896816684962,
            "logloss": 1.3494448884006298,
            "mae": 0.4817344569889907,
            "precision": 0.9230769230769231,
            "recall": 0.05139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8606400361110005,
            "auditor_fn_violation": 0.014346698368096834,
            "auditor_fp_violation": 0.02072755417956657,
            "ave_precision_score": 0.8610702611946504,
            "fpr": 0.1513157894736842,
            "logloss": 0.532487433998394,
            "mae": 0.2811372068701945,
            "precision": 0.7410881801125704,
            "recall": 0.811088295687885
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8636122610747375,
            "auditor_fn_violation": 0.010612617144254027,
            "auditor_fp_violation": 0.021019372830569316,
            "ave_precision_score": 0.8639051596959515,
            "fpr": 0.16465422612513722,
            "logloss": 0.5188933664205602,
            "mae": 0.27525679057161273,
            "precision": 0.7257769652650823,
            "recall": 0.8501070663811563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 5740,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.7297503186405618,
            "auditor_fn_violation": 0.002632029251774212,
            "auditor_fp_violation": 0.001566047471620227,
            "ave_precision_score": 0.7334021573789432,
            "fpr": 0.0043859649122807015,
            "logloss": 1.413286378292335,
            "mae": 0.4952554918556033,
            "precision": 0.8620689655172413,
            "recall": 0.0513347022587269
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7081514334372692,
            "auditor_fn_violation": 0.00030791868126186605,
            "auditor_fp_violation": 0.0008603554157890053,
            "ave_precision_score": 0.7184573988714998,
            "fpr": 0.0021953896816684962,
            "logloss": 1.3485848335821564,
            "mae": 0.47842138024032144,
            "precision": 0.9090909090909091,
            "recall": 0.042826552462526764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 5740,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7805131274538242,
            "auditor_fn_violation": 0.01778252098418532,
            "auditor_fp_violation": 0.021798245614035087,
            "ave_precision_score": 0.7809913839141773,
            "fpr": 0.14912280701754385,
            "logloss": 0.9260533901896812,
            "mae": 0.3205941988724245,
            "precision": 0.7100213219616205,
            "recall": 0.6837782340862423
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7665801405067438,
            "auditor_fn_violation": 0.00579874340971754,
            "auditor_fp_violation": 0.024564630492182635,
            "ave_precision_score": 0.7670955969611476,
            "fpr": 0.1712403951701427,
            "logloss": 0.9606490818510554,
            "mae": 0.3197409125706975,
            "precision": 0.6809815950920245,
            "recall": 0.7130620985010707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6892138497773832,
            "auditor_fn_violation": 0.004253125112576106,
            "auditor_fp_violation": 0.013101135190918477,
            "ave_precision_score": 0.6807115829835259,
            "fpr": 0.07894736842105263,
            "logloss": 9.23063515601331,
            "mae": 0.42851793932026355,
            "precision": 0.7209302325581395,
            "recall": 0.38193018480492813
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.665655632839935,
            "auditor_fn_violation": 0.012528294436073976,
            "auditor_fp_violation": 0.008025039309342273,
            "ave_precision_score": 0.6561786433058547,
            "fpr": 0.07244785949506037,
            "logloss": 8.94787322121472,
            "mae": 0.42009422797774526,
            "precision": 0.7130434782608696,
            "recall": 0.3511777301927195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.49854326735481613,
            "auditor_fn_violation": 0.09251053712309522,
            "auditor_fp_violation": 0.10221620227038185,
            "ave_precision_score": 0.55255267943345,
            "fpr": 0.3092105263157895,
            "logloss": 0.6909934944686015,
            "mae": 0.49877292244580756,
            "precision": 0.5600624024960998,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5759523022394458,
            "auditor_fn_violation": 0.0903471019210835,
            "auditor_fp_violation": 0.10721808526418845,
            "ave_precision_score": 0.5547597079763935,
            "fpr": 0.2897914379802415,
            "logloss": 0.6895247705350029,
            "mae": 0.49803794588398853,
            "precision": 0.5686274509803921,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8527967596516475,
            "auditor_fn_violation": 0.030348265427428942,
            "auditor_fp_violation": 0.031586687306501555,
            "ave_precision_score": 0.8532507528485475,
            "fpr": 0.15570175438596492,
            "logloss": 0.6411209454612946,
            "mae": 0.27518036907687465,
            "precision": 0.7394495412844037,
            "recall": 0.8275154004106776
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.850750784802921,
            "auditor_fn_violation": 0.026123726897284438,
            "auditor_fp_violation": 0.038251204003124976,
            "ave_precision_score": 0.8510582585480324,
            "fpr": 0.15587266739846323,
            "logloss": 0.6207745886215006,
            "mae": 0.26759483306665344,
            "precision": 0.7355679702048417,
            "recall": 0.8458244111349036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 5740,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6691727001806066,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6584063875549228,
            "fpr": 0.46600877192982454,
            "logloss": 2.4826986397895237,
            "mae": 0.4604054575687961,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6647426977923621,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6508905391424011,
            "fpr": 0.48737650933040616,
            "logloss": 2.7391317830102633,
            "mae": 0.4788926156763188,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6950692287103546,
            "mae": 0.5008165549421519,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6940424173814935,
            "mae": 0.5003032480518852,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 5740,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8466279167933033,
            "auditor_fn_violation": 0.015368889369213594,
            "auditor_fp_violation": 0.02042053663570692,
            "ave_precision_score": 0.8470317678324201,
            "fpr": 0.13157894736842105,
            "logloss": 0.7014972768807656,
            "mae": 0.26897514173695475,
            "precision": 0.7623762376237624,
            "recall": 0.7905544147843943
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8407104027108787,
            "auditor_fn_violation": 0.005234617581451543,
            "auditor_fp_violation": 0.017943849447691385,
            "ave_precision_score": 0.8410001526411611,
            "fpr": 0.14270032930845225,
            "logloss": 0.7134436097952368,
            "mae": 0.2657471776481199,
            "precision": 0.7420634920634921,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 5740,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7960997683096348,
            "auditor_fn_violation": 0.015337368060809113,
            "auditor_fp_violation": 0.019344685242518058,
            "ave_precision_score": 0.7965936416145457,
            "fpr": 0.1337719298245614,
            "logloss": 0.8506639074204103,
            "mae": 0.30868458302530233,
            "precision": 0.7393162393162394,
            "recall": 0.7104722792607803
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7817661648070098,
            "auditor_fn_violation": 0.012657573271718266,
            "auditor_fp_violation": 0.020203518556976295,
            "ave_precision_score": 0.7822131835638426,
            "fpr": 0.14928649835345773,
            "logloss": 0.87576007369014,
            "mae": 0.3064427668876308,
            "precision": 0.7124735729386892,
            "recall": 0.721627408993576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6952966546677568,
            "mae": 0.5008994258548084,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.694165587399057,
            "mae": 0.5003340242330382,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 5740,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6953666616420942,
            "mae": 0.5009245061429969,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6942040394633533,
            "mae": 0.500343338423843,
            "precision": 0,
            "recall": 0
        }
    }
]