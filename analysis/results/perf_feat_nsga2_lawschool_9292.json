[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.4714998552804259,
            "auditor_fn_violation": 0.10575375293904868,
            "auditor_fp_violation": 0.08960670117917746,
            "ave_precision_score": 0.47781178109066896,
            "fpr": 0.26973684210526316,
            "logloss": 0.6880702707003986,
            "mae": 0.4968475472966307,
            "precision": 0.5794871794871795,
            "recall": 0.6989690721649484
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.44986313493497715,
            "auditor_fn_violation": 0.10060174273684114,
            "auditor_fp_violation": 0.09929419711817852,
            "ave_precision_score": 0.4577263920598939,
            "fpr": 0.27442371020856204,
            "logloss": 0.6886850210538852,
            "mae": 0.4970255279187706,
            "precision": 0.5667244367417678,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.4714998552804259,
            "auditor_fn_violation": 0.10575375293904868,
            "auditor_fp_violation": 0.08960670117917746,
            "ave_precision_score": 0.47781178109066896,
            "fpr": 0.26973684210526316,
            "logloss": 0.68807027084467,
            "mae": 0.49684754736198666,
            "precision": 0.5794871794871795,
            "recall": 0.6989690721649484
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.44986313493497715,
            "auditor_fn_violation": 0.10060174273684114,
            "auditor_fp_violation": 0.09929419711817852,
            "ave_precision_score": 0.4577263920598939,
            "fpr": 0.27442371020856204,
            "logloss": 0.688685020692112,
            "mae": 0.4970255277224875,
            "precision": 0.5667244367417678,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5644131416788383,
            "auditor_fn_violation": 0.09452206547296076,
            "auditor_fp_violation": 0.0912219072270841,
            "ave_precision_score": 0.5595421348230356,
            "fpr": 0.2905701754385965,
            "logloss": 0.7018702086971884,
            "mae": 0.49606818970488875,
            "precision": 0.5705024311183144,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5795224576246438,
            "auditor_fn_violation": 0.10007981107478132,
            "auditor_fp_violation": 0.0968206585175656,
            "ave_precision_score": 0.5529216224283455,
            "fpr": 0.2864983534577388,
            "logloss": 0.6942811117851044,
            "mae": 0.4951067564254535,
            "precision": 0.5583756345177665,
            "recall": 0.7036247334754797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8259927141404436,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.7976849193758548,
            "fpr": 0.4506578947368421,
            "logloss": 0.6729151288656436,
            "mae": 0.4605404234965119,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8331587412243164,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.8043546247090547,
            "fpr": 0.47091108671789245,
            "logloss": 0.6858081519397266,
            "mae": 0.462599196627687,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.582591298012255,
            "auditor_fn_violation": 0.10718484355217943,
            "auditor_fp_violation": 0.09864825999424794,
            "ave_precision_score": 0.5839476648367622,
            "fpr": 0.27960526315789475,
            "logloss": 0.6887230807386165,
            "mae": 0.49724669401582916,
            "precision": 0.5714285714285714,
            "recall": 0.7010309278350515
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5693920248851756,
            "auditor_fn_violation": 0.10226349825281622,
            "auditor_fp_violation": 0.10594990339292013,
            "ave_precision_score": 0.5702393897706748,
            "fpr": 0.28210757409440174,
            "logloss": 0.6890385259164304,
            "mae": 0.49741769092143173,
            "precision": 0.559931506849315,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6915943722035874,
            "auditor_fn_violation": 0.015522698498824379,
            "auditor_fp_violation": 0.0047480381281071555,
            "ave_precision_score": 0.6162556654388104,
            "fpr": 0.03179824561403509,
            "logloss": 0.6711690281046422,
            "mae": 0.4769587626909478,
            "precision": 0.7387387387387387,
            "recall": 0.16907216494845362
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.699714039301025,
            "auditor_fn_violation": 0.0038828907056375843,
            "auditor_fp_violation": 0.005647416443568055,
            "ave_precision_score": 0.5951175778254975,
            "fpr": 0.020856201975850714,
            "logloss": 0.66749935571467,
            "mae": 0.4757132029363274,
            "precision": 0.7978723404255319,
            "recall": 0.15991471215351813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.557987821685362,
            "auditor_fn_violation": 0.016205462108880457,
            "auditor_fp_violation": 0.0047480381281071555,
            "ave_precision_score": 0.5165383597045737,
            "fpr": 0.03179824561403509,
            "logloss": 0.6765069970761737,
            "mae": 0.47967242936424,
            "precision": 0.7238095238095238,
            "recall": 0.15670103092783505
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5396287008800182,
            "auditor_fn_violation": 0.006307649458525166,
            "auditor_fp_violation": 0.005647416443568055,
            "ave_precision_score": 0.4903245638337378,
            "fpr": 0.020856201975850714,
            "logloss": 0.6736000399980179,
            "mae": 0.47974098134381055,
            "precision": 0.7738095238095238,
            "recall": 0.13859275053304904
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8259930155813311,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.7976794934398809,
            "fpr": 0.4506578947368421,
            "logloss": 0.6730353418534197,
            "mae": 0.4605468323356227,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8331173629882949,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.8042718682370118,
            "fpr": 0.47091108671789245,
            "logloss": 0.6859376113341735,
            "mae": 0.46261517924351697,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6874765974281729,
            "auditor_fn_violation": 0.016142159522517643,
            "auditor_fp_violation": 0.006180923620526727,
            "ave_precision_score": 0.6163471147819005,
            "fpr": 0.03508771929824561,
            "logloss": 0.6750014881891618,
            "mae": 0.4771441465014951,
            "precision": 0.7264957264957265,
            "recall": 0.17525773195876287
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6872374098698681,
            "auditor_fn_violation": 0.0031386114745388647,
            "auditor_fp_violation": 0.005682185058436109,
            "ave_precision_score": 0.5934572815919099,
            "fpr": 0.025246981339187707,
            "logloss": 0.6717872493525217,
            "mae": 0.4766364177089884,
            "precision": 0.7676767676767676,
            "recall": 0.16204690831556504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.693293971375052,
            "auditor_fn_violation": 0.015522698498824379,
            "auditor_fp_violation": 0.0047480381281071555,
            "ave_precision_score": 0.6180546550069734,
            "fpr": 0.03179824561403509,
            "logloss": 0.6698304243061954,
            "mae": 0.47701944126502466,
            "precision": 0.7387387387387387,
            "recall": 0.16907216494845362
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7017135534614838,
            "auditor_fn_violation": 0.0038828907056375843,
            "auditor_fp_violation": 0.005647416443568055,
            "ave_precision_score": 0.5972032848177876,
            "fpr": 0.020856201975850714,
            "logloss": 0.6669040413249725,
            "mae": 0.475895830030368,
            "precision": 0.7978723404255319,
            "recall": 0.15991471215351813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5624885383764586,
            "auditor_fn_violation": 0.0032261710978477116,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.48693155033972446,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6685471167239337,
            "mae": 0.48054107138070096,
            "precision": 0.9565217391304348,
            "recall": 0.09072164948453608
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5332361214549657,
            "auditor_fn_violation": 0.003049672446923305,
            "auditor_fp_violation": 0.00072765743973854,
            "ave_precision_score": 0.4617626590160617,
            "fpr": 0.003293084522502744,
            "logloss": 0.6716902366911429,
            "mae": 0.4819234435893309,
            "precision": 0.9318181818181818,
            "recall": 0.08742004264392324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7884690356007795,
            "auditor_fn_violation": 0.012129227708446374,
            "auditor_fp_violation": 0.027396873330868154,
            "ave_precision_score": 0.7600576673740924,
            "fpr": 0.21710526315789475,
            "logloss": 2.2701225807418592,
            "mae": 0.28565456032418807,
            "precision": 0.6821829855537721,
            "recall": 0.8762886597938144
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8122127689740277,
            "auditor_fn_violation": 0.008814325736848143,
            "auditor_fp_violation": 0.027511908250592312,
            "ave_precision_score": 0.794132174518907,
            "fpr": 0.23819978046103182,
            "logloss": 1.7995600091037551,
            "mae": 0.28275087455631454,
            "precision": 0.6646058732612056,
            "recall": 0.9168443496801706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6956955411011966,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6901488174308971,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6500151649053374,
            "mae": 0.46341680382427414,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6608972100132497,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.656047011262202,
            "fpr": 0.006586169045005488,
            "logloss": 0.6470631716873383,
            "mae": 0.45877197872270736,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7396243152365587,
            "auditor_fn_violation": 0.017600379815518177,
            "auditor_fp_violation": 0.0037825095525699506,
            "ave_precision_score": 0.7405220186873079,
            "fpr": 0.019736842105263157,
            "logloss": 1.1215966203938932,
            "mae": 0.44571562454879504,
            "precision": 0.847457627118644,
            "recall": 0.20618556701030927
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7604387510203314,
            "auditor_fn_violation": 0.014908989629241299,
            "auditor_fp_violation": 0.004003357654807258,
            "ave_precision_score": 0.7611080534030515,
            "fpr": 0.013172338090010977,
            "logloss": 1.0487281529718826,
            "mae": 0.4243969968975671,
            "precision": 0.9,
            "recall": 0.2302771855010661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6975789544691322,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6976806693509771,
            "fpr": 0.4682017543859649,
            "logloss": 2.759502931724472,
            "mae": 0.46494682727937114,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7340499052108673,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.734227067277029,
            "fpr": 0.48518111964873767,
            "logloss": 2.832437407025139,
            "mae": 0.4809525555365695,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7585879286117865,
            "auditor_fn_violation": 0.010567010309278374,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7592104364070755,
            "fpr": 0.017543859649122806,
            "logloss": 1.0015380329163734,
            "mae": 0.4328131073066687,
            "precision": 0.875968992248062,
            "recall": 0.2329896907216495
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7824906551230467,
            "auditor_fn_violation": 0.010686726318228527,
            "auditor_fp_violation": 0.003841931942919868,
            "ave_precision_score": 0.7828286387730008,
            "fpr": 0.014270032930845226,
            "logloss": 0.9376012863214523,
            "mae": 0.4123847158090288,
            "precision": 0.8992248062015504,
            "recall": 0.24733475479744135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6888253684233947,
            "auditor_fn_violation": 0.01586408030385242,
            "auditor_fp_violation": 0.0047480381281071555,
            "ave_precision_score": 0.6157233614276433,
            "fpr": 0.03179824561403509,
            "logloss": 0.6671750826313851,
            "mae": 0.47594674781226276,
            "precision": 0.7314814814814815,
            "recall": 0.16288659793814433
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6955234395521569,
            "auditor_fn_violation": 0.0034241525631993853,
            "auditor_fp_violation": 0.005647416443568055,
            "ave_precision_score": 0.5937267664733623,
            "fpr": 0.020856201975850714,
            "logloss": 0.6633793050995506,
            "mae": 0.4743065517702427,
            "precision": 0.7865168539325843,
            "recall": 0.14925373134328357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7645361140271448,
            "auditor_fn_violation": 0.010567010309278362,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7650832445804261,
            "fpr": 0.017543859649122806,
            "logloss": 0.928977252231945,
            "mae": 0.42616181059285035,
            "precision": 0.8787878787878788,
            "recall": 0.23917525773195877
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7880274880217002,
            "auditor_fn_violation": 0.007316405271743846,
            "auditor_fp_violation": 0.004097729609449117,
            "ave_precision_score": 0.7883056760938849,
            "fpr": 0.01756311745334797,
            "logloss": 0.869654869832374,
            "mae": 0.40653806314527635,
            "precision": 0.8848920863309353,
            "recall": 0.2622601279317697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7190364337766861,
            "auditor_fn_violation": 0.1012185747874842,
            "auditor_fp_violation": 0.09392590081761783,
            "ave_precision_score": 0.568311454051492,
            "fpr": 0.2708333333333333,
            "logloss": 0.6861757254981605,
            "mae": 0.4956013684471448,
            "precision": 0.577054794520548,
            "recall": 0.6948453608247422
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6819944330682077,
            "auditor_fn_violation": 0.10155900753407184,
            "auditor_fp_violation": 0.09929419711817852,
            "ave_precision_score": 0.5598324699081995,
            "fpr": 0.27442371020856204,
            "logloss": 0.6853897038805687,
            "mae": 0.49314684366028344,
            "precision": 0.5659722222222222,
            "recall": 0.6950959488272921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.468131253257112,
            "auditor_fn_violation": 0.1041372761801411,
            "auditor_fp_violation": 0.09760055877398414,
            "ave_precision_score": 0.4738427923641478,
            "fpr": 0.27850877192982454,
            "logloss": 0.6884665417231578,
            "mae": 0.49710005302831795,
            "precision": 0.5752508361204013,
            "recall": 0.709278350515464
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.45710976519267255,
            "auditor_fn_violation": 0.10153560252680459,
            "auditor_fp_violation": 0.10085878478724092,
            "ave_precision_score": 0.46465391271109036,
            "fpr": 0.2810098792535675,
            "logloss": 0.688977615886396,
            "mae": 0.49736897302249655,
            "precision": 0.5616438356164384,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5957237945785858,
            "auditor_fn_violation": 0.005159160788569382,
            "auditor_fp_violation": 0.0036130284728213996,
            "ave_precision_score": 0.5964647087947277,
            "fpr": 0.03837719298245614,
            "logloss": 1.016408257013168,
            "mae": 0.49903683022324613,
            "precision": 0.7388059701492538,
            "recall": 0.20412371134020618
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6051058695571594,
            "auditor_fn_violation": 0.0024317802550677713,
            "auditor_fp_violation": 0.0057864909030402685,
            "ave_precision_score": 0.6059864031545844,
            "fpr": 0.043907793633369926,
            "logloss": 0.9123852849700825,
            "mae": 0.48677795670582447,
            "precision": 0.7333333333333333,
            "recall": 0.2345415778251599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5580016806762712,
            "auditor_fn_violation": 0.016205462108880457,
            "auditor_fp_violation": 0.0047480381281071555,
            "ave_precision_score": 0.5165518724146456,
            "fpr": 0.03179824561403509,
            "logloss": 0.6766657301139541,
            "mae": 0.47967931824295146,
            "precision": 0.7238095238095238,
            "recall": 0.15670103092783505
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5396287008800182,
            "auditor_fn_violation": 0.006307649458525166,
            "auditor_fp_violation": 0.005647416443568055,
            "ave_precision_score": 0.4903245638337378,
            "fpr": 0.020856201975850714,
            "logloss": 0.6736984546296101,
            "mae": 0.479726972976448,
            "precision": 0.7738095238095238,
            "recall": 0.13859275053304904
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6670781646372341,
            "auditor_fn_violation": 0.10718484355217943,
            "auditor_fp_violation": 0.0916995357245573,
            "ave_precision_score": 0.6694625738924931,
            "fpr": 0.28618421052631576,
            "logloss": 0.6884804854766355,
            "mae": 0.4971233488044195,
            "precision": 0.5657237936772047,
            "recall": 0.7010309278350515
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6378984363822604,
            "auditor_fn_violation": 0.10226349825281622,
            "auditor_fp_violation": 0.10567672141895686,
            "ave_precision_score": 0.6439013645943692,
            "fpr": 0.2843029637760702,
            "logloss": 0.6891337079100044,
            "mae": 0.4974502965922413,
            "precision": 0.5580204778156996,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7190711122034383,
            "auditor_fn_violation": 0.10489916802315068,
            "auditor_fp_violation": 0.09864825999424794,
            "ave_precision_score": 0.5659655206346129,
            "fpr": 0.27960526315789475,
            "logloss": 0.686461256891385,
            "mae": 0.4957220176921079,
            "precision": 0.5735785953177257,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6792125087173928,
            "auditor_fn_violation": 0.10153560252680459,
            "auditor_fp_violation": 0.10526446498552137,
            "ave_precision_score": 0.5555037366891836,
            "fpr": 0.283205268935236,
            "logloss": 0.6856010957489292,
            "mae": 0.4932283796410922,
            "precision": 0.5597269624573379,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5358677916555274,
            "auditor_fn_violation": 0.09452206547296076,
            "auditor_fp_violation": 0.08812759357409919,
            "ave_precision_score": 0.5523785753446754,
            "fpr": 0.29714912280701755,
            "logloss": 0.7125558534646599,
            "mae": 0.4993356672164641,
            "precision": 0.565008025682183,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5589361536111633,
            "auditor_fn_violation": 0.09773696984732914,
            "auditor_fp_violation": 0.09477924413031277,
            "ave_precision_score": 0.5493034799860615,
            "fpr": 0.2897914379802415,
            "logloss": 0.6996722338571685,
            "mae": 0.4965507211787248,
            "precision": 0.5563025210084034,
            "recall": 0.7057569296375267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7657286419929916,
            "auditor_fn_violation": 0.01324832700307471,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7662818588438725,
            "fpr": 0.017543859649122806,
            "logloss": 0.9526778681074447,
            "mae": 0.42908784372705494,
            "precision": 0.8769230769230769,
            "recall": 0.23505154639175257
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7887625483397416,
            "auditor_fn_violation": 0.006855326628578916,
            "auditor_fp_violation": 0.0036730558135607536,
            "ave_precision_score": 0.7890450360272785,
            "fpr": 0.01646542261251372,
            "logloss": 0.8927654222677704,
            "mae": 0.40943645073242,
            "precision": 0.8905109489051095,
            "recall": 0.2601279317697228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6670801221103986,
            "auditor_fn_violation": 0.10718484355217943,
            "auditor_fp_violation": 0.0916995357245573,
            "ave_precision_score": 0.6694645309751666,
            "fpr": 0.28618421052631576,
            "logloss": 0.6884805158453181,
            "mae": 0.49712342288541167,
            "precision": 0.5657237936772047,
            "recall": 0.7010309278350515
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6379004706061153,
            "auditor_fn_violation": 0.10226349825281622,
            "auditor_fp_violation": 0.10567672141895686,
            "ave_precision_score": 0.6439033984561147,
            "fpr": 0.2843029637760702,
            "logloss": 0.689133549455058,
            "mae": 0.4974503391856812,
            "precision": 0.5580204778156996,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7605899100736238,
            "auditor_fn_violation": 0.01493262796165673,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7611800667991782,
            "fpr": 0.017543859649122806,
            "logloss": 1.019314056320124,
            "mae": 0.4343390300555416,
            "precision": 0.8740157480314961,
            "recall": 0.2288659793814433
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7837072588971661,
            "auditor_fn_violation": 0.009696694510823674,
            "auditor_fp_violation": 0.003841931942919868,
            "ave_precision_score": 0.7840278093437701,
            "fpr": 0.014270032930845226,
            "logloss": 0.9552647322859165,
            "mae": 0.4140467219326633,
            "precision": 0.8984375,
            "recall": 0.24520255863539445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6977680649742775,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.6964574917710087,
            "fpr": 0.4451754385964912,
            "logloss": 3.6556756848453507,
            "mae": 0.4530987447779217,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7296991359396732,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.7342161862263528,
            "fpr": 0.45554335894621295,
            "logloss": 3.7417090035074274,
            "mae": 0.46462832537349863,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7603003488217079,
            "auditor_fn_violation": 0.013282239102911932,
            "auditor_fp_violation": 0.005687887752167307,
            "ave_precision_score": 0.7347482104441517,
            "fpr": 0.08662280701754387,
            "logloss": 2.6160543684203286,
            "mae": 0.3636852755762131,
            "precision": 0.7443365695792881,
            "recall": 0.4742268041237113
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7837566958754778,
            "auditor_fn_violation": 0.010796729852384626,
            "auditor_fp_violation": 0.007500086921537173,
            "ave_precision_score": 0.7674147521706165,
            "fpr": 0.07903402854006586,
            "logloss": 2.0166875764526413,
            "mae": 0.33375320685461823,
            "precision": 0.7623762376237624,
            "recall": 0.4925373134328358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7670373342549781,
            "auditor_fn_violation": 0.011326641345632132,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7675829033454071,
            "fpr": 0.017543859649122806,
            "logloss": 0.9192866391399678,
            "mae": 0.42527021980781127,
            "precision": 0.8778625954198473,
            "recall": 0.23711340206185566
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7890275069804866,
            "auditor_fn_violation": 0.006970011164188462,
            "auditor_fp_violation": 0.004097729609449117,
            "ave_precision_score": 0.7893063325747931,
            "fpr": 0.01756311745334797,
            "logloss": 0.862113454512856,
            "mae": 0.4058988946653559,
            "precision": 0.8857142857142857,
            "recall": 0.26439232409381663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6907691927217393,
            "auditor_fn_violation": 0.005174986435160067,
            "auditor_fp_violation": 0.009924914745881093,
            "ave_precision_score": 0.535316865659473,
            "fpr": 0.32456140350877194,
            "logloss": 10.963241470414486,
            "mae": 0.4781252673189891,
            "precision": 0.5316455696202531,
            "recall": 0.6927835051546392
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.6632079894347029,
            "auditor_fn_violation": 0.013441495673584415,
            "auditor_fp_violation": 0.003581167331409483,
            "ave_precision_score": 0.4986170667999832,
            "fpr": 0.3633369923161361,
            "logloss": 12.220372086064362,
            "mae": 0.5081639430525536,
            "precision": 0.48919753086419754,
            "recall": 0.67590618336887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 9292,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7034941000876265,
            "auditor_fn_violation": 0.0075804847169470115,
            "auditor_fp_violation": 0.004812235506799786,
            "ave_precision_score": 0.612020834706931,
            "fpr": 0.019736842105263157,
            "logloss": 0.6642697102481674,
            "mae": 0.47661112569141806,
            "precision": 0.7804878048780488,
            "recall": 0.13195876288659794
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7089043791727242,
            "auditor_fn_violation": 0.004355671852436101,
            "auditor_fp_violation": 0.0018725382578937176,
            "ave_precision_score": 0.5909853392733997,
            "fpr": 0.014270032930845226,
            "logloss": 0.6627741178108663,
            "mae": 0.4754500938364755,
            "precision": 0.8266666666666667,
            "recall": 0.13219616204690832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7633367100193849,
            "auditor_fn_violation": 0.01493262796165673,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7639145483435794,
            "fpr": 0.017543859649122806,
            "logloss": 1.0290461125861947,
            "mae": 0.4345128975630934,
            "precision": 0.8740157480314961,
            "recall": 0.2288659793814433
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7866263030649099,
            "auditor_fn_violation": 0.009696694510823674,
            "auditor_fp_violation": 0.003841931942919868,
            "ave_precision_score": 0.7869326468768534,
            "fpr": 0.014270032930845226,
            "logloss": 0.9642835201619572,
            "mae": 0.41420563456868703,
            "precision": 0.8984375,
            "recall": 0.24520255863539445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8259930155813311,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.7976794934398809,
            "fpr": 0.4506578947368421,
            "logloss": 0.6729670706767985,
            "mae": 0.4605369667538948,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.8331173811713108,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.8042721421471795,
            "fpr": 0.47091108671789245,
            "logloss": 0.6858263677754267,
            "mae": 0.46258938695282625,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5455906700571417,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5469809734321905,
            "fpr": 0.4682017543859649,
            "logloss": 2.0949597312253414,
            "mae": 0.46953141584730984,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5598549967696815,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5606744867671608,
            "fpr": 0.48518111964873767,
            "logloss": 2.150646766220569,
            "mae": 0.48590136477243234,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 9292,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7210971277205183,
            "auditor_fn_violation": 0.02563528667028397,
            "auditor_fp_violation": 0.004003348535272609,
            "ave_precision_score": 0.7227828187505416,
            "fpr": 0.021929824561403508,
            "logloss": 1.152381144325902,
            "mae": 0.4536810621347078,
            "precision": 0.8165137614678899,
            "recall": 0.18350515463917524
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.740761384679629,
            "auditor_fn_violation": 0.028678155404567255,
            "auditor_fp_violation": 0.005264961680019471,
            "ave_precision_score": 0.7425398082592362,
            "fpr": 0.010976948408342482,
            "logloss": 1.078520815330123,
            "mae": 0.4304003745487929,
            "precision": 0.9065420560747663,
            "recall": 0.2068230277185501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7816641679752352,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.782100855974984,
            "fpr": 0.4682017543859649,
            "logloss": 2.205046877687829,
            "mae": 0.4684252516088778,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7898196052909605,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7902573702941444,
            "fpr": 0.48518111964873767,
            "logloss": 2.2776445741731117,
            "mae": 0.4850239932340796,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7190364337766861,
            "auditor_fn_violation": 0.1012185747874842,
            "auditor_fp_violation": 0.09392590081761783,
            "ave_precision_score": 0.568311454051492,
            "fpr": 0.2708333333333333,
            "logloss": 0.6861757254981605,
            "mae": 0.4956013684471448,
            "precision": 0.577054794520548,
            "recall": 0.6948453608247422
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6819944330682077,
            "auditor_fn_violation": 0.10155900753407184,
            "auditor_fp_violation": 0.09929419711817852,
            "ave_precision_score": 0.5598324699081995,
            "fpr": 0.27442371020856204,
            "logloss": 0.6853897038805687,
            "mae": 0.49314684366028344,
            "precision": 0.5659722222222222,
            "recall": 0.6950959488272921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7359248902507973,
            "auditor_fn_violation": 0.005774100198950984,
            "auditor_fp_violation": 0.017433440157771474,
            "ave_precision_score": 0.7366522780782288,
            "fpr": 0.09539473684210527,
            "logloss": 0.6118562335615007,
            "mae": 0.42017447829998117,
            "precision": 0.7030716723549488,
            "recall": 0.4247422680412371
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7171756322648268,
            "auditor_fn_violation": 0.004276094827727452,
            "auditor_fp_violation": 0.013659098698163721,
            "ave_precision_score": 0.7177318139711291,
            "fpr": 0.11086717892425905,
            "logloss": 0.6052908723890441,
            "mae": 0.4158739966619453,
            "precision": 0.6529209621993127,
            "recall": 0.4051172707889126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7976525649588269,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.7997653803584983,
            "fpr": 0.4451754385964912,
            "logloss": 3.8639873644793252,
            "mae": 0.4528116376878837,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8092040839166224,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.8131277005896433,
            "fpr": 0.45554335894621295,
            "logloss": 3.9550784407284603,
            "mae": 0.46428039621765316,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 9292,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7128596930075799,
            "auditor_fn_violation": 0.007481009224091157,
            "auditor_fp_violation": 0.010025062656641603,
            "ave_precision_score": 0.714496860776751,
            "fpr": 0.2675438596491228,
            "logloss": 0.9512450451040796,
            "mae": 0.3686517332114353,
            "precision": 0.6363636363636364,
            "recall": 0.8804123711340206
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7674361919047057,
            "auditor_fn_violation": 0.0044399298785982285,
            "auditor_fp_violation": 0.011657419870760093,
            "ave_precision_score": 0.7675921543409985,
            "fpr": 0.24368825466520308,
            "logloss": 0.8026476910830164,
            "mae": 0.33798146415039876,
            "precision": 0.65527950310559,
            "recall": 0.8997867803837953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8021373392553464,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.802971609979735,
            "fpr": 0.4451754385964912,
            "logloss": 4.103482147873903,
            "mae": 0.45283392992695365,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.810760211316375,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.8149373555968146,
            "fpr": 0.45554335894621295,
            "logloss": 4.203443461560076,
            "mae": 0.46430223136673254,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7880604738437545,
            "auditor_fn_violation": 0.022325465726171105,
            "auditor_fp_violation": 0.0104076790336497,
            "ave_precision_score": 0.7611566207551728,
            "fpr": 0.08662280701754387,
            "logloss": 2.4495778872438296,
            "mae": 0.3192165150150395,
            "precision": 0.7696793002915452,
            "recall": 0.5443298969072164
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8112743738065595,
            "auditor_fn_violation": 0.013368940151055922,
            "auditor_fp_violation": 0.013574660633484168,
            "ave_precision_score": 0.7948975769818257,
            "fpr": 0.07683863885839737,
            "logloss": 1.7766441149660819,
            "mae": 0.28957239776508387,
            "precision": 0.7959183673469388,
            "recall": 0.582089552238806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5586105573859744,
            "auditor_fn_violation": 0.008478024959305492,
            "auditor_fp_violation": 0.0065481326266485914,
            "ave_precision_score": 0.5519746234702482,
            "fpr": 0.049342105263157895,
            "logloss": 0.6931531032193388,
            "mae": 0.49990825018469703,
            "precision": 0.5360824742268041,
            "recall": 0.10721649484536082
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5285772078213324,
            "auditor_fn_violation": 0.009003906295712915,
            "auditor_fp_violation": 0.008304732008483544,
            "ave_precision_score": 0.5187592772382973,
            "fpr": 0.06256860592755215,
            "logloss": 0.6934435055239031,
            "mae": 0.5000551781656976,
            "precision": 0.5289256198347108,
            "recall": 0.13646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 9292,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.739479782824759,
            "auditor_fn_violation": 0.008025863628142524,
            "auditor_fp_violation": 0.011540120793787762,
            "ave_precision_score": 0.7410801528691147,
            "fpr": 0.2532894736842105,
            "logloss": 0.8596165308168926,
            "mae": 0.3567643962819602,
            "precision": 0.6478658536585366,
            "recall": 0.8762886597938144
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7943124481506966,
            "auditor_fn_violation": 0.007866422942524324,
            "auditor_fp_violation": 0.013624330083295673,
            "ave_precision_score": 0.7947448188276063,
            "fpr": 0.2283205268935236,
            "logloss": 0.7063835391323456,
            "mae": 0.32632468817919147,
            "precision": 0.6703645007923931,
            "recall": 0.9019189765458422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7994043620241391,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.8008155828428816,
            "fpr": 0.4451754385964912,
            "logloss": 3.913320923129215,
            "mae": 0.4528156873531968,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8115328775401274,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.8151581228123201,
            "fpr": 0.45554335894621295,
            "logloss": 4.005590100337493,
            "mae": 0.46428507584045486,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5586105573859744,
            "auditor_fn_violation": 0.008478024959305492,
            "auditor_fp_violation": 0.0065481326266485914,
            "ave_precision_score": 0.5519746234702482,
            "fpr": 0.049342105263157895,
            "logloss": 0.6931530970774081,
            "mae": 0.4999082486488317,
            "precision": 0.5360824742268041,
            "recall": 0.10721649484536082
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5285772078213324,
            "auditor_fn_violation": 0.009003906295712915,
            "auditor_fp_violation": 0.008304732008483544,
            "ave_precision_score": 0.5187592772382973,
            "fpr": 0.06256860592755215,
            "logloss": 0.6934434992477957,
            "mae": 0.5000551765300048,
            "precision": 0.5289256198347108,
            "recall": 0.13646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7741465679595922,
            "auditor_fn_violation": 0.002504973774642801,
            "auditor_fp_violation": 0.006460824191626607,
            "ave_precision_score": 0.7747736401802354,
            "fpr": 0.02631578947368421,
            "logloss": 0.6933939753509467,
            "mae": 0.40198212618155305,
            "precision": 0.8736842105263158,
            "recall": 0.3422680412371134
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7960448044985043,
            "auditor_fn_violation": 0.01062353279860694,
            "auditor_fp_violation": 0.003377522587182302,
            "ave_precision_score": 0.7962692591574017,
            "fpr": 0.018660812294182216,
            "logloss": 0.6577333220134043,
            "mae": 0.3874858476560968,
            "precision": 0.91005291005291,
            "recall": 0.36673773987206826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7902571710739126,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6371872904976946,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6462066861014855,
            "mae": 0.46342725803454715,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7706235472950277,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.6290529121492738,
            "fpr": 0.006586169045005488,
            "logloss": 0.6429552179401977,
            "mae": 0.458354235284284,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.794068088006511,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.7923003944115218,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6451753789716803,
            "mae": 0.46308886344756994,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.8032869249064095,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.801200002770756,
            "fpr": 0.006586169045005488,
            "logloss": 0.6422184919346577,
            "mae": 0.45812334684587597,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6956231102637727,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6900783546053142,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6500614881836148,
            "mae": 0.4633907316612047,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6607685887370088,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.6559227949411867,
            "fpr": 0.006586169045005488,
            "logloss": 0.6471018339286555,
            "mae": 0.4587352011520436,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5586105573859744,
            "auditor_fn_violation": 0.008478024959305492,
            "auditor_fp_violation": 0.0065481326266485914,
            "ave_precision_score": 0.5519746234702482,
            "fpr": 0.049342105263157895,
            "logloss": 0.6931531005555529,
            "mae": 0.4999082493350694,
            "precision": 0.5360824742268041,
            "recall": 0.10721649484536082
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5285772078213324,
            "auditor_fn_violation": 0.009003906295712915,
            "auditor_fp_violation": 0.008304732008483544,
            "ave_precision_score": 0.5187592772382973,
            "fpr": 0.06256860592755215,
            "logloss": 0.6934435018099098,
            "mae": 0.5000551767917155,
            "precision": 0.5289256198347108,
            "recall": 0.13646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7879429841207669,
            "auditor_fn_violation": 0.012389220473865084,
            "auditor_fp_violation": 0.0066303052713751615,
            "ave_precision_score": 0.7630969381259468,
            "fpr": 0.07346491228070176,
            "logloss": 2.6676184111459493,
            "mae": 0.34652312378301653,
            "precision": 0.7781456953642384,
            "recall": 0.4845360824742268
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8092954562551777,
            "auditor_fn_violation": 0.009050716310247417,
            "auditor_fp_violation": 0.0049470772012258435,
            "ave_precision_score": 0.7938125915339265,
            "fpr": 0.06366630076838639,
            "logloss": 2.011115094189559,
            "mae": 0.3156036987988599,
            "precision": 0.8006872852233677,
            "recall": 0.4968017057569296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8016397294421784,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.8023468592301259,
            "fpr": 0.4451754385964912,
            "logloss": 2.724914232804799,
            "mae": 0.4525359790453889,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8105786824168038,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.812175536699481,
            "fpr": 0.45554335894621295,
            "logloss": 2.787626859018,
            "mae": 0.4638999854718682,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7364033843822599,
            "auditor_fn_violation": 0.01200262253572075,
            "auditor_fp_violation": 0.03018817535642385,
            "ave_precision_score": 0.7371343269535369,
            "fpr": 0.2138157894736842,
            "logloss": 0.6125661661122974,
            "mae": 0.42035592947433,
            "precision": 0.6441605839416058,
            "recall": 0.7278350515463917
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7182601521847713,
            "auditor_fn_violation": 0.01520155222008197,
            "auditor_fp_violation": 0.02707978403723222,
            "ave_precision_score": 0.7188139673758273,
            "fpr": 0.2261251372118551,
            "logloss": 0.6063553031050312,
            "mae": 0.4162806436893838,
            "precision": 0.6404886561954625,
            "recall": 0.7825159914712153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7679846992952317,
            "auditor_fn_violation": 0.04485892566467716,
            "auditor_fp_violation": 0.023655450100661495,
            "ave_precision_score": 0.7682252300348889,
            "fpr": 0.12280701754385964,
            "logloss": 1.0830079736991154,
            "mae": 0.3216064387667454,
            "precision": 0.7389277389277389,
            "recall": 0.6536082474226804
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7924773124868009,
            "auditor_fn_violation": 0.042110289075244764,
            "auditor_fp_violation": 0.02549532858824523,
            "ave_precision_score": 0.792851064863431,
            "fpr": 0.12184412733260154,
            "logloss": 0.9130913017574573,
            "mae": 0.30015522582982573,
            "precision": 0.7430555555555556,
            "recall": 0.6844349680170576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5586105573859744,
            "auditor_fn_violation": 0.008478024959305492,
            "auditor_fp_violation": 0.0065481326266485914,
            "ave_precision_score": 0.5519746234702482,
            "fpr": 0.049342105263157895,
            "logloss": 0.6931531128897063,
            "mae": 0.4999082527989358,
            "precision": 0.5360824742268041,
            "recall": 0.10721649484536082
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5285772078213324,
            "auditor_fn_violation": 0.009003906295712915,
            "auditor_fp_violation": 0.008304732008483544,
            "ave_precision_score": 0.5187592772382973,
            "fpr": 0.06256860592755215,
            "logloss": 0.6934435132484231,
            "mae": 0.500055179866818,
            "precision": 0.5289256198347108,
            "recall": 0.13646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.8199906481800614,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.00741094539627758,
            "ave_precision_score": 0.820225678254864,
            "fpr": 0.4440789473684211,
            "logloss": 1.6431226298190476,
            "mae": 0.44575511725265804,
            "precision": 0.5413363533408834,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.824641862936052,
            "auditor_fn_violation": 0.0015564329832724413,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.824972815607472,
            "fpr": 0.45554335894621295,
            "logloss": 1.6732154367172372,
            "mae": 0.45559428715822264,
            "precision": 0.5267958950969214,
            "recall": 0.9850746268656716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.798328452219229,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.6551510703168664,
            "fpr": 0.4506578947368421,
            "logloss": 7.785660855360171,
            "mae": 0.4594299462438116,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7971072836510352,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.65081827008982,
            "fpr": 0.47091108671789245,
            "logloss": 8.07626234251831,
            "mae": 0.47749733816976986,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7378806237281393,
            "auditor_fn_violation": 0.05624434798336046,
            "auditor_fp_violation": 0.029040326225399565,
            "ave_precision_score": 0.7393800053631183,
            "fpr": 0.11293859649122807,
            "logloss": 0.7095550104362559,
            "mae": 0.36466492049699456,
            "precision": 0.745049504950495,
            "recall": 0.6206185567010309
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8018496320339779,
            "auditor_fn_violation": 0.04299031734849353,
            "auditor_fp_violation": 0.03165434036487178,
            "ave_precision_score": 0.8022754260536757,
            "fpr": 0.10428100987925357,
            "logloss": 0.6014661720049983,
            "mae": 0.33739008987373564,
            "precision": 0.7642679900744417,
            "recall": 0.6567164179104478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6670801221103986,
            "auditor_fn_violation": 0.10718484355217943,
            "auditor_fp_violation": 0.0916995357245573,
            "ave_precision_score": 0.6694645309751666,
            "fpr": 0.28618421052631576,
            "logloss": 0.6884806532057072,
            "mae": 0.4971236456512359,
            "precision": 0.5657237936772047,
            "recall": 0.7010309278350515
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6379004706061153,
            "auditor_fn_violation": 0.10226349825281622,
            "auditor_fp_violation": 0.10567672141895686,
            "ave_precision_score": 0.6439033984561147,
            "fpr": 0.2843029637760702,
            "logloss": 0.6891331855825716,
            "mae": 0.49745047589688346,
            "precision": 0.5580204778156996,
            "recall": 0.697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7759658261875152,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7758143403412006,
            "fpr": 0.4682017543859649,
            "logloss": 2.744410491270252,
            "mae": 0.4642684471450354,
            "precision": 0.5317982456140351,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7826302170370784,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7829117430783958,
            "fpr": 0.48518111964873767,
            "logloss": 2.8168884870113615,
            "mae": 0.48000822495157974,
            "precision": 0.5148188803512623,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8018231028838252,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.8027863190035509,
            "fpr": 0.4451754385964912,
            "logloss": 4.1238407123583665,
            "mae": 0.45283466955968726,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8122830321819525,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.8148817078415818,
            "fpr": 0.45554335894621295,
            "logloss": 4.224119213323488,
            "mae": 0.4643032357430043,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7650375868778682,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.5396739051716999,
            "fpr": 0.4506578947368421,
            "logloss": 15.54376058854117,
            "mae": 0.45942985673039016,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7572871361627782,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.5238186180524564,
            "fpr": 0.47091108671789245,
            "logloss": 16.10433330969952,
            "mae": 0.477497277820347,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7647244377640057,
            "auditor_fn_violation": 0.003533640803038524,
            "auditor_fp_violation": 0.0046119396852787806,
            "ave_precision_score": 0.537083314090285,
            "fpr": 0.4506578947368421,
            "logloss": 15.582402937509018,
            "mae": 0.46196866192315755,
            "precision": 0.5371621621621622,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7564328895289254,
            "auditor_fn_violation": 0.0004002256242700565,
            "auditor_fp_violation": 0.005682185058436113,
            "ave_precision_score": 0.5190185513909322,
            "fpr": 0.47091108671789245,
            "logloss": 16.278110965601186,
            "mae": 0.4797211731370011,
            "precision": 0.5190582959641256,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 9292,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7098540229324717,
            "auditor_fn_violation": 0.008025863628142524,
            "auditor_fp_violation": 0.011057356506019148,
            "ave_precision_score": 0.7114943229868234,
            "fpr": 0.26535087719298245,
            "logloss": 0.962187254750245,
            "mae": 0.3692867548790988,
            "precision": 0.6371814092953523,
            "recall": 0.8762886597938144
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7658696494122631,
            "auditor_fn_violation": 0.008453888624932421,
            "auditor_fp_violation": 0.011096155087890093,
            "ave_precision_score": 0.7660198645090697,
            "fpr": 0.24368825466520308,
            "logloss": 0.8109262503966986,
            "mae": 0.33907883667841865,
            "precision": 0.6542056074766355,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 9292,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7883762858736916,
            "auditor_fn_violation": 0.02121767046482185,
            "auditor_fp_violation": 0.011198590739142943,
            "ave_precision_score": 0.7614363744008767,
            "fpr": 0.08881578947368421,
            "logloss": 2.433697138190963,
            "mae": 0.3142927809560706,
            "precision": 0.7724719101123596,
            "recall": 0.5670103092783505
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8111698844538854,
            "auditor_fn_violation": 0.01407811187125374,
            "auditor_fp_violation": 0.013574660633484168,
            "ave_precision_score": 0.79479697019222,
            "fpr": 0.07683863885839737,
            "logloss": 1.7603460102523414,
            "mae": 0.28527542819645607,
            "precision": 0.8005698005698005,
            "recall": 0.5991471215351812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5586105573859744,
            "auditor_fn_violation": 0.008478024959305492,
            "auditor_fp_violation": 0.0065481326266485914,
            "ave_precision_score": 0.5519746234702482,
            "fpr": 0.049342105263157895,
            "logloss": 0.6931531046624088,
            "mae": 0.49990825100164665,
            "precision": 0.5360824742268041,
            "recall": 0.10721649484536082
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5285772078213324,
            "auditor_fn_violation": 0.009003906295712915,
            "auditor_fp_violation": 0.008304732008483544,
            "ave_precision_score": 0.5187592772382973,
            "fpr": 0.06256860592755215,
            "logloss": 0.6934435064344673,
            "mae": 0.500055178721833,
            "precision": 0.5289256198347108,
            "recall": 0.13646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7524781651841781,
            "auditor_fn_violation": 0.016266503888587445,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7535864312183768,
            "fpr": 0.017543859649122806,
            "logloss": 0.9560169277493096,
            "mae": 0.4340570081145862,
            "precision": 0.872,
            "recall": 0.22474226804123712
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.785648119028957,
            "auditor_fn_violation": 0.01895571538574963,
            "auditor_fp_violation": 0.00401825848975071,
            "ave_precision_score": 0.7859370450982759,
            "fpr": 0.01756311745334797,
            "logloss": 0.8987938970417293,
            "mae": 0.41329808944900664,
            "precision": 0.8805970149253731,
            "recall": 0.2515991471215352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7839236322888116,
            "auditor_fn_violation": 0.010888044854404054,
            "auditor_fp_violation": 0.01678889847569745,
            "ave_precision_score": 0.783354409493898,
            "fpr": 0.20285087719298245,
            "logloss": 1.0902188671113873,
            "mae": 0.31346120808337763,
            "precision": 0.6926910299003323,
            "recall": 0.8597938144329897
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.817898690772206,
            "auditor_fn_violation": 0.007985788479587324,
            "auditor_fp_violation": 0.012412395507894962,
            "ave_precision_score": 0.817428353234384,
            "fpr": 0.2052689352360044,
            "logloss": 0.9372707560202945,
            "mae": 0.3007913496532875,
            "precision": 0.6909090909090909,
            "recall": 0.8912579957356077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7358601346476544,
            "auditor_fn_violation": 0.056355127509495395,
            "auditor_fp_violation": 0.03212436829779367,
            "ave_precision_score": 0.7373658927204291,
            "fpr": 0.1118421052631579,
            "logloss": 0.7124992591659874,
            "mae": 0.3656818955095603,
            "precision": 0.7456359102244389,
            "recall": 0.6164948453608248
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7998184851285004,
            "auditor_fn_violation": 0.04403886167406656,
            "auditor_fp_violation": 0.03236461349717629,
            "ave_precision_score": 0.8002474035622051,
            "fpr": 0.10537870472008781,
            "logloss": 0.6046859083356281,
            "mae": 0.33839266403204055,
            "precision": 0.7605985037406484,
            "recall": 0.650319829424307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7682420199254519,
            "auditor_fn_violation": 0.03642159522517635,
            "auditor_fp_violation": 0.02186562718271088,
            "ave_precision_score": 0.7686661231210676,
            "fpr": 0.11074561403508772,
            "logloss": 1.108277575744098,
            "mae": 0.32546870694195923,
            "precision": 0.7455919395465995,
            "recall": 0.6103092783505155
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7934162512556602,
            "auditor_fn_violation": 0.03859017598224965,
            "auditor_fp_violation": 0.023324773631482484,
            "ave_precision_score": 0.7937741757094215,
            "fpr": 0.10976948408342481,
            "logloss": 0.9286873262695754,
            "mae": 0.29985436224682704,
            "precision": 0.7493734335839599,
            "recall": 0.6375266524520256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7827988849726935,
            "auditor_fn_violation": 0.017910110327364805,
            "auditor_fp_violation": 0.02313159949052961,
            "ave_precision_score": 0.7824495633398947,
            "fpr": 0.16776315789473684,
            "logloss": 1.0311416913842617,
            "mae": 0.30735574782792946,
            "precision": 0.7166666666666667,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8085580709498088,
            "auditor_fn_violation": 0.014913670630694736,
            "auditor_fp_violation": 0.025957254471492226,
            "ave_precision_score": 0.8080897636679283,
            "fpr": 0.1712403951701427,
            "logloss": 0.8934260024043494,
            "mae": 0.2891711549500272,
            "precision": 0.7132352941176471,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7769922520223375,
            "auditor_fn_violation": 0.0393018629046844,
            "auditor_fp_violation": 0.02669840585069231,
            "ave_precision_score": 0.7771730151863301,
            "fpr": 0.11293859649122807,
            "logloss": 1.1567485221716294,
            "mae": 0.3136932838954807,
            "precision": 0.7529976019184652,
            "recall": 0.6474226804123712
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8023376132578021,
            "auditor_fn_violation": 0.036046051692299054,
            "auditor_fp_violation": 0.031256984766379746,
            "ave_precision_score": 0.8027556836038565,
            "fpr": 0.10976948408342481,
            "logloss": 0.9368853225221874,
            "mae": 0.2871423257051382,
            "precision": 0.7624703087885986,
            "recall": 0.6844349680170576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 9292,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7095056455323384,
            "auditor_fn_violation": 0.008025863628142524,
            "auditor_fp_violation": 0.011057356506019148,
            "ave_precision_score": 0.7111467152871613,
            "fpr": 0.26535087719298245,
            "logloss": 0.9645764942632168,
            "mae": 0.3693729075405053,
            "precision": 0.6371814092953523,
            "recall": 0.8762886597938144
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7657013240720122,
            "auditor_fn_violation": 0.008400057108217732,
            "auditor_fp_violation": 0.011096155087890093,
            "ave_precision_score": 0.7658520211300726,
            "fpr": 0.24368825466520308,
            "logloss": 0.8123659238429903,
            "mae": 0.339332217605652,
            "precision": 0.65527950310559,
            "recall": 0.8997867803837953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.36766069246895,
            "mae": 0.5317982456140351,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.781214192330527,
            "mae": 0.5148188803512623,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7633612408610503,
            "auditor_fn_violation": 0.01493262796165673,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.7639388132938072,
            "fpr": 0.017543859649122806,
            "logloss": 1.0292068163354562,
            "mae": 0.43452914402204396,
            "precision": 0.8740157480314961,
            "recall": 0.2288659793814433
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7866791057327989,
            "auditor_fn_violation": 0.009696694510823674,
            "auditor_fp_violation": 0.003841931942919868,
            "ave_precision_score": 0.7869850852208871,
            "fpr": 0.014270032930845226,
            "logloss": 0.9644409860857474,
            "mae": 0.4142232177797991,
            "precision": 0.8984375,
            "recall": 0.24520255863539445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.58834064336589,
            "auditor_fn_violation": 0.03962063664315429,
            "auditor_fp_violation": 0.021102962323842393,
            "ave_precision_score": 0.5900165600486544,
            "fpr": 0.06030701754385965,
            "logloss": 5.936452953689173,
            "mae": 0.4867848382992467,
            "precision": 0.6333333333333333,
            "recall": 0.1958762886597938
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.596831804055486,
            "auditor_fn_violation": 0.040874504691533725,
            "auditor_fp_violation": 0.018745250358861775,
            "ave_precision_score": 0.5990401453838129,
            "fpr": 0.05598243688254665,
            "logloss": 5.963355618754421,
            "mae": 0.4649348391786228,
            "precision": 0.6666666666666666,
            "recall": 0.21748400852878466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.695694273311646,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6901475497562577,
            "fpr": 0.0021929824561403508,
            "logloss": 0.650027069975334,
            "mae": 0.4634096175432205,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6608987980597689,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.6560485993087212,
            "fpr": 0.006586169045005488,
            "logloss": 0.6470731816566653,
            "mae": 0.4587619358634844,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8242643004192058,
            "auditor_fn_violation": 0.01325510942304215,
            "auditor_fp_violation": 0.003428140022186614,
            "ave_precision_score": 0.7893940553377956,
            "fpr": 0.01206140350877193,
            "logloss": 0.6152584287459095,
            "mae": 0.42875984281693635,
            "precision": 0.9290322580645162,
            "recall": 0.29690721649484536
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.8366153981384092,
            "auditor_fn_violation": 0.0024317802550677726,
            "auditor_fp_violation": 0.0013187238924954432,
            "ave_precision_score": 0.8009302997034176,
            "fpr": 0.012074643249176729,
            "logloss": 0.6030127891561069,
            "mae": 0.42290024474083265,
            "precision": 0.9294871794871795,
            "recall": 0.3091684434968017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6956547774446018,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6901090544625338,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6500306280560426,
            "mae": 0.46340754131476086,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6609020933494051,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.6560505863446416,
            "fpr": 0.006586169045005488,
            "logloss": 0.6470761598692417,
            "mae": 0.4587590240032037,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7091377306308309,
            "auditor_fn_violation": 0.008025863628142524,
            "auditor_fp_violation": 0.014567669172932342,
            "ave_precision_score": 0.7107796950278433,
            "fpr": 0.2675438596491228,
            "logloss": 0.9666499519472844,
            "mae": 0.36937908820612775,
            "precision": 0.6352765321375187,
            "recall": 0.8762886597938144
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7654519906253265,
            "auditor_fn_violation": 0.008453888624932421,
            "auditor_fp_violation": 0.01179401085774174,
            "ave_precision_score": 0.7656307004894074,
            "fpr": 0.24478594950603733,
            "logloss": 0.8134512913393779,
            "mae": 0.3391752140769503,
            "precision": 0.6531881804043546,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7190711122034383,
            "auditor_fn_violation": 0.10489916802315068,
            "auditor_fp_violation": 0.09864825999424794,
            "ave_precision_score": 0.5659655206346129,
            "fpr": 0.27960526315789475,
            "logloss": 0.686461256891385,
            "mae": 0.4957220176921079,
            "precision": 0.5735785953177257,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6792125087173928,
            "auditor_fn_violation": 0.10153560252680459,
            "auditor_fp_violation": 0.10526446498552137,
            "ave_precision_score": 0.5555037366891836,
            "fpr": 0.283205268935236,
            "logloss": 0.6856010957489292,
            "mae": 0.4932283796410922,
            "precision": 0.5597269624573379,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7343184352449802,
            "auditor_fn_violation": 0.026745342738289022,
            "auditor_fp_violation": 0.041545975594724525,
            "ave_precision_score": 0.7350936282918329,
            "fpr": 0.29605263157894735,
            "logloss": 0.6105462119782312,
            "mae": 0.4249003359378038,
            "precision": 0.6058394160583942,
            "recall": 0.8556701030927835
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7304305005739515,
            "auditor_fn_violation": 0.014752176080550674,
            "auditor_fp_violation": 0.03246395239679932,
            "ave_precision_score": 0.7309341776746647,
            "fpr": 0.31174533479692645,
            "logloss": 0.603838029684074,
            "mae": 0.4218586639191395,
            "precision": 0.5919540229885057,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8054545763500689,
            "auditor_fn_violation": 0.0038343280882618923,
            "auditor_fp_violation": 0.006853712149225527,
            "ave_precision_score": 0.805786823764562,
            "fpr": 0.38596491228070173,
            "logloss": 0.6124829456417307,
            "mae": 0.41375807868602704,
            "precision": 0.5707317073170731,
            "recall": 0.9649484536082474
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8005211902951619,
            "auditor_fn_violation": 0.0006319351962158797,
            "auditor_fp_violation": 0.01108125425294667,
            "ave_precision_score": 0.8008968359830817,
            "fpr": 0.40175631174533477,
            "logloss": 0.614959053517777,
            "mae": 0.40911473097222417,
            "precision": 0.5525672371638142,
            "recall": 0.9637526652452025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7827868462173486,
            "auditor_fn_violation": 0.01739916802315066,
            "auditor_fp_violation": 0.02182197296519988,
            "ave_precision_score": 0.7825158504599966,
            "fpr": 0.16885964912280702,
            "logloss": 1.0328979591738814,
            "mae": 0.30726150263135904,
            "precision": 0.7148148148148148,
            "recall": 0.7958762886597938
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8084548944418356,
            "auditor_fn_violation": 0.014913670630694736,
            "auditor_fp_violation": 0.02390590619427709,
            "ave_precision_score": 0.8079535217459395,
            "fpr": 0.1668496158068057,
            "logloss": 0.8941838130447926,
            "mae": 0.2890187426809882,
            "precision": 0.7185185185185186,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 9292,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7034941000876265,
            "auditor_fn_violation": 0.0075804847169470115,
            "auditor_fp_violation": 0.004812235506799786,
            "ave_precision_score": 0.612020834706931,
            "fpr": 0.019736842105263157,
            "logloss": 0.6643051627561111,
            "mae": 0.47666031821516525,
            "precision": 0.7804878048780488,
            "recall": 0.13195876288659794
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7089043791727242,
            "auditor_fn_violation": 0.004355671852436101,
            "auditor_fp_violation": 0.0018725382578937176,
            "ave_precision_score": 0.5909853392733997,
            "fpr": 0.014270032930845226,
            "logloss": 0.6628357834954234,
            "mae": 0.4755143937700797,
            "precision": 0.8266666666666667,
            "recall": 0.13219616204690832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7373760277189536,
            "auditor_fn_violation": 0.009206004702477845,
            "auditor_fp_violation": 0.007585562266321549,
            "ave_precision_score": 0.7390389231439581,
            "fpr": 0.23793859649122806,
            "logloss": 0.8108338131302946,
            "mae": 0.35355806347284835,
            "precision": 0.6571879936808847,
            "recall": 0.8577319587628865
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8142645417596747,
            "auditor_fn_violation": 0.009993938103117779,
            "auditor_fp_violation": 0.017356989236630233,
            "ave_precision_score": 0.8148138404231053,
            "fpr": 0.20087815587266739,
            "logloss": 0.6264762691883595,
            "mae": 0.31230084858126794,
            "precision": 0.6944908180300501,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8016697052033109,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.8026498315748516,
            "fpr": 0.4451754385964912,
            "logloss": 3.6268648465235103,
            "mae": 0.45280636149842063,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8103418580677408,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.8123634147416862,
            "fpr": 0.45554335894621295,
            "logloss": 3.7143843164592867,
            "mae": 0.4642648506426837,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7190711122034383,
            "auditor_fn_violation": 0.10489916802315068,
            "auditor_fp_violation": 0.09864825999424794,
            "ave_precision_score": 0.5659655206346129,
            "fpr": 0.27960526315789475,
            "logloss": 0.6864572045202401,
            "mae": 0.4957195816136766,
            "precision": 0.5735785953177257,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6792125087173928,
            "auditor_fn_violation": 0.10153560252680459,
            "auditor_fp_violation": 0.10526446498552137,
            "ave_precision_score": 0.5555037366891836,
            "fpr": 0.283205268935236,
            "logloss": 0.6856000305082907,
            "mae": 0.49322753735745384,
            "precision": 0.5597269624573379,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7843037233754115,
            "auditor_fn_violation": 0.0001650388858744802,
            "auditor_fp_violation": 0.0072799827437446275,
            "ave_precision_score": 0.7851705446195925,
            "fpr": 0.4451754385964912,
            "logloss": 2.7339130431151237,
            "mae": 0.45253189056671783,
            "precision": 0.5407239819004525,
            "recall": 0.9855670103092784
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7844590920321,
            "auditor_fn_violation": 0.0024294397543410443,
            "auditor_fp_violation": 0.005702052838360713,
            "ave_precision_score": 0.7861002065329351,
            "fpr": 0.45554335894621295,
            "logloss": 2.7959972998098364,
            "mae": 0.4639018228464227,
            "precision": 0.526255707762557,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7190711122034383,
            "auditor_fn_violation": 0.10489916802315068,
            "auditor_fp_violation": 0.09864825999424794,
            "ave_precision_score": 0.5659655206346129,
            "fpr": 0.27960526315789475,
            "logloss": 0.6864544593631461,
            "mae": 0.49572652104523096,
            "precision": 0.5735785953177257,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6792125087173928,
            "auditor_fn_violation": 0.10153560252680459,
            "auditor_fp_violation": 0.10526446498552137,
            "ave_precision_score": 0.5555037366891836,
            "fpr": 0.283205268935236,
            "logloss": 0.6856689270059593,
            "mae": 0.4932638027927093,
            "precision": 0.5597269624573379,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7285494937735203,
            "auditor_fn_violation": 0.009280611322119735,
            "auditor_fp_violation": 0.01983699001602366,
            "ave_precision_score": 0.73003820216863,
            "fpr": 0.2774122807017544,
            "logloss": 0.9307191028593496,
            "mae": 0.3769905253043521,
            "precision": 0.6212574850299402,
            "recall": 0.8556701030927835
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7821031199189374,
            "auditor_fn_violation": 0.010445654743375799,
            "auditor_fp_violation": 0.012829618886311603,
            "ave_precision_score": 0.7826660529771752,
            "fpr": 0.2678375411635565,
            "logloss": 0.8005881815353626,
            "mae": 0.34884923709579524,
            "precision": 0.6330827067669172,
            "recall": 0.8976545842217484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6955976987963178,
            "auditor_fn_violation": 0.006572164948453614,
            "auditor_fp_violation": 0.0011606886067628086,
            "ave_precision_score": 0.6900531786112036,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6500994243506103,
            "mae": 0.4633725893994172,
            "precision": 0.9746835443037974,
            "recall": 0.15876288659793814
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6607321288264394,
            "auditor_fn_violation": 0.0035201130929951264,
            "auditor_fp_violation": 0.0028510264191803554,
            "ave_precision_score": 0.6558868842788905,
            "fpr": 0.006586169045005488,
            "logloss": 0.6471330121535969,
            "mae": 0.45870897448677916,
            "precision": 0.9347826086956522,
            "recall": 0.18336886993603413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7383360769395595,
            "auditor_fn_violation": 0.01207496834870682,
            "auditor_fp_violation": 0.011768663461933518,
            "ave_precision_score": 0.7399862471066065,
            "fpr": 0.23355263157894737,
            "logloss": 0.8191048098166193,
            "mae": 0.3517538026072292,
            "precision": 0.6597444089456869,
            "recall": 0.8515463917525773
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8143246229179686,
            "auditor_fn_violation": 0.015056441175024986,
            "auditor_fp_violation": 0.018611142844370716,
            "ave_precision_score": 0.8148479946923014,
            "fpr": 0.19758507135016465,
            "logloss": 0.6497929036477816,
            "mae": 0.3118358113731152,
            "precision": 0.6964586846543002,
            "recall": 0.8805970149253731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7685914718026048,
            "auditor_fn_violation": 0.012479652740097677,
            "auditor_fp_violation": 0.00686141583466864,
            "ave_precision_score": 0.769122800876828,
            "fpr": 0.017543859649122806,
            "logloss": 0.9179927089664233,
            "mae": 0.4248865378684601,
            "precision": 0.8778625954198473,
            "recall": 0.23711340206185566
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7900715192596958,
            "auditor_fn_violation": 0.006970011164188462,
            "auditor_fp_violation": 0.004097729609449117,
            "ave_precision_score": 0.7903422446021225,
            "fpr": 0.01756311745334797,
            "logloss": 0.8612427007642397,
            "mae": 0.40568300459736345,
            "precision": 0.8857142857142857,
            "recall": 0.26439232409381663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5947185791844232,
            "auditor_fn_violation": 0.026153011394465558,
            "auditor_fp_violation": 0.010592567484284481,
            "ave_precision_score": 0.5966023312967754,
            "fpr": 0.10087719298245613,
            "logloss": 5.796211117322425,
            "mae": 0.4780777586612276,
            "precision": 0.6260162601626016,
            "recall": 0.31752577319587627
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.612254779649271,
            "auditor_fn_violation": 0.019695313615394883,
            "auditor_fp_violation": 0.007527405118933496,
            "ave_precision_score": 0.6138523459179261,
            "fpr": 0.0867178924259056,
            "logloss": 5.824319468804544,
            "mae": 0.45291436146668473,
            "precision": 0.6652542372881356,
            "recall": 0.3347547974413646
        }
    }
]