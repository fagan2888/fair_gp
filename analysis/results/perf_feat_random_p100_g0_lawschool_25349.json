[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8525991922582441,
            "auditor_fn_violation": 0.018974757952973726,
            "auditor_fp_violation": 0.023908608731130154,
            "ave_precision_score": 0.8528251424042699,
            "fpr": 0.125,
            "logloss": 0.7196302446041006,
            "mae": 0.264885151804769,
            "precision": 0.7659137577002053,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.836831411480884,
            "auditor_fn_violation": 0.021177138179314967,
            "auditor_fp_violation": 0.024964431186535612,
            "ave_precision_score": 0.8374487181502424,
            "fpr": 0.1251372118551043,
            "logloss": 0.7410296883224547,
            "mae": 0.2629694351383742,
            "precision": 0.7625,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8403316815804336,
            "auditor_fn_violation": 0.007693637621023517,
            "auditor_fp_violation": 0.014912280701754392,
            "ave_precision_score": 0.840553662873254,
            "fpr": 0.18859649122807018,
            "logloss": 0.533565316341042,
            "mae": 0.3637141070147775,
            "precision": 0.7079796264855688,
            "recall": 0.8651452282157677
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8400198503545517,
            "auditor_fn_violation": 0.007102457720143631,
            "auditor_fp_violation": 0.01569278546942083,
            "ave_precision_score": 0.8405500269744657,
            "fpr": 0.16575192096597147,
            "logloss": 0.5264649722625383,
            "mae": 0.3597205341798708,
            "precision": 0.7274368231046932,
            "recall": 0.8538135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5971404718152992,
            "auditor_fn_violation": 0.0034669141734003056,
            "auditor_fp_violation": 0.007185842513259892,
            "ave_precision_score": 0.5989678067037741,
            "fpr": 0.4309210526315789,
            "logloss": 0.9018282742546827,
            "mae": 0.4555866800150589,
            "precision": 0.5451388888888888,
            "recall": 0.9771784232365145
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5703610725790298,
            "auditor_fn_violation": 0.004507060596476215,
            "auditor_fp_violation": 0.00484335969634611,
            "ave_precision_score": 0.5719391915484757,
            "fpr": 0.446761800219539,
            "logloss": 0.9428929408640121,
            "mae": 0.4684382159217914,
            "precision": 0.5272938443670151,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7931460780678901,
            "auditor_fn_violation": 0.010548609594525735,
            "auditor_fp_violation": 0.040215728274173815,
            "ave_precision_score": 0.6221498952074774,
            "fpr": 0.2774122807017544,
            "logloss": 0.6271370750931612,
            "mae": 0.44863202775779526,
            "precision": 0.6322674418604651,
            "recall": 0.9024896265560166
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7670494162509829,
            "auditor_fn_violation": 0.007023386481608966,
            "auditor_fp_violation": 0.03912694503274333,
            "ave_precision_score": 0.5898238795829449,
            "fpr": 0.29527991218441274,
            "logloss": 0.6518046213106563,
            "mae": 0.45976775537861425,
            "precision": 0.6014814814814815,
            "recall": 0.8601694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7507813719146548,
            "auditor_fn_violation": 0.011699697896192775,
            "auditor_fp_violation": 0.027062933496532035,
            "ave_precision_score": 0.7517207398572326,
            "fpr": 0.1524122807017544,
            "logloss": 0.6801141561634143,
            "mae": 0.3780731403089145,
            "precision": 0.7067510548523207,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7292304198656061,
            "auditor_fn_violation": 0.015918900816759386,
            "auditor_fp_violation": 0.023301636040397183,
            "ave_precision_score": 0.7298238097349745,
            "fpr": 0.1964873765093304,
            "logloss": 0.7386875112135106,
            "mae": 0.3971120868078571,
            "precision": 0.6531007751937985,
            "recall": 0.7139830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7850710825538891,
            "auditor_fn_violation": 0.006715440052413191,
            "auditor_fp_violation": 0.023694410444716443,
            "ave_precision_score": 0.7398837226703865,
            "fpr": 0.17763157894736842,
            "logloss": 4.315355212754714,
            "mae": 0.30045197572375104,
            "precision": 0.699443413729128,
            "recall": 0.7821576763485477
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7530928222201474,
            "auditor_fn_violation": 0.011869988278851698,
            "auditor_fp_violation": 0.02490192009081612,
            "ave_precision_score": 0.6972255644261842,
            "fpr": 0.21514818880351264,
            "logloss": 5.030420536664059,
            "mae": 0.3316589012790504,
            "precision": 0.6524822695035462,
            "recall": 0.7796610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6773851641461648,
            "auditor_fn_violation": 0.01048263813059619,
            "auditor_fp_violation": 0.0120359037127703,
            "ave_precision_score": 0.6780063938086562,
            "fpr": 0.09868421052631579,
            "logloss": 0.8570708470728575,
            "mae": 0.4410568241397222,
            "precision": 0.7019867549668874,
            "recall": 0.43983402489626555
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6805453493950797,
            "auditor_fn_violation": 0.015125862806749915,
            "auditor_fp_violation": 0.010561874732765065,
            "ave_precision_score": 0.682261356709297,
            "fpr": 0.08562019758507135,
            "logloss": 0.7941636848916033,
            "mae": 0.42717543261843344,
            "precision": 0.7272727272727273,
            "recall": 0.4406779661016949
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6774829201153836,
            "auditor_fn_violation": 0.009872970808764652,
            "auditor_fp_violation": 0.008210934312525503,
            "ave_precision_score": 0.6624537947674225,
            "fpr": 0.043859649122807015,
            "logloss": 10.732720198665588,
            "mae": 0.40639501258584687,
            "precision": 0.7959183673469388,
            "recall": 0.3236514522821577
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6500900719206504,
            "auditor_fn_violation": 0.010511823475785612,
            "auditor_fp_violation": 0.00486336324697634,
            "ave_precision_score": 0.6418963625962516,
            "fpr": 0.04610318331503842,
            "logloss": 10.993940339997026,
            "mae": 0.4116063036273566,
            "precision": 0.7717391304347826,
            "recall": 0.3008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7892978683270269,
            "auditor_fn_violation": 0.03197568610322486,
            "auditor_fp_violation": 0.03693390452876378,
            "ave_precision_score": 0.7624986274037007,
            "fpr": 0.1787280701754386,
            "logloss": 1.042890728318591,
            "mae": 0.35777501782629795,
            "precision": 0.6912878787878788,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7891045788802257,
            "auditor_fn_violation": 0.028205175910249496,
            "auditor_fp_violation": 0.033298410467858044,
            "ave_precision_score": 0.7749116646797739,
            "fpr": 0.16245883644346873,
            "logloss": 1.0134607369928477,
            "mae": 0.34582593309085263,
            "precision": 0.7063492063492064,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.814242678855363,
            "auditor_fn_violation": 0.006851932736405326,
            "auditor_fp_violation": 0.012693798449612402,
            "ave_precision_score": 0.7959420865088285,
            "fpr": 0.10087719298245613,
            "logloss": 0.5605040828341985,
            "mae": 0.3780326591232759,
            "precision": 0.775609756097561,
            "recall": 0.6597510373443983
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8005989603307386,
            "auditor_fn_violation": 0.0018977097248321024,
            "auditor_fp_violation": 0.005868541666145743,
            "ave_precision_score": 0.7880646160719704,
            "fpr": 0.09549945115257959,
            "logloss": 0.5626218135480545,
            "mae": 0.3798359290223352,
            "precision": 0.779746835443038,
            "recall": 0.652542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8370201542873619,
            "auditor_fn_violation": 0.005659896629540658,
            "auditor_fp_violation": 0.008440432476540194,
            "ave_precision_score": 0.8374082510816889,
            "fpr": 0.14802631578947367,
            "logloss": 0.5205594124963029,
            "mae": 0.32827385369966033,
            "precision": 0.7443181818181818,
            "recall": 0.8153526970954357
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8570098862681251,
            "auditor_fn_violation": 0.011611843941282627,
            "auditor_fp_violation": 0.00956169720125323,
            "ave_precision_score": 0.8572799267297024,
            "fpr": 0.1251372118551043,
            "logloss": 0.4809497032621387,
            "mae": 0.3151096767642659,
            "precision": 0.768762677484787,
            "recall": 0.8029661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 25349,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8419165159059107,
            "auditor_fn_violation": 0.0029937395355608934,
            "auditor_fp_violation": 0.014463484292125664,
            "ave_precision_score": 0.8421958838504235,
            "fpr": 0.14035087719298245,
            "logloss": 0.5149266047808545,
            "mae": 0.32239533422653677,
            "precision": 0.751937984496124,
            "recall": 0.8049792531120332
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8544079696410762,
            "auditor_fn_violation": 0.006986176487004409,
            "auditor_fp_violation": 0.010434352097497308,
            "ave_precision_score": 0.8548134387555693,
            "fpr": 0.1251372118551043,
            "logloss": 0.4791504160931767,
            "mae": 0.3104786650286875,
            "precision": 0.7692307692307693,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5848383028102105,
            "auditor_fn_violation": 0.029482419742301817,
            "auditor_fp_violation": 0.02542329661362709,
            "ave_precision_score": 0.5504109058892154,
            "fpr": 0.05701754385964912,
            "logloss": 14.093653200048697,
            "mae": 0.5017395162103625,
            "precision": 0.6090225563909775,
            "recall": 0.16804979253112035
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6097210751730613,
            "auditor_fn_violation": 0.0386704868927794,
            "auditor_fp_violation": 0.019933538203031037,
            "ave_precision_score": 0.5654430382444948,
            "fpr": 0.054884742041712405,
            "logloss": 13.173540550717618,
            "mae": 0.4705968584505732,
            "precision": 0.647887323943662,
            "recall": 0.19491525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8347285825433727,
            "auditor_fn_violation": 0.05145091723083643,
            "auditor_fp_violation": 0.03526111791105671,
            "ave_precision_score": 0.8349652801701041,
            "fpr": 0.15570175438596492,
            "logloss": 0.5554734647610299,
            "mae": 0.3287612469437973,
            "precision": 0.7253384912959381,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8455022026234298,
            "auditor_fn_violation": 0.042312415114699804,
            "auditor_fp_violation": 0.03452612838778883,
            "ave_precision_score": 0.84592924790425,
            "fpr": 0.14270032930845225,
            "logloss": 0.5083872753636322,
            "mae": 0.3074432290082493,
            "precision": 0.7485493230174082,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8162588147243226,
            "auditor_fn_violation": 0.003403217587537306,
            "auditor_fp_violation": 0.005153508771929826,
            "ave_precision_score": 0.816554405837038,
            "fpr": 0.047149122807017545,
            "logloss": 0.6206285398655684,
            "mae": 0.3742760930560364,
            "precision": 0.8401486988847584,
            "recall": 0.46887966804979253
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8111951464624256,
            "auditor_fn_violation": 0.0022209715529591272,
            "auditor_fp_violation": 0.006088580723078349,
            "ave_precision_score": 0.8116019609424897,
            "fpr": 0.03512623490669594,
            "logloss": 0.6164444724459482,
            "mae": 0.3722901410335301,
            "precision": 0.8704453441295547,
            "recall": 0.4555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 25349,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5046984636367156,
            "auditor_fn_violation": 0.004738571012593726,
            "auditor_fp_violation": 0.0036005711954304603,
            "ave_precision_score": 0.5065347821604647,
            "fpr": 0.4451754385964912,
            "logloss": 0.6969103936940697,
            "mae": 0.49897671990880843,
            "precision": 0.5251461988304094,
            "recall": 0.9315352697095436
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.535102958655034,
            "auditor_fn_violation": 0.013428156802917264,
            "auditor_fp_violation": 0.0032255725391257093,
            "ave_precision_score": 0.5372356075335669,
            "fpr": 0.4500548847420417,
            "logloss": 0.6948564525299091,
            "mae": 0.49811924295551036,
            "precision": 0.5165094339622641,
            "recall": 0.9279661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6252426878295326,
            "auditor_fn_violation": 0.006601696149086412,
            "auditor_fp_violation": 0.013744390044879661,
            "ave_precision_score": 0.55795126717695,
            "fpr": 0.28399122807017546,
            "logloss": 5.775030092251233,
            "mae": 0.4106618631453206,
            "precision": 0.6081694402420574,
            "recall": 0.8340248962655602
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6275783873709382,
            "auditor_fn_violation": 0.0017442184970883233,
            "auditor_fp_violation": 0.007468825716564696,
            "ave_precision_score": 0.5641106829841259,
            "fpr": 0.2557628979143798,
            "logloss": 5.516387490975785,
            "mae": 0.4074099187941166,
            "precision": 0.6266025641025641,
            "recall": 0.8283898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.8281068802183656,
            "auditor_fn_violation": 0.0057281429715367255,
            "auditor_fp_violation": 0.011678906568747458,
            "ave_precision_score": 0.8281024471523282,
            "fpr": 0.42214912280701755,
            "logloss": 0.7629067196314334,
            "mae": 0.39524103908211383,
            "precision": 0.5497076023391813,
            "recall": 0.975103734439834
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.8377456599372759,
            "auditor_fn_violation": 0.0023488809094122684,
            "auditor_fp_violation": 0.010854426660732287,
            "ave_precision_score": 0.8378077235416438,
            "fpr": 0.424807903402854,
            "logloss": 0.7351005342587755,
            "mae": 0.3927074772695286,
            "precision": 0.5463071512309496,
            "recall": 0.9872881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8343143627485279,
            "auditor_fn_violation": 0.00914046007134018,
            "auditor_fp_violation": 0.01188290493676051,
            "ave_precision_score": 0.8275369309489062,
            "fpr": 0.09868421052631579,
            "logloss": 0.5257464998241363,
            "mae": 0.3112052625796774,
            "precision": 0.7945205479452054,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8417649090363101,
            "auditor_fn_violation": 0.008688533740162608,
            "auditor_fp_violation": 0.004115730542171239,
            "ave_precision_score": 0.8325054002297582,
            "fpr": 0.08562019758507135,
            "logloss": 0.5000538233708263,
            "mae": 0.3020593482759729,
            "precision": 0.8164705882352942,
            "recall": 0.7351694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.777631920619061,
            "auditor_fn_violation": 0.014288509135910314,
            "auditor_fp_violation": 0.0186046511627907,
            "ave_precision_score": 0.7485089682031625,
            "fpr": 0.12280701754385964,
            "logloss": 1.9191882496663968,
            "mae": 0.3251369292194253,
            "precision": 0.7389277389277389,
            "recall": 0.6576763485477178
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7413603802236128,
            "auditor_fn_violation": 0.012700236283465742,
            "auditor_fp_violation": 0.02224894918848096,
            "ave_precision_score": 0.707560767753931,
            "fpr": 0.16136114160263446,
            "logloss": 2.3011643402664026,
            "mae": 0.3535073255848152,
            "precision": 0.6790393013100436,
            "recall": 0.6588983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8525293540446304,
            "auditor_fn_violation": 0.009522639586518169,
            "auditor_fp_violation": 0.02129232966136272,
            "ave_precision_score": 0.8529759192454994,
            "fpr": 0.1699561403508772,
            "logloss": 0.5549661973003642,
            "mae": 0.30046386161133376,
            "precision": 0.7217235188509874,
            "recall": 0.8340248962655602
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8417855413923401,
            "auditor_fn_violation": 0.007125713966771477,
            "auditor_fp_violation": 0.021346288966291524,
            "ave_precision_score": 0.842121850415757,
            "fpr": 0.1778265642151482,
            "logloss": 0.5492862888579823,
            "mae": 0.29761918959474654,
            "precision": 0.7137809187279152,
            "recall": 0.8559322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8131494810744031,
            "auditor_fn_violation": 0.001362651961854846,
            "auditor_fp_violation": 0.010031619747042026,
            "ave_precision_score": 0.7834448633307307,
            "fpr": 0.10197368421052631,
            "logloss": 0.5388379473225795,
            "mae": 0.33992931553930567,
            "precision": 0.7905405405405406,
            "recall": 0.7282157676348547
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.827816651888806,
            "auditor_fn_violation": 0.004939626783754113,
            "auditor_fp_violation": 0.006056074953304215,
            "ave_precision_score": 0.8024241081611003,
            "fpr": 0.09659714599341383,
            "logloss": 0.5171183389693685,
            "mae": 0.3329671673664801,
            "precision": 0.8009049773755657,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8345466108397348,
            "auditor_fn_violation": 0.0033895683191380956,
            "auditor_fp_violation": 0.017288861689106497,
            "ave_precision_score": 0.8348192721929022,
            "fpr": 0.16228070175438597,
            "logloss": 0.6969397671805821,
            "mae": 0.2865193352397335,
            "precision": 0.7366548042704626,
            "recall": 0.8589211618257261
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8063579085948043,
            "auditor_fn_violation": 0.008121081322443208,
            "auditor_fp_violation": 0.010616884496998217,
            "ave_precision_score": 0.8068876503948853,
            "fpr": 0.16575192096597147,
            "logloss": 0.763858161692059,
            "mae": 0.2943534750990267,
            "precision": 0.7289048473967684,
            "recall": 0.8601694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5761599143985652,
            "auditor_fn_violation": 0.007507097619567589,
            "auditor_fp_violation": 0.009679722562219516,
            "ave_precision_score": 0.5777125857683245,
            "fpr": 0.3881578947368421,
            "logloss": 0.6915770098408456,
            "mae": 0.4990433189495091,
            "precision": 0.527369826435247,
            "recall": 0.8195020746887967
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5471912325360598,
            "auditor_fn_violation": 0.0025209771344583192,
            "auditor_fp_violation": 0.006851216090856142,
            "ave_precision_score": 0.5490948557769656,
            "fpr": 0.40504939626783754,
            "logloss": 0.6930019190867792,
            "mae": 0.4997574690929752,
            "precision": 0.5119047619047619,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7088868532824106,
            "auditor_fn_violation": 0.009304251292130743,
            "auditor_fp_violation": 0.012642798857609142,
            "ave_precision_score": 0.7102752430984816,
            "fpr": 0.1513157894736842,
            "logloss": 0.6082041978207428,
            "mae": 0.3769333865330146,
            "precision": 0.727810650887574,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7544663436166659,
            "auditor_fn_violation": 0.008888537461162074,
            "auditor_fp_violation": 0.006606172595635728,
            "ave_precision_score": 0.7557289945517842,
            "fpr": 0.11964873765093303,
            "logloss": 0.558548210382008,
            "mae": 0.35860005519981575,
            "precision": 0.7665952890792291,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5630187859986053,
            "auditor_fn_violation": 0.008576290310839337,
            "auditor_fp_violation": 0.004146266829865363,
            "ave_precision_score": 0.5543520362459248,
            "fpr": 0.03179824561403509,
            "logloss": 0.723083694999232,
            "mae": 0.49972661205551083,
            "precision": 0.5396825396825397,
            "recall": 0.07053941908713693
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5470605360036468,
            "auditor_fn_violation": 0.0032279670319447866,
            "auditor_fp_violation": 0.003723160861052838,
            "ave_precision_score": 0.5359901378971199,
            "fpr": 0.030735455543358946,
            "logloss": 0.7224001847619183,
            "mae": 0.4996029320126962,
            "precision": 0.5625,
            "recall": 0.07627118644067797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6937571371353328,
            "auditor_fn_violation": 0.008130414209798355,
            "auditor_fp_violation": 0.004312015503875972,
            "ave_precision_score": 0.6913849557724513,
            "fpr": 0.0625,
            "logloss": 7.215260733784903,
            "mae": 0.41677598911889024,
            "precision": 0.7574468085106383,
            "recall": 0.36929460580912865
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6595518034232262,
            "auditor_fn_violation": 0.014139797949729298,
            "auditor_fp_violation": 0.013472391349464532,
            "ave_precision_score": 0.6599744208627398,
            "fpr": 0.06366630076838639,
            "logloss": 7.155123024638571,
            "mae": 0.417380840188166,
            "precision": 0.7363636363636363,
            "recall": 0.3432203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.659306085516228,
            "auditor_fn_violation": 0.028181189488243434,
            "auditor_fp_violation": 0.050790493676050597,
            "ave_precision_score": 0.6628053097008078,
            "fpr": 0.32456140350877194,
            "logloss": 0.6711436858200053,
            "mae": 0.44071378129975575,
            "precision": 0.5877437325905293,
            "recall": 0.8755186721991701
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6337687102165183,
            "auditor_fn_violation": 0.023986492771958554,
            "auditor_fp_violation": 0.04116230630936992,
            "ave_precision_score": 0.6394733300862089,
            "fpr": 0.35236004390779363,
            "logloss": 0.6963494589017146,
            "mae": 0.4480999245969773,
            "precision": 0.560875512995896,
            "recall": 0.8686440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6832338871922461,
            "auditor_fn_violation": 0.0033668195384727504,
            "auditor_fp_violation": 0.010505915952672381,
            "ave_precision_score": 0.6848271564224865,
            "fpr": 0.08333333333333333,
            "logloss": 0.6528227929224779,
            "mae": 0.45487660685913606,
            "precision": 0.7256317689530686,
            "recall": 0.4170124481327801
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7429787339778171,
            "auditor_fn_violation": 0.003953561926733532,
            "auditor_fp_violation": 0.004795851263599291,
            "ave_precision_score": 0.743622951785528,
            "fpr": 0.07683863885839737,
            "logloss": 0.6265637028297434,
            "mae": 0.4430002214879812,
            "precision": 0.7348484848484849,
            "recall": 0.4110169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8474335871545324,
            "auditor_fn_violation": 0.0006255914682972953,
            "auditor_fp_violation": 0.009317625458996325,
            "ave_precision_score": 0.8379923542177787,
            "fpr": 0.10087719298245613,
            "logloss": 0.5074388054709444,
            "mae": 0.3190463712957704,
            "precision": 0.7932584269662921,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8503531432748119,
            "auditor_fn_violation": 0.006074531619192919,
            "auditor_fp_violation": 0.011742084219949045,
            "ave_precision_score": 0.840891167836387,
            "fpr": 0.09440175631174534,
            "logloss": 0.4838450303177557,
            "mae": 0.30455741395664726,
            "precision": 0.8041002277904328,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8532229266914041,
            "auditor_fn_violation": 0.0058851095581276885,
            "auditor_fp_violation": 0.01393308853529172,
            "ave_precision_score": 0.8316103239438085,
            "fpr": 0.17214912280701755,
            "logloss": 0.5220948832920669,
            "mae": 0.3296525434411147,
            "precision": 0.7176258992805755,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8571853582780129,
            "auditor_fn_violation": 0.007535023907421534,
            "auditor_fp_violation": 0.009436675009814245,
            "ave_precision_score": 0.834422307275277,
            "fpr": 0.14489571899012074,
            "logloss": 0.5031954910635513,
            "mae": 0.32010172528309827,
            "precision": 0.7441860465116279,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7191027351899757,
            "auditor_fn_violation": 0.013981400596927998,
            "auditor_fp_violation": 0.006244900040799678,
            "ave_precision_score": 0.7194854117346396,
            "fpr": 0.09978070175438597,
            "logloss": 1.8356137073369128,
            "mae": 0.4186715261840627,
            "precision": 0.7299703264094956,
            "recall": 0.5103734439834025
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.718992548422325,
            "auditor_fn_violation": 0.007962938845373867,
            "auditor_fp_violation": 0.002905515729041909,
            "ave_precision_score": 0.7194577507345002,
            "fpr": 0.07683863885839737,
            "logloss": 1.700745221605821,
            "mae": 0.4043285463819777,
            "precision": 0.7741935483870968,
            "recall": 0.5084745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.8275553531986887,
            "auditor_fn_violation": 0.0016015141588410914,
            "auditor_fp_violation": 0.003575071399428805,
            "ave_precision_score": 0.8145084672375056,
            "fpr": 0.03070175438596491,
            "logloss": 0.798767420837084,
            "mae": 0.4032192183638057,
            "precision": 0.8715596330275229,
            "recall": 0.3941908713692946
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8395644257652539,
            "auditor_fn_violation": 0.012242088224897215,
            "auditor_fp_violation": 0.004963381000127523,
            "ave_precision_score": 0.8260984848332572,
            "fpr": 0.021953896816684963,
            "logloss": 0.778009867960996,
            "mae": 0.3908776802232675,
            "precision": 0.9014778325123153,
            "recall": 0.3877118644067797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8376924790968742,
            "auditor_fn_violation": 0.009802449588702048,
            "auditor_fp_violation": 0.013514891880864955,
            "ave_precision_score": 0.8380578935187344,
            "fpr": 0.08881578947368421,
            "logloss": 0.517674450927173,
            "mae": 0.32678858255620297,
            "precision": 0.8052884615384616,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.864579941470083,
            "auditor_fn_violation": 0.009423431133602491,
            "auditor_fp_violation": 0.004388278919508212,
            "ave_precision_score": 0.8647824619113997,
            "fpr": 0.06915477497255763,
            "logloss": 0.4768272433918856,
            "mae": 0.313627933055923,
            "precision": 0.8413098236775819,
            "recall": 0.7076271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.834936986556625,
            "auditor_fn_violation": 0.007370604935575456,
            "auditor_fp_violation": 0.012981946144430849,
            "ave_precision_score": 0.727516259606097,
            "fpr": 0.0800438596491228,
            "logloss": 0.5542635511241041,
            "mae": 0.35213524756724374,
            "precision": 0.818407960199005,
            "recall": 0.6825726141078838
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8495116705013633,
            "auditor_fn_violation": 0.004553573089731902,
            "auditor_fp_violation": 0.006633677477752302,
            "ave_precision_score": 0.7461043202870958,
            "fpr": 0.06147091108671789,
            "logloss": 0.5249287029813288,
            "mae": 0.34065408846026063,
            "precision": 0.8518518518518519,
            "recall": 0.6822033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6008372865755445,
            "auditor_fn_violation": 0.0074252020091723145,
            "auditor_fp_violation": 0.011961954304365566,
            "ave_precision_score": 0.6062756680495335,
            "fpr": 0.11074561403508772,
            "logloss": 5.668911554997667,
            "mae": 0.4623217815345487,
            "precision": 0.6273062730627307,
            "recall": 0.35269709543568467
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5687878792308677,
            "auditor_fn_violation": 0.005888481646170166,
            "auditor_fp_violation": 0.01421002227895452,
            "ave_precision_score": 0.5721481904970159,
            "fpr": 0.12733260153677278,
            "logloss": 5.6008711493786505,
            "mae": 0.4719092486987693,
            "precision": 0.6013745704467354,
            "recall": 0.3707627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8093600693565076,
            "auditor_fn_violation": 0.0348693310038582,
            "auditor_fp_violation": 0.017645858833129344,
            "ave_precision_score": 0.8091281695833514,
            "fpr": 0.11513157894736842,
            "logloss": 2.2596478819570684,
            "mae": 0.3353479483849852,
            "precision": 0.7608200455580866,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8368943196460723,
            "auditor_fn_violation": 0.03023079499153473,
            "auditor_fp_violation": 0.016220379117293324,
            "ave_precision_score": 0.836515005973947,
            "fpr": 0.08342480790340286,
            "logloss": 2.1170963159114744,
            "mae": 0.3166839789914034,
            "precision": 0.8114143920595533,
            "recall": 0.6927966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8589157628203359,
            "auditor_fn_violation": 0.0007234112251583346,
            "auditor_fp_violation": 0.011168910648714813,
            "ave_precision_score": 0.8591166302108397,
            "fpr": 0.24561403508771928,
            "logloss": 0.5685847983556622,
            "mae": 0.34499157684152587,
            "precision": 0.6606060606060606,
            "recall": 0.9045643153526971
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8734809592875485,
            "auditor_fn_violation": 0.006948966492399861,
            "auditor_fp_violation": 0.017488104138484586,
            "ave_precision_score": 0.8736594669012213,
            "fpr": 0.20965971459934138,
            "logloss": 0.5322290778613193,
            "mae": 0.3353031706044493,
            "precision": 0.6919354838709677,
            "recall": 0.9088983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7731779743272429,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5898091528960714,
            "fpr": 0.47149122807017546,
            "logloss": 0.8483131767459547,
            "mae": 0.47775742908318836,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7808171066658124,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6033739721891632,
            "fpr": 0.4818880351262349,
            "logloss": 0.8540439617064682,
            "mae": 0.48203456912161097,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8081927156788311,
            "auditor_fn_violation": 0.011294769600349423,
            "auditor_fp_violation": 0.01543757649938801,
            "ave_precision_score": 0.763416225663135,
            "fpr": 0.14692982456140352,
            "logloss": 2.5772560200039365,
            "mae": 0.2832211185145593,
            "precision": 0.750465549348231,
            "recall": 0.8360995850622407
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.787244501775535,
            "auditor_fn_violation": 0.017679398686487192,
            "auditor_fp_violation": 0.018065706662932675,
            "ave_precision_score": 0.7315526678052325,
            "fpr": 0.15587266739846323,
            "logloss": 3.14498543853746,
            "mae": 0.28999999761410344,
            "precision": 0.7325800376647834,
            "recall": 0.8241525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7467900423726994,
            "auditor_fn_violation": 0.010139131542549322,
            "auditor_fp_violation": 0.014432884536923705,
            "ave_precision_score": 0.7470705074060026,
            "fpr": 0.03728070175438596,
            "logloss": 1.1955061992595135,
            "mae": 0.4079900262401191,
            "precision": 0.8528138528138528,
            "recall": 0.4087136929460581
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7530879224328733,
            "auditor_fn_violation": 0.024039982139202592,
            "auditor_fp_violation": 0.012987305246681286,
            "ave_precision_score": 0.7510886629905692,
            "fpr": 0.04171240395170143,
            "logloss": 1.2073525562559921,
            "mae": 0.384792289453972,
            "precision": 0.848605577689243,
            "recall": 0.451271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7522409690631626,
            "auditor_fn_violation": 0.010621405692654875,
            "auditor_fp_violation": 0.012805997552019594,
            "ave_precision_score": 0.5270534088925073,
            "fpr": 0.4517543859649123,
            "logloss": 0.6983313215203757,
            "mae": 0.5003012313523836,
            "precision": 0.5269804822043628,
            "recall": 0.9522821576763485
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7559496423817241,
            "auditor_fn_violation": 0.008858304340545872,
            "auditor_fp_violation": 0.016322897314273298,
            "ave_precision_score": 0.5249771849302247,
            "fpr": 0.45554335894621295,
            "logloss": 0.6905478128983115,
            "mae": 0.49681354648587994,
            "precision": 0.5251716247139588,
            "recall": 0.972457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8315782788290337,
            "auditor_fn_violation": 0.004590703938268912,
            "auditor_fp_violation": 0.016452468380252966,
            "ave_precision_score": 0.8318864264773387,
            "fpr": 0.23684210526315788,
            "logloss": 0.5709597011988878,
            "mae": 0.3572530429054607,
            "precision": 0.6630265210608425,
            "recall": 0.8817427385892116
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8497912256509265,
            "auditor_fn_violation": 0.009265288656533146,
            "auditor_fp_violation": 0.02201890835623324,
            "ave_precision_score": 0.8501350886434972,
            "fpr": 0.20417124039517015,
            "logloss": 0.5282498951834116,
            "mae": 0.3401148702568987,
            "precision": 0.693069306930693,
            "recall": 0.8898305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8040308511831741,
            "auditor_fn_violation": 0.005823687850331228,
            "auditor_fp_violation": 0.011908404732762144,
            "ave_precision_score": 0.8038138060777695,
            "fpr": 0.12609649122807018,
            "logloss": 0.5636933456849239,
            "mae": 0.378752095081533,
            "precision": 0.7427293064876958,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8087976036942159,
            "auditor_fn_violation": 0.00707455022419022,
            "auditor_fp_violation": 0.002845505077151197,
            "ave_precision_score": 0.8088634952939493,
            "fpr": 0.1141602634467618,
            "logloss": 0.5448140078848078,
            "mae": 0.36924394001339844,
            "precision": 0.7620137299771167,
            "recall": 0.7055084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5705030525620397,
            "auditor_fn_violation": 0.012566426439542856,
            "auditor_fp_violation": 0.022184822521419834,
            "ave_precision_score": 0.5260731824107647,
            "fpr": 0.1206140350877193,
            "logloss": 0.8344085448259914,
            "mae": 0.5104237600442088,
            "precision": 0.5154185022026432,
            "recall": 0.24273858921161826
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5712810126083149,
            "auditor_fn_violation": 0.01946315280284286,
            "auditor_fp_violation": 0.008906580918112972,
            "ave_precision_score": 0.5217211769096431,
            "fpr": 0.14270032930845225,
            "logloss": 0.825454434804466,
            "mae": 0.5078707597291038,
            "precision": 0.4820717131474104,
            "recall": 0.2563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.840511775345482,
            "auditor_fn_violation": 0.00699297517653054,
            "auditor_fp_violation": 0.011276009791921665,
            "ave_precision_score": 0.8404828250676849,
            "fpr": 0.10855263157894737,
            "logloss": 0.6655838708764373,
            "mae": 0.30547962057788736,
            "precision": 0.7857142857142857,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8536129277767368,
            "auditor_fn_violation": 0.010218794768274765,
            "auditor_fp_violation": 0.013619917535362533,
            "ave_precision_score": 0.8541784554069585,
            "fpr": 0.0889132821075741,
            "logloss": 0.5721009826683083,
            "mae": 0.2918584503350254,
            "precision": 0.8187919463087249,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7971442852123279,
            "auditor_fn_violation": 0.010855718133508045,
            "auditor_fp_violation": 0.048271113831089354,
            "ave_precision_score": 0.757691997590791,
            "fpr": 0.16447368421052633,
            "logloss": 0.5770426366214308,
            "mae": 0.3834909741815768,
            "precision": 0.6981891348088531,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7982485983422198,
            "auditor_fn_violation": 0.012595583173640441,
            "auditor_fp_violation": 0.037456648555118544,
            "ave_precision_score": 0.7600498222256316,
            "fpr": 0.14928649835345773,
            "logloss": 0.5585768202125463,
            "mae": 0.37752606558616547,
            "precision": 0.7166666666666667,
            "recall": 0.7288135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 25349,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.6522619460772274,
            "auditor_fn_violation": 0.0085671907985732,
            "auditor_fp_violation": 0.0018436352509179927,
            "ave_precision_score": 0.6524452945252612,
            "fpr": 0.003289473684210526,
            "logloss": 1.085597383934893,
            "mae": 0.4928298849947424,
            "precision": 0.8235294117647058,
            "recall": 0.029045643153526972
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.6235493732864769,
            "auditor_fn_violation": 0.0009558317364044013,
            "auditor_fp_violation": 0.0016877995844262357,
            "ave_precision_score": 0.6316143737431102,
            "fpr": 0.003293084522502744,
            "logloss": 1.0743791553230908,
            "mae": 0.49072671017142344,
            "precision": 0.7,
            "recall": 0.014830508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7407384407924367,
            "auditor_fn_violation": 0.004436012229744486,
            "auditor_fp_violation": 0.01040391676866586,
            "ave_precision_score": 0.5459751114848246,
            "fpr": 0.4276315789473684,
            "logloss": 0.6876698620674724,
            "mae": 0.49156822153378144,
            "precision": 0.5433255269320844,
            "recall": 0.9626556016597511
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7397951492847096,
            "auditor_fn_violation": 0.0030907551768405003,
            "auditor_fp_violation": 0.010589379614881649,
            "ave_precision_score": 0.5447939987538934,
            "fpr": 0.433589462129528,
            "logloss": 0.6852381244568779,
            "mae": 0.4900322717214622,
            "precision": 0.5319905213270142,
            "recall": 0.951271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8537293692960659,
            "auditor_fn_violation": 0.007632215913227049,
            "auditor_fp_violation": 0.015350877192982457,
            "ave_precision_score": 0.8539470488712637,
            "fpr": 0.18859649122807018,
            "logloss": 0.5397163321503088,
            "mae": 0.3216603700729733,
            "precision": 0.7079796264855688,
            "recall": 0.8651452282157677
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8602615955030197,
            "auditor_fn_violation": 0.012746748776721434,
            "auditor_fp_violation": 0.012107149018950871,
            "ave_precision_score": 0.8605209781776477,
            "fpr": 0.16136114160263446,
            "logloss": 0.4968126283950759,
            "mae": 0.31418824521495664,
            "precision": 0.7267657992565055,
            "recall": 0.8283898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7537894056408337,
            "auditor_fn_violation": 0.009094962510009463,
            "auditor_fp_violation": 0.016069971440228478,
            "ave_precision_score": 0.5435330788940633,
            "fpr": 0.41228070175438597,
            "logloss": 14.379427673175359,
            "mae": 0.4439968034234591,
            "precision": 0.5458937198067633,
            "recall": 0.9377593360995851
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7604385769046038,
            "auditor_fn_violation": 0.011837429533572719,
            "auditor_fp_violation": 0.015935328520812454,
            "ave_precision_score": 0.54336380893511,
            "fpr": 0.4149286498353458,
            "logloss": 14.476195918916428,
            "mae": 0.4374491947280825,
            "precision": 0.5456730769230769,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.735446571468869,
            "auditor_fn_violation": 0.013392207177695301,
            "auditor_fp_violation": 0.002784577723378214,
            "ave_precision_score": 0.7393846192581369,
            "fpr": 0.046052631578947366,
            "logloss": 0.7474785146437111,
            "mae": 0.40012128870697333,
            "precision": 0.8028169014084507,
            "recall": 0.35477178423236516
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7673919339615836,
            "auditor_fn_violation": 0.018332899216729627,
            "auditor_fp_violation": 0.006606172595635727,
            "ave_precision_score": 0.7668026035637949,
            "fpr": 0.03732162458836443,
            "logloss": 0.7140059188712179,
            "mae": 0.39051864669033615,
            "precision": 0.8274111675126904,
            "recall": 0.3453389830508475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.4977903730193395,
            "auditor_fn_violation": 0.010762448132780083,
            "auditor_fp_violation": 0.03195634434924521,
            "ave_precision_score": 0.5416237093858436,
            "fpr": 0.28399122807017546,
            "logloss": 0.720964620034418,
            "mae": 0.4909255807206296,
            "precision": 0.5503472222222222,
            "recall": 0.6576763485477178
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5541001880208336,
            "auditor_fn_violation": 0.012739771902733071,
            "auditor_fp_violation": 0.02446434242077971,
            "ave_precision_score": 0.539439615256795,
            "fpr": 0.2864983534577388,
            "logloss": 0.7138145972146952,
            "mae": 0.48725598451858293,
            "precision": 0.5484429065743944,
            "recall": 0.6716101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6116907349468463,
            "auditor_fn_violation": 0.011237897648686043,
            "auditor_fp_violation": 0.009501223990208077,
            "ave_precision_score": 0.6132622916175586,
            "fpr": 0.25109649122807015,
            "logloss": 0.70214772053227,
            "mae": 0.4774831145544324,
            "precision": 0.5821167883211679,
            "recall": 0.6618257261410788
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6033779097564236,
            "auditor_fn_violation": 0.004721018065452386,
            "auditor_fp_violation": 0.02278154372401102,
            "ave_precision_score": 0.6045433065396782,
            "fpr": 0.23710208562019758,
            "logloss": 0.7113794897446664,
            "mae": 0.47730472526880047,
            "precision": 0.5977653631284916,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7047679749217495,
            "auditor_fn_violation": 0.02286479944674966,
            "auditor_fp_violation": 0.07280191758465933,
            "ave_precision_score": 0.6886145965010935,
            "fpr": 0.17543859649122806,
            "logloss": 0.6276270987042435,
            "mae": 0.39969009383205784,
            "precision": 0.6844181459566075,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7087672186027069,
            "auditor_fn_violation": 0.020753874490688214,
            "auditor_fp_violation": 0.07539588276919153,
            "ave_precision_score": 0.6963016849981188,
            "fpr": 0.1756311745334797,
            "logloss": 0.6201110620720096,
            "mae": 0.3958191698668555,
            "precision": 0.68,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.608109042486027,
            "auditor_fn_violation": 0.014866328164810368,
            "auditor_fp_violation": 0.03250203998368014,
            "ave_precision_score": 0.6089587175522058,
            "fpr": 0.24342105263157895,
            "logloss": 0.6960018996850335,
            "mae": 0.4794206860426225,
            "precision": 0.5771428571428572,
            "recall": 0.6286307053941909
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.616155261265731,
            "auditor_fn_violation": 0.013683975515823552,
            "auditor_fp_violation": 0.0370815819808016,
            "ave_precision_score": 0.6168118813285892,
            "fpr": 0.2711306256860593,
            "logloss": 0.7244225854341091,
            "mae": 0.4942020653909569,
            "precision": 0.5108910891089109,
            "recall": 0.5466101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7821424391041588,
            "auditor_fn_violation": 0.004260846618621243,
            "auditor_fp_violation": 0.012869747042023672,
            "ave_precision_score": 0.7234006044077522,
            "fpr": 0.3256578947368421,
            "logloss": 0.6501980988926654,
            "mae": 0.40577086512195437,
            "precision": 0.5997304582210242,
            "recall": 0.9232365145228216
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7846577694773087,
            "auditor_fn_violation": 0.0029442408230850817,
            "auditor_fp_violation": 0.01643541728656837,
            "ave_precision_score": 0.7074319178740198,
            "fpr": 0.30735455543358947,
            "logloss": 0.6550421132217574,
            "mae": 0.4066359022413467,
            "precision": 0.6050775740479548,
            "recall": 0.9088983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8426762525314297,
            "auditor_fn_violation": 0.005391461017689448,
            "auditor_fp_violation": 0.002697878416972666,
            "ave_precision_score": 0.8385533917233206,
            "fpr": 0.08333333333333333,
            "logloss": 0.5261551476848845,
            "mae": 0.32683697209301354,
            "precision": 0.8020833333333334,
            "recall": 0.6390041493775933
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8576739058109282,
            "auditor_fn_violation": 0.0047070643174756815,
            "auditor_fp_violation": 0.0035206249109216887,
            "ave_precision_score": 0.8492275881308105,
            "fpr": 0.07354555433589462,
            "logloss": 0.5079309712099643,
            "mae": 0.31625927225957523,
            "precision": 0.8232189973614775,
            "recall": 0.6610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7631514338270771,
            "auditor_fn_violation": 0.042849603261265204,
            "auditor_fp_violation": 0.027710628314973482,
            "ave_precision_score": 0.7249341610805845,
            "fpr": 0.11074561403508772,
            "logloss": 0.6380684779743604,
            "mae": 0.40983340085132797,
            "precision": 0.7396907216494846,
            "recall": 0.5954356846473029
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7274652402343816,
            "auditor_fn_violation": 0.044935719734320645,
            "auditor_fp_violation": 0.024284310465107557,
            "ave_precision_score": 0.69579068571641,
            "fpr": 0.13172338090010977,
            "logloss": 0.6519172399888059,
            "mae": 0.41569181730813304,
            "precision": 0.7022332506203474,
            "recall": 0.5995762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 25349,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8504526377236354,
            "auditor_fn_violation": 0.032517107083060354,
            "auditor_fp_violation": 0.015447776417788658,
            "ave_precision_score": 0.8501719699424659,
            "fpr": 0.1118421052631579,
            "logloss": 0.50528969327978,
            "mae": 0.3156899650858944,
            "precision": 0.7801724137931034,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8619225196655497,
            "auditor_fn_violation": 0.021416677519581755,
            "auditor_fp_violation": 0.012417204053719542,
            "ave_precision_score": 0.8593635381479828,
            "fpr": 0.0867178924259056,
            "logloss": 0.4750021730401788,
            "mae": 0.29882529405744096,
            "precision": 0.8212669683257918,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8503320370031275,
            "auditor_fn_violation": 0.01014823105481546,
            "auditor_fp_violation": 0.003875968992248063,
            "ave_precision_score": 0.8482425704656902,
            "fpr": 0.08333333333333333,
            "logloss": 0.5169362774323049,
            "mae": 0.3092378501518907,
            "precision": 0.8177458033573142,
            "recall": 0.7074688796680498
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.847569821228538,
            "auditor_fn_violation": 0.0035721594820368814,
            "auditor_fp_violation": 0.006281114897894377,
            "ave_precision_score": 0.8467541299964432,
            "fpr": 0.07903402854006586,
            "logloss": 0.48972304065834005,
            "mae": 0.2995866071657737,
            "precision": 0.8285714285714286,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.6177433175417975,
            "auditor_fn_violation": 0.00017061585499017194,
            "auditor_fp_violation": 0.006609547123623019,
            "ave_precision_score": 0.5355163746499638,
            "fpr": 0.14473684210526316,
            "logloss": 0.6938552879617066,
            "mae": 0.498196883813331,
            "precision": 0.5494880546075085,
            "recall": 0.33402489626556015
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6292351754202306,
            "auditor_fn_violation": 0.0009442036130904804,
            "auditor_fp_violation": 0.005886044772947202,
            "ave_precision_score": 0.5373928263716141,
            "fpr": 0.132821075740944,
            "logloss": 0.689994230179598,
            "mae": 0.4963239929940384,
            "precision": 0.573943661971831,
            "recall": 0.3453389830508475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6985910699465925,
            "auditor_fn_violation": 0.049890350877192985,
            "auditor_fp_violation": 0.034628722970216255,
            "ave_precision_score": 0.7001608904799009,
            "fpr": 0.17543859649122806,
            "logloss": 0.6666092675924862,
            "mae": 0.42971565237824333,
            "precision": 0.6420581655480985,
            "recall": 0.5954356846473029
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.692005884314689,
            "auditor_fn_violation": 0.04887067666375188,
            "auditor_fp_violation": 0.04961130600681622,
            "ave_precision_score": 0.6927333357251964,
            "fpr": 0.18880351262349068,
            "logloss": 0.6726833334130783,
            "mae": 0.4317073930304346,
            "precision": 0.6371308016877637,
            "recall": 0.6398305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8424034159264069,
            "auditor_fn_violation": 0.014345381087573706,
            "auditor_fp_violation": 0.04424724602203183,
            "ave_precision_score": 0.8427144131884653,
            "fpr": 0.2708333333333333,
            "logloss": 0.7238073269548854,
            "mae": 0.3370651863780886,
            "precision": 0.6446043165467625,
            "recall": 0.9294605809128631
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8622659344487458,
            "auditor_fn_violation": 0.018028242385904853,
            "auditor_fp_violation": 0.039589527141067546,
            "ave_precision_score": 0.8626232019692701,
            "fpr": 0.2524698133918771,
            "logloss": 0.6383350758691134,
            "mae": 0.3184343353772595,
            "precision": 0.6567164179104478,
            "recall": 0.9322033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.734944470050023,
            "auditor_fn_violation": 0.014750309383417053,
            "auditor_fp_violation": 0.02790952672378621,
            "ave_precision_score": 0.7361194441681022,
            "fpr": 0.19188596491228072,
            "logloss": 0.6315226283769412,
            "mae": 0.40203345380723476,
            "precision": 0.6628131021194605,
            "recall": 0.7136929460580913
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7596016843504657,
            "auditor_fn_violation": 0.007514093285456485,
            "auditor_fp_violation": 0.014837633679978198,
            "ave_precision_score": 0.7613188513964144,
            "fpr": 0.18331503841931943,
            "logloss": 0.5971436121010586,
            "mae": 0.38754268012670995,
            "precision": 0.6763565891472868,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8481679561716724,
            "auditor_fn_violation": 0.008294205430588937,
            "auditor_fp_violation": 0.011760505915952672,
            "ave_precision_score": 0.8430611254700379,
            "fpr": 0.07456140350877193,
            "logloss": 0.5196561194121616,
            "mae": 0.3273198970740563,
            "precision": 0.8308457711442786,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8560690839771485,
            "auditor_fn_violation": 0.010381588494669677,
            "auditor_fp_violation": 0.0062536100157778015,
            "ave_precision_score": 0.8457718324849383,
            "fpr": 0.07354555433589462,
            "logloss": 0.4965024442046717,
            "mae": 0.318007769899363,
            "precision": 0.830379746835443,
            "recall": 0.6949152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 25349,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5035372140317067,
            "auditor_fn_violation": 0.0048363907694547684,
            "auditor_fp_violation": 0.0072827417380660975,
            "ave_precision_score": 0.493391604742531,
            "fpr": 0.06359649122807018,
            "logloss": 1.8177918510766269,
            "mae": 0.5000071914055585,
            "precision": 0.532258064516129,
            "recall": 0.13692946058091288
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.4665468729504887,
            "auditor_fn_violation": 0.00538149546968316,
            "auditor_fp_violation": 0.012257175648677641,
            "ave_precision_score": 0.4571916664043912,
            "fpr": 0.07244785949506037,
            "logloss": 1.7934362180926855,
            "mae": 0.5120851938909404,
            "precision": 0.5,
            "recall": 0.13983050847457626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.25404629643306,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7123524669179646,
            "auditor_fn_violation": 0.0005095726869039818,
            "auditor_fp_violation": 0.006530497756017957,
            "ave_precision_score": 0.6989584377675636,
            "fpr": 0.1875,
            "logloss": 1.509752438755671,
            "mae": 0.3395880326652651,
            "precision": 0.6946428571428571,
            "recall": 0.8070539419087137
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6825590647971097,
            "auditor_fn_violation": 0.007676887011851385,
            "auditor_fp_violation": 0.025579540368415397,
            "ave_precision_score": 0.6695747716948226,
            "fpr": 0.18990120746432493,
            "logloss": 1.605065216582694,
            "mae": 0.3504612271874414,
            "precision": 0.6843065693430657,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6339929455440583,
            "auditor_fn_violation": 0.08708233238698407,
            "auditor_fp_violation": 0.09694512443900449,
            "ave_precision_score": 0.6197030188214212,
            "fpr": 0.2982456140350877,
            "logloss": 5.468695861464857,
            "mae": 0.4261840741970505,
            "precision": 0.5736677115987461,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6437124440242556,
            "auditor_fn_violation": 0.07488511414165845,
            "auditor_fp_violation": 0.10289326355428088,
            "ave_precision_score": 0.6239615298252542,
            "fpr": 0.29198682766191,
            "logloss": 5.2746244001226215,
            "mae": 0.39891652231654917,
            "precision": 0.5830721003134797,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6732003769911836,
            "auditor_fn_violation": 0.014732110358884767,
            "auditor_fp_violation": 0.008914728682170546,
            "ave_precision_score": 0.6750614754244381,
            "fpr": 0.09539473684210527,
            "logloss": 0.7484022895071891,
            "mae": 0.3756372847372208,
            "precision": 0.7298136645962733,
            "recall": 0.487551867219917
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7137265032954369,
            "auditor_fn_violation": 0.004239613760256008,
            "auditor_fp_violation": 0.00016752973652823646,
            "ave_precision_score": 0.7149155678565045,
            "fpr": 0.07244785949506037,
            "logloss": 0.6499072945630142,
            "mae": 0.36691867382313204,
            "precision": 0.7716262975778547,
            "recall": 0.4724576271186441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8309799570350043,
            "auditor_fn_violation": 0.005960180534323362,
            "auditor_fp_violation": 0.01579457364341086,
            "ave_precision_score": 0.8313100365086266,
            "fpr": 0.10307017543859649,
            "logloss": 0.54066474197791,
            "mae": 0.3364138264378039,
            "precision": 0.7863636363636364,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8459199708622536,
            "auditor_fn_violation": 0.006328024707436423,
            "auditor_fp_violation": 0.01184210197310023,
            "ave_precision_score": 0.8463003122678654,
            "fpr": 0.0889132821075741,
            "logloss": 0.5041519164800932,
            "mae": 0.32401385655844916,
            "precision": 0.8071428571428572,
            "recall": 0.7182203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6083018742439903,
            "auditor_fn_violation": 0.005088902234840213,
            "auditor_fp_violation": 0.00864443084455325,
            "ave_precision_score": 0.5462484640500654,
            "fpr": 0.3508771929824561,
            "logloss": 0.6927836925250878,
            "mae": 0.49397977562457845,
            "precision": 0.524517087667162,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6031701231165889,
            "auditor_fn_violation": 0.00960482985729967,
            "auditor_fp_violation": 0.009814242027959984,
            "ave_precision_score": 0.5463548121451806,
            "fpr": 0.35236004390779363,
            "logloss": 0.6894635192438874,
            "mae": 0.49335120907860974,
            "precision": 0.5244444444444445,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.794983809172372,
            "auditor_fn_violation": 0.004208524423090928,
            "auditor_fp_violation": 0.024168706650346806,
            "ave_precision_score": 0.7637008448509284,
            "fpr": 0.21600877192982457,
            "logloss": 3.7179231880369086,
            "mae": 0.29328455509276413,
            "precision": 0.6743801652892562,
            "recall": 0.8464730290456431
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.760655313714488,
            "auditor_fn_violation": 0.01118160337866751,
            "auditor_fp_violation": 0.023284132933595714,
            "ave_precision_score": 0.7200083037927542,
            "fpr": 0.2524698133918771,
            "logloss": 4.327722954079792,
            "mae": 0.3268745787529395,
            "precision": 0.6360759493670886,
            "recall": 0.8516949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7163649245083672,
            "auditor_fn_violation": 0.005675820776006418,
            "auditor_fp_violation": 0.013382292941656469,
            "ave_precision_score": 0.7178292818839338,
            "fpr": 0.13925438596491227,
            "logloss": 0.600956074838025,
            "mae": 0.393368764339309,
            "precision": 0.7100456621004566,
            "recall": 0.6452282157676349
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7199140351512593,
            "auditor_fn_violation": 0.004553573089731906,
            "auditor_fp_violation": 0.00964921273526051,
            "ave_precision_score": 0.7218278282629084,
            "fpr": 0.11964873765093303,
            "logloss": 0.5724479871226413,
            "mae": 0.37705010362173935,
            "precision": 0.7398568019093079,
            "recall": 0.6567796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6940888066905467,
            "auditor_fn_violation": 0.0011215148868020676,
            "auditor_fp_violation": 0.005518155854753162,
            "ave_precision_score": 0.6850592306666393,
            "fpr": 0.44298245614035087,
            "logloss": 0.6818721501700925,
            "mae": 0.469987598394877,
            "precision": 0.540386803185438,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.72386553269539,
            "auditor_fn_violation": 0.0014023516716590077,
            "auditor_fp_violation": 0.00746382482890713,
            "ave_precision_score": 0.7129093659410696,
            "fpr": 0.45334796926454446,
            "logloss": 0.6854244175177728,
            "mae": 0.4724809457062366,
            "precision": 0.5317460317460317,
            "recall": 0.9936440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.80656094728253,
            "auditor_fn_violation": 0.03806325980927422,
            "auditor_fp_violation": 0.006339249286005714,
            "ave_precision_score": 0.7463490272598765,
            "fpr": 0.04276315789473684,
            "logloss": 0.593920478357734,
            "mae": 0.3976368117227889,
            "precision": 0.85,
            "recall": 0.45850622406639
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7768245170444997,
            "auditor_fn_violation": 0.036377420975273966,
            "auditor_fp_violation": 0.018368260366215004,
            "ave_precision_score": 0.7210294939330484,
            "fpr": 0.05159165751920966,
            "logloss": 0.5903229554494601,
            "mae": 0.3995277159627523,
            "precision": 0.8233082706766918,
            "recall": 0.4639830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4418859649122807,
            "auc_prc": 0.6074602096405732,
            "auditor_fn_violation": 0.006599421271019886,
            "auditor_fp_violation": 0.021220930232558145,
            "ave_precision_score": 0.5529966611734525,
            "fpr": 0.2149122807017544,
            "logloss": 0.6873793186548042,
            "mae": 0.4813290617445059,
            "precision": 0.46301369863013697,
            "recall": 0.3506224066390041
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0.6026456670158756,
            "auditor_fn_violation": 0.0020279447059480408,
            "auditor_fp_violation": 0.019443451212590238,
            "ave_precision_score": 0.5377628755702634,
            "fpr": 0.2052689352360044,
            "logloss": 0.6968815872436566,
            "mae": 0.48483624040229917,
            "precision": 0.4702549575070821,
            "recall": 0.3516949152542373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8491849988926979,
            "auditor_fn_violation": 0.002720754167576632,
            "auditor_fp_violation": 0.012469400244798041,
            "ave_precision_score": 0.8406919770276742,
            "fpr": 0.07456140350877193,
            "logloss": 0.5376493803352489,
            "mae": 0.32524500572400394,
            "precision": 0.8172043010752689,
            "recall": 0.6307053941908713
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8626813998598732,
            "auditor_fn_violation": 0.0066791940315168745,
            "auditor_fp_violation": 0.006718692567930808,
            "ave_precision_score": 0.8529248316775516,
            "fpr": 0.054884742041712405,
            "logloss": 0.49232894752482825,
            "mae": 0.30359281124250653,
            "precision": 0.8603351955307262,
            "recall": 0.652542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.717556572926936,
            "auditor_fn_violation": 0.005489280774550485,
            "auditor_fp_violation": 0.014325785393716848,
            "ave_precision_score": 0.7185385797730036,
            "fpr": 0.24013157894736842,
            "logloss": 0.655504741230783,
            "mae": 0.35537638511149244,
            "precision": 0.6556603773584906,
            "recall": 0.8651452282157677
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.761131258766678,
            "auditor_fn_violation": 0.010290889132821078,
            "auditor_fp_violation": 0.00884907071005104,
            "ave_precision_score": 0.762858433994217,
            "fpr": 0.20965971459934138,
            "logloss": 0.6033675429012414,
            "mae": 0.3414343880524227,
            "precision": 0.6837748344370861,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8143353028790336,
            "auditor_fn_violation": 0.011920361068646721,
            "auditor_fp_violation": 0.01907384740922073,
            "ave_precision_score": 0.8145313627535633,
            "fpr": 0.12609649122807018,
            "logloss": 0.8618272946231412,
            "mae": 0.2844198283927386,
            "precision": 0.7578947368421053,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7776839516471964,
            "auditor_fn_violation": 0.01377932612699771,
            "auditor_fp_violation": 0.01923841481863031,
            "ave_precision_score": 0.775322042932469,
            "fpr": 0.1525795828759605,
            "logloss": 1.0294025031726541,
            "mae": 0.3064259718716252,
            "precision": 0.7104166666666667,
            "recall": 0.722457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7083739457083101,
            "auditor_fn_violation": 0.008412499090048781,
            "auditor_fp_violation": 0.017513259893920864,
            "ave_precision_score": 0.5601118121544864,
            "fpr": 0.2598684210526316,
            "logloss": 0.6992587441561308,
            "mae": 0.4807815444941649,
            "precision": 0.5745062836624776,
            "recall": 0.6639004149377593
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7063381316520203,
            "auditor_fn_violation": 0.016139835159723906,
            "auditor_fp_violation": 0.0152802122376722,
            "ave_precision_score": 0.5598309069920959,
            "fpr": 0.24807903402854006,
            "logloss": 0.6842776927900667,
            "mae": 0.4744024108093473,
            "precision": 0.5767790262172284,
            "recall": 0.652542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7829903946704106,
            "auditor_fn_violation": 0.01637229744485696,
            "auditor_fp_violation": 0.02355671154630763,
            "ave_precision_score": 0.7427508085457735,
            "fpr": 0.1074561403508772,
            "logloss": 0.6105845457288488,
            "mae": 0.4035932193060912,
            "precision": 0.7493606138107417,
            "recall": 0.6078838174273858
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7572007929453171,
            "auditor_fn_violation": 0.0015814247706934107,
            "auditor_fp_violation": 0.025024441838426326,
            "ave_precision_score": 0.7349809630434394,
            "fpr": 0.11964873765093303,
            "logloss": 0.5966118044827087,
            "mae": 0.40079105068622417,
            "precision": 0.7281795511221946,
            "recall": 0.6186440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8074588429685085,
            "auditor_fn_violation": 0.00255468806871952,
            "auditor_fp_violation": 0.008246634026927786,
            "ave_precision_score": 0.8077338476707785,
            "fpr": 0.12280701754385964,
            "logloss": 0.573212488004394,
            "mae": 0.35264081395182173,
            "precision": 0.7494407158836689,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8260470714909701,
            "auditor_fn_violation": 0.012037433254572178,
            "auditor_fp_violation": 0.003520624910921693,
            "ave_precision_score": 0.8263181712775565,
            "fpr": 0.1119648737650933,
            "logloss": 0.5339361078007648,
            "mae": 0.3362001539131322,
            "precision": 0.7649769585253456,
            "recall": 0.7033898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7594987420703299,
            "auditor_fn_violation": 0.006567572978088372,
            "auditor_fp_violation": 0.0002447980416156676,
            "ave_precision_score": 0.7360052028136199,
            "fpr": 0.05043859649122807,
            "logloss": 0.6127321226644796,
            "mae": 0.4138351128060828,
            "precision": 0.8237547892720306,
            "recall": 0.4460580912863071
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7879795113883685,
            "auditor_fn_violation": 0.0011349048354388038,
            "auditor_fp_violation": 0.00041257323174863575,
            "ave_precision_score": 0.7564237418725193,
            "fpr": 0.03732162458836443,
            "logloss": 0.591614518822706,
            "mae": 0.4058059753950289,
            "precision": 0.8571428571428571,
            "recall": 0.4322033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7654185022026432,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002009383924928611,
            "ave_precision_score": 0.5308370044052864,
            "fpr": 0.46710526315789475,
            "logloss": 16.133619169449496,
            "mae": 0.4671066990327434,
            "precision": 0.5308370044052864,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7605784148733955,
            "auditor_fn_violation": 0.0006116392863123035,
            "auditor_fp_violation": 0.002502944272608388,
            "ave_precision_score": 0.5221716227571406,
            "fpr": 0.47310647639956094,
            "logloss": 16.34453523542197,
            "mae": 0.47447559779129483,
            "precision": 0.5221729490022173,
            "recall": 0.9978813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5779497536431986,
            "auditor_fn_violation": 0.008953920069884271,
            "auditor_fp_violation": 0.00216748266013872,
            "ave_precision_score": 0.608368287166273,
            "fpr": 0.05482456140350877,
            "logloss": 9.454226044505145,
            "mae": 0.46518690316990713,
            "precision": 0.7252747252747253,
            "recall": 0.27385892116182575
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5404684511146665,
            "auditor_fn_violation": 0.015721222720422704,
            "auditor_fp_violation": 0.010169305051646666,
            "ave_precision_score": 0.570922058821635,
            "fpr": 0.06695938529088913,
            "logloss": 9.570306982374488,
            "mae": 0.4728233500037855,
            "precision": 0.6629834254143646,
            "recall": 0.2542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 25349,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8044955684199254,
            "auditor_fn_violation": 0.025182900196549476,
            "auditor_fp_violation": 0.02126937984496124,
            "ave_precision_score": 0.7484765689019337,
            "fpr": 0.11293859649122807,
            "logloss": 3.8460941515330207,
            "mae": 0.27572549086445747,
            "precision": 0.778969957081545,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.7912071954995767,
            "auditor_fn_violation": 0.019795717129621016,
            "auditor_fp_violation": 0.014315040919763261,
            "ave_precision_score": 0.7262882463105094,
            "fpr": 0.11745334796926454,
            "logloss": 4.247738965773213,
            "mae": 0.27402057438625593,
            "precision": 0.7708779443254818,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7776961836315529,
            "auditor_fn_violation": 0.008885673727888186,
            "auditor_fp_violation": 0.009526723786209713,
            "ave_precision_score": 0.7681780442679597,
            "fpr": 0.09210526315789473,
            "logloss": 0.5417273467759118,
            "mae": 0.35802908163321645,
            "precision": 0.8028169014084507,
            "recall": 0.7095435684647303
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.815038271736667,
            "auditor_fn_violation": 0.003362853262386276,
            "auditor_fp_violation": 0.0011226992791220503,
            "ave_precision_score": 0.7897054624501121,
            "fpr": 0.07574094401756312,
            "logloss": 0.5215263716715697,
            "mae": 0.3496906800537026,
            "precision": 0.8287841191066998,
            "recall": 0.7076271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7427197921262914,
            "auditor_fn_violation": 0.007934774696076289,
            "auditor_fp_violation": 0.011306609547123628,
            "ave_precision_score": 0.7422200759403017,
            "fpr": 0.10197368421052631,
            "logloss": 0.5695881856062252,
            "mae": 0.36622523660199685,
            "precision": 0.7910112359550562,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.7668076870926307,
            "auditor_fn_violation": 0.007746655751734923,
            "auditor_fp_violation": 0.0065786677135191525,
            "ave_precision_score": 0.7639178454031267,
            "fpr": 0.09110867178924259,
            "logloss": 0.5486285698526736,
            "mae": 0.35683764263774903,
            "precision": 0.8078703703703703,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6125812611532571,
            "auditor_fn_violation": 0.006369658586299781,
            "auditor_fp_violation": 0.006206650346797227,
            "ave_precision_score": 0.6135677585957315,
            "fpr": 0.08991228070175439,
            "logloss": 1.5874361000847383,
            "mae": 0.4807094442081093,
            "precision": 0.645021645021645,
            "recall": 0.3091286307053942
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6160701566432852,
            "auditor_fn_violation": 0.00802107946194348,
            "auditor_fp_violation": 0.01238969917160296,
            "ave_precision_score": 0.616738939070682,
            "fpr": 0.09989023051591657,
            "logloss": 1.6287374806746955,
            "mae": 0.480472485327532,
            "precision": 0.59375,
            "recall": 0.2817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7642543859649122,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.47149122807017546,
            "logloss": 0.6919259926807687,
            "mae": 0.49918546200844277,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7590559824368825,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.4818880351262349,
            "logloss": 0.6925202588860613,
            "mae": 0.49948251424060824,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7279171341318067,
            "auditor_fn_violation": 0.08962109630923783,
            "auditor_fp_violation": 0.09653712770297838,
            "ave_precision_score": 0.5664809474055328,
            "fpr": 0.2817982456140351,
            "logloss": 0.7692065286053144,
            "mae": 0.4574958929105809,
            "precision": 0.5800653594771242,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7497059507084429,
            "auditor_fn_violation": 0.07862936984874137,
            "auditor_fp_violation": 0.0952169009999275,
            "ave_precision_score": 0.5869241580354599,
            "fpr": 0.26125137211855104,
            "logloss": 0.7160190250144275,
            "mae": 0.4336950988984134,
            "precision": 0.6066115702479339,
            "recall": 0.777542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7156925381050561,
            "auditor_fn_violation": 0.07442036106864672,
            "auditor_fp_violation": 0.050436046511627905,
            "ave_precision_score": 0.6928506373537059,
            "fpr": 0.16776315789473684,
            "logloss": 0.6241241049821092,
            "mae": 0.43332716459898574,
            "precision": 0.6765327695560254,
            "recall": 0.6639004149377593
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6999003235151222,
            "auditor_fn_violation": 0.07218971515749131,
            "auditor_fp_violation": 0.05257433194392005,
            "ave_precision_score": 0.67863383976443,
            "fpr": 0.16465422612513722,
            "logloss": 0.6383846317597327,
            "mae": 0.43807784048380366,
            "precision": 0.6746203904555315,
            "recall": 0.6588983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8449510103901167,
            "auditor_fn_violation": 0.0068655820048045485,
            "auditor_fp_violation": 0.011028661770705835,
            "ave_precision_score": 0.8451816134334268,
            "fpr": 0.10416666666666667,
            "logloss": 0.5139811973687956,
            "mae": 0.3302739745112169,
            "precision": 0.7865168539325843,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.861022369787664,
            "auditor_fn_violation": 0.0056047554373104685,
            "auditor_fp_violation": 0.007153769794138462,
            "ave_precision_score": 0.8612039630126676,
            "fpr": 0.09549945115257959,
            "logloss": 0.4832779056040613,
            "mae": 0.3196010507038016,
            "precision": 0.8004587155963303,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6331910353196556,
            "auditor_fn_violation": 0.0035078619785979467,
            "auditor_fp_violation": 0.021679926560587523,
            "ave_precision_score": 0.6326703861851787,
            "fpr": 0.375,
            "logloss": 1.3719459944015753,
            "mae": 0.4170607882697629,
            "precision": 0.5767326732673267,
            "recall": 0.966804979253112
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6366666023069735,
            "auditor_fn_violation": 0.006237325345587825,
            "auditor_fp_violation": 0.014537580420524653,
            "ave_precision_score": 0.6343403975975866,
            "fpr": 0.3995609220636663,
            "logloss": 1.5272784091341305,
            "mae": 0.4342011102333918,
            "precision": 0.5571776155717761,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6451650106314463,
            "auditor_fn_violation": 0.010141406420615852,
            "auditor_fp_violation": 0.0038020195838433346,
            "ave_precision_score": 0.5483865865282038,
            "fpr": 0.17434210526315788,
            "logloss": 0.795031078665975,
            "mae": 0.49801263377568766,
            "precision": 0.5643835616438356,
            "recall": 0.42738589211618255
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6552206071645139,
            "auditor_fn_violation": 0.005134979255428017,
            "auditor_fp_violation": 0.007706367880298762,
            "ave_precision_score": 0.5522154929021663,
            "fpr": 0.1712403951701427,
            "logloss": 0.7775368785687473,
            "mae": 0.4946970972104732,
            "precision": 0.5806451612903226,
            "recall": 0.4576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7954981583881515,
            "auditor_fn_violation": 0.005400560529955591,
            "auditor_fp_violation": 0.005087209302325581,
            "ave_precision_score": 0.7917326546470407,
            "fpr": 0.09320175438596491,
            "logloss": 0.5705364364919998,
            "mae": 0.37417573362523526,
            "precision": 0.7848101265822784,
            "recall": 0.6431535269709544
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.802598101022867,
            "auditor_fn_violation": 0.005395449217659867,
            "auditor_fp_violation": 7.251287103461141e-05,
            "ave_precision_score": 0.795047426541517,
            "fpr": 0.0801317233809001,
            "logloss": 0.5494073297405104,
            "mae": 0.36357854854654925,
            "precision": 0.8078947368421052,
            "recall": 0.6504237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8041248141225662,
            "auditor_fn_violation": 0.027325835335226034,
            "auditor_fp_violation": 0.05201958384332928,
            "ave_precision_score": 0.8045301728589181,
            "fpr": 0.28728070175438597,
            "logloss": 0.743984116857862,
            "mae": 0.3493900374096962,
            "precision": 0.6191860465116279,
            "recall": 0.8838174273858921
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8262294440302944,
            "auditor_fn_violation": 0.024270218980818253,
            "auditor_fp_violation": 0.051429128670339,
            "ave_precision_score": 0.826533032182744,
            "fpr": 0.2689352360043908,
            "logloss": 0.6993440800343719,
            "mae": 0.34271475803653956,
            "precision": 0.6326836581709145,
            "recall": 0.8940677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7005458642499731,
            "auditor_fn_violation": 0.014748034505350525,
            "auditor_fp_violation": 0.015503875968992255,
            "ave_precision_score": 0.7014269627028835,
            "fpr": 0.14473684210526316,
            "logloss": 0.6274823841755138,
            "mae": 0.431868686961631,
            "precision": 0.6923076923076923,
            "recall": 0.6161825726141079
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7171929393584843,
            "auditor_fn_violation": 0.001525609778786583,
            "auditor_fp_violation": 0.014024989435624833,
            "ave_precision_score": 0.7182171488606854,
            "fpr": 0.12623490669593854,
            "logloss": 0.6071628087686617,
            "mae": 0.4208468842748491,
            "precision": 0.7117794486215538,
            "recall": 0.6016949152542372
        }
    }
]