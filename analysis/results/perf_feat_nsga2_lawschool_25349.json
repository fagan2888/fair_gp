[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.25404629643306,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7035697643144673,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6768002761087804,
            "fpr": 0.03399122807017544,
            "logloss": 1.5857486669843168,
            "mae": 0.5342465478256998,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7167089370449459,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6875297255322972,
            "fpr": 0.03293084522502744,
            "logloss": 1.5446753873981638,
            "mae": 0.5214877259681404,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7036710069120881,
            "auditor_fn_violation": 0.0020655892844143554,
            "auditor_fp_violation": 0.0059032027743778,
            "ave_precision_score": 0.7046007949013453,
            "fpr": 0.4440789473684211,
            "logloss": 2.8899145628842895,
            "mae": 0.4495186934690808,
            "precision": 0.5408163265306123,
            "recall": 0.9896265560165975
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7200688117341643,
            "auditor_fn_violation": 0.0015023535321587378,
            "auditor_fp_violation": 0.00712126402436433,
            "ave_precision_score": 0.7207032972765164,
            "fpr": 0.4566410537870472,
            "logloss": 2.95296639077697,
            "mae": 0.4667678618267931,
            "precision": 0.5261958997722096,
            "recall": 0.9788135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7004174066966078,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6740583321502318,
            "fpr": 0.03399122807017544,
            "logloss": 1.363405379418117,
            "mae": 0.5318361489804821,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.716548898639183,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6860497265359242,
            "fpr": 0.03293084522502744,
            "logloss": 1.3279621826990833,
            "mae": 0.5198700941780134,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6733523191499531,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6587703214937422,
            "fpr": 0.03399122807017544,
            "logloss": 1.7048102374011214,
            "mae": 0.5353375049593875,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.666503307807166,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6522134438402418,
            "fpr": 0.03293084522502744,
            "logloss": 1.660348866019553,
            "mae": 0.5202533926867955,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7032164636589489,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6774672870550846,
            "fpr": 0.03399122807017544,
            "logloss": 1.4903870826910104,
            "mae": 0.5345556088845784,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7162703822109527,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6885320419450249,
            "fpr": 0.03293084522502744,
            "logloss": 1.453415007452903,
            "mae": 0.5213783145969085,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7015767074848591,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6759676595603397,
            "fpr": 0.03399122807017544,
            "logloss": 0.9699686223098041,
            "mae": 0.5226925624893946,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7180735621238521,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6899876574853527,
            "fpr": 0.03293084522502744,
            "logloss": 0.94989516360877,
            "mae": 0.5143101115748858,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6715110088238132,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6628765217887964,
            "fpr": 0.03399122807017544,
            "logloss": 1.6810123517530762,
            "mae": 0.5344312255507695,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6675801744431983,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.659861756467437,
            "fpr": 0.03293084522502744,
            "logloss": 1.637586580400351,
            "mae": 0.5194592691138059,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018901522560566,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6732240555643223,
            "fpr": 0.03399122807017544,
            "logloss": 1.9789625149100885,
            "mae": 0.5378750257925212,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7177911816288033,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6850151298025804,
            "fpr": 0.03293084522502744,
            "logloss": 1.9227842351015068,
            "mae": 0.5239230712546541,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.700345568105192,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6790964903692193,
            "fpr": 0.03399122807017544,
            "logloss": 1.6423672623353922,
            "mae": 0.5365488983429315,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7187615532883759,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6956039341111141,
            "fpr": 0.03293084522502744,
            "logloss": 1.6001464729019808,
            "mae": 0.5227397367517688,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7009154249929664,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6753245054483843,
            "fpr": 0.03399122807017544,
            "logloss": 1.7536213073981737,
            "mae": 0.5362952417783897,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7173414451793065,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6871638834983391,
            "fpr": 0.03293084522502744,
            "logloss": 1.7049744443110042,
            "mae": 0.5228168939993718,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6957262135381126,
            "mae": 0.5009884227786148,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6950049926050147,
            "mae": 0.5006279568509919,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.703327684009988,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6770163705011878,
            "fpr": 0.03399122807017544,
            "logloss": 1.5955899321889553,
            "mae": 0.5343400537763444,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.716313217536577,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6880109548734742,
            "fpr": 0.03293084522502744,
            "logloss": 1.5541954641046254,
            "mae": 0.5215477740901199,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6963926578356714,
            "mae": 0.5011877386193526,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6955258480379997,
            "mae": 0.5007545845961335,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8276541782817284,
            "auditor_fn_violation": 0.0017402817208997596,
            "auditor_fp_violation": 0.005762953896368845,
            "ave_precision_score": 0.7928325715525383,
            "fpr": 0.4375,
            "logloss": 1.5751165034772612,
            "mae": 0.4542382220786653,
            "precision": 0.5413793103448276,
            "recall": 0.9771784232365145
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.8284193202353867,
            "auditor_fn_violation": 0.0014697947868797562,
            "auditor_fp_violation": 0.007421317283817875,
            "ave_precision_score": 0.7889497136031971,
            "fpr": 0.4489571899012075,
            "logloss": 1.617692057915397,
            "mae": 0.46888257767575764,
            "precision": 0.5271676300578034,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7038612762891653,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6773719429874234,
            "fpr": 0.03399122807017544,
            "logloss": 2.147318544379442,
            "mae": 0.5386129515664243,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7162539056026748,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6875441974813425,
            "fpr": 0.03293084522502744,
            "logloss": 2.0881118653114545,
            "mae": 0.5244581776300014,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.4076313059620004,
            "auditor_fn_violation": 0.0023021766033340697,
            "auditor_fp_violation": 0.004146266829865361,
            "ave_precision_score": 0.5218670379267671,
            "fpr": 0.013157894736842105,
            "logloss": 0.733350534417383,
            "mae": 0.5088036878589999,
            "precision": 0.3333333333333333,
            "recall": 0.012448132780082987
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.43433663489545343,
            "auditor_fn_violation": 0.0018558484809019931,
            "auditor_fp_violation": 0.00428075983487069,
            "ave_precision_score": 0.5090402298082907,
            "fpr": 0.018660812294182216,
            "logloss": 0.7280218872045189,
            "mae": 0.5063405957167025,
            "precision": 0.34615384615384615,
            "recall": 0.019067796610169493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8282686933930117,
            "auditor_fn_violation": 0.0012511829365945942,
            "auditor_fp_violation": 0.005905752753977972,
            "ave_precision_score": 0.7939304869100994,
            "fpr": 0.05921052631578947,
            "logloss": 0.6531732052191193,
            "mae": 0.47779902328916807,
            "precision": 0.8411764705882353,
            "recall": 0.5933609958506224
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8420525122058417,
            "auditor_fn_violation": 0.005781502911682086,
            "auditor_fp_violation": 0.00389569148523863,
            "ave_precision_score": 0.8035161406352814,
            "fpr": 0.04720087815587267,
            "logloss": 0.6512286633817771,
            "mae": 0.47685590880369905,
            "precision": 0.8626198083067093,
            "recall": 0.5720338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7679626693437803,
            "auditor_fn_violation": 0.0020655892844143554,
            "auditor_fp_violation": 0.0059032027743778,
            "ave_precision_score": 0.5406886548023883,
            "fpr": 0.4440789473684211,
            "logloss": 0.6918755530718479,
            "mae": 0.48994543743238117,
            "precision": 0.5408163265306123,
            "recall": 0.9896265560165975
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.757993203751293,
            "auditor_fn_violation": 0.0015023535321587378,
            "auditor_fp_violation": 0.00712126402436433,
            "ave_precision_score": 0.5260246299650392,
            "fpr": 0.4566410537870472,
            "logloss": 0.6991898916769808,
            "mae": 0.49354190560125233,
            "precision": 0.5261958997722096,
            "recall": 0.9788135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8510274196571246,
            "auditor_fn_violation": 0.00910861177840868,
            "auditor_fp_violation": 0.02088943288453693,
            "ave_precision_score": 0.8512265837520445,
            "fpr": 0.1118421052631579,
            "logloss": 0.694883796313791,
            "mae": 0.26784840124135995,
            "precision": 0.7815845824411135,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8249753898034125,
            "auditor_fn_violation": 0.010521125974436732,
            "auditor_fp_violation": 0.0156102708230711,
            "ave_precision_score": 0.8255031777902,
            "fpr": 0.12952799121844127,
            "logloss": 0.7321064937918149,
            "mae": 0.2742514917005807,
            "precision": 0.7541666666666667,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7021612504611037,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6714497863870129,
            "fpr": 0.03399122807017544,
            "logloss": 2.019940693000618,
            "mae": 0.5379663601133711,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7178769681249826,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6836923277911435,
            "fpr": 0.03293084522502744,
            "logloss": 1.962599581884826,
            "mae": 0.523983796563666,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6957262135381126,
            "mae": 0.5009884227786148,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6950049926050147,
            "mae": 0.5006279568509919,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8481837176532985,
            "auditor_fn_violation": 0.014663864016888696,
            "auditor_fp_violation": 0.01910954712362302,
            "ave_precision_score": 0.8483879573456992,
            "fpr": 0.12280701754385964,
            "logloss": 0.6975756073252607,
            "mae": 0.2697345689329585,
            "precision": 0.7666666666666667,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8212941393316364,
            "auditor_fn_violation": 0.010707175947459489,
            "auditor_fp_violation": 0.016903000282550158,
            "ave_precision_score": 0.8218465799480241,
            "fpr": 0.13721185510428102,
            "logloss": 0.7374674634418712,
            "mae": 0.27634770865488,
            "precision": 0.7443762781186094,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7019577287125421,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6733725409800724,
            "fpr": 0.03399122807017544,
            "logloss": 0.9799743540600538,
            "mae": 0.5229451945378331,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7178367952559511,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6853111214199309,
            "fpr": 0.03293084522502744,
            "logloss": 0.959485096006717,
            "mae": 0.5144428593463354,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.2642543859649123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006170950632394941,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6975906406263015,
            "mae": 0.501589144955863,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.25905598243688255,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005500976423315139,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6965719812733779,
            "mae": 0.5010801887407522,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.6238608927228169,
            "auditor_fn_violation": 0.006178568828710781,
            "auditor_fp_violation": 0.0022184822521419826,
            "ave_precision_score": 0.5388236757176482,
            "fpr": 0.015350877192982455,
            "logloss": 0.691714722020288,
            "mae": 0.49820784214687974,
            "precision": 0.6888888888888889,
            "recall": 0.06431535269709543
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6377036618657393,
            "auditor_fn_violation": 0.00472101806545239,
            "auditor_fp_violation": 0.0016302893763643048,
            "ave_precision_score": 0.5302172183718817,
            "fpr": 0.010976948408342482,
            "logloss": 0.6907130025246573,
            "mae": 0.4978585223596784,
            "precision": 0.7297297297297297,
            "recall": 0.057203389830508475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8484664101251733,
            "auditor_fn_violation": 0.008899322996287403,
            "auditor_fp_violation": 0.02112403100775194,
            "ave_precision_score": 0.8486712133997741,
            "fpr": 0.125,
            "logloss": 0.6954641559633677,
            "mae": 0.2694809035960895,
            "precision": 0.7634854771784232,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8217999683410359,
            "auditor_fn_violation": 0.011293233362481168,
            "auditor_fp_violation": 0.01674547232133704,
            "ave_precision_score": 0.822328946320397,
            "fpr": 0.13611416026344675,
            "logloss": 0.7367555999052272,
            "mae": 0.2760028174779012,
            "precision": 0.7464212678936605,
            "recall": 0.7733050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.702137299999522,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6711613527857161,
            "fpr": 0.03399122807017544,
            "logloss": 1.5693321946309446,
            "mae": 0.5341698855709023,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 1.5267398288261713,
            "mae": 0.5214218373168117,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6427021857333393,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6349062788627138,
            "fpr": 0.03399122807017544,
            "logloss": 2.289433062451671,
            "mae": 0.5391634155698979,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6565687128008217,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6462878150924058,
            "fpr": 0.03293084522502744,
            "logloss": 2.2206590151041654,
            "mae": 0.525042271086666,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6997706060837962,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6924874601095423,
            "fpr": 0.03399122807017544,
            "logloss": 1.9214096424833063,
            "mae": 0.5431524883637107,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7266260585512511,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7173203579988796,
            "fpr": 0.03293084522502744,
            "logloss": 1.8608869929257976,
            "mae": 0.5266716536114036,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8536327974372897,
            "auditor_fn_violation": 0.004454211254276772,
            "auditor_fp_violation": 0.015065279477764178,
            "ave_precision_score": 0.8538411796551773,
            "fpr": 0.11951754385964912,
            "logloss": 0.6074354721666202,
            "mae": 0.27064460147102054,
            "precision": 0.7724425887265136,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8389614914299983,
            "auditor_fn_violation": 0.01237697445533871,
            "auditor_fp_violation": 0.01667295945030243,
            "ave_precision_score": 0.839269822101244,
            "fpr": 0.13391877058177826,
            "logloss": 0.6231643059887294,
            "mae": 0.2751397211543138,
            "precision": 0.7484536082474227,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.851051965312071,
            "auditor_fn_violation": 0.005778190289000512,
            "auditor_fp_violation": 0.018655650754793963,
            "ave_precision_score": 0.8512515718035192,
            "fpr": 0.1337719298245614,
            "logloss": 0.6937236446113803,
            "mae": 0.26659425695008154,
            "precision": 0.7530364372469636,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.824672639215046,
            "auditor_fn_violation": 0.011737427673072991,
            "auditor_fp_violation": 0.017705642751588407,
            "ave_precision_score": 0.8252076639631458,
            "fpr": 0.141602634467618,
            "logloss": 0.7364365862667102,
            "mae": 0.2740699694145678,
            "precision": 0.742,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7017059331943976,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6708806797023441,
            "fpr": 0.03399122807017544,
            "logloss": 2.5332917415156073,
            "mae": 0.5404505061441134,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7178847282464521,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6834625273710353,
            "fpr": 0.03293084522502744,
            "logloss": 2.459882845773882,
            "mae": 0.5256972556006527,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8245987029040667,
            "auditor_fn_violation": 0.001064642935138684,
            "auditor_fp_violation": 0.004895960832313343,
            "ave_precision_score": 0.790332234860628,
            "fpr": 0.05482456140350877,
            "logloss": 0.6561961067405908,
            "mae": 0.47938553374587445,
            "precision": 0.8470948012232415,
            "recall": 0.5746887966804979
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.835309690360135,
            "auditor_fn_violation": 0.004846601797242737,
            "auditor_fp_violation": 0.00389569148523863,
            "ave_precision_score": 0.7968647725129336,
            "fpr": 0.04720087815587267,
            "logloss": 0.6540989702549505,
            "mae": 0.4783470684950752,
            "precision": 0.8571428571428571,
            "recall": 0.5466101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8212955355816423,
            "auditor_fn_violation": 0.004422362961345279,
            "auditor_fp_violation": 0.008052835577315383,
            "ave_precision_score": 0.7892931144213169,
            "fpr": 0.07346491228070176,
            "logloss": 0.607889312504144,
            "mae": 0.44833519264009963,
            "precision": 0.8236842105263158,
            "recall": 0.6493775933609959
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.844600178356131,
            "auditor_fn_violation": 0.006530354053098666,
            "auditor_fp_violation": 0.003665650652990909,
            "ave_precision_score": 0.8103095507331802,
            "fpr": 0.06147091108671789,
            "logloss": 0.6031367294131018,
            "mae": 0.4466070831476268,
            "precision": 0.8486486486486486,
            "recall": 0.6652542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018889222862141,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6709300687875979,
            "fpr": 0.03399122807017544,
            "logloss": 2.3313739408380174,
            "mae": 0.5387512327538468,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.2652299523032986,
            "mae": 0.524601037041555,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.711256288716996,
            "auditor_fn_violation": 6.824634199606876e-05,
            "auditor_fp_violation": 0.017016013871889033,
            "ave_precision_score": 0.7051263185407103,
            "fpr": 0.1787280701754386,
            "logloss": 1.750698342470516,
            "mae": 0.31192311089059827,
            "precision": 0.6970260223048327,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6362631133068808,
            "auditor_fn_violation": 0.005195445496660407,
            "auditor_fp_violation": 0.03322339715299466,
            "ave_precision_score": 0.6287882979232025,
            "fpr": 0.21405049396267836,
            "logloss": 2.2813208101129487,
            "mae": 0.3398077930447239,
            "precision": 0.6578947368421053,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.857670164491796,
            "auditor_fn_violation": 0.004083406129431464,
            "auditor_fp_violation": 0.021037331701346397,
            "ave_precision_score": 0.8578658762099287,
            "fpr": 0.17105263157894737,
            "logloss": 0.7017774930201544,
            "mae": 0.26814636131785063,
            "precision": 0.7229129662522202,
            "recall": 0.8443983402489627
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8324075917869069,
            "auditor_fn_violation": 0.014500269772460888,
            "auditor_fp_violation": 0.023081596983464573,
            "ave_precision_score": 0.8328296937158919,
            "fpr": 0.19099890230515917,
            "logloss": 0.7610703276941203,
            "mae": 0.2783764963004876,
            "precision": 0.6994818652849741,
            "recall": 0.8580508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7195021764012379,
            "auditor_fn_violation": 0.00048454902817208866,
            "auditor_fp_violation": 0.012002753977968185,
            "ave_precision_score": 0.7154878272777699,
            "fpr": 0.17214912280701755,
            "logloss": 1.286844528703771,
            "mae": 0.315213885138123,
            "precision": 0.7015209125475285,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6594939178225272,
            "auditor_fn_violation": 0.0011302535861132325,
            "auditor_fp_violation": 0.02361169107516585,
            "ave_precision_score": 0.653397922575715,
            "fpr": 0.2030735455543359,
            "logloss": 1.7620307747287032,
            "mae": 0.3380901027029665,
            "precision": 0.6666666666666666,
            "recall": 0.7838983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018254105256634,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6708623844438262,
            "fpr": 0.03399122807017544,
            "logloss": 2.4499269456717307,
            "mae": 0.538696947749071,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179093871075188,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833026673378764,
            "fpr": 0.03293084522502744,
            "logloss": 2.3806242540845246,
            "mae": 0.5244764828140531,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.813083580810742,
            "auditor_fn_violation": 0.006576672490354519,
            "auditor_fp_violation": 0.019650142798857614,
            "ave_precision_score": 0.8137528146650699,
            "fpr": 0.13596491228070176,
            "logloss": 0.5592758847878401,
            "mae": 0.325471697463511,
            "precision": 0.7389473684210527,
            "recall": 0.7282157676348547
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7472109819449728,
            "auditor_fn_violation": 0.010737409068075689,
            "auditor_fp_violation": 0.029897806860717777,
            "ave_precision_score": 0.7488018782540815,
            "fpr": 0.15806805708013172,
            "logloss": 0.6034056515163914,
            "mae": 0.3301305360386698,
            "precision": 0.7137176938369781,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.848972616986735,
            "auditor_fn_violation": 0.011135528135691936,
            "auditor_fp_violation": 0.0184108527131783,
            "ave_precision_score": 0.849175519505861,
            "fpr": 0.11513157894736842,
            "logloss": 0.692113014036825,
            "mae": 0.26960300192616143,
            "precision": 0.777542372881356,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.821316596078739,
            "auditor_fn_violation": 0.011535098327410745,
            "auditor_fp_violation": 0.017250561974750524,
            "ave_precision_score": 0.8218901978488404,
            "fpr": 0.132821075740944,
            "logloss": 0.730432512653366,
            "mae": 0.2762545338076719,
            "precision": 0.75,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7020921833713638,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6711295358780511,
            "fpr": 0.03399122807017544,
            "logloss": 2.098862663221956,
            "mae": 0.5380431861798443,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.039521083287068,
            "mae": 0.5241211498254331,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 25349,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8546007345152113,
            "auditor_fn_violation": 0.00703392298172818,
            "auditor_fp_violation": 0.023388412892696865,
            "ave_precision_score": 0.8547997620220862,
            "fpr": 0.12938596491228072,
            "logloss": 0.6601786047536218,
            "mae": 0.2684612213487125,
            "precision": 0.7620967741935484,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.83173230322688,
            "auditor_fn_violation": 0.013181640588662119,
            "auditor_fp_violation": 0.014302538700619363,
            "ave_precision_score": 0.8321830484615415,
            "fpr": 0.14928649835345773,
            "logloss": 0.6853219752951939,
            "mae": 0.27451333388043564,
            "precision": 0.7338551859099804,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8137003672536944,
            "auditor_fn_violation": 0.007372879813641996,
            "auditor_fp_violation": 0.019650142798857614,
            "ave_precision_score": 0.8143604136111597,
            "fpr": 0.13596491228070176,
            "logloss": 0.558126316347434,
            "mae": 0.3254499347755898,
            "precision": 0.740041928721174,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7478869608135821,
            "auditor_fn_violation": 0.010195538521646917,
            "auditor_fp_violation": 0.029720275348874427,
            "ave_precision_score": 0.7494671955115328,
            "fpr": 0.16136114160263446,
            "logloss": 0.6021748539118448,
            "mae": 0.32995686509864225,
            "precision": 0.7100591715976331,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6908138262418693,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6818385951598984,
            "fpr": 0.03399122807017544,
            "logloss": 2.9994736650847726,
            "mae": 0.5486650668714439,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7097426987653753,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6975875675215064,
            "fpr": 0.03293084522502744,
            "logloss": 2.9058309049818867,
            "mae": 0.5317790618857152,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018254105256634,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6708623844438262,
            "fpr": 0.03399122807017544,
            "logloss": 2.4508952694187784,
            "mae": 0.5387507541873083,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179093871075188,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833026673378764,
            "fpr": 0.03293084522502744,
            "logloss": 2.381537483677856,
            "mae": 0.5245197571172051,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8575471078277064,
            "auditor_fn_violation": 0.009174583242338214,
            "auditor_fp_violation": 0.02047123623011017,
            "ave_precision_score": 0.8577396608882011,
            "fpr": 0.13596491228070176,
            "logloss": 0.6287600567632138,
            "mae": 0.2705153666747404,
            "precision": 0.7544554455445545,
            "recall": 0.7904564315352697
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8356832351762244,
            "auditor_fn_violation": 0.015737502093062197,
            "auditor_fp_violation": 0.015030167854794227,
            "ave_precision_score": 0.8361269489661511,
            "fpr": 0.1525795828759605,
            "logloss": 0.6461093196594632,
            "mae": 0.27584945273052586,
            "precision": 0.7306201550387597,
            "recall": 0.798728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 25349,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7167412823918918,
            "auditor_fn_violation": 0.0010054961054087512,
            "auditor_fp_violation": 0.004768461852305196,
            "ave_precision_score": 0.7124234026908014,
            "fpr": 0.3366228070175439,
            "logloss": 1.8998651153128703,
            "mae": 0.3570681748178817,
            "precision": 0.6018158236057068,
            "recall": 0.9626556016597511
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6675026386785424,
            "auditor_fn_violation": 0.004074494409198312,
            "auditor_fp_violation": 0.010466857867271442,
            "ave_precision_score": 0.660566430254506,
            "fpr": 0.3589462129527991,
            "logloss": 2.4135189642408608,
            "mae": 0.385605394204291,
            "precision": 0.5802310654685494,
            "recall": 0.9576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8509780776461799,
            "auditor_fn_violation": 0.00910861177840868,
            "auditor_fp_violation": 0.019446144430844553,
            "ave_precision_score": 0.8511770740527133,
            "fpr": 0.11074561403508772,
            "logloss": 0.6949706132931155,
            "mae": 0.26808552749518105,
            "precision": 0.7832618025751072,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.824933340445183,
            "auditor_fn_violation": 0.010521125974436732,
            "auditor_fp_violation": 0.01704302513696181,
            "ave_precision_score": 0.8254611650332744,
            "fpr": 0.12733260153677278,
            "logloss": 0.7316971479930041,
            "mae": 0.2743598336928323,
            "precision": 0.7573221757322176,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8497470323565757,
            "auditor_fn_violation": 0.009927567882361505,
            "auditor_fp_violation": 0.019152896776825783,
            "ave_precision_score": 0.8499490807426173,
            "fpr": 0.12171052631578948,
            "logloss": 0.6916688534587293,
            "mae": 0.2685585554078823,
            "precision": 0.7677824267782427,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8232942547409678,
            "auditor_fn_violation": 0.011535098327410745,
            "auditor_fp_violation": 0.018038201780816096,
            "ave_precision_score": 0.8238269628216278,
            "fpr": 0.1350164654226125,
            "logloss": 0.7318487635062407,
            "mae": 0.27560335046502354,
            "precision": 0.7469135802469136,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7019266297086405,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.670967291227992,
            "fpr": 0.03399122807017544,
            "logloss": 2.2613765294674257,
            "mae": 0.5386287146033474,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.197222242531467,
            "mae": 0.5245307919024423,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6932242910796351,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6941607648923529,
            "fpr": 0.03399122807017544,
            "logloss": 2.8118801926315315,
            "mae": 0.5474903643429443,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7223066983119767,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7232837256629416,
            "fpr": 0.03293084522502744,
            "logloss": 2.7244730082985975,
            "mae": 0.5306293763548471,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7586002506055323,
            "auditor_fn_violation": 0.0017402817208997596,
            "auditor_fp_violation": 0.005762953896368845,
            "ave_precision_score": 0.7298306341312246,
            "fpr": 0.4375,
            "logloss": 0.6959254679860798,
            "mae": 0.49919753841925085,
            "precision": 0.5413793103448276,
            "recall": 0.9771784232365145
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7444558954592001,
            "auditor_fn_violation": 0.0014697947868797562,
            "auditor_fp_violation": 0.007421317283817875,
            "ave_precision_score": 0.7126863213747425,
            "fpr": 0.4489571899012075,
            "logloss": 0.6996064994046289,
            "mae": 0.5001175768681598,
            "precision": 0.5271676300578034,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8595120450626057,
            "auditor_fn_violation": 0.010587282521656841,
            "auditor_fp_violation": 0.02091493268053856,
            "ave_precision_score": 0.8597052964778111,
            "fpr": 0.19517543859649122,
            "logloss": 0.7286532442160256,
            "mae": 0.2737710682948835,
            "precision": 0.7043189368770764,
            "recall": 0.8796680497925311
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.836316064499881,
            "auditor_fn_violation": 0.01324675807922008,
            "auditor_fp_violation": 0.02650970547272141,
            "ave_precision_score": 0.8367244907052016,
            "fpr": 0.21295279912184412,
            "logloss": 0.7935014487851051,
            "mae": 0.28541905102426923,
            "precision": 0.6819672131147541,
            "recall": 0.8813559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7191629684846692,
            "auditor_fn_violation": 0.00048454902817208866,
            "auditor_fp_violation": 0.01382088943288454,
            "ave_precision_score": 0.7151661295784675,
            "fpr": 0.17543859649122806,
            "logloss": 1.2890628276498712,
            "mae": 0.3153907310729313,
            "precision": 0.6975425330812854,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6593066860641918,
            "auditor_fn_violation": 0.0019488734674133527,
            "auditor_fp_violation": 0.024221799369388078,
            "ave_precision_score": 0.6532031226868527,
            "fpr": 0.2052689352360044,
            "logloss": 1.7637962480316882,
            "mae": 0.3381382840262376,
            "precision": 0.6648745519713262,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7005685913249851,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6737946281512847,
            "fpr": 0.03399122807017544,
            "logloss": 1.0293846787210346,
            "mae": 0.5245325436586874,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7158473248641095,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6854060071403374,
            "fpr": 0.03293084522502744,
            "logloss": 1.0069022971316968,
            "mae": 0.515343137142687,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.708323289176396,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.702375868185217,
            "fpr": 0.03399122807017544,
            "logloss": 3.1695091434455183,
            "mae": 0.5424035437370772,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.726204699105842,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7182367102762715,
            "fpr": 0.03293084522502744,
            "logloss": 3.0693793946211203,
            "mae": 0.526858802072849,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5761599143985652,
            "auditor_fn_violation": 0.0016515614763048642,
            "auditor_fp_violation": 0.0004793961648306814,
            "ave_precision_score": 0.5777125857683245,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6956961443233599,
            "mae": 0.5007797307089755,
            "precision": 0.75,
            "recall": 0.006224066390041493
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5471912325360598,
            "auditor_fn_violation": 0.000511637425812572,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5490948557769656,
            "fpr": 0.0,
            "logloss": 0.6957969194188114,
            "mae": 0.5008308803407081,
            "precision": 1.0,
            "recall": 0.00211864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.5109489140009078,
            "auditor_fn_violation": 0.0006756387857610808,
            "auditor_fp_violation": 0.001438188494492044,
            "ave_precision_score": 0.5125212242551398,
            "fpr": 0.003289473684210526,
            "logloss": 0.6948303167339079,
            "mae": 0.5006942014749113,
            "precision": 0.25,
            "recall": 0.002074688796680498
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5178525956002574,
            "auditor_fn_violation": 0.0008651323745558083,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5189615113870849,
            "fpr": 0.0,
            "logloss": 0.694064607733602,
            "mae": 0.5003074640827304,
            "precision": 1.0,
            "recall": 0.00847457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018698293137298,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6726634327950004,
            "fpr": 0.03399122807017544,
            "logloss": 2.4236223528330876,
            "mae": 0.539626546812207,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.717463948436588,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6852752641373462,
            "fpr": 0.03293084522502744,
            "logloss": 2.3543799934145273,
            "mae": 0.525088064755905,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8486896013676368,
            "auditor_fn_violation": 0.011049082769163575,
            "auditor_fp_violation": 0.01286464708282334,
            "ave_precision_score": 0.8488921110327123,
            "fpr": 0.10416666666666667,
            "logloss": 0.6956377005920786,
            "mae": 0.2707226679382642,
            "precision": 0.7916666666666666,
            "recall": 0.7489626556016598
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8230145597666582,
            "auditor_fn_violation": 0.011535098327410745,
            "auditor_fp_violation": 0.018150721753111186,
            "ave_precision_score": 0.8235594486840765,
            "fpr": 0.12294182217343579,
            "logloss": 0.7286748698089861,
            "mae": 0.27592102229279364,
            "precision": 0.7642105263157895,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6004046002526042,
            "auditor_fn_violation": 0.008412499090048787,
            "auditor_fp_violation": 0.011564157486740109,
            "ave_precision_score": 0.6018526825795633,
            "fpr": 0.044956140350877194,
            "logloss": 0.6902570614067725,
            "mae": 0.4981207669826976,
            "precision": 0.6746031746031746,
            "recall": 0.17634854771784234
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5766169784474355,
            "auditor_fn_violation": 0.0009860648570205921,
            "auditor_fp_violation": 0.010379342333264156,
            "ave_precision_score": 0.5782277852825424,
            "fpr": 0.04720087815587267,
            "logloss": 0.6915322345206056,
            "mae": 0.4987794500412716,
            "precision": 0.6666666666666666,
            "recall": 0.18220338983050846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7079151033737634,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.7022288525897535,
            "fpr": 0.03399122807017544,
            "logloss": 2.7432152201977584,
            "mae": 0.5407875810208345,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7263928191243323,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7185363840356624,
            "fpr": 0.03293084522502744,
            "logloss": 2.6559053673491793,
            "mae": 0.5254739055782659,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.702137299999522,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6711613527857161,
            "fpr": 0.03399122807017544,
            "logloss": 1.3749456471159935,
            "mae": 0.531678859830687,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 1.339020337024708,
            "mae": 0.5197847897818662,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.2642543859649123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006170950632394941,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6977822856810753,
            "mae": 0.5016384533557453,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.25905598243688255,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005500976423315139,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.0010976948408342481,
            "logloss": 0.696721895403845,
            "mae": 0.5011086878739911,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 25349,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5752526904155666,
            "auditor_fn_violation": 0.040615672999927216,
            "auditor_fp_violation": 0.030854753161974703,
            "ave_precision_score": 0.5763390883759838,
            "fpr": 0.11403508771929824,
            "logloss": 0.880749533396525,
            "mae": 0.49055678018939625,
            "precision": 0.5517241379310345,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5668161448171912,
            "auditor_fn_violation": 0.0492567303577741,
            "auditor_fp_violation": 0.023301636040397172,
            "ave_precision_score": 0.5685470011625899,
            "fpr": 0.1141602634467618,
            "logloss": 0.9097488250825589,
            "mae": 0.48341825964930135,
            "precision": 0.5772357723577236,
            "recall": 0.3008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.4438795853269538,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006170950632394941,
            "ave_precision_score": 0.5271405361763519,
            "fpr": 0.0010964912280701754,
            "logloss": 0.7000425967343606,
            "mae": 0.5022337290605432,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.5213318697402122,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005500976423315139,
            "ave_precision_score": 0.51836995416969,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6983204112034008,
            "mae": 0.5013792103915,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7019142881871085,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6709204405964726,
            "fpr": 0.03399122807017544,
            "logloss": 2.301503044324183,
            "mae": 0.5387519274556422,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179090822355275,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.683273724555765,
            "fpr": 0.03293084522502744,
            "logloss": 2.236179972102047,
            "mae": 0.5246126046956289,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 25349,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.2642543859649123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006170950632394941,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6975906406263015,
            "mae": 0.501589144955863,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.25905598243688255,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005500976423315139,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6965719812733779,
            "mae": 0.5010801887407522,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7108598994169211,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.7102515588695868,
            "fpr": 0.03399122807017544,
            "logloss": 2.9430954549960804,
            "mae": 0.5415122567091634,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7252405973898308,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7242224797136437,
            "fpr": 0.03293084522502744,
            "logloss": 2.8502863878057143,
            "mae": 0.5259701045401012,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6932594062075783,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6942261519132591,
            "fpr": 0.03399122807017544,
            "logloss": 2.8117663371255937,
            "mae": 0.5474897112093331,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7223179916748426,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7232949916009046,
            "fpr": 0.03293084522502744,
            "logloss": 2.7243664914846346,
            "mae": 0.5306287411922123,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7843228970232952,
            "auditor_fn_violation": 0.0015446422071776912,
            "auditor_fp_violation": 0.004513463892288864,
            "ave_precision_score": 0.7844200162018931,
            "fpr": 0.0625,
            "logloss": 0.6753706704063291,
            "mae": 0.49053798021193135,
            "precision": 0.821875,
            "recall": 0.5456431535269709
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7838267689643051,
            "auditor_fn_violation": 0.010000186049973036,
            "auditor_fp_violation": 0.0024079274071147645,
            "ave_precision_score": 0.7839029105857077,
            "fpr": 0.04720087815587267,
            "logloss": 0.6763079640165479,
            "mae": 0.4910182132744501,
            "precision": 0.8506944444444444,
            "recall": 0.5190677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7076900638753454,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.7017720580768576,
            "fpr": 0.03399122807017544,
            "logloss": 3.022337001253274,
            "mae": 0.548561979788039,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7233992932140874,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.715522852202898,
            "fpr": 0.03293084522502744,
            "logloss": 2.9271085441660087,
            "mae": 0.5317165944146394,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 25349,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.7658091561569416,
            "auditor_fn_violation": 0.000561894882434305,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5467911169405473,
            "fpr": 0.0,
            "logloss": 0.6963739546418491,
            "mae": 0.500569916183227,
            "precision": 1.0,
            "recall": 0.002074688796680498
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6959513479698257,
            "mae": 0.5003436076261603,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7020039057117273,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6710439043792339,
            "fpr": 0.03399122807017544,
            "logloss": 2.1883466075867952,
            "mae": 0.538380820034562,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.126340801199459,
            "mae": 0.5243589315158607,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6887127240167797,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.689681549874671,
            "fpr": 0.03399122807017544,
            "logloss": 2.4506610785072116,
            "mae": 0.545308646500129,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7151314849252938,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7162435399971538,
            "fpr": 0.03293084522502744,
            "logloss": 2.3721061140282784,
            "mae": 0.5286143766166632,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7017995135939387,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6708061445470028,
            "fpr": 0.03399122807017544,
            "logloss": 2.467864942006505,
            "mae": 0.538765225938844,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179090822355275,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.683273724555765,
            "fpr": 0.03293084522502744,
            "logloss": 2.398055281298192,
            "mae": 0.5245098165460299,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018034442491533,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6708448544443879,
            "fpr": 0.03399122807017544,
            "logloss": 2.081032183174922,
            "mae": 0.5426193729345278,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.0204419217823153,
            "mae": 0.5261052831573949,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7999789012569255,
            "auditor_fn_violation": 0.004094780519764142,
            "auditor_fp_violation": 0.0061072011423908635,
            "ave_precision_score": 0.8000027333406445,
            "fpr": 0.06030701754385965,
            "logloss": 0.666838164142904,
            "mae": 0.48595638847664785,
            "precision": 0.8382352941176471,
            "recall": 0.5912863070539419
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7963623090851636,
            "auditor_fn_violation": 0.0037907682003386197,
            "auditor_fp_violation": 0.008296472623890744,
            "ave_precision_score": 0.7968962975916207,
            "fpr": 0.050493962678375415,
            "logloss": 0.6672638238845505,
            "mae": 0.48619309044826436,
            "precision": 0.8580246913580247,
            "recall": 0.5889830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6413923231528287,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6333388325676118,
            "fpr": 0.03399122807017544,
            "logloss": 2.291883799830719,
            "mae": 0.5388691570730308,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6553690661784678,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6448317816389761,
            "fpr": 0.03293084522502744,
            "logloss": 2.223772715132579,
            "mae": 0.5247715726759566,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5683967134324892,
            "auditor_fn_violation": 0.034573596855208576,
            "auditor_fp_violation": 0.02533149734802122,
            "ave_precision_score": 0.5697235164715557,
            "fpr": 0.06798245614035088,
            "logloss": 0.940586267254205,
            "mae": 0.49595422259868394,
            "precision": 0.6075949367088608,
            "recall": 0.1991701244813278
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5618009212981717,
            "auditor_fn_violation": 0.04360546242720797,
            "auditor_fp_violation": 0.02275153839806566,
            "ave_precision_score": 0.5635403891732343,
            "fpr": 0.07903402854006586,
            "logloss": 0.9673308074042486,
            "mae": 0.4880413241646356,
            "precision": 0.6065573770491803,
            "recall": 0.23516949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7044897910752679,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6754022633469563,
            "fpr": 0.03399122807017544,
            "logloss": 2.448051482159089,
            "mae": 0.5384330164683011,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7172403064360635,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6853351155377058,
            "fpr": 0.03293084522502744,
            "logloss": 2.380954700646068,
            "mae": 0.5243129677289502,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7021274063090157,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6711880075582657,
            "fpr": 0.03399122807017544,
            "logloss": 2.092135320304443,
            "mae": 0.5379307625821399,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.717908223223661,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.683344567156761,
            "fpr": 0.03293084522502744,
            "logloss": 2.0330349477535803,
            "mae": 0.5240377284970817,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018153631281461,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6709461203556147,
            "fpr": 0.03399122807017544,
            "logloss": 2.448734786863055,
            "mae": 0.5387316011954426,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179059508106436,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833898288000815,
            "fpr": 0.03293084522502744,
            "logloss": 2.3794428028562185,
            "mae": 0.5245071937116405,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7018657823143778,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6709069398588984,
            "fpr": 0.03399122807017544,
            "logloss": 2.353327801706199,
            "mae": 0.5388233382857339,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.286548125022466,
            "mae": 0.5246478794986008,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7009218883665512,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6798093371447906,
            "fpr": 0.03399122807017544,
            "logloss": 1.6377824612329757,
            "mae": 0.5364817327394951,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7193221047255073,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6963059854751472,
            "fpr": 0.03293084522502744,
            "logloss": 1.5957200965389018,
            "mae": 0.5226914169988569,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8500306631988508,
            "auditor_fn_violation": 0.013430880104826385,
            "auditor_fp_violation": 0.01593482252141983,
            "ave_precision_score": 0.8502364820618502,
            "fpr": 0.09758771929824561,
            "logloss": 0.698909856651886,
            "mae": 0.2695605031791286,
            "precision": 0.7995495495495496,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8215894467061848,
            "auditor_fn_violation": 0.011409514595620387,
            "auditor_fp_violation": 0.014034991210939943,
            "ave_precision_score": 0.8221347493635649,
            "fpr": 0.10976948408342481,
            "logloss": 0.7365903594462737,
            "mae": 0.2770889453849613,
            "precision": 0.7782705099778271,
            "recall": 0.7436440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6446217999142021,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6365170057129136,
            "fpr": 0.03399122807017544,
            "logloss": 2.3292076813573717,
            "mae": 0.5389643345220145,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6596442096766726,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6490697174367914,
            "fpr": 0.03293084522502744,
            "logloss": 2.259943548924482,
            "mae": 0.5248280613684186,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7020921783361612,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.6711298861731394,
            "fpr": 0.03399122807017544,
            "logloss": 2.0998489369299467,
            "mae": 0.53791740605722,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7179084697690417,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6833018980141132,
            "fpr": 0.03293084522502744,
            "logloss": 2.0405355581643185,
            "mae": 0.5240252976265912,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.826844386473551,
            "auditor_fn_violation": 0.009336099585062246,
            "auditor_fp_violation": 0.020920032639738885,
            "ave_precision_score": 0.8271054580686656,
            "fpr": 0.12938596491228072,
            "logloss": 0.740007312316786,
            "mae": 0.2848596299089636,
            "precision": 0.7531380753138075,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7974305909733524,
            "auditor_fn_violation": 0.012128132616420775,
            "auditor_fp_violation": 0.017750650740506448,
            "ave_precision_score": 0.7980064012550998,
            "fpr": 0.14928649835345773,
            "logloss": 0.7947249289547903,
            "mae": 0.29347845597050704,
            "precision": 0.7274549098196392,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6491349473391809,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.641183335192388,
            "fpr": 0.03399122807017544,
            "logloss": 2.4386443138776,
            "mae": 0.5391721329626243,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6664398852717867,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.6561410137656588,
            "fpr": 0.03293084522502744,
            "logloss": 2.366010096628492,
            "mae": 0.5249298000636661,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 25349,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7082849293331761,
            "auditor_fn_violation": 0.0017402817208997568,
            "auditor_fp_violation": 0.00576295389636883,
            "ave_precision_score": 0.7023358615541232,
            "fpr": 0.03399122807017544,
            "logloss": 3.167358923682765,
            "mae": 0.5423789243853989,
            "precision": 0.2619047619047619,
            "recall": 0.022821576763485476
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.7262875416068522,
            "auditor_fn_violation": 0.0014697947868797644,
            "auditor_fp_violation": 0.007421317283817878,
            "ave_precision_score": 0.7183185641469088,
            "fpr": 0.03293084522502744,
            "logloss": 3.067193852327795,
            "mae": 0.5268333680231562,
            "precision": 0.34782608695652173,
            "recall": 0.03389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8595290077760684,
            "auditor_fn_violation": 0.006906529810002186,
            "auditor_fp_violation": 0.02014483884128927,
            "ave_precision_score": 0.8597214688352663,
            "fpr": 0.17543859649122806,
            "logloss": 0.683130606570535,
            "mae": 0.2686372311935351,
            "precision": 0.7183098591549296,
            "recall": 0.8464730290456431
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8356082238666529,
            "auditor_fn_violation": 0.013649091145881786,
            "auditor_fp_violation": 0.02414178516686712,
            "ave_precision_score": 0.8360276301807138,
            "fpr": 0.19319429198682767,
            "logloss": 0.7370662765620836,
            "mae": 0.27822470797858306,
            "precision": 0.6991452991452991,
            "recall": 0.8665254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8120657421861943,
            "auditor_fn_violation": 0.009809274222901655,
            "auditor_fp_violation": 0.01952774377804978,
            "ave_precision_score": 0.8127363884670701,
            "fpr": 0.1337719298245614,
            "logloss": 0.5618615025891011,
            "mae": 0.32616029541455455,
            "precision": 0.7409766454352441,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7458562247711888,
            "auditor_fn_violation": 0.008507135016465422,
            "auditor_fp_violation": 0.0296502629216686,
            "ave_precision_score": 0.7474473256453997,
            "fpr": 0.15587266739846323,
            "logloss": 0.6051478120086738,
            "mae": 0.33123510410093204,
            "precision": 0.7137096774193549,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8320340906604687,
            "auditor_fn_violation": 0.012807563514595622,
            "auditor_fp_violation": 0.021924724602203186,
            "ave_precision_score": 0.8322877924097543,
            "fpr": 0.11842105263157894,
            "logloss": 0.7397605292968858,
            "mae": 0.28146326511598746,
            "precision": 0.7667386609071274,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.801249996369001,
            "auditor_fn_violation": 0.011972315764014212,
            "auditor_fp_violation": 0.017063028687592043,
            "ave_precision_score": 0.8017629237668912,
            "fpr": 0.13721185510428102,
            "logloss": 0.7972246507453057,
            "mae": 0.2911444023304741,
            "precision": 0.7417355371900827,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7166685070395291,
            "auditor_fn_violation": 0.002015541966950573,
            "auditor_fp_violation": 0.0034399224806201693,
            "ave_precision_score": 0.7123179250855385,
            "fpr": 0.33223684210526316,
            "logloss": 1.877439736710372,
            "mae": 0.35417839118602407,
            "precision": 0.6039215686274509,
            "recall": 0.9585062240663901
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6693591071855687,
            "auditor_fn_violation": 0.004074494409198312,
            "auditor_fp_violation": 0.015457743749515555,
            "ave_precision_score": 0.6618211077732089,
            "fpr": 0.3556531284302964,
            "logloss": 2.3880171471169658,
            "mae": 0.3827294583531235,
            "precision": 0.5824742268041238,
            "recall": 0.9576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7756792168797488,
            "auditor_fn_violation": 0.0111082295988935,
            "auditor_fp_violation": 0.02876376988984089,
            "ave_precision_score": 0.7761368038956603,
            "fpr": 0.12719298245614036,
            "logloss": 0.5897085464556178,
            "mae": 0.39596601551921484,
            "precision": 0.7427937915742794,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7515841168338,
            "auditor_fn_violation": 0.011239743995237125,
            "auditor_fp_violation": 0.022116425665555637,
            "ave_precision_score": 0.7530795945741826,
            "fpr": 0.1119648737650933,
            "logloss": 0.591454876271136,
            "mae": 0.3881906061939298,
            "precision": 0.76,
            "recall": 0.684322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7308294067726484,
            "auditor_fn_violation": 0.002356773676930917,
            "auditor_fp_violation": 0.011780905752753973,
            "ave_precision_score": 0.7267416571248303,
            "fpr": 0.16447368421052633,
            "logloss": 1.2351301421649628,
            "mae": 0.3087623755316648,
            "precision": 0.7126436781609196,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6700011708737308,
            "auditor_fn_violation": 0.0026279558689464005,
            "auditor_fp_violation": 0.02785494425260485,
            "ave_precision_score": 0.6638971678572747,
            "fpr": 0.19758507135016465,
            "logloss": 1.7050977240803233,
            "mae": 0.33154893012102626,
            "precision": 0.6750902527075813,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7168947408504522,
            "auditor_fn_violation": 0.002015541966950573,
            "auditor_fp_violation": 0.003177274581803358,
            "ave_precision_score": 0.7125908606974961,
            "fpr": 0.3333333333333333,
            "logloss": 1.8764558755245024,
            "mae": 0.35468320996709546,
            "precision": 0.6031331592689295,
            "recall": 0.9585062240663901
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6687495054338372,
            "auditor_fn_violation": 0.004074494409198312,
            "auditor_fp_violation": 0.015457743749515555,
            "ave_precision_score": 0.6618043975040342,
            "fpr": 0.3556531284302964,
            "logloss": 2.3865675520400815,
            "mae": 0.3831740189094612,
            "precision": 0.5824742268041238,
            "recall": 0.9576271186440678
        }
    }
]