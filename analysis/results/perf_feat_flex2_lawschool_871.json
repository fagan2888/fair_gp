[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8768625041457182,
            "auditor_fn_violation": 0.011509620826259195,
            "auditor_fp_violation": 0.016400761411358378,
            "ave_precision_score": 0.8758369584300505,
            "fpr": 0.18530701754385964,
            "logloss": 1.0620155076323174,
            "mae": 0.24534577514766653,
            "precision": 0.7086206896551724,
            "recall": 0.8838709677419355
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8840378168193993,
            "auditor_fn_violation": 0.008465045490359814,
            "auditor_fp_violation": 0.016548660135989303,
            "ave_precision_score": 0.8833941756375763,
            "fpr": 0.1602634467618002,
            "logloss": 1.0252979856147728,
            "mae": 0.22847749625976838,
            "precision": 0.7487091222030982,
            "recall": 0.8895705521472392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 871,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8054499725344579,
            "auditor_fn_violation": 0.005859743444633088,
            "auditor_fp_violation": 0.01990609914046863,
            "ave_precision_score": 0.805842376531896,
            "fpr": 0.15021929824561403,
            "logloss": 0.761827927685079,
            "mae": 0.28491889487072225,
            "precision": 0.7254509018036072,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7966168785967341,
            "auditor_fn_violation": 0.014056779331910147,
            "auditor_fp_violation": 0.01447292439431696,
            "ave_precision_score": 0.7970751842798771,
            "fpr": 0.13611416026344675,
            "logloss": 0.8122372081461335,
            "mae": 0.2856354641013208,
            "precision": 0.7494949494949495,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.872171210978964,
            "auditor_fn_violation": 0.011566213921901533,
            "auditor_fp_violation": 0.017146473566466505,
            "ave_precision_score": 0.8714193644669319,
            "fpr": 0.17105263157894737,
            "logloss": 1.0168395848673977,
            "mae": 0.24165427638470618,
            "precision": 0.7204301075268817,
            "recall": 0.864516129032258
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8826854304697764,
            "auditor_fn_violation": 0.005409907088774111,
            "auditor_fp_violation": 0.012623490669593855,
            "ave_precision_score": 0.8826575172120237,
            "fpr": 0.1350164654226125,
            "logloss": 0.961026100597486,
            "mae": 0.22381914958790164,
            "precision": 0.7726432532347505,
            "recall": 0.8548057259713702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8660070913204847,
            "auditor_fn_violation": 0.01073853989813243,
            "auditor_fp_violation": 0.016830036500647596,
            "ave_precision_score": 0.8653415012176191,
            "fpr": 0.16885964912280702,
            "logloss": 1.0521875453408849,
            "mae": 0.24694404416393598,
            "precision": 0.7184643510054844,
            "recall": 0.8451612903225807
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8720243512922733,
            "auditor_fn_violation": 0.01024739662251195,
            "auditor_fp_violation": 0.012563663699595782,
            "ave_precision_score": 0.8717446416679752,
            "fpr": 0.14709110867178923,
            "logloss": 1.0448854034028758,
            "mae": 0.2362359739497747,
            "precision": 0.7532228360957642,
            "recall": 0.83640081799591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 871,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8048376441447944,
            "auditor_fn_violation": 0.010773910582908889,
            "auditor_fp_violation": 0.01777934769810433,
            "ave_precision_score": 0.8051385719280089,
            "fpr": 0.13486842105263158,
            "logloss": 0.9656227319160792,
            "mae": 0.28913685606544254,
            "precision": 0.7331887201735358,
            "recall": 0.7268817204301076
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8005527883521711,
            "auditor_fn_violation": 0.010292292117024607,
            "auditor_fp_violation": 0.009978098126635497,
            "ave_precision_score": 0.8011563898664694,
            "fpr": 0.1207464324917673,
            "logloss": 1.052272749141731,
            "mae": 0.2839596957782736,
            "precision": 0.7624190064794817,
            "recall": 0.721881390593047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 871,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8749951162402214,
            "auditor_fn_violation": 0.01036361063950198,
            "auditor_fp_violation": 0.014519310020016484,
            "ave_precision_score": 0.8742570424195865,
            "fpr": 0.13815789473684212,
            "logloss": 0.884566271098597,
            "mae": 0.22863128472571356,
            "precision": 0.7558139534883721,
            "recall": 0.8387096774193549
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8845172594180093,
            "auditor_fn_violation": 0.006943088226381045,
            "auditor_fp_violation": 0.011478974721804588,
            "ave_precision_score": 0.8846193331905454,
            "fpr": 0.11525795828759605,
            "logloss": 0.8849238015138917,
            "mae": 0.21690531481991124,
            "precision": 0.7928994082840237,
            "recall": 0.8220858895705522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 871,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6168692072403161,
            "auditor_fn_violation": 0.01233022071307301,
            "auditor_fp_violation": 0.0424025668197339,
            "ave_precision_score": 0.5933447864471447,
            "fpr": 0.1875,
            "logloss": 3.390482122540087,
            "mae": 0.3501599319360793,
            "precision": 0.6545454545454545,
            "recall": 0.6967741935483871
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.636908073782753,
            "auditor_fn_violation": 0.01584586478823918,
            "auditor_fp_violation": 0.03211927937114052,
            "ave_precision_score": 0.6133301385298798,
            "fpr": 0.1690450054884742,
            "logloss": 3.4019772089607687,
            "mae": 0.34505282311718427,
            "precision": 0.6926147704590818,
            "recall": 0.7096114519427403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 871,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8745237990431526,
            "auditor_fn_violation": 0.0060837577815506545,
            "auditor_fp_violation": 0.006829153420463918,
            "ave_precision_score": 0.8738577180226079,
            "fpr": 0.11074561403508772,
            "logloss": 0.870540315595003,
            "mae": 0.22127692818832082,
            "precision": 0.7878151260504201,
            "recall": 0.8064516129032258
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8853268136542599,
            "auditor_fn_violation": 0.006271900583416955,
            "auditor_fp_violation": 0.014670613512571465,
            "ave_precision_score": 0.8854516692904477,
            "fpr": 0.09549945115257959,
            "logloss": 0.9067516737646911,
            "mae": 0.21611858895774375,
            "precision": 0.8160676532769556,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 871,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8702383702053503,
            "auditor_fn_violation": 0.007010469722693834,
            "auditor_fp_violation": 0.021988696573648894,
            "ave_precision_score": 0.8694332478566948,
            "fpr": 0.23135964912280702,
            "logloss": 1.192003914023933,
            "mae": 0.2822254642907371,
            "precision": 0.6677165354330709,
            "recall": 0.9118279569892473
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8710303131505426,
            "auditor_fn_violation": 0.006666980935128256,
            "auditor_fp_violation": 0.02135042477148699,
            "ave_precision_score": 0.8701124876185096,
            "fpr": 0.21295279912184412,
            "logloss": 1.1286622708646692,
            "mae": 0.26186323783876037,
            "precision": 0.694488188976378,
            "recall": 0.901840490797546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 871,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8441336467380531,
            "auditor_fn_violation": 0.0012568383323901143,
            "auditor_fp_violation": 0.0076190195847560755,
            "ave_precision_score": 0.7812944821858454,
            "fpr": 0.09978070175438597,
            "logloss": 6.210730669814545,
            "mae": 0.2271442291504133,
            "precision": 0.7931818181818182,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8643867201911959,
            "auditor_fn_violation": 0.0070575717373882975,
            "auditor_fp_violation": 0.008737338792327581,
            "ave_precision_score": 0.8217688640441578,
            "fpr": 0.07574094401756312,
            "logloss": 6.280760470314411,
            "mae": 0.23437368909684222,
            "precision": 0.8337349397590361,
            "recall": 0.7075664621676891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 871,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6176180279156769,
            "auditor_fn_violation": 0.005305602716468593,
            "auditor_fp_violation": 0.04144834962125673,
            "ave_precision_score": 0.6143733136505739,
            "fpr": 0.22916666666666666,
            "logloss": 1.6631525874562036,
            "mae": 0.37886195211046325,
            "precision": 0.6510851419031719,
            "recall": 0.8387096774193549
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6537772772961021,
            "auditor_fn_violation": 0.01614666460147392,
            "auditor_fp_violation": 0.03937134860395067,
            "ave_precision_score": 0.6498313305518745,
            "fpr": 0.21514818880351264,
            "logloss": 1.3056409206255237,
            "mae": 0.37277137088813256,
            "precision": 0.67003367003367,
            "recall": 0.8139059304703476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 871,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8198451304930031,
            "auditor_fn_violation": 0.009880211280890401,
            "auditor_fp_violation": 0.01454874602613918,
            "ave_precision_score": 0.8201439434548295,
            "fpr": 0.13486842105263158,
            "logloss": 0.7228766053573209,
            "mae": 0.2822318314509915,
            "precision": 0.7399577167019028,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.804958679999844,
            "auditor_fn_violation": 0.007142873176962333,
            "auditor_fp_violation": 0.009723183210991514,
            "ave_precision_score": 0.8063420033163442,
            "fpr": 0.11855104281009879,
            "logloss": 0.7896355146393129,
            "mae": 0.2811266364569286,
            "precision": 0.7697228144989339,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8341605875796951,
            "auditor_fn_violation": 0.007427843803056027,
            "auditor_fp_violation": 0.01837297382157856,
            "ave_precision_score": 0.8344188805073012,
            "fpr": 0.12938596491228072,
            "logloss": 0.9088327354387208,
            "mae": 0.2605568377038175,
            "precision": 0.7510548523206751,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8346526405746476,
            "auditor_fn_violation": 0.011872613523869813,
            "auditor_fp_violation": 0.004687313040718759,
            "ave_precision_score": 0.8350445171056087,
            "fpr": 0.10647639956092206,
            "logloss": 1.0029373085703,
            "mae": 0.2562760595193671,
            "precision": 0.7922912205567452,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 871,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8748749816947278,
            "auditor_fn_violation": 0.007357102433503111,
            "auditor_fp_violation": 0.011705718434789434,
            "ave_precision_score": 0.8742893240355069,
            "fpr": 0.1162280701754386,
            "logloss": 0.8672817236077122,
            "mae": 0.22269698455786402,
            "precision": 0.78099173553719,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8806160190504162,
            "auditor_fn_violation": 0.0077152907319985925,
            "auditor_fp_violation": 0.01292262551958423,
            "ave_precision_score": 0.880753682779584,
            "fpr": 0.09989023051591657,
            "logloss": 0.9307261384039278,
            "mae": 0.21979479409216238,
            "precision": 0.8092243186582809,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 871,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8738026837368414,
            "auditor_fn_violation": 0.009866063006979817,
            "auditor_fp_violation": 0.016587189450135414,
            "ave_precision_score": 0.8732968639532948,
            "fpr": 0.15789473684210525,
            "logloss": 0.9825761440538858,
            "mae": 0.2381879575544399,
            "precision": 0.7338262476894639,
            "recall": 0.853763440860215
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8801627941297911,
            "auditor_fn_violation": 0.0073000074077565974,
            "auditor_fp_violation": 0.012787364543936409,
            "ave_precision_score": 0.880072378417935,
            "fpr": 0.12733260153677278,
            "logloss": 0.9750653392873907,
            "mae": 0.2243210144707972,
            "precision": 0.779467680608365,
            "recall": 0.8384458077709611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 871,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8459606833637032,
            "auditor_fn_violation": 0.00766129032258065,
            "auditor_fp_violation": 0.0203108442246556,
            "ave_precision_score": 0.8458316357759785,
            "fpr": 0.19736842105263158,
            "logloss": 0.9202837806526287,
            "mae": 0.28575198991210016,
            "precision": 0.6907216494845361,
            "recall": 0.864516129032258
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8591224770835503,
            "auditor_fn_violation": 0.009089092864085623,
            "auditor_fp_violation": 0.01887931079330563,
            "ave_precision_score": 0.8593165840409513,
            "fpr": 0.17233809001097694,
            "logloss": 0.8503708128443933,
            "mae": 0.26701641740532156,
            "precision": 0.7255244755244755,
            "recall": 0.8486707566462167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 871,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.684765749814726,
            "auditor_fn_violation": 0.003214016223354087,
            "auditor_fp_violation": 0.0407026374661486,
            "ave_precision_score": 0.6818481153066505,
            "fpr": 0.1962719298245614,
            "logloss": 1.5149197020885197,
            "mae": 0.3015541580457173,
            "precision": 0.6780575539568345,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7281901673907867,
            "auditor_fn_violation": 0.005369501143712728,
            "auditor_fp_violation": 0.01757092097117381,
            "ave_precision_score": 0.7246813041045775,
            "fpr": 0.16136114160263446,
            "logloss": 1.3127427330512973,
            "mae": 0.28811006219997937,
            "precision": 0.7267657992565055,
            "recall": 0.7995910020449898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8332528852856931,
            "auditor_fn_violation": 0.008571495944161484,
            "auditor_fp_violation": 0.021863593547627465,
            "ave_precision_score": 0.8336668895969235,
            "fpr": 0.12719298245614036,
            "logloss": 0.6254977841914963,
            "mae": 0.27698518245114373,
            "precision": 0.7537154989384289,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8333134316854933,
            "auditor_fn_violation": 0.00507543565465488,
            "auditor_fp_violation": 0.004942227956362732,
            "ave_precision_score": 0.8336506817522662,
            "fpr": 0.10976948408342481,
            "logloss": 0.6624087165930764,
            "mae": 0.27423505984086766,
            "precision": 0.7863247863247863,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 871,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8430188072919413,
            "auditor_fn_violation": 0.0004810413129598224,
            "auditor_fp_violation": 0.006983692452608034,
            "ave_precision_score": 0.7882328428409726,
            "fpr": 0.09868421052631579,
            "logloss": 5.433686386810475,
            "mae": 0.2283220771776149,
            "precision": 0.7940503432494279,
            "recall": 0.7462365591397849
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8715454851345134,
            "auditor_fn_violation": 0.009003791424511602,
            "auditor_fp_violation": 0.008945432601016538,
            "ave_precision_score": 0.837913902902595,
            "fpr": 0.07354555433589462,
            "logloss": 5.258161278429327,
            "mae": 0.23193716415141058,
            "precision": 0.837378640776699,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8682334209658302,
            "auditor_fn_violation": 0.00436238445576307,
            "auditor_fp_violation": 0.007503728560775543,
            "ave_precision_score": 0.8699560933966752,
            "fpr": 0.03728070175438596,
            "logloss": 1.1915287675449415,
            "mae": 0.2498261645784003,
            "precision": 0.89171974522293,
            "recall": 0.6021505376344086
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8809989584766025,
            "auditor_fn_violation": 0.013369878265866632,
            "auditor_fp_violation": 0.0005488474204171233,
            "ave_precision_score": 0.8811715456970568,
            "fpr": 0.04061470911086718,
            "logloss": 1.3179828225978578,
            "mae": 0.2620433515523537,
            "precision": 0.8878787878787879,
            "recall": 0.5991820040899796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 871,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8649993166760215,
            "auditor_fn_violation": 0.010691378985097151,
            "auditor_fp_violation": 0.012632952627654149,
            "ave_precision_score": 0.8648891700121861,
            "fpr": 0.1074561403508772,
            "logloss": 0.78474719233547,
            "mae": 0.23139887923341523,
            "precision": 0.7910447761194029,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8707895244727737,
            "auditor_fn_violation": 0.007751207127608711,
            "auditor_fp_violation": 0.013081297048709563,
            "ave_precision_score": 0.871005875395268,
            "fpr": 0.09330406147091108,
            "logloss": 0.8398724244477845,
            "mae": 0.23009067596160626,
            "precision": 0.816414686825054,
            "recall": 0.7730061349693251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 871,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8363042337716453,
            "auditor_fn_violation": 0.00821307300509338,
            "auditor_fp_violation": 0.015498057223595901,
            "ave_precision_score": 0.8365490142804654,
            "fpr": 0.12171052631578948,
            "logloss": 0.92943386087124,
            "mae": 0.2592060805467788,
            "precision": 0.7571115973741794,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.838131043540421,
            "auditor_fn_violation": 0.0035938843357374915,
            "auditor_fp_violation": 0.006341658819795965,
            "ave_precision_score": 0.8385220389762628,
            "fpr": 0.10318331503841932,
            "logloss": 1.0299374750794676,
            "mae": 0.2525179893584358,
            "precision": 0.7965367965367965,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 871,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8410182763984488,
            "auditor_fn_violation": 0.0016270514997170356,
            "auditor_fp_violation": 0.007376172534243892,
            "ave_precision_score": 0.8411310516320497,
            "fpr": 0.09978070175438597,
            "logloss": 0.9396049799029047,
            "mae": 0.2451608011093474,
            "precision": 0.7922374429223744,
            "recall": 0.7462365591397849
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8606031139122506,
            "auditor_fn_violation": 0.00795997117709253,
            "auditor_fp_violation": 0.009884455912725456,
            "ave_precision_score": 0.8608529265199714,
            "fpr": 0.07683863885839737,
            "logloss": 0.9841691177626332,
            "mae": 0.2458972552649089,
            "precision": 0.8300970873786407,
            "recall": 0.6993865030674846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 871,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8763268470569333,
            "auditor_fn_violation": 0.004775042444821733,
            "auditor_fp_violation": 0.009213469916401745,
            "ave_precision_score": 0.8756818077725994,
            "fpr": 0.09539473684210527,
            "logloss": 1.0753986695748525,
            "mae": 0.21653193053968503,
            "precision": 0.8053691275167785,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8849220372912637,
            "auditor_fn_violation": 0.000471402692382809,
            "auditor_fp_violation": 0.012613085979159411,
            "ave_precision_score": 0.8849870749246426,
            "fpr": 0.07793633369923161,
            "logloss": 1.1533590680451566,
            "mae": 0.21221742665027052,
            "precision": 0.8393665158371041,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 871,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8719286467702929,
            "auditor_fn_violation": 0.008387568383323902,
            "auditor_fp_violation": 0.012902782683778799,
            "ave_precision_score": 0.8713966024514344,
            "fpr": 0.11293859649122807,
            "logloss": 0.9762132000222588,
            "mae": 0.22528095763553127,
            "precision": 0.7836134453781513,
            "recall": 0.8021505376344086
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8796925711160728,
            "auditor_fn_violation": 0.005306647451395015,
            "auditor_fp_violation": 0.013786214825643399,
            "ave_precision_score": 0.879744517105805,
            "fpr": 0.09440175631174534,
            "logloss": 1.0229955072340993,
            "mae": 0.21968452950097425,
            "precision": 0.8170212765957446,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 871,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.87344618267407,
            "auditor_fn_violation": 0.007993774759479348,
            "auditor_fp_violation": 0.01050865418580007,
            "ave_precision_score": 0.8727506726469769,
            "fpr": 0.09978070175438597,
            "logloss": 0.9752499928276019,
            "mae": 0.22159934427578248,
            "precision": 0.8008752735229759,
            "recall": 0.7870967741935484
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8804854461823294,
            "auditor_fn_violation": 0.009701916364183273,
            "auditor_fp_violation": 0.008742541137544807,
            "ave_precision_score": 0.8805480408643304,
            "fpr": 0.0801317233809001,
            "logloss": 1.036879138132578,
            "mae": 0.2155921928720782,
            "precision": 0.838495575221239,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 871,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8154238371682987,
            "auditor_fn_violation": 0.023196095076400684,
            "auditor_fp_violation": 0.05716717689077281,
            "ave_precision_score": 0.8158052499930356,
            "fpr": 0.18311403508771928,
            "logloss": 0.6161704735932838,
            "mae": 0.36314300680226697,
            "precision": 0.6895910780669146,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8300481717356101,
            "auditor_fn_violation": 0.02905187449913464,
            "auditor_fp_violation": 0.06283912787884778,
            "ave_precision_score": 0.8303408854622819,
            "fpr": 0.14270032930845225,
            "logloss": 0.6157868671158953,
            "mae": 0.3631605277364178,
            "precision": 0.7470817120622568,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 871,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.8728217213103038,
            "auditor_fn_violation": 0.005128749292586305,
            "auditor_fp_violation": 0.023185760822638256,
            "ave_precision_score": 0.8706900515187951,
            "fpr": 0.3442982456140351,
            "logloss": 1.7610837907639416,
            "mae": 0.3591905795434733,
            "precision": 0.5916775032509753,
            "recall": 0.978494623655914
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8849555743072262,
            "auditor_fn_violation": 0.007690598210016635,
            "auditor_fp_violation": 0.021641756103651526,
            "ave_precision_score": 0.8833775989746764,
            "fpr": 0.29857299670691545,
            "logloss": 1.5019377365459836,
            "mae": 0.32018102238917867,
            "precision": 0.6339165545087483,
            "recall": 0.9631901840490797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8439607842695143,
            "auditor_fn_violation": 0.007373608753065461,
            "auditor_fp_violation": 0.017965775736881354,
            "ave_precision_score": 0.8442165963257051,
            "fpr": 0.1206140350877193,
            "logloss": 0.8930295070229592,
            "mae": 0.25243899069283776,
            "precision": 0.7619047619047619,
            "recall": 0.7569892473118279
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8468832075224342,
            "auditor_fn_violation": 0.0017666377090727137,
            "auditor_fp_violation": 0.010074341513154133,
            "ave_precision_score": 0.8472125776642425,
            "fpr": 0.10208562019758508,
            "logloss": 0.9876841022545638,
            "mae": 0.2481832540623808,
            "precision": 0.7978260869565217,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 871,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.840796207880464,
            "auditor_fn_violation": 0.00428692699490663,
            "auditor_fp_violation": 0.008980434867930452,
            "ave_precision_score": 0.8409505154004575,
            "fpr": 0.10087719298245613,
            "logloss": 0.968757712747595,
            "mae": 0.24581457049756122,
            "precision": 0.7909090909090909,
            "recall": 0.7483870967741936
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8600936789251775,
            "auditor_fn_violation": 0.00695431210000921,
            "auditor_fp_violation": 0.009798617216641265,
            "ave_precision_score": 0.8603441417764417,
            "fpr": 0.0801317233809001,
            "logloss": 0.9726124787656836,
            "mae": 0.24664595409948448,
            "precision": 0.8236714975845411,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 871,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8713251463193267,
            "auditor_fn_violation": 0.006946802490096209,
            "auditor_fp_violation": 0.011381922367439854,
            "ave_precision_score": 0.8708368483667249,
            "fpr": 0.11732456140350878,
            "logloss": 0.8453368104413498,
            "mae": 0.22647000735117961,
            "precision": 0.7793814432989691,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8827971742272641,
            "auditor_fn_violation": 0.006020485814146125,
            "auditor_fp_violation": 0.0115466052096285,
            "ave_precision_score": 0.8829237392723671,
            "fpr": 0.09989023051591657,
            "logloss": 0.870185563604807,
            "mae": 0.21914481906775468,
            "precision": 0.8096234309623431,
            "recall": 0.7914110429447853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 871,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8729832415640052,
            "auditor_fn_violation": 0.01075268817204301,
            "auditor_fp_violation": 0.011835727461831312,
            "ave_precision_score": 0.8729021399248226,
            "fpr": 0.1074561403508772,
            "logloss": 0.7752450160811046,
            "mae": 0.218541794024818,
            "precision": 0.7932489451476793,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8878779027449812,
            "auditor_fn_violation": 0.00581172176466231,
            "auditor_fp_violation": 0.016330161636865896,
            "ave_precision_score": 0.8880369663023732,
            "fpr": 0.08781558726673985,
            "logloss": 0.7941261348278479,
            "mae": 0.21472263168355984,
            "precision": 0.8297872340425532,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 871,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7547107298881993,
            "auditor_fn_violation": 0.0023344651952461803,
            "auditor_fp_violation": 0.005793987205149332,
            "ave_precision_score": 0.5187586942271263,
            "fpr": 0.4649122807017544,
            "logloss": 16.379084610359456,
            "mae": 0.47478070168902997,
            "precision": 0.5181818181818182,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7719509367008615,
            "auditor_fn_violation": 0.002188655357491599,
            "auditor_fp_violation": 0.006492526831095462,
            "ave_precision_score": 0.5494619687789599,
            "fpr": 0.43578485181119647,
            "logloss": 15.25844310799256,
            "mae": 0.44237102065991885,
            "precision": 0.5488636363636363,
            "recall": 0.9877300613496932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 871,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8315311150502939,
            "auditor_fn_violation": 0.005902188266364841,
            "auditor_fp_violation": 0.020953530358334315,
            "ave_precision_score": 0.8319245361950002,
            "fpr": 0.1425438596491228,
            "logloss": 0.655159438297458,
            "mae": 0.27448783513674785,
            "precision": 0.7368421052631579,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8295940559086995,
            "auditor_fn_violation": 0.007306741731933493,
            "auditor_fp_violation": 0.014244021204759108,
            "ave_precision_score": 0.8299033588631275,
            "fpr": 0.12294182217343579,
            "logloss": 0.6912744989244864,
            "mae": 0.27074970364717754,
            "precision": 0.7709611451942741,
            "recall": 0.7709611451942741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 871,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8424609195697916,
            "auditor_fn_violation": 0.0054942463686096996,
            "auditor_fp_violation": 0.021179206405274934,
            "ave_precision_score": 0.8431974312556415,
            "fpr": 0.11293859649122807,
            "logloss": 0.5967528838659156,
            "mae": 0.2711313271579247,
            "precision": 0.7726269315673289,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8596694490646528,
            "auditor_fn_violation": 0.013390081238397324,
            "auditor_fp_violation": 0.013526097564782206,
            "ave_precision_score": 0.859876580399389,
            "fpr": 0.10098792535675083,
            "logloss": 0.633722535521698,
            "mae": 0.2682598806675724,
            "precision": 0.7969094922737306,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 871,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8378875591653634,
            "auditor_fn_violation": 0.007986700622524052,
            "auditor_fp_violation": 0.007123513481690807,
            "ave_precision_score": 0.8382579424252028,
            "fpr": 0.2565789473684211,
            "logloss": 1.1311508646614121,
            "mae": 0.3062431394303993,
            "precision": 0.6470588235294118,
            "recall": 0.9225806451612903
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8646935585402806,
            "auditor_fn_violation": 0.0029249414674990316,
            "auditor_fp_violation": 0.016439410886427596,
            "ave_precision_score": 0.8648986266297213,
            "fpr": 0.2305159165751921,
            "logloss": 0.9739608394894995,
            "mae": 0.2934926509044826,
            "precision": 0.6798780487804879,
            "recall": 0.9120654396728016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 871,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8561343201743685,
            "auditor_fn_violation": 0.01605121675155631,
            "auditor_fp_violation": 0.0191603869853605,
            "ave_precision_score": 0.8567102378388493,
            "fpr": 0.15021929824561403,
            "logloss": 0.5355637916086678,
            "mae": 0.2751658483539957,
            "precision": 0.7453531598513011,
            "recall": 0.8623655913978494
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8789175716783887,
            "auditor_fn_violation": 0.022113275822204865,
            "auditor_fp_violation": 0.021306204837140595,
            "ave_precision_score": 0.8791006954266015,
            "fpr": 0.12843029637760703,
            "logloss": 0.5223215707893503,
            "mae": 0.26957604816145686,
            "precision": 0.7754318618042226,
            "recall": 0.8261758691206544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 871,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8724902884059027,
            "auditor_fn_violation": 0.00845359366157329,
            "auditor_fp_violation": 0.013192236743985244,
            "ave_precision_score": 0.8718152727121312,
            "fpr": 0.10416666666666667,
            "logloss": 0.9244129669933809,
            "mae": 0.22447655147607498,
            "precision": 0.7956989247311828,
            "recall": 0.7956989247311828
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8785995997499296,
            "auditor_fn_violation": 0.008815230347558472,
            "auditor_fp_violation": 0.008271728895386046,
            "ave_precision_score": 0.8787926227778147,
            "fpr": 0.08781558726673985,
            "logloss": 0.9757245144249779,
            "mae": 0.2192768726568057,
            "precision": 0.8264642082429501,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8206512724227999,
            "auditor_fn_violation": 0.009094982078853049,
            "auditor_fp_violation": 0.020112151183327442,
            "ave_precision_score": 0.8210469150177938,
            "fpr": 0.15460526315789475,
            "logloss": 1.010491813423171,
            "mae": 0.2636189868835618,
            "precision": 0.7262135922330097,
            "recall": 0.8043010752688172
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8297089278475646,
            "auditor_fn_violation": 0.009145212232226438,
            "auditor_fp_violation": 0.016413399160341496,
            "ave_precision_score": 0.8300094519513643,
            "fpr": 0.13611416026344675,
            "logloss": 1.0797093868113603,
            "mae": 0.26405289290751316,
            "precision": 0.7559055118110236,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 871,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.869438390463191,
            "auditor_fn_violation": 0.00955715902659876,
            "auditor_fp_violation": 0.006924820440362656,
            "ave_precision_score": 0.8699047109192053,
            "fpr": 0.09868421052631579,
            "logloss": 0.8844711634693702,
            "mae": 0.2224772194251179,
            "precision": 0.8013245033112583,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8775928718962347,
            "auditor_fn_violation": 0.010624518776418193,
            "auditor_fp_violation": 0.00933820966491695,
            "ave_precision_score": 0.87783880277072,
            "fpr": 0.07683863885839737,
            "logloss": 0.9651653573133213,
            "mae": 0.21881473818339786,
            "precision": 0.8423423423423423,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 871,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8532867826730222,
            "auditor_fn_violation": 0.0038341822297679688,
            "auditor_fp_violation": 0.012316515561835245,
            "ave_precision_score": 0.8536682611396762,
            "fpr": 0.26535087719298245,
            "logloss": 0.8131815618656276,
            "mae": 0.3150198055613018,
            "precision": 0.6456808199121523,
            "recall": 0.9483870967741935
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8766119641181409,
            "auditor_fn_violation": 0.006314551303203968,
            "auditor_fp_violation": 0.02015908771674272,
            "ave_precision_score": 0.8767967465468989,
            "fpr": 0.2524698133918771,
            "logloss": 0.788082131229519,
            "mae": 0.3030754338043132,
            "precision": 0.6637426900584795,
            "recall": 0.9284253578732107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.872894447948424,
            "auditor_fn_violation": 0.00889926428975665,
            "auditor_fp_violation": 0.016601907453196757,
            "ave_precision_score": 0.8718131698190293,
            "fpr": 0.19078947368421054,
            "logloss": 1.0996610919061098,
            "mae": 0.25233858368386525,
            "precision": 0.7030716723549488,
            "recall": 0.886021505376344
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8818925038798936,
            "auditor_fn_violation": 0.011073473721544675,
            "auditor_fp_violation": 0.020367181525431665,
            "ave_precision_score": 0.8811181460980537,
            "fpr": 0.1690450054884742,
            "logloss": 1.029701814654506,
            "mae": 0.23292054777879856,
            "precision": 0.737649063032368,
            "recall": 0.885480572597137
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 871,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8707218878759488,
            "auditor_fn_violation": 0.011778438030560274,
            "auditor_fp_violation": 0.009755583029161269,
            "ave_precision_score": 0.8705775231985557,
            "fpr": 0.10087719298245613,
            "logloss": 0.8348640872386195,
            "mae": 0.22343762514909588,
            "precision": 0.7995642701525054,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8797859464207997,
            "auditor_fn_violation": 0.0038722364017159056,
            "auditor_fp_violation": 0.013442860041306626,
            "ave_precision_score": 0.8799669829220289,
            "fpr": 0.09001097694840834,
            "logloss": 0.8888804597246825,
            "mae": 0.22086442950012475,
            "precision": 0.8236559139784946,
            "recall": 0.7832310838445807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 871,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7618964674602375,
            "auditor_fn_violation": 0.006989247311827964,
            "auditor_fp_violation": 0.009147238902625691,
            "ave_precision_score": 0.7623092809832998,
            "fpr": 0.09868421052631579,
            "logloss": 1.2566897274732824,
            "mae": 0.33799395960938494,
            "precision": 0.7383720930232558,
            "recall": 0.546236559139785
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.748147505074045,
            "auditor_fn_violation": 0.02237142491565259,
            "auditor_fp_violation": 0.011616836870061029,
            "ave_precision_score": 0.7497563025422098,
            "fpr": 0.09659714599341383,
            "logloss": 1.3659926911297622,
            "mae": 0.3472198014877819,
            "precision": 0.7528089887640449,
            "recall": 0.5480572597137015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 871,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6797931511379544,
            "auditor_fn_violation": 0.004767968307866445,
            "auditor_fp_violation": 0.032158836689038024,
            "ave_precision_score": 0.6811760652540451,
            "fpr": 0.19078947368421054,
            "logloss": 1.284005100678312,
            "mae": 0.30696395267203425,
            "precision": 0.6847826086956522,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7314457959416101,
            "auditor_fn_violation": 0.007562646050655587,
            "auditor_fp_violation": 0.016361375708169246,
            "ave_precision_score": 0.730510595812243,
            "fpr": 0.17014270032930845,
            "logloss": 1.0177509802510973,
            "mae": 0.2949460367624809,
            "precision": 0.7161172161172161,
            "recall": 0.7995910020449898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 871,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8689377682643141,
            "auditor_fn_violation": 0.006319562346727035,
            "auditor_fp_violation": 0.017666509674634016,
            "ave_precision_score": 0.8682675555746656,
            "fpr": 0.15570175438596492,
            "logloss": 0.8540631978916186,
            "mae": 0.24483199319830923,
            "precision": 0.7335834896810507,
            "recall": 0.8408602150537634
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8764833097114331,
            "auditor_fn_violation": 0.005519901050330098,
            "auditor_fp_violation": 0.012033024487438941,
            "ave_precision_score": 0.8766428725952171,
            "fpr": 0.12623490669593854,
            "logloss": 0.8432273740625118,
            "mae": 0.2330130317972038,
            "precision": 0.7771317829457365,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 871,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8610798932959453,
            "auditor_fn_violation": 0.004673646481795889,
            "auditor_fp_violation": 0.021002590368538795,
            "ave_precision_score": 0.8601887976603676,
            "fpr": 0.22807017543859648,
            "logloss": 1.14487559811892,
            "mae": 0.2870797516484527,
            "precision": 0.6698412698412698,
            "recall": 0.9075268817204301
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8700162939155777,
            "auditor_fn_violation": 0.0067837092208611425,
            "auditor_fp_violation": 0.021933087435816078,
            "ave_precision_score": 0.8692284648951953,
            "fpr": 0.20417124039517015,
            "logloss": 1.0623089571873627,
            "mae": 0.2668529334165007,
            "precision": 0.7014446227929374,
            "recall": 0.8936605316973415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 871,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8765747638124148,
            "auditor_fn_violation": 0.007439634031314849,
            "auditor_fp_violation": 0.020965795360885442,
            "ave_precision_score": 0.8746154667146958,
            "fpr": 0.18092105263157895,
            "logloss": 1.1398768313786014,
            "mae": 0.24526083436000787,
            "precision": 0.7155172413793104,
            "recall": 0.8924731182795699
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8802138214272099,
            "auditor_fn_violation": 0.008970119803627106,
            "auditor_fp_violation": 0.016803575051633286,
            "ave_precision_score": 0.8783218950801194,
            "fpr": 0.1602634467618002,
            "logloss": 1.1038772410686604,
            "mae": 0.22853453189134265,
            "precision": 0.7474048442906575,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 871,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8285537810880947,
            "auditor_fn_violation": 0.002051499717034527,
            "auditor_fp_violation": 0.004425212920444288,
            "ave_precision_score": 0.7146489745563114,
            "fpr": 0.10307017543859649,
            "logloss": 8.104941845500687,
            "mae": 0.23496226690323502,
            "precision": 0.785876993166287,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8425626114547854,
            "auditor_fn_violation": 0.006974515072539894,
            "auditor_fp_violation": 0.011689669703102161,
            "ave_precision_score": 0.7404502261047258,
            "fpr": 0.08122941822173436,
            "logloss": 8.195015906452172,
            "mae": 0.238408663219213,
            "precision": 0.8238095238095238,
            "recall": 0.7075664621676891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 871,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6673442213208671,
            "auditor_fn_violation": 0.007491511035653654,
            "auditor_fp_violation": 0.03851210801051848,
            "ave_precision_score": 0.662775343008326,
            "fpr": 0.21162280701754385,
            "logloss": 1.750716088241154,
            "mae": 0.30630567384963236,
            "precision": 0.6683848797250859,
            "recall": 0.8365591397849462
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7102269856942346,
            "auditor_fn_violation": 0.011881592622772344,
            "auditor_fp_violation": 0.017490284620306835,
            "ave_precision_score": 0.7059604619255853,
            "fpr": 0.18660812294182216,
            "logloss": 1.412732152519977,
            "mae": 0.29674944350649546,
            "precision": 0.7007042253521126,
            "recall": 0.8139059304703476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 871,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7933894657111986,
            "auditor_fn_violation": 0.00981890209394454,
            "auditor_fp_violation": 0.018586384865968066,
            "ave_precision_score": 0.793759493712671,
            "fpr": 0.14692982456140352,
            "logloss": 0.7534840143995161,
            "mae": 0.30485525437481065,
            "precision": 0.7208333333333333,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7912478837060017,
            "auditor_fn_violation": 0.012624613056956675,
            "auditor_fp_violation": 0.017953293344639763,
            "ave_precision_score": 0.7917346298151315,
            "fpr": 0.13721185510428102,
            "logloss": 0.7896510093424537,
            "mae": 0.29908882201140835,
            "precision": 0.7417355371900827,
            "recall": 0.7341513292433538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 871,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8489309090261232,
            "auditor_fn_violation": 0.007123655913978498,
            "auditor_fp_violation": 0.01704099454452687,
            "ave_precision_score": 0.8491789959023851,
            "fpr": 0.1162280701754386,
            "logloss": 0.8355118673220585,
            "mae": 0.2480563604569433,
            "precision": 0.7720430107526882,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8518329914262059,
            "auditor_fn_violation": 0.008608711072800292,
            "auditor_fp_violation": 0.01019139428054167,
            "ave_precision_score": 0.8521511708151184,
            "fpr": 0.09989023051591657,
            "logloss": 0.925244197518759,
            "mae": 0.24465067667598878,
            "precision": 0.803030303030303,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 871,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8423090654013,
            "auditor_fn_violation": 0.0046359177513676676,
            "auditor_fp_violation": 0.0075920365791436115,
            "ave_precision_score": 0.7790960550380222,
            "fpr": 0.10087719298245613,
            "logloss": 6.1408661116524925,
            "mae": 0.22823499074452622,
            "precision": 0.7927927927927928,
            "recall": 0.7569892473118279
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8646366495129245,
            "auditor_fn_violation": 0.0070575717373882975,
            "auditor_fp_violation": 0.01204863152309061,
            "ave_precision_score": 0.8231174375959904,
            "fpr": 0.07903402854006586,
            "logloss": 6.166195847821075,
            "mae": 0.23652496029884826,
            "precision": 0.8277511961722488,
            "recall": 0.7075664621676891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 871,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7926180682478916,
            "auditor_fn_violation": 0.005168836068666294,
            "auditor_fp_violation": 0.015711468267985397,
            "ave_precision_score": 0.7930232107559678,
            "fpr": 0.11951754385964912,
            "logloss": 0.8616899979081772,
            "mae": 0.2978812020997016,
            "precision": 0.7423167848699763,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7876039963442034,
            "auditor_fn_violation": 0.013755979518675408,
            "auditor_fp_violation": 0.007163629364117347,
            "ave_precision_score": 0.7890510410031073,
            "fpr": 0.10428100987925357,
            "logloss": 0.9410442592007224,
            "mae": 0.2995558787744908,
            "precision": 0.7769953051643192,
            "recall": 0.6768916155419223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8393087168560973,
            "auditor_fn_violation": 0.006703923787964536,
            "auditor_fp_violation": 0.017220063581773228,
            "ave_precision_score": 0.8395598265018048,
            "fpr": 0.11732456140350878,
            "logloss": 0.9150575868070464,
            "mae": 0.25576299324795626,
            "precision": 0.7653508771929824,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8405310171419613,
            "auditor_fn_violation": 0.0036836753247627843,
            "auditor_fp_violation": 0.008500632084943897,
            "ave_precision_score": 0.8409036459977375,
            "fpr": 0.10098792535675083,
            "logloss": 1.0143738942348581,
            "mae": 0.2516263971340468,
            "precision": 0.7995642701525054,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 871,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8700921769646999,
            "auditor_fn_violation": 0.011134691567628752,
            "auditor_fp_violation": 0.015534852231249268,
            "ave_precision_score": 0.8695489142596337,
            "fpr": 0.10855263157894737,
            "logloss": 0.8969534396777276,
            "mae": 0.2247920698180655,
            "precision": 0.7893617021276595,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8764174271567515,
            "auditor_fn_violation": 0.005645608434965509,
            "auditor_fp_violation": 0.00915872875492272,
            "ave_precision_score": 0.8765236131544375,
            "fpr": 0.09769484083424808,
            "logloss": 0.9669601974741927,
            "mae": 0.2229123546102882,
            "precision": 0.8110403397027601,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8394511078139716,
            "auditor_fn_violation": 0.008241369552914548,
            "auditor_fp_violation": 0.01656756544605362,
            "ave_precision_score": 0.8397014935739314,
            "fpr": 0.12390350877192982,
            "logloss": 0.9000655287534438,
            "mae": 0.2557929894433586,
            "precision": 0.7564655172413793,
            "recall": 0.7548387096774194
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8409628989349791,
            "auditor_fn_violation": 0.005373990693163988,
            "auditor_fp_violation": 0.006835881615432233,
            "ave_precision_score": 0.841219852193692,
            "fpr": 0.10537870472008781,
            "logloss": 0.9937350014105134,
            "mae": 0.25120887698499916,
            "precision": 0.7939914163090128,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 871,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7938418559895289,
            "auditor_fn_violation": 0.0037115638558762516,
            "auditor_fp_violation": 0.01766405667412379,
            "ave_precision_score": 0.7942469858259653,
            "fpr": 0.11951754385964912,
            "logloss": 0.8385581517982645,
            "mae": 0.29657918898328967,
            "precision": 0.744131455399061,
            "recall": 0.6817204301075269
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.791111111670757,
            "auditor_fn_violation": 0.013412528985653652,
            "auditor_fp_violation": 0.0042555183876891705,
            "ave_precision_score": 0.7918728008392633,
            "fpr": 0.10428100987925357,
            "logloss": 0.915876198639725,
            "mae": 0.2981599534870166,
            "precision": 0.7790697674418605,
            "recall": 0.6850715746421268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 871,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.843431073380964,
            "auditor_fn_violation": 0.0028367289190718765,
            "auditor_fp_violation": 0.011762137446524594,
            "ave_precision_score": 0.8438280740369596,
            "fpr": 0.10307017543859649,
            "logloss": 0.6363419223823659,
            "mae": 0.25238638677464814,
            "precision": 0.7911111111111111,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8658508794645422,
            "auditor_fn_violation": 0.007549177402301793,
            "auditor_fp_violation": 0.010701224111829612,
            "ave_precision_score": 0.8661050383321358,
            "fpr": 0.0845225027442371,
            "logloss": 0.6406026481914602,
            "mae": 0.2530394488786705,
            "precision": 0.8188235294117647,
            "recall": 0.7116564417177914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 871,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8418208053107198,
            "auditor_fn_violation": 0.003742218449349187,
            "auditor_fp_violation": 0.007376172534243892,
            "ave_precision_score": 0.8419520882116445,
            "fpr": 0.09978070175438597,
            "logloss": 0.8913148194422061,
            "mae": 0.244559859618198,
            "precision": 0.7927107061503417,
            "recall": 0.7483870967741936
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8623750739157741,
            "auditor_fn_violation": 0.007847732440810901,
            "auditor_fp_violation": 0.009213353379703575,
            "ave_precision_score": 0.8625990209138346,
            "fpr": 0.07574094401756312,
            "logloss": 0.8952671631662407,
            "mae": 0.24410478216707385,
            "precision": 0.8325242718446602,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 871,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6760645938949205,
            "auditor_fn_violation": 0.004258630447085455,
            "auditor_fp_violation": 0.03880401507123513,
            "ave_precision_score": 0.6715104120012598,
            "fpr": 0.2149122807017544,
            "logloss": 1.7442081667866665,
            "mae": 0.30462999332978125,
            "precision": 0.6694772344013491,
            "recall": 0.853763440860215
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7211883784826605,
            "auditor_fn_violation": 0.011973628386523272,
            "auditor_fp_violation": 0.017308202537703998,
            "ave_precision_score": 0.7176564094099425,
            "fpr": 0.18990120746432493,
            "logloss": 1.404599475221852,
            "mae": 0.29250284347826366,
            "precision": 0.7022375215146299,
            "recall": 0.8343558282208589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 871,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8603444656699462,
            "auditor_fn_violation": 0.007279286926994911,
            "auditor_fp_violation": 0.023423701872129995,
            "ave_precision_score": 0.8596892163629672,
            "fpr": 0.2050438596491228,
            "logloss": 0.9939914738003139,
            "mae": 0.2664377343104554,
            "precision": 0.684654300168634,
            "recall": 0.8731182795698925
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8695309264301445,
            "auditor_fn_violation": 0.006592903369182388,
            "auditor_fp_violation": 0.022666618111444645,
            "ave_precision_score": 0.8695729008622728,
            "fpr": 0.1734357848518112,
            "logloss": 0.938783601294444,
            "mae": 0.25203677959552756,
            "precision": 0.7280550774526678,
            "recall": 0.8650306748466258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 871,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.8247490444944743,
            "auditor_fn_violation": 0.008776645915864932,
            "auditor_fp_violation": 0.01732308960320264,
            "ave_precision_score": 0.8252199008461727,
            "fpr": 0.3826754385964912,
            "logloss": 0.9626890320874807,
            "mae": 0.38556828183606595,
            "precision": 0.562107904642409,
            "recall": 0.9634408602150538
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.8517503189252507,
            "auditor_fn_violation": 0.015976061722325855,
            "auditor_fp_violation": 0.026094963609595206,
            "ave_precision_score": 0.8520523441439369,
            "fpr": 0.3633369923161361,
            "logloss": 0.8976563461474693,
            "mae": 0.3774316051728772,
            "precision": 0.5804816223067174,
            "recall": 0.9366053169734151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 871,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.7636252628544214,
            "auditor_fn_violation": 0.004845783814374646,
            "auditor_fp_violation": 0.0024063935005298556,
            "ave_precision_score": 0.5706239925783244,
            "fpr": 0.48355263157894735,
            "logloss": 13.765104160964212,
            "mae": 0.49344863061645383,
            "precision": 0.5083612040133779,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7858805696436708,
            "auditor_fn_violation": 0.001436655824404742,
            "auditor_fp_violation": 0.001989897045588156,
            "ave_precision_score": 0.6132986459052059,
            "fpr": 0.45993413830954993,
            "logloss": 12.558246166563292,
            "mae": 0.468076816809198,
            "precision": 0.5349611542730299,
            "recall": 0.9856850715746421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 871,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.8502566997800699,
            "auditor_fn_violation": 0.0037492925863044707,
            "auditor_fp_violation": 0.012466148592958921,
            "ave_precision_score": 0.8506260724779728,
            "fpr": 0.38596491228070173,
            "logloss": 0.9929766638221743,
            "mae": 0.379705565720143,
            "precision": 0.5659679408138101,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8775709658805713,
            "auditor_fn_violation": 0.0026869953465819938,
            "auditor_fp_violation": 0.013164534572185155,
            "ave_precision_score": 0.8777559304875139,
            "fpr": 0.3611416026344676,
            "logloss": 0.8775585297084733,
            "mae": 0.3608366215129257,
            "precision": 0.5918114143920595,
            "recall": 0.9754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 871,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8737263244822064,
            "auditor_fn_violation": 0.006225240520656475,
            "auditor_fp_violation": 0.012157070528670674,
            "ave_precision_score": 0.8730715299494607,
            "fpr": 0.09868421052631579,
            "logloss": 1.001391324547229,
            "mae": 0.22014699185549896,
            "precision": 0.7991071428571429,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8808876477235277,
            "auditor_fn_violation": 0.008687278188197428,
            "auditor_fp_violation": 0.010331857601406718,
            "ave_precision_score": 0.8808562741427803,
            "fpr": 0.08232711306256861,
            "logloss": 1.0763631103385085,
            "mae": 0.21443874538292942,
            "precision": 0.8337028824833703,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 871,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6787996207241787,
            "auditor_fn_violation": 0.004767968307866445,
            "auditor_fp_violation": 0.03286039483496213,
            "ave_precision_score": 0.6801732589715698,
            "fpr": 0.19188596491228072,
            "logloss": 1.289253673041166,
            "mae": 0.30708211698542476,
            "precision": 0.6835443037974683,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7305631109674513,
            "auditor_fn_violation": 0.007562646050655587,
            "auditor_fp_violation": 0.016361375708169246,
            "ave_precision_score": 0.7295616740888196,
            "fpr": 0.17014270032930845,
            "logloss": 1.0227179083181943,
            "mae": 0.2950631040061181,
            "precision": 0.7161172161172161,
            "recall": 0.7995910020449898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 871,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8425235623468789,
            "auditor_fn_violation": 0.0023344651952461833,
            "auditor_fp_violation": 0.00924535892303466,
            "ave_precision_score": 0.8429454971360635,
            "fpr": 0.10416666666666667,
            "logloss": 0.6329980619417922,
            "mae": 0.2533758231565068,
            "precision": 0.7907488986784141,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8656258990328599,
            "auditor_fn_violation": 0.006229249863629947,
            "auditor_fp_violation": 0.012909619656541171,
            "ave_precision_score": 0.8658840516465685,
            "fpr": 0.0867178924259056,
            "logloss": 0.6344714288540036,
            "mae": 0.2532510242921296,
            "precision": 0.8162790697674419,
            "recall": 0.7177914110429447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8288282007941743,
            "auditor_fn_violation": 0.003629032258064522,
            "auditor_fp_violation": 0.014936320106754584,
            "ave_precision_score": 0.7916893096197168,
            "fpr": 0.1787280701754386,
            "logloss": 3.247533581674633,
            "mae": 0.24957064782770466,
            "precision": 0.7115044247787611,
            "recall": 0.864516129032258
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8305585319200309,
            "auditor_fn_violation": 0.008622179721154087,
            "auditor_fp_violation": 0.007309295030199618,
            "ave_precision_score": 0.792119304146812,
            "fpr": 0.1778265642151482,
            "logloss": 3.5375084045891776,
            "mae": 0.260347473775284,
            "precision": 0.7177700348432056,
            "recall": 0.8425357873210634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 871,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8724744117029719,
            "auditor_fn_violation": 0.010158460667798531,
            "auditor_fp_violation": 0.010152969111817576,
            "ave_precision_score": 0.8718635064482495,
            "fpr": 0.10635964912280702,
            "logloss": 0.8635025623700071,
            "mae": 0.22222687049007334,
            "precision": 0.7918454935622318,
            "recall": 0.7935483870967742
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8803254212920603,
            "auditor_fn_violation": 0.005542348797586419,
            "auditor_fp_violation": 0.011195446907465888,
            "ave_precision_score": 0.8804815063878646,
            "fpr": 0.09220636663007684,
            "logloss": 0.9275932495386723,
            "mae": 0.2193190702817187,
            "precision": 0.8197424892703863,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 871,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8746239878848501,
            "auditor_fn_violation": 0.0053268251273344645,
            "auditor_fp_violation": 0.010040131088347264,
            "ave_precision_score": 0.874198562056775,
            "fpr": 0.10416666666666667,
            "logloss": 0.8591512069070351,
            "mae": 0.22041977893475345,
            "precision": 0.7970085470085471,
            "recall": 0.8021505376344086
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8852100742228066,
            "auditor_fn_violation": 0.003930600544582347,
            "auditor_fp_violation": 0.011957590481789194,
            "ave_precision_score": 0.8853383431950311,
            "fpr": 0.09110867178924259,
            "logloss": 0.9040796675549958,
            "mae": 0.21715740402331452,
            "precision": 0.821505376344086,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8663717831694357,
            "auditor_fn_violation": 0.007196755329183175,
            "auditor_fp_violation": 0.02475813414969191,
            "ave_precision_score": 0.8645849163834465,
            "fpr": 0.19846491228070176,
            "logloss": 1.0921266010445816,
            "mae": 0.2675550886648575,
            "precision": 0.6932203389830508,
            "recall": 0.8795698924731182
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8699569247494807,
            "auditor_fn_violation": 0.009237247995977364,
            "auditor_fp_violation": 0.027455376883899263,
            "ave_precision_score": 0.8697000077726448,
            "fpr": 0.17233809001097694,
            "logloss": 1.0205865133933492,
            "mae": 0.25306506051928535,
            "precision": 0.729776247848537,
            "recall": 0.8670756646216768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 871,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.8499557990532356,
            "auditor_fn_violation": 0.0029711375212224107,
            "auditor_fp_violation": 0.012466148592958921,
            "ave_precision_score": 0.8503255607706955,
            "fpr": 0.38596491228070173,
            "logloss": 1.0002919447454532,
            "mae": 0.3805592021202309,
            "precision": 0.5659679408138101,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.8762925257326983,
            "auditor_fn_violation": 0.0018339809508416784,
            "auditor_fp_violation": 0.01122405980616063,
            "ave_precision_score": 0.8764787086434966,
            "fpr": 0.3633369923161361,
            "logloss": 0.9582185890510113,
            "mae": 0.3634788424152836,
            "precision": 0.5893300248138957,
            "recall": 0.9713701431492843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 871,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8353433260154008,
            "auditor_fn_violation": 0.0030230145255612157,
            "auditor_fp_violation": 0.010346756152125285,
            "ave_precision_score": 0.7785235330886466,
            "fpr": 0.11842105263157894,
            "logloss": 5.280494910689721,
            "mae": 0.23600717594040996,
            "precision": 0.7682403433476395,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8624930499021306,
            "auditor_fn_violation": 0.005017071511788434,
            "auditor_fp_violation": 0.011975798690049479,
            "ave_precision_score": 0.825753218356053,
            "fpr": 0.09110867178924259,
            "logloss": 5.175563286672273,
            "mae": 0.24317201002323122,
            "precision": 0.8078703703703703,
            "recall": 0.7137014314928425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 871,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8631706498833823,
            "auditor_fn_violation": 0.009323712507074138,
            "auditor_fp_violation": 0.01755121865065349,
            "ave_precision_score": 0.8625893367820548,
            "fpr": 0.1611842105263158,
            "logloss": 1.0062814684270738,
            "mae": 0.24485536610132336,
            "precision": 0.7272727272727273,
            "recall": 0.843010752688172
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.867059926045427,
            "auditor_fn_violation": 0.009044197369572977,
            "auditor_fp_violation": 0.01158302162614907,
            "ave_precision_score": 0.8669890015780604,
            "fpr": 0.141602634467618,
            "logloss": 1.0165494298875588,
            "mae": 0.23838540319775878,
            "precision": 0.7579737335834896,
            "recall": 0.8261758691206544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 871,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8738959922236856,
            "auditor_fn_violation": 0.006720430107526883,
            "auditor_fp_violation": 0.010967365281211984,
            "ave_precision_score": 0.8731313504964926,
            "fpr": 0.10307017543859649,
            "logloss": 1.0241071430199922,
            "mae": 0.22030124218548164,
            "precision": 0.7929515418502202,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8814080912188804,
            "auditor_fn_violation": 0.006417810940583059,
            "auditor_fp_violation": 0.010331857601406718,
            "ave_precision_score": 0.8813308955916398,
            "fpr": 0.08232711306256861,
            "logloss": 1.0728400222958743,
            "mae": 0.21338478318182552,
            "precision": 0.834070796460177,
            "recall": 0.7709611451942741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 871,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.836900791437982,
            "auditor_fn_violation": 0.008055083946425205,
            "auditor_fp_violation": 0.006417049334746268,
            "ave_precision_score": 0.8371348286242234,
            "fpr": 0.13815789473684212,
            "logloss": 1.2406524909379082,
            "mae": 0.25705039720639766,
            "precision": 0.7464788732394366,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8547121426579274,
            "auditor_fn_violation": 0.006671470484579519,
            "auditor_fp_violation": 0.00994168171011492,
            "ave_precision_score": 0.8548834007436802,
            "fpr": 0.11964873765093303,
            "logloss": 1.1575902120117345,
            "mae": 0.25725842542717847,
            "precision": 0.7724425887265136,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 871,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6641578983825662,
            "auditor_fn_violation": 0.008128183361629883,
            "auditor_fp_violation": 0.0435505710585188,
            "ave_precision_score": 0.6589033579298798,
            "fpr": 0.20065789473684212,
            "logloss": 1.741651391442922,
            "mae": 0.30621391262897735,
            "precision": 0.6761061946902654,
            "recall": 0.821505376344086
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7031421228279692,
            "auditor_fn_violation": 0.010198011578548041,
            "auditor_fp_violation": 0.025111720363539886,
            "ave_precision_score": 0.697877768874136,
            "fpr": 0.1712403951701427,
            "logloss": 1.4592587124063205,
            "mae": 0.2980754136719655,
            "precision": 0.7148080438756855,
            "recall": 0.7995910020449898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 871,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8512830149599113,
            "auditor_fn_violation": 0.006932654216185626,
            "auditor_fp_violation": 0.017735193688920292,
            "ave_precision_score": 0.8516684402193542,
            "fpr": 0.3256578947368421,
            "logloss": 0.9680891680079335,
            "mae": 0.34532931410674855,
            "precision": 0.6013422818791946,
            "recall": 0.9634408602150538
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.8780191676371598,
            "auditor_fn_violation": 0.005753357621795865,
            "auditor_fp_violation": 0.018301850474193776,
            "ave_precision_score": 0.8782037741722497,
            "fpr": 0.31174533479692645,
            "logloss": 0.8874510747351,
            "mae": 0.3312719036959399,
            "precision": 0.6203208556149733,
            "recall": 0.9488752556237219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 871,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6608587836757052,
            "auditor_fn_violation": 0.011247877758913413,
            "auditor_fp_violation": 0.046849856744770206,
            "ave_precision_score": 0.6529159722178317,
            "fpr": 0.19298245614035087,
            "logloss": 1.7780326667649113,
            "mae": 0.32326348227032115,
            "precision": 0.6890459363957597,
            "recall": 0.8387096774193549
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.6969182704392789,
            "auditor_fn_violation": 0.014061268881361416,
            "auditor_fp_violation": 0.04348380249816618,
            "ave_precision_score": 0.6886291308973793,
            "fpr": 0.17453347969264543,
            "logloss": 1.457592390608163,
            "mae": 0.3130888620966025,
            "precision": 0.7160714285714286,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 871,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8477779677359096,
            "auditor_fn_violation": 0.011153555932842861,
            "auditor_fp_violation": 0.008119431688841793,
            "ave_precision_score": 0.8482609618299638,
            "fpr": 0.09429824561403509,
            "logloss": 0.596810378669624,
            "mae": 0.2768103813093483,
            "precision": 0.7957244655581948,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8718763215710073,
            "auditor_fn_violation": 0.006592903369182381,
            "auditor_fp_violation": 0.009424048361001138,
            "ave_precision_score": 0.8720810549516259,
            "fpr": 0.06476399560922064,
            "logloss": 0.6096075423042918,
            "mae": 0.2717032185592101,
            "precision": 0.8525,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 871,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8405779931928006,
            "auditor_fn_violation": 0.004527447651386531,
            "auditor_fp_violation": 0.007778464617920643,
            "ave_precision_score": 0.8401148777806186,
            "fpr": 0.10197368421052631,
            "logloss": 0.9366680122241562,
            "mae": 0.2448247505657778,
            "precision": 0.7900677200902935,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8618667934119302,
            "auditor_fn_violation": 0.007847732440810901,
            "auditor_fp_violation": 0.009114508820576323,
            "ave_precision_score": 0.8620361512591699,
            "fpr": 0.07793633369923161,
            "logloss": 0.9160673271554339,
            "mae": 0.2443831369143493,
            "precision": 0.8285024154589372,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8729954607628827,
            "auditor_fn_violation": 0.007611771363893606,
            "auditor_fp_violation": 0.014936320106754577,
            "ave_precision_score": 0.8721668362048924,
            "fpr": 0.19298245614035087,
            "logloss": 1.078759410692229,
            "mae": 0.25279830280989196,
            "precision": 0.7016949152542373,
            "recall": 0.8903225806451613
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8817960642182561,
            "auditor_fn_violation": 0.00880176169920468,
            "auditor_fp_violation": 0.015024372987342704,
            "ave_precision_score": 0.8809821622040054,
            "fpr": 0.16794731064763996,
            "logloss": 1.013427830074643,
            "mae": 0.23366968133238136,
            "precision": 0.7393526405451448,
            "recall": 0.8875255623721882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 871,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.8494198009128958,
            "auditor_fn_violation": 0.0071590265987549525,
            "auditor_fp_violation": 0.028589720946661956,
            "ave_precision_score": 0.849622047886982,
            "fpr": 0.3026315789473684,
            "logloss": 1.174170419625219,
            "mae": 0.32606287526834876,
            "precision": 0.6182572614107884,
            "recall": 0.9612903225806452
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8493822123125779,
            "auditor_fn_violation": 0.006067626083384402,
            "auditor_fp_violation": 0.032337777870263915,
            "ave_precision_score": 0.8497050589480584,
            "fpr": 0.25466520307354557,
            "logloss": 1.0632360559563339,
            "mae": 0.2973397457018068,
            "precision": 0.6657060518731989,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 871,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.8143219061955528,
            "auditor_fn_violation": 0.0006932654216185626,
            "auditor_fp_violation": 0.005224891086777359,
            "ave_precision_score": 0.7888410348987844,
            "fpr": 0.45723684210526316,
            "logloss": 4.788905099815427,
            "mae": 0.4575946735754271,
            "precision": 0.5255972696245734,
            "recall": 0.9935483870967742
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.8458012932561313,
            "auditor_fn_violation": 0.0005409907088774107,
            "auditor_fp_violation": 0.0024190905260091365,
            "ave_precision_score": 0.8289818070614862,
            "fpr": 0.433589462129528,
            "logloss": 4.2271075545847125,
            "mae": 0.4312447073485914,
            "precision": 0.5526613816534541,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 871,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8715545589457507,
            "auditor_fn_violation": 0.009182229767968309,
            "auditor_fp_violation": 0.0122821735546921,
            "ave_precision_score": 0.8709066027328882,
            "fpr": 0.1118421052631579,
            "logloss": 0.8799218441271014,
            "mae": 0.22793719434874346,
            "precision": 0.7825159914712153,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.879377487432577,
            "auditor_fn_violation": 0.003872236401715904,
            "auditor_fp_violation": 0.011921174065268622,
            "ave_precision_score": 0.8795724318672797,
            "fpr": 0.09110867178924259,
            "logloss": 0.9062716826678575,
            "mae": 0.21963698674066878,
            "precision": 0.8211206896551724,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 871,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.874763994928032,
            "auditor_fn_violation": 0.004369458592718356,
            "auditor_fp_violation": 0.010685270222536207,
            "ave_precision_score": 0.8741300917249366,
            "fpr": 0.10526315789473684,
            "logloss": 0.9558837721481993,
            "mae": 0.21873794171935837,
            "precision": 0.7931034482758621,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8843584512634767,
            "auditor_fn_violation": 0.006222515539453038,
            "auditor_fp_violation": 0.007936177628875097,
            "ave_precision_score": 0.8843808173812024,
            "fpr": 0.0845225027442371,
            "logloss": 1.0051912571900539,
            "mae": 0.21073884679746055,
            "precision": 0.8329718004338394,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 871,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6544212089802306,
            "auditor_fn_violation": 0.011313903037162804,
            "auditor_fp_violation": 0.0365815966089721,
            "ave_precision_score": 0.6374045143402695,
            "fpr": 0.1787280701754386,
            "logloss": 2.5398046287324103,
            "mae": 0.3255851812615344,
            "precision": 0.674,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6643345450818275,
            "auditor_fn_violation": 0.011870368749144187,
            "auditor_fp_violation": 0.031164649023779925,
            "ave_precision_score": 0.6461545692935203,
            "fpr": 0.16355653128430298,
            "logloss": 2.734770863283196,
            "mae": 0.3235921829384688,
            "precision": 0.7061143984220908,
            "recall": 0.7321063394683026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 871,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.870190118599327,
            "auditor_fn_violation": 0.012167515563101302,
            "auditor_fp_violation": 0.01686683150830096,
            "ave_precision_score": 0.8695249984201222,
            "fpr": 0.17105263157894737,
            "logloss": 0.9943026243926218,
            "mae": 0.246629378540802,
            "precision": 0.7199281867145422,
            "recall": 0.8623655913978494
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8777523622139443,
            "auditor_fn_violation": 0.011048781199562718,
            "auditor_fp_violation": 0.015601833306454555,
            "ave_precision_score": 0.8777404525075239,
            "fpr": 0.15148188803512624,
            "logloss": 0.9688696182422343,
            "mae": 0.23327358174134435,
            "precision": 0.7522441651705566,
            "recall": 0.8568507157464212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 871,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6797192852615644,
            "auditor_fn_violation": 0.0035299943406904306,
            "auditor_fp_violation": 0.009117802896503002,
            "ave_precision_score": 0.6818559667066687,
            "fpr": 0.08881578947368421,
            "logloss": 6.068237914091658,
            "mae": 0.38625391658641783,
            "precision": 0.7157894736842105,
            "recall": 0.43870967741935485
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6884520197878874,
            "auditor_fn_violation": 0.010229438424706893,
            "auditor_fp_violation": 0.003157823546854922,
            "ave_precision_score": 0.6914883684001601,
            "fpr": 0.07574094401756312,
            "logloss": 6.826001513747156,
            "mae": 0.39224804589686996,
            "precision": 0.7517985611510791,
            "recall": 0.4274028629856851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 871,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8760094430782854,
            "auditor_fn_violation": 0.011229013393699304,
            "auditor_fp_violation": 0.015422014207778955,
            "ave_precision_score": 0.8751771546596008,
            "fpr": 0.14912280701754385,
            "logloss": 0.9667407939471035,
            "mae": 0.23181284245886588,
            "precision": 0.7433962264150943,
            "recall": 0.8473118279569892
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8838235056582064,
            "auditor_fn_violation": 0.007737738479254918,
            "auditor_fp_violation": 0.012228112433084835,
            "ave_precision_score": 0.8838338414098518,
            "fpr": 0.12403951701427003,
            "logloss": 0.9590613472075425,
            "mae": 0.22070118943681394,
            "precision": 0.783109404990403,
            "recall": 0.8343558282208589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 871,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8312856353618631,
            "auditor_fn_violation": 0.004338803999245429,
            "auditor_fp_violation": 0.020953530358334315,
            "ave_precision_score": 0.8316790041079362,
            "fpr": 0.1425438596491228,
            "logloss": 0.6524641746220711,
            "mae": 0.27503988934421475,
            "precision": 0.7368421052631579,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8291492905338913,
            "auditor_fn_violation": 0.007306741731933493,
            "auditor_fp_violation": 0.008443406287554436,
            "ave_precision_score": 0.8294908451297537,
            "fpr": 0.12294182217343579,
            "logloss": 0.6868558262480139,
            "mae": 0.27120597726576917,
            "precision": 0.7709611451942741,
            "recall": 0.7709611451942741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 871,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8698858704435996,
            "auditor_fn_violation": 0.006366723259762311,
            "auditor_fp_violation": 0.015593724243494655,
            "ave_precision_score": 0.8691709799904904,
            "fpr": 0.16447368421052633,
            "logloss": 0.8749751701348092,
            "mae": 0.2474010254183688,
            "precision": 0.7237569060773481,
            "recall": 0.8451612903225807
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8778548687111163,
            "auditor_fn_violation": 0.005989058967987268,
            "auditor_fp_violation": 0.011627241560495471,
            "ave_precision_score": 0.8780169026072446,
            "fpr": 0.13611416026344675,
            "logloss": 0.8543215690106889,
            "mae": 0.23382846109761468,
            "precision": 0.7664783427495292,
            "recall": 0.8323108384458078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 871,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6600063342735376,
            "auditor_fn_violation": 0.004765610262214675,
            "auditor_fp_violation": 0.04137966560697045,
            "ave_precision_score": 0.6371818151016334,
            "fpr": 0.18859649122807018,
            "logloss": 2.8875704658466588,
            "mae": 0.3056230002842638,
            "precision": 0.6861313868613139,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6778464279787649,
            "auditor_fn_violation": 0.003865502077539013,
            "auditor_fp_violation": 0.02971059353556584,
            "ave_precision_score": 0.6545607089093151,
            "fpr": 0.16794731064763996,
            "logloss": 2.8616478452997294,
            "mae": 0.30261310618999043,
            "precision": 0.7166666666666667,
            "recall": 0.7914110429447853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 871,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8326450692016766,
            "auditor_fn_violation": 0.008413506885493307,
            "auditor_fp_violation": 0.010847168256211001,
            "ave_precision_score": 0.8329718096087172,
            "fpr": 0.12280701754385964,
            "logloss": 0.639564377571278,
            "mae": 0.2739147209608471,
            "precision": 0.7622080679405521,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.837424172518609,
            "auditor_fn_violation": 0.013232947007603052,
            "auditor_fp_violation": 0.013161933399576529,
            "ave_precision_score": 0.8377235757688173,
            "fpr": 0.1163556531284303,
            "logloss": 0.6723648810296442,
            "mae": 0.26887944268580793,
            "precision": 0.7768421052631579,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 871,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.8345189153643269,
            "auditor_fn_violation": 0.0031055461233729484,
            "auditor_fp_violation": 0.021220907413948744,
            "ave_precision_score": 0.8352769576184313,
            "fpr": 0.3706140350877193,
            "logloss": 1.0170712792448438,
            "mae": 0.37009063169458195,
            "precision": 0.5743073047858942,
            "recall": 0.9806451612903225
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8505465024474754,
            "auditor_fn_violation": 0.003919376670954187,
            "auditor_fp_violation": 0.01616368658991473,
            "ave_precision_score": 0.8507918726200778,
            "fpr": 0.34577387486278816,
            "logloss": 1.01126250204817,
            "mae": 0.3565380847578384,
            "precision": 0.5992366412213741,
            "recall": 0.9631901840490797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 871,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8377261018809753,
            "auditor_fn_violation": 0.004289285040558388,
            "auditor_fp_violation": 0.008982887868440679,
            "ave_precision_score": 0.7751212275276623,
            "fpr": 0.10964912280701754,
            "logloss": 6.00812116368815,
            "mae": 0.23510153924672134,
            "precision": 0.7787610619469026,
            "recall": 0.7569892473118279
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8616130469714222,
            "auditor_fn_violation": 0.006429034814211222,
            "auditor_fp_violation": 0.006921720311516433,
            "ave_precision_score": 0.8188766273246775,
            "fpr": 0.09330406147091108,
            "logloss": 6.076768864912012,
            "mae": 0.24496912334758467,
            "precision": 0.804147465437788,
            "recall": 0.7137014314928425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 871,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8367171718822761,
            "auditor_fn_violation": 0.00014148273910583175,
            "auditor_fp_violation": 0.013783409866949255,
            "ave_precision_score": 0.8371373566576904,
            "fpr": 0.11842105263157894,
            "logloss": 0.5805880861061498,
            "mae": 0.27148112702866856,
            "precision": 0.7692307692307693,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8624552860911747,
            "auditor_fn_violation": 0.007647947490229621,
            "auditor_fp_violation": 0.009907866466202965,
            "ave_precision_score": 0.8627065856103063,
            "fpr": 0.09549945115257959,
            "logloss": 0.5930592695838003,
            "mae": 0.2704056488761928,
            "precision": 0.8022727272727272,
            "recall": 0.721881390593047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 871,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8753986811856912,
            "auditor_fn_violation": 0.011085172608941717,
            "auditor_fp_violation": 0.017175909572589198,
            "ave_precision_score": 0.874723419777562,
            "fpr": 0.14144736842105263,
            "logloss": 0.8900597809743298,
            "mae": 0.2287373428255367,
            "precision": 0.75,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8835568112117836,
            "auditor_fn_violation": 0.006599637693359282,
            "auditor_fp_violation": 0.01428303879388829,
            "ave_precision_score": 0.883632717383623,
            "fpr": 0.11306256860592755,
            "logloss": 0.900087470018289,
            "mae": 0.21654779017248557,
            "precision": 0.7964426877470355,
            "recall": 0.8241308793456033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8302799427971993,
            "auditor_fn_violation": 0.010016977928692702,
            "auditor_fp_violation": 0.023806369951724964,
            "ave_precision_score": 0.8306716718213625,
            "fpr": 0.16666666666666666,
            "logloss": 0.714262164352906,
            "mae": 0.272525805631062,
            "precision": 0.7148217636022514,
            "recall": 0.8193548387096774
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8246274233828914,
            "auditor_fn_violation": 0.011412434705115168,
            "auditor_fp_violation": 0.016507041374251515,
            "ave_precision_score": 0.8249735803709489,
            "fpr": 0.15148188803512624,
            "logloss": 0.7609461739114108,
            "mae": 0.27114286143186295,
            "precision": 0.7406015037593985,
            "recall": 0.8057259713701431
        }
    }
]