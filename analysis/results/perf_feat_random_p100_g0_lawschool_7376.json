[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8448689023587022,
            "auditor_fn_violation": 0.02626018647023238,
            "auditor_fp_violation": 0.028231377967592012,
            "ave_precision_score": 0.8452019050166015,
            "fpr": 0.12390350877192982,
            "logloss": 0.8198119022197045,
            "mae": 0.2647470385951819,
            "precision": 0.7717171717171717,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8305169722576893,
            "auditor_fn_violation": 0.016310650021072886,
            "auditor_fp_violation": 0.02416392242956458,
            "ave_precision_score": 0.8309830802841475,
            "fpr": 0.1350164654226125,
            "logloss": 0.7910828587014265,
            "mae": 0.2672036570963912,
            "precision": 0.7415966386554622,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8473486490676643,
            "auditor_fn_violation": 0.009078858403615532,
            "auditor_fp_violation": 0.004061466314952062,
            "ave_precision_score": 0.8391583106141738,
            "fpr": 0.07456140350877193,
            "logloss": 0.5191094976891031,
            "mae": 0.3274635528459361,
            "precision": 0.8278481012658228,
            "recall": 0.6632860040567952
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8418115981435871,
            "auditor_fn_violation": 0.01059120748813609,
            "auditor_fp_violation": 0.009354799365776312,
            "ave_precision_score": 0.8299168212455136,
            "fpr": 0.06037321624588365,
            "logloss": 0.4958294318956627,
            "mae": 0.31967359804982803,
            "precision": 0.8467966573816156,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.769843706617014,
            "auditor_fn_violation": 0.02189423863919434,
            "auditor_fp_violation": 0.021887953774651425,
            "ave_precision_score": 0.7677689750405854,
            "fpr": 0.14364035087719298,
            "logloss": 1.243579112881978,
            "mae": 0.3170568889870792,
            "precision": 0.7230443974630021,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7410457532968309,
            "auditor_fn_violation": 0.008443440142295545,
            "auditor_fp_violation": 0.028391267227710706,
            "ave_precision_score": 0.7396450881098403,
            "fpr": 0.16355653128430298,
            "logloss": 1.249301051878462,
            "mae": 0.3228223551224179,
            "precision": 0.6869747899159664,
            "recall": 0.7093275488069414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8282455117579667,
            "auditor_fn_violation": 0.011856784456069181,
            "auditor_fp_violation": 0.011367918603190558,
            "ave_precision_score": 0.822698244293298,
            "fpr": 0.09758771929824561,
            "logloss": 3.577888330787857,
            "mae": 0.3105027594424307,
            "precision": 0.7870813397129187,
            "recall": 0.6673427991886409
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8219535038646552,
            "auditor_fn_violation": 0.0016786873379352422,
            "auditor_fp_violation": 0.011179412123429688,
            "ave_precision_score": 0.8160103364538215,
            "fpr": 0.07793633369923161,
            "logloss": 3.3330226318163145,
            "mae": 0.2805947131891094,
            "precision": 0.8121693121693122,
            "recall": 0.665943600867679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8306921430310203,
            "auditor_fn_violation": 0.020826660972919117,
            "auditor_fp_violation": 0.014196813633128164,
            "ave_precision_score": 0.8310640900646914,
            "fpr": 0.1074561403508772,
            "logloss": 0.720706404081717,
            "mae": 0.28319403691221195,
            "precision": 0.7887931034482759,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8168531109681163,
            "auditor_fn_violation": 0.0019572780025287483,
            "auditor_fp_violation": 0.01516038541285523,
            "ave_precision_score": 0.8171803006794551,
            "fpr": 0.12623490669593854,
            "logloss": 0.7304829903509854,
            "mae": 0.2833517504726008,
            "precision": 0.745575221238938,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7234686074654723,
            "auditor_fn_violation": 0.010402209885769193,
            "auditor_fp_violation": 0.012644977599129104,
            "ave_precision_score": 0.6476713559124165,
            "fpr": 0.3717105263157895,
            "logloss": 6.734597122574191,
            "mae": 0.4480378837909643,
            "precision": 0.5521796565389696,
            "recall": 0.847870182555781
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6910897350243879,
            "auditor_fn_violation": 0.00747432560819676,
            "auditor_fp_violation": 0.0030735455543359144,
            "ave_precision_score": 0.6046105670812522,
            "fpr": 0.4061470911086718,
            "logloss": 7.2609591919528045,
            "mae": 0.4770671351059132,
            "precision": 0.5112285336856011,
            "recall": 0.8394793926247288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8281887100518349,
            "auditor_fn_violation": 0.02060647307924987,
            "auditor_fp_violation": 0.006149771804212201,
            "ave_precision_score": 0.8284260409296111,
            "fpr": 0.03728070175438596,
            "logloss": 0.8339590750269681,
            "mae": 0.3865862284214704,
            "precision": 0.8629032258064516,
            "recall": 0.4340770791075051
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8131507401047561,
            "auditor_fn_violation": 0.023182553081046064,
            "auditor_fp_violation": 0.0029296255640931823,
            "ave_precision_score": 0.8135878208806339,
            "fpr": 0.018660812294182216,
            "logloss": 1.0240422062229915,
            "mae": 0.3872876974528395,
            "precision": 0.9178743961352657,
            "recall": 0.4121475054229935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7826862647313431,
            "auditor_fn_violation": 0.0020951211700651223,
            "auditor_fp_violation": 0.0075707616296110175,
            "ave_precision_score": 0.7551034166747629,
            "fpr": 0.4331140350877193,
            "logloss": 1.8476479297757527,
            "mae": 0.3976224266286743,
            "precision": 0.5526613816534541,
            "recall": 0.9898580121703854
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7452476824115236,
            "auditor_fn_violation": 0.0007595762564558029,
            "auditor_fp_violation": 0.005829979265764136,
            "ave_precision_score": 0.7025955078685948,
            "fpr": 0.47200878155872666,
            "logloss": 2.5869757355662806,
            "mae": 0.41812540751060984,
            "precision": 0.5152198421645998,
            "recall": 0.9913232104121475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8558591293385136,
            "auditor_fn_violation": 0.009078858403615532,
            "auditor_fp_violation": 0.004061466314952062,
            "ave_precision_score": 0.8392462721424493,
            "fpr": 0.07456140350877193,
            "logloss": 0.5250538545589203,
            "mae": 0.33024735853337406,
            "precision": 0.8278481012658228,
            "recall": 0.6632860040567952
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8440624759708548,
            "auditor_fn_violation": 0.01059120748813609,
            "auditor_fp_violation": 0.009354799365776312,
            "ave_precision_score": 0.823744888482675,
            "fpr": 0.06037321624588365,
            "logloss": 0.4910897850743797,
            "mae": 0.3158815840400273,
            "precision": 0.8467966573816156,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8279324756841806,
            "auditor_fn_violation": 0.01611152628020356,
            "auditor_fp_violation": 0.017329271867018388,
            "ave_precision_score": 0.7952102279610239,
            "fpr": 0.10307017543859649,
            "logloss": 0.5320164156802786,
            "mae": 0.33849212688214164,
            "precision": 0.7960954446854663,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.7979928917562448,
            "auditor_fn_violation": 0.017332149124582415,
            "auditor_fp_violation": 0.01753872423466277,
            "ave_precision_score": 0.7689599116076213,
            "fpr": 0.09659714599341383,
            "logloss": 0.5185554350037481,
            "mae": 0.32954357586531163,
            "precision": 0.7962962962962963,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.859684762046241,
            "auditor_fn_violation": 0.006421034838617841,
            "auditor_fp_violation": 0.008989134530837837,
            "ave_precision_score": 0.845100282304724,
            "fpr": 0.0712719298245614,
            "logloss": 0.5167936754413737,
            "mae": 0.33068200263292774,
            "precision": 0.8379052369077307,
            "recall": 0.6815415821501014
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8471574784322535,
            "auditor_fn_violation": 0.007048105702536614,
            "auditor_fp_violation": 0.007200878155872667,
            "ave_precision_score": 0.8294724349660527,
            "fpr": 0.07025246981339188,
            "logloss": 0.5044999364014681,
            "mae": 0.3240882798407787,
            "precision": 0.8279569892473119,
            "recall": 0.6681127982646421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 7376,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7400783164271059,
            "auditor_fn_violation": 0.01661640155154621,
            "auditor_fp_violation": 0.019035506427165772,
            "ave_precision_score": 0.7044631194746926,
            "fpr": 0.15789473684210525,
            "logloss": 0.6311602952948692,
            "mae": 0.4310098844335267,
            "precision": 0.7061224489795919,
            "recall": 0.7018255578093306
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.713825597407441,
            "auditor_fn_violation": 0.003628821990089798,
            "auditor_fp_violation": 0.03156482497865594,
            "ave_precision_score": 0.6764685546950883,
            "fpr": 0.1756311745334797,
            "logloss": 0.6216057601314902,
            "mae": 0.4255334760760633,
            "precision": 0.6754563894523327,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7909399562708566,
            "auditor_fn_violation": 0.03201176114729013,
            "auditor_fp_violation": 0.037081815517313585,
            "ave_precision_score": 0.7158514644621008,
            "fpr": 0.2817982456140351,
            "logloss": 0.6350629309465831,
            "mae": 0.38909334102808907,
            "precision": 0.6291486291486291,
            "recall": 0.8843813387423936
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.762286179955202,
            "auditor_fn_violation": 0.021713404020753814,
            "auditor_fp_violation": 0.05035979997560679,
            "ave_precision_score": 0.677685058128586,
            "fpr": 0.29088913282107576,
            "logloss": 0.6365222983990657,
            "mae": 0.388878687292043,
            "precision": 0.6085672082717873,
            "recall": 0.8937093275488069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8384516981109549,
            "auditor_fn_violation": 0.03955820077577311,
            "auditor_fp_violation": 0.038850856257589085,
            "ave_precision_score": 0.8386565454457856,
            "fpr": 0.1611842105263158,
            "logloss": 1.1481695158476695,
            "mae": 0.3230273810560147,
            "precision": 0.7210626185958254,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8181735459169283,
            "auditor_fn_violation": 0.03951463315324154,
            "auditor_fp_violation": 0.04259055982436883,
            "ave_precision_score": 0.8186671167587084,
            "fpr": 0.14270032930845225,
            "logloss": 1.2778690263712746,
            "mae": 0.3215518413372019,
            "precision": 0.721627408993576,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7084479961566028,
            "auditor_fn_violation": 0.004819668339205013,
            "auditor_fp_violation": 0.015293304861198344,
            "ave_precision_score": 0.6672940132412164,
            "fpr": 0.11951754385964912,
            "logloss": 0.655125828581772,
            "mae": 0.43966510691148997,
            "precision": 0.6561514195583596,
            "recall": 0.42190669371196754
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6741866113389501,
            "auditor_fn_violation": 0.0007405273221246313,
            "auditor_fp_violation": 0.02435662885717771,
            "ave_precision_score": 0.6322771779010341,
            "fpr": 0.12623490669593854,
            "logloss": 0.6517746579290917,
            "mae": 0.43699265892988504,
            "precision": 0.6179401993355482,
            "recall": 0.403470715835141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8487896518066667,
            "auditor_fn_violation": 0.00761761147290132,
            "auditor_fp_violation": 0.00906764225599799,
            "ave_precision_score": 0.8490222084049761,
            "fpr": 0.10197368421052631,
            "logloss": 0.5086996668026399,
            "mae": 0.32970517678819433,
            "precision": 0.7947019867549668,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8565130688962057,
            "auditor_fn_violation": 0.0066266480304592494,
            "auditor_fp_violation": 0.0072203927308208335,
            "ave_precision_score": 0.8568844462901616,
            "fpr": 0.08781558726673985,
            "logloss": 0.48018865410753686,
            "mae": 0.3170429757560075,
            "precision": 0.8081534772182254,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7713572512509631,
            "auditor_fn_violation": 0.000622753638660546,
            "auditor_fp_violation": 0.0027817903948415355,
            "ave_precision_score": 0.5436401690154359,
            "fpr": 0.45285087719298245,
            "logloss": 0.6918636734262417,
            "mae": 0.49627052212650724,
            "precision": 0.543646408839779,
            "recall": 0.9979716024340771
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7546961325966851,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0029857299670691694,
            "ave_precision_score": 0.5093922651933702,
            "fpr": 0.48737650933040616,
            "logloss": 0.6884521198104603,
            "mae": 0.49652222343889174,
            "precision": 0.5093922651933702,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6915175134489036,
            "mae": 0.49904750182963253,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931393218457523,
            "mae": 0.499858257014194,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8457265740226598,
            "auditor_fn_violation": 0.01786635706914345,
            "auditor_fp_violation": 0.018996252564585692,
            "ave_precision_score": 0.8462027253381958,
            "fpr": 0.1524122807017544,
            "logloss": 1.2743069576418122,
            "mae": 0.2854345979993666,
            "precision": 0.7411545623836127,
            "recall": 0.8073022312373225
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8565317387763796,
            "auditor_fn_violation": 0.004709849013384263,
            "auditor_fp_violation": 0.019163312599097454,
            "ave_precision_score": 0.8567505265690798,
            "fpr": 0.1602634467618002,
            "logloss": 1.2150107280122833,
            "mae": 0.2820612640961817,
            "precision": 0.7165048543689321,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 7376,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7179032468634696,
            "auditor_fn_violation": 0.06555594106971283,
            "auditor_fp_violation": 0.07997058577230667,
            "ave_precision_score": 0.7184274133583566,
            "fpr": 0.2576754385964912,
            "logloss": 0.7023737102199438,
            "mae": 0.40249416410204086,
            "precision": 0.6251993620414673,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6749984464350712,
            "auditor_fn_violation": 0.06859759364337062,
            "auditor_fp_violation": 0.08422978412001465,
            "ave_precision_score": 0.6757652142720583,
            "fpr": 0.2689352360043908,
            "logloss": 0.7233735455569267,
            "mae": 0.4151265520344843,
            "precision": 0.5889261744966443,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8382473572623796,
            "auditor_fn_violation": 0.007915643571403161,
            "auditor_fp_violation": 0.005218146798978354,
            "ave_precision_score": 0.8331809839771644,
            "fpr": 0.08771929824561403,
            "logloss": 0.5404611938728259,
            "mae": 0.35800626210606934,
            "precision": 0.8104265402843602,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8229801477821813,
            "auditor_fn_violation": 0.007743391805624679,
            "auditor_fp_violation": 0.006708135138431517,
            "ave_precision_score": 0.8182503577502948,
            "fpr": 0.07135016465422613,
            "logloss": 0.5121894288741351,
            "mae": 0.3455262897305117,
            "precision": 0.8324742268041238,
            "recall": 0.7006507592190889
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8500470712667239,
            "auditor_fn_violation": 0.039769492188890074,
            "auditor_fp_violation": 0.013346313277226483,
            "ave_precision_score": 0.8499347665364001,
            "fpr": 0.09758771929824561,
            "logloss": 1.994037393672963,
            "mae": 0.290434616399066,
            "precision": 0.8008948545861297,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8294635572249529,
            "auditor_fn_violation": 0.03820025668439012,
            "auditor_fp_violation": 0.027437492377119163,
            "ave_precision_score": 0.8296723933447582,
            "fpr": 0.09989023051591657,
            "logloss": 1.9916520936925268,
            "mae": 0.2868447251388259,
            "precision": 0.7807228915662651,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.68439138169541,
            "auditor_fn_violation": 0.007926764172093525,
            "auditor_fp_violation": 0.006372210358832646,
            "ave_precision_score": 0.7157136594967823,
            "fpr": 0.07236842105263158,
            "logloss": 0.6013151869070219,
            "mae": 0.3894595332247646,
            "precision": 0.8075801749271136,
            "recall": 0.5618661257606491
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7236728836426422,
            "auditor_fn_violation": 0.013029471082527128,
            "auditor_fp_violation": 0.007420417124039516,
            "ave_precision_score": 0.719670372144719,
            "fpr": 0.0570801317233809,
            "logloss": 0.5724903906212011,
            "mae": 0.3801142964941479,
            "precision": 0.8327974276527331,
            "recall": 0.561822125813449
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8501283997573882,
            "auditor_fn_violation": 0.014372264332230166,
            "auditor_fp_violation": 0.007772264790855423,
            "ave_precision_score": 0.8518681646832487,
            "fpr": 0.0756578947368421,
            "logloss": 0.5230268322260109,
            "mae": 0.3225004669409572,
            "precision": 0.8261964735516373,
            "recall": 0.665314401622718
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8559094414275478,
            "auditor_fn_violation": 0.006359962949822728,
            "auditor_fp_violation": 0.009293816319063305,
            "ave_precision_score": 0.8518907091336285,
            "fpr": 0.06695938529088913,
            "logloss": 0.49109191902341864,
            "mae": 0.30711349469132143,
            "precision": 0.8398950131233596,
            "recall": 0.6941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8432671754356592,
            "auditor_fn_violation": 0.01852024838973702,
            "auditor_fp_violation": 0.01494002009797764,
            "ave_precision_score": 0.8435627565391599,
            "fpr": 0.11513157894736842,
            "logloss": 0.6996089751410434,
            "mae": 0.2703294659064812,
            "precision": 0.7830578512396694,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8354367506827642,
            "auditor_fn_violation": 0.00328356005533716,
            "auditor_fp_violation": 0.019319429198682767,
            "ave_precision_score": 0.8358378029830925,
            "fpr": 0.13172338090010977,
            "logloss": 0.7040715389415081,
            "mae": 0.27240426033601095,
            "precision": 0.7446808510638298,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.801989102616651,
            "auditor_fn_violation": 0.017821874666381982,
            "auditor_fp_violation": 0.017221977975966172,
            "ave_precision_score": 0.8025705607434748,
            "fpr": 0.1425438596491228,
            "logloss": 0.8921533426963913,
            "mae": 0.2932940172374522,
            "precision": 0.7352342158859471,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7846386696110765,
            "auditor_fn_violation": 0.0019382290681975748,
            "auditor_fp_violation": 0.021636784973777294,
            "ave_precision_score": 0.7850246059823657,
            "fpr": 0.15367727771679474,
            "logloss": 0.941003418584816,
            "mae": 0.2962936661824938,
            "precision": 0.7137014314928425,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8533898147084165,
            "auditor_fn_violation": 0.007172787445286647,
            "auditor_fp_violation": 0.010151048863208143,
            "ave_precision_score": 0.8083430131302625,
            "fpr": 0.07894736842105263,
            "logloss": 0.517922707732604,
            "mae": 0.3287539930479078,
            "precision": 0.8325581395348837,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8445000487476149,
            "auditor_fn_violation": 0.005224170240326121,
            "auditor_fp_violation": 0.01012318575436029,
            "ave_precision_score": 0.799511132824951,
            "fpr": 0.07683863885839737,
            "logloss": 0.5073798624161041,
            "mae": 0.3243559982145101,
            "precision": 0.826302729528536,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 7376,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7666547024068421,
            "auditor_fn_violation": 0.010146436069890751,
            "auditor_fp_violation": 0.00861229745006909,
            "ave_precision_score": 0.7333738492974413,
            "fpr": 0.22697368421052633,
            "logloss": 0.5994109599771367,
            "mae": 0.40439194698997755,
            "precision": 0.6703821656050956,
            "recall": 0.8539553752535497
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7565956177986054,
            "auditor_fn_violation": 0.007905307747439704,
            "auditor_fp_violation": 0.025520185388462024,
            "ave_precision_score": 0.7235610794903726,
            "fpr": 0.25466520307354557,
            "logloss": 0.6094685851610909,
            "mae": 0.4125802981719358,
            "precision": 0.6276083467094703,
            "recall": 0.8481561822125814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8308212184501101,
            "auditor_fn_violation": 0.027479004305896587,
            "auditor_fp_violation": 0.041501800443830346,
            "ave_precision_score": 0.8311572477290574,
            "fpr": 0.22149122807017543,
            "logloss": 0.5783415984454816,
            "mae": 0.344895818287125,
            "precision": 0.6798732171156894,
            "recall": 0.8701825557809331
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8247234925074252,
            "auditor_fn_violation": 0.028020982401165802,
            "auditor_fp_violation": 0.04972313696792294,
            "ave_precision_score": 0.8252075924924922,
            "fpr": 0.21624588364434688,
            "logloss": 0.5664380628749709,
            "mae": 0.34518544191278316,
            "precision": 0.6649659863945578,
            "recall": 0.8481561822125814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7455149363699699,
            "auditor_fn_violation": 0.007159442724458195,
            "auditor_fp_violation": 0.0018370807687476452,
            "ave_precision_score": 0.664240040903495,
            "fpr": 0.017543859649122806,
            "logloss": 0.6475665076148736,
            "mae": 0.4466616401513771,
            "precision": 0.872,
            "recall": 0.2210953346855984
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7417082931870267,
            "auditor_fn_violation": 0.003735972245702697,
            "auditor_fp_violation": 0.0014245639712160026,
            "ave_precision_score": 0.6326531216887958,
            "fpr": 0.007683863885839737,
            "logloss": 0.6256966509047366,
            "mae": 0.44467140867074884,
            "precision": 0.9357798165137615,
            "recall": 0.22125813449023862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.813701684053098,
            "auditor_fn_violation": 0.012853190277926052,
            "auditor_fp_violation": 0.025682493824058964,
            "ave_precision_score": 0.7610521739340217,
            "fpr": 0.1962719298245614,
            "logloss": 0.5512609607969661,
            "mae": 0.3731022422700271,
            "precision": 0.7006688963210702,
            "recall": 0.8498985801217038
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8104284850238772,
            "auditor_fn_violation": 0.00951970493200721,
            "auditor_fp_violation": 0.016792291742895475,
            "ave_precision_score": 0.7541043715219006,
            "fpr": 0.19538968166849616,
            "logloss": 0.5466522249991835,
            "mae": 0.3707460638352401,
            "precision": 0.687170474516696,
            "recall": 0.8481561822125814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6404715913366772,
            "auditor_fn_violation": 0.022327942066118645,
            "auditor_fp_violation": 0.003914918561319768,
            "ave_precision_score": 0.6151526520160794,
            "fpr": 0.06469298245614036,
            "logloss": 0.6836066725601814,
            "mae": 0.4828774672361058,
            "precision": 0.6910994764397905,
            "recall": 0.26774847870182555
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6021679609571235,
            "auditor_fn_violation": 0.0028811513175909685,
            "auditor_fp_violation": 0.0070740334187096,
            "ave_precision_score": 0.6064407408822862,
            "fpr": 0.054884742041712405,
            "logloss": 0.6699934911310672,
            "mae": 0.4768542309591197,
            "precision": 0.691358024691358,
            "recall": 0.24295010845986983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7643487848066255,
            "auditor_fn_violation": 0.002846873776733924,
            "auditor_fp_violation": 0.02253695096930873,
            "ave_precision_score": 0.6596186966990278,
            "fpr": 0.37280701754385964,
            "logloss": 6.4488296384045025,
            "mae": 0.37936374446246446,
            "precision": 0.5893719806763285,
            "recall": 0.9898580121703854
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7438779918076929,
            "auditor_fn_violation": 0.002171578513754521,
            "auditor_fp_violation": 0.026739846322722277,
            "ave_precision_score": 0.6271332420955102,
            "fpr": 0.4083424807903403,
            "logloss": 7.039146135751994,
            "mae": 0.4049209022749334,
            "precision": 0.5485436893203883,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.663047079758516,
            "auditor_fn_violation": 0.0646907583360023,
            "auditor_fp_violation": 0.03684105849348909,
            "ave_precision_score": 0.664736679130093,
            "fpr": 0.07675438596491228,
            "logloss": 0.6867308096444341,
            "mae": 0.46970792763392655,
            "precision": 0.7142857142857143,
            "recall": 0.35496957403651114
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6480730003230903,
            "auditor_fn_violation": 0.05597291241538107,
            "auditor_fp_violation": 0.033479692645444564,
            "ave_precision_score": 0.6491976690254595,
            "fpr": 0.09330406147091108,
            "logloss": 0.6680485616000663,
            "mae": 0.4621826167556771,
            "precision": 0.6544715447154471,
            "recall": 0.3492407809110629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8192444536798386,
            "auditor_fn_violation": 0.011474235792320563,
            "auditor_fp_violation": 0.008520705104048905,
            "ave_precision_score": 0.6887786784405232,
            "fpr": 0.17105263157894737,
            "logloss": 0.5840500960453111,
            "mae": 0.3845954887046103,
            "precision": 0.7214285714285714,
            "recall": 0.8194726166328601
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8142914575805686,
            "auditor_fn_violation": 0.007798157491826819,
            "auditor_fp_violation": 0.007683863885839738,
            "ave_precision_score": 0.6790198300621703,
            "fpr": 0.16465422612513722,
            "logloss": 0.5644324560703577,
            "mae": 0.37477916995989635,
            "precision": 0.7164461247637051,
            "recall": 0.8221258134490239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 7376,
        "test": {
            "accuracy": 0.3618421052631579,
            "auc_prc": 0.4562188585663739,
            "auditor_fn_violation": 0.02066430020283976,
            "auditor_fp_violation": 0.048473286438052175,
            "ave_precision_score": 0.4480372335769226,
            "fpr": 0.28618421052631576,
            "logloss": 2.0315804982201993,
            "mae": 0.519354423431459,
            "precision": 0.3972286374133949,
            "recall": 0.3488843813387424
        },
        "train": {
            "accuracy": 0.41822173435784854,
            "auc_prc": 0.4498906355583172,
            "auditor_fn_violation": 0.012729450366811074,
            "auditor_fp_violation": 0.062173435784851815,
            "ave_precision_score": 0.441226096622953,
            "fpr": 0.2667398463227223,
            "logloss": 1.8687731254197437,
            "mae": 0.4981588422659167,
            "precision": 0.4172661870503597,
            "recall": 0.3774403470715835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7579974043803175,
            "auditor_fn_violation": 0.011191772534785248,
            "auditor_fp_violation": 0.010737239877737304,
            "ave_precision_score": 0.7121248586182513,
            "fpr": 0.10087719298245613,
            "logloss": 0.6674666113718714,
            "mae": 0.40959422819708524,
            "precision": 0.7783132530120482,
            "recall": 0.6551724137931034
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7763439409526249,
            "auditor_fn_violation": 0.001078645906503076,
            "auditor_fp_violation": 0.00633004024881083,
            "ave_precision_score": 0.7137416489156704,
            "fpr": 0.0867178924259056,
            "logloss": 0.6260221043787773,
            "mae": 0.39057060191254456,
            "precision": 0.793733681462141,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 7376,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7590036811974943,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018135284511996074,
            "ave_precision_score": 0.7598691738272848,
            "fpr": 0.45614035087719296,
            "logloss": 0.7280134452415206,
            "mae": 0.43285570662926165,
            "precision": 0.5423542354235423,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7912652696285265,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002273447981461174,
            "ave_precision_score": 0.7919623354514943,
            "fpr": 0.48957189901207465,
            "logloss": 0.7305360275043152,
            "mae": 0.44561235120869624,
            "precision": 0.5082690187431091,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8475704520182845,
            "auditor_fn_violation": 0.03180269385431124,
            "auditor_fp_violation": 0.02616924172005193,
            "ave_precision_score": 0.8478974926845229,
            "fpr": 0.1787280701754386,
            "logloss": 0.5706259170284536,
            "mae": 0.3008606621794267,
            "precision": 0.7165217391304348,
            "recall": 0.8356997971602435
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8414347909471976,
            "auditor_fn_violation": 0.02847577570832272,
            "auditor_fp_violation": 0.02667398463227223,
            "ave_precision_score": 0.8418037950168666,
            "fpr": 0.16794731064763996,
            "logloss": 0.5555999888091212,
            "mae": 0.30711540640463425,
            "precision": 0.7063339731285988,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7897170306039902,
            "auditor_fn_violation": 0.04290550158357355,
            "auditor_fp_violation": 0.035731482644558894,
            "ave_precision_score": 0.7811695677460306,
            "fpr": 0.1787280701754386,
            "logloss": 1.3747733753129565,
            "mae": 0.3053262516589728,
            "precision": 0.7068345323741008,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7645924212122588,
            "auditor_fn_violation": 0.02266108850373002,
            "auditor_fp_violation": 0.04489815831198927,
            "ave_precision_score": 0.7556188483382631,
            "fpr": 0.20197585071350166,
            "logloss": 1.4637659940173755,
            "mae": 0.31385697265174456,
            "precision": 0.6666666666666666,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7695207780506381,
            "auditor_fn_violation": 0.03218079427778371,
            "auditor_fp_violation": 0.03765492191098272,
            "ave_precision_score": 0.7656302257503685,
            "fpr": 0.17763157894736842,
            "logloss": 0.5948581971046183,
            "mae": 0.3954296892958442,
            "precision": 0.7,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7796637218593211,
            "auditor_fn_violation": 0.01836079157846614,
            "auditor_fp_violation": 0.0270740334187096,
            "ave_precision_score": 0.770809064762057,
            "fpr": 0.18331503841931943,
            "logloss": 0.5854996622111697,
            "mae": 0.39823127376549733,
            "precision": 0.6782273603082851,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7641198153199704,
            "auditor_fn_violation": 0.007337372335504075,
            "auditor_fp_violation": 0.0016826822425993417,
            "ave_precision_score": 0.7719881485272029,
            "fpr": 0.0800438596491228,
            "logloss": 0.5962649906508732,
            "mae": 0.34867603585467133,
            "precision": 0.8223844282238443,
            "recall": 0.6855983772819473
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8002348029943698,
            "auditor_fn_violation": 0.00784339871086337,
            "auditor_fp_violation": 0.00942066105622637,
            "ave_precision_score": 0.8005721308276565,
            "fpr": 0.06476399560922064,
            "logloss": 0.5319600705432288,
            "mae": 0.32127593184129205,
            "precision": 0.8413978494623656,
            "recall": 0.6789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6734096211511157,
            "auditor_fn_violation": 0.018762677484787018,
            "auditor_fp_violation": 0.017656387388519032,
            "ave_precision_score": 0.6752523816742275,
            "fpr": 0.16228070175438597,
            "logloss": 0.611602993666562,
            "mae": 0.41895543760211584,
            "precision": 0.7115009746588694,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.645855488093835,
            "auditor_fn_violation": 0.0074362277395344,
            "auditor_fp_violation": 0.024873765093304058,
            "ave_precision_score": 0.6476974422858814,
            "fpr": 0.1877058177826564,
            "logloss": 0.7317596018452929,
            "mae": 0.4236895234784607,
            "precision": 0.6679611650485436,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 7376,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7294555431961816,
            "auditor_fn_violation": 0.018457973025870975,
            "auditor_fp_violation": 0.021673365992547003,
            "ave_precision_score": 0.6533855287830059,
            "fpr": 0.16337719298245615,
            "logloss": 0.658062841251001,
            "mae": 0.42978970915601966,
            "precision": 0.702,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7249279798802317,
            "auditor_fn_violation": 0.009831631231680285,
            "auditor_fp_violation": 0.02753018660812295,
            "ave_precision_score": 0.6466771635951831,
            "fpr": 0.1778265642151482,
            "logloss": 0.6368251735825844,
            "mae": 0.42133154745421214,
            "precision": 0.6746987951807228,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8208848377989533,
            "auditor_fn_violation": 0.012581847621081098,
            "auditor_fp_violation": 0.004331009504668596,
            "ave_precision_score": 0.807597618630649,
            "fpr": 0.09429824561403509,
            "logloss": 0.5847738843884894,
            "mae": 0.35744740426736443,
            "precision": 0.8013856812933026,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8043528093664757,
            "auditor_fn_violation": 0.0030668784273199788,
            "auditor_fp_violation": 0.004141968532747898,
            "ave_precision_score": 0.7922053204275092,
            "fpr": 0.10208562019758508,
            "logloss": 0.5750416667045447,
            "mae": 0.3547348253322616,
            "precision": 0.7769784172661871,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8064843762975655,
            "auditor_fn_violation": 0.008111366143553615,
            "auditor_fp_violation": 0.004833458945693595,
            "ave_precision_score": 0.8002823449273918,
            "fpr": 0.08442982456140351,
            "logloss": 0.5718310428753677,
            "mae": 0.3543871254762308,
            "precision": 0.8045685279187818,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7854846086689128,
            "auditor_fn_violation": 0.004633653276059538,
            "auditor_fp_violation": 0.007000853762653983,
            "ave_precision_score": 0.7801490549104526,
            "fpr": 0.06805708013172337,
            "logloss": 0.5482797085630925,
            "mae": 0.3443395575645465,
            "precision": 0.8258426966292135,
            "recall": 0.6377440347071583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6785889441751545,
            "auditor_fn_violation": 0.006027365574178857,
            "auditor_fp_violation": 0.020283779257212243,
            "ave_precision_score": 0.6800266287673736,
            "fpr": 0.20285087719298245,
            "logloss": 0.7737659389858604,
            "mae": 0.3748880250118019,
            "precision": 0.6916666666666667,
            "recall": 0.8417849898580122
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6409720273150039,
            "auditor_fn_violation": 0.0024882670470103892,
            "auditor_fp_violation": 0.027517989998780343,
            "ave_precision_score": 0.6425571880280885,
            "fpr": 0.23161361141602635,
            "logloss": 0.8011663562925213,
            "mae": 0.38994297911090986,
            "precision": 0.6423728813559322,
            "recall": 0.8221258134490239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.8148820059846216,
            "auditor_fn_violation": 0.013578253442937978,
            "auditor_fp_violation": 0.0029204873759577955,
            "ave_precision_score": 0.8034154896750241,
            "fpr": 0.020833333333333332,
            "logloss": 0.7273297580643422,
            "mae": 0.41721955256887894,
            "precision": 0.905940594059406,
            "recall": 0.3711967545638945
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8154208111309328,
            "auditor_fn_violation": 0.004893195006321876,
            "auditor_fp_violation": 0.0038419319429198687,
            "ave_precision_score": 0.7993653237261324,
            "fpr": 0.009879253567508232,
            "logloss": 0.6903357026110473,
            "mae": 0.3943436792136694,
            "precision": 0.9510869565217391,
            "recall": 0.3796095444685466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6926675370678481,
            "mae": 0.49975074461677615,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6930918688791491,
            "mae": 0.49996290785290143,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6909475623834088,
            "mae": 0.49860497655575736,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6933233539592519,
            "mae": 0.4997924040230124,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8175825094954559,
            "auditor_fn_violation": 0.018446852425180602,
            "auditor_fp_violation": 0.018873257128501447,
            "ave_precision_score": 0.8178519738757509,
            "fpr": 0.14364035087719298,
            "logloss": 0.6808500492402674,
            "mae": 0.34627416543866785,
            "precision": 0.7265135699373695,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8004585005988245,
            "auditor_fn_violation": 0.008822037712127747,
            "auditor_fp_violation": 0.02541773386998415,
            "ave_precision_score": 0.8008960541339674,
            "fpr": 0.15916575192096596,
            "logloss": 0.677661370347158,
            "mae": 0.34302169021165857,
            "precision": 0.6953781512605042,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7961616504127595,
            "auditor_fn_violation": 0.008155848546315082,
            "auditor_fp_violation": 0.007531507767030949,
            "ave_precision_score": 0.7511034794338454,
            "fpr": 0.10964912280701754,
            "logloss": 0.5704568625199922,
            "mae": 0.3413335190465053,
            "precision": 0.7777777777777778,
            "recall": 0.7099391480730223
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8065797035696233,
            "auditor_fn_violation": 0.011569846489400461,
            "auditor_fp_violation": 0.006791072081961218,
            "ave_precision_score": 0.76231116761841,
            "fpr": 0.09220636663007684,
            "logloss": 0.5326450694597494,
            "mae": 0.3302270820779413,
            "precision": 0.7941176470588235,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.5199105949503313,
            "auditor_fn_violation": 0.005480232020212804,
            "auditor_fp_violation": 0.0008321818866976499,
            "ave_precision_score": 0.6820763078834258,
            "fpr": 0.09100877192982457,
            "logloss": 0.6265471146758216,
            "mae": 0.39974357102785196,
            "precision": 0.7756756756756756,
            "recall": 0.5821501014198783
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8043489199934376,
            "auditor_fn_violation": 0.008195803995990202,
            "auditor_fp_violation": 0.002902793023539455,
            "ave_precision_score": 0.7000125015887119,
            "fpr": 0.06366630076838639,
            "logloss": 0.5748076031063281,
            "mae": 0.3837115800603161,
            "precision": 0.826865671641791,
            "recall": 0.6008676789587852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.840311083504326,
            "auditor_fn_violation": 0.006125226860254086,
            "auditor_fp_violation": 0.023337729765942304,
            "ave_precision_score": 0.7950275401942919,
            "fpr": 0.19517543859649122,
            "logloss": 0.543050605576728,
            "mae": 0.3544035583669156,
            "precision": 0.6993243243243243,
            "recall": 0.8397565922920892
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.8307630913542665,
            "auditor_fn_violation": 0.006007557664695899,
            "auditor_fp_violation": 0.024076106842297853,
            "ave_precision_score": 0.7843933847969886,
            "fpr": 0.2239297475301866,
            "logloss": 0.5484723429071887,
            "mae": 0.36427733625983566,
            "precision": 0.6458333333333334,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.759418822751426,
            "auditor_fn_violation": 0.04550549802498133,
            "auditor_fp_violation": 0.026695243478624973,
            "ave_precision_score": 0.7600876142298819,
            "fpr": 0.13706140350877194,
            "logloss": 0.9265749478397468,
            "mae": 0.36650578395330247,
            "precision": 0.7417355371900827,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.712289742328899,
            "auditor_fn_violation": 0.03623345421469578,
            "auditor_fp_violation": 0.02994023661422125,
            "ave_precision_score": 0.7135290164702348,
            "fpr": 0.13391877058177826,
            "logloss": 0.9021558301601307,
            "mae": 0.36436791511309263,
            "precision": 0.7306843267108167,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8146222484727932,
            "auditor_fn_violation": 0.013120084694494858,
            "auditor_fp_violation": 0.00870388979608927,
            "ave_precision_score": 0.7882036442349089,
            "fpr": 0.10964912280701754,
            "logloss": 0.5510793281317713,
            "mae": 0.3637942942640253,
            "precision": 0.7727272727272727,
            "recall": 0.6896551724137931
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8286555330484778,
            "auditor_fn_violation": 0.0014572434763352722,
            "auditor_fp_violation": 0.0012879619465788563,
            "ave_precision_score": 0.7985932969065976,
            "fpr": 0.09659714599341383,
            "logloss": 0.5335810452723149,
            "mae": 0.3582944650285477,
            "precision": 0.7810945273631841,
            "recall": 0.6811279826464208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8523557342105084,
            "auditor_fn_violation": 0.025888758407174126,
            "auditor_fp_violation": 0.013246870158690287,
            "ave_precision_score": 0.8480596538122911,
            "fpr": 0.09429824561403509,
            "logloss": 0.4994282014289359,
            "mae": 0.32167445698328184,
            "precision": 0.8114035087719298,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8481960335580271,
            "auditor_fn_violation": 0.014143833740901158,
            "auditor_fp_violation": 0.010903768752286868,
            "ave_precision_score": 0.8417714495377984,
            "fpr": 0.08781558726673985,
            "logloss": 0.48816575938918005,
            "mae": 0.3162340550201932,
            "precision": 0.8099762470308789,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8370879731254247,
            "auditor_fn_violation": 0.010806999750898548,
            "auditor_fp_violation": 0.0091225976636101,
            "ave_precision_score": 0.7889834314700817,
            "fpr": 0.10635964912280702,
            "logloss": 0.5527623137186088,
            "mae": 0.3382591382976164,
            "precision": 0.7886710239651417,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8508774104392445,
            "auditor_fn_violation": 0.006150424672179748,
            "auditor_fp_violation": 0.010998902305159165,
            "ave_precision_score": 0.8079576703931468,
            "fpr": 0.0889132821075741,
            "logloss": 0.5122048731026597,
            "mae": 0.3227818294558122,
            "precision": 0.8057553956834532,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8493083887561814,
            "auditor_fn_violation": 0.00938801110280773,
            "auditor_fp_violation": 0.0035171460871749804,
            "ave_precision_score": 0.8350785514405437,
            "fpr": 0.10087719298245613,
            "logloss": 0.5369290341887824,
            "mae": 0.31255374167506633,
            "precision": 0.7973568281938326,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8437733127816697,
            "auditor_fn_violation": 0.005707536948979814,
            "auditor_fp_violation": 0.0059080375655567756,
            "ave_precision_score": 0.8268407548135079,
            "fpr": 0.0845225027442371,
            "logloss": 0.4981792236211598,
            "mae": 0.2954896299575346,
            "precision": 0.8126520681265207,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 7376,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.5755878364163842,
            "auditor_fn_violation": 0.017127949183303084,
            "auditor_fp_violation": 0.03968303814428674,
            "ave_precision_score": 0.5960562020557021,
            "fpr": 0.27521929824561403,
            "logloss": 0.6446436804165732,
            "mae": 0.4403575880763431,
            "precision": 0.6378066378066378,
            "recall": 0.896551724137931
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.5521367717628402,
            "auditor_fn_violation": 0.004755090232420813,
            "auditor_fp_violation": 0.03548237589949995,
            "ave_precision_score": 0.5635684303390357,
            "fpr": 0.3106476399560922,
            "logloss": 0.6685659895112982,
            "mae": 0.45264888154066746,
            "precision": 0.5922190201729106,
            "recall": 0.8915401301518439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.872632832458989,
            "auditor_fn_violation": 0.023651293548272306,
            "auditor_fp_violation": 0.01383044424904744,
            "ave_precision_score": 0.8728003356782347,
            "fpr": 0.10197368421052631,
            "logloss": 0.5165915316037596,
            "mae": 0.2982742081606982,
            "precision": 0.7960526315789473,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.85585727695597,
            "auditor_fn_violation": 0.007474325608196761,
            "auditor_fp_violation": 0.01207464324917673,
            "ave_precision_score": 0.8571460204561052,
            "fpr": 0.08122941822173436,
            "logloss": 0.5128252166956295,
            "mae": 0.2955292701617289,
            "precision": 0.817283950617284,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7828604308501719,
            "auditor_fn_violation": 0.02298183338671222,
            "auditor_fp_violation": 0.0012404220575304662,
            "ave_precision_score": 0.7838566458566858,
            "fpr": 0.06907894736842106,
            "logloss": 1.8180786755477312,
            "mae": 0.3876169366864013,
            "precision": 0.8141592920353983,
            "recall": 0.5598377281947262
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7626516124885168,
            "auditor_fn_violation": 0.004393160480128395,
            "auditor_fp_violation": 0.017172825954384685,
            "ave_precision_score": 0.7635035505699734,
            "fpr": 0.0845225027442371,
            "logloss": 2.0978199427383384,
            "mae": 0.3910178899817477,
            "precision": 0.7616099071207431,
            "recall": 0.5336225596529284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8539244869590014,
            "auditor_fn_violation": 0.010435571687840293,
            "auditor_fp_violation": 0.013594921073566971,
            "ave_precision_score": 0.8025725493613666,
            "fpr": 0.1513157894736842,
            "logloss": 3.5503615032819393,
            "mae": 0.22294396403460592,
            "precision": 0.7566137566137566,
            "recall": 0.8701825557809331
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8266974802707867,
            "auditor_fn_violation": 0.002635896288077035,
            "auditor_fp_violation": 0.009806073911452625,
            "ave_precision_score": 0.7625696817558153,
            "fpr": 0.15916575192096596,
            "logloss": 4.010384724579578,
            "mae": 0.23457991385460522,
            "precision": 0.7304832713754646,
            "recall": 0.8524945770065075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7991476482166233,
            "auditor_fn_violation": 0.013909647343510908,
            "auditor_fp_violation": 0.019883389858895453,
            "ave_precision_score": 0.800582072347907,
            "fpr": 0.13157894736842105,
            "logloss": 0.8631434410392758,
            "mae": 0.2846043902434243,
            "precision": 0.7560975609756098,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7907237205108008,
            "auditor_fn_violation": 0.005224170240326124,
            "auditor_fp_violation": 0.019456031223319917,
            "ave_precision_score": 0.7910903256147575,
            "fpr": 0.14928649835345773,
            "logloss": 0.8718855087607094,
            "mae": 0.2966309122284943,
            "precision": 0.71900826446281,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5581670250962354,
            "auditor_fn_violation": 0.008605120814205896,
            "auditor_fp_violation": 0.017198425658418122,
            "ave_precision_score": 0.5550113986481358,
            "fpr": 0.09868421052631579,
            "logloss": 9.192774920640016,
            "mae": 0.5169305413988882,
            "precision": 0.5673076923076923,
            "recall": 0.23935091277890466
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5287348844413458,
            "auditor_fn_violation": 0.014339085317795751,
            "auditor_fp_violation": 0.02001463593121112,
            "ave_precision_score": 0.529012635442337,
            "fpr": 0.09330406147091108,
            "logloss": 8.804639562189012,
            "mae": 0.4910132865625644,
            "precision": 0.5812807881773399,
            "recall": 0.2559652928416486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7548890926606577,
            "auditor_fn_violation": 0.07089605352122699,
            "auditor_fp_violation": 0.006168090273416238,
            "ave_precision_score": 0.6399336958013696,
            "fpr": 0.09649122807017543,
            "logloss": 0.64655924343388,
            "mae": 0.44503765422524066,
            "precision": 0.7380952380952381,
            "recall": 0.5030425963488844
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7583012554315667,
            "auditor_fn_violation": 0.06781658733579225,
            "auditor_fp_violation": 0.010484205390901334,
            "ave_precision_score": 0.6347985457720775,
            "fpr": 0.07793633369923161,
            "logloss": 0.6251696630370865,
            "mae": 0.43645056679795785,
            "precision": 0.7641196013289037,
            "recall": 0.49891540130151846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 7376,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7251404026878119,
            "auditor_fn_violation": 0.048227821073983136,
            "auditor_fp_violation": 0.015554997278398862,
            "ave_precision_score": 0.7262455864818529,
            "fpr": 0.09649122807017543,
            "logloss": 0.6754895283687536,
            "mae": 0.4414601272966138,
            "precision": 0.7267080745341615,
            "recall": 0.4746450304259635
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6976335457092377,
            "auditor_fn_violation": 0.022861102314207425,
            "auditor_fp_violation": 0.007647274057811932,
            "ave_precision_score": 0.6994581900470311,
            "fpr": 0.07793633369923161,
            "logloss": 0.6623924377262147,
            "mae": 0.4359629951232587,
            "precision": 0.7473309608540926,
            "recall": 0.455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7639541918320687,
            "auditor_fn_violation": 0.007341820575780233,
            "auditor_fp_violation": 0.004383347988108697,
            "ave_precision_score": 0.7381902652645879,
            "fpr": 0.06030701754385965,
            "logloss": 0.5957035765636614,
            "mae": 0.38064128144137693,
            "precision": 0.8372781065088757,
            "recall": 0.5740365111561866
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8041238317645122,
            "auditor_fn_violation": 0.008831562179293337,
            "auditor_fp_violation": 0.009001097694840835,
            "ave_precision_score": 0.7552783273001379,
            "fpr": 0.04939626783754116,
            "logloss": 0.5512049817586524,
            "mae": 0.3613418859851871,
            "precision": 0.859375,
            "recall": 0.596529284164859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7768680239939106,
            "auditor_fn_violation": 0.004199138820682538,
            "auditor_fp_violation": 0.020200037683708073,
            "ave_precision_score": 0.7769169488225195,
            "fpr": 0.3223684210526316,
            "logloss": 0.8662349749391405,
            "mae": 0.4191431296793254,
            "precision": 0.5944827586206897,
            "recall": 0.8742393509127789
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.795756334511954,
            "auditor_fn_violation": 0.00415504880098864,
            "auditor_fp_violation": 0.010947676545920245,
            "ave_precision_score": 0.7962099668976509,
            "fpr": 0.2897914379802415,
            "logloss": 0.8075319792604435,
            "mae": 0.4107409519042194,
            "precision": 0.6077265973254086,
            "recall": 0.8872017353579176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8352825090929834,
            "auditor_fn_violation": 0.003950037365218323,
            "auditor_fp_violation": 0.00035328476322070445,
            "ave_precision_score": 0.8267780984800795,
            "fpr": 0.10526315789473684,
            "logloss": 0.5283462179462571,
            "mae": 0.33748259945168047,
            "precision": 0.7894736842105263,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8437751141927725,
            "auditor_fn_violation": 0.005528953189624999,
            "auditor_fp_violation": 0.005825100622027078,
            "ave_precision_score": 0.8322410782772339,
            "fpr": 0.09549945115257959,
            "logloss": 0.4952995232115622,
            "mae": 0.32294664136926376,
            "precision": 0.7948113207547169,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7671993666386651,
            "auditor_fn_violation": 0.00505542507384079,
            "auditor_fp_violation": 0.011577272536950976,
            "ave_precision_score": 0.5472506602550177,
            "fpr": 0.4342105263157895,
            "logloss": 0.6884803454983972,
            "mae": 0.4941307320484173,
            "precision": 0.5474285714285714,
            "recall": 0.9716024340770791
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7562811036565785,
            "auditor_fn_violation": 0.0017882187103395236,
            "auditor_fp_violation": 0.008988901085498234,
            "ave_precision_score": 0.5198500148335383,
            "fpr": 0.45993413830954993,
            "logloss": 0.684217555158506,
            "mae": 0.49209623635387706,
            "precision": 0.5200458190148912,
            "recall": 0.9848156182212582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7127215762996217,
            "auditor_fn_violation": 0.07390973630831645,
            "auditor_fp_violation": 0.02347642674705858,
            "ave_precision_score": 0.7198757198733554,
            "fpr": 0.10416666666666667,
            "logloss": 0.6054339101927898,
            "mae": 0.3924505276638165,
            "precision": 0.759493670886076,
            "recall": 0.6085192697768763
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.726031992482559,
            "auditor_fn_violation": 0.07092156363177457,
            "auditor_fp_violation": 0.0314062690572021,
            "ave_precision_score": 0.7226409670455247,
            "fpr": 0.09769484083424808,
            "logloss": 0.5742834206223116,
            "mae": 0.3822674391756466,
            "precision": 0.7513966480446927,
            "recall": 0.5835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7536514627356771,
            "auditor_fn_violation": 0.014258834205188428,
            "auditor_fp_violation": 0.0074608508143868026,
            "ave_precision_score": 0.5355832429800597,
            "fpr": 0.4407894736842105,
            "logloss": 0.7036856913926227,
            "mae": 0.4968963255942391,
            "precision": 0.5352601156069364,
            "recall": 0.9391480730223124
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7391128526366649,
            "auditor_fn_violation": 0.011000759576256458,
            "auditor_fp_violation": 0.006244663983412608,
            "ave_precision_score": 0.5030282734436579,
            "fpr": 0.47530186608122943,
            "logloss": 0.7108612009176716,
            "mae": 0.5006830123724451,
            "precision": 0.5028702640642939,
            "recall": 0.9501084598698482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.700793300420939,
            "auditor_fn_violation": 0.13453702715205865,
            "auditor_fp_violation": 0.10943976887325714,
            "ave_precision_score": 0.5807696364077153,
            "fpr": 0.17982456140350878,
            "logloss": 0.6821022306363258,
            "mae": 0.4910704279481842,
            "precision": 0.6159250585480094,
            "recall": 0.5334685598377282
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6724523621170381,
            "auditor_fn_violation": 0.12540865916932362,
            "auditor_fp_violation": 0.12067081351384316,
            "ave_precision_score": 0.5403724237586156,
            "fpr": 0.20965971459934138,
            "logloss": 0.6856602489469865,
            "mae": 0.4927781076384167,
            "precision": 0.5688487584650113,
            "recall": 0.5466377440347071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 7376,
        "test": {
            "accuracy": 0.38706140350877194,
            "auc_prc": 0.45236004081106557,
            "auditor_fn_violation": 0.009432493505569194,
            "auditor_fp_violation": 0.02532659213666625,
            "ave_precision_score": 0.5061106293613039,
            "fpr": 0.09210526315789473,
            "logloss": 0.8966662627649541,
            "mae": 0.5434969009733513,
            "precision": 0.17647058823529413,
            "recall": 0.036511156186612576
        },
        "train": {
            "accuracy": 0.424807903402854,
            "auc_prc": 0.444271204409076,
            "auditor_fn_violation": 0.005162261203749806,
            "auditor_fp_violation": 0.01697768020490304,
            "ave_precision_score": 0.4905700688403541,
            "fpr": 0.09220636663007684,
            "logloss": 0.8497088084779962,
            "mae": 0.5232684061209274,
            "precision": 0.2,
            "recall": 0.0455531453362256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5712833859871144,
            "auditor_fn_violation": 0.04126854916195154,
            "auditor_fp_violation": 0.03295492609806138,
            "ave_precision_score": 0.572434160890488,
            "fpr": 0.30701754385964913,
            "logloss": 0.7099459424998732,
            "mae": 0.4828545954078436,
            "precision": 0.5814648729446936,
            "recall": 0.7890466531440162
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.568547084254946,
            "auditor_fn_violation": 0.040343261796647864,
            "auditor_fp_violation": 0.03356019026710575,
            "ave_precision_score": 0.5700217782522392,
            "fpr": 0.33040614709110866,
            "logloss": 0.6984815748253164,
            "mae": 0.4803667212504194,
            "precision": 0.5494011976047904,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7460163429089127,
            "auditor_fn_violation": 0.005462439059108224,
            "auditor_fp_violation": 0.012898819243813593,
            "ave_precision_score": 0.7296923613985886,
            "fpr": 0.19736842105263158,
            "logloss": 0.6196636308077733,
            "mae": 0.40992913832642924,
            "precision": 0.6622889305816135,
            "recall": 0.716024340770791
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7210034095081495,
            "auditor_fn_violation": 0.00816008724411924,
            "auditor_fp_violation": 0.004288327844859134,
            "ave_precision_score": 0.7159525298839723,
            "fpr": 0.17453347969264543,
            "logloss": 0.5949478806417481,
            "mae": 0.399851372786496,
            "precision": 0.6761710794297352,
            "recall": 0.720173535791757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.538712182355096,
            "auditor_fn_violation": 0.01075584498772286,
            "auditor_fp_violation": 0.0037160323242473895,
            "ave_precision_score": 0.49842347153734157,
            "fpr": 0.30153508771929827,
            "logloss": 6.276534476747121,
            "mae": 0.4453715751633832,
            "precision": 0.5913818722139673,
            "recall": 0.8073022312373225
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.5279392700916476,
            "auditor_fn_violation": 0.0018263165790018852,
            "auditor_fp_violation": 0.005415294548115624,
            "ave_precision_score": 0.48354749225187854,
            "fpr": 0.31284302963776073,
            "logloss": 6.20666179090001,
            "mae": 0.4595426629848459,
            "precision": 0.5648854961832062,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.806918598921192,
            "auditor_fn_violation": 0.011649941283228354,
            "auditor_fp_violation": 0.004527278817568986,
            "ave_precision_score": 0.7795863949302598,
            "fpr": 0.11513157894736842,
            "logloss": 0.5704074331541643,
            "mae": 0.368802605482766,
            "precision": 0.765625,
            "recall": 0.6957403651115619
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8171059665189705,
            "auditor_fn_violation": 0.001785837593548134,
            "auditor_fp_violation": 0.007739968288815708,
            "ave_precision_score": 0.7849638624677762,
            "fpr": 0.10647639956092206,
            "logloss": 0.5469920901961193,
            "mae": 0.35806917516120046,
            "precision": 0.7690476190476191,
            "recall": 0.7006507592190889
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6950634927921677,
            "auditor_fn_violation": 0.0011476459912458633,
            "auditor_fp_violation": 0.0025855210819411374,
            "ave_precision_score": 0.6889774275559513,
            "fpr": 0.4517543859649123,
            "logloss": 0.6883933941431102,
            "mae": 0.49701293825841786,
            "precision": 0.5437430786267996,
            "recall": 0.9959432048681541
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6706711341367884,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00219538968166851,
            "ave_precision_score": 0.6747948626945579,
            "fpr": 0.48737650933040616,
            "logloss": 0.691576760263373,
            "mae": 0.498614678889284,
            "precision": 0.5093922651933702,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8617069031054441,
            "auditor_fn_violation": 0.03296368456638554,
            "auditor_fp_violation": 0.02655654649750869,
            "ave_precision_score": 0.8619111994416762,
            "fpr": 0.15021929824561403,
            "logloss": 0.593653326555464,
            "mae": 0.28503036742263804,
            "precision": 0.7419962335216572,
            "recall": 0.7991886409736308
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8476679560043412,
            "auditor_fn_violation": 0.024442163863695354,
            "auditor_fp_violation": 0.0306110501280644,
            "ave_precision_score": 0.8480089413909305,
            "fpr": 0.141602634467618,
            "logloss": 0.5524483181586389,
            "mae": 0.2754108182028293,
            "precision": 0.7430278884462151,
            "recall": 0.8091106290672451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.8118581023097416,
            "auditor_fn_violation": 0.0035096615778797903,
            "auditor_fp_violation": 0.02032826696813634,
            "ave_precision_score": 0.7607059563612356,
            "fpr": 0.38048245614035087,
            "logloss": 3.8056300473266838,
            "mae": 0.38048166354684454,
            "precision": 0.5839328537170264,
            "recall": 0.9878296146044625
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7723077585397566,
            "auditor_fn_violation": 0.000540513511647233,
            "auditor_fp_violation": 0.018894987193560198,
            "ave_precision_score": 0.7054738010204595,
            "fpr": 0.4083424807903403,
            "logloss": 4.54609637450366,
            "mae": 0.406331507444497,
            "precision": 0.549636803874092,
            "recall": 0.9848156182212582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7934524797240181,
            "auditor_fn_violation": 0.030810736272730507,
            "auditor_fp_violation": 0.024182996273499985,
            "ave_precision_score": 0.7738541543462327,
            "fpr": 0.12828947368421054,
            "logloss": 4.379539684779535,
            "mae": 0.30985670044175434,
            "precision": 0.7370786516853932,
            "recall": 0.665314401622718
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7580390590780349,
            "auditor_fn_violation": 0.02495172285705442,
            "auditor_fp_violation": 0.02261251372118551,
            "ave_precision_score": 0.7293382895822712,
            "fpr": 0.13172338090010977,
            "logloss": 4.760435874775383,
            "mae": 0.31319968219927047,
            "precision": 0.7129186602870813,
            "recall": 0.6464208242950108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8655705659707816,
            "auditor_fn_violation": 0.0180798726023985,
            "auditor_fp_violation": 0.007227944563078342,
            "ave_precision_score": 0.8657522575652481,
            "fpr": 0.041666666666666664,
            "logloss": 0.616068300506122,
            "mae": 0.3244671179491273,
            "precision": 0.8827160493827161,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8579679254682404,
            "auditor_fn_violation": 0.006943336563715117,
            "auditor_fp_violation": 0.009147457006952067,
            "ave_precision_score": 0.8582240791407899,
            "fpr": 0.03293084522502744,
            "logloss": 0.6271908824779698,
            "mae": 0.3097999975747731,
            "precision": 0.8983050847457628,
            "recall": 0.5748373101952278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5846916827111031,
            "auditor_fn_violation": 0.006558930287178391,
            "auditor_fp_violation": 0.0007746095549135415,
            "ave_precision_score": 0.5863388365041946,
            "fpr": 0.07346491228070176,
            "logloss": 0.6982004934116995,
            "mae": 0.4962258161486764,
            "precision": 0.6318681318681318,
            "recall": 0.2332657200811359
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5563374546732718,
            "auditor_fn_violation": 0.005131306685461626,
            "auditor_fp_violation": 0.004668862056348338,
            "ave_precision_score": 0.558302333425645,
            "fpr": 0.07244785949506037,
            "logloss": 0.6905107636928278,
            "mae": 0.4944705502564572,
            "precision": 0.6373626373626373,
            "recall": 0.25162689804772237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6909475623834088,
            "mae": 0.49860497655575736,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6933233539592519,
            "mae": 0.4997924040230124,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7084987183649627,
            "auditor_fn_violation": 0.007117184441834817,
            "auditor_fp_violation": 0.005558346941339029,
            "ave_precision_score": 0.6896216579895369,
            "fpr": 0.05921052631578947,
            "logloss": 0.7417224709928824,
            "mae": 0.4524299061301638,
            "precision": 0.7416267942583732,
            "recall": 0.3144016227180527
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.685281608820473,
            "auditor_fn_violation": 0.008955380252446013,
            "auditor_fp_violation": 0.01055006708135139,
            "ave_precision_score": 0.6664156447787861,
            "fpr": 0.07135016465422613,
            "logloss": 0.7045279884081237,
            "mae": 0.4365414190959721,
            "precision": 0.7098214285714286,
            "recall": 0.34490238611713664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 7376,
        "test": {
            "accuracy": 0.3300438596491228,
            "auc_prc": 0.5232763939394764,
            "auditor_fn_violation": 0.011514269954805888,
            "auditor_fp_violation": 0.008939412971569737,
            "ave_precision_score": 0.5138308202619744,
            "fpr": 0.3190789473684211,
            "logloss": 1.0366521601051695,
            "mae": 0.5709466426061434,
            "precision": 0.3728448275862069,
            "recall": 0.3509127789046653
        },
        "train": {
            "accuracy": 0.32821075740944017,
            "auc_prc": 0.5016419198614543,
            "auditor_fn_violation": 0.010657878758295231,
            "auditor_fp_violation": 0.00117575314062692,
            "ave_precision_score": 0.4818519588154744,
            "fpr": 0.3633369923161361,
            "logloss": 1.0591838479175852,
            "mae": 0.5757746319853906,
            "precision": 0.3522504892367906,
            "recall": 0.39045553145336226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 7376,
        "test": {
            "accuracy": 0.35964912280701755,
            "auc_prc": 0.5029749434953451,
            "auditor_fn_violation": 0.02127148500053379,
            "auditor_fp_violation": 0.021696918310095046,
            "ave_precision_score": 0.4949213069147538,
            "fpr": 0.29385964912280704,
            "logloss": 0.7002742529779485,
            "mae": 0.5023661019247875,
            "precision": 0.39775280898876403,
            "recall": 0.359026369168357
        },
        "train": {
            "accuracy": 0.3578485181119649,
            "auc_prc": 0.48726407575218617,
            "auditor_fn_violation": 0.011179343335611283,
            "auditor_fp_violation": 0.031011098914501777,
            "ave_precision_score": 0.46805452131492775,
            "fpr": 0.3084522502744237,
            "logloss": 0.7009179592295793,
            "mae": 0.5025463939759917,
            "precision": 0.3584474885844749,
            "recall": 0.3405639913232104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8089853252028587,
            "auditor_fn_violation": 0.04589471904914416,
            "auditor_fp_violation": 0.040269229158815895,
            "ave_precision_score": 0.80944515102476,
            "fpr": 0.15679824561403508,
            "logloss": 1.0282107042455444,
            "mae": 0.3000543251353287,
            "precision": 0.7286527514231499,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.762727603201489,
            "auditor_fn_violation": 0.043091070573920594,
            "auditor_fp_violation": 0.04679107208196122,
            "ave_precision_score": 0.7635709645742066,
            "fpr": 0.16355653128430298,
            "logloss": 1.0031913095245344,
            "mae": 0.31129138173276205,
            "precision": 0.6983805668016194,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5982009585559164,
            "auditor_fn_violation": 0.07782641187146366,
            "auditor_fp_violation": 0.05330674538374576,
            "ave_precision_score": 0.5780859977010817,
            "fpr": 0.10635964912280702,
            "logloss": 0.6921462877023453,
            "mae": 0.49726847180149014,
            "precision": 0.5975103734439834,
            "recall": 0.2920892494929006
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5818915364586783,
            "auditor_fn_violation": 0.07485993080474605,
            "auditor_fp_violation": 0.062085620197585074,
            "ave_precision_score": 0.5638742537555743,
            "fpr": 0.11086717892425905,
            "logloss": 0.6862617252504144,
            "mae": 0.4941610745292333,
            "precision": 0.596,
            "recall": 0.3232104121475054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8542930582873631,
            "auditor_fn_violation": 0.009078858403615532,
            "auditor_fp_violation": 0.004061466314952062,
            "ave_precision_score": 0.7999121724288327,
            "fpr": 0.07456140350877193,
            "logloss": 0.5240742603843992,
            "mae": 0.3328380890909517,
            "precision": 0.8278481012658228,
            "recall": 0.6632860040567952
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8552377897148149,
            "auditor_fn_violation": 0.01059120748813609,
            "auditor_fp_violation": 0.009354799365776312,
            "ave_precision_score": 0.7975826123547699,
            "fpr": 0.06037321624588365,
            "logloss": 0.4966761996077994,
            "mae": 0.3219981852399531,
            "precision": 0.8467966573816156,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5867674590109377,
            "auditor_fn_violation": 0.0014990569730614566,
            "auditor_fp_violation": 0.003689863082527323,
            "ave_precision_score": 0.588481244733416,
            "fpr": 0.42872807017543857,
            "logloss": 1.5507585235067014,
            "mae": 0.45261058819137123,
            "precision": 0.5495391705069125,
            "recall": 0.9675456389452333
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5712712755903688,
            "auditor_fn_violation": 0.0021025261268039935,
            "auditor_fp_violation": 0.004500548847420426,
            "ave_precision_score": 0.5730408366653417,
            "fpr": 0.45773874862788144,
            "logloss": 1.6429020645529415,
            "mae": 0.4774132586696669,
            "precision": 0.5190311418685121,
            "recall": 0.9761388286334056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7858622181647231,
            "auditor_fn_violation": 0.05887913241521656,
            "auditor_fp_violation": 0.01842052924674455,
            "ave_precision_score": 0.7343126441874086,
            "fpr": 0.06140350877192982,
            "logloss": 0.7397160691252326,
            "mae": 0.4199216427178614,
            "precision": 0.7829457364341085,
            "recall": 0.40973630831643004
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7755863314008566,
            "auditor_fn_violation": 0.04961294946555833,
            "auditor_fp_violation": 0.012352725942188073,
            "ave_precision_score": 0.7269660361567765,
            "fpr": 0.04610318331503842,
            "logloss": 0.6831969928864349,
            "mae": 0.40059913487853965,
            "precision": 0.7961165048543689,
            "recall": 0.3557483731019523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7966400968997317,
            "auditor_fn_violation": 0.007410768300060494,
            "auditor_fp_violation": 0.012430389817024661,
            "ave_precision_score": 0.7929186726466477,
            "fpr": 0.0625,
            "logloss": 0.6482080063817993,
            "mae": 0.36836809989497915,
            "precision": 0.836676217765043,
            "recall": 0.592292089249493
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8284362760130349,
            "auditor_fn_violation": 0.011165056634862888,
            "auditor_fp_violation": 0.011840468349798757,
            "ave_precision_score": 0.8165931679600986,
            "fpr": 0.052689352360043906,
            "logloss": 0.599390260283208,
            "mae": 0.34680675552456625,
            "precision": 0.8504672897196262,
            "recall": 0.5921908893709328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8408933197493023,
            "auditor_fn_violation": 0.005771591758300423,
            "auditor_fp_violation": 0.011490914039274802,
            "ave_precision_score": 0.8412318770754168,
            "fpr": 0.12609649122807018,
            "logloss": 0.5163316294955639,
            "mae": 0.315303570753282,
            "precision": 0.7657841140529531,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8541514160698261,
            "auditor_fn_violation": 0.00852677922999446,
            "auditor_fp_violation": 0.012757653372362489,
            "ave_precision_score": 0.8544838041421235,
            "fpr": 0.10428100987925357,
            "logloss": 0.5287636712104979,
            "mae": 0.30633461741337725,
            "precision": 0.7855530474040632,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6569426064454897,
            "auditor_fn_violation": 0.014926070246610463,
            "auditor_fp_violation": 0.016572980781308883,
            "ave_precision_score": 0.6575156354964173,
            "fpr": 0.10526315789473684,
            "logloss": 0.7114078448509772,
            "mae": 0.4703098387833227,
            "precision": 0.6903225806451613,
            "recall": 0.4340770791075051
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6539709051031698,
            "auditor_fn_violation": 0.00015001035785806527,
            "auditor_fp_violation": 0.019343822417367974,
            "ave_precision_score": 0.6545154854898796,
            "fpr": 0.1141602634467618,
            "logloss": 0.6680928833042163,
            "mae": 0.465994563931037,
            "precision": 0.68,
            "recall": 0.4793926247288503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6691999136420702,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5395492525714967,
            "fpr": 0.4594298245614035,
            "logloss": 0.6922800326354157,
            "mae": 0.4995115718297791,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6598941838599692,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5230012948789183,
            "fpr": 0.49396267837541163,
            "logloss": 0.6925876970315527,
            "mae": 0.4996686836890672,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    }
]