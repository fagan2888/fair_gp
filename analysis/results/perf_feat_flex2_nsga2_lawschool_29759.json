[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6550071667861658,
            "auditor_fn_violation": 0.003426240332012829,
            "auditor_fp_violation": 0.01699929353585307,
            "ave_precision_score": 0.6527410116154233,
            "fpr": 0.40131578947368424,
            "logloss": 2.412768794536313,
            "mae": 0.4094128285028299,
            "precision": 0.5442092154420921,
            "recall": 0.9397849462365592
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6508487885167688,
            "auditor_fn_violation": 0.00507768042938051,
            "auditor_fp_violation": 0.012631294187419692,
            "ave_precision_score": 0.6508609166617314,
            "fpr": 0.38419319429198684,
            "logloss": 2.463734695405938,
            "mae": 0.3959785245954756,
            "precision": 0.5689655172413793,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5918590997253956,
            "auditor_fn_violation": 0.002589134125636673,
            "auditor_fp_violation": 0.013793221868990149,
            "ave_precision_score": 0.5940076557765707,
            "fpr": 0.41228070175438597,
            "logloss": 3.524280743273657,
            "mae": 0.4418750699406189,
            "precision": 0.538083538083538,
            "recall": 0.9419354838709677
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6477541420181787,
            "auditor_fn_violation": 0.004500773324892982,
            "auditor_fp_violation": 0.010901514402692736,
            "ave_precision_score": 0.6471292976401595,
            "fpr": 0.39846322722283206,
            "logloss": 3.384390648888163,
            "mae": 0.42696945424005106,
            "precision": 0.5605326876513317,
            "recall": 0.9468302658486708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6410169952563511,
            "auditor_fn_violation": 0.018925674401056414,
            "auditor_fp_violation": 0.010405628164370661,
            "ave_precision_score": 0.6432089354331537,
            "fpr": 0.11842105263157894,
            "logloss": 0.6540068916698147,
            "mae": 0.43856759003379886,
            "precision": 0.7172774869109948,
            "recall": 0.589247311827957
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6854453296705867,
            "auditor_fn_violation": 0.006830849490099425,
            "auditor_fp_violation": 0.01797410272550866,
            "ave_precision_score": 0.6859969622677766,
            "fpr": 0.1141602634467618,
            "logloss": 0.6507386657295031,
            "mae": 0.43747575124715476,
            "precision": 0.7270341207349081,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 29759,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.61023138556301,
            "mae": 0.5098684210526315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.53947492547895,
            "mae": 0.5367727771679474,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7035970099848023,
            "auditor_fn_violation": 0.003581871345029239,
            "auditor_fp_violation": 0.011188135327132146,
            "ave_precision_score": 0.7047887587521431,
            "fpr": 0.40021929824561403,
            "logloss": 1.3202231572570395,
            "mae": 0.41643973866593387,
            "precision": 0.5431789737171464,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.710634898676025,
            "auditor_fn_violation": 0.006060891759207504,
            "auditor_fp_violation": 0.017276988466400668,
            "ave_precision_score": 0.71230978334853,
            "fpr": 0.37980241492864986,
            "logloss": 1.269971117341039,
            "mae": 0.4038244577189866,
            "precision": 0.5701863354037268,
            "recall": 0.9386503067484663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5998103699877501,
            "auditor_fn_violation": 0.003435672514619884,
            "auditor_fp_violation": 0.015792417284822786,
            "ave_precision_score": 0.6018885087408108,
            "fpr": 0.40350877192982454,
            "logloss": 1.799811610235464,
            "mae": 0.4433536491307773,
            "precision": 0.5411471321695761,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6518130790215113,
            "auditor_fn_violation": 0.006348222924088453,
            "auditor_fp_violation": 0.01617409128034918,
            "ave_precision_score": 0.6533964422981022,
            "fpr": 0.38199780461031835,
            "logloss": 1.732291981339978,
            "mae": 0.4311852961713213,
            "precision": 0.5693069306930693,
            "recall": 0.9406952965235174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7564945388317847,
            "auditor_fn_violation": 0.018925674401056414,
            "auditor_fp_violation": 0.010405628164370661,
            "ave_precision_score": 0.6376863061397964,
            "fpr": 0.11842105263157894,
            "logloss": 0.6579464029182408,
            "mae": 0.4406298921492539,
            "precision": 0.7172774869109948,
            "recall": 0.589247311827957
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7665803912971323,
            "auditor_fn_violation": 0.006830849490099425,
            "auditor_fp_violation": 0.01797410272550866,
            "ave_precision_score": 0.6565222498661833,
            "fpr": 0.1141602634467618,
            "logloss": 0.6535225624360516,
            "mae": 0.4389248120994128,
            "precision": 0.7270341207349081,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5721853847589932,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.5708563604373756,
            "fpr": 0.4725877192982456,
            "logloss": 0.858241787668296,
            "mae": 0.4767429644993523,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6251085572432589,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002273424859926856,
            "ave_precision_score": 0.6276555971195574,
            "fpr": 0.4489571899012075,
            "logloss": 0.7929300814732333,
            "mae": 0.4640826938017532,
            "precision": 0.5440356744704571,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6462896818178696,
            "auditor_fn_violation": 0.01978400301829844,
            "auditor_fp_violation": 0.011943659484281176,
            "ave_precision_score": 0.6314824216629331,
            "fpr": 0.3684210526315789,
            "logloss": 5.3165557840322295,
            "mae": 0.47927407733156757,
            "precision": 0.52,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6420752548279789,
            "auditor_fn_violation": 0.025752055652455003,
            "auditor_fp_violation": 0.024794377305289227,
            "ave_precision_score": 0.6268748227608099,
            "fpr": 0.3578485181119649,
            "logloss": 5.5812463487644415,
            "mae": 0.4772906915919942,
            "precision": 0.5382436260623229,
            "recall": 0.7770961145194274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 29759,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7150191301254081,
            "auditor_fn_violation": 0.09033201282776836,
            "auditor_fp_violation": 0.10882246163507202,
            "ave_precision_score": 0.5458380571055673,
            "fpr": 0.29714912280701755,
            "logloss": 0.6859394541108077,
            "mae": 0.4939993108181577,
            "precision": 0.5586319218241043,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7259028522288918,
            "auditor_fn_violation": 0.08780885294256295,
            "auditor_fp_violation": 0.09644627798211435,
            "ave_precision_score": 0.5603870404330915,
            "fpr": 0.305159165751921,
            "logloss": 0.6859171079327231,
            "mae": 0.49390266752269213,
            "precision": 0.5683229813664596,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7260400540864707,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.7265316830692683,
            "fpr": 0.48903508771929827,
            "logloss": 3.2463629570319914,
            "mae": 0.48452171194775584,
            "precision": 0.5104281009879253,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7896035045508587,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021199556760187485,
            "ave_precision_score": 0.789976749958893,
            "fpr": 0.45554335894621295,
            "logloss": 2.9167406036428414,
            "mae": 0.45025553568711035,
            "precision": 0.540929203539823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6552626869741389,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0020458024255269026,
            "ave_precision_score": 0.6566763018459004,
            "fpr": 0.4868421052631579,
            "logloss": 2.9212189639526844,
            "mae": 0.4832884983012551,
            "precision": 0.5115511551155115,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6932194911699224,
            "auditor_fn_violation": 0.0007183279122023711,
            "auditor_fp_violation": 0.0001612727017339375,
            "ave_precision_score": 0.6963400430604835,
            "fpr": 0.4522502744237102,
            "logloss": 2.6046074797171954,
            "mae": 0.4511571789858607,
            "precision": 0.5422222222222223,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7404193066463715,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.7414258399693169,
            "fpr": 0.48903508771929827,
            "logloss": 3.137043322375795,
            "mae": 0.48350541439038097,
            "precision": 0.5104281009879253,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.8023619481829509,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0028196711077353776,
            "ave_precision_score": 0.8028065519023928,
            "fpr": 0.4544456641053787,
            "logloss": 2.8169334546989258,
            "mae": 0.4487755181312328,
            "precision": 0.5415282392026578,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6922032062404471,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5193966647497501,
            "fpr": 0.4901315789473684,
            "logloss": 0.9122166529439634,
            "mae": 0.49358263664078295,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6973763529802509,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5384800353584122,
            "fpr": 0.4632272228320527,
            "logloss": 0.8930294128649959,
            "mae": 0.4873661149608055,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7442237977752926,
            "auditor_fn_violation": 0.0006319562346727033,
            "auditor_fp_violation": 0.0013933042898073072,
            "ave_precision_score": 0.7450138299020025,
            "fpr": 0.48793859649122806,
            "logloss": 2.9566303070819075,
            "mae": 0.481790849171056,
            "precision": 0.5104510451045104,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.8041504660856305,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003001753190338221,
            "ave_precision_score": 0.8045907569980082,
            "fpr": 0.4522502744237102,
            "logloss": 2.6540254533555174,
            "mae": 0.4455842538933555,
            "precision": 0.5427302996670367,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6790494094364098,
            "auditor_fn_violation": 0.0004881154499151104,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.6799046844085311,
            "fpr": 0.48903508771929827,
            "logloss": 2.738555864099972,
            "mae": 0.4849961900495385,
            "precision": 0.5098901098901099,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.721375065937168,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026011726086119713,
            "ave_precision_score": 0.7233797663933378,
            "fpr": 0.45773874862788144,
            "logloss": 2.4776695002584677,
            "mae": 0.4534558410114536,
            "precision": 0.5397350993377483,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6517688254475934,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5390944807021075,
            "fpr": 0.4901315789473684,
            "logloss": 9.342727831461959,
            "mae": 0.4877074562143861,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6408735353069359,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005332403847654549,
            "ave_precision_score": 0.5353588907927419,
            "fpr": 0.4621295279912184,
            "logloss": 9.313965919900673,
            "mae": 0.4598085554339642,
            "precision": 0.5373626373626373,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6523318517975383,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013589622826641551,
            "ave_precision_score": 0.5396561730122803,
            "fpr": 0.48793859649122806,
            "logloss": 9.158305278817698,
            "mae": 0.4865620852889199,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6421076992042443,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00027572429651287874,
            "ave_precision_score": 0.5365905915235845,
            "fpr": 0.4588364434687157,
            "logloss": 9.154131010313861,
            "mae": 0.4579442059864013,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7111035842984067,
            "auditor_fn_violation": 0.005440011318619128,
            "auditor_fp_violation": 0.012230660543977413,
            "ave_precision_score": 0.7118118898809205,
            "fpr": 0.40131578947368424,
            "logloss": 1.3217321916495361,
            "mae": 0.40347512102736904,
            "precision": 0.5481481481481482,
            "recall": 0.9548387096774194
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.721447866493926,
            "auditor_fn_violation": 0.005602957715178494,
            "auditor_fp_violation": 0.021381638842790342,
            "ave_precision_score": 0.7211250339124025,
            "fpr": 0.3809001097694841,
            "logloss": 1.2513421765043868,
            "mae": 0.392184249485355,
            "precision": 0.5726600985221675,
            "recall": 0.950920245398773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6256624345642923,
            "auditor_fn_violation": 0.012365591397849462,
            "auditor_fp_violation": 0.0049746850347345,
            "ave_precision_score": 0.5351538319399003,
            "fpr": 0.4407894736842105,
            "logloss": 7.504250410676198,
            "mae": 0.4603548444421521,
            "precision": 0.5231316725978647,
            "recall": 0.9483870967741935
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6269089108908179,
            "auditor_fn_violation": 0.013172338090010977,
            "auditor_fp_violation": 0.006159576737193127,
            "ave_precision_score": 0.5423700373343912,
            "fpr": 0.40175631174533477,
            "logloss": 7.398221373619327,
            "mae": 0.43979580638100596,
            "precision": 0.5563636363636364,
            "recall": 0.9386503067484663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6793117825612623,
            "auditor_fn_violation": 0.06649688737973967,
            "auditor_fp_violation": 0.04003051532634719,
            "ave_precision_score": 0.6628925164712061,
            "fpr": 0.16557017543859648,
            "logloss": 2.2572364719972398,
            "mae": 0.36172130375480477,
            "precision": 0.6575963718820862,
            "recall": 0.6236559139784946
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7445873266187619,
            "auditor_fn_violation": 0.07147811681358716,
            "auditor_fp_violation": 0.03292304170720162,
            "ave_precision_score": 0.732636545727362,
            "fpr": 0.141602634467618,
            "logloss": 1.7603531631310807,
            "mae": 0.3288955175252764,
            "precision": 0.7114093959731543,
            "recall": 0.6503067484662577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.610223610803389,
            "auditor_fn_violation": 0.0029711375212224116,
            "auditor_fp_violation": 0.0140311629184819,
            "ave_precision_score": 0.6003661998900423,
            "fpr": 0.4057017543859649,
            "logloss": 1.6897307464698441,
            "mae": 0.4484962001933092,
            "precision": 0.5403726708074534,
            "recall": 0.9354838709677419
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6572971820512739,
            "auditor_fn_violation": 0.00507768042938051,
            "auditor_fp_violation": 0.011858745922661935,
            "ave_precision_score": 0.6476185897918245,
            "fpr": 0.3896816684961581,
            "logloss": 1.6265285000943925,
            "mae": 0.4385022348617628,
            "precision": 0.565483476132191,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7326556490394474,
            "auditor_fn_violation": 0.0005871533672891907,
            "auditor_fp_violation": 0.003868381804623418,
            "ave_precision_score": 0.7301378803553127,
            "fpr": 0.4780701754385965,
            "logloss": 1.2259383159685338,
            "mae": 0.42796012076238793,
            "precision": 0.5155555555555555,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7624119914731219,
            "auditor_fn_violation": 0.0018519391486467376,
            "auditor_fp_violation": 0.00011445159477893654,
            "ave_precision_score": 0.7614452776216827,
            "fpr": 0.4566410537870472,
            "logloss": 1.0492673415955756,
            "mae": 0.4088629445574286,
            "precision": 0.5388026607538803,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6536315585091582,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0020458024255269026,
            "ave_precision_score": 0.6549942371490197,
            "fpr": 0.4868421052631579,
            "logloss": 2.9331081911268355,
            "mae": 0.4833354586245198,
            "precision": 0.5115511551155115,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6905001038490689,
            "auditor_fn_violation": 0.0007183279122023711,
            "auditor_fp_violation": 0.0009260174486658648,
            "ave_precision_score": 0.693545356554937,
            "fpr": 0.45334796926454446,
            "logloss": 2.616706807277626,
            "mae": 0.4512263576895751,
            "precision": 0.5416204217536071,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7762180751562207,
            "auditor_fn_violation": 0.019418505942275045,
            "auditor_fp_violation": 0.022518544683857295,
            "ave_precision_score": 0.7766482383711817,
            "fpr": 0.16776315789473684,
            "logloss": 0.9808008519336548,
            "mae": 0.3030497749387322,
            "precision": 0.7,
            "recall": 0.7677419354838709
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8032580741597138,
            "auditor_fn_violation": 0.013713328798888393,
            "auditor_fp_violation": 0.020733946863245957,
            "ave_precision_score": 0.8039343226046641,
            "fpr": 0.15697036223929747,
            "logloss": 0.8895604989997317,
            "mae": 0.291518937169587,
            "precision": 0.723404255319149,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.65192324793351,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013589622826641551,
            "ave_precision_score": 0.5392511650339237,
            "fpr": 0.48793859649122806,
            "logloss": 9.165633739816435,
            "mae": 0.48663883041917233,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6418335697474147,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00036156299259706206,
            "ave_precision_score": 0.5363185478636658,
            "fpr": 0.45993413830954993,
            "logloss": 9.15827679471188,
            "mae": 0.45790412554910465,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6779193467367515,
            "auditor_fn_violation": 0.0004881154499151104,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.6797860541626679,
            "fpr": 0.48903508771929827,
            "logloss": 2.699779975891028,
            "mae": 0.484643508369724,
            "precision": 0.5098901098901099,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7213758143563052,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026011726086119713,
            "ave_precision_score": 0.7230161645994767,
            "fpr": 0.45773874862788144,
            "logloss": 2.4414869969456943,
            "mae": 0.45292881481549074,
            "precision": 0.5397350993377483,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.679054078809209,
            "auditor_fn_violation": 0.0004881154499151104,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.6799219479514651,
            "fpr": 0.48903508771929827,
            "logloss": 2.738592533906032,
            "mae": 0.4849964499375538,
            "precision": 0.5098901098901099,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.7213773634428358,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026011726086119713,
            "ave_precision_score": 0.7233797663933379,
            "fpr": 0.45773874862788144,
            "logloss": 2.4777016827278118,
            "mae": 0.453456263819507,
            "precision": 0.5397350993377483,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.745697376331274,
            "auditor_fn_violation": 0.0006319562346727033,
            "auditor_fp_violation": 0.0017955963734840438,
            "ave_precision_score": 0.746392524926127,
            "fpr": 0.4868421052631579,
            "logloss": 2.843340551450509,
            "mae": 0.4809281120991759,
            "precision": 0.5110132158590308,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.8028568348372491,
            "auditor_fn_violation": 0.0006150682748232802,
            "auditor_fp_violation": 0.0039563835376987995,
            "ave_precision_score": 0.803394751172134,
            "fpr": 0.45115257958287597,
            "logloss": 2.5571607135775416,
            "mae": 0.4444015748151215,
            "precision": 0.542825361512792,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7589186206881186,
            "auditor_fn_violation": 0.018925674401056414,
            "auditor_fp_violation": 0.010565073197535229,
            "ave_precision_score": 0.6331929831988319,
            "fpr": 0.11732456140350878,
            "logloss": 0.6816391816846986,
            "mae": 0.43065872406096833,
            "precision": 0.7191601049868767,
            "recall": 0.589247311827957
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7631037973404651,
            "auditor_fn_violation": 0.006830849490099425,
            "auditor_fp_violation": 0.01797410272550866,
            "ave_precision_score": 0.6445486302723402,
            "fpr": 0.1141602634467618,
            "logloss": 0.6762960529496141,
            "mae": 0.42860985855632244,
            "precision": 0.7270341207349081,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6282910673041742,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5178870682850782,
            "fpr": 0.48026315789473684,
            "logloss": 8.011703711427431,
            "mae": 0.48384683829767644,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6209883718051407,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5163241560319165,
            "fpr": 0.45993413830954993,
            "logloss": 8.38965875082413,
            "mae": 0.4768723953764734,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.8188511660659499,
            "auditor_fn_violation": 0.0020302773061686473,
            "auditor_fp_violation": 0.005016386043408304,
            "ave_precision_score": 0.8068740328713138,
            "fpr": 0.45614035087719296,
            "logloss": 3.8419808843847814,
            "mae": 0.4517353357144186,
            "precision": 0.5261958997722096,
            "recall": 0.9935483870967742
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.8513051951547679,
            "auditor_fn_violation": 0.0023435448135602356,
            "auditor_fp_violation": 0.010409892779665078,
            "ave_precision_score": 0.8440373232931278,
            "fpr": 0.433589462129528,
            "logloss": 3.3802494797924543,
            "mae": 0.4316204403021142,
            "precision": 0.5511363636363636,
            "recall": 0.9918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6745027952463635,
            "auditor_fn_violation": 0.0704183172986229,
            "auditor_fp_violation": 0.04041073040543193,
            "ave_precision_score": 0.6581091661540792,
            "fpr": 0.16228070175438597,
            "logloss": 2.2772868429533566,
            "mae": 0.3666161568210063,
            "precision": 0.6525821596244131,
            "recall": 0.5978494623655914
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7424570055256227,
            "auditor_fn_violation": 0.07429306431953023,
            "auditor_fp_violation": 0.03328200352719006,
            "ave_precision_score": 0.7304861176628208,
            "fpr": 0.13721185510428102,
            "logloss": 1.7624676752642434,
            "mae": 0.3300539203509574,
            "precision": 0.7191011235955056,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6815498785836935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6822503910980873,
            "fpr": 0.4901315789473684,
            "logloss": 2.9549995930499793,
            "mae": 0.4865031891355389,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.72193111359461,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005332403847654549,
            "ave_precision_score": 0.7236336585759602,
            "fpr": 0.4621295279912184,
            "logloss": 2.69044598585245,
            "mae": 0.4564289197695782,
            "precision": 0.5373626373626373,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6574420669359552,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5441439438459674,
            "fpr": 0.48026315789473684,
            "logloss": 9.67626779907195,
            "mae": 0.4795799026625198,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.64834797392748,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5384857711651719,
            "fpr": 0.4588364434687157,
            "logloss": 9.773622769749883,
            "mae": 0.4558656836576703,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7589186206881186,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6331929831988319,
            "fpr": 0.4901315789473684,
            "logloss": 0.68709717996568,
            "mae": 0.4327497072517872,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7631037973404651,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6445486302723402,
            "fpr": 0.4632272228320527,
            "logloss": 0.6803535605208266,
            "mae": 0.43001167788594535,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 29759,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6744904230278461,
            "auditor_fn_violation": 0.07647142048670062,
            "auditor_fp_violation": 0.03751864280387771,
            "ave_precision_score": 0.6745941771737567,
            "fpr": 0.10964912280701754,
            "logloss": 1.268135625455862,
            "mae": 0.3645533386207111,
            "precision": 0.7058823529411765,
            "recall": 0.5161290322580645
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7186681008571565,
            "auditor_fn_violation": 0.07605745725387729,
            "auditor_fp_violation": 0.03218690985896443,
            "ave_precision_score": 0.7194125346815062,
            "fpr": 0.09659714599341383,
            "logloss": 1.1694103398021831,
            "mae": 0.3608613752393006,
            "precision": 0.752112676056338,
            "recall": 0.5460122699386503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6741941796502449,
            "auditor_fn_violation": 0.012268911526127147,
            "auditor_fp_violation": 0.020139134188939922,
            "ave_precision_score": 0.5519566385542315,
            "fpr": 0.37390350877192985,
            "logloss": 8.887995396178365,
            "mae": 0.42044838724869527,
            "precision": 0.5559895833333334,
            "recall": 0.9182795698924732
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6587255851456721,
            "auditor_fn_violation": 0.017361087728041055,
            "auditor_fp_violation": 0.019142029226775444,
            "ave_precision_score": 0.5392100177844854,
            "fpr": 0.3633369923161361,
            "logloss": 9.514082684544961,
            "mae": 0.4295184447481577,
            "precision": 0.5661861074705111,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.694597489942015,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5118516381575822,
            "fpr": 0.4901315789473684,
            "logloss": 0.9096762509477739,
            "mae": 0.49365189266309406,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6957013666168306,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5276739737993804,
            "fpr": 0.4632272228320527,
            "logloss": 0.8917365861961997,
            "mae": 0.48801480735826963,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5720950305277545,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.570737214657196,
            "fpr": 0.4725877192982456,
            "logloss": 0.8596949207578269,
            "mae": 0.4767390296941525,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6250641920419094,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002273424859926856,
            "ave_precision_score": 0.6276266381524154,
            "fpr": 0.4489571899012075,
            "logloss": 0.7942308752388865,
            "mae": 0.46401684388567405,
            "precision": 0.5440356744704571,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5708191771376465,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.5779740135551159,
            "fpr": 0.4725877192982456,
            "logloss": 0.8611176346637199,
            "mae": 0.47663466413423683,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6529957277808345,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002273424859926856,
            "ave_precision_score": 0.6484983611958726,
            "fpr": 0.4489571899012075,
            "logloss": 0.7954468269449,
            "mae": 0.4638324795059786,
            "precision": 0.5440356744704571,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.583914420189489,
            "auditor_fn_violation": 0.08676428975664968,
            "auditor_fp_violation": 0.10773823540955296,
            "ave_precision_score": 0.5843937959930726,
            "fpr": 0.2883771929824561,
            "logloss": 0.6867028376761884,
            "mae": 0.4946514488312236,
            "precision": 0.5557432432432432,
            "recall": 0.7075268817204301
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5632212266279436,
            "auditor_fn_violation": 0.08685257890944355,
            "auditor_fp_violation": 0.09425088830044587,
            "ave_precision_score": 0.5647959601717903,
            "fpr": 0.2996706915477497,
            "logloss": 0.6898585276391168,
            "mae": 0.49603020202707904,
            "precision": 0.5659777424483307,
            "recall": 0.7280163599182005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7564945388317847,
            "auditor_fn_violation": 0.018925674401056414,
            "auditor_fp_violation": 0.010405628164370661,
            "ave_precision_score": 0.6376863061397964,
            "fpr": 0.11842105263157894,
            "logloss": 0.6736580932172314,
            "mae": 0.4361967058492857,
            "precision": 0.7172774869109948,
            "recall": 0.589247311827957
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7665803912971323,
            "auditor_fn_violation": 0.006830849490099425,
            "auditor_fp_violation": 0.01797410272550866,
            "ave_precision_score": 0.6565222498661833,
            "fpr": 0.1141602634467618,
            "logloss": 0.6670121344078354,
            "mae": 0.43362655293535846,
            "precision": 0.7270341207349081,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5839748439990188,
            "auditor_fn_violation": 0.08676428975664968,
            "auditor_fp_violation": 0.10773823540955296,
            "ave_precision_score": 0.5844580443178247,
            "fpr": 0.2883771929824561,
            "logloss": 0.6867348464107377,
            "mae": 0.4946855484720385,
            "precision": 0.5557432432432432,
            "recall": 0.7075268817204301
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5631752195606503,
            "auditor_fn_violation": 0.08722296673917289,
            "auditor_fp_violation": 0.09425088830044587,
            "ave_precision_score": 0.5647526772961219,
            "fpr": 0.2996706915477497,
            "logloss": 0.6898436479690833,
            "mae": 0.4960434550642313,
            "precision": 0.5666666666666667,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7193925684089497,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013589622826641551,
            "ave_precision_score": 0.7204379880134582,
            "fpr": 0.48793859649122806,
            "logloss": 2.5979569738378245,
            "mae": 0.4835243834542078,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7641488497743368,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.001628334052991099,
            "ave_precision_score": 0.7657819968585182,
            "fpr": 0.45554335894621295,
            "logloss": 2.358930515008171,
            "mae": 0.4517545331379145,
            "precision": 0.540929203539823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5846233511338352,
            "auditor_fn_violation": 0.018350311262026048,
            "auditor_fp_violation": 0.0181939047843322,
            "ave_precision_score": 0.5681153694389812,
            "fpr": 0.1699561403508772,
            "logloss": 9.912264022366065,
            "mae": 0.44928496034389404,
            "precision": 0.5788043478260869,
            "recall": 0.45806451612903226
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6469031198124939,
            "auditor_fn_violation": 0.017529445832463488,
            "auditor_fp_violation": 0.020668917548030658,
            "ave_precision_score": 0.6217961559021953,
            "fpr": 0.13611416026344675,
            "logloss": 9.414293183445125,
            "mae": 0.4224499582086011,
            "precision": 0.6507042253521127,
            "recall": 0.4723926380368098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6283989664923935,
            "auditor_fn_violation": 0.01965195246179966,
            "auditor_fp_violation": 0.01446779700930178,
            "ave_precision_score": 0.5398265921933181,
            "fpr": 0.3881578947368421,
            "logloss": 7.179076828675151,
            "mae": 0.4427349381421983,
            "precision": 0.5444015444015444,
            "recall": 0.9096774193548387
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.629773610707611,
            "auditor_fn_violation": 0.016079321359704947,
            "auditor_fp_violation": 0.0195660203619792,
            "ave_precision_score": 0.5465200273490032,
            "fpr": 0.3754116355653128,
            "logloss": 7.1451124000856465,
            "mae": 0.4271876956550885,
            "precision": 0.5676359039190898,
            "recall": 0.918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6273907610977314,
            "auditor_fn_violation": 0.01803904923599321,
            "auditor_fp_violation": 0.024738510145610113,
            "ave_precision_score": 0.5417937469970215,
            "fpr": 0.37390350877192985,
            "logloss": 6.948873257324929,
            "mae": 0.4376470324812608,
            "precision": 0.5519053876478318,
            "recall": 0.9032258064516129
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6280318052142899,
            "auditor_fn_violation": 0.019722590739406347,
            "auditor_fp_violation": 0.020169492407177164,
            "ave_precision_score": 0.5486280057588828,
            "fpr": 0.3578485181119649,
            "logloss": 6.882607454254635,
            "mae": 0.4232827227125118,
            "precision": 0.5755208333333334,
            "recall": 0.9038854805725971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5726008132942396,
            "auditor_fn_violation": 0.002475947934352009,
            "auditor_fp_violation": 0.006679520389340247,
            "ave_precision_score": 0.5718909594323747,
            "fpr": 0.4725877192982456,
            "logloss": 0.8600140502175337,
            "mae": 0.47673827334584895,
            "precision": 0.5162738496071829,
            "recall": 0.989247311827957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.62516921948747,
            "auditor_fn_violation": 0.0006352712473539718,
            "auditor_fp_violation": 0.002273424859926856,
            "ave_precision_score": 0.6280152723845804,
            "fpr": 0.4489571899012075,
            "logloss": 0.7945164560058668,
            "mae": 0.4640025044540935,
            "precision": 0.5440356744704571,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 29759,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6744794665012672,
            "auditor_fn_violation": 0.0704183172986229,
            "auditor_fp_violation": 0.0402046783625731,
            "ave_precision_score": 0.658059271510325,
            "fpr": 0.16337719298245615,
            "logloss": 2.2776238783274034,
            "mae": 0.36667638746315445,
            "precision": 0.6510538641686182,
            "recall": 0.5978494623655914
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7424214749736667,
            "auditor_fn_violation": 0.07429306431953023,
            "auditor_fp_violation": 0.03328200352719006,
            "ave_precision_score": 0.7304468593202924,
            "fpr": 0.13721185510428102,
            "logloss": 1.7627499318509097,
            "mae": 0.33011721202084093,
            "precision": 0.7191011235955056,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6741949771313529,
            "auditor_fn_violation": 0.012268911526127147,
            "auditor_fp_violation": 0.020139134188939922,
            "ave_precision_score": 0.5519563088862292,
            "fpr": 0.37390350877192985,
            "logloss": 8.888015726472549,
            "mae": 0.4204480749894255,
            "precision": 0.5559895833333334,
            "recall": 0.9182795698924732
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6587242833736231,
            "auditor_fn_violation": 0.017361087728041055,
            "auditor_fp_violation": 0.019142029226775444,
            "ave_precision_score": 0.5392087161536403,
            "fpr": 0.3633369923161361,
            "logloss": 9.514117047355251,
            "mae": 0.42951982201716116,
            "precision": 0.5661861074705111,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 29759,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.8192262851349299,
            "auditor_fn_violation": 0.0020302773061686473,
            "auditor_fp_violation": 0.007967345657207903,
            "ave_precision_score": 0.8100298693279939,
            "fpr": 0.45285087719298245,
            "logloss": 3.6001921894615245,
            "mae": 0.44886491536938894,
            "precision": 0.528,
            "recall": 0.9935483870967742
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.854827846115647,
            "auditor_fn_violation": 0.002029276351971698,
            "auditor_fp_violation": 0.010180989590107228,
            "ave_precision_score": 0.8501301185493125,
            "fpr": 0.4281009879253567,
            "logloss": 3.0890506123430552,
            "mae": 0.42535268145927063,
            "precision": 0.5542857142857143,
            "recall": 0.9918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6741941796502449,
            "auditor_fn_violation": 0.012268911526127147,
            "auditor_fp_violation": 0.020139134188939922,
            "ave_precision_score": 0.5519566385542315,
            "fpr": 0.37390350877192985,
            "logloss": 8.887997067297878,
            "mae": 0.42044851678277434,
            "precision": 0.5559895833333334,
            "recall": 0.9182795698924732
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6587255851456721,
            "auditor_fn_violation": 0.017361087728041055,
            "auditor_fp_violation": 0.019142029226775444,
            "ave_precision_score": 0.5392100177844854,
            "fpr": 0.3633369923161361,
            "logloss": 9.514084662313952,
            "mae": 0.42951851530395974,
            "precision": 0.5661861074705111,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.8264861722175284,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0035470387377840723,
            "ave_precision_score": 0.7896102247872961,
            "fpr": 0.47478070175438597,
            "logloss": 6.013719572299853,
            "mae": 0.47529801149574813,
            "precision": 0.5172798216276477,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.8539073481895976,
            "auditor_fn_violation": 0.0007183279122023711,
            "auditor_fp_violation": 0.0028820992503420678,
            "ave_precision_score": 0.8257946383786896,
            "fpr": 0.4566410537870472,
            "logloss": 5.432531072163879,
            "mae": 0.4559205665675316,
            "precision": 0.5398230088495575,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6642166059361905,
            "auditor_fn_violation": 0.0011318619128466328,
            "auditor_fp_violation": 0.004054809843400452,
            "ave_precision_score": 0.5524650634586694,
            "fpr": 0.4791666666666667,
            "logloss": 9.390370688059871,
            "mae": 0.4780575364109194,
            "precision": 0.5144444444444445,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6510615712096604,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5440127606561409,
            "fpr": 0.45993413830954993,
            "logloss": 9.465381764723421,
            "mae": 0.4552257859876991,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6742505719411775,
            "auditor_fn_violation": 0.07154310507451425,
            "auditor_fp_violation": 0.03916460614623809,
            "ave_precision_score": 0.6578519756984273,
            "fpr": 0.1611842105263158,
            "logloss": 2.2785129881760806,
            "mae": 0.3669229752628961,
            "precision": 0.6533018867924528,
            "recall": 0.5956989247311828
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7425758427955421,
            "auditor_fn_violation": 0.0737318706381221,
            "auditor_fp_violation": 0.032561478714604554,
            "ave_precision_score": 0.7305972746698042,
            "fpr": 0.13611416026344675,
            "logloss": 1.7650080715733742,
            "mae": 0.33052273246646646,
            "precision": 0.7188208616780045,
            "recall": 0.6482617586912065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6644048675567015,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5526353661808122,
            "fpr": 0.48026315789473684,
            "logloss": 9.387677154914952,
            "mae": 0.4784066622194491,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6510240476458844,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5439768418314261,
            "fpr": 0.4588364434687157,
            "logloss": 9.470662994812418,
            "mae": 0.4557638613570535,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7739949461349764,
            "auditor_fn_violation": 0.03331211092246746,
            "auditor_fp_violation": 0.019731936104242714,
            "ave_precision_score": 0.7745099035865493,
            "fpr": 0.12938596491228072,
            "logloss": 0.8063895807787365,
            "mae": 0.31212666910623577,
            "precision": 0.7330316742081447,
            "recall": 0.6967741935483871
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8271669971954112,
            "auditor_fn_violation": 0.041624857737401766,
            "auditor_fp_violation": 0.019079601084168746,
            "ave_precision_score": 0.8270553279929747,
            "fpr": 0.10208562019758508,
            "logloss": 0.7154448756585414,
            "mae": 0.28912393580480344,
            "precision": 0.7876712328767124,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6579319452992335,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5441295019654103,
            "fpr": 0.48026315789473684,
            "logloss": 9.734833900578934,
            "mae": 0.4796749391968836,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6494433226993936,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5388480411557344,
            "fpr": 0.4588364434687157,
            "logloss": 9.827514227262176,
            "mae": 0.4562239701870898,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6797176895001917,
            "auditor_fn_violation": 0.07503537068477646,
            "auditor_fp_violation": 0.04571657050904667,
            "ave_precision_score": 0.6634038766351864,
            "fpr": 0.17324561403508773,
            "logloss": 2.638645938515453,
            "mae": 0.37138057845337175,
            "precision": 0.6359447004608295,
            "recall": 0.5935483870967742
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7422012569571999,
            "auditor_fn_violation": 0.07830447675423534,
            "auditor_fp_violation": 0.03572970695189392,
            "ave_precision_score": 0.729212686416507,
            "fpr": 0.1394072447859495,
            "logloss": 2.1110749058640885,
            "mae": 0.32836127993337993,
            "precision": 0.7158836689038032,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6289566628717695,
            "auditor_fn_violation": 0.011269100169779287,
            "auditor_fp_violation": 0.006924820440362658,
            "ave_precision_score": 0.5390679886613149,
            "fpr": 0.42872807017543857,
            "logloss": 7.367493566545437,
            "mae": 0.4524422450585438,
            "precision": 0.5300480769230769,
            "recall": 0.9483870967741935
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6308530870469136,
            "auditor_fn_violation": 0.015441805337625342,
            "auditor_fp_violation": 0.007704673266708636,
            "ave_precision_score": 0.5455586359233867,
            "fpr": 0.3973655323819978,
            "logloss": 7.341288705955406,
            "mae": 0.43574794353794566,
            "precision": 0.5574572127139364,
            "recall": 0.9325153374233128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6782087140998829,
            "auditor_fn_violation": 0.0004881154499151104,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.6789249757657698,
            "fpr": 0.48903508771929827,
            "logloss": 2.7408369682363136,
            "mae": 0.484974811964652,
            "precision": 0.5098901098901099,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.720363639157962,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026011726086119713,
            "ave_precision_score": 0.7219432421382103,
            "fpr": 0.45773874862788144,
            "logloss": 2.4805528429393977,
            "mae": 0.45342630749472757,
            "precision": 0.5397350993377483,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 29759,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6267230734931666,
            "auditor_fn_violation": 0.015074985851726093,
            "auditor_fp_violation": 0.01381284587307194,
            "ave_precision_score": 0.5397407133426263,
            "fpr": 0.3848684210526316,
            "logloss": 7.061894400731316,
            "mae": 0.4404083372863712,
            "precision": 0.5465116279069767,
            "recall": 0.9096774193548387
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6280658615901809,
            "auditor_fn_violation": 0.018523881035918642,
            "auditor_fp_violation": 0.01684519381337108,
            "ave_precision_score": 0.5478908060922029,
            "fpr": 0.36443468715697036,
            "logloss": 6.954406841571429,
            "mae": 0.4251774996570204,
            "precision": 0.5732647814910026,
            "recall": 0.9120654396728016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5865360208784832,
            "auditor_fn_violation": 0.002589134125636673,
            "auditor_fp_violation": 0.013793221868990149,
            "ave_precision_score": 0.5919012386760384,
            "fpr": 0.41228070175438597,
            "logloss": 3.7060122193990104,
            "mae": 0.44188576053865186,
            "precision": 0.538083538083538,
            "recall": 0.9419354838709677
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6412253601891862,
            "auditor_fn_violation": 0.004500773324892982,
            "auditor_fp_violation": 0.010901514402692736,
            "ave_precision_score": 0.6441440421069154,
            "fpr": 0.39846322722283206,
            "logloss": 3.561686209222414,
            "mae": 0.4269980159111249,
            "precision": 0.5605326876513317,
            "recall": 0.9468302658486708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6517688203812929,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5390967352058023,
            "fpr": 0.4901315789473684,
            "logloss": 9.34272160632759,
            "mae": 0.4877074151054809,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6408735400998772,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005332403847654549,
            "ave_precision_score": 0.5353567339691561,
            "fpr": 0.4621295279912184,
            "logloss": 9.313960647914005,
            "mae": 0.4598085155501516,
            "precision": 0.5373626373626373,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6849222431553315,
            "auditor_fn_violation": 0.061120543293718174,
            "auditor_fp_violation": 0.023222555830291612,
            "ave_precision_score": 0.6842005784385581,
            "fpr": 0.09758771929824561,
            "logloss": 1.249000373822828,
            "mae": 0.3570006696342222,
            "precision": 0.7319277108433735,
            "recall": 0.5225806451612903
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7538626869133246,
            "auditor_fn_violation": 0.060332810300822264,
            "auditor_fp_violation": 0.01532090666472446,
            "ave_precision_score": 0.754703004504029,
            "fpr": 0.07793633369923161,
            "logloss": 1.0316891299553745,
            "mae": 0.34070320241838903,
            "precision": 0.7936046511627907,
            "recall": 0.558282208588957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.8031649805375067,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.7265292995827202,
            "fpr": 0.48026315789473684,
            "logloss": 8.809901811191374,
            "mae": 0.4813506955509646,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8470212204406709,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.7883153754411132,
            "fpr": 0.45993413830954993,
            "logloss": 7.9358300808886275,
            "mae": 0.4599328126786962,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6643778032813105,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5526021006112355,
            "fpr": 0.48026315789473684,
            "logloss": 9.373098698844782,
            "mae": 0.4782842551929909,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6510417318476798,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.5439900941313236,
            "fpr": 0.45993413830954993,
            "logloss": 9.45780520227567,
            "mae": 0.45560047792681746,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6284061937899963,
            "auditor_fn_violation": 0.01803904923599321,
            "auditor_fp_violation": 0.014455532006750668,
            "ave_precision_score": 0.5428693882649971,
            "fpr": 0.38377192982456143,
            "logloss": 6.957257893267449,
            "mae": 0.439321610260282,
            "precision": 0.5454545454545454,
            "recall": 0.9032258064516129
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6283903975998535,
            "auditor_fn_violation": 0.01884937337113534,
            "auditor_fp_violation": 0.02473975268050839,
            "ave_precision_score": 0.5487305766893315,
            "fpr": 0.3633369923161361,
            "logloss": 6.917530859556408,
            "mae": 0.4210311863947104,
            "precision": 0.5750962772785623,
            "recall": 0.9161554192229039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6282264115024584,
            "auditor_fn_violation": 0.01208498396528957,
            "auditor_fp_violation": 0.017619902664939766,
            "ave_precision_score": 0.53939593751071,
            "fpr": 0.4232456140350877,
            "logloss": 7.293298224290165,
            "mae": 0.45057401839202565,
            "precision": 0.5326876513317191,
            "recall": 0.946236559139785
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6295971973414896,
            "auditor_fn_violation": 0.016175846672907144,
            "auditor_fp_violation": 0.02127238959322863,
            "ave_precision_score": 0.5466020662536952,
            "fpr": 0.3907793633369923,
            "logloss": 7.209714901355757,
            "mae": 0.43270968509128505,
            "precision": 0.561035758323058,
            "recall": 0.9304703476482618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.690568811325102,
            "auditor_fn_violation": 0.0004881154499151104,
            "auditor_fp_violation": 0.001314808273480127,
            "ave_precision_score": 0.6912397369419698,
            "fpr": 0.48793859649122806,
            "logloss": 2.627942218682769,
            "mae": 0.48396864321017474,
            "precision": 0.5104510451045104,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7379718904901831,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011445159477892716,
            "ave_precision_score": 0.7391255565823834,
            "fpr": 0.4566410537870472,
            "logloss": 2.3749662761104733,
            "mae": 0.45190998154263495,
            "precision": 0.5403314917127072,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 29759,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6741858826650804,
            "auditor_fn_violation": 0.07441992076966611,
            "auditor_fp_violation": 0.03898799010950194,
            "ave_precision_score": 0.6581697134691791,
            "fpr": 0.15460526315789475,
            "logloss": 2.2403576365858386,
            "mae": 0.36841683566369593,
            "precision": 0.656934306569343,
            "recall": 0.5806451612903226
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7430910767955519,
            "auditor_fn_violation": 0.07906321061149908,
            "auditor_fp_violation": 0.032967261641548014,
            "ave_precision_score": 0.7323334888579461,
            "fpr": 0.1251372118551043,
            "logloss": 1.717146716536735,
            "mae": 0.33465599651778477,
            "precision": 0.7253012048192771,
            "recall": 0.6155419222903885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.8090643709144957,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.7457336429579955,
            "fpr": 0.48026315789473684,
            "logloss": 8.317644609897373,
            "mae": 0.4813532720140198,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8461856154565558,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.7953253966838445,
            "fpr": 0.45993413830954993,
            "logloss": 7.640463895969446,
            "mae": 0.4599327383528164,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6284410911850853,
            "auditor_fn_violation": 0.014619883040935672,
            "auditor_fp_violation": 0.018353349817496787,
            "ave_precision_score": 0.543968483347267,
            "fpr": 0.41228070175438597,
            "logloss": 6.965051388107995,
            "mae": 0.4446782213104725,
            "precision": 0.5358024691358024,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6304227424184079,
            "auditor_fn_violation": 0.018256752843568383,
            "auditor_fp_violation": 0.021631351413217096,
            "ave_precision_score": 0.550815053140718,
            "fpr": 0.38309549945115257,
            "logloss": 6.9091849740847335,
            "mae": 0.4295066923872209,
            "precision": 0.5648379052369077,
            "recall": 0.9263803680981595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7564945388317847,
            "auditor_fn_violation": 0.002171760045274477,
            "auditor_fp_violation": 0.001238765257663171,
            "ave_precision_score": 0.6376863061397964,
            "fpr": 0.46271929824561403,
            "logloss": 0.7687302501556407,
            "mae": 0.44312352631567864,
            "precision": 0.5209988649262202,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7665803912971323,
            "auditor_fn_violation": 0.0007115935880254737,
            "auditor_fp_violation": 0.006586169045005505,
            "ave_precision_score": 0.6565222498661833,
            "fpr": 0.43907793633369924,
            "logloss": 0.7425162344388441,
            "mae": 0.4328460921374948,
            "precision": 0.5475113122171946,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6282833724376893,
            "auditor_fn_violation": 0.018555461233729486,
            "auditor_fp_violation": 0.01349640880725305,
            "ave_precision_score": 0.5380939856786486,
            "fpr": 0.39035087719298245,
            "logloss": 7.284979282038804,
            "mae": 0.44378500032747215,
            "precision": 0.5430038510911425,
            "recall": 0.9096774193548387
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6304302694404218,
            "auditor_fn_violation": 0.017785350151185576,
            "auditor_fp_violation": 0.0195660203619792,
            "ave_precision_score": 0.5456574642705906,
            "fpr": 0.3754116355653128,
            "logloss": 7.237487665239759,
            "mae": 0.4281395000516019,
            "precision": 0.5665399239543726,
            "recall": 0.9141104294478528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5999785340101431,
            "auditor_fn_violation": 0.017649971703452196,
            "auditor_fp_violation": 0.02171886651752424,
            "ave_precision_score": 0.5898670388818738,
            "fpr": 0.16228070175438597,
            "logloss": 9.530306013088495,
            "mae": 0.44122620115882083,
            "precision": 0.5922865013774105,
            "recall": 0.46236559139784944
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6530962768210812,
            "auditor_fn_violation": 0.015661793260737324,
            "auditor_fp_violation": 0.017498088138132674,
            "ave_precision_score": 0.6313021529411305,
            "fpr": 0.132821075740944,
            "logloss": 9.189786501847555,
            "mae": 0.4208091832984169,
            "precision": 0.6572237960339944,
            "recall": 0.47443762781186094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5864735484913162,
            "auditor_fn_violation": 0.01994906621392192,
            "auditor_fp_violation": 0.018419580831272812,
            "ave_precision_score": 0.5764740376615424,
            "fpr": 0.17105263157894737,
            "logloss": 9.590417747556574,
            "mae": 0.4487686501722874,
            "precision": 0.5772357723577236,
            "recall": 0.45806451612903226
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6448228971251606,
            "auditor_fn_violation": 0.01919731345360837,
            "auditor_fp_violation": 0.021116319236711926,
            "ave_precision_score": 0.6240805889731634,
            "fpr": 0.13830954994511527,
            "logloss": 9.213903394942882,
            "mae": 0.4218619247890766,
            "precision": 0.6509695290858726,
            "recall": 0.48057259713701433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7322080670137664,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006475921346991738,
            "ave_precision_score": 0.7327384402087409,
            "fpr": 0.48903508771929827,
            "logloss": 3.19670587433878,
            "mae": 0.484203515639692,
            "precision": 0.5104281009879253,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7920593621610215,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021199556760187485,
            "ave_precision_score": 0.7922217896950038,
            "fpr": 0.45554335894621295,
            "logloss": 2.87911897753282,
            "mae": 0.4497544366583171,
            "precision": 0.540929203539823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6642201134754921,
            "auditor_fn_violation": 0.0011318619128466328,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5524581688612435,
            "fpr": 0.48026315789473684,
            "logloss": 9.385552396611004,
            "mae": 0.47828906317029085,
            "precision": 0.5138734739178691,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6510494729853992,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.544005515622281,
            "fpr": 0.4588364434687157,
            "logloss": 9.463348664566436,
            "mae": 0.45516072257813456,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.8064331152515801,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.7946126647909296,
            "fpr": 0.48026315789473684,
            "logloss": 5.820286388308904,
            "mae": 0.48125644341895457,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.839632246648868,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015294894938638378,
            "ave_precision_score": 0.8296247121630286,
            "fpr": 0.45993413830954993,
            "logloss": 5.433830653753764,
            "mae": 0.4598445326384284,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6284392980452498,
            "auditor_fn_violation": 0.014619883040935672,
            "auditor_fp_violation": 0.018353349817496787,
            "ave_precision_score": 0.5439666906545301,
            "fpr": 0.41228070175438597,
            "logloss": 6.965131484873582,
            "mae": 0.44468130842065684,
            "precision": 0.5358024691358024,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6304261123808836,
            "auditor_fn_violation": 0.018256752843568383,
            "auditor_fp_violation": 0.021631351413217096,
            "ave_precision_score": 0.5508156138337852,
            "fpr": 0.38309549945115257,
            "logloss": 6.909291673506481,
            "mae": 0.42951033822885426,
            "precision": 0.5648379052369077,
            "recall": 0.9263803680981595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8156954212851519,
            "auditor_fn_violation": 0.03290416902471233,
            "auditor_fp_violation": 0.010393363161819541,
            "ave_precision_score": 0.8160044425405121,
            "fpr": 0.1074561403508772,
            "logloss": 0.9226703756953732,
            "mae": 0.2681388621204449,
            "precision": 0.7731481481481481,
            "recall": 0.7182795698924731
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8483839869469187,
            "auditor_fn_violation": 0.02690362508670443,
            "auditor_fp_violation": 0.012589675425681901,
            "ave_precision_score": 0.8479390253328433,
            "fpr": 0.0889132821075741,
            "logloss": 0.8670131234048907,
            "mae": 0.2610409236149762,
            "precision": 0.8089622641509434,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6642296617788253,
            "auditor_fn_violation": 0.0011318619128466328,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5524584725738737,
            "fpr": 0.48026315789473684,
            "logloss": 9.378336523441282,
            "mae": 0.47822717721002145,
            "precision": 0.5138734739178691,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6510968015782685,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5440470356682273,
            "fpr": 0.4588364434687157,
            "logloss": 9.457769766906575,
            "mae": 0.4551864913148493,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6586782527244525,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.544617100688134,
            "fpr": 0.48026315789473684,
            "logloss": 9.739688106789815,
            "mae": 0.4797087524151593,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6501532103685028,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5393000550089843,
            "fpr": 0.4588364434687157,
            "logloss": 9.831717264971562,
            "mae": 0.4562722869487285,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6818789072465454,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6825658485331572,
            "fpr": 0.4901315789473684,
            "logloss": 2.957955288245265,
            "mae": 0.4865241908190543,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7222719129854394,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005332403847654549,
            "ave_precision_score": 0.7239079140262881,
            "fpr": 0.4621295279912184,
            "logloss": 2.6931077386105238,
            "mae": 0.4564604409638093,
            "precision": 0.5373626373626373,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 29759,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6586704634258775,
            "auditor_fn_violation": 0.0006437464629315224,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.5446120994547132,
            "fpr": 0.48026315789473684,
            "logloss": 9.757456124571549,
            "mae": 0.479852979839371,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6501426159200858,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021121521581929166,
            "ave_precision_score": 0.5393036548324067,
            "fpr": 0.4588364434687157,
            "logloss": 9.846851108479074,
            "mae": 0.4564616918302132,
            "precision": 0.5391400220507166,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.815726692000841,
            "auditor_fn_violation": 0.03290416902471233,
            "auditor_fp_violation": 0.010393363161819541,
            "ave_precision_score": 0.8161050133220191,
            "fpr": 0.1074561403508772,
            "logloss": 0.9215465702986188,
            "mae": 0.26816332403146065,
            "precision": 0.7731481481481481,
            "recall": 0.7182795698924731
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8484406322130846,
            "auditor_fn_violation": 0.02690362508670443,
            "auditor_fp_violation": 0.013042279459580385,
            "ave_precision_score": 0.8480053709816802,
            "fpr": 0.08781558726673985,
            "logloss": 0.8661112979685449,
            "mae": 0.26100229167915157,
            "precision": 0.8108747044917257,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7696920290959692,
            "auditor_fn_violation": 0.020128277683455948,
            "auditor_fp_violation": 0.01787256171749284,
            "ave_precision_score": 0.6465892983079895,
            "fpr": 0.13925438596491227,
            "logloss": 0.6434638528003959,
            "mae": 0.43606834829245744,
            "precision": 0.7080459770114943,
            "recall": 0.6623655913978495
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7727448042415537,
            "auditor_fn_violation": 0.008633403594782254,
            "auditor_fp_violation": 0.02149088809235204,
            "ave_precision_score": 0.6577687322439685,
            "fpr": 0.1394072447859495,
            "logloss": 0.6476082577777245,
            "mae": 0.4380449110603228,
            "precision": 0.7087155963302753,
            "recall": 0.6319018404907976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6849222431553315,
            "auditor_fn_violation": 0.061120543293718174,
            "auditor_fp_violation": 0.023222555830291612,
            "ave_precision_score": 0.6842005784385581,
            "fpr": 0.09758771929824561,
            "logloss": 1.2489986647952387,
            "mae": 0.357000531783065,
            "precision": 0.7319277108433735,
            "recall": 0.5225806451612903
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7538626869133246,
            "auditor_fn_violation": 0.060332810300822264,
            "auditor_fp_violation": 0.01532090666472446,
            "ave_precision_score": 0.754703004504029,
            "fpr": 0.07793633369923161,
            "logloss": 1.0316881334635137,
            "mae": 0.3407033562371248,
            "precision": 0.7936046511627907,
            "recall": 0.558282208588957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.8153004465339158,
            "auditor_fn_violation": 0.008830880965855499,
            "auditor_fp_violation": 0.001155363240315554,
            "ave_precision_score": 0.8156774328581671,
            "fpr": 0.003289473684210526,
            "logloss": 3.7360529874373887,
            "mae": 0.4611895953252687,
            "precision": 0.9302325581395349,
            "recall": 0.08602150537634409
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.8472656472871072,
            "auditor_fn_violation": 0.014936731024358062,
            "auditor_fp_violation": 0.0012069440903959506,
            "ave_precision_score": 0.8478604348974399,
            "fpr": 0.0021953896816684962,
            "logloss": 3.94782697741382,
            "mae": 0.4801076648195534,
            "precision": 0.9629629629629629,
            "recall": 0.10633946830265849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.668840665624365,
            "auditor_fn_violation": 0.0011318619128466328,
            "auditor_fp_violation": 0.011659111425095191,
            "ave_precision_score": 0.5585818841705223,
            "fpr": 0.46600877192982454,
            "logloss": 9.119942394530083,
            "mae": 0.46492070312562744,
            "precision": 0.5213963963963963,
            "recall": 0.9956989247311828
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6523556232567723,
            "auditor_fn_violation": 0.0011852410551339123,
            "auditor_fp_violation": 0.004432398125074785,
            "ave_precision_score": 0.5458052599439236,
            "fpr": 0.4445664105378705,
            "logloss": 9.378367829536552,
            "mae": 0.442905756427145,
            "precision": 0.5454545454545454,
            "recall": 0.9938650306748467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.8162338383890809,
            "auditor_fn_violation": 0.022087813620071693,
            "auditor_fp_violation": 0.0029583186153302726,
            "ave_precision_score": 0.8166054352943521,
            "fpr": 0.013157894736842105,
            "logloss": 2.114466318916832,
            "mae": 0.3817974102299968,
            "precision": 0.9142857142857143,
            "recall": 0.2752688172043011
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.8476857292918337,
            "auditor_fn_violation": 0.022735078421205052,
            "auditor_fp_violation": 0.0028977062859937264,
            "ave_precision_score": 0.8482779255926082,
            "fpr": 0.008781558726673985,
            "logloss": 2.2361604371955455,
            "mae": 0.4012444886886046,
            "precision": 0.9398496240601504,
            "recall": 0.2556237218813906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6519232428573823,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013589622826641551,
            "ave_precision_score": 0.539253418834639,
            "fpr": 0.48793859649122806,
            "logloss": 9.166256871803457,
            "mae": 0.4866446940261021,
            "precision": 0.510989010989011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6418326222510298,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00036156299259706206,
            "ave_precision_score": 0.5363143972766634,
            "fpr": 0.45993413830954993,
            "logloss": 9.158812564733527,
            "mae": 0.4579114429407337,
            "precision": 0.538546255506608,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6276941646571942,
            "auditor_fn_violation": 0.015831918505942275,
            "auditor_fp_violation": 0.021336198437929284,
            "ave_precision_score": 0.5396443446912442,
            "fpr": 0.40021929824561403,
            "logloss": 7.175624827739441,
            "mae": 0.4442878347972669,
            "precision": 0.5426065162907269,
            "recall": 0.9311827956989247
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6299496631289417,
            "auditor_fn_violation": 0.017280275837918285,
            "auditor_fp_violation": 0.020216313514132174,
            "ave_precision_score": 0.5482620789191873,
            "fpr": 0.38199780461031835,
            "logloss": 7.066046326723918,
            "mae": 0.4270177692382951,
            "precision": 0.565,
            "recall": 0.9243353783231084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7440081416596129,
            "auditor_fn_violation": 0.0006319562346727033,
            "auditor_fp_violation": 0.0011921582479689176,
            "ave_precision_score": 0.7448256515643383,
            "fpr": 0.48793859649122806,
            "logloss": 2.844480726201807,
            "mae": 0.48099701338562,
            "precision": 0.5104510451045104,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.8030197283395359,
            "auditor_fn_violation": 0.0006150682748232802,
            "auditor_fp_violation": 0.003001753190338221,
            "ave_precision_score": 0.8036105147633458,
            "fpr": 0.4522502744237102,
            "logloss": 2.5555460317791296,
            "mae": 0.44468017814974337,
            "precision": 0.5422222222222223,
            "recall": 0.9979550102249489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.674266668066936,
            "auditor_fn_violation": 0.07154310507451425,
            "auditor_fp_violation": 0.03916460614623809,
            "ave_precision_score": 0.657851263583788,
            "fpr": 0.1611842105263158,
            "logloss": 2.278582798359378,
            "mae": 0.3669207401808543,
            "precision": 0.6533018867924528,
            "recall": 0.5956989247311828
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7425821281906746,
            "auditor_fn_violation": 0.0737318706381221,
            "auditor_fp_violation": 0.032561478714604554,
            "ave_precision_score": 0.7306076024728472,
            "fpr": 0.13611416026344675,
            "logloss": 1.76504760151724,
            "mae": 0.3305395929025638,
            "precision": 0.7188208616780045,
            "recall": 0.6482617586912065
        }
    }
]