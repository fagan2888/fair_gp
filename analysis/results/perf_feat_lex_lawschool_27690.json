[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8054027166753011,
            "auditor_fn_violation": 0.012280701754385972,
            "auditor_fp_violation": 0.014314605162792569,
            "ave_precision_score": 0.805815166110788,
            "fpr": 0.10197368421052631,
            "logloss": 0.6155091211889295,
            "mae": 0.3291244725960226,
            "precision": 0.7842227378190255,
            "recall": 0.7115789473684211
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8148826719113557,
            "auditor_fn_violation": 0.015081272959353211,
            "auditor_fp_violation": 0.015261007439931702,
            "ave_precision_score": 0.8152411926630675,
            "fpr": 0.11086717892425905,
            "logloss": 0.6704764338730683,
            "mae": 0.3288385923144881,
            "precision": 0.7662037037037037,
            "recall": 0.6910229645093946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7660444357705367,
            "auditor_fn_violation": 0.008520313942751625,
            "auditor_fp_violation": 0.01833172748805652,
            "ave_precision_score": 0.7668095331563832,
            "fpr": 0.09649122807017543,
            "logloss": 0.5964578954307271,
            "mae": 0.34409023865673427,
            "precision": 0.7690288713910761,
            "recall": 0.6168421052631579
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7618857860559312,
            "auditor_fn_violation": 0.0025483020104544512,
            "auditor_fp_violation": 0.013131682725535635,
            "ave_precision_score": 0.7628654479185506,
            "fpr": 0.08781558726673985,
            "logloss": 0.6041764269625831,
            "mae": 0.3425665922804391,
            "precision": 0.7889182058047494,
            "recall": 0.6242171189979123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8076177685598359,
            "auditor_fn_violation": 0.006911357340720223,
            "auditor_fp_violation": 0.015503934320928182,
            "ave_precision_score": 0.8079694113106914,
            "fpr": 0.11513157894736842,
            "logloss": 0.5670732602458203,
            "mae": 0.337646353732891,
            "precision": 0.7608200455580866,
            "recall": 0.7031578947368421
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8006775222422672,
            "auditor_fn_violation": 0.010332997990233043,
            "auditor_fp_violation": 0.016991401390413465,
            "ave_precision_score": 0.8010574424451339,
            "fpr": 0.10647639956092206,
            "logloss": 0.5994587369129319,
            "mae": 0.3359189779626088,
            "precision": 0.7651331719128329,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8092951474275882,
            "auditor_fn_violation": 0.009397506925207756,
            "auditor_fp_violation": 0.028676883857240362,
            "ave_precision_score": 0.8096832355777206,
            "fpr": 0.1524122807017544,
            "logloss": 0.535700339740722,
            "mae": 0.3216082644337388,
            "precision": 0.7377358490566037,
            "recall": 0.8231578947368421
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8129326310524745,
            "auditor_fn_violation": 0.008944265060075306,
            "auditor_fp_violation": 0.019778834817254138,
            "ave_precision_score": 0.8132891404189276,
            "fpr": 0.14928649835345773,
            "logloss": 0.5371131535507843,
            "mae": 0.3178672573028764,
            "precision": 0.7409523809523809,
            "recall": 0.8121085594989561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8112157396673686,
            "auditor_fn_violation": 0.005974145891043402,
            "auditor_fp_violation": 0.03023756473563773,
            "ave_precision_score": 0.8115819403780865,
            "fpr": 0.14473684210526316,
            "logloss": 0.5353445977680076,
            "mae": 0.3218111354288882,
            "precision": 0.7461538461538462,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8138912458883878,
            "auditor_fn_violation": 0.007615114730881434,
            "auditor_fp_violation": 0.016096983371955937,
            "ave_precision_score": 0.8142498898212969,
            "fpr": 0.145993413830955,
            "logloss": 0.5363545466909952,
            "mae": 0.31858428148194967,
            "precision": 0.74373795761079,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8721252781906708,
            "auditor_fn_violation": 0.007500000000000003,
            "auditor_fp_violation": 0.027073547713677787,
            "ave_precision_score": 0.8724689800479172,
            "fpr": 0.17982456140350878,
            "logloss": 0.5179943296653582,
            "mae": 0.3029764276309658,
            "precision": 0.718213058419244,
            "recall": 0.88
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.859129862541731,
            "auditor_fn_violation": 0.004984313734477014,
            "auditor_fp_violation": 0.013904134650567144,
            "ave_precision_score": 0.8593397114305901,
            "fpr": 0.16794731064763996,
            "logloss": 0.5479076765317646,
            "mae": 0.3076707948672868,
            "precision": 0.7306338028169014,
            "recall": 0.8663883089770354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8753678616201932,
            "auditor_fn_violation": 0.019203601108033246,
            "auditor_fp_violation": 0.016048416235095748,
            "ave_precision_score": 0.8757973611275753,
            "fpr": 0.09210526315789473,
            "logloss": 0.46041393234482175,
            "mae": 0.2787750848291213,
            "precision": 0.8141592920353983,
            "recall": 0.7747368421052632
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8663809048619522,
            "auditor_fn_violation": 0.017194163655071742,
            "auditor_fp_violation": 0.006415924706264994,
            "ave_precision_score": 0.8668808788050852,
            "fpr": 0.10647639956092206,
            "logloss": 0.48740375951716314,
            "mae": 0.2878654220046396,
            "precision": 0.7918454935622318,
            "recall": 0.7703549060542797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8459354841010122,
            "auditor_fn_violation": 0.012497691597414595,
            "auditor_fp_violation": 0.01543367859006785,
            "ave_precision_score": 0.8463134866178819,
            "fpr": 0.10197368421052631,
            "logloss": 0.6145139810344751,
            "mae": 0.27326459795756564,
            "precision": 0.7891156462585034,
            "recall": 0.7326315789473684
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8336700623654592,
            "auditor_fn_violation": 0.023454920033274592,
            "auditor_fp_violation": 0.0203962881652234,
            "ave_precision_score": 0.8340574528052637,
            "fpr": 0.10647639956092206,
            "logloss": 0.671682927389775,
            "mae": 0.2826137812290732,
            "precision": 0.7829977628635347,
            "recall": 0.7306889352818372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7795733054279151,
            "auditor_fn_violation": 0.005803324099722992,
            "auditor_fp_violation": 0.024717471596611675,
            "ave_precision_score": 0.7501932842141473,
            "fpr": 0.3059210526315789,
            "logloss": 2.1292048205147025,
            "mae": 0.34457957628183067,
            "precision": 0.6188524590163934,
            "recall": 0.9536842105263158
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7461632944956973,
            "auditor_fn_violation": 0.008371355435422775,
            "auditor_fp_violation": 0.02031243647599301,
            "ave_precision_score": 0.708585697849086,
            "fpr": 0.287596048298573,
            "logloss": 2.6874628138554706,
            "mae": 0.34920759204239404,
            "precision": 0.6345885634588564,
            "recall": 0.9498956158663883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8329673921806013,
            "auditor_fn_violation": 0.016325023084025867,
            "auditor_fp_violation": 0.030593861656429404,
            "ave_precision_score": 0.8334410334433768,
            "fpr": 0.09868421052631579,
            "logloss": 0.5109241098752615,
            "mae": 0.32849571239529995,
            "precision": 0.7867298578199052,
            "recall": 0.6989473684210527
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8315615178859166,
            "auditor_fn_violation": 0.021438278154497684,
            "auditor_fp_violation": 0.019092775541732734,
            "ave_precision_score": 0.8319100825029784,
            "fpr": 0.09769484083424808,
            "logloss": 0.5173888902090275,
            "mae": 0.32842311318697964,
            "precision": 0.7944572748267898,
            "recall": 0.7181628392484343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7660524671816223,
            "auditor_fn_violation": 0.004861495844875351,
            "auditor_fp_violation": 0.020700349271347708,
            "ave_precision_score": 0.7668158010303371,
            "fpr": 0.16776315789473684,
            "logloss": 0.6438933732171741,
            "mae": 0.31489880474104565,
            "precision": 0.7213114754098361,
            "recall": 0.8336842105263158
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7604015574391291,
            "auditor_fn_violation": 0.010374247483208024,
            "auditor_fp_violation": 0.010692360857015082,
            "ave_precision_score": 0.7620415557854701,
            "fpr": 0.1756311745334797,
            "logloss": 0.6950341845309748,
            "mae": 0.31375650883653294,
            "precision": 0.7168141592920354,
            "recall": 0.8455114822546973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8017150983832715,
            "auditor_fn_violation": 0.0009395198522622379,
            "auditor_fp_violation": 0.024561905335420936,
            "ave_precision_score": 0.7782922446358058,
            "fpr": 0.16557017543859648,
            "logloss": 1.785688745759272,
            "mae": 0.2828690275082847,
            "precision": 0.7145557655954632,
            "recall": 0.7957894736842105
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7801822464778756,
            "auditor_fn_violation": 0.016809168387305236,
            "auditor_fp_violation": 0.021953896816684963,
            "ave_precision_score": 0.7526289239593241,
            "fpr": 0.15806805708013172,
            "logloss": 2.0604554483341815,
            "mae": 0.2830841643012683,
            "precision": 0.7246653919694073,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8170508625569632,
            "auditor_fn_violation": 0.0016966759002770104,
            "auditor_fp_violation": 0.010214681440443213,
            "ave_precision_score": 0.8173649637610509,
            "fpr": 0.1513157894736842,
            "logloss": 0.5235283501406516,
            "mae": 0.3424672206096339,
            "precision": 0.7256461232604374,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7934497315277576,
            "auditor_fn_violation": 0.013550458442281648,
            "auditor_fp_violation": 0.01756311745334797,
            "ave_precision_score": 0.7938085285750137,
            "fpr": 0.14818880351262348,
            "logloss": 0.5463084250705922,
            "mae": 0.3473056521124598,
            "precision": 0.7321428571428571,
            "recall": 0.7703549060542797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8529791034580301,
            "auditor_fn_violation": 0.006352723915050792,
            "auditor_fp_violation": 0.015077381669276168,
            "ave_precision_score": 0.8532290332299756,
            "fpr": 0.07346491228070176,
            "logloss": 0.5183870640694035,
            "mae": 0.33118564759666025,
            "precision": 0.8227513227513228,
            "recall": 0.6547368421052632
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8306617478787524,
            "auditor_fn_violation": 0.025978014020244335,
            "auditor_fp_violation": 0.014818880351262352,
            "ave_precision_score": 0.831424999092764,
            "fpr": 0.07903402854006586,
            "logloss": 0.5459263394116618,
            "mae": 0.34156942884790437,
            "precision": 0.8105263157894737,
            "recall": 0.6430062630480167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7087385881520765,
            "auditor_fn_violation": 0.011285780240073868,
            "auditor_fp_violation": 0.012753924284395202,
            "ave_precision_score": 0.7185955738112544,
            "fpr": 0.22697368421052633,
            "logloss": 5.5986102486850795,
            "mae": 0.4563639730239581,
            "precision": 0.59251968503937,
            "recall": 0.6336842105263157
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7142745156799055,
            "auditor_fn_violation": 0.014423572710252108,
            "auditor_fp_violation": 0.013441679879660126,
            "ave_precision_score": 0.7212644756039398,
            "fpr": 0.21295279912184412,
            "logloss": 5.153164558409077,
            "mae": 0.44025514811138355,
            "precision": 0.6203522504892368,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8044287477056482,
            "auditor_fn_violation": 0.02225069252077563,
            "auditor_fp_violation": 0.017990485366734917,
            "ave_precision_score": 0.8047602993893128,
            "fpr": 0.08991228070175439,
            "logloss": 0.6657792840124439,
            "mae": 0.3398169335310724,
            "precision": 0.788659793814433,
            "recall": 0.6442105263157895
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.789626687347206,
            "auditor_fn_violation": 0.00741115890450514,
            "auditor_fp_violation": 0.014757897304549334,
            "ave_precision_score": 0.7899954058348135,
            "fpr": 0.09659714599341383,
            "logloss": 0.7472645402937591,
            "mae": 0.3427577234405563,
            "precision": 0.76657824933687,
            "recall": 0.6033402922755741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8772343908891069,
            "auditor_fn_violation": 0.010540166204986151,
            "auditor_fp_violation": 0.016517624151912966,
            "ave_precision_score": 0.8776237733654515,
            "fpr": 0.09978070175438597,
            "logloss": 0.4553888276142583,
            "mae": 0.28273221387184766,
            "precision": 0.8043010752688172,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8704860578591845,
            "auditor_fn_violation": 0.011222153727693768,
            "auditor_fp_violation": 0.00228686425173802,
            "ave_precision_score": 0.8707218556515853,
            "fpr": 0.10976948408342481,
            "logloss": 0.47042550872772637,
            "mae": 0.2851386042178888,
            "precision": 0.7916666666666666,
            "recall": 0.7933194154488518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8585800148239191,
            "auditor_fn_violation": 0.017809325946445062,
            "auditor_fp_violation": 0.019513529246457103,
            "ave_precision_score": 0.858827896612476,
            "fpr": 0.08771929824561403,
            "logloss": 0.5180378657552294,
            "mae": 0.32871306312467397,
            "precision": 0.8095238095238095,
            "recall": 0.7157894736842105
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8377962726004904,
            "auditor_fn_violation": 0.029475054369123385,
            "auditor_fp_violation": 0.021816684961580683,
            "ave_precision_score": 0.8380709654373436,
            "fpr": 0.0889132821075741,
            "logloss": 0.5669499959680327,
            "mae": 0.34183101187799286,
            "precision": 0.8029197080291971,
            "recall": 0.6889352818371608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8615369811697686,
            "auditor_fn_violation": 0.00985918744228994,
            "auditor_fp_violation": 0.024454012605885422,
            "ave_precision_score": 0.8622591621325453,
            "fpr": 0.12390350877192982,
            "logloss": 0.47349191850081124,
            "mae": 0.31454935137554185,
            "precision": 0.7650727650727651,
            "recall": 0.7747368421052632
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8670070416046083,
            "auditor_fn_violation": 0.016630420584413656,
            "auditor_fp_violation": 0.02208094483067041,
            "ave_precision_score": 0.8672812169595671,
            "fpr": 0.11306256860592755,
            "logloss": 0.4750702789558736,
            "mae": 0.3122276191509704,
            "precision": 0.7910750507099391,
            "recall": 0.81419624217119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7057726137813404,
            "auditor_fn_violation": 0.010676361957525398,
            "auditor_fp_violation": 0.01800052189971497,
            "ave_precision_score": 0.7156188748467832,
            "fpr": 0.12719298245614036,
            "logloss": 5.516608401065037,
            "mae": 0.4289931148819609,
            "precision": 0.6830601092896175,
            "recall": 0.5263157894736842
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7098079640661423,
            "auditor_fn_violation": 0.011586524248972772,
            "auditor_fp_violation": 0.015022157173639063,
            "ave_precision_score": 0.7168215751303719,
            "fpr": 0.1141602634467618,
            "logloss": 5.083492672252403,
            "mae": 0.41901368532701916,
            "precision": 0.7142857142857143,
            "recall": 0.5427974947807933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7709961635282249,
            "auditor_fn_violation": 0.007165281625115421,
            "auditor_fp_violation": 0.02814494760929785,
            "ave_precision_score": 0.7416211941280366,
            "fpr": 0.24561403508771928,
            "logloss": 2.088838606034887,
            "mae": 0.3274637567504358,
            "precision": 0.6646706586826348,
            "recall": 0.9347368421052632
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7373873657906721,
            "auditor_fn_violation": 0.00889155737460727,
            "auditor_fp_violation": 0.01572346221083872,
            "ave_precision_score": 0.6998169318981493,
            "fpr": 0.24807903402854006,
            "logloss": 2.664855268837839,
            "mae": 0.336363197027263,
            "precision": 0.6631892697466468,
            "recall": 0.9290187891440501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7031365587682161,
            "auditor_fn_violation": 0.0059441366574330586,
            "auditor_fp_violation": 0.018685515275603196,
            "ave_precision_score": 0.7036733630080869,
            "fpr": 0.22807017543859648,
            "logloss": 0.845661854950249,
            "mae": 0.3487514889913431,
            "precision": 0.6714060031595577,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7006917027596657,
            "auditor_fn_violation": 0.01147194232404227,
            "auditor_fp_violation": 0.015855592145383585,
            "ave_precision_score": 0.7012804594296121,
            "fpr": 0.2217343578485181,
            "logloss": 0.9023976428583775,
            "mae": 0.3465303135146392,
            "precision": 0.6757624398073836,
            "recall": 0.8789144050104384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 27690,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7748275080944328,
            "auditor_fn_violation": 0.00714219759926131,
            "auditor_fp_violation": 0.024642197599261322,
            "ave_precision_score": 0.7454454334886368,
            "fpr": 0.20942982456140352,
            "logloss": 1.98984178778068,
            "mae": 0.3166948764303111,
            "precision": 0.6879084967320261,
            "recall": 0.8863157894736842
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7421402028203727,
            "auditor_fn_violation": 0.015331061555701714,
            "auditor_fp_violation": 0.017060007317965618,
            "ave_precision_score": 0.7045623563441628,
            "fpr": 0.22722283205268934,
            "logloss": 2.56364638228088,
            "mae": 0.3304311990263564,
            "precision": 0.6703821656050956,
            "recall": 0.8789144050104384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.8751370155242444,
            "auditor_fn_violation": 0.004342105263157895,
            "auditor_fp_violation": 0.01820125255931591,
            "ave_precision_score": 0.8754414307888768,
            "fpr": 0.3048245614035088,
            "logloss": 0.652879260954681,
            "mae": 0.3442207266527571,
            "precision": 0.6227951153324288,
            "recall": 0.9663157894736842
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.8575560944218361,
            "auditor_fn_violation": 0.0024497615550142203,
            "auditor_fp_violation": 0.0081310728950685,
            "ave_precision_score": 0.8578193007072936,
            "fpr": 0.305159165751921,
            "logloss": 0.678648217863606,
            "mae": 0.34877331595168615,
            "precision": 0.6227951153324288,
            "recall": 0.9582463465553236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7122568337581565,
            "auditor_fn_violation": 0.004789935364727609,
            "auditor_fp_violation": 0.013208077401742352,
            "ave_precision_score": 0.7128958610960519,
            "fpr": 0.21162280701754385,
            "logloss": 0.792291541327565,
            "mae": 0.3480350899575442,
            "precision": 0.6825657894736842,
            "recall": 0.8736842105263158
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7066295225149328,
            "auditor_fn_violation": 0.006615960345487418,
            "auditor_fp_violation": 0.011251372118551041,
            "ave_precision_score": 0.7071822136564723,
            "fpr": 0.21734357848518113,
            "logloss": 0.8637463530286402,
            "mae": 0.3456229565483155,
            "precision": 0.6738056013179572,
            "recall": 0.8538622129436325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7751024376719562,
            "auditor_fn_violation": 0.0032156048014773844,
            "auditor_fp_violation": 0.018256453490706176,
            "ave_precision_score": 0.7755535549457491,
            "fpr": 0.13157894736842105,
            "logloss": 0.6261245443693909,
            "mae": 0.34421271946768583,
            "precision": 0.7424892703862661,
            "recall": 0.728421052631579
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.771034509746622,
            "auditor_fn_violation": 0.008087192261595122,
            "auditor_fp_violation": 0.014384376143432135,
            "ave_precision_score": 0.7715752681874437,
            "fpr": 0.132821075740944,
            "logloss": 0.7061244815296512,
            "mae": 0.34547449877801367,
            "precision": 0.7386609071274298,
            "recall": 0.7139874739039666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8703608401959346,
            "auditor_fn_violation": 0.012241458910433984,
            "auditor_fp_violation": 0.014939379340800517,
            "ave_precision_score": 0.8710629936863635,
            "fpr": 0.11293859649122807,
            "logloss": 0.46064862918797644,
            "mae": 0.2950882615149838,
            "precision": 0.789795918367347,
            "recall": 0.8147368421052632
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8661759222995491,
            "auditor_fn_violation": 0.005813886870973877,
            "auditor_fp_violation": 0.013561105012806442,
            "ave_precision_score": 0.8664517194686382,
            "fpr": 0.11745334796926454,
            "logloss": 0.47470795577809094,
            "mae": 0.29967366202103646,
            "precision": 0.785140562248996,
            "recall": 0.8162839248434238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7464865895364028,
            "auditor_fn_violation": 0.008991228070175442,
            "auditor_fp_violation": 0.012073949174996995,
            "ave_precision_score": 0.747300342224659,
            "fpr": 0.18969298245614036,
            "logloss": 0.6530077305835167,
            "mae": 0.34275030764636766,
            "precision": 0.7042735042735043,
            "recall": 0.8673684210526316
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.735204035979183,
            "auditor_fn_violation": 0.00659075232200271,
            "auditor_fp_violation": 0.00832418587632638,
            "ave_precision_score": 0.7368791722060695,
            "fpr": 0.20856201975850713,
            "logloss": 0.715663312613221,
            "mae": 0.342908433130426,
            "precision": 0.6833333333333333,
            "recall": 0.8559498956158664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8736695723923871,
            "auditor_fn_violation": 0.012211449676823641,
            "auditor_fp_violation": 0.022469288209081062,
            "ave_precision_score": 0.8739863618417874,
            "fpr": 0.13925438596491227,
            "logloss": 0.4852962778551278,
            "mae": 0.2972218148283053,
            "precision": 0.7603773584905661,
            "recall": 0.848421052631579
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8607963497777288,
            "auditor_fn_violation": 0.007706780270825842,
            "auditor_fp_violation": 0.011546123510997281,
            "ave_precision_score": 0.8610142775694023,
            "fpr": 0.14050493962678376,
            "logloss": 0.5226108384282505,
            "mae": 0.3053811796254903,
            "precision": 0.7598499061913696,
            "recall": 0.8455114822546973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8460538769182426,
            "auditor_fn_violation": 0.004270544783010158,
            "auditor_fp_violation": 0.024875546991047413,
            "ave_precision_score": 0.8462807929199714,
            "fpr": 0.17982456140350878,
            "logloss": 0.5360698990943593,
            "mae": 0.3184647317821354,
            "precision": 0.7112676056338029,
            "recall": 0.8505263157894737
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8323669931293217,
            "auditor_fn_violation": 0.008479062444857452,
            "auditor_fp_violation": 0.01831778265642152,
            "ave_precision_score": 0.8326842402765753,
            "fpr": 0.16794731064763996,
            "logloss": 0.5651312002936376,
            "mae": 0.31825958098209295,
            "precision": 0.7272727272727273,
            "recall": 0.8517745302713987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.8737989434027246,
            "auditor_fn_violation": 0.024030470914127428,
            "auditor_fp_violation": 0.00799158938536272,
            "ave_precision_score": 0.8742202793855856,
            "fpr": 0.08771929824561403,
            "logloss": 0.462683903286334,
            "mae": 0.30334130611082766,
            "precision": 0.8222222222222222,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8671960839210588,
            "auditor_fn_violation": 0.010614869525562086,
            "auditor_fp_violation": 0.012013660202463713,
            "ave_precision_score": 0.8675202744821562,
            "fpr": 0.10318331503841932,
            "logloss": 0.472769399779394,
            "mae": 0.3055537321188709,
            "precision": 0.8,
            "recall": 0.7849686847599165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7200804942607628,
            "auditor_fn_violation": 0.00843951985226224,
            "auditor_fp_violation": 0.025083805050383403,
            "ave_precision_score": 0.720618435751675,
            "fpr": 0.16337719298245615,
            "logloss": 0.9944665980701232,
            "mae": 0.30768293023480475,
            "precision": 0.7061143984220908,
            "recall": 0.7536842105263157
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7142652493734316,
            "auditor_fn_violation": 0.01787248865066034,
            "auditor_fp_violation": 0.01311897792413709,
            "ave_precision_score": 0.7149621929302966,
            "fpr": 0.16355653128430298,
            "logloss": 1.0806560193494197,
            "mae": 0.3071277527761224,
            "precision": 0.707843137254902,
            "recall": 0.7536534446764092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8361289946052621,
            "auditor_fn_violation": 0.040766389658356425,
            "auditor_fp_violation": 0.01938054518447148,
            "ave_precision_score": 0.8349265568732448,
            "fpr": 0.09210526315789473,
            "logloss": 2.6945212404510683,
            "mae": 0.32230669231157344,
            "precision": 0.7985611510791367,
            "recall": 0.7010526315789474
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.812736545957472,
            "auditor_fn_violation": 0.053631215782972676,
            "auditor_fp_violation": 0.01852360043907794,
            "ave_precision_score": 0.8129121349223739,
            "fpr": 0.09879253567508232,
            "logloss": 3.6159104680843357,
            "mae": 0.3481535952666085,
            "precision": 0.7788697788697788,
            "recall": 0.6617954070981211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8372953555835592,
            "auditor_fn_violation": 0.012294552169898429,
            "auditor_fp_violation": 0.008470833835159987,
            "ave_precision_score": 0.83758312445366,
            "fpr": 0.05263157894736842,
            "logloss": 0.6404052884642643,
            "mae": 0.32856996450836157,
            "precision": 0.8523076923076923,
            "recall": 0.5831578947368421
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8269187163992444,
            "auditor_fn_violation": 0.0168893757347566,
            "auditor_fp_violation": 0.00798115623856568,
            "ave_precision_score": 0.8271860775717017,
            "fpr": 0.06256860592755215,
            "logloss": 0.7266624656126977,
            "mae": 0.3368005411301074,
            "precision": 0.8240740740740741,
            "recall": 0.55741127348643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8544746827170769,
            "auditor_fn_violation": 0.0072807017543859666,
            "auditor_fp_violation": 0.00796147978642258,
            "ave_precision_score": 0.8547167193830927,
            "fpr": 0.0625,
            "logloss": 0.5494707255258668,
            "mae": 0.320766337044623,
            "precision": 0.85,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8524866874256483,
            "auditor_fn_violation": 0.0016568546344951178,
            "auditor_fp_violation": 0.011881530267918852,
            "ave_precision_score": 0.8527490866595447,
            "fpr": 0.07464324917672886,
            "logloss": 0.5886392360317242,
            "mae": 0.3227296943742799,
            "precision": 0.8242894056847545,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8307886725196617,
            "auditor_fn_violation": 0.0027008310249307522,
            "auditor_fp_violation": 0.019960154964069218,
            "ave_precision_score": 0.8311187956920321,
            "fpr": 0.20723684210526316,
            "logloss": 0.7561973920590416,
            "mae": 0.29340909525912967,
            "precision": 0.6855241264559068,
            "recall": 0.8673684210526316
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8200153456848874,
            "auditor_fn_violation": 0.009961752553458202,
            "auditor_fp_violation": 0.017339512948733586,
            "ave_precision_score": 0.8203739501277458,
            "fpr": 0.2030735455543359,
            "logloss": 0.7856380835042208,
            "mae": 0.28988815388060113,
            "precision": 0.6916666666666667,
            "recall": 0.8663883089770354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8732950395457691,
            "auditor_fn_violation": 0.006904432132963993,
            "auditor_fp_violation": 0.02286322212854791,
            "ave_precision_score": 0.8736105920696196,
            "fpr": 0.1425438596491228,
            "logloss": 0.49154985786626093,
            "mae": 0.29923848028594674,
            "precision": 0.7565543071161048,
            "recall": 0.8505263157894737
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8597624637280739,
            "auditor_fn_violation": 0.006315755702169494,
            "auditor_fp_violation": 0.015123795584827425,
            "ave_precision_score": 0.8599849833658053,
            "fpr": 0.14050493962678376,
            "logloss": 0.5272927386735154,
            "mae": 0.3054000075088441,
            "precision": 0.7566539923954373,
            "recall": 0.8308977035490606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8352638871129265,
            "auditor_fn_violation": 0.04083564173591874,
            "auditor_fp_violation": 0.018329218354811518,
            "ave_precision_score": 0.8339354789414524,
            "fpr": 0.07675438596491228,
            "logloss": 2.755321371084558,
            "mae": 0.31822701955051896,
            "precision": 0.8214285714285714,
            "recall": 0.6778947368421052
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8085576830534453,
            "auditor_fn_violation": 0.0540895434826947,
            "auditor_fp_violation": 0.01752246208887263,
            "ave_precision_score": 0.8087538464674224,
            "fpr": 0.08342480790340286,
            "logloss": 3.643883465318253,
            "mae": 0.3413993803032522,
            "precision": 0.8,
            "recall": 0.6346555323590815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8737363468625894,
            "auditor_fn_violation": 0.014946906740535556,
            "auditor_fp_violation": 0.016999377734955242,
            "ave_precision_score": 0.8740356861815451,
            "fpr": 0.10635964912280702,
            "logloss": 0.4567718248338336,
            "mae": 0.293867506068445,
            "precision": 0.7962184873949579,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.872470364687841,
            "auditor_fn_violation": 0.005410558495218499,
            "auditor_fp_violation": 0.001994653819571495,
            "ave_precision_score": 0.8726871864924555,
            "fpr": 0.11306256860592755,
            "logloss": 0.4637152657465663,
            "mae": 0.2955847622706063,
            "precision": 0.7880658436213992,
            "recall": 0.7995824634655533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8051728086351171,
            "auditor_fn_violation": 0.010724838411819022,
            "auditor_fp_violation": 0.028084728411417566,
            "ave_precision_score": 0.8055246663941137,
            "fpr": 0.1699561403508772,
            "logloss": 0.5835712872164547,
            "mae": 0.3435991739868081,
            "precision": 0.7097378277153558,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7862577413758306,
            "auditor_fn_violation": 0.008362188881428334,
            "auditor_fp_violation": 0.018963186567467583,
            "ave_precision_score": 0.7866351524548632,
            "fpr": 0.15916575192096596,
            "logloss": 0.6511130942999124,
            "mae": 0.3490546251095652,
            "precision": 0.7162426614481409,
            "recall": 0.7640918580375783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8054573466499935,
            "auditor_fn_violation": 0.030932594644506,
            "auditor_fp_violation": 0.03461349311493838,
            "ave_precision_score": 0.8060600502471814,
            "fpr": 0.13925438596491227,
            "logloss": 0.8376357911788319,
            "mae": 0.3309388783296937,
            "precision": 0.7337526205450734,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7823840867309652,
            "auditor_fn_violation": 0.04180636113014445,
            "auditor_fp_violation": 0.02891358702280766,
            "ave_precision_score": 0.7839581792406383,
            "fpr": 0.11306256860592755,
            "logloss": 1.1911911501718353,
            "mae": 0.3387013361820881,
            "precision": 0.7659090909090909,
            "recall": 0.7035490605427975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8423394371490909,
            "auditor_fn_violation": 0.02286241920590951,
            "auditor_fp_violation": 0.01705206953310049,
            "ave_precision_score": 0.8431578895633645,
            "fpr": 0.10855263157894737,
            "logloss": 1.9446237903991122,
            "mae": 0.32932195670723,
            "precision": 0.7828947368421053,
            "recall": 0.751578947368421
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8427927188520914,
            "auditor_fn_violation": 0.003006629710176483,
            "auditor_fp_violation": 0.016170671220067493,
            "ave_precision_score": 0.843245842302541,
            "fpr": 0.10757409440175632,
            "logloss": 1.7730739506374598,
            "mae": 0.3287257252661787,
            "precision": 0.7822222222222223,
            "recall": 0.7348643006263048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8722694302236719,
            "auditor_fn_violation": 0.009418282548476457,
            "auditor_fp_violation": 0.022567144405636515,
            "ave_precision_score": 0.8725874633187767,
            "fpr": 0.13486842105263158,
            "logloss": 0.48893502846000514,
            "mae": 0.29899509020315074,
            "precision": 0.7661596958174905,
            "recall": 0.848421052631579
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8606834314660905,
            "auditor_fn_violation": 0.0074203254584995736,
            "auditor_fp_violation": 0.009879253567508238,
            "ave_precision_score": 0.8609076647100062,
            "fpr": 0.13830954994511527,
            "logloss": 0.522201445831354,
            "mae": 0.30490302292672533,
            "precision": 0.7586206896551724,
            "recall": 0.826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.74544649825726,
            "auditor_fn_violation": 0.012040627885503235,
            "auditor_fp_violation": 0.010410393833554141,
            "ave_precision_score": 0.746252480035302,
            "fpr": 0.14473684210526316,
            "logloss": 0.6502551994266503,
            "mae": 0.3345613138047619,
            "precision": 0.7338709677419355,
            "recall": 0.7663157894736842
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7372260147676402,
            "auditor_fn_violation": 0.0038522443161636195,
            "auditor_fp_violation": 0.014986583729723144,
            "ave_precision_score": 0.7388967561299078,
            "fpr": 0.15916575192096596,
            "logloss": 0.7105519792738327,
            "mae": 0.33561447774735814,
            "precision": 0.7238095238095238,
            "recall": 0.7933194154488518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7982456140350878,
            "auc_prc": 0.8811830697649523,
            "auditor_fn_violation": 0.017156048014773773,
            "auditor_fp_violation": 0.01563942751615882,
            "ave_precision_score": 0.8814575838032099,
            "fpr": 0.10087719298245613,
            "logloss": 0.4537006845166153,
            "mae": 0.30076267055783157,
            "precision": 0.8063157894736842,
            "recall": 0.8063157894736842
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8660567086259965,
            "auditor_fn_violation": 0.01203110211770314,
            "auditor_fp_violation": 0.009508273366670735,
            "ave_precision_score": 0.8663148875154126,
            "fpr": 0.10428100987925357,
            "logloss": 0.4742287343845227,
            "mae": 0.30707822048793315,
            "precision": 0.79957805907173,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8572872680168269,
            "auditor_fn_violation": 0.015549399815327797,
            "auditor_fp_violation": 0.02000030109598941,
            "ave_precision_score": 0.8575451805292922,
            "fpr": 0.08442982456140351,
            "logloss": 0.5259554594753678,
            "mae": 0.32894187859512625,
            "precision": 0.8149038461538461,
            "recall": 0.7136842105263158
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8356447741584476,
            "auditor_fn_violation": 0.029825675059410733,
            "auditor_fp_violation": 0.018889498719356027,
            "ave_precision_score": 0.8359237092360067,
            "fpr": 0.08562019758507135,
            "logloss": 0.5812925742940651,
            "mae": 0.3429002388576499,
            "precision": 0.806930693069307,
            "recall": 0.6805845511482255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8735327443151164,
            "auditor_fn_violation": 0.0075831024930747915,
            "auditor_fp_violation": 0.024905656589987557,
            "ave_precision_score": 0.8738433245724808,
            "fpr": 0.13925438596491227,
            "logloss": 0.49195120885698945,
            "mae": 0.2972670897871081,
            "precision": 0.7621722846441947,
            "recall": 0.8568421052631578
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8584478186120996,
            "auditor_fn_violation": 0.006315755702169494,
            "auditor_fp_violation": 0.013294304183437005,
            "ave_precision_score": 0.858671032487001,
            "fpr": 0.14050493962678376,
            "logloss": 0.5314446652028134,
            "mae": 0.3035992993096516,
            "precision": 0.7566539923954373,
            "recall": 0.8308977035490606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8472245569040849,
            "auditor_fn_violation": 0.005577100646352725,
            "auditor_fp_violation": 0.022245975350275005,
            "ave_precision_score": 0.8477668283465969,
            "fpr": 0.14912280701754385,
            "logloss": 0.6075072431535693,
            "mae": 0.2723134893291649,
            "precision": 0.7384615384615385,
            "recall": 0.8084210526315789
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8454930979865904,
            "auditor_fn_violation": 0.011526941648008911,
            "auditor_fp_violation": 0.014742651542871082,
            "ave_precision_score": 0.8457424146020436,
            "fpr": 0.145993413830955,
            "logloss": 0.6535240600790941,
            "mae": 0.27735380350784616,
            "precision": 0.7422480620155039,
            "recall": 0.7995824634655533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8555360086912531,
            "auditor_fn_violation": 0.0021975992613111747,
            "auditor_fp_violation": 0.017215163194026255,
            "ave_precision_score": 0.8558745194080281,
            "fpr": 0.10964912280701754,
            "logloss": 0.4927571575542933,
            "mae": 0.2930148372808553,
            "precision": 0.7920997920997921,
            "recall": 0.8021052631578948
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8574854756905402,
            "auditor_fn_violation": 0.00298600496368899,
            "auditor_fp_violation": 0.014768061145668178,
            "ave_precision_score": 0.8577406689439689,
            "fpr": 0.11745334796926454,
            "logloss": 0.49555090795638873,
            "mae": 0.29120391179218635,
            "precision": 0.779835390946502,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8572902671673781,
            "auditor_fn_violation": 0.015549399815327797,
            "auditor_fp_violation": 0.02000030109598941,
            "ave_precision_score": 0.8575485766094755,
            "fpr": 0.08442982456140351,
            "logloss": 0.5255630990775205,
            "mae": 0.3288760774032736,
            "precision": 0.8149038461538461,
            "recall": 0.7136842105263158
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8357642905057336,
            "auditor_fn_violation": 0.030183170665193916,
            "auditor_fp_violation": 0.018691303817538724,
            "ave_precision_score": 0.8360430576158864,
            "fpr": 0.08562019758507135,
            "logloss": 0.580607319432648,
            "mae": 0.34278323500114444,
            "precision": 0.8074074074074075,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.865139463875733,
            "auditor_fn_violation": 0.013640350877192984,
            "auditor_fp_violation": 0.007976534585892653,
            "ave_precision_score": 0.8655083740001875,
            "fpr": 0.05592105263157895,
            "logloss": 0.5068222470553676,
            "mae": 0.2988693868453301,
            "precision": 0.8647214854111406,
            "recall": 0.6863157894736842
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.847259300475121,
            "auditor_fn_violation": 0.012594845188361233,
            "auditor_fp_violation": 0.005305525064032202,
            "ave_precision_score": 0.8475131003396675,
            "fpr": 0.07244785949506037,
            "logloss": 0.549953527834049,
            "mae": 0.3180468806335266,
            "precision": 0.8303341902313625,
            "recall": 0.6743215031315241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7314813397301665,
            "auditor_fn_violation": 0.009609879963065561,
            "auditor_fp_violation": 0.015032217270865955,
            "ave_precision_score": 0.7323105135965944,
            "fpr": 0.16557017543859648,
            "logloss": 0.6750815531280623,
            "mae": 0.3422066267955591,
            "precision": 0.7239488117001828,
            "recall": 0.8336842105263158
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7280560859582954,
            "auditor_fn_violation": 0.005740554439018355,
            "auditor_fp_violation": 0.009193194291986827,
            "ave_precision_score": 0.7286986180377425,
            "fpr": 0.1877058177826564,
            "logloss": 0.7313523585259124,
            "mae": 0.33847252251713256,
            "precision": 0.6978798586572438,
            "recall": 0.824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8643617390246966,
            "auditor_fn_violation": 0.0041204986149584585,
            "auditor_fp_violation": 0.013080111606246737,
            "ave_precision_score": 0.8645711758921787,
            "fpr": 0.07894736842105263,
            "logloss": 0.5328860938401989,
            "mae": 0.30553185322749593,
            "precision": 0.8230958230958231,
            "recall": 0.7052631578947368
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8598308636049178,
            "auditor_fn_violation": 0.004690984006654926,
            "auditor_fp_violation": 0.002520632597471239,
            "ave_precision_score": 0.8600772876319805,
            "fpr": 0.07135016465422613,
            "logloss": 0.5813999487102408,
            "mae": 0.3085474813069489,
            "precision": 0.8354430379746836,
            "recall": 0.6889352818371608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 27690,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7790228027900052,
            "auditor_fn_violation": 0.005803324099722992,
            "auditor_fp_violation": 0.02284565819583283,
            "ave_precision_score": 0.7496381657739001,
            "fpr": 0.30701754385964913,
            "logloss": 2.1374545436471935,
            "mae": 0.34489010916532653,
            "precision": 0.6180081855388813,
            "recall": 0.9536842105263158
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7458250645246779,
            "auditor_fn_violation": 0.007065121491215005,
            "auditor_fp_violation": 0.019883014188722212,
            "ave_precision_score": 0.7082449493844919,
            "fpr": 0.28869374313940727,
            "logloss": 2.696202566791506,
            "mae": 0.34983741819989406,
            "precision": 0.6347222222222222,
            "recall": 0.954070981210856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8539927835079615,
            "auditor_fn_violation": 0.006578947368421055,
            "auditor_fp_violation": 0.026830161788911643,
            "ave_precision_score": 0.8542379091745175,
            "fpr": 0.13815789473684212,
            "logloss": 0.5006456835403741,
            "mae": 0.30356798605128443,
            "precision": 0.7485029940119761,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8384219303881304,
            "auditor_fn_violation": 0.01580543072491401,
            "auditor_fp_violation": 0.018091637191527423,
            "ave_precision_score": 0.838823368536928,
            "fpr": 0.13062568605927552,
            "logloss": 0.5116097761509562,
            "mae": 0.29935432478026963,
            "precision": 0.7624750499001997,
            "recall": 0.7974947807933194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7392614819250878,
            "auditor_fn_violation": 0.00149122807017544,
            "auditor_fp_violation": 0.016755991810189094,
            "ave_precision_score": 0.7400721685666699,
            "fpr": 0.21820175438596492,
            "logloss": 0.6722790972125575,
            "mae": 0.3479524281268057,
            "precision": 0.6774716369529984,
            "recall": 0.88
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7354127221459412,
            "auditor_fn_violation": 0.007761779594792481,
            "auditor_fp_violation": 0.004624547709070217,
            "ave_precision_score": 0.7370841392529712,
            "fpr": 0.21514818880351264,
            "logloss": 0.7260720049218373,
            "mae": 0.34472907163636224,
            "precision": 0.6813008130081301,
            "recall": 0.8747390396659708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8422143397536905,
            "auditor_fn_violation": 0.04322714681440445,
            "auditor_fp_violation": 0.015255530129672009,
            "ave_precision_score": 0.8409314972498693,
            "fpr": 0.08552631578947369,
            "logloss": 2.687772620744569,
            "mae": 0.30594964812871894,
            "precision": 0.8115942028985508,
            "recall": 0.7073684210526315
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8078089411553544,
            "auditor_fn_violation": 0.056630970577653324,
            "auditor_fp_violation": 0.01564215148188804,
            "ave_precision_score": 0.8080621629031985,
            "fpr": 0.0889132821075741,
            "logloss": 3.6222080075744594,
            "mae": 0.3374819353034737,
            "precision": 0.7944162436548223,
            "recall": 0.6534446764091858
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7081182487511433,
            "auditor_fn_violation": 0.007121421975992613,
            "auditor_fp_violation": 0.014011000040146132,
            "ave_precision_score": 0.708765398869068,
            "fpr": 0.20942982456140352,
            "logloss": 0.7999490449723343,
            "mae": 0.34979593869821546,
            "precision": 0.6848184818481848,
            "recall": 0.8736842105263158
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7021697943273788,
            "auditor_fn_violation": 0.005474724373179586,
            "auditor_fp_violation": 0.007887140708216457,
            "ave_precision_score": 0.7027288782984837,
            "fpr": 0.21953896816684962,
            "logloss": 0.8726392261920654,
            "mae": 0.3470695444620925,
            "precision": 0.6721311475409836,
            "recall": 0.8559498956158664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8065619489258588,
            "auditor_fn_violation": 0.0020475530932594762,
            "auditor_fp_violation": 0.00581115259544743,
            "ave_precision_score": 0.8073336986631143,
            "fpr": 0.03837719298245614,
            "logloss": 0.6635021881352902,
            "mae": 0.382603646886102,
            "precision": 0.8776223776223776,
            "recall": 0.5284210526315789
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8130185326182537,
            "auditor_fn_violation": 0.006641168368972139,
            "auditor_fp_violation": 0.004573728503476036,
            "ave_precision_score": 0.8138156826246958,
            "fpr": 0.03951701427003293,
            "logloss": 0.6621350650052346,
            "mae": 0.3810544514049225,
            "precision": 0.8745644599303136,
            "recall": 0.524008350730689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8198866642547787,
            "auditor_fn_violation": 0.018416435826408128,
            "auditor_fp_violation": 0.02728431490625879,
            "ave_precision_score": 0.8060118670732299,
            "fpr": 0.18092105263157895,
            "logloss": 1.1868135011221006,
            "mae": 0.29085371085992,
            "precision": 0.708994708994709,
            "recall": 0.8463157894736842
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7791983978263293,
            "auditor_fn_violation": 0.022102853319094624,
            "auditor_fp_violation": 0.02119669065333172,
            "ave_precision_score": 0.7627247258498547,
            "fpr": 0.18221734357848518,
            "logloss": 1.438984499087553,
            "mae": 0.3086713097455914,
            "precision": 0.7040998217468806,
            "recall": 0.824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8734939035930427,
            "auditor_fn_violation": 0.007075253924284396,
            "auditor_fp_violation": 0.01730549199084668,
            "ave_precision_score": 0.8737480407178213,
            "fpr": 0.10416666666666667,
            "logloss": 0.4690711716086575,
            "mae": 0.3062159398028406,
            "precision": 0.7956989247311828,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8640053298173043,
            "auditor_fn_violation": 0.013536708611289987,
            "auditor_fp_violation": 0.013467089482457211,
            "ave_precision_score": 0.864241563149949,
            "fpr": 0.11306256860592755,
            "logloss": 0.4822829788297568,
            "mae": 0.30836058124995963,
            "precision": 0.7836134453781513,
            "recall": 0.778705636743215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8019230677282028,
            "auditor_fn_violation": 0.00329409048938135,
            "auditor_fp_violation": 0.02197749809305874,
            "ave_precision_score": 0.7783374406563288,
            "fpr": 0.15350877192982457,
            "logloss": 1.8383244602088318,
            "mae": 0.2806054576399925,
            "precision": 0.7265625,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7817455274495522,
            "auditor_fn_violation": 0.015415852180150291,
            "auditor_fp_violation": 0.021984388340041475,
            "ave_precision_score": 0.7533387568892251,
            "fpr": 0.15148188803512624,
            "logloss": 2.1167476506604803,
            "mae": 0.2821387795378557,
            "precision": 0.7335907335907336,
            "recall": 0.7933194154488518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 27690,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8400003245375973,
            "auditor_fn_violation": 0.03703139427516159,
            "auditor_fp_violation": 0.014979525472720705,
            "ave_precision_score": 0.8387530520420522,
            "fpr": 0.06907894736842106,
            "logloss": 2.693456248936398,
            "mae": 0.3151367242752206,
            "precision": 0.8337730870712401,
            "recall": 0.6652631578947369
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8077566747972837,
            "auditor_fn_violation": 0.05483203435624437,
            "auditor_fp_violation": 0.019768670976135303,
            "ave_precision_score": 0.8079820324564619,
            "fpr": 0.07464324917672886,
            "logloss": 3.6218006137567262,
            "mae": 0.3434256011806441,
            "precision": 0.8191489361702128,
            "recall": 0.6430062630480167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8406330508047029,
            "auditor_fn_violation": 0.04227608494921515,
            "auditor_fp_violation": 0.017430948653097276,
            "ave_precision_score": 0.839342745800315,
            "fpr": 0.07346491228070176,
            "logloss": 2.6901775925015237,
            "mae": 0.3167256686848672,
            "precision": 0.8295165394402035,
            "recall": 0.6863157894736842
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8159436243736595,
            "auditor_fn_violation": 0.05742158585967381,
            "auditor_fp_violation": 0.019966865877952596,
            "ave_precision_score": 0.8161127009789191,
            "fpr": 0.07683863885839737,
            "logloss": 3.61499663819136,
            "mae": 0.34267873864431797,
            "precision": 0.8148148148148148,
            "recall": 0.6430062630480167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8604152433043932,
            "auditor_fn_violation": 0.006241920590951066,
            "auditor_fp_violation": 0.015812557710064633,
            "ave_precision_score": 0.8608532386366176,
            "fpr": 0.08223684210526316,
            "logloss": 0.4840964228692367,
            "mae": 0.316705424146596,
            "precision": 0.8226950354609929,
            "recall": 0.7326315789473684
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8636249693091893,
            "auditor_fn_violation": 0.009920503060483223,
            "auditor_fp_violation": 0.007917632231572958,
            "ave_precision_score": 0.8638762766780999,
            "fpr": 0.10098792535675083,
            "logloss": 0.48379185474529,
            "mae": 0.316454780246126,
            "precision": 0.8017241379310345,
            "recall": 0.7766179540709812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8710249320196113,
            "auditor_fn_violation": 0.006966759002770085,
            "auditor_fp_violation": 0.010214681440443218,
            "ave_precision_score": 0.871396244395238,
            "fpr": 0.09649122807017543,
            "logloss": 0.46364650038403316,
            "mae": 0.28679716442568687,
            "precision": 0.8061674008810573,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8687538930028383,
            "auditor_fn_violation": 0.010142791994848403,
            "auditor_fp_violation": 0.004840529332845473,
            "ave_precision_score": 0.8689687786054714,
            "fpr": 0.10208562019758508,
            "logloss": 0.47554169977119565,
            "mae": 0.28837668949085915,
            "precision": 0.8008565310492506,
            "recall": 0.7807933194154488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8258606592109029,
            "auditor_fn_violation": 0.003591874422899356,
            "auditor_fp_violation": 0.0162491468946967,
            "ave_precision_score": 0.8262115504575394,
            "fpr": 0.14692982456140352,
            "logloss": 0.6385393936037463,
            "mae": 0.2841618668663821,
            "precision": 0.7372549019607844,
            "recall": 0.791578947368421
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8255729382747468,
            "auditor_fn_violation": 0.010782159135960624,
            "auditor_fp_violation": 0.014376753262592997,
            "ave_precision_score": 0.8260049179541676,
            "fpr": 0.141602634467618,
            "logloss": 0.6453882102927765,
            "mae": 0.28160481113061947,
            "precision": 0.7455621301775148,
            "recall": 0.7891440501043842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8031294540140372,
            "auditor_fn_violation": 0.00329409048938135,
            "auditor_fp_violation": 0.02005299289413465,
            "ave_precision_score": 0.7796391189640361,
            "fpr": 0.14802631578947367,
            "logloss": 1.8046767050426253,
            "mae": 0.2785801237297312,
            "precision": 0.7337278106508875,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7810362318190902,
            "auditor_fn_violation": 0.01791373814363532,
            "auditor_fp_violation": 0.0229906086108062,
            "ave_precision_score": 0.75278022132727,
            "fpr": 0.14928649835345773,
            "logloss": 2.0939905887500316,
            "mae": 0.2816620866097883,
            "precision": 0.7338551859099804,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8367514567104427,
            "auditor_fn_violation": 0.03756925207756233,
            "auditor_fp_violation": 0.024702416797141597,
            "ave_precision_score": 0.8359100482289996,
            "fpr": 0.08991228070175439,
            "logloss": 2.688541197001416,
            "mae": 0.31442353265623224,
            "precision": 0.7985257985257985,
            "recall": 0.6842105263157895
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8091322885830203,
            "auditor_fn_violation": 0.05769199920250981,
            "auditor_fp_violation": 0.02267044761556288,
            "ave_precision_score": 0.809415762831945,
            "fpr": 0.08562019758507135,
            "logloss": 3.617351926279589,
            "mae": 0.3421396822089578,
            "precision": 0.8035264483627204,
            "recall": 0.6659707724425887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8449965015462618,
            "auditor_fn_violation": 0.009492151431209602,
            "auditor_fp_violation": 0.019184832791360556,
            "ave_precision_score": 0.8452997891856558,
            "fpr": 0.18421052631578946,
            "logloss": 0.5439449859637091,
            "mae": 0.31894458710416024,
            "precision": 0.7062937062937062,
            "recall": 0.8505263157894737
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8287185759183952,
            "auditor_fn_violation": 0.009482800107248683,
            "auditor_fp_violation": 0.015720921250559017,
            "ave_precision_score": 0.8290682468626623,
            "fpr": 0.17233809001097694,
            "logloss": 0.5814329982537509,
            "mae": 0.3200526054730955,
            "precision": 0.7235915492957746,
            "recall": 0.8580375782881002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8367420489218902,
            "auditor_fn_violation": 0.03746537396121884,
            "auditor_fp_violation": 0.021786803966437836,
            "ave_precision_score": 0.8358987635956991,
            "fpr": 0.08333333333333333,
            "logloss": 2.691578169322847,
            "mae": 0.3207200834070519,
            "precision": 0.8075949367088607,
            "recall": 0.671578947368421
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8098895660548686,
            "auditor_fn_violation": 0.05623451711739376,
            "auditor_fp_violation": 0.017692706427613128,
            "ave_precision_score": 0.8101537214035804,
            "fpr": 0.08232711306256861,
            "logloss": 3.6172958232319177,
            "mae": 0.3475307584710098,
            "precision": 0.8091603053435115,
            "recall": 0.6638830897703549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.872103325586494,
            "auditor_fn_violation": 0.015618651892890129,
            "auditor_fp_violation": 0.014540427154843633,
            "ave_precision_score": 0.8724322701691581,
            "fpr": 0.10416666666666667,
            "logloss": 0.4570866903467137,
            "mae": 0.29345601005888167,
            "precision": 0.7974413646055437,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.873070763691334,
            "auditor_fn_violation": 0.007899277904709089,
            "auditor_fp_violation": 0.005366508110745212,
            "ave_precision_score": 0.8733025892806794,
            "fpr": 0.1119648737650933,
            "logloss": 0.4645103162164372,
            "mae": 0.29551313120389255,
            "precision": 0.7888198757763976,
            "recall": 0.7954070981210856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8192476393499916,
            "auditor_fn_violation": 0.005560941828254848,
            "auditor_fp_violation": 0.017839937372034202,
            "ave_precision_score": 0.8195597261645517,
            "fpr": 0.09978070175438597,
            "logloss": 0.6362337421707793,
            "mae": 0.32544233125268657,
            "precision": 0.7833333333333333,
            "recall": 0.6926315789473684
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7941006321737973,
            "auditor_fn_violation": 0.002633092634903035,
            "auditor_fp_violation": 0.00933040614709111,
            "ave_precision_score": 0.7944776289502298,
            "fpr": 0.10208562019758508,
            "logloss": 0.721843711251085,
            "mae": 0.3331718550372061,
            "precision": 0.7698019801980198,
            "recall": 0.6492693110647182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 27690,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7590777564648433,
            "auditor_fn_violation": 0.009743767313019402,
            "auditor_fp_violation": 0.025086314183628416,
            "ave_precision_score": 0.7598864683765347,
            "fpr": 0.16776315789473684,
            "logloss": 0.7167788045103408,
            "mae": 0.31864164499127484,
            "precision": 0.6952191235059761,
            "recall": 0.7347368421052631
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7550481050190054,
            "auditor_fn_violation": 0.017822072603690915,
            "auditor_fp_violation": 0.025318128227019558,
            "ave_precision_score": 0.7556909998844012,
            "fpr": 0.15367727771679474,
            "logloss": 0.7141730481067684,
            "mae": 0.30999139825304617,
            "precision": 0.716024340770791,
            "recall": 0.7369519832985386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8622364148860321,
            "auditor_fn_violation": 0.006982917820867968,
            "auditor_fp_violation": 0.011271026536593202,
            "ave_precision_score": 0.8624482871605447,
            "fpr": 0.07675438596491228,
            "logloss": 0.5410904089986365,
            "mae": 0.30539060478042857,
            "precision": 0.8241206030150754,
            "recall": 0.6905263157894737
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8556918502507519,
            "auditor_fn_violation": 0.008071150792104851,
            "auditor_fp_violation": 0.003049152335650691,
            "ave_precision_score": 0.855950806043255,
            "fpr": 0.07244785949506037,
            "logloss": 0.5921814027932588,
            "mae": 0.3092046322975808,
            "precision": 0.8320610687022901,
            "recall": 0.6826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.8541838447404504,
            "auditor_fn_violation": 0.0016297322253000933,
            "auditor_fp_violation": 0.014600646352723934,
            "ave_precision_score": 0.854475079881605,
            "fpr": 0.3256578947368421,
            "logloss": 0.7151064430622162,
            "mae": 0.35758227624178845,
            "precision": 0.6081794195250659,
            "recall": 0.9705263157894737
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.854090342242054,
            "auditor_fn_violation": 0.002101432503225481,
            "auditor_fp_violation": 0.007943041834370041,
            "ave_precision_score": 0.8543328872982908,
            "fpr": 0.3227222832052689,
            "logloss": 0.7173611742077619,
            "mae": 0.35634342765458066,
            "precision": 0.6111111111111112,
            "recall": 0.964509394572025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8270614940157147,
            "auditor_fn_violation": 0.0353162511542013,
            "auditor_fp_violation": 0.01324571440041752,
            "ave_precision_score": 0.8258156788061595,
            "fpr": 0.0537280701754386,
            "logloss": 2.7311396158687846,
            "mae": 0.340826371888849,
            "precision": 0.851963746223565,
            "recall": 0.5936842105263158
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7972278854721357,
            "auditor_fn_violation": 0.04891960702983026,
            "auditor_fp_violation": 0.016927877383420744,
            "ave_precision_score": 0.7975366021210495,
            "fpr": 0.054884742041712405,
            "logloss": 3.645869621128718,
            "mae": 0.3624105865916387,
            "precision": 0.8376623376623377,
            "recall": 0.5386221294363257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8443995202239565,
            "auditor_fn_violation": 0.010941828254847654,
            "auditor_fp_violation": 0.00798908025211771,
            "ave_precision_score": 0.8446765157197588,
            "fpr": 0.05482456140350877,
            "logloss": 0.608064544994663,
            "mae": 0.3248551059458862,
            "precision": 0.8475609756097561,
            "recall": 0.5852631578947368
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8352144798651168,
            "auditor_fn_violation": 0.017730407063746508,
            "auditor_fp_violation": 0.008153941537585887,
            "ave_precision_score": 0.835465665490231,
            "fpr": 0.06037321624588365,
            "logloss": 0.6795244803571189,
            "mae": 0.33178112972184115,
            "precision": 0.8363095238095238,
            "recall": 0.5866388308977035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8734180778141448,
            "auditor_fn_violation": 0.006904432132963993,
            "auditor_fp_violation": 0.021041591392669316,
            "ave_precision_score": 0.8737332045827286,
            "fpr": 0.14144736842105263,
            "logloss": 0.4914328545223178,
            "mae": 0.2991271650238432,
            "precision": 0.7579737335834896,
            "recall": 0.8505263157894737
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8595865414668237,
            "auditor_fn_violation": 0.006687001138944334,
            "auditor_fp_violation": 0.013439138919380417,
            "ave_precision_score": 0.8598094158032028,
            "fpr": 0.141602634467618,
            "logloss": 0.5273837695423234,
            "mae": 0.30534237146830184,
            "precision": 0.7556818181818182,
            "recall": 0.8329853862212944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7774923334432284,
            "auditor_fn_violation": 0.030334718374884592,
            "auditor_fp_violation": 0.03483931510698945,
            "ave_precision_score": 0.7782297772573497,
            "fpr": 0.13706140350877194,
            "logloss": 0.9147010375473541,
            "mae": 0.3325055240512649,
            "precision": 0.7401247401247402,
            "recall": 0.7494736842105263
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7699811899377124,
            "auditor_fn_violation": 0.04202635842601102,
            "auditor_fp_violation": 0.03381509940236614,
            "ave_precision_score": 0.771613705102193,
            "fpr": 0.12403951701427003,
            "logloss": 1.342303710841727,
            "mae": 0.34022228296024026,
            "precision": 0.7543478260869565,
            "recall": 0.7244258872651357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8386755925983683,
            "auditor_fn_violation": 0.04279085872576178,
            "auditor_fp_violation": 0.019287707254406043,
            "ave_precision_score": 0.8374725029792044,
            "fpr": 0.08991228070175439,
            "logloss": 2.690562841457379,
            "mae": 0.31872564442638224,
            "precision": 0.8019323671497585,
            "recall": 0.6989473684210527
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.814687742485148,
            "auditor_fn_violation": 0.054779326670776333,
            "auditor_fp_violation": 0.020947676545920235,
            "ave_precision_score": 0.8148554804408993,
            "fpr": 0.09549945115257959,
            "logloss": 3.613330002124591,
            "mae": 0.3455068398286645,
            "precision": 0.7835820895522388,
            "recall": 0.6576200417536534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8356911701604961,
            "auditor_fn_violation": 0.007063711911357348,
            "auditor_fp_violation": 0.026192841944678632,
            "ave_precision_score": 0.8360191975716054,
            "fpr": 0.17543859649122806,
            "logloss": 0.5164254822227435,
            "mae": 0.32148647207130826,
            "precision": 0.7158081705150977,
            "recall": 0.848421052631579
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8363735379265285,
            "auditor_fn_violation": 0.01608959389874166,
            "auditor_fp_violation": 0.022604382648290445,
            "ave_precision_score": 0.8366934010545692,
            "fpr": 0.1668496158068057,
            "logloss": 0.5249832064654292,
            "mae": 0.3182621278907285,
            "precision": 0.7290552584670231,
            "recall": 0.8538622129436325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8675891277080361,
            "auditor_fn_violation": 0.0015558633425669436,
            "auditor_fp_violation": 0.014663374683849236,
            "ave_precision_score": 0.8678672608150093,
            "fpr": 0.3717105263157895,
            "logloss": 0.8125515479257571,
            "mae": 0.37288817796415014,
            "precision": 0.5767790262172284,
            "recall": 0.9726315789473684
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.8625395968666364,
            "auditor_fn_violation": 0.0025964264189252684,
            "auditor_fp_violation": 0.021056937837947716,
            "ave_precision_score": 0.8627748478719652,
            "fpr": 0.3743139407244786,
            "logloss": 0.82081566923555,
            "mae": 0.37342293899911166,
            "precision": 0.5769230769230769,
            "recall": 0.9707724425887265
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8168690018505624,
            "auditor_fn_violation": 0.012199907663896588,
            "auditor_fp_violation": 0.012678650287044846,
            "ave_precision_score": 0.8175488515881382,
            "fpr": 0.06030701754385965,
            "logloss": 0.7110520306728441,
            "mae": 0.3408992826156293,
            "precision": 0.8493150684931506,
            "recall": 0.6526315789473685
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7912141171464191,
            "auditor_fn_violation": 0.019932671660910842,
            "auditor_fp_violation": 0.007157885107939996,
            "ave_precision_score": 0.7916077265347174,
            "fpr": 0.06915477497255763,
            "logloss": 0.9422107665938142,
            "mae": 0.371048520867105,
            "precision": 0.8194842406876791,
            "recall": 0.5970772442588727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8775479246558243,
            "auditor_fn_violation": 0.01180978762696214,
            "auditor_fp_violation": 0.02153087237544663,
            "ave_precision_score": 0.8778189115449622,
            "fpr": 0.13048245614035087,
            "logloss": 0.46073652426955336,
            "mae": 0.3023940900140524,
            "precision": 0.7693798449612403,
            "recall": 0.8357894736842105
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8642863388755295,
            "auditor_fn_violation": 0.014710027522578372,
            "auditor_fp_violation": 0.009899581249745907,
            "ave_precision_score": 0.8644895888511859,
            "fpr": 0.13611416026344675,
            "logloss": 0.48771849421655755,
            "mae": 0.31161525193090694,
            "precision": 0.7573385518590998,
            "recall": 0.8079331941544885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.859703766974772,
            "auditor_fn_violation": 0.02044321329639889,
            "auditor_fp_violation": 0.02170651170259746,
            "ave_precision_score": 0.8598990034710887,
            "fpr": 0.08771929824561403,
            "logloss": 0.5428187911723911,
            "mae": 0.3300812565691804,
            "precision": 0.8081534772182254,
            "recall": 0.7094736842105264
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8274403026603744,
            "auditor_fn_violation": 0.032445017863322094,
            "auditor_fp_violation": 0.02446944749359678,
            "ave_precision_score": 0.8277355871976083,
            "fpr": 0.08562019758507135,
            "logloss": 0.6137242742849035,
            "mae": 0.3463455582579803,
            "precision": 0.8040201005025126,
            "recall": 0.6680584551148225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8390727322374061,
            "auditor_fn_violation": 0.03668051708217914,
            "auditor_fp_violation": 0.018615259544742867,
            "ave_precision_score": 0.8380497665222097,
            "fpr": 0.07346491228070176,
            "logloss": 2.690349743382797,
            "mae": 0.3175378463945475,
            "precision": 0.8255208333333334,
            "recall": 0.6673684210526316
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8093373348253802,
            "auditor_fn_violation": 0.05625055858688404,
            "auditor_fp_violation": 0.01970260600886287,
            "ave_precision_score": 0.8096074297465932,
            "fpr": 0.07354555433589462,
            "logloss": 3.6181142631343017,
            "mae": 0.3450111469454839,
            "precision": 0.8236842105263158,
            "recall": 0.6534446764091858
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 27690,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8760797108600756,
            "auditor_fn_violation": 0.018686518928901195,
            "auditor_fp_violation": 0.0154863703882131,
            "ave_precision_score": 0.8764531700285079,
            "fpr": 0.09320175438596491,
            "logloss": 0.45818443389320646,
            "mae": 0.2797084393318265,
            "precision": 0.8140043763676149,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8692070303565965,
            "auditor_fn_violation": 0.015001065611901858,
            "auditor_fp_violation": 0.0029475139244623315,
            "ave_precision_score": 0.8694750021984918,
            "fpr": 0.10318331503841932,
            "logloss": 0.48358641899874044,
            "mae": 0.28836915707041877,
            "precision": 0.7965367965367965,
            "recall": 0.7682672233820459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8629754729803488,
            "auditor_fn_violation": 0.010422437673130194,
            "auditor_fp_violation": 0.023201955116624515,
            "ave_precision_score": 0.8632418736080026,
            "fpr": 0.1600877192982456,
            "logloss": 0.4962593291485505,
            "mae": 0.30079376599539837,
            "precision": 0.7355072463768116,
            "recall": 0.8547368421052631
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8658769086056163,
            "auditor_fn_violation": 0.01224651613657249,
            "auditor_fp_violation": 0.02268061145668171,
            "ave_precision_score": 0.8661434789632334,
            "fpr": 0.1602634467618002,
            "logloss": 0.4993016352621828,
            "mae": 0.2989742874614992,
            "precision": 0.737410071942446,
            "recall": 0.8559498956158664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8655937093607363,
            "auditor_fn_violation": 0.013388734995383192,
            "auditor_fp_violation": 0.022787948131197566,
            "ave_precision_score": 0.865785137081977,
            "fpr": 0.125,
            "logloss": 0.4790016887895215,
            "mae": 0.3265497449687437,
            "precision": 0.7644628099173554,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8507748231349764,
            "auditor_fn_violation": 0.012150267319630864,
            "auditor_fp_violation": 0.02257389112493394,
            "ave_precision_score": 0.8510869203112685,
            "fpr": 0.1163556531284303,
            "logloss": 0.48692629439184204,
            "mae": 0.32839760490162573,
            "precision": 0.7827868852459017,
            "recall": 0.7974947807933194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8556145694642789,
            "auditor_fn_violation": 0.013681902123730383,
            "auditor_fp_violation": 0.01822634389176603,
            "ave_precision_score": 0.8558418264764522,
            "fpr": 0.09539473684210527,
            "logloss": 0.5125559320181297,
            "mae": 0.30828801991368526,
            "precision": 0.7923627684964201,
            "recall": 0.6989473684210527
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8444187394056307,
            "auditor_fn_violation": 0.01772353214825068,
            "auditor_fp_violation": 0.015388055453917143,
            "ave_precision_score": 0.8447459967107537,
            "fpr": 0.09440175631174534,
            "logloss": 0.5418609239209401,
            "mae": 0.31235176573237244,
            "precision": 0.7976470588235294,
            "recall": 0.7077244258872651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 27690,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7144482703862466,
            "auditor_fn_violation": 0.007686980609418286,
            "auditor_fp_violation": 0.0044888393753261865,
            "ave_precision_score": 0.714886165891716,
            "fpr": 0.02631578947368421,
            "logloss": 2.00557179503059,
            "mae": 0.4222028180028905,
            "precision": 0.8536585365853658,
            "recall": 0.29473684210526313
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7232950279350532,
            "auditor_fn_violation": 0.022717012436722153,
            "auditor_fp_violation": 0.00570191486766679,
            "ave_precision_score": 0.7237131921168796,
            "fpr": 0.036223929747530186,
            "logloss": 2.185620488167538,
            "mae": 0.4138670731145112,
            "precision": 0.8253968253968254,
            "recall": 0.325678496868476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8679472262707032,
            "auditor_fn_violation": 0.0061172668513388775,
            "auditor_fp_violation": 0.022424123810670847,
            "ave_precision_score": 0.8682943926793708,
            "fpr": 0.13815789473684212,
            "logloss": 0.49267071522334965,
            "mae": 0.31311041139255386,
            "precision": 0.7534246575342466,
            "recall": 0.8105263157894737
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8626108599391078,
            "auditor_fn_violation": 0.010610286248564861,
            "auditor_fp_violation": 0.015520185388462011,
            "ave_precision_score": 0.8628270177802013,
            "fpr": 0.132821075740944,
            "logloss": 0.5200375306846059,
            "mae": 0.3178270648416258,
            "precision": 0.7618110236220472,
            "recall": 0.8079331941544885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8601192018231909,
            "auditor_fn_violation": 0.0036472760849492153,
            "auditor_fp_violation": 0.011584668192219679,
            "ave_precision_score": 0.8605585458404561,
            "fpr": 0.08333333333333333,
            "logloss": 0.4823184391425707,
            "mae": 0.31589255324899823,
            "precision": 0.8199052132701422,
            "recall": 0.728421052631579
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8628790995438804,
            "auditor_fn_violation": 0.004044741950046869,
            "auditor_fp_violation": 0.002657844452575517,
            "ave_precision_score": 0.8631333362317136,
            "fpr": 0.09440175631174534,
            "logloss": 0.48171393028983917,
            "mae": 0.31623783370052616,
            "precision": 0.810989010989011,
            "recall": 0.7703549060542797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8768568059569142,
            "auditor_fn_violation": 0.00753693444136658,
            "auditor_fp_violation": 0.008709201493436108,
            "ave_precision_score": 0.8771838890247314,
            "fpr": 0.09210526315789473,
            "logloss": 0.45742865100418273,
            "mae": 0.28139054983917605,
            "precision": 0.8149779735682819,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8706924673682703,
            "auditor_fn_violation": 0.0031899607900652887,
            "auditor_fp_violation": 0.008618937268772615,
            "ave_precision_score": 0.8709064655513292,
            "fpr": 0.09769484083424808,
            "logloss": 0.4754527565554298,
            "mae": 0.2850308791119871,
            "precision": 0.8098290598290598,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8610399104689487,
            "auditor_fn_violation": 0.004048938134810721,
            "auditor_fp_violation": 0.014763740013649686,
            "ave_precision_score": 0.8614769948915073,
            "fpr": 0.08442982456140351,
            "logloss": 0.48260249643629255,
            "mae": 0.3152278191338522,
            "precision": 0.8213457076566125,
            "recall": 0.7452631578947368
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8641909381549563,
            "auditor_fn_violation": 0.009244469703393229,
            "auditor_fp_violation": 0.00719599951213563,
            "ave_precision_score": 0.8644413178024094,
            "fpr": 0.10537870472008781,
            "logloss": 0.48233934570390646,
            "mae": 0.31475986756331215,
            "precision": 0.7970401691331924,
            "recall": 0.7870563674321504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 27690,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8836348049483305,
            "auditor_fn_violation": 0.016562788550323178,
            "auditor_fp_violation": 0.014106347103456585,
            "ave_precision_score": 0.8838359346117239,
            "fpr": 0.09649122807017543,
            "logloss": 0.4538432150514231,
            "mae": 0.2789462789088455,
            "precision": 0.8099352051835853,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8624926598106384,
            "auditor_fn_violation": 0.012897341470177763,
            "auditor_fp_violation": 0.010910883441070048,
            "ave_precision_score": 0.8627352106722824,
            "fpr": 0.10428100987925357,
            "logloss": 0.4861053206604837,
            "mae": 0.28840950467982474,
            "precision": 0.7970085470085471,
            "recall": 0.778705636743215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7411366274195529,
            "auditor_fn_violation": 0.009771468144044322,
            "auditor_fp_violation": 0.011715143120960298,
            "ave_precision_score": 0.7419432988839475,
            "fpr": 0.17653508771929824,
            "logloss": 0.6561341257394996,
            "mae": 0.3436971580724052,
            "precision": 0.7135231316725978,
            "recall": 0.8442105263157895
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7372716508173425,
            "auditor_fn_violation": 0.007736571571307771,
            "auditor_fp_violation": 0.004865938935642562,
            "ave_precision_score": 0.7389491404733535,
            "fpr": 0.1964873765093304,
            "logloss": 0.7137322000210107,
            "mae": 0.34104559954938723,
            "precision": 0.6897746967071057,
            "recall": 0.8308977035490606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.797276030136705,
            "auditor_fn_violation": 0.005909510618651893,
            "auditor_fp_violation": 0.017716989843028625,
            "ave_precision_score": 0.7989710222270716,
            "fpr": 0.12609649122807018,
            "logloss": 0.5402692493951516,
            "mae": 0.32589115633980553,
            "precision": 0.7578947368421053,
            "recall": 0.7578947368421053
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7750976050223624,
            "auditor_fn_violation": 0.003515373456867927,
            "auditor_fp_violation": 0.011358092450298824,
            "ave_precision_score": 0.7766618413533157,
            "fpr": 0.132821075740944,
            "logloss": 0.5663292529980536,
            "mae": 0.3316264194850406,
            "precision": 0.7540650406504065,
            "recall": 0.7745302713987474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8501900964041176,
            "auditor_fn_violation": 0.006853647276084951,
            "auditor_fp_violation": 0.010829419085471114,
            "ave_precision_score": 0.8507452199750402,
            "fpr": 0.08223684210526316,
            "logloss": 0.49800359277212136,
            "mae": 0.32332645327857645,
            "precision": 0.8205741626794258,
            "recall": 0.7221052631578947
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8555878517023559,
            "auditor_fn_violation": 0.0025895515034294377,
            "auditor_fp_violation": 0.005488474204171238,
            "ave_precision_score": 0.855858803806809,
            "fpr": 0.08342480790340286,
            "logloss": 0.4974066900983455,
            "mae": 0.3237191116361665,
            "precision": 0.8173076923076923,
            "recall": 0.7098121085594989
        }
    }
]