[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7902097104166768,
            "auditor_fn_violation": 0.017493393525655147,
            "auditor_fp_violation": 0.015512571751960554,
            "ave_precision_score": 0.7614309877772184,
            "fpr": 0.15899122807017543,
            "logloss": 2.0921441788395425,
            "mae": 0.2816970543819097,
            "precision": 0.7339449541284404,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8160003959459875,
            "auditor_fn_violation": 0.012600429853609948,
            "auditor_fp_violation": 0.026980582156781105,
            "ave_precision_score": 0.7953701137195457,
            "fpr": 0.14489571899012074,
            "logloss": 1.6830553638259684,
            "mae": 0.2731263384367513,
            "precision": 0.7426900584795322,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8005328824341225,
            "auditor_fn_violation": 0.014859979446524259,
            "auditor_fp_violation": 0.015563101301641197,
            "ave_precision_score": 0.7752575382350655,
            "fpr": 0.12938596491228072,
            "logloss": 1.8811085479121012,
            "mae": 0.3072371693295983,
            "precision": 0.7440347071583514,
            "recall": 0.7175732217573222
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.815757180018991,
            "auditor_fn_violation": 0.015049488511101484,
            "auditor_fp_violation": 0.015879985364068785,
            "ave_precision_score": 0.7955138675397184,
            "fpr": 0.1163556531284303,
            "logloss": 1.6671904460922524,
            "mae": 0.30038901993086814,
            "precision": 0.7617977528089888,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.766747432434796,
            "auditor_fn_violation": 0.006014644351464436,
            "auditor_fp_violation": 0.023708464710162514,
            "ave_precision_score": 0.694552483649105,
            "fpr": 0.20942982456140352,
            "logloss": 4.676115401631174,
            "mae": 0.3029374777930405,
            "precision": 0.6832504145936982,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7694472825616634,
            "auditor_fn_violation": 0.016691418609156065,
            "auditor_fp_violation": 0.03733928864327441,
            "ave_precision_score": 0.7022663657828213,
            "fpr": 0.19978046103183314,
            "logloss": 4.3684549210077295,
            "mae": 0.30597255771122384,
            "precision": 0.6840277777777778,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7974057337528716,
            "auditor_fn_violation": 0.015304998898920941,
            "auditor_fp_violation": 0.015969864176570467,
            "ave_precision_score": 0.7748505541391164,
            "fpr": 0.17214912280701755,
            "logloss": 1.774404563196913,
            "mae": 0.2780324682759161,
            "precision": 0.7221238938053097,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8136338183993603,
            "auditor_fn_violation": 0.013866468651126758,
            "auditor_fp_violation": 0.026677769786895802,
            "ave_precision_score": 0.7979340073679497,
            "fpr": 0.150384193194292,
            "logloss": 1.5073767991250928,
            "mae": 0.2804746532307439,
            "precision": 0.7375478927203065,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8109965462744919,
            "auditor_fn_violation": 0.0201199258606768,
            "auditor_fp_violation": 0.01855192416525184,
            "ave_precision_score": 0.8122070595831701,
            "fpr": 0.15021929824561403,
            "logloss": 0.8962953574392534,
            "mae": 0.3058159391624431,
            "precision": 0.7424812030075187,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8512490067869403,
            "auditor_fn_violation": 0.019297290815338212,
            "auditor_fp_violation": 0.018554827964722364,
            "ave_precision_score": 0.8501109427495196,
            "fpr": 0.1350164654226125,
            "logloss": 0.8269181942762098,
            "mae": 0.30625554557550294,
            "precision": 0.7592954990215264,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8657823693672229,
            "auditor_fn_violation": 0.008214508551714015,
            "auditor_fp_violation": 0.016219985447489697,
            "ave_precision_score": 0.8659984624380084,
            "fpr": 0.14692982456140352,
            "logloss": 0.49661970562452307,
            "mae": 0.31507232592986456,
            "precision": 0.7447619047619047,
            "recall": 0.8179916317991632
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8637309309184019,
            "auditor_fn_violation": 0.01699812746174211,
            "auditor_fp_violation": 0.01824696872200563,
            "ave_precision_score": 0.8639203596655011,
            "fpr": 0.14709110867178923,
            "logloss": 0.5024867068870329,
            "mae": 0.3209413138844899,
            "precision": 0.7418111753371869,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7757196234879742,
            "auditor_fn_violation": 0.015254532775453283,
            "auditor_fp_violation": 0.015037593984962409,
            "ave_precision_score": 0.7511420376965428,
            "fpr": 0.17214912280701755,
            "logloss": 2.0295597792701843,
            "mae": 0.29245002735435677,
            "precision": 0.718132854578097,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8059025099487157,
            "auditor_fn_violation": 0.013698124694444187,
            "auditor_fp_violation": 0.022890091726913718,
            "ave_precision_score": 0.7886027607131795,
            "fpr": 0.1602634467618002,
            "logloss": 1.6236610447442077,
            "mae": 0.28740155441639076,
            "precision": 0.7234848484848485,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7836179579982393,
            "auditor_fn_violation": 0.006574359539014901,
            "auditor_fp_violation": 0.018584768372544275,
            "ave_precision_score": 0.75618010645844,
            "fpr": 0.19298245614035087,
            "logloss": 2.072118983320752,
            "mae": 0.2866684737243001,
            "precision": 0.7037037037037037,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7924570477024343,
            "auditor_fn_violation": 0.017816786429171012,
            "auditor_fp_violation": 0.03506314899630317,
            "ave_precision_score": 0.7682479474613901,
            "fpr": 0.1800219538968167,
            "logloss": 1.889689535425885,
            "mae": 0.2981274592492481,
            "precision": 0.7023593466424682,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7668615287414438,
            "auditor_fn_violation": 0.023801658959113264,
            "auditor_fp_violation": 0.016972875737731423,
            "ave_precision_score": 0.7366402874825457,
            "fpr": 0.15460526315789475,
            "logloss": 2.238310143650913,
            "mae": 0.29056941119134927,
            "precision": 0.7324478178368121,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8036595549706947,
            "auditor_fn_violation": 0.02045955594092741,
            "auditor_fp_violation": 0.02720769143419509,
            "ave_precision_score": 0.7838809591974428,
            "fpr": 0.145993413830955,
            "logloss": 1.7263813375819945,
            "mae": 0.2778521730351768,
            "precision": 0.7366336633663366,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7180262818914714,
            "auditor_fn_violation": 0.029174007193716506,
            "auditor_fp_violation": 0.061908804268736364,
            "ave_precision_score": 0.603683149760528,
            "fpr": 0.2894736842105263,
            "logloss": 7.395254963314958,
            "mae": 0.35286080583777896,
            "precision": 0.6223175965665236,
            "recall": 0.9100418410041841
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.715927722370635,
            "auditor_fn_violation": 0.03160715438755085,
            "auditor_fp_violation": 0.06913206404481623,
            "ave_precision_score": 0.5944190393238831,
            "fpr": 0.29308452250274425,
            "logloss": 7.858951399261531,
            "mae": 0.35641552342070487,
            "precision": 0.6169296987087518,
            "recall": 0.9033613445378151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7747117072686058,
            "auditor_fn_violation": 0.016520773691551055,
            "auditor_fp_violation": 0.01614924407793678,
            "ave_precision_score": 0.7435634472075979,
            "fpr": 0.15570175438596492,
            "logloss": 2.3065745823863364,
            "mae": 0.27536399695214026,
            "precision": 0.7360594795539034,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8045020934361176,
            "auditor_fn_violation": 0.008846129011428944,
            "auditor_fp_violation": 0.024346114538778912,
            "ave_precision_score": 0.7794718099901018,
            "fpr": 0.15587266739846323,
            "logloss": 1.8881977696646612,
            "mae": 0.274043704962959,
            "precision": 0.7269230769230769,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7894915678136185,
            "auditor_fn_violation": 0.009767488805696249,
            "auditor_fp_violation": 0.013943629234376264,
            "ave_precision_score": 0.759283201462982,
            "fpr": 0.18969298245614036,
            "logloss": 2.150705124184933,
            "mae": 0.2888598813718234,
            "precision": 0.7042735042735043,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8097346817847233,
            "auditor_fn_violation": 0.013446761800219543,
            "auditor_fp_violation": 0.027374238237632013,
            "ave_precision_score": 0.7883376345318069,
            "fpr": 0.16575192096597147,
            "logloss": 1.7480299019620058,
            "mae": 0.28862749365527435,
            "precision": 0.7214022140221402,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.773097819288254,
            "auditor_fn_violation": 0.012527068193496292,
            "auditor_fp_violation": 0.017460485892149737,
            "ave_precision_score": 0.7426915914730632,
            "fpr": 0.17214912280701755,
            "logloss": 2.229625744064179,
            "mae": 0.28164865329183575,
            "precision": 0.7196428571428571,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8042269799830885,
            "auditor_fn_violation": 0.013492883432187365,
            "auditor_fp_violation": 0.028661190809644584,
            "ave_precision_score": 0.779894418738188,
            "fpr": 0.15148188803512624,
            "logloss": 1.8381768469353734,
            "mae": 0.2753946023449965,
            "precision": 0.7351247600767754,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6713031336893274,
            "auditor_fn_violation": 0.014190156353226164,
            "auditor_fp_violation": 0.00630103484517746,
            "ave_precision_score": 0.6650666885387484,
            "fpr": 0.013157894736842105,
            "logloss": 14.880540856813472,
            "mae": 0.4756451051078007,
            "precision": 0.8260869565217391,
            "recall": 0.1192468619246862
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7188906040301899,
            "auditor_fn_violation": 0.017406303904657385,
            "auditor_fp_violation": 0.003388975106299759,
            "ave_precision_score": 0.7132591349067993,
            "fpr": 0.007683863885839737,
            "logloss": 14.218352620726627,
            "mae": 0.4534773306235842,
            "precision": 0.9066666666666666,
            "recall": 0.14285714285714285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7229316910291621,
            "auditor_fn_violation": 0.014252092050209206,
            "auditor_fp_violation": 0.028187909289352414,
            "ave_precision_score": 0.6845416839625731,
            "fpr": 0.19407894736842105,
            "logloss": 2.984461384999711,
            "mae": 0.30639056668873377,
            "precision": 0.6905594405594405,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7408796973001963,
            "auditor_fn_violation": 0.017576953942938317,
            "auditor_fp_violation": 0.03644346871569704,
            "ave_precision_score": 0.7059121264881426,
            "fpr": 0.18880351262349068,
            "logloss": 2.774779973880963,
            "mae": 0.31546116278047265,
            "precision": 0.6867030965391621,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7754179447995039,
            "auditor_fn_violation": 0.01359603244512956,
            "auditor_fp_violation": 0.017983466731344495,
            "ave_precision_score": 0.7461065787266192,
            "fpr": 0.15570175438596492,
            "logloss": 2.142936045204623,
            "mae": 0.2859296965417391,
            "precision": 0.7295238095238096,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8064021201877876,
            "auditor_fn_violation": 0.01489728712560765,
            "auditor_fp_violation": 0.021446686097127066,
            "ave_precision_score": 0.7866525031456812,
            "fpr": 0.1350164654226125,
            "logloss": 1.6794944181598614,
            "mae": 0.2785339170724918,
            "precision": 0.7469135802469136,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8034153257168359,
            "auditor_fn_violation": 0.014795749834838145,
            "auditor_fp_violation": 0.01623514431239389,
            "ave_precision_score": 0.7795776117018082,
            "fpr": 0.14912280701754385,
            "logloss": 1.8244072565857388,
            "mae": 0.2761254331053032,
            "precision": 0.7443609022556391,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8156237969214846,
            "auditor_fn_violation": 0.01724949035596676,
            "auditor_fp_violation": 0.0219160452704493,
            "ave_precision_score": 0.7974922433954246,
            "fpr": 0.13721185510428102,
            "logloss": 1.586989493157576,
            "mae": 0.2730425308622971,
            "precision": 0.7504990019960079,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6318941814912892,
            "auditor_fn_violation": 0.0002752697643691016,
            "auditor_fp_violation": 0.0028675519443770716,
            "ave_precision_score": 0.6337869950751656,
            "fpr": 0.005482456140350877,
            "logloss": 7.59277221600147,
            "mae": 0.5127066047108623,
            "precision": 0.6153846153846154,
            "recall": 0.016736401673640166
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.6103488304840271,
            "auditor_fn_violation": 0.0012176110839505956,
            "auditor_fp_violation": 0.0006333825403434397,
            "ave_precision_score": 0.6120895652133203,
            "fpr": 0.0010976948408342481,
            "logloss": 8.015349838158171,
            "mae": 0.5094196789545612,
            "precision": 0.8,
            "recall": 0.008403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7531240256103587,
            "auditor_fn_violation": 0.008829277692138298,
            "auditor_fp_violation": 0.020085495998059675,
            "ave_precision_score": 0.7150476685539223,
            "fpr": 0.18092105263157895,
            "logloss": 2.716560809623143,
            "mae": 0.28968017068029694,
            "precision": 0.7095070422535211,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7874936989102821,
            "auditor_fn_violation": 0.008181977511092254,
            "auditor_fp_violation": 0.025867746697452593,
            "ave_precision_score": 0.7567549373826993,
            "fpr": 0.15806805708013172,
            "logloss": 2.180447469214057,
            "mae": 0.28314698248236253,
            "precision": 0.7283018867924528,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.624827954132618,
            "auditor_fn_violation": 0.0007386405343903749,
            "auditor_fp_violation": 0.0022940415555016574,
            "ave_precision_score": 0.6268098159527318,
            "fpr": 0.0043859649122807015,
            "logloss": 7.857149039077166,
            "mae": 0.5147804382998192,
            "precision": 0.6,
            "recall": 0.012552301255230125
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.6035756619928394,
            "auditor_fn_violation": 0.0012176110839505956,
            "auditor_fp_violation": 0.0006333825403434397,
            "ave_precision_score": 0.605453017381443,
            "fpr": 0.0010976948408342481,
            "logloss": 8.228537967759278,
            "mae": 0.510230567049506,
            "precision": 0.8,
            "recall": 0.008403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7414784869961869,
            "auditor_fn_violation": 0.015343995448873233,
            "auditor_fp_violation": 0.009570296709515726,
            "ave_precision_score": 0.7044099802205916,
            "fpr": 0.20175438596491227,
            "logloss": 2.759520073870526,
            "mae": 0.30362354268849584,
            "precision": 0.6907563025210084,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7655708301658974,
            "auditor_fn_violation": 0.009445710227010674,
            "auditor_fp_violation": 0.014580415609977674,
            "ave_precision_score": 0.7278082576819935,
            "fpr": 0.18221734357848518,
            "logloss": 2.5965939988671503,
            "mae": 0.29935222333865474,
            "precision": 0.6998191681735986,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7880626410390538,
            "auditor_fn_violation": 0.01467417235557513,
            "auditor_fp_violation": 0.01627556795213841,
            "ave_precision_score": 0.7606988069763039,
            "fpr": 0.17543859649122806,
            "logloss": 2.0183980632762646,
            "mae": 0.2776204065072913,
            "precision": 0.7178130511463845,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8028457187548229,
            "auditor_fn_violation": 0.01645619828612016,
            "auditor_fp_violation": 0.023127294749990538,
            "ave_precision_score": 0.7793737179338277,
            "fpr": 0.15367727771679474,
            "logloss": 1.7984920659433914,
            "mae": 0.27972331888365826,
            "precision": 0.732824427480916,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7886363281801153,
            "auditor_fn_violation": 0.008712288042281439,
            "auditor_fp_violation": 0.016144191122968717,
            "ave_precision_score": 0.7403400579960899,
            "fpr": 0.16337719298245615,
            "logloss": 2.974451502898507,
            "mae": 0.28817006498125886,
            "precision": 0.7225325884543762,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8063948567942457,
            "auditor_fn_violation": 0.013366048944275847,
            "auditor_fp_violation": 0.022832052689352362,
            "ave_precision_score": 0.7649696225494377,
            "fpr": 0.14050493962678376,
            "logloss": 2.529281405583195,
            "mae": 0.28189783217896563,
            "precision": 0.7398373983739838,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.755916719026991,
            "auditor_fn_violation": 0.008515011377816928,
            "auditor_fp_violation": 0.018680774516937507,
            "ave_precision_score": 0.7168317957719801,
            "fpr": 0.18311403508771928,
            "logloss": 2.774873094248634,
            "mae": 0.28724508600655035,
            "precision": 0.7075306479859895,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7871732961312412,
            "auditor_fn_violation": 0.008237323469453649,
            "auditor_fp_violation": 0.025612879619465796,
            "ave_precision_score": 0.7557287626719098,
            "fpr": 0.15916575192096596,
            "logloss": 2.2384248006766008,
            "mae": 0.28113649350124065,
            "precision": 0.725897920604915,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7776781373756096,
            "auditor_fn_violation": 0.007416226235043677,
            "auditor_fp_violation": 0.015876384509661265,
            "ave_precision_score": 0.7512373430467868,
            "fpr": 0.16228070175438597,
            "logloss": 2.075921042910625,
            "mae": 0.29036466749596257,
            "precision": 0.7274401473296501,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8036123201563203,
            "auditor_fn_violation": 0.007840677434530346,
            "auditor_fp_violation": 0.028714182974374506,
            "ave_precision_score": 0.7846843189473689,
            "fpr": 0.15806805708013172,
            "logloss": 1.6888338048170546,
            "mae": 0.29161491376081655,
            "precision": 0.7214700193423598,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8084439027520253,
            "auditor_fn_violation": 0.026100161491595098,
            "auditor_fp_violation": 0.03483254507235832,
            "ave_precision_score": 0.8086057014638268,
            "fpr": 0.1524122807017544,
            "logloss": 0.7591200352878318,
            "mae": 0.3107648296308342,
            "precision": 0.7362428842504743,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8438824936551204,
            "auditor_fn_violation": 0.035246151149812284,
            "auditor_fp_violation": 0.023124771313574825,
            "ave_precision_score": 0.8426692446792163,
            "fpr": 0.12733260153677278,
            "logloss": 0.5797131117664077,
            "mae": 0.3123693014155477,
            "precision": 0.7661290322580645,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7995500529944534,
            "auditor_fn_violation": 0.01411216325332159,
            "auditor_fp_violation": 0.019388188212466653,
            "ave_precision_score": 0.7817265324030369,
            "fpr": 0.15789473684210525,
            "logloss": 1.631506917363044,
            "mae": 0.27551219217427486,
            "precision": 0.7262357414448669,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8185577880664383,
            "auditor_fn_violation": 0.01286793531902333,
            "auditor_fp_violation": 0.027790605246224318,
            "ave_precision_score": 0.8073135434385383,
            "fpr": 0.141602634467618,
            "logloss": 1.3729482920080642,
            "mae": 0.2740813782154466,
            "precision": 0.7404426559356136,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.8066937099367588,
            "auditor_fn_violation": 0.00550768920208471,
            "auditor_fp_violation": 0.022867147707979627,
            "ave_precision_score": 0.7826612083245197,
            "fpr": 0.3958333333333333,
            "logloss": 2.6174134568297998,
            "mae": 0.39725620448173193,
            "precision": 0.562953995157385,
            "recall": 0.9728033472803347
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.8174393412098329,
            "auditor_fn_violation": 0.0035836508039000453,
            "auditor_fp_violation": 0.024126575570612083,
            "ave_precision_score": 0.8000776065469528,
            "fpr": 0.3940724478594951,
            "logloss": 2.3102968862488122,
            "mae": 0.38907229639971075,
            "precision": 0.5669481302774427,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7457147363598435,
            "auditor_fn_violation": 0.011024554062981728,
            "auditor_fp_violation": 0.011202401164200826,
            "ave_precision_score": 0.7080065300427313,
            "fpr": 0.18640350877192982,
            "logloss": 2.7394120089907945,
            "mae": 0.29487862431815104,
            "precision": 0.7017543859649122,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7686343359634036,
            "auditor_fn_violation": 0.010439631395917316,
            "auditor_fp_violation": 0.02120191276480312,
            "ave_precision_score": 0.7321891611943782,
            "fpr": 0.17672886937431395,
            "logloss": 2.5354009631414467,
            "mae": 0.29407405689573607,
            "precision": 0.7040441176470589,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8531167179175397,
            "auditor_fn_violation": 0.0049043896351758055,
            "auditor_fp_violation": 0.026669496321448792,
            "ave_precision_score": 0.8538588562361351,
            "fpr": 0.26864035087719296,
            "logloss": 0.9170046699777766,
            "mae": 0.3084686703767371,
            "precision": 0.6469740634005764,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8681514370112221,
            "auditor_fn_violation": 0.008274220775027907,
            "auditor_fp_violation": 0.024262841137060457,
            "ave_precision_score": 0.8683074918838272,
            "fpr": 0.2579582875960483,
            "logloss": 0.87460386782053,
            "mae": 0.30561350468971304,
            "precision": 0.6539027982326951,
            "recall": 0.9327731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8060667499236776,
            "auditor_fn_violation": 0.012506422961168615,
            "auditor_fp_violation": 0.013546972269383138,
            "ave_precision_score": 0.7819496520988449,
            "fpr": 0.1206140350877193,
            "logloss": 1.850559950443397,
            "mae": 0.2708382874995865,
            "precision": 0.7717842323651453,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8151344998011373,
            "auditor_fn_violation": 0.014270032930845224,
            "auditor_fp_violation": 0.017923968860794632,
            "ave_precision_score": 0.7977495591493305,
            "fpr": 0.11306256860592755,
            "logloss": 1.6185791561518639,
            "mae": 0.27325558607888495,
            "precision": 0.7726269315673289,
            "recall": 0.7352941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7869393573997157,
            "auditor_fn_violation": 0.016814394773544742,
            "auditor_fp_violation": 0.0169779286926995,
            "ave_precision_score": 0.7646281199981677,
            "fpr": 0.1611842105263158,
            "logloss": 2.025750540145614,
            "mae": 0.27630844280054334,
            "precision": 0.73224043715847,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8047574307052857,
            "auditor_fn_violation": 0.013656615225673142,
            "auditor_fp_violation": 0.02585512951537404,
            "ave_precision_score": 0.7891984941139403,
            "fpr": 0.1437980241492865,
            "logloss": 1.8186762333127657,
            "mae": 0.28020214879439076,
            "precision": 0.7426326129666012,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7298978414169587,
            "auditor_fn_violation": 0.004684173823680544,
            "auditor_fp_violation": 0.01798346673134449,
            "ave_precision_score": 0.7270922773437439,
            "fpr": 0.1425438596491228,
            "logloss": 1.2259373236731894,
            "mae": 0.2928932738456679,
            "precision": 0.7319587628865979,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7757149007359598,
            "auditor_fn_violation": 0.003216983829755839,
            "auditor_fp_violation": 0.02472715343755126,
            "ave_precision_score": 0.7742281211213228,
            "fpr": 0.12403951701427003,
            "logloss": 0.9837827548358329,
            "mae": 0.28801170851387436,
            "precision": 0.7543478260869565,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7300780528742006,
            "auditor_fn_violation": 0.012951442413565294,
            "auditor_fp_violation": 0.007998827714447411,
            "ave_precision_score": 0.6859478343537917,
            "fpr": 0.20065789473684212,
            "logloss": 3.1842674771042896,
            "mae": 0.30404904062668303,
            "precision": 0.6903553299492385,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7587128990796923,
            "auditor_fn_violation": 0.008142774123919602,
            "auditor_fp_violation": 0.012657557061205959,
            "ave_precision_score": 0.717903705103819,
            "fpr": 0.18331503841931943,
            "logloss": 2.801995323324949,
            "mae": 0.29975618034009616,
            "precision": 0.6985559566787004,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7990218318376012,
            "auditor_fn_violation": 0.016720344270718644,
            "auditor_fp_violation": 0.01650800388066942,
            "ave_precision_score": 0.7758937748397349,
            "fpr": 0.15789473684210525,
            "logloss": 1.7982108384850672,
            "mae": 0.27768213450944085,
            "precision": 0.7367458866544789,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8166422886995375,
            "auditor_fn_violation": 0.02150421090499866,
            "auditor_fp_violation": 0.0240433021688936,
            "ave_precision_score": 0.8009909243856952,
            "fpr": 0.14489571899012074,
            "logloss": 1.5034133061810924,
            "mae": 0.2770717511151682,
            "precision": 0.7436893203883496,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8049708728227629,
            "auditor_fn_violation": 0.006955149379725464,
            "auditor_fp_violation": 0.012465639906217161,
            "ave_precision_score": 0.8065616490824279,
            "fpr": 0.14364035087719298,
            "logloss": 0.6218716537538257,
            "mae": 0.2811986512061323,
            "precision": 0.744140625,
            "recall": 0.797071129707113
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8459532935237268,
            "auditor_fn_violation": 0.011359757953675432,
            "auditor_fp_violation": 0.023556278940661396,
            "ave_precision_score": 0.8464730438647973,
            "fpr": 0.12952799121844127,
            "logloss": 0.5847208016697282,
            "mae": 0.2800485526679777,
            "precision": 0.7526205450733753,
            "recall": 0.7542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.729148277198271,
            "auditor_fn_violation": 0.014827864640681202,
            "auditor_fp_violation": 0.010181704260651639,
            "ave_precision_score": 0.6845557678231493,
            "fpr": 0.20394736842105263,
            "logloss": 3.2077168033193137,
            "mae": 0.304960435568534,
            "precision": 0.6879194630872483,
            "recall": 0.8577405857740585
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7573113404238625,
            "auditor_fn_violation": 0.00962097242848841,
            "auditor_fp_violation": 0.012657557061205959,
            "ave_precision_score": 0.7153508549136405,
            "fpr": 0.18331503841931943,
            "logloss": 2.8437407071781533,
            "mae": 0.30042088620506385,
            "precision": 0.6990990990990991,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7726659403217117,
            "auditor_fn_violation": 0.016208801291932765,
            "auditor_fp_violation": 0.013936049801924163,
            "ave_precision_score": 0.7435193882347024,
            "fpr": 0.16885964912280702,
            "logloss": 2.1525682398030916,
            "mae": 0.2859398516856457,
            "precision": 0.72,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8100741757911692,
            "auditor_fn_violation": 0.012397494672951509,
            "auditor_fp_violation": 0.026246262159809228,
            "ave_precision_score": 0.7910245307831077,
            "fpr": 0.141602634467618,
            "logloss": 1.647356728933077,
            "mae": 0.2761397993620935,
            "precision": 0.7455621301775148,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7873388296903717,
            "auditor_fn_violation": 0.01172649196212288,
            "auditor_fp_violation": 0.017235629396070824,
            "ave_precision_score": 0.7599359306687226,
            "fpr": 0.17105263157894737,
            "logloss": 2.1668930564241076,
            "mae": 0.272196402422713,
            "precision": 0.7224199288256228,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8005147799513246,
            "auditor_fn_violation": 0.013001688051730026,
            "auditor_fp_violation": 0.02424770051856619,
            "ave_precision_score": 0.7762803897256233,
            "fpr": 0.15477497255762898,
            "logloss": 1.90767445941834,
            "mae": 0.2765958496456352,
            "precision": 0.7309160305343512,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7920767391209667,
            "auditor_fn_violation": 0.008783399398076782,
            "auditor_fp_violation": 0.033776477484032674,
            "ave_precision_score": 0.756487119104889,
            "fpr": 0.33881578947368424,
            "logloss": 2.578154575770363,
            "mae": 0.36890099797104686,
            "precision": 0.5997409326424871,
            "recall": 0.9686192468619247
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8153729481583574,
            "auditor_fn_violation": 0.009996863729026188,
            "auditor_fp_violation": 0.02904475314483266,
            "ave_precision_score": 0.7875829359477021,
            "fpr": 0.32711306256860595,
            "logloss": 2.1850746757238815,
            "mae": 0.356457553502276,
            "precision": 0.6063408190224571,
            "recall": 0.9642857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7252570926470678,
            "auditor_fn_violation": 0.0008716875871687578,
            "auditor_fp_violation": 0.021222410865874366,
            "ave_precision_score": 0.7222244840275398,
            "fpr": 0.14583333333333334,
            "logloss": 1.2416743576416935,
            "mae": 0.29068244440652846,
            "precision": 0.7313131313131314,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7797217444096264,
            "auditor_fn_violation": 0.004150946877104297,
            "auditor_fp_violation": 0.027465081948597602,
            "ave_precision_score": 0.7781278396481783,
            "fpr": 0.12294182217343579,
            "logloss": 0.982165692303757,
            "mae": 0.28584783276738474,
            "precision": 0.7565217391304347,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7815530272414957,
            "auditor_fn_violation": 0.0037780775159656516,
            "auditor_fp_violation": 0.020105707817931927,
            "ave_precision_score": 0.7467178881150243,
            "fpr": 0.15789473684210525,
            "logloss": 3.5423811476245834,
            "mae": 0.2867749760104042,
            "precision": 0.7225433526011561,
            "recall": 0.7845188284518828
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7948836209367227,
            "auditor_fn_violation": 0.011267514689739787,
            "auditor_fp_violation": 0.02720516799777938,
            "ave_precision_score": 0.7615423392538603,
            "fpr": 0.14928649835345773,
            "logloss": 3.28535637893882,
            "mae": 0.2821873819597796,
            "precision": 0.7263581488933601,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7741296800410193,
            "auditor_fn_violation": 0.018527949056742276,
            "auditor_fp_violation": 0.01651810979060555,
            "ave_precision_score": 0.7457604513147678,
            "fpr": 0.17982456140350878,
            "logloss": 2.1310825375226954,
            "mae": 0.28419110207390696,
            "precision": 0.712784588441331,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8117040170702129,
            "auditor_fn_violation": 0.009122858803235896,
            "auditor_fp_violation": 0.025405957833377492,
            "ave_precision_score": 0.7926533716266188,
            "fpr": 0.15806805708013172,
            "logloss": 1.6470189308311496,
            "mae": 0.27675449941773733,
            "precision": 0.7303370786516854,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.785564869568845,
            "auditor_fn_violation": 0.015589444322102327,
            "auditor_fp_violation": 0.01360002829654783,
            "ave_precision_score": 0.76357990836986,
            "fpr": 0.1611842105263158,
            "logloss": 1.8113571795919272,
            "mae": 0.2779634856610356,
            "precision": 0.7302752293577982,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8089841228120643,
            "auditor_fn_violation": 0.012106928391554212,
            "auditor_fp_violation": 0.024217419281577657,
            "ave_precision_score": 0.7952060593435328,
            "fpr": 0.15148188803512624,
            "logloss": 1.4750207467275378,
            "mae": 0.27735853025407436,
            "precision": 0.7361376673040153,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7886743745095468,
            "auditor_fn_violation": 0.011462691771269184,
            "auditor_fp_violation": 0.013612660683967987,
            "ave_precision_score": 0.7666416009836393,
            "fpr": 0.13267543859649122,
            "logloss": 1.762297650023215,
            "mae": 0.27349001833280245,
            "precision": 0.7608695652173914,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8089983881754641,
            "auditor_fn_violation": 0.020828528996670023,
            "auditor_fp_violation": 0.019781218062757868,
            "ave_precision_score": 0.7945357210988855,
            "fpr": 0.12403951701427003,
            "logloss": 1.4656885700531814,
            "mae": 0.2760294192751681,
            "precision": 0.7621052631578947,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8102283184343791,
            "auditor_fn_violation": 0.00849666006019233,
            "auditor_fp_violation": 0.014825369876303665,
            "ave_precision_score": 0.810762099922637,
            "fpr": 0.17214912280701755,
            "logloss": 0.890408648902893,
            "mae": 0.2763319238712248,
            "precision": 0.7097966728280961,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8465669467675828,
            "auditor_fn_violation": 0.01089392947080039,
            "auditor_fp_violation": 0.025595215564555816,
            "ave_precision_score": 0.8467780556304035,
            "fpr": 0.141602634467618,
            "logloss": 0.787947630459209,
            "mae": 0.265217473216004,
            "precision": 0.7425149700598802,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.789808574769497,
            "auditor_fn_violation": 0.001454341921749983,
            "auditor_fp_violation": 0.023657935160481855,
            "ave_precision_score": 0.7592681987378904,
            "fpr": 0.22587719298245615,
            "logloss": 2.267439771272144,
            "mae": 0.3017979928831106,
            "precision": 0.6835637480798771,
            "recall": 0.9309623430962343
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8093148486173868,
            "auditor_fn_violation": 0.012072337167578337,
            "auditor_fp_violation": 0.035307922328627124,
            "ave_precision_score": 0.7876312121405642,
            "fpr": 0.21185510428100987,
            "logloss": 1.858828878991719,
            "mae": 0.30266713765442155,
            "precision": 0.6907051282051282,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7737052095194117,
            "auditor_fn_violation": 0.006734933568230199,
            "auditor_fp_violation": 0.023844894494300273,
            "ave_precision_score": 0.7098341062145228,
            "fpr": 0.16228070175438597,
            "logloss": 6.197931995687069,
            "mae": 0.3028416107222702,
            "precision": 0.7098039215686275,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7849374590361771,
            "auditor_fn_violation": 0.015017203368724004,
            "auditor_fp_violation": 0.019632335314230923,
            "ave_precision_score": 0.7281778291578511,
            "fpr": 0.150384193194292,
            "logloss": 6.012231535962818,
            "mae": 0.2978514581953003,
            "precision": 0.7198364008179959,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 29756,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7725011390837163,
            "auditor_fn_violation": 0.015323350216545547,
            "auditor_fp_violation": 0.015244765138653086,
            "ave_precision_score": 0.741624761488994,
            "fpr": 0.1425438596491228,
            "logloss": 2.2871300697381565,
            "mae": 0.27542454096928776,
            "precision": 0.748062015503876,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8065475991056231,
            "auditor_fn_violation": 0.006161850030901495,
            "auditor_fp_violation": 0.024202278663083394,
            "ave_precision_score": 0.7837419082386698,
            "fpr": 0.13830954994511527,
            "logloss": 1.8054089904003796,
            "mae": 0.2738900494747407,
            "precision": 0.7469879518072289,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7874564179961502,
            "auditor_fn_violation": 0.013919474418263232,
            "auditor_fp_violation": 0.01906227261702645,
            "ave_precision_score": 0.7604763824617354,
            "fpr": 0.16776315789473684,
            "logloss": 2.2600415265045903,
            "mae": 0.2743864616407799,
            "precision": 0.7262969588550984,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.798372732345029,
            "auditor_fn_violation": 0.013794980121576629,
            "auditor_fp_violation": 0.027026004012263904,
            "ave_precision_score": 0.7741876949045358,
            "fpr": 0.15148188803512624,
            "logloss": 2.1512061823726443,
            "mae": 0.2785774844790424,
            "precision": 0.7346153846153847,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7953448143746973,
            "auditor_fn_violation": 0.015493099904573147,
            "auditor_fp_violation": 0.01601281429379902,
            "ave_precision_score": 0.7726980592689535,
            "fpr": 0.1787280701754386,
            "logloss": 1.7860785635249798,
            "mae": 0.284278151769142,
            "precision": 0.7145359019264448,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8115051892121932,
            "auditor_fn_violation": 0.016031879272016162,
            "auditor_fp_violation": 0.027066378994915284,
            "ave_precision_score": 0.7966140877245422,
            "fpr": 0.14928649835345773,
            "logloss": 1.4961564620759498,
            "mae": 0.28578774974467774,
            "precision": 0.739961759082218,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7847724766234572,
            "auditor_fn_violation": 0.005668263231300011,
            "auditor_fp_violation": 0.017013299377475952,
            "ave_precision_score": 0.7568016928337364,
            "fpr": 0.16885964912280702,
            "logloss": 2.0889343341994153,
            "mae": 0.2814918160360353,
            "precision": 0.7264653641207816,
            "recall": 0.8556485355648535
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8116929012769497,
            "auditor_fn_violation": 0.007441725318008658,
            "auditor_fp_violation": 0.027237972671183625,
            "ave_precision_score": 0.7926771075828398,
            "fpr": 0.15806805708013172,
            "logloss": 1.6675924579074841,
            "mae": 0.281669319219096,
            "precision": 0.7277882797731569,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7895876938548416,
            "auditor_fn_violation": 0.01458470968215518,
            "auditor_fp_violation": 0.015595945508933626,
            "ave_precision_score": 0.7675773588393416,
            "fpr": 0.17214912280701755,
            "logloss": 1.777291204133157,
            "mae": 0.27739790679948273,
            "precision": 0.7221238938053097,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8101287254200775,
            "auditor_fn_violation": 0.01654382938685903,
            "auditor_fp_violation": 0.028047995760626828,
            "ave_precision_score": 0.7956453963573309,
            "fpr": 0.15477497255762898,
            "logloss": 1.4675179310156377,
            "mae": 0.278537283245355,
            "precision": 0.7349624060150376,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7733052764950793,
            "auditor_fn_violation": 0.013846069147764808,
            "auditor_fp_violation": 0.019782318699975755,
            "ave_precision_score": 0.7415422728153169,
            "fpr": 0.17763157894736842,
            "logloss": 2.3281931984821718,
            "mae": 0.27928060910054886,
            "precision": 0.7127659574468085,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8043395507359377,
            "auditor_fn_violation": 0.011327472811297956,
            "auditor_fp_violation": 0.02259737310269125,
            "ave_precision_score": 0.7785022903885187,
            "fpr": 0.150384193194292,
            "logloss": 1.921507684762194,
            "mae": 0.2700612430454553,
            "precision": 0.7380497131931166,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7889414802262492,
            "auditor_fn_violation": 0.014942560375834985,
            "auditor_fp_violation": 0.01584606677985286,
            "ave_precision_score": 0.766915666290341,
            "fpr": 0.15350877192982457,
            "logloss": 1.7696669278728114,
            "mae": 0.27520645221588785,
            "precision": 0.7416974169741697,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8100206987260288,
            "auditor_fn_violation": 0.009740888671604756,
            "auditor_fp_violation": 0.02654907452969454,
            "ave_precision_score": 0.7963076270921577,
            "fpr": 0.1394072447859495,
            "logloss": 1.440271063047388,
            "mae": 0.2774692149557206,
            "precision": 0.75049115913556,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8038400871850419,
            "auditor_fn_violation": 0.01578901490126991,
            "auditor_fp_violation": 0.014845581696175931,
            "ave_precision_score": 0.7799123946670468,
            "fpr": 0.1524122807017544,
            "logloss": 1.8337008710220797,
            "mae": 0.2771808059586507,
            "precision": 0.741635687732342,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8149405290601925,
            "auditor_fn_violation": 0.01888680829082456,
            "auditor_fp_violation": 0.024770051856618347,
            "ave_precision_score": 0.7960116611690153,
            "fpr": 0.1437980241492865,
            "logloss": 1.6156710947965718,
            "mae": 0.27425558796904764,
            "precision": 0.7426326129666012,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7875721643243598,
            "auditor_fn_violation": 0.008092931072451005,
            "auditor_fp_violation": 0.017680289433260575,
            "ave_precision_score": 0.7583450082089537,
            "fpr": 0.17105263157894737,
            "logloss": 2.121457692726444,
            "mae": 0.28214827740047393,
            "precision": 0.7229129662522202,
            "recall": 0.8514644351464435
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8102831456995736,
            "auditor_fn_violation": 0.006424743333118102,
            "auditor_fp_violation": 0.027972292668155496,
            "ave_precision_score": 0.7896811191627425,
            "fpr": 0.15806805708013172,
            "logloss": 1.7222643012925851,
            "mae": 0.28204618814505095,
            "precision": 0.7262357414448669,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7914898269627813,
            "auditor_fn_violation": 0.010570358951772739,
            "auditor_fp_violation": 0.020378567386207466,
            "ave_precision_score": 0.7690822037486691,
            "fpr": 0.19846491228070176,
            "logloss": 1.8446721322580253,
            "mae": 0.28724436923447794,
            "precision": 0.7056910569105691,
            "recall": 0.9079497907949791
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8117457217570281,
            "auditor_fn_violation": 0.017463955944617145,
            "auditor_fp_violation": 0.027707331844505852,
            "ave_precision_score": 0.7968130531899108,
            "fpr": 0.18111964873765093,
            "logloss": 1.531244294152035,
            "mae": 0.28711299343202284,
            "precision": 0.7155172413793104,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8017727102617775,
            "auditor_fn_violation": 0.018585296924319167,
            "auditor_fp_violation": 0.019297235023041478,
            "ave_precision_score": 0.7943816807122118,
            "fpr": 0.18640350877192982,
            "logloss": 1.155093747001883,
            "mae": 0.2844826118295052,
            "precision": 0.711864406779661,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8269828098557219,
            "auditor_fn_violation": 0.01837024601278492,
            "auditor_fp_violation": 0.0270941367954881,
            "ave_precision_score": 0.8241950511270237,
            "fpr": 0.16136114160263446,
            "logloss": 0.9380098690666951,
            "mae": 0.28191082198616396,
            "precision": 0.7360861759425493,
            "recall": 0.8613445378151261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.804662292374481,
            "auditor_fn_violation": 0.01589224106290832,
            "auditor_fp_violation": 0.016131558735548557,
            "ave_precision_score": 0.7806990225501931,
            "fpr": 0.15021929824561403,
            "logloss": 1.8284490321804054,
            "mae": 0.27630797274159385,
            "precision": 0.7429643527204502,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8138189572585662,
            "auditor_fn_violation": 0.016613011834810766,
            "auditor_fp_violation": 0.023846474128468152,
            "ave_precision_score": 0.7949123714637049,
            "fpr": 0.13830954994511527,
            "logloss": 1.6182627596571186,
            "mae": 0.2759230425914864,
            "precision": 0.749003984063745,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8041574699508433,
            "auditor_fn_violation": 0.01578901490126991,
            "auditor_fp_violation": 0.014845581696175931,
            "ave_precision_score": 0.7801814438872342,
            "fpr": 0.1524122807017544,
            "logloss": 1.8344047976787186,
            "mae": 0.2771965960642582,
            "precision": 0.741635687732342,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8149229985812587,
            "auditor_fn_violation": 0.01888680829082456,
            "auditor_fp_violation": 0.024770051856618347,
            "ave_precision_score": 0.7960004848427327,
            "fpr": 0.1437980241492865,
            "logloss": 1.616255527592652,
            "mae": 0.2743370811683118,
            "precision": 0.7426326129666012,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7970302501409355,
            "auditor_fn_violation": 0.015304998898920941,
            "auditor_fp_violation": 0.015969864176570467,
            "ave_precision_score": 0.7745402407446441,
            "fpr": 0.17214912280701755,
            "logloss": 1.767804749361775,
            "mae": 0.27856929853062373,
            "precision": 0.7221238938053097,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8139920717460437,
            "auditor_fn_violation": 0.015406931158852123,
            "auditor_fp_violation": 0.027692191226011582,
            "ave_precision_score": 0.7991690005151693,
            "fpr": 0.1525795828759605,
            "logloss": 1.4790369555024758,
            "mae": 0.2810257893004179,
            "precision": 0.7357414448669202,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7993298860821509,
            "auditor_fn_violation": 0.015194890993173312,
            "auditor_fp_violation": 0.016040605546123375,
            "ave_precision_score": 0.7764597746565305,
            "fpr": 0.1611842105263158,
            "logloss": 1.7862377273079455,
            "mae": 0.2779818491285129,
            "precision": 0.7341772151898734,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8164193726646097,
            "auditor_fn_violation": 0.01718953223440858,
            "auditor_fp_violation": 0.023137388495653388,
            "ave_precision_score": 0.8007799486332445,
            "fpr": 0.14709110867178923,
            "logloss": 1.4975098991287246,
            "mae": 0.2780504079316957,
            "precision": 0.7408123791102514,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.745884199980163,
            "auditor_fn_violation": 0.01664693900022022,
            "auditor_fp_violation": 0.006755800792303345,
            "ave_precision_score": 0.7087944661416506,
            "fpr": 0.19298245614035087,
            "logloss": 2.7135859865419323,
            "mae": 0.29831152430633184,
            "precision": 0.6991452991452991,
            "recall": 0.8556485355648535
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.769013604457135,
            "auditor_fn_violation": 0.010497283435877098,
            "auditor_fp_violation": 0.01639728982928952,
            "ave_precision_score": 0.7318310995503813,
            "fpr": 0.17892425905598244,
            "logloss": 2.549312642596152,
            "mae": 0.29565951958922676,
            "precision": 0.7030965391621129,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7904514139936535,
            "auditor_fn_violation": 0.010038170740659179,
            "auditor_fp_violation": 0.019544829816476678,
            "ave_precision_score": 0.7679743983184754,
            "fpr": 0.17324561403508773,
            "logloss": 1.817880420277794,
            "mae": 0.2757911649337314,
            "precision": 0.7208480565371025,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8099699770532857,
            "auditor_fn_violation": 0.014131668034941747,
            "auditor_fp_violation": 0.027222832052689352,
            "ave_precision_score": 0.7934842098809545,
            "fpr": 0.15806805708013172,
            "logloss": 1.5533718977825428,
            "mae": 0.27587979508181276,
            "precision": 0.7293233082706767,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6938006268203933,
            "auditor_fn_violation": 0.014720050649636648,
            "auditor_fp_violation": 0.002854919556956913,
            "ave_precision_score": 0.6523174366248988,
            "fpr": 0.24342105263157895,
            "logloss": 3.5709926871940505,
            "mae": 0.35546439935706475,
            "precision": 0.642512077294686,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7105647981597705,
            "auditor_fn_violation": 0.003588262967096828,
            "auditor_fp_violation": 0.010386464287066126,
            "ave_precision_score": 0.6725397399686379,
            "fpr": 0.22063666300768386,
            "logloss": 3.2771024120383427,
            "mae": 0.34626640617698506,
            "precision": 0.6558219178082192,
            "recall": 0.8046218487394958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7205567278007805,
            "auditor_fn_violation": 0.013896535271232477,
            "auditor_fp_violation": 0.015323085940658107,
            "ave_precision_score": 0.7084632229078767,
            "fpr": 0.17434210526315788,
            "logloss": 1.800694402588058,
            "mae": 0.27657014021458864,
            "precision": 0.7205623901581723,
            "recall": 0.8577405857740585
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.7657489460673227,
            "auditor_fn_violation": 0.010575690210222402,
            "auditor_fp_violation": 0.021257428365948745,
            "ave_precision_score": 0.7522346182925579,
            "fpr": 0.14489571899012074,
            "logloss": 1.4875619807046303,
            "mae": 0.26651971252598317,
            "precision": 0.7532710280373832,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7982332184381319,
            "auditor_fn_violation": 0.008813220289216767,
            "auditor_fp_violation": 0.019529670951572486,
            "ave_precision_score": 0.7744043380252942,
            "fpr": 0.1425438596491228,
            "logloss": 1.8356169999961596,
            "mae": 0.2902232820433391,
            "precision": 0.7475728155339806,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8080956773487276,
            "auditor_fn_violation": 0.011341309300888305,
            "auditor_fp_violation": 0.01987458521013917,
            "ave_precision_score": 0.7908389854158342,
            "fpr": 0.1394072447859495,
            "logloss": 1.5814335546967042,
            "mae": 0.29458742293145335,
            "precision": 0.7397540983606558,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7880747065288846,
            "auditor_fn_violation": 0.014428723482346034,
            "auditor_fp_violation": 0.01640947125879215,
            "ave_precision_score": 0.760708398778146,
            "fpr": 0.17434210526315788,
            "logloss": 2.0187267440737156,
            "mae": 0.27863317916951036,
            "precision": 0.7175843694493783,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8035251239136989,
            "auditor_fn_violation": 0.01385032607993802,
            "auditor_fp_violation": 0.026180652813000745,
            "ave_precision_score": 0.7807930489241206,
            "fpr": 0.15367727771679474,
            "logloss": 1.7780881968344944,
            "mae": 0.2800812677783906,
            "precision": 0.7338403041825095,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7772112801005864,
            "auditor_fn_violation": 0.013763488218454085,
            "auditor_fp_violation": 0.016614115934998796,
            "ave_precision_score": 0.7497248098542082,
            "fpr": 0.17543859649122806,
            "logloss": 2.117553531726037,
            "mae": 0.28918990291911767,
            "precision": 0.7132616487455197,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8011714407787105,
            "auditor_fn_violation": 0.012759549483898935,
            "auditor_fp_violation": 0.02132303771275723,
            "ave_precision_score": 0.7768991318250794,
            "fpr": 0.15367727771679474,
            "logloss": 1.8521752921646444,
            "mae": 0.28178540147779735,
            "precision": 0.7281553398058253,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8091817816444393,
            "auditor_fn_violation": 0.010386845775526683,
            "auditor_fp_violation": 0.015004749777669985,
            "ave_precision_score": 0.8105153872378246,
            "fpr": 0.15679824561403508,
            "logloss": 0.671547276329876,
            "mae": 0.27882639410177434,
            "precision": 0.7327102803738318,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8531073052871152,
            "auditor_fn_violation": 0.015446134546024785,
            "auditor_fp_violation": 0.027775464627730048,
            "ave_precision_score": 0.8530052042288476,
            "fpr": 0.13830954994511527,
            "logloss": 0.5751017444785725,
            "mae": 0.2759716219558052,
            "precision": 0.748,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8025801119099834,
            "auditor_fn_violation": 0.003096784849152171,
            "auditor_fp_violation": 0.018923316355404642,
            "ave_precision_score": 0.7781838608788488,
            "fpr": 0.22039473684210525,
            "logloss": 1.943172362386231,
            "mae": 0.3004075175204618,
            "precision": 0.6898148148148148,
            "recall": 0.9351464435146444
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8100900984227702,
            "auditor_fn_violation": 0.01281258936066194,
            "auditor_fp_violation": 0.031934087840821634,
            "ave_precision_score": 0.7919709349958777,
            "fpr": 0.20856201975850713,
            "logloss": 1.697742791405138,
            "mae": 0.3065887156349497,
            "precision": 0.6935483870967742,
            "recall": 0.9033613445378151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.856603866630131,
            "auditor_fn_violation": 0.008113576304778682,
            "auditor_fp_violation": 0.018367491308917454,
            "ave_precision_score": 0.8573008207892671,
            "fpr": 0.14692982456140352,
            "logloss": 0.5441214828276107,
            "mae": 0.2735591366176857,
            "precision": 0.7418111753371869,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8578268258670725,
            "auditor_fn_violation": 0.013322233393906419,
            "auditor_fp_violation": 0.025708770203262808,
            "ave_precision_score": 0.8580252329752395,
            "fpr": 0.1350164654226125,
            "logloss": 0.5728211491624627,
            "mae": 0.28152396225214055,
            "precision": 0.7448132780082988,
            "recall": 0.7542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8575951561680765,
            "auditor_fn_violation": 0.02708654481391764,
            "auditor_fp_violation": 0.0214649527043415,
            "ave_precision_score": 0.8577678391357566,
            "fpr": 0.09429824561403509,
            "logloss": 0.5331959299434029,
            "mae": 0.30162580527201444,
            "precision": 0.8071748878923767,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8662911412063097,
            "auditor_fn_violation": 0.02155725078176167,
            "auditor_fp_violation": 0.015372774644510898,
            "ave_precision_score": 0.8664810511570916,
            "fpr": 0.0845225027442371,
            "logloss": 0.5033909210154847,
            "mae": 0.3080421166499153,
            "precision": 0.8205128205128205,
            "recall": 0.7394957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8000975742867444,
            "auditor_fn_violation": 0.012749577919694634,
            "auditor_fp_violation": 0.017367006225240525,
            "ave_precision_score": 0.7772109227399243,
            "fpr": 0.17653508771929824,
            "logloss": 1.7807149141960192,
            "mae": 0.2803467001587642,
            "precision": 0.7209705372616985,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.81394795165484,
            "auditor_fn_violation": 0.013605881430508539,
            "auditor_fp_violation": 0.028176691017828083,
            "ave_precision_score": 0.7991774151765781,
            "fpr": 0.1668496158068057,
            "logloss": 1.4877159638107778,
            "mae": 0.28802124593272993,
            "precision": 0.7195571955719557,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.755310435132448,
            "auditor_fn_violation": 0.008590710563018425,
            "auditor_fp_violation": 0.018329594146656962,
            "ave_precision_score": 0.7165152792465874,
            "fpr": 0.18969298245614036,
            "logloss": 2.7630694048780353,
            "mae": 0.28660490868535643,
            "precision": 0.7037671232876712,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7880588118067312,
            "auditor_fn_violation": 0.008680091136344773,
            "auditor_fp_violation": 0.0253353016137376,
            "ave_precision_score": 0.7566127263363966,
            "fpr": 0.16355653128430298,
            "logloss": 2.22633461436283,
            "mae": 0.2811795285347421,
            "precision": 0.7230483271375465,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7717491426970938,
            "auditor_fn_violation": 0.015323350216545547,
            "auditor_fp_violation": 0.0158106960950764,
            "ave_precision_score": 0.7409258182422824,
            "fpr": 0.14144736842105263,
            "logloss": 2.278891164518189,
            "mae": 0.2762962149661074,
            "precision": 0.7495145631067961,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8078430881812791,
            "auditor_fn_violation": 0.007755352415389865,
            "auditor_fp_violation": 0.02296074794655362,
            "ave_precision_score": 0.7865628015616696,
            "fpr": 0.14050493962678376,
            "logloss": 1.754271528590597,
            "mae": 0.2746813793691509,
            "precision": 0.7424547283702213,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7763970951763646,
            "auditor_fn_violation": 0.024203094032151512,
            "auditor_fp_violation": 0.027058573853989815,
            "ave_precision_score": 0.7517934704210801,
            "fpr": 0.17434210526315788,
            "logloss": 1.9576035216849104,
            "mae": 0.2953214403382319,
            "precision": 0.7140287769784173,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7983497676513185,
            "auditor_fn_violation": 0.026690588419780642,
            "auditor_fp_violation": 0.03327150914114842,
            "ave_precision_score": 0.7779775268323214,
            "fpr": 0.1525795828759605,
            "logloss": 1.713284510089392,
            "mae": 0.28532780310802625,
            "precision": 0.7352380952380952,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7676237939289831,
            "auditor_fn_violation": 0.012297676723188728,
            "auditor_fp_violation": 0.01709919961193307,
            "ave_precision_score": 0.7366544327676583,
            "fpr": 0.16666666666666666,
            "logloss": 2.379177621770103,
            "mae": 0.28283228199808774,
            "precision": 0.7211009174311926,
            "recall": 0.8221757322175732
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8039197366499791,
            "auditor_fn_violation": 0.013495189513785753,
            "auditor_fp_violation": 0.027866308338695644,
            "ave_precision_score": 0.7802927589576465,
            "fpr": 0.14709110867178923,
            "logloss": 1.920883405990154,
            "mae": 0.2710305707259378,
            "precision": 0.73828125,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8548369090711205,
            "auditor_fn_violation": 0.01095573662188945,
            "auditor_fp_violation": 0.016790969358881077,
            "ave_precision_score": 0.8555368501834782,
            "fpr": 0.15570175438596492,
            "logloss": 0.607046938070096,
            "mae": 0.2783990708103469,
            "precision": 0.7330827067669173,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8668333728598179,
            "auditor_fn_violation": 0.017708400594046617,
            "auditor_fp_violation": 0.02837351905825353,
            "ave_precision_score": 0.867013161116939,
            "fpr": 0.13611416026344675,
            "logloss": 0.5566662288456284,
            "mae": 0.27530676723679615,
            "precision": 0.7505030181086519,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7894351394731742,
            "auditor_fn_violation": 0.01458470968215518,
            "auditor_fp_violation": 0.015750060635459626,
            "ave_precision_score": 0.767461655511039,
            "fpr": 0.17324561403508773,
            "logloss": 1.7804382939600147,
            "mae": 0.27747368244493836,
            "precision": 0.7208480565371025,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8099449600995856,
            "auditor_fn_violation": 0.01177254655978747,
            "auditor_fp_violation": 0.02534539535940044,
            "ave_precision_score": 0.7954075284440335,
            "fpr": 0.15477497255762898,
            "logloss": 1.4715773915108443,
            "mae": 0.2783907061040455,
            "precision": 0.7339622641509433,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8447671361482483,
            "auditor_fn_violation": 0.006617943918373344,
            "auditor_fp_violation": 0.02081817446842914,
            "ave_precision_score": 0.8461013657956306,
            "fpr": 0.15789473684210525,
            "logloss": 0.5127078305455361,
            "mae": 0.3221273623091787,
            "precision": 0.7414721723518851,
            "recall": 0.8640167364016736
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8436148882028143,
            "auditor_fn_violation": 0.014318460644411448,
            "auditor_fp_violation": 0.026281590269629188,
            "ave_precision_score": 0.8438410296889323,
            "fpr": 0.1602634467618002,
            "logloss": 0.5293907949916927,
            "mae": 0.3331509987388162,
            "precision": 0.726078799249531,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 29756,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7870986559571242,
            "auditor_fn_violation": 0.006390846362768848,
            "auditor_fp_violation": 0.020189081574905014,
            "ave_precision_score": 0.7578487421634539,
            "fpr": 0.16557017543859648,
            "logloss": 2.1199844201599407,
            "mae": 0.2823656268585757,
            "precision": 0.7264492753623188,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8097133965372093,
            "auditor_fn_violation": 0.00829728159101182,
            "auditor_fp_violation": 0.0277653708820672,
            "ave_precision_score": 0.7891978659450568,
            "fpr": 0.15697036223929747,
            "logloss": 1.7183563691011392,
            "mae": 0.2814546156918444,
            "precision": 0.72552783109405,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7697959262712519,
            "auditor_fn_violation": 0.011357171694927701,
            "auditor_fp_violation": 0.008622867653003491,
            "ave_precision_score": 0.7363764127723642,
            "fpr": 0.24451754385964913,
            "logloss": 2.5320034200462724,
            "mae": 0.317279074204475,
            "precision": 0.6600609756097561,
            "recall": 0.9058577405857741
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7909725647483444,
            "auditor_fn_violation": 0.011880932394911862,
            "auditor_fp_violation": 0.022801771452363836,
            "ave_precision_score": 0.7679236458710077,
            "fpr": 0.24039517014270034,
            "logloss": 2.1146791053711236,
            "mae": 0.32293301236940475,
            "precision": 0.6572769953051644,
            "recall": 0.8823529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7897197623677608,
            "auditor_fn_violation": 0.017736548484181165,
            "auditor_fp_violation": 0.020744906621392188,
            "ave_precision_score": 0.7603165778318974,
            "fpr": 0.18969298245614036,
            "logloss": 2.129255827241255,
            "mae": 0.287090632904214,
            "precision": 0.70578231292517,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8147632931967546,
            "auditor_fn_violation": 0.01353208681936002,
            "auditor_fp_violation": 0.026135230957517956,
            "ave_precision_score": 0.7941376349314658,
            "fpr": 0.16245883644346873,
            "logloss": 1.7078244555033735,
            "mae": 0.28071316260868495,
            "precision": 0.7274401473296501,
            "recall": 0.8298319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7338000344464186,
            "auditor_fn_violation": 0.030417308962783527,
            "auditor_fp_violation": 0.04916525183927561,
            "ave_precision_score": 0.5990165864532995,
            "fpr": 0.3026315789473684,
            "logloss": 8.589744090850164,
            "mae": 0.368647872223192,
            "precision": 0.6079545454545454,
            "recall": 0.895397489539749
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7407530359681507,
            "auditor_fn_violation": 0.03033189126364047,
            "auditor_fp_violation": 0.0546752968192084,
            "ave_precision_score": 0.5987432541101398,
            "fpr": 0.305159165751921,
            "logloss": 8.939242311882307,
            "mae": 0.3699132540788702,
            "precision": 0.6056737588652482,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7630566191389895,
            "auditor_fn_violation": 0.00573249284298613,
            "auditor_fp_violation": 0.022202684129679042,
            "ave_precision_score": 0.7324188282545963,
            "fpr": 0.16228070175438597,
            "logloss": 2.3152525507976778,
            "mae": 0.29306013252967095,
            "precision": 0.725417439703154,
            "recall": 0.8179916317991632
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8001026347088196,
            "auditor_fn_violation": 0.010649484821370922,
            "auditor_fp_violation": 0.030629471213899088,
            "ave_precision_score": 0.7795545142547838,
            "fpr": 0.15477497255762898,
            "logloss": 1.738633808767496,
            "mae": 0.2915660359287569,
            "precision": 0.7218934911242604,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8085788099209306,
            "auditor_fn_violation": 0.008677879321735308,
            "auditor_fp_violation": 0.01085374727140432,
            "ave_precision_score": 0.8087368705526501,
            "fpr": 0.08552631578947369,
            "logloss": 0.8356184413967664,
            "mae": 0.2713137793583436,
            "precision": 0.8164705882352942,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8457993295387287,
            "auditor_fn_violation": 0.009805458956359722,
            "auditor_fp_violation": 0.008597347868327089,
            "ave_precision_score": 0.8445610266105846,
            "fpr": 0.08122941822173436,
            "logloss": 0.6495277764482756,
            "mae": 0.27840127177681145,
            "precision": 0.8199513381995134,
            "recall": 0.707983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7978058689083395,
            "auditor_fn_violation": 0.012387139396608682,
            "auditor_fp_violation": 0.018534238822863622,
            "ave_precision_score": 0.7729299944826734,
            "fpr": 0.13048245614035087,
            "logloss": 1.8711176383386132,
            "mae": 0.2956862509170988,
            "precision": 0.746268656716418,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8074222077219633,
            "auditor_fn_violation": 0.019131252940254043,
            "auditor_fp_violation": 0.020389366238944197,
            "ave_precision_score": 0.7891706314713576,
            "fpr": 0.1163556531284303,
            "logloss": 1.6324413955561352,
            "mae": 0.2966036612665563,
            "precision": 0.7623318385650224,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7858082529146289,
            "auditor_fn_violation": 0.029366696028774862,
            "auditor_fp_violation": 0.04367774274395667,
            "ave_precision_score": 0.7651572812408778,
            "fpr": 0.2050438596491228,
            "logloss": 1.821533399342848,
            "mae": 0.2999386637887477,
            "precision": 0.6888519134775375,
            "recall": 0.8661087866108786
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8043140643274294,
            "auditor_fn_violation": 0.032259775479895586,
            "auditor_fp_violation": 0.041722497697364275,
            "ave_precision_score": 0.7905997244189951,
            "fpr": 0.18880351262349068,
            "logloss": 1.5151388484252002,
            "mae": 0.29874929736533906,
            "precision": 0.7008695652173913,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7824059965142964,
            "auditor_fn_violation": 0.0072097739117668634,
            "auditor_fp_violation": 0.014112903225806455,
            "ave_precision_score": 0.7536421134245637,
            "fpr": 0.14473684210526316,
            "logloss": 2.1317168705213794,
            "mae": 0.2832725979999994,
            "precision": 0.7426900584795322,
            "recall": 0.797071129707113
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8110236338451002,
            "auditor_fn_violation": 0.015054100674298262,
            "auditor_fp_violation": 0.018161171883871455,
            "ave_precision_score": 0.7897185789180727,
            "fpr": 0.12843029637760703,
            "logloss": 1.7278261313781658,
            "mae": 0.2760166326179537,
            "precision": 0.7552301255230126,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.789398525318185,
            "auditor_fn_violation": 0.010510717169492772,
            "auditor_fp_violation": 0.02372867653003477,
            "ave_precision_score": 0.7655993589932625,
            "fpr": 0.18859649122807018,
            "logloss": 1.9047371472679255,
            "mae": 0.29254759796190466,
            "precision": 0.706984667802385,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8037688125269644,
            "auditor_fn_violation": 0.008836904685035375,
            "auditor_fp_violation": 0.021242287747454486,
            "ave_precision_score": 0.7857226397349621,
            "fpr": 0.1800219538968167,
            "logloss": 1.6476665710246443,
            "mae": 0.29658760369727727,
            "precision": 0.7066189624329159,
            "recall": 0.8298319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7579363490007595,
            "auditor_fn_violation": 0.020535124421933497,
            "auditor_fp_violation": 0.017296264855687603,
            "ave_precision_score": 0.7190494970169381,
            "fpr": 0.17763157894736842,
            "logloss": 2.7267751858868174,
            "mae": 0.29149214435369286,
            "precision": 0.7117437722419929,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7891555163460915,
            "auditor_fn_violation": 0.011936278353273249,
            "auditor_fp_violation": 0.033735821441639224,
            "ave_precision_score": 0.7576691048309016,
            "fpr": 0.15697036223929747,
            "logloss": 2.2151442458202,
            "mae": 0.27992341633607265,
            "precision": 0.7265774378585086,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6635473547174657,
            "auditor_fn_violation": 0.014217683329663068,
            "auditor_fp_violation": 0.0055178268251273345,
            "ave_precision_score": 0.6558840891134716,
            "fpr": 0.01206140350877193,
            "logloss": 14.865658039926256,
            "mae": 0.47700923415396834,
            "precision": 0.8307692307692308,
            "recall": 0.11297071129707113
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7090538196374321,
            "auditor_fn_violation": 0.016474646938907316,
            "auditor_fp_violation": 0.0022181006094098947,
            "ave_precision_score": 0.7034723948783353,
            "fpr": 0.006586169045005488,
            "logloss": 14.130200396974303,
            "mae": 0.455418237483884,
            "precision": 0.9166666666666666,
            "recall": 0.13865546218487396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 29756,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7725052575522278,
            "auditor_fn_violation": 0.01003817074065918,
            "auditor_fp_violation": 0.01128324844368987,
            "ave_precision_score": 0.7457473967210024,
            "fpr": 0.13815789473684212,
            "logloss": 2.1063131565169915,
            "mae": 0.2921096684177316,
            "precision": 0.7402061855670103,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8088428519329511,
            "auditor_fn_violation": 0.01383648959034767,
            "auditor_fp_violation": 0.011620424694348768,
            "ave_precision_score": 0.7916261516959542,
            "fpr": 0.11525795828759605,
            "logloss": 1.6219886613435062,
            "mae": 0.28172615490783487,
            "precision": 0.7682119205298014,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 29756,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7867848176084313,
            "auditor_fn_violation": 0.0058219555164060795,
            "auditor_fp_violation": 0.00825147546285068,
            "ave_precision_score": 0.7637332454748311,
            "fpr": 0.14473684210526316,
            "logloss": 1.922515066422701,
            "mae": 0.2811667651400185,
            "precision": 0.7461538461538462,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8122808609372558,
            "auditor_fn_violation": 0.004870444335802379,
            "auditor_fp_violation": 0.019566725967422437,
            "ave_precision_score": 0.7941747112101467,
            "fpr": 0.13611416026344675,
            "logloss": 1.6247232107334868,
            "mae": 0.2760028626018896,
            "precision": 0.7479674796747967,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 29756,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.774991521458317,
            "auditor_fn_violation": 0.007670850767085086,
            "auditor_fp_violation": 0.014148273910582912,
            "ave_precision_score": 0.7086960132339104,
            "fpr": 0.09210526315789473,
            "logloss": 7.472427441619509,
            "mae": 0.3554162882717849,
            "precision": 0.7383177570093458,
            "recall": 0.49581589958158995
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7808116281869576,
            "auditor_fn_violation": 0.009959966423451934,
            "auditor_fp_violation": 0.004125818539687346,
            "ave_precision_score": 0.722403953755021,
            "fpr": 0.07683863885839737,
            "logloss": 6.935794017974451,
            "mae": 0.3447193719115755,
            "precision": 0.7674418604651163,
            "recall": 0.4852941176470588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7760819451351528,
            "auditor_fn_violation": 0.005711847610658446,
            "auditor_fp_violation": 0.02314253375373919,
            "ave_precision_score": 0.7744460297871593,
            "fpr": 0.21710526315789475,
            "logloss": 1.0155200618186924,
            "mae": 0.3035107395839428,
            "precision": 0.6901408450704225,
            "recall": 0.9225941422594143
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8248639205957492,
            "auditor_fn_violation": 0.014662066802571741,
            "auditor_fp_violation": 0.03293589209785887,
            "ave_precision_score": 0.8251632414325589,
            "fpr": 0.2052689352360044,
            "logloss": 0.8151884924092281,
            "mae": 0.2999763879117389,
            "precision": 0.6944444444444444,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7473294838198995,
            "auditor_fn_violation": 0.012217389708581078,
            "auditor_fp_violation": 0.015391300832726978,
            "ave_precision_score": 0.7090237921712302,
            "fpr": 0.22039473684210525,
            "logloss": 2.798667704015781,
            "mae": 0.3015911420224049,
            "precision": 0.6799363057324841,
            "recall": 0.893305439330544
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7679936618550816,
            "auditor_fn_violation": 0.013082400907673717,
            "auditor_fp_violation": 0.023374591518730215,
            "ave_precision_score": 0.7302316935855135,
            "fpr": 0.1964873765093304,
            "logloss": 2.6166996354786924,
            "mae": 0.3031983927851525,
            "precision": 0.6966101694915254,
            "recall": 0.8634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 29756,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7994470908114899,
            "auditor_fn_violation": 0.008675585407032225,
            "auditor_fp_violation": 0.0157096369957151,
            "ave_precision_score": 0.7835086364072852,
            "fpr": 0.14912280701754385,
            "logloss": 1.441455769986949,
            "mae": 0.28251496024313383,
            "precision": 0.7424242424242424,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8178931726923745,
            "auditor_fn_violation": 0.012385964264959555,
            "auditor_fp_violation": 0.023112154131496275,
            "ave_precision_score": 0.8094582565696754,
            "fpr": 0.14709110867178923,
            "logloss": 1.1541510689418757,
            "mae": 0.28821621106581763,
            "precision": 0.7377690802348337,
            "recall": 0.792016806722689
        }
    }
]