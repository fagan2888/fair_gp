[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 10132,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8143302881731377,
            "auditor_fn_violation": 0.02692216508005982,
            "auditor_fp_violation": 0.02993853543371189,
            "ave_precision_score": 0.8139025726385734,
            "fpr": 0.12938596491228072,
            "logloss": 1.2347880153671842,
            "mae": 0.2703555060229927,
            "precision": 0.7586912065439673,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8324273373881816,
            "auditor_fn_violation": 0.027047850676370326,
            "auditor_fp_violation": 0.027051411214531675,
            "ave_precision_score": 0.8327677436148624,
            "fpr": 0.14270032930845225,
            "logloss": 1.1697846578711173,
            "mae": 0.2577724994241225,
            "precision": 0.74609375,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.815160630636083,
            "auditor_fn_violation": 0.02557947623737098,
            "auditor_fp_violation": 0.027229108153213662,
            "ave_precision_score": 0.8146898868398661,
            "fpr": 0.13267543859649122,
            "logloss": 1.2238603717726146,
            "mae": 0.27139710935621114,
            "precision": 0.7545638945233266,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8328071510573463,
            "auditor_fn_violation": 0.027047850676370326,
            "auditor_fp_violation": 0.027815787758948222,
            "ave_precision_score": 0.833023487832989,
            "fpr": 0.1437980241492865,
            "logloss": 1.1615790970544029,
            "mae": 0.2577262680213801,
            "precision": 0.7446393762183235,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8143115329487642,
            "auditor_fn_violation": 0.0180066199803042,
            "auditor_fp_violation": 0.029615439410591447,
            "ave_precision_score": 0.8148206002141656,
            "fpr": 0.12390350877192982,
            "logloss": 1.0804379687366743,
            "mae": 0.28105006724358783,
            "precision": 0.7527352297592997,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8305686890768664,
            "auditor_fn_violation": 0.03306544628373439,
            "auditor_fp_violation": 0.02401395425770267,
            "ave_precision_score": 0.8308913395760221,
            "fpr": 0.12952799121844127,
            "logloss": 0.9688221966017575,
            "mae": 0.2674917100498909,
            "precision": 0.7510548523206751,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7315710023884161,
            "auditor_fn_violation": 0.010917040522303688,
            "auditor_fp_violation": 0.013536960149794441,
            "ave_precision_score": 0.7319952744775428,
            "fpr": 0.14583333333333334,
            "logloss": 0.9081040778028326,
            "mae": 0.3232782508602484,
            "precision": 0.72,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7731904247223989,
            "auditor_fn_violation": 0.006655790282267714,
            "auditor_fp_violation": 0.010059696555042633,
            "ave_precision_score": 0.7744059193187488,
            "fpr": 0.13172338090010977,
            "logloss": 0.8264638504416822,
            "mae": 0.3012148232792701,
            "precision": 0.744136460554371,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8169059467073396,
            "auditor_fn_violation": 0.027384925411241205,
            "auditor_fp_violation": 0.029500956567753495,
            "ave_precision_score": 0.8174498062868225,
            "fpr": 0.12719298245614036,
            "logloss": 1.1615607488368505,
            "mae": 0.27094484505831157,
            "precision": 0.7578288100208769,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8433673957900669,
            "auditor_fn_violation": 0.02840778551089225,
            "auditor_fp_violation": 0.026725611375927917,
            "ave_precision_score": 0.84367293768619,
            "fpr": 0.14270032930845225,
            "logloss": 1.0790423403095422,
            "mae": 0.25762105413807235,
            "precision": 0.7455968688845401,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8073504966878755,
            "auditor_fn_violation": 0.02219653864390707,
            "auditor_fp_violation": 0.0297731713273904,
            "ave_precision_score": 0.8069162689598812,
            "fpr": 0.13048245614035087,
            "logloss": 1.2644340529945866,
            "mae": 0.27431732016696836,
            "precision": 0.7536231884057971,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8256583069084832,
            "auditor_fn_violation": 0.02639573175401425,
            "auditor_fp_violation": 0.025487571989233564,
            "ave_precision_score": 0.8262580332918736,
            "fpr": 0.13830954994511527,
            "logloss": 1.2137502388016463,
            "mae": 0.25729492937676995,
            "precision": 0.7514792899408284,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.826985956874956,
            "auditor_fn_violation": 0.016050716708611443,
            "auditor_fp_violation": 0.028806427321203244,
            "ave_precision_score": 0.8274505052162037,
            "fpr": 0.13267543859649122,
            "logloss": 0.913982204610166,
            "mae": 0.271852964344052,
            "precision": 0.7540650406504065,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8444632666908182,
            "auditor_fn_violation": 0.020048595623609028,
            "auditor_fp_violation": 0.021202051035291648,
            "ave_precision_score": 0.8447559726150435,
            "fpr": 0.13172338090010977,
            "logloss": 0.809567642198066,
            "mae": 0.26042327718570807,
            "precision": 0.7575757575757576,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8188467695078355,
            "auditor_fn_violation": 0.012405624247729516,
            "auditor_fp_violation": 0.018480074897219846,
            "ave_precision_score": 0.8195052052964618,
            "fpr": 0.17653508771929824,
            "logloss": 0.8740350214184642,
            "mae": 0.2835107212260606,
            "precision": 0.710431654676259,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8489598922629629,
            "auditor_fn_violation": 0.016110354302476426,
            "auditor_fp_violation": 0.0244450125057015,
            "ave_precision_score": 0.8491675577615517,
            "fpr": 0.17892425905598244,
            "logloss": 0.7884600723773548,
            "mae": 0.27099056149248474,
            "precision": 0.7104795737122558,
            "recall": 0.8456659619450317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7556207091284424,
            "auditor_fn_violation": 0.015202702702702707,
            "auditor_fp_violation": 0.02926435869255506,
            "ave_precision_score": 0.756332260639331,
            "fpr": 0.1699561403508772,
            "logloss": 1.0996929600440162,
            "mae": 0.3276430585727482,
            "precision": 0.6893787575150301,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.767699070635823,
            "auditor_fn_violation": 0.024446337110672237,
            "auditor_fp_violation": 0.030647740202196395,
            "ave_precision_score": 0.7683213647087956,
            "fpr": 0.15916575192096596,
            "logloss": 1.0043279407787926,
            "mae": 0.30455182449266743,
            "precision": 0.7111553784860558,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8419829727518883,
            "auditor_fn_violation": 0.00040577014261225313,
            "auditor_fp_violation": 0.005645276183498191,
            "ave_precision_score": 0.8423914841358713,
            "fpr": 0.12938596491228072,
            "logloss": 0.5066849893035293,
            "mae": 0.31874639881068123,
            "precision": 0.764,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8705244316577548,
            "auditor_fn_violation": 0.012095529620355394,
            "auditor_fp_violation": 0.020059245447573794,
            "ave_precision_score": 0.870717442623375,
            "fpr": 0.12952799121844127,
            "logloss": 0.48031616104801417,
            "mae": 0.31231126929433967,
            "precision": 0.7699805068226121,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7531895855492767,
            "auditor_fn_violation": 0.023897125870810085,
            "auditor_fp_violation": 0.024435726787967606,
            "ave_precision_score": 0.7515055817831178,
            "fpr": 0.13815789473684212,
            "logloss": 1.6483979648821987,
            "mae": 0.3030439556521005,
            "precision": 0.7278617710583153,
            "recall": 0.7006237006237006
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7715984864090983,
            "auditor_fn_violation": 0.03285426186403901,
            "auditor_fp_violation": 0.027457407936484067,
            "ave_precision_score": 0.7693274323421047,
            "fpr": 0.145993413830955,
            "logloss": 1.5768794978336094,
            "mae": 0.28347004463386144,
            "precision": 0.7285714285714285,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8173634177161566,
            "auditor_fn_violation": 0.017607688660320243,
            "auditor_fp_violation": 0.030236190825090572,
            "ave_precision_score": 0.8178475918967723,
            "fpr": 0.1206140350877193,
            "logloss": 1.006998721097266,
            "mae": 0.280722847515096,
            "precision": 0.7587719298245614,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8350121068350519,
            "auditor_fn_violation": 0.024590221001014153,
            "auditor_fp_violation": 0.02069079590394418,
            "ave_precision_score": 0.8353181024263259,
            "fpr": 0.1251372118551043,
            "logloss": 0.890231183959056,
            "mae": 0.2649164147068997,
            "precision": 0.758985200845666,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8126595243728689,
            "auditor_fn_violation": 0.023062789510157933,
            "auditor_fp_violation": 0.03525308340456711,
            "ave_precision_score": 0.8133604360764312,
            "fpr": 0.1513157894736842,
            "logloss": 1.003267453519261,
            "mae": 0.27589311737215405,
            "precision": 0.7335907335907336,
            "recall": 0.7900207900207901
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8343757671597314,
            "auditor_fn_violation": 0.03254792842008526,
            "auditor_fp_violation": 0.03802835962287417,
            "ave_precision_score": 0.8347018318135326,
            "fpr": 0.16465422612513722,
            "logloss": 0.9128271392267034,
            "mae": 0.26954382244102104,
            "precision": 0.719626168224299,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8325108531364018,
            "auditor_fn_violation": 0.012065962723857461,
            "auditor_fp_violation": 0.02411517482802133,
            "ave_precision_score": 0.8320203048493184,
            "fpr": 0.16447368421052633,
            "logloss": 0.8745324869944913,
            "mae": 0.27957786215041697,
            "precision": 0.7175141242937854,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8608618979028424,
            "auditor_fn_violation": 0.014557800711529047,
            "auditor_fp_violation": 0.02321699772942574,
            "ave_precision_score": 0.8610294169136644,
            "fpr": 0.17453347969264543,
            "logloss": 0.7626523371096714,
            "mae": 0.27155772601323985,
            "precision": 0.7124773960216998,
            "recall": 0.8329809725158562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7761897824435404,
            "auditor_fn_violation": 0.04659289856658278,
            "auditor_fp_violation": 0.06320979362559533,
            "ave_precision_score": 0.7768270808539733,
            "fpr": 0.21162280701754385,
            "logloss": 0.7065561973065682,
            "mae": 0.33507653246836033,
            "precision": 0.6723259762308998,
            "recall": 0.8232848232848233
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8194208870852885,
            "auditor_fn_violation": 0.04672977445039836,
            "auditor_fp_violation": 0.060643880727185254,
            "ave_precision_score": 0.8196732251260941,
            "fpr": 0.20636663007683864,
            "logloss": 0.6500748050134408,
            "mae": 0.3264942099343215,
            "precision": 0.6724738675958188,
            "recall": 0.8160676532769556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.819644528108781,
            "auditor_fn_violation": 0.017199638910165228,
            "auditor_fp_violation": 0.025074286644685966,
            "ave_precision_score": 0.8211257902866,
            "fpr": 0.125,
            "logloss": 0.9879462382348337,
            "mae": 0.2720624423258158,
            "precision": 0.758985200845666,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8513307872760056,
            "auditor_fn_violation": 0.02321404121113104,
            "auditor_fp_violation": 0.017142083815767713,
            "ave_precision_score": 0.851626764170875,
            "fpr": 0.12184412733260154,
            "logloss": 0.8197250092226964,
            "mae": 0.254856530626246,
            "precision": 0.7682672233820459,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.811360906650129,
            "auditor_fn_violation": 0.02104533683481052,
            "auditor_fp_violation": 0.024962347865022192,
            "ave_precision_score": 0.8110321501941677,
            "fpr": 0.12609649122807018,
            "logloss": 1.2152164514498969,
            "mae": 0.27573680588319904,
            "precision": 0.7573839662447257,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8301584247007019,
            "auditor_fn_violation": 0.022531753085961344,
            "auditor_fp_violation": 0.02533970898555955,
            "ave_precision_score": 0.830572312304749,
            "fpr": 0.13721185510428102,
            "logloss": 1.1676480446348863,
            "mae": 0.25691342898226577,
            "precision": 0.750996015936255,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.81005599519772,
            "auditor_fn_violation": 0.01595041397672977,
            "auditor_fp_violation": 0.03190764033052469,
            "ave_precision_score": 0.810587770894778,
            "fpr": 0.13815789473684212,
            "logloss": 1.0267714475697294,
            "mae": 0.27990316657118364,
            "precision": 0.7375,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8298859768777151,
            "auditor_fn_violation": 0.02633307264047825,
            "auditor_fp_violation": 0.027908515405320064,
            "ave_precision_score": 0.8302987989271515,
            "fpr": 0.1350164654226125,
            "logloss": 0.8976126213375896,
            "mae": 0.26395495331863666,
            "precision": 0.7505070993914807,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8111680021231553,
            "auditor_fn_violation": 0.02340017142648722,
            "auditor_fp_violation": 0.03610025644156797,
            "ave_precision_score": 0.8118664099026643,
            "fpr": 0.13925438596491227,
            "logloss": 1.0033624487016979,
            "mae": 0.2764525218334802,
            "precision": 0.7381443298969073,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8375601475532697,
            "auditor_fn_violation": 0.02833352285781255,
            "auditor_fp_violation": 0.031549955139868385,
            "ave_precision_score": 0.8378920775887402,
            "fpr": 0.1437980241492865,
            "logloss": 0.8812708171949418,
            "mae": 0.26456117169848087,
            "precision": 0.7385229540918163,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8170592074746482,
            "auditor_fn_violation": 0.02518510413247256,
            "auditor_fp_violation": 0.0340828143444458,
            "ave_precision_score": 0.8175269613273758,
            "fpr": 0.15021929824561403,
            "logloss": 0.9644839509641798,
            "mae": 0.27361867236040743,
            "precision": 0.730844793713163,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8385419235791306,
            "auditor_fn_violation": 0.02998586688883577,
            "auditor_fp_violation": 0.03386814629916445,
            "ave_precision_score": 0.8388500382315726,
            "fpr": 0.1525795828759605,
            "logloss": 0.8709988033801932,
            "mae": 0.2669103032333587,
            "precision": 0.7337164750957854,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7844015278842063,
            "auditor_fn_violation": 0.018154794470583952,
            "auditor_fp_violation": 0.02209010054137665,
            "ave_precision_score": 0.7840732925918645,
            "fpr": 0.13048245614035087,
            "logloss": 1.4215487903607162,
            "mae": 0.2840097028925045,
            "precision": 0.75,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8023083556025736,
            "auditor_fn_violation": 0.02232521008208344,
            "auditor_fp_violation": 0.02075094356645565,
            "ave_precision_score": 0.800299393020611,
            "fpr": 0.14709110867178923,
            "logloss": 1.4250447452909123,
            "mae": 0.26259620788098725,
            "precision": 0.7377690802348337,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8139134724418832,
            "auditor_fn_violation": 0.023671444724076306,
            "auditor_fp_violation": 0.03224091260634184,
            "ave_precision_score": 0.8144134323748571,
            "fpr": 0.1425438596491228,
            "logloss": 0.9861148504907252,
            "mae": 0.27614936862731504,
            "precision": 0.7352342158859471,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8419206107298359,
            "auditor_fn_violation": 0.03277071637932435,
            "auditor_fp_violation": 0.03365261717516503,
            "ave_precision_score": 0.8421993032193459,
            "fpr": 0.145993413830955,
            "logloss": 0.8702025672005795,
            "mae": 0.26444212486968594,
            "precision": 0.7387033398821218,
            "recall": 0.7949260042283298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 10132,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6393369521304606,
            "auditor_fn_violation": 0.019536236641499807,
            "auditor_fp_violation": 0.014272194407131528,
            "ave_precision_score": 0.596234278680479,
            "fpr": 0.15350877192982457,
            "logloss": 6.299585260416528,
            "mae": 0.4280465121012643,
            "precision": 0.6306068601583114,
            "recall": 0.4968814968814969
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6842370721279563,
            "auditor_fn_violation": 0.020057878455243986,
            "auditor_fp_violation": 0.006648822860121605,
            "ave_precision_score": 0.6413576130493239,
            "fpr": 0.1525795828759605,
            "logloss": 5.681750306203896,
            "mae": 0.3888599369360949,
            "precision": 0.6533665835411472,
            "recall": 0.5539112050739958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8158200690750108,
            "auditor_fn_violation": 0.023691961191961198,
            "auditor_fp_violation": 0.03381568771115725,
            "ave_precision_score": 0.8163668797051788,
            "fpr": 0.14473684210526316,
            "logloss": 0.96788583387131,
            "mae": 0.27353473023391833,
            "precision": 0.7365269461077845,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8366579839473539,
            "auditor_fn_violation": 0.030733134835450208,
            "auditor_fp_violation": 0.03306617746567824,
            "ave_precision_score": 0.8369839290001051,
            "fpr": 0.1525795828759605,
            "logloss": 0.8714474051874046,
            "mae": 0.2667235731793045,
            "precision": 0.7316602316602316,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7912379466686776,
            "auditor_fn_violation": 0.012850147718568773,
            "auditor_fp_violation": 0.023547848740179917,
            "ave_precision_score": 0.7553972754999829,
            "fpr": 0.14035087719298245,
            "logloss": 4.1507419996994,
            "mae": 0.28721300181570913,
            "precision": 0.7355371900826446,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7992359138339387,
            "auditor_fn_violation": 0.013232676495638227,
            "auditor_fp_violation": 0.013267571888987464,
            "ave_precision_score": 0.7572308874740858,
            "fpr": 0.145993413830955,
            "logloss": 3.8595283238386715,
            "mae": 0.26443418598463414,
            "precision": 0.740234375,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7149755053601101,
            "auditor_fn_violation": 0.02371019805230332,
            "auditor_fp_violation": 0.01758202059673546,
            "ave_precision_score": 0.7149834522231694,
            "fpr": 0.07017543859649122,
            "logloss": 3.2411807169812143,
            "mae": 0.3816952026939052,
            "precision": 0.7730496453900709,
            "recall": 0.45322245322245325
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7265725361515438,
            "auditor_fn_violation": 0.02297732900443952,
            "auditor_fp_violation": 0.01869589843064724,
            "ave_precision_score": 0.727452808783007,
            "fpr": 0.07025246981339188,
            "logloss": 3.4538031565192564,
            "mae": 0.3644755957383812,
            "precision": 0.7762237762237763,
            "recall": 0.4693446088794926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8078957452583827,
            "auditor_fn_violation": 0.020441240835977682,
            "auditor_fp_violation": 0.026025766271828066,
            "ave_precision_score": 0.8075834970857247,
            "fpr": 0.12828947368421054,
            "logloss": 1.251734048308306,
            "mae": 0.27702305678668154,
            "precision": 0.7536842105263157,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8255214698705989,
            "auditor_fn_violation": 0.022886821395998642,
            "auditor_fp_violation": 0.025457498157977834,
            "ave_precision_score": 0.8260549085862139,
            "fpr": 0.1394072447859495,
            "logloss": 1.204006460453431,
            "mae": 0.25851352581713616,
            "precision": 0.7470119521912351,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8283241565463404,
            "auditor_fn_violation": 0.01950660174344385,
            "auditor_fp_violation": 0.026532034843489236,
            "ave_precision_score": 0.8287405089128168,
            "fpr": 0.12938596491228072,
            "logloss": 0.8385801421674055,
            "mae": 0.2701095573490803,
            "precision": 0.756701030927835,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.85567296601569,
            "auditor_fn_violation": 0.020118216860871244,
            "auditor_fp_violation": 0.02604393786746463,
            "ave_precision_score": 0.8559308731613612,
            "fpr": 0.132821075740944,
            "logloss": 0.7233820179490003,
            "mae": 0.2541150057909253,
            "precision": 0.7584830339321357,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8292740566467219,
            "auditor_fn_violation": 0.016221687274318858,
            "auditor_fp_violation": 0.027196035331949368,
            "ave_precision_score": 0.8288887652095218,
            "fpr": 0.1699561403508772,
            "logloss": 0.9400582140874656,
            "mae": 0.2785020508317099,
            "precision": 0.7176684881602914,
            "recall": 0.8191268191268192
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8509283146914672,
            "auditor_fn_violation": 0.013279090653813042,
            "auditor_fp_violation": 0.02457533244114301,
            "ave_precision_score": 0.8511142454092924,
            "fpr": 0.18221734357848518,
            "logloss": 0.8232751108587039,
            "mae": 0.2671378844241907,
            "precision": 0.7092819614711033,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8235136199488953,
            "auditor_fn_violation": 0.009982401429769855,
            "auditor_fp_violation": 0.024191496723246633,
            "ave_precision_score": 0.8239104218759088,
            "fpr": 0.12828947368421054,
            "logloss": 0.838691139714243,
            "mae": 0.28118053676750665,
            "precision": 0.7526427061310782,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.843046817182775,
            "auditor_fn_violation": 0.011236867694121418,
            "auditor_fp_violation": 0.015187284784145084,
            "ave_precision_score": 0.8433334656723098,
            "fpr": 0.13391877058177826,
            "logloss": 0.7311429681031103,
            "mae": 0.2631912990717415,
            "precision": 0.7530364372469636,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7961084300717023,
            "auditor_fn_violation": 0.013068990042674264,
            "auditor_fp_violation": 0.022486974396548225,
            "ave_precision_score": 0.7965590933363987,
            "fpr": 0.13157894736842105,
            "logloss": 0.9423294986660823,
            "mae": 0.3017447592101705,
            "precision": 0.7379912663755459,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8126954519139199,
            "auditor_fn_violation": 0.015602119270462265,
            "auditor_fp_violation": 0.014144725300613009,
            "ave_precision_score": 0.8132344965308201,
            "fpr": 0.12623490669593854,
            "logloss": 0.8240484574408169,
            "mae": 0.27753033850570835,
            "precision": 0.7568710359408034,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8282532354156149,
            "auditor_fn_violation": 0.01950660174344385,
            "auditor_fp_violation": 0.026532034843489236,
            "ave_precision_score": 0.8286727571660648,
            "fpr": 0.12938596491228072,
            "logloss": 0.8386008257054678,
            "mae": 0.27011937957001275,
            "precision": 0.756701030927835,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.855643620603243,
            "auditor_fn_violation": 0.020118216860871244,
            "auditor_fp_violation": 0.02604393786746463,
            "ave_precision_score": 0.8559017267682651,
            "fpr": 0.132821075740944,
            "logloss": 0.7234727603541067,
            "mae": 0.25412473590963125,
            "precision": 0.7584830339321357,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8154593567841253,
            "auditor_fn_violation": 0.024375843454790828,
            "auditor_fp_violation": 0.03466031668498393,
            "ave_precision_score": 0.8160522015967688,
            "fpr": 0.14692982456140352,
            "logloss": 0.9691552756838878,
            "mae": 0.27415896710456983,
            "precision": 0.7341269841269841,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8360851098955249,
            "auditor_fn_violation": 0.029261806021308748,
            "auditor_fp_violation": 0.03377291250018796,
            "ave_precision_score": 0.8364028211523422,
            "fpr": 0.15697036223929747,
            "logloss": 0.8769472003581414,
            "mae": 0.26730160028687666,
            "precision": 0.7270992366412213,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7849247236155644,
            "auditor_fn_violation": 0.017293102819418614,
            "auditor_fp_violation": 0.021532950706231936,
            "ave_precision_score": 0.7846108412166154,
            "fpr": 0.12719298245614036,
            "logloss": 1.4157220511985387,
            "mae": 0.28433476389732343,
            "precision": 0.7521367521367521,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.802440453016309,
            "auditor_fn_violation": 0.02211170495447931,
            "auditor_fp_violation": 0.020615611325804854,
            "ave_precision_score": 0.8003654347557039,
            "fpr": 0.141602634467618,
            "logloss": 1.4166123142938762,
            "mae": 0.26262019483329874,
            "precision": 0.742,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7595260230682548,
            "auditor_fn_violation": 0.021555968924389986,
            "auditor_fp_violation": 0.020678145479708556,
            "ave_precision_score": 0.7560233454898124,
            "fpr": 0.1337719298245614,
            "logloss": 1.5985963059879915,
            "mae": 0.2879311474793435,
            "precision": 0.7436974789915967,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7603298509543583,
            "auditor_fn_violation": 0.029034376646252174,
            "auditor_fp_violation": 0.020244700740317485,
            "ave_precision_score": 0.7605181586444847,
            "fpr": 0.145993413830955,
            "logloss": 1.5592957920588477,
            "mae": 0.2702228774795223,
            "precision": 0.7397260273972602,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7689157611329644,
            "auditor_fn_violation": 0.0028289929605719096,
            "auditor_fp_violation": 0.018991431595229383,
            "ave_precision_score": 0.5917391869404148,
            "fpr": 0.375,
            "logloss": 11.889510944078646,
            "mae": 0.4126648843738737,
            "precision": 0.5665399239543726,
            "recall": 0.9293139293139293
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7729014624986248,
            "auditor_fn_violation": 0.007463396634509393,
            "auditor_fp_violation": 0.01525495090447049,
            "ave_precision_score": 0.5837543528950774,
            "fpr": 0.38529088913282106,
            "logloss": 12.395201984567855,
            "mae": 0.41902854119256455,
            "precision": 0.5584905660377358,
            "recall": 0.9386892177589852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7891648960025255,
            "auditor_fn_violation": 0.017662399241346615,
            "auditor_fp_violation": 0.023268001791020475,
            "ave_precision_score": 0.7888315262497516,
            "fpr": 0.12828947368421054,
            "logloss": 1.4109099121655588,
            "mae": 0.2833085047263804,
            "precision": 0.75,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8046497184444648,
            "auditor_fn_violation": 0.022986611836074478,
            "auditor_fp_violation": 0.023066628573147077,
            "ave_precision_score": 0.8033809735825017,
            "fpr": 0.141602634467618,
            "logloss": 1.3895326387140157,
            "mae": 0.26298228084552655,
            "precision": 0.7409638554216867,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8038501374824011,
            "auditor_fn_violation": 0.032071798519166944,
            "auditor_fp_violation": 0.023016139536776982,
            "ave_precision_score": 0.8035317744326229,
            "fpr": 0.1425438596491228,
            "logloss": 1.1042645575144805,
            "mae": 0.27816737062444635,
            "precision": 0.7504798464491362,
            "recall": 0.8128898128898129
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8304618665197394,
            "auditor_fn_violation": 0.029939452730660964,
            "auditor_fp_violation": 0.032760426847911625,
            "ave_precision_score": 0.8304897102878969,
            "fpr": 0.1437980241492865,
            "logloss": 1.081676412974213,
            "mae": 0.26207244288589854,
            "precision": 0.7509505703422054,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7522599026037515,
            "auditor_fn_violation": 0.024660794397636507,
            "auditor_fp_violation": 0.030757723775796803,
            "ave_precision_score": 0.7520920240407176,
            "fpr": 0.17324561403508773,
            "logloss": 1.374915340255056,
            "mae": 0.32528900594781174,
            "precision": 0.6871287128712872,
            "recall": 0.7214137214137214
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7632980785856237,
            "auditor_fn_violation": 0.031139258719479795,
            "auditor_fp_violation": 0.032254184021773456,
            "ave_precision_score": 0.7641203667980924,
            "fpr": 0.1668496158068057,
            "logloss": 1.361011183645151,
            "mae": 0.29928481252083194,
            "precision": 0.7071290944123314,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8317114010157908,
            "auditor_fn_violation": 0.0223196374512164,
            "auditor_fp_violation": 0.023234928969756187,
            "ave_precision_score": 0.8320577328212353,
            "fpr": 0.14035087719298245,
            "logloss": 0.6710154029909927,
            "mae": 0.27771989480452786,
            "precision": 0.75,
            "recall": 0.7983367983367984
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8728701786144202,
            "auditor_fn_violation": 0.027201017398347196,
            "auditor_fp_violation": 0.03251482389265647,
            "ave_precision_score": 0.8730378623796468,
            "fpr": 0.145993413830955,
            "logloss": 0.5789476249375811,
            "mae": 0.2611241794803927,
            "precision": 0.7481060606060606,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8161592292725827,
            "auditor_fn_violation": 0.02520334099281468,
            "auditor_fp_violation": 0.03443389506248219,
            "ave_precision_score": 0.816703562582488,
            "fpr": 0.1425438596491228,
            "logloss": 0.9643830439253692,
            "mae": 0.2734973026162761,
            "precision": 0.7379032258064516,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8385836509029947,
            "auditor_fn_violation": 0.029273409560852445,
            "auditor_fp_violation": 0.031261747590334274,
            "ave_precision_score": 0.8389542441145232,
            "fpr": 0.14818880351262348,
            "logloss": 0.85969592188205,
            "mae": 0.2648564500629856,
            "precision": 0.7368421052631579,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8062115936956946,
            "auditor_fn_violation": 0.022440456650982973,
            "auditor_fp_violation": 0.026152969430536903,
            "ave_precision_score": 0.8057885382828471,
            "fpr": 0.12938596491228072,
            "logloss": 1.294552529478821,
            "mae": 0.27422238165230983,
            "precision": 0.7546777546777547,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8229205855108583,
            "auditor_fn_violation": 0.023710672703601506,
            "auditor_fp_violation": 0.025713125723651576,
            "ave_precision_score": 0.8234649872065491,
            "fpr": 0.14270032930845225,
            "logloss": 1.243646072631636,
            "mae": 0.2582391752867297,
            "precision": 0.7445972495088409,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8170035095030296,
            "auditor_fn_violation": 0.016162417478206962,
            "auditor_fp_violation": 0.027038303415150407,
            "ave_precision_score": 0.8175307275332164,
            "fpr": 0.11732456140350878,
            "logloss": 1.0164972776741026,
            "mae": 0.28094541091365793,
            "precision": 0.7632743362831859,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8345660438614286,
            "auditor_fn_violation": 0.02519128434937794,
            "auditor_fp_violation": 0.021076743405059422,
            "ave_precision_score": 0.8348734594323894,
            "fpr": 0.1207464324917673,
            "logloss": 0.8980389273075503,
            "mae": 0.26489328597092593,
            "precision": 0.7644539614561028,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7906365794837895,
            "auditor_fn_violation": 0.015214100740416537,
            "auditor_fp_violation": 0.021212398746285666,
            "ave_precision_score": 0.7903061898282511,
            "fpr": 0.14583333333333334,
            "logloss": 1.3882104931228052,
            "mae": 0.2794580068513324,
            "precision": 0.7366336633663366,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7974189900532954,
            "auditor_fn_violation": 0.021826257881704236,
            "auditor_fp_violation": 0.028494955114806857,
            "ave_precision_score": 0.7958828303700312,
            "fpr": 0.15477497255762898,
            "logloss": 1.4256631314018038,
            "mae": 0.2666085593869175,
            "precision": 0.7319391634980988,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8145330820066119,
            "auditor_fn_violation": 0.017457234562497728,
            "auditor_fp_violation": 0.015579842878658361,
            "ave_precision_score": 0.814953340793124,
            "fpr": 0.1074561403508772,
            "logloss": 0.9819687728824714,
            "mae": 0.28623880534147245,
            "precision": 0.7715617715617715,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8446197308725831,
            "auditor_fn_violation": 0.021724146733719654,
            "auditor_fp_violation": 0.013929196176613597,
            "ave_precision_score": 0.8448745454672866,
            "fpr": 0.10098792535675083,
            "logloss": 0.8157785422642059,
            "mae": 0.25957608591479053,
            "precision": 0.7927927927927928,
            "recall": 0.7441860465116279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8114126648264129,
            "auditor_fn_violation": 0.05106092935040304,
            "auditor_fp_violation": 0.04325925021370131,
            "ave_precision_score": 0.812059151311231,
            "fpr": 0.14473684210526316,
            "logloss": 0.6986776674495093,
            "mae": 0.31420660634685454,
            "precision": 0.7338709677419355,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8580029401755197,
            "auditor_fn_violation": 0.052608127583238,
            "auditor_fp_violation": 0.0455994466415049,
            "ave_precision_score": 0.8581610273629039,
            "fpr": 0.141602634467618,
            "logloss": 0.6402055959825425,
            "mae": 0.2975208917719158,
            "precision": 0.7404426559356136,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.789889128222216,
            "auditor_fn_violation": 0.016839460918408298,
            "auditor_fp_violation": 0.021199678430414787,
            "ave_precision_score": 0.7895617951068091,
            "fpr": 0.12280701754385964,
            "logloss": 1.43042534214182,
            "mae": 0.27897532957996335,
            "precision": 0.7606837606837606,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8004418793379389,
            "auditor_fn_violation": 0.024801405420709532,
            "auditor_fp_violation": 0.02207419214170789,
            "ave_precision_score": 0.7988460669460808,
            "fpr": 0.1350164654226125,
            "logloss": 1.4209255829828185,
            "mae": 0.26409251797812144,
            "precision": 0.7494908350305499,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8086477522948937,
            "auditor_fn_violation": 0.02340017142648722,
            "auditor_fp_violation": 0.03557617942768755,
            "ave_precision_score": 0.8091767087354335,
            "fpr": 0.14364035087719298,
            "logloss": 1.0611468972963454,
            "mae": 0.2804048129381469,
            "precision": 0.7321063394683026,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8302784283156807,
            "auditor_fn_violation": 0.027595537742833076,
            "auditor_fp_violation": 0.031123909197078827,
            "ave_precision_score": 0.830531358552395,
            "fpr": 0.145993413830955,
            "logloss": 0.9424893653030408,
            "mae": 0.26698242677325784,
            "precision": 0.73767258382643,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8124473267167389,
            "auditor_fn_violation": 0.026251960462486786,
            "auditor_fp_violation": 0.02773792078804901,
            "ave_precision_score": 0.812053626410286,
            "fpr": 0.12609649122807018,
            "logloss": 1.1886939072194351,
            "mae": 0.26961956525747915,
            "precision": 0.760914760914761,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8319147107441686,
            "auditor_fn_violation": 0.029305899471574814,
            "auditor_fp_violation": 0.027828318521971443,
            "ave_precision_score": 0.8325120696209826,
            "fpr": 0.1394072447859495,
            "logloss": 1.143468998686679,
            "mae": 0.25630919816970954,
            "precision": 0.7509803921568627,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8229790249166663,
            "auditor_fn_violation": 0.018911624174782076,
            "auditor_fp_violation": 0.027267269100826316,
            "ave_precision_score": 0.8233842220213871,
            "fpr": 0.11842105263157894,
            "logloss": 0.9895235878677929,
            "mae": 0.275740495881491,
            "precision": 0.7631578947368421,
            "recall": 0.7234927234927235
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8424978733268904,
            "auditor_fn_violation": 0.025000986300861224,
            "auditor_fp_violation": 0.02069079590394418,
            "ave_precision_score": 0.8427854383424415,
            "fpr": 0.1251372118551043,
            "logloss": 0.8665440914384444,
            "mae": 0.2622116515689006,
            "precision": 0.759493670886076,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.813312669712057,
            "auditor_fn_violation": 0.026726118831381995,
            "auditor_fp_violation": 0.02934831277730289,
            "ave_precision_score": 0.8128883164664297,
            "fpr": 0.12609649122807018,
            "logloss": 1.2463913706600953,
            "mae": 0.2706968019833352,
            "precision": 0.762396694214876,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8315485026026463,
            "auditor_fn_violation": 0.03021329626389234,
            "auditor_fp_violation": 0.025780791843976966,
            "ave_precision_score": 0.8321927007231804,
            "fpr": 0.141602634467618,
            "logloss": 1.1762728124232549,
            "mae": 0.25797036029505815,
            "precision": 0.7465618860510805,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8036787930000799,
            "auditor_fn_violation": 0.02836287704708758,
            "auditor_fp_violation": 0.03208318068954289,
            "ave_precision_score": 0.8042895989613189,
            "fpr": 0.16557017543859648,
            "logloss": 0.9789291669380633,
            "mae": 0.2983072987472526,
            "precision": 0.7203703703703703,
            "recall": 0.8087318087318087
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8145979138456783,
            "auditor_fn_violation": 0.029166656997050382,
            "auditor_fp_violation": 0.03645700193976212,
            "ave_precision_score": 0.8173483134476208,
            "fpr": 0.16355653128430298,
            "logloss": 0.9231175097353604,
            "mae": 0.27990251697170154,
            "precision": 0.7214953271028037,
            "recall": 0.8160676532769556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8112901870609869,
            "auditor_fn_violation": 0.0069345661450924655,
            "auditor_fp_violation": 0.02274646884031424,
            "ave_precision_score": 0.8116957117375697,
            "fpr": 0.13596491228070176,
            "logloss": 0.9348614511051149,
            "mae": 0.28475077682566874,
            "precision": 0.7416666666666667,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8222031200894355,
            "auditor_fn_violation": 0.009317642253593038,
            "auditor_fp_violation": 0.011423043571969186,
            "ave_precision_score": 0.8224796172213629,
            "fpr": 0.145993413830955,
            "logloss": 0.8543551125785876,
            "mae": 0.2733554830661181,
            "precision": 0.7371541501976284,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8167732953821732,
            "auditor_fn_violation": 0.01734553379290222,
            "auditor_fp_violation": 0.031284344852851385,
            "ave_precision_score": 0.817258450020456,
            "fpr": 0.12280701754385964,
            "logloss": 1.017022322401695,
            "mae": 0.2806102903624993,
            "precision": 0.7559912854030502,
            "recall": 0.7214137214137214
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8344136086182524,
            "auditor_fn_violation": 0.02519128434937794,
            "auditor_fp_violation": 0.02069079590394418,
            "ave_precision_score": 0.8347203574606639,
            "fpr": 0.1251372118551043,
            "logloss": 0.8980949114609512,
            "mae": 0.26453964681603515,
            "precision": 0.7579617834394905,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.804888635251917,
            "auditor_fn_violation": 0.02324515811357917,
            "auditor_fp_violation": 0.027190947205601015,
            "ave_precision_score": 0.8045001138881299,
            "fpr": 0.13157894736842105,
            "logloss": 1.348202972381831,
            "mae": 0.2754792895587014,
            "precision": 0.7478991596638656,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8251872580091169,
            "auditor_fn_violation": 0.02729848713051429,
            "auditor_fp_violation": 0.028028810730343,
            "ave_precision_score": 0.8254195832043071,
            "fpr": 0.14270032930845225,
            "logloss": 1.2792658787456992,
            "mae": 0.25910109410616067,
            "precision": 0.7440944881889764,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7555908466297794,
            "auditor_fn_violation": 0.022729966808914183,
            "auditor_fp_violation": 0.013768469898644522,
            "ave_precision_score": 0.7540260602952051,
            "fpr": 0.11513157894736842,
            "logloss": 1.3852576261448295,
            "mae": 0.314002644619157,
            "precision": 0.7717391304347826,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.7859188581173948,
            "auditor_fn_violation": 0.02922699540267763,
            "auditor_fp_violation": 0.013708654747404885,
            "ave_precision_score": 0.7839794369569286,
            "fpr": 0.10098792535675083,
            "logloss": 1.258215975918257,
            "mae": 0.29455112245626014,
            "precision": 0.7973568281938326,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7889896990359542,
            "auditor_fn_violation": 0.018631232447021927,
            "auditor_fp_violation": 0.020673057353360207,
            "ave_precision_score": 0.7886482665682741,
            "fpr": 0.12280701754385964,
            "logloss": 1.4379952334878352,
            "mae": 0.2843113027532084,
            "precision": 0.7543859649122807,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8066427485127359,
            "auditor_fn_violation": 0.0234693190810925,
            "auditor_fp_violation": 0.02673062368113719,
            "ave_precision_score": 0.8054150242081137,
            "fpr": 0.12733260153677278,
            "logloss": 1.3944565769719703,
            "mae": 0.26107147943159187,
            "precision": 0.7608247422680412,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8211913950438573,
            "auditor_fn_violation": 0.011607761607761617,
            "auditor_fp_violation": 0.02357328937192169,
            "ave_precision_score": 0.8216988507592005,
            "fpr": 0.12609649122807018,
            "logloss": 0.8774536400838375,
            "mae": 0.2803494548117381,
            "precision": 0.7553191489361702,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8340061894127707,
            "auditor_fn_violation": 0.010517448242411869,
            "auditor_fp_violation": 0.02130730944468671,
            "ave_precision_score": 0.834293652373067,
            "fpr": 0.1350164654226125,
            "logloss": 0.7720306851905461,
            "mae": 0.2629521676861849,
            "precision": 0.7525150905432596,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8312630741753784,
            "auditor_fn_violation": 0.02493662691031113,
            "auditor_fp_violation": 0.02234450685879432,
            "ave_precision_score": 0.8316101321022059,
            "fpr": 0.14144736842105263,
            "logloss": 0.6726972647263281,
            "mae": 0.2779964148451633,
            "precision": 0.7485380116959064,
            "recall": 0.7983367983367984
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8723224770242863,
            "auditor_fn_violation": 0.027201017398347196,
            "auditor_fp_violation": 0.03251482389265647,
            "ave_precision_score": 0.8724911585939203,
            "fpr": 0.145993413830955,
            "logloss": 0.5807142824934807,
            "mae": 0.26146504909728413,
            "precision": 0.7481060606060606,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8286233844893813,
            "auditor_fn_violation": 0.010431484115694648,
            "auditor_fp_violation": 0.02218168681564701,
            "ave_precision_score": 0.8290336920247183,
            "fpr": 0.11293859649122807,
            "logloss": 0.8882917221581993,
            "mae": 0.27605659121283854,
            "precision": 0.7726269315673289,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8475380530076482,
            "auditor_fn_violation": 0.018865034590151382,
            "auditor_fp_violation": 0.01961315028394709,
            "ave_precision_score": 0.8478217787108675,
            "fpr": 0.1163556531284303,
            "logloss": 0.7596760033760314,
            "mae": 0.25610302091074544,
            "precision": 0.7739872068230277,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8127328920147763,
            "auditor_fn_violation": 0.021932104168946278,
            "auditor_fp_violation": 0.035395550942321,
            "ave_precision_score": 0.8135431801502422,
            "fpr": 0.13925438596491227,
            "logloss": 0.9880729298101047,
            "mae": 0.27487184609078663,
            "precision": 0.7392197125256673,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8393387703228778,
            "auditor_fn_violation": 0.027987737379410217,
            "auditor_fp_violation": 0.030555012555824553,
            "ave_precision_score": 0.8396603759470738,
            "fpr": 0.141602634467618,
            "logloss": 0.8676210013291457,
            "mae": 0.26286956576347026,
            "precision": 0.742,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7902816084834026,
            "auditor_fn_violation": 0.015396469343837767,
            "auditor_fp_violation": 0.020576382952741484,
            "ave_precision_score": 0.7899523981897767,
            "fpr": 0.12390350877192982,
            "logloss": 1.3899747979366897,
            "mae": 0.28014785935050507,
            "precision": 0.7595744680851064,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7995811950492291,
            "auditor_fn_violation": 0.02618222662641012,
            "auditor_fp_violation": 0.023096702404402814,
            "ave_precision_score": 0.7984131702402572,
            "fpr": 0.132821075740944,
            "logloss": 1.383553547530991,
            "mae": 0.26491050725402887,
            "precision": 0.7535641547861507,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8240130347036465,
            "auditor_fn_violation": 0.013531750373855643,
            "auditor_fp_violation": 0.026043574714047307,
            "ave_precision_score": 0.8244172115605861,
            "fpr": 0.12280701754385964,
            "logloss": 0.9415992772666691,
            "mae": 0.27506916696876205,
            "precision": 0.7617021276595745,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8460698779761168,
            "auditor_fn_violation": 0.020844598436307014,
            "auditor_fp_violation": 0.02178849074477843,
            "ave_precision_score": 0.8463605274619386,
            "fpr": 0.1251372118551043,
            "logloss": 0.8164233066775727,
            "mae": 0.2575879594476786,
            "precision": 0.7644628099173554,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7637215922731619,
            "auditor_fn_violation": 0.01896633475580844,
            "auditor_fp_violation": 0.027689583587739652,
            "ave_precision_score": 0.763313723122546,
            "fpr": 0.17982456140350878,
            "logloss": 1.5326511733538553,
            "mae": 0.3108148058409913,
            "precision": 0.6893939393939394,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7771071264216467,
            "auditor_fn_violation": 0.02354126102626345,
            "auditor_fp_violation": 0.03069034479647535,
            "ave_precision_score": 0.776879014453761,
            "fpr": 0.1877058177826564,
            "logloss": 1.5344092777852503,
            "mae": 0.2878274774561778,
            "precision": 0.6968085106382979,
            "recall": 0.8308668076109936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8233897380627897,
            "auditor_fn_violation": 0.013873691505270461,
            "auditor_fp_violation": 0.027023039036105354,
            "ave_precision_score": 0.8239316207741769,
            "fpr": 0.13486842105263158,
            "logloss": 0.8883884118686244,
            "mae": 0.2746624429356234,
            "precision": 0.7463917525773196,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8458295615261467,
            "auditor_fn_violation": 0.0192386685634586,
            "auditor_fp_violation": 0.02419439724523706,
            "ave_precision_score": 0.8461515049587216,
            "fpr": 0.13172338090010977,
            "logloss": 0.7708560673734538,
            "mae": 0.2570714389784374,
            "precision": 0.7585513078470825,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8336652037254823,
            "auditor_fn_violation": 0.026117463617463622,
            "auditor_fp_violation": 0.023041580168518747,
            "ave_precision_score": 0.8340124338150154,
            "fpr": 0.13706140350877194,
            "logloss": 0.6714976058595459,
            "mae": 0.2753891220299903,
            "precision": 0.7553816046966731,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8747907412820453,
            "auditor_fn_violation": 0.027379711907320206,
            "auditor_fp_violation": 0.031848187299821064,
            "ave_precision_score": 0.8749511472050072,
            "fpr": 0.145993413830955,
            "logloss": 0.5772646724264333,
            "mae": 0.26030476023117377,
            "precision": 0.7466666666666667,
            "recall": 0.828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8082371153584238,
            "auditor_fn_violation": 0.02254075938286465,
            "auditor_fp_violation": 0.027053567794195474,
            "ave_precision_score": 0.8077822648560395,
            "fpr": 0.12938596491228072,
            "logloss": 1.2516924779123553,
            "mae": 0.27663571459468994,
            "precision": 0.751578947368421,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8280041800842953,
            "auditor_fn_violation": 0.02603138061234199,
            "auditor_fp_violation": 0.024713170834398456,
            "ave_precision_score": 0.8281139861155677,
            "fpr": 0.13721185510428102,
            "logloss": 1.1860416692550537,
            "mae": 0.257517141191801,
            "precision": 0.750996015936255,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7920028164513999,
            "auditor_fn_violation": 0.018248258379837328,
            "auditor_fp_violation": 0.02148970163227094,
            "ave_precision_score": 0.7916812742620696,
            "fpr": 0.12719298245614036,
            "logloss": 1.3993230632182576,
            "mae": 0.27785615097891275,
            "precision": 0.7552742616033755,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8054251300796901,
            "auditor_fn_violation": 0.02307247802869787,
            "auditor_fp_violation": 0.025028946062583646,
            "ave_precision_score": 0.8041005541365035,
            "fpr": 0.1394072447859495,
            "logloss": 1.3895471578387024,
            "mae": 0.26126303635386605,
            "precision": 0.746,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8080049878184452,
            "auditor_fn_violation": 0.02174289674289675,
            "auditor_fp_violation": 0.025692493996010913,
            "ave_precision_score": 0.8076148700210807,
            "fpr": 0.12609649122807018,
            "logloss": 1.266186234915781,
            "mae": 0.2728771808809985,
            "precision": 0.7584033613445378,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8247975833963941,
            "auditor_fn_violation": 0.027161565363898608,
            "auditor_fp_violation": 0.025988802510162445,
            "ave_precision_score": 0.8254227770450296,
            "fpr": 0.13611416026344675,
            "logloss": 1.2144265110196202,
            "mae": 0.25771997013381437,
            "precision": 0.7524950099800399,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8164626957576401,
            "auditor_fn_violation": 0.016285516285516288,
            "auditor_fp_violation": 0.0291396995970204,
            "ave_precision_score": 0.8169502357505741,
            "fpr": 0.1206140350877193,
            "logloss": 1.0174896088902987,
            "mae": 0.28159398296163685,
            "precision": 0.7577092511013216,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8339108393521648,
            "auditor_fn_violation": 0.02519128434937794,
            "auditor_fp_violation": 0.019167055120320384,
            "ave_precision_score": 0.8341228847307338,
            "fpr": 0.1207464324917673,
            "logloss": 0.8999040198407895,
            "mae": 0.2654146796585854,
            "precision": 0.7644539614561028,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7753862054019838,
            "auditor_fn_violation": 0.016679888390414708,
            "auditor_fp_violation": 0.02075955550128221,
            "ave_precision_score": 0.7749559626012373,
            "fpr": 0.125,
            "logloss": 1.5026420794657769,
            "mae": 0.2890110600276238,
            "precision": 0.7527114967462039,
            "recall": 0.7214137214137214
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7977811838812523,
            "auditor_fn_violation": 0.025578842570137598,
            "auditor_fp_violation": 0.020948929622222556,
            "ave_precision_score": 0.7954297004005487,
            "fpr": 0.13721185510428102,
            "logloss": 1.4813293331268984,
            "mae": 0.26657024178292266,
            "precision": 0.7438524590163934,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7873391893073675,
            "auditor_fn_violation": 0.01461684356421199,
            "auditor_fp_violation": 0.021189502177718082,
            "ave_precision_score": 0.788004848264015,
            "fpr": 0.21271929824561403,
            "logloss": 1.2243410861976387,
            "mae": 0.29875970621496256,
            "precision": 0.680921052631579,
            "recall": 0.8607068607068608
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7952872997274687,
            "auditor_fn_violation": 0.005170537220673794,
            "auditor_fp_violation": 0.026344676180021953,
            "ave_precision_score": 0.7958713544580245,
            "fpr": 0.24039517014270034,
            "logloss": 1.2193753190164278,
            "mae": 0.30205342505264243,
            "precision": 0.6583463338533542,
            "recall": 0.8921775898520085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7962801183477641,
            "auditor_fn_violation": 0.01852409089251195,
            "auditor_fp_violation": 0.026303069157813337,
            "ave_precision_score": 0.796830354363283,
            "fpr": 0.19956140350877194,
            "logloss": 1.0863873121518983,
            "mae": 0.2933436864625888,
            "precision": 0.6878216123499142,
            "recall": 0.8336798336798337
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8088444125490225,
            "auditor_fn_violation": 0.016108033594567688,
            "auditor_fp_violation": 0.030560024861033833,
            "ave_precision_score": 0.8102333157647569,
            "fpr": 0.20636663007683864,
            "logloss": 0.9953895486300726,
            "mae": 0.2838600613337414,
            "precision": 0.6850921273031826,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7888169658338438,
            "auditor_fn_violation": 0.018494455994455997,
            "auditor_fp_violation": 0.02320694427484024,
            "ave_precision_score": 0.7884983184967206,
            "fpr": 0.12609649122807018,
            "logloss": 1.4053950091697955,
            "mae": 0.282589277269321,
            "precision": 0.7547974413646056,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8068428946650652,
            "auditor_fn_violation": 0.020048595623609028,
            "auditor_fp_violation": 0.018096927958137228,
            "ave_precision_score": 0.8054827149770726,
            "fpr": 0.141602634467618,
            "logloss": 1.391797672153611,
            "mae": 0.2607572754033963,
            "precision": 0.7440476190476191,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8068165667758258,
            "auditor_fn_violation": 0.03654894773315826,
            "auditor_fp_violation": 0.0273563113119225,
            "ave_precision_score": 0.8065870687929898,
            "fpr": 0.11732456140350878,
            "logloss": 1.062535282609176,
            "mae": 0.2780778577839305,
            "precision": 0.7780082987551867,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8341042693456165,
            "auditor_fn_violation": 0.03330912061415214,
            "auditor_fp_violation": 0.029156579402432978,
            "ave_precision_score": 0.8349192780604906,
            "fpr": 0.1163556531284303,
            "logloss": 1.0159116047820815,
            "mae": 0.2639316116564347,
            "precision": 0.7818930041152263,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8257120861853333,
            "auditor_fn_violation": 0.01500665645402488,
            "auditor_fp_violation": 0.025992693450563764,
            "ave_precision_score": 0.8262266416245606,
            "fpr": 0.13048245614035087,
            "logloss": 0.8998754679974169,
            "mae": 0.27681314308559224,
            "precision": 0.7510460251046025,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8448759539869474,
            "auditor_fn_violation": 0.01785320594194053,
            "auditor_fp_violation": 0.024434987895282926,
            "ave_precision_score": 0.8451854819491721,
            "fpr": 0.12952799121844127,
            "logloss": 0.7803958369328422,
            "mae": 0.25763341143020846,
            "precision": 0.7606490872210954,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5073680319964099,
            "auditor_fn_violation": 0.03836807455228508,
            "auditor_fp_violation": 0.03805918508568407,
            "ave_precision_score": 0.49932400994936166,
            "fpr": 0.25219298245614036,
            "logloss": 4.7784839353164585,
            "mae": 0.4591557837969751,
            "precision": 0.5700934579439252,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5244296162329498,
            "auditor_fn_violation": 0.03486631562091702,
            "auditor_fp_violation": 0.03386313399395516,
            "ave_precision_score": 0.5215818111151753,
            "fpr": 0.22722283205268934,
            "logloss": 4.560083679662556,
            "mae": 0.4385991348046707,
            "precision": 0.5900990099009901,
            "recall": 0.6300211416490487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8113688539037867,
            "auditor_fn_violation": 0.023049111864901346,
            "auditor_fp_violation": 0.03389709773273091,
            "ave_precision_score": 0.8119879376882161,
            "fpr": 0.13925438596491227,
            "logloss": 0.9537614995968129,
            "mae": 0.27803449257566365,
            "precision": 0.7392197125256673,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.836128234120481,
            "auditor_fn_violation": 0.03016688210571753,
            "auditor_fp_violation": 0.033622543343909295,
            "ave_precision_score": 0.8364398626474706,
            "fpr": 0.14489571899012074,
            "logloss": 0.8524049431647108,
            "mae": 0.26975458951684683,
            "precision": 0.736,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.815339903676233,
            "auditor_fn_violation": 0.020744428639165483,
            "auditor_fp_violation": 0.020586559205438195,
            "ave_precision_score": 0.816806651150381,
            "fpr": 0.10526315789473684,
            "logloss": 1.0334333714612403,
            "mae": 0.2806175755614486,
            "precision": 0.7788018433179723,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8488601577684152,
            "auditor_fn_violation": 0.02931982371902726,
            "auditor_fp_violation": 0.017039331558977293,
            "ave_precision_score": 0.8491391937185337,
            "fpr": 0.10428100987925357,
            "logloss": 0.8554109477853957,
            "mae": 0.2598214780070466,
            "precision": 0.7850678733031674,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8113936426326147,
            "auditor_fn_violation": 0.027229912098333156,
            "auditor_fp_violation": 0.024148247649285637,
            "ave_precision_score": 0.8110128039447675,
            "fpr": 0.12719298245614036,
            "logloss": 1.1828324733506663,
            "mae": 0.2696837934938739,
            "precision": 0.7593360995850622,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8324778055827723,
            "auditor_fn_violation": 0.029305899471574814,
            "auditor_fp_violation": 0.027006300467648087,
            "ave_precision_score": 0.8330897370720725,
            "fpr": 0.14050493962678376,
            "logloss": 1.1370680726123374,
            "mae": 0.2559620693503053,
            "precision": 0.7495107632093934,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8069968148375376,
            "auditor_fn_violation": 0.01894353868038079,
            "auditor_fp_violation": 0.024611267146985798,
            "ave_precision_score": 0.8066002856811213,
            "fpr": 0.11074561403508772,
            "logloss": 1.301078475493237,
            "mae": 0.2751193003628424,
            "precision": 0.7730337078651686,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8238255050999035,
            "auditor_fn_violation": 0.028607366391043925,
            "auditor_fp_violation": 0.025031452215188293,
            "ave_precision_score": 0.8244007645722855,
            "fpr": 0.11964873765093303,
            "logloss": 1.225571200935237,
            "mae": 0.2586326790637047,
            "precision": 0.7680851063829788,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8282676433095635,
            "auditor_fn_violation": 0.02163347558084401,
            "auditor_fp_violation": 0.016795905075914847,
            "ave_precision_score": 0.828845671514878,
            "fpr": 0.06798245614035088,
            "logloss": 0.6671342629452139,
            "mae": 0.31327768934834854,
            "precision": 0.8342245989304813,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8599152842351594,
            "auditor_fn_violation": 0.030626382271648156,
            "auditor_fp_violation": 0.015087038679959305,
            "ave_precision_score": 0.8601414098428976,
            "fpr": 0.0570801317233809,
            "logloss": 0.6158526053321236,
            "mae": 0.3050696555507498,
            "precision": 0.8571428571428571,
            "recall": 0.6596194503171248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.822071431071045,
            "auditor_fn_violation": 0.015918499471131053,
            "auditor_fp_violation": 0.029595086905198034,
            "ave_precision_score": 0.8217997847233587,
            "fpr": 0.23355263157894737,
            "logloss": 0.9624432767107366,
            "mae": 0.31205978754235963,
            "precision": 0.6753048780487805,
            "recall": 0.920997920997921
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8344674105452837,
            "auditor_fn_violation": 0.012487729256932534,
            "auditor_fp_violation": 0.021958909121894254,
            "ave_precision_score": 0.8342284233960102,
            "fpr": 0.24807903402854006,
            "logloss": 0.9436122132742374,
            "mae": 0.3124160251577775,
            "precision": 0.6591251885369532,
            "recall": 0.9238900634249472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8241988496818181,
            "auditor_fn_violation": 0.01500665645402488,
            "auditor_fp_violation": 0.026491329832702405,
            "ave_precision_score": 0.8247159476254904,
            "fpr": 0.1337719298245614,
            "logloss": 0.9103149237107042,
            "mae": 0.27784339013525056,
            "precision": 0.7463617463617463,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8460973647344501,
            "auditor_fn_violation": 0.018867355298060124,
            "auditor_fp_violation": 0.02270574259807829,
            "ave_precision_score": 0.8464124768540681,
            "fpr": 0.12952799121844127,
            "logloss": 0.7755765265407316,
            "mae": 0.25643643470215066,
            "precision": 0.7611336032388664,
            "recall": 0.7949260042283298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8130304132813762,
            "auditor_fn_violation": 0.024487544224386332,
            "auditor_fp_violation": 0.034426262872959676,
            "ave_precision_score": 0.8135675709684014,
            "fpr": 0.13925438596491227,
            "logloss": 0.9876585718196434,
            "mae": 0.2765245730929762,
            "precision": 0.7397540983606558,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.838991782956763,
            "auditor_fn_violation": 0.029795568840319055,
            "auditor_fp_violation": 0.03188828574149537,
            "ave_precision_score": 0.8393195210368766,
            "fpr": 0.14270032930845225,
            "logloss": 0.87016105554953,
            "mae": 0.2644739598150007,
            "precision": 0.7405189620758483,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.807470097328254,
            "auditor_fn_violation": 0.020783181967392497,
            "auditor_fp_violation": 0.025336325151626166,
            "ave_precision_score": 0.8069735628302056,
            "fpr": 0.12828947368421054,
            "logloss": 1.2787500895893216,
            "mae": 0.27506002719728057,
            "precision": 0.7542016806722689,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8248029557364651,
            "auditor_fn_violation": 0.02618222662641012,
            "auditor_fp_violation": 0.026414848452951997,
            "ave_precision_score": 0.8249271121249568,
            "fpr": 0.14050493962678376,
            "logloss": 1.2290684734895005,
            "mae": 0.25780554943665174,
            "precision": 0.7485265225933202,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8210844065511365,
            "auditor_fn_violation": 0.025260331181383815,
            "auditor_fp_violation": 0.027671775145520414,
            "ave_precision_score": 0.8208482830032339,
            "fpr": 0.13267543859649122,
            "logloss": 1.136389599292343,
            "mae": 0.26923872924617115,
            "precision": 0.7565392354124748,
            "recall": 0.7817047817047817
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.844175845973981,
            "auditor_fn_violation": 0.027184772442986005,
            "auditor_fp_violation": 0.029595156108245747,
            "ave_precision_score": 0.8445380680083532,
            "fpr": 0.145993413830955,
            "logloss": 1.0674179097914271,
            "mae": 0.2555305859178189,
            "precision": 0.7427466150870407,
            "recall": 0.8118393234672304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7890177068445122,
            "auditor_fn_violation": 0.0159549731918153,
            "auditor_fp_violation": 0.020115907518215497,
            "ave_precision_score": 0.7887138409511476,
            "fpr": 0.125,
            "logloss": 1.4220980297435186,
            "mae": 0.2811984066938295,
            "precision": 0.7558886509635975,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7964939163061584,
            "auditor_fn_violation": 0.023831349514856017,
            "auditor_fp_violation": 0.023577883704494533,
            "ave_precision_score": 0.7952913316781378,
            "fpr": 0.13391877058177826,
            "logloss": 1.4163934952312556,
            "mae": 0.2653156542316808,
            "precision": 0.75,
            "recall": 0.773784355179704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8174326244426123,
            "auditor_fn_violation": 0.016511197432250074,
            "auditor_fp_violation": 0.030236190825090572,
            "ave_precision_score": 0.8179148053750052,
            "fpr": 0.1206140350877193,
            "logloss": 1.0064821493268519,
            "mae": 0.2805637947562722,
            "precision": 0.7587719298245614,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.835178454333128,
            "auditor_fn_violation": 0.025799309821467945,
            "auditor_fp_violation": 0.02069079590394418,
            "ave_precision_score": 0.8354833395025013,
            "fpr": 0.1251372118551043,
            "logloss": 0.8901770808840197,
            "mae": 0.2648284553632314,
            "precision": 0.7584745762711864,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8074573263217252,
            "auditor_fn_violation": 0.02209167669693986,
            "auditor_fp_violation": 0.025692493996010913,
            "ave_precision_score": 0.8070680259697378,
            "fpr": 0.12609649122807018,
            "logloss": 1.2762733624565958,
            "mae": 0.27295375622820434,
            "precision": 0.7589098532494759,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8233810046321982,
            "auditor_fn_violation": 0.023710672703601506,
            "auditor_fp_violation": 0.0261040855299761,
            "ave_precision_score": 0.8237412786455245,
            "fpr": 0.13830954994511527,
            "logloss": 1.226414702167223,
            "mae": 0.2578246021177743,
            "precision": 0.7504950495049505,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8138790916165561,
            "auditor_fn_violation": 0.02075126746179378,
            "auditor_fp_violation": 0.03251312736597876,
            "ave_precision_score": 0.8144666705999588,
            "fpr": 0.13486842105263158,
            "logloss": 0.9470510197791036,
            "mae": 0.2766162244322525,
            "precision": 0.7448132780082988,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8394232885375439,
            "auditor_fn_violation": 0.025792347697741722,
            "auditor_fp_violation": 0.028610238134620495,
            "ave_precision_score": 0.8397329379383165,
            "fpr": 0.14050493962678376,
            "logloss": 0.8262032003737702,
            "mae": 0.2627130446030477,
            "precision": 0.7434869739478958,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7464613155326776,
            "auditor_fn_violation": 0.023083305978042822,
            "auditor_fp_violation": 0.02720621158464608,
            "ave_precision_score": 0.7461894301648238,
            "fpr": 0.15789473684210525,
            "logloss": 1.4445485906156155,
            "mae": 0.33086452277353845,
            "precision": 0.6936170212765957,
            "recall": 0.6777546777546778
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7584861836848358,
            "auditor_fn_violation": 0.025349092487172292,
            "auditor_fp_violation": 0.030555012555824556,
            "ave_precision_score": 0.7594099209711229,
            "fpr": 0.15806805708013172,
            "logloss": 1.3981601113342665,
            "mae": 0.30519157532387337,
            "precision": 0.708502024291498,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7549150140613775,
            "auditor_fn_violation": 0.020678320020425293,
            "auditor_fp_violation": 0.022665058818740588,
            "ave_precision_score": 0.7553487176549609,
            "fpr": 0.09100877192982457,
            "logloss": 1.5571480600075394,
            "mae": 0.3432395744181317,
            "precision": 0.7601156069364162,
            "recall": 0.5467775467775468
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7662907533179817,
            "auditor_fn_violation": 0.02630522414557337,
            "auditor_fp_violation": 0.019858753239202248,
            "ave_precision_score": 0.7670645379808676,
            "fpr": 0.10647639956092206,
            "logloss": 1.4311574185831601,
            "mae": 0.32220035510971823,
            "precision": 0.7433862433862434,
            "recall": 0.5940803382663847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8132676114791849,
            "auditor_fn_violation": 0.020427563190721088,
            "auditor_fp_violation": 0.01981061993731429,
            "ave_precision_score": 0.813707191771121,
            "fpr": 0.10416666666666667,
            "logloss": 1.0491458676361007,
            "mae": 0.281432278183454,
            "precision": 0.7785547785547785,
            "recall": 0.6943866943866944
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8452803444200316,
            "auditor_fn_violation": 0.02753519933720582,
            "auditor_fp_violation": 0.01660576715837381,
            "ave_precision_score": 0.8455624887477049,
            "fpr": 0.10318331503841932,
            "logloss": 0.8577801841115466,
            "mae": 0.2599780986684877,
            "precision": 0.7887640449438202,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7740198054268819,
            "auditor_fn_violation": 0.01965249662618084,
            "auditor_fp_violation": 0.02770739202995889,
            "ave_precision_score": 0.7737770701497451,
            "fpr": 0.13815789473684212,
            "logloss": 1.329814042941753,
            "mae": 0.2975690944090656,
            "precision": 0.7375,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.789601800841266,
            "auditor_fn_violation": 0.02914809133378046,
            "auditor_fp_violation": 0.028261882922574925,
            "ave_precision_score": 0.7901023699141957,
            "fpr": 0.145993413830955,
            "logloss": 1.2887386277099349,
            "mae": 0.2754289493148754,
            "precision": 0.73558648111332,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7245399005905436,
            "auditor_fn_violation": 0.018510413247255355,
            "auditor_fp_violation": 0.020840965522855866,
            "ave_precision_score": 0.7217676180086494,
            "fpr": 0.14912280701754385,
            "logloss": 1.6954874386012562,
            "mae": 0.3002479004969072,
            "precision": 0.721881390593047,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7526244399804309,
            "auditor_fn_violation": 0.026019777072798293,
            "auditor_fp_violation": 0.023026530131472767,
            "ave_precision_score": 0.7493834020253552,
            "fpr": 0.15367727771679474,
            "logloss": 1.6329119665663543,
            "mae": 0.2723839753172579,
            "precision": 0.7307692307692307,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7873717310864214,
            "auditor_fn_violation": 0.016062114746325275,
            "auditor_fp_violation": 0.025310884519884398,
            "ave_precision_score": 0.7870146680841238,
            "fpr": 0.1337719298245614,
            "logloss": 1.4392398768158003,
            "mae": 0.28408103692363573,
            "precision": 0.7420718816067653,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8021890151926043,
            "auditor_fn_violation": 0.023996119776376584,
            "auditor_fp_violation": 0.02028479918199179,
            "ave_precision_score": 0.8007180425648852,
            "fpr": 0.145993413830955,
            "logloss": 1.4217647296049383,
            "mae": 0.2646369667544072,
            "precision": 0.73558648111332,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8258843080651985,
            "auditor_fn_violation": 0.010151092387934496,
            "auditor_fp_violation": 0.021873855171571623,
            "ave_precision_score": 0.8263736447691432,
            "fpr": 0.12390350877192982,
            "logloss": 0.8125871781266253,
            "mae": 0.2829272017741623,
            "precision": 0.755939524838013,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8496997813595657,
            "auditor_fn_violation": 0.012148905902256422,
            "auditor_fp_violation": 0.011197489837551193,
            "ave_precision_score": 0.849935555311139,
            "fpr": 0.12733260153677278,
            "logloss": 0.7102090575355853,
            "mae": 0.26352984175666516,
            "precision": 0.7608247422680412,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8051330668520027,
            "auditor_fn_violation": 0.01052950724003356,
            "auditor_fp_violation": 0.01956384580941914,
            "ave_precision_score": 0.8054923925271206,
            "fpr": 0.11842105263157894,
            "logloss": 0.9870042826278178,
            "mae": 0.30163621819056297,
            "precision": 0.7494199535962877,
            "recall": 0.6715176715176715
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8066363747783911,
            "auditor_fn_violation": 0.01379892922537091,
            "auditor_fp_violation": 0.01258339222791955,
            "ave_precision_score": 0.8079831043106513,
            "fpr": 0.11964873765093303,
            "logloss": 0.8375149977122254,
            "mae": 0.2793976082771109,
            "precision": 0.7625272331154684,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8173883212456785,
            "auditor_fn_violation": 0.016511197432250074,
            "auditor_fp_violation": 0.029712113811210163,
            "ave_precision_score": 0.8178705725543446,
            "fpr": 0.11951754385964912,
            "logloss": 1.0070653903623126,
            "mae": 0.2806159261517796,
            "precision": 0.7604395604395604,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8351553431974068,
            "auditor_fn_violation": 0.025799309821467945,
            "auditor_fp_violation": 0.02069079590394418,
            "ave_precision_score": 0.8354603504966343,
            "fpr": 0.1251372118551043,
            "logloss": 0.8906741434088205,
            "mae": 0.26484453283711895,
            "precision": 0.7584745762711864,
            "recall": 0.7568710359408034
        }
    }
]