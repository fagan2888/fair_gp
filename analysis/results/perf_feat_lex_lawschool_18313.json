[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6482755232147825,
            "auditor_fn_violation": 0.022381320949432404,
            "auditor_fp_violation": 0.01765199983904717,
            "ave_precision_score": 0.5940265310235646,
            "fpr": 0.20942982456140352,
            "logloss": 7.2443439360346895,
            "mae": 0.3789333636203274,
            "precision": 0.6262230919765166,
            "recall": 0.6722689075630253
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6414382489585871,
            "auditor_fn_violation": 0.01512430590320996,
            "auditor_fp_violation": 0.023011030185340585,
            "ave_precision_score": 0.587249927394169,
            "fpr": 0.2074643249176729,
            "logloss": 7.464203905047603,
            "mae": 0.37088615142485465,
            "precision": 0.6372360844529751,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7710451457549237,
            "auditor_fn_violation": 0.014104655019902705,
            "auditor_fp_violation": 0.021874497022372447,
            "ave_precision_score": 0.7539019648885414,
            "fpr": 0.1513157894736842,
            "logloss": 3.489171085462693,
            "mae": 0.29371110253786115,
            "precision": 0.7154639175257732,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7798487984076689,
            "auditor_fn_violation": 0.017641196165875936,
            "auditor_fp_violation": 0.018480820761389533,
            "ave_precision_score": 0.7619881634897885,
            "fpr": 0.16136114160263446,
            "logloss": 3.3055465920348746,
            "mae": 0.3034985832411042,
            "precision": 0.703030303030303,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7691444333722097,
            "auditor_fn_violation": 0.014153029632905793,
            "auditor_fp_violation": 0.01894465234186383,
            "ave_precision_score": 0.7507407707982492,
            "fpr": 0.1699561403508772,
            "logloss": 3.0802020427895394,
            "mae": 0.31060805771321875,
            "precision": 0.6924603174603174,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7616748343853386,
            "auditor_fn_violation": 0.019184398954663832,
            "auditor_fp_violation": 0.017454108496867904,
            "ave_precision_score": 0.7393476138415471,
            "fpr": 0.17892425905598244,
            "logloss": 3.0677796673542197,
            "mae": 0.3144179259295686,
            "precision": 0.6853281853281853,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8245585298622928,
            "auditor_fn_violation": 0.008974642488574385,
            "auditor_fp_violation": 0.009325205214872045,
            "ave_precision_score": 0.8259061090281739,
            "fpr": 0.1074561403508772,
            "logloss": 0.8974204953683579,
            "mae": 0.28399659753936485,
            "precision": 0.7802690582959642,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8334902380637578,
            "auditor_fn_violation": 0.010062968185221085,
            "auditor_fp_violation": 0.01763917021368291,
            "ave_precision_score": 0.8338743696262017,
            "fpr": 0.10428100987925357,
            "logloss": 0.8292242462294879,
            "mae": 0.2879350841242347,
            "precision": 0.7835990888382688,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7964296680413689,
            "auditor_fn_violation": 0.00791500810850656,
            "auditor_fp_violation": 0.0144279132464188,
            "ave_precision_score": 0.7965173610534826,
            "fpr": 0.12828947368421054,
            "logloss": 0.9027594476096147,
            "mae": 0.2767545744110224,
            "precision": 0.7547169811320755,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8095263714492112,
            "auditor_fn_violation": 0.012869208970784782,
            "auditor_fp_violation": 0.018640531558092904,
            "ave_precision_score": 0.8098600187924481,
            "fpr": 0.13062568605927552,
            "logloss": 0.8688638650615188,
            "mae": 0.28035736405038403,
            "precision": 0.7510460251046025,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.829442503478639,
            "auditor_fn_violation": 0.01073686053368716,
            "auditor_fp_violation": 0.009707468211813942,
            "ave_precision_score": 0.8298585060738723,
            "fpr": 0.08552631578947369,
            "logloss": 0.7786766470128025,
            "mae": 0.2717120507122429,
            "precision": 0.8111380145278451,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8436005819997104,
            "auditor_fn_violation": 0.017457481548163085,
            "auditor_fp_violation": 0.017732968618095996,
            "ave_precision_score": 0.8438646930095368,
            "fpr": 0.09110867178924259,
            "logloss": 0.7608956829058813,
            "mae": 0.2732463861935275,
            "precision": 0.8004807692307693,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7891995483850619,
            "auditor_fn_violation": 0.012066010614772232,
            "auditor_fp_violation": 0.016306534685337198,
            "ave_precision_score": 0.7533639238299797,
            "fpr": 0.15021929824561403,
            "logloss": 3.0165016271546294,
            "mae": 0.27876774261774534,
            "precision": 0.7297830374753451,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7858623600299052,
            "auditor_fn_violation": 0.01572597127621952,
            "auditor_fp_violation": 0.021383501114172945,
            "ave_precision_score": 0.750655670805577,
            "fpr": 0.141602634467618,
            "logloss": 2.8321695325908376,
            "mae": 0.27700868425065067,
            "precision": 0.7414829659318637,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7710691158678481,
            "auditor_fn_violation": 0.01580237358101136,
            "auditor_fp_violation": 0.01955577015934331,
            "ave_precision_score": 0.7541862713473139,
            "fpr": 0.16666666666666666,
            "logloss": 3.2638659477227105,
            "mae": 0.3008851647380098,
            "precision": 0.7042801556420234,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7712135097831943,
            "auditor_fn_violation": 0.01544121361876461,
            "auditor_fp_violation": 0.018272943216474047,
            "ave_precision_score": 0.7530012416053005,
            "fpr": 0.18111964873765093,
            "logloss": 3.1411761899802304,
            "mae": 0.3067622151821248,
            "precision": 0.6869070208728653,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8153818062728844,
            "auditor_fn_violation": 0.013729175880878668,
            "auditor_fp_violation": 0.015934331240946405,
            "ave_precision_score": 0.8158114628144058,
            "fpr": 0.12719298245614036,
            "logloss": 1.0821784280142153,
            "mae": 0.2859866055118537,
            "precision": 0.7521367521367521,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8237659849632935,
            "auditor_fn_violation": 0.016851223309710693,
            "auditor_fp_violation": 0.01993089339177566,
            "ave_precision_score": 0.8240559471618725,
            "fpr": 0.13062568605927552,
            "logloss": 1.0033510167545971,
            "mae": 0.29119029579902556,
            "precision": 0.7440860215053764,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8107827453159726,
            "auditor_fn_violation": 0.007355244729470736,
            "auditor_fp_violation": 0.017865765330758093,
            "ave_precision_score": 0.8111697818289137,
            "fpr": 0.14035087719298245,
            "logloss": 0.7703522648220642,
            "mae": 0.2738590735568375,
            "precision": 0.747534516765286,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8192146728354723,
            "auditor_fn_violation": 0.012338733012138944,
            "auditor_fp_violation": 0.02153560663484282,
            "ave_precision_score": 0.8195485601811945,
            "fpr": 0.1394072447859495,
            "logloss": 0.7458830380962724,
            "mae": 0.2726145340564416,
            "precision": 0.7470119521912351,
            "recall": 0.7845188284518828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7687267691824908,
            "auditor_fn_violation": 0.012522114108801417,
            "auditor_fp_violation": 0.02065226138741349,
            "ave_precision_score": 0.7525050638452212,
            "fpr": 0.16666666666666666,
            "logloss": 3.2596340115198568,
            "mae": 0.30347575860787523,
            "precision": 0.7019607843137254,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7684051869024366,
            "auditor_fn_violation": 0.016047471857217,
            "auditor_fp_violation": 0.02046833289814254,
            "ave_precision_score": 0.7504095576607964,
            "fpr": 0.18111964873765093,
            "logloss": 3.1557046630698715,
            "mae": 0.3078534288632229,
            "precision": 0.6863117870722434,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8060378774259686,
            "auditor_fn_violation": 0.012932146542827662,
            "auditor_fp_violation": 0.013804220988250451,
            "ave_precision_score": 0.8064761194276757,
            "fpr": 0.13048245614035087,
            "logloss": 0.7861535462642467,
            "mae": 0.2738244497618391,
            "precision": 0.7566462167689162,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8116432495683994,
            "auditor_fn_violation": 0.016419493958085514,
            "auditor_fp_violation": 0.021297307985793344,
            "ave_precision_score": 0.8119908378830778,
            "fpr": 0.12952799121844127,
            "logloss": 0.7942929214474742,
            "mae": 0.2780841843772868,
            "precision": 0.7546777546777547,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7863845606954047,
            "auditor_fn_violation": 0.010884287925696597,
            "auditor_fp_violation": 0.015310638982778055,
            "ave_precision_score": 0.7496586373185942,
            "fpr": 0.1524122807017544,
            "logloss": 3.1166405509088544,
            "mae": 0.2836965637985662,
            "precision": 0.7316602316602316,
            "recall": 0.7962184873949579
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7841900000858321,
            "auditor_fn_violation": 0.013018477097676477,
            "auditor_fp_violation": 0.02345720637930554,
            "ave_precision_score": 0.7481597342738053,
            "fpr": 0.150384193194292,
            "logloss": 2.8842579173856433,
            "mae": 0.2782437285943702,
            "precision": 0.7365384615384616,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7604030772024728,
            "auditor_fn_violation": 0.0006104415450390683,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5238100959407158,
            "fpr": 0.4725877192982456,
            "logloss": 16.323536150622928,
            "mae": 0.4736552219721102,
            "precision": 0.5242825607064018,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7640500029795119,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002791136304292178,
            "ave_precision_score": 0.5300676268860419,
            "fpr": 0.4643249176728869,
            "logloss": 16.008200242196875,
            "mae": 0.4643468209688046,
            "precision": 0.5305216426193119,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7499650269693822,
            "auditor_fn_violation": 0.006224200206398357,
            "auditor_fp_violation": 0.012192177691936265,
            "ave_precision_score": 0.7502975920278743,
            "fpr": 0.05701754385964912,
            "logloss": 1.153936550571466,
            "mae": 0.40376323324728913,
            "precision": 0.7777777777777778,
            "recall": 0.38235294117647056
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7650110267516232,
            "auditor_fn_violation": 0.011973600209434655,
            "auditor_fp_violation": 0.004499788319817069,
            "ave_precision_score": 0.7654776680867366,
            "fpr": 0.036223929747530186,
            "logloss": 1.1208060110328686,
            "mae": 0.395071032652673,
            "precision": 0.8405797101449275,
            "recall": 0.36401673640167365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7713429514900727,
            "auditor_fn_violation": 0.015968229397021968,
            "auditor_fp_violation": 0.018154977466602287,
            "ave_precision_score": 0.7557480024953951,
            "fpr": 0.15021929824561403,
            "logloss": 2.8939744231219366,
            "mae": 0.2975054557472102,
            "precision": 0.7175257731958763,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7730763503774177,
            "auditor_fn_violation": 0.017625121136826058,
            "auditor_fp_violation": 0.016305711815810368,
            "ave_precision_score": 0.7557720320808601,
            "fpr": 0.16355653128430298,
            "logloss": 2.83477884269523,
            "mae": 0.3040644178136988,
            "precision": 0.7008032128514057,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6434731018378022,
            "auditor_fn_violation": 0.002450980392156863,
            "auditor_fp_violation": 0.0071171334299050554,
            "ave_precision_score": 0.5368597068186052,
            "fpr": 0.4057017543859649,
            "logloss": 8.25790087179004,
            "mae": 0.42956453046083387,
            "precision": 0.5552884615384616,
            "recall": 0.9705882352941176
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6281225144922556,
            "auditor_fn_violation": 0.004514786730293163,
            "auditor_fp_violation": 0.000656588830891631,
            "ave_precision_score": 0.5256403698147063,
            "fpr": 0.3918770581778266,
            "logloss": 8.31938436298494,
            "mae": 0.43008886214394765,
            "precision": 0.5635696821515892,
            "recall": 0.9644351464435147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7256701384539259,
            "auditor_fn_violation": 0.0074612081674775175,
            "auditor_fp_violation": 0.024092628359890556,
            "ave_precision_score": 0.7211739489116329,
            "fpr": 0.17105263157894737,
            "logloss": 1.9134377284734105,
            "mae": 0.298327429772598,
            "precision": 0.7017208413001912,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7610554621969149,
            "auditor_fn_violation": 0.012933509086984285,
            "auditor_fp_violation": 0.018845874010997236,
            "ave_precision_score": 0.758005324916448,
            "fpr": 0.17453347969264543,
            "logloss": 1.7356475698840188,
            "mae": 0.3033876925249923,
            "precision": 0.6924564796905223,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7532975606966461,
            "auditor_fn_violation": 0.013904245908889876,
            "auditor_fp_violation": 0.021064703042008692,
            "ave_precision_score": 0.7539042950468953,
            "fpr": 0.14912280701754385,
            "logloss": 1.4054157753286542,
            "mae": 0.334332580570319,
            "precision": 0.7068965517241379,
            "recall": 0.6890756302521008
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7405970640918009,
            "auditor_fn_violation": 0.008758594399459883,
            "auditor_fp_violation": 0.018450399657255565,
            "ave_precision_score": 0.7414843539102054,
            "fpr": 0.15806805708013172,
            "logloss": 1.3234885823612428,
            "mae": 0.3426934993045192,
            "precision": 0.6862745098039216,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7736300871265025,
            "auditor_fn_violation": 0.009218819106590006,
            "auditor_fp_violation": 0.01992797360373411,
            "ave_precision_score": 0.7574017318029138,
            "fpr": 0.14035087719298245,
            "logloss": 3.1472219458496946,
            "mae": 0.2995652455411888,
            "precision": 0.7229437229437229,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7694989270312427,
            "auditor_fn_violation": 0.01841279756026988,
            "auditor_fp_violation": 0.019459366277699053,
            "ave_precision_score": 0.7499112953094504,
            "fpr": 0.14928649835345773,
            "logloss": 3.1094199232430504,
            "mae": 0.3093890322505216,
            "precision": 0.7112526539278131,
            "recall": 0.700836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7546604361846465,
            "auditor_fn_violation": 0.010568701164676403,
            "auditor_fp_violation": 0.019243924030259138,
            "ave_precision_score": 0.7307333402641165,
            "fpr": 0.16337719298245615,
            "logloss": 3.800255119577759,
            "mae": 0.31963412023495436,
            "precision": 0.6902286902286903,
            "recall": 0.6974789915966386
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7528909111822998,
            "auditor_fn_violation": 0.014848733976640693,
            "auditor_fp_violation": 0.021657291051378712,
            "ave_precision_score": 0.7289725351826681,
            "fpr": 0.17014270032930845,
            "logloss": 3.6018512617816234,
            "mae": 0.32076431391445404,
            "precision": 0.6868686868686869,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.775139780007119,
            "auditor_fn_violation": 0.0025431225121627598,
            "auditor_fp_violation": 0.004727989699018193,
            "ave_precision_score": 0.5717875963297165,
            "fpr": 0.45614035087719296,
            "logloss": 13.742295414837823,
            "mae": 0.4594161594087331,
            "precision": 0.5315315315315315,
            "recall": 0.9915966386554622
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7904248832224754,
            "auditor_fn_violation": 0.002085160911040789,
            "auditor_fp_violation": 0.0049180785016592335,
            "ave_precision_score": 0.5943196711499973,
            "fpr": 0.45554335894621295,
            "logloss": 13.143278335449681,
            "mae": 0.45873281459152415,
            "precision": 0.5331833520809899,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7544954874959824,
            "auditor_fn_violation": 0.010006634232640428,
            "auditor_fp_violation": 0.01632413890230163,
            "ave_precision_score": 0.7415180621024504,
            "fpr": 0.13267543859649122,
            "logloss": 2.8907789472068717,
            "mae": 0.3224437915333108,
            "precision": 0.714622641509434,
            "recall": 0.6365546218487395
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7533806671945174,
            "auditor_fn_violation": 0.0177652035328321,
            "auditor_fp_violation": 0.022912161596905168,
            "ave_precision_score": 0.7381636540130819,
            "fpr": 0.132821075740944,
            "logloss": 2.836778449257233,
            "mae": 0.3282346262603651,
            "precision": 0.709832134292566,
            "recall": 0.6192468619246861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7706438713692881,
            "auditor_fn_violation": 0.015689499484004134,
            "auditor_fp_violation": 0.020083896668276195,
            "ave_precision_score": 0.7466273010864182,
            "fpr": 0.1513157894736842,
            "logloss": 3.529155476031654,
            "mae": 0.2992777689082011,
            "precision": 0.7130977130977131,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7714361726416128,
            "auditor_fn_violation": 0.016603208575798355,
            "auditor_fp_violation": 0.01960133143032427,
            "ave_precision_score": 0.7455996168374307,
            "fpr": 0.15806805708013172,
            "logloss": 3.4567689462592663,
            "mae": 0.3086624641104745,
            "precision": 0.7055214723926381,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8532430801564415,
            "auditor_fn_violation": 0.010868163054695564,
            "auditor_fp_violation": 0.010092246096893609,
            "ave_precision_score": 0.8535015704471909,
            "fpr": 0.09978070175438597,
            "logloss": 0.509360589064754,
            "mae": 0.297755640902196,
            "precision": 0.7936507936507936,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8711877193386377,
            "auditor_fn_violation": 0.007082198512830173,
            "auditor_fp_violation": 0.014219331090621939,
            "ave_precision_score": 0.8714357917699654,
            "fpr": 0.0889132821075741,
            "logloss": 0.48060997880960776,
            "mae": 0.2849449006416073,
            "precision": 0.8133640552995391,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8089815782308597,
            "auditor_fn_violation": 0.005579205366357076,
            "auditor_fp_violation": 0.02061956784162241,
            "ave_precision_score": 0.809388456549708,
            "fpr": 0.14583333333333334,
            "logloss": 0.7833890102951864,
            "mae": 0.27480059350122477,
            "precision": 0.7412451361867705,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8189256843284727,
            "auditor_fn_violation": 0.01243977605188101,
            "auditor_fp_violation": 0.021074219888810867,
            "ave_precision_score": 0.819219048220162,
            "fpr": 0.14050493962678376,
            "logloss": 0.7517846292040197,
            "mae": 0.2725165703610378,
            "precision": 0.7445109780439122,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7698308210710092,
            "auditor_fn_violation": 0.01322009066784609,
            "auditor_fp_violation": 0.01915338805729922,
            "ave_precision_score": 0.749787101955689,
            "fpr": 0.15679824561403508,
            "logloss": 3.266778375661378,
            "mae": 0.307639562784081,
            "precision": 0.7020833333333333,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.766957554579945,
            "auditor_fn_violation": 0.016125550569744962,
            "auditor_fp_violation": 0.018356601252842476,
            "ave_precision_score": 0.7443828478343457,
            "fpr": 0.16794731064763996,
            "logloss": 3.2223069871800907,
            "mae": 0.31406694335724955,
            "precision": 0.6921529175050302,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8100565060886438,
            "auditor_fn_violation": 0.010324524546660769,
            "auditor_fp_violation": 0.02248309995171416,
            "ave_precision_score": 0.8101023232723874,
            "fpr": 0.23684210526315788,
            "logloss": 1.0226263112252005,
            "mae": 0.2988230626310914,
            "precision": 0.6635514018691588,
            "recall": 0.8949579831932774
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.818151315047309,
            "auditor_fn_violation": 0.009066316384128895,
            "auditor_fp_violation": 0.023558610059752117,
            "ave_precision_score": 0.8185001362285738,
            "fpr": 0.2261251372118551,
            "logloss": 0.9816101296915168,
            "mae": 0.28614287925243026,
            "precision": 0.6801242236024845,
            "recall": 0.9163179916317992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8031670972147361,
            "auditor_fn_violation": 0.009062177502579984,
            "auditor_fp_violation": 0.02171857395783037,
            "ave_precision_score": 0.8028998514747765,
            "fpr": 0.1787280701754386,
            "logloss": 0.9739606415893326,
            "mae": 0.2791922590964161,
            "precision": 0.7078853046594982,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.812182148023386,
            "auditor_fn_violation": 0.011606170974008978,
            "auditor_fp_violation": 0.023756347236622958,
            "ave_precision_score": 0.812423120160263,
            "fpr": 0.1734357848518112,
            "logloss": 0.9237051759060844,
            "mae": 0.27495641489280925,
            "precision": 0.7148014440433214,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8118508848322122,
            "auditor_fn_violation": 0.005924738316379181,
            "auditor_fp_violation": 0.0038729277321744725,
            "ave_precision_score": 0.8121588035424653,
            "fpr": 0.08333333333333333,
            "logloss": 0.6072918150676937,
            "mae": 0.338274096578352,
            "precision": 0.8031088082901554,
            "recall": 0.6512605042016807
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.839511388727844,
            "auditor_fn_violation": 0.004592865442821134,
            "auditor_fp_violation": 0.010056710008289754,
            "ave_precision_score": 0.839803906847767,
            "fpr": 0.07574094401756312,
            "logloss": 0.596198884357386,
            "mae": 0.3278172908774672,
            "precision": 0.8188976377952756,
            "recall": 0.6527196652719666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8082035313000498,
            "auditor_fn_violation": 0.00831121922453192,
            "auditor_fp_violation": 0.0162964751327861,
            "ave_precision_score": 0.8086462673352885,
            "fpr": 0.13596491228070176,
            "logloss": 0.7808858929910494,
            "mae": 0.2746047316166593,
            "precision": 0.75,
            "recall": 0.7815126050420168
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.818918908859755,
            "auditor_fn_violation": 0.013617846037964626,
            "auditor_fp_violation": 0.02228345877813635,
            "ave_precision_score": 0.8192106824871456,
            "fpr": 0.1350164654226125,
            "logloss": 0.7532635288629347,
            "mae": 0.27355493713809315,
            "precision": 0.7453416149068323,
            "recall": 0.7531380753138075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8018637668386912,
            "auditor_fn_violation": 0.007647795960489468,
            "auditor_fp_violation": 0.01857999356188637,
            "ave_precision_score": 0.8026340009957598,
            "fpr": 0.13267543859649122,
            "logloss": 0.8301287388860848,
            "mae": 0.27862900841861393,
            "precision": 0.7484407484407485,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8132916695247068,
            "auditor_fn_violation": 0.012657937160415012,
            "auditor_fp_violation": 0.022605415463554258,
            "ave_precision_score": 0.8136482070831395,
            "fpr": 0.13611416026344675,
            "logloss": 0.7912330836295076,
            "mae": 0.2777089735875402,
            "precision": 0.7427385892116183,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6834091099271185,
            "auditor_fn_violation": 0.0005989237800383311,
            "auditor_fp_violation": 0.0011568485433768026,
            "ave_precision_score": 0.5448631176310463,
            "fpr": 0.4692982456140351,
            "logloss": 10.259117973723649,
            "mae": 0.4655714675522687,
            "precision": 0.5260243632336655,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6734229137886246,
            "auditor_fn_violation": 0.0004960294678246812,
            "auditor_fp_violation": 0.00243368833071797,
            "ave_precision_score": 0.5350822844813973,
            "fpr": 0.4676180021953897,
            "logloss": 10.481976290963956,
            "mae": 0.46228060855823605,
            "precision": 0.5282392026578073,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8026543335240208,
            "auditor_fn_violation": 0.006422305764411029,
            "auditor_fp_violation": 0.017911033317238055,
            "ave_precision_score": 0.802619233537735,
            "fpr": 0.13925438596491227,
            "logloss": 0.8126993664909805,
            "mae": 0.27465603420507245,
            "precision": 0.7495069033530573,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8193310310408748,
            "auditor_fn_violation": 0.011941450151334918,
            "auditor_fp_violation": 0.02171052798361317,
            "ave_precision_score": 0.8196697231143949,
            "fpr": 0.141602634467618,
            "logloss": 0.758777827230384,
            "mae": 0.27030816510482153,
            "precision": 0.7425149700598802,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.5571298072462181,
            "auditor_fn_violation": 0.010674664602683182,
            "auditor_fp_violation": 0.031413467728955424,
            "ave_precision_score": 0.5068015624169273,
            "fpr": 0.2949561403508772,
            "logloss": 6.376878184999864,
            "mae": 0.4017388203550454,
            "precision": 0.5899390243902439,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.5417336000718097,
            "auditor_fn_violation": 0.006657358459369218,
            "auditor_fp_violation": 0.02127195706568171,
            "ave_precision_score": 0.48974795085094125,
            "fpr": 0.29198682766191,
            "logloss": 6.978496545431543,
            "mae": 0.41013736697476105,
            "precision": 0.5913978494623656,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8055726326431927,
            "auditor_fn_violation": 0.008320433436532507,
            "auditor_fp_violation": 0.012654917109286982,
            "ave_precision_score": 0.8070023571101373,
            "fpr": 0.14692982456140352,
            "logloss": 0.8820718045393263,
            "mae": 0.272786445457846,
            "precision": 0.73828125,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8236970302005117,
            "auditor_fn_violation": 0.01292202692337723,
            "auditor_fp_violation": 0.021221255225458414,
            "ave_precision_score": 0.824006354525715,
            "fpr": 0.1437980241492865,
            "logloss": 0.8300966448447267,
            "mae": 0.2727443592814392,
            "precision": 0.7400793650793651,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.8293490181242612,
            "auditor_fn_violation": 0.004201680672268908,
            "auditor_fp_violation": 0.02220143248028329,
            "ave_precision_score": 0.8297622514786686,
            "fpr": 0.3782894736842105,
            "logloss": 1.017393410195812,
            "mae": 0.3725222858586022,
            "precision": 0.5735475896168108,
            "recall": 0.9747899159663865
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.824480361525358,
            "auditor_fn_violation": 0.0012515558331687559,
            "auditor_fp_violation": 0.019946103943842657,
            "ave_precision_score": 0.8257984725018533,
            "fpr": 0.3732162458836443,
            "logloss": 1.023332347631133,
            "mae": 0.37018123499637123,
            "precision": 0.5797280593325093,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7603970129919158,
            "auditor_fn_violation": 0.0017138434321096862,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5238040320290913,
            "fpr": 0.4725877192982456,
            "logloss": 16.297313456635532,
            "mae": 0.47572582627834525,
            "precision": 0.5232300884955752,
            "recall": 0.9936974789915967
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7640438774560492,
            "auditor_fn_violation": 0.0010701376481773216,
            "auditor_fp_violation": 0.002441293606751468,
            "ave_precision_score": 0.5300615017319943,
            "fpr": 0.4632272228320527,
            "logloss": 16.00591119262812,
            "mae": 0.465958689203492,
            "precision": 0.5300668151447662,
            "recall": 0.99581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7905513163548363,
            "auditor_fn_violation": 0.010649325519681563,
            "auditor_fp_violation": 0.014168879768227914,
            "ave_precision_score": 0.7540633322415735,
            "fpr": 0.14692982456140352,
            "logloss": 2.9597394979569955,
            "mae": 0.2757510787761453,
            "precision": 0.7367387033398821,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.78678716930638,
            "auditor_fn_violation": 0.011583206646794877,
            "auditor_fp_violation": 0.020899298540040512,
            "ave_precision_score": 0.7515516635664155,
            "fpr": 0.13830954994511527,
            "logloss": 2.8020165751862094,
            "mae": 0.2772375312949087,
            "precision": 0.7474949899799599,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8364425806017992,
            "auditor_fn_violation": 0.003851540616246501,
            "auditor_fp_violation": 0.014083373571543541,
            "ave_precision_score": 0.8368754120970016,
            "fpr": 0.15679824561403508,
            "logloss": 0.7334332611355461,
            "mae": 0.2691366373444595,
            "precision": 0.7306967984934086,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8442246951979631,
            "auditor_fn_violation": 0.01077026946341553,
            "auditor_fp_violation": 0.022410213378694577,
            "ave_precision_score": 0.8444871999635145,
            "fpr": 0.150384193194292,
            "logloss": 0.7044603668118711,
            "mae": 0.26880427832792964,
            "precision": 0.7375478927203065,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7913567482969137,
            "auditor_fn_violation": 0.010743771192687605,
            "auditor_fp_violation": 0.017335123933687437,
            "ave_precision_score": 0.7917738443891429,
            "fpr": 0.14802631578947367,
            "logloss": 1.114240137779946,
            "mae": 0.3034289868764719,
            "precision": 0.7181628392484343,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7836696353019982,
            "auditor_fn_violation": 0.012529336928016025,
            "auditor_fp_violation": 0.018942207507421482,
            "ave_precision_score": 0.7841223529954,
            "fpr": 0.14818880351262348,
            "logloss": 1.0285821971496876,
            "mae": 0.3146698599924916,
            "precision": 0.7157894736842105,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 18313,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.80586208706331,
            "auditor_fn_violation": 0.00898155314757482,
            "auditor_fp_violation": 0.016397070658297118,
            "ave_precision_score": 0.8072974547927729,
            "fpr": 0.13048245614035087,
            "logloss": 0.8845373266655447,
            "mae": 0.2764636063861211,
            "precision": 0.7520833333333333,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8181753960079574,
            "auditor_fn_violation": 0.012869208970784782,
            "auditor_fp_violation": 0.01862785609803708,
            "ave_precision_score": 0.8184672600466302,
            "fpr": 0.13172338090010977,
            "logloss": 0.8599200265461442,
            "mae": 0.28006768333812315,
            "precision": 0.7494780793319415,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7214094716500126,
            "auditor_fn_violation": 0.007779098481497868,
            "auditor_fp_violation": 0.025649344117173668,
            "ave_precision_score": 0.7102367877947096,
            "fpr": 0.18092105263157895,
            "logloss": 2.405159636574555,
            "mae": 0.3014046781103927,
            "precision": 0.6898496240601504,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7595793419976606,
            "auditor_fn_violation": 0.010529144027667421,
            "auditor_fp_violation": 0.018011828739324102,
            "ave_precision_score": 0.7533262729211759,
            "fpr": 0.18221734357848518,
            "logloss": 2.1180354641989694,
            "mae": 0.3086098451085706,
            "precision": 0.687382297551789,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7464872994815693,
            "auditor_fn_violation": 0.004303037004275394,
            "auditor_fp_violation": 0.009186886367294384,
            "ave_precision_score": 0.7468187820508727,
            "fpr": 0.06907894736842106,
            "logloss": 1.1460611142306156,
            "mae": 0.3962529324044136,
            "precision": 0.7741935483870968,
            "recall": 0.453781512605042
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7625143857070295,
            "auditor_fn_violation": 0.009126023634885568,
            "auditor_fp_violation": 0.007050090883048601,
            "ave_precision_score": 0.7629368432917008,
            "fpr": 0.059275521405049394,
            "logloss": 1.1076393426782778,
            "mae": 0.38468682805146504,
            "precision": 0.7985074626865671,
            "recall": 0.4476987447698745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7819453579930515,
            "auditor_fn_violation": 0.01577473094500959,
            "auditor_fp_violation": 0.021457025591501692,
            "ave_precision_score": 0.7462666058499674,
            "fpr": 0.16666666666666666,
            "logloss": 3.685510202453749,
            "mae": 0.29895504112832993,
            "precision": 0.7019607843137254,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7809958549446575,
            "auditor_fn_violation": 0.018210711480785756,
            "auditor_fp_violation": 0.019586120878257274,
            "ave_precision_score": 0.744046081725132,
            "fpr": 0.18221734357848518,
            "logloss": 3.6508225604343005,
            "mae": 0.31509829097443687,
            "precision": 0.6795366795366795,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.82711075738315,
            "auditor_fn_violation": 0.006740196078431377,
            "auditor_fp_violation": 0.012473845163367142,
            "ave_precision_score": 0.8275980637777287,
            "fpr": 0.16666666666666666,
            "logloss": 0.80916852261935,
            "mae": 0.26848271865376666,
            "precision": 0.7241379310344828,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8298312947315579,
            "auditor_fn_violation": 0.008942309017172724,
            "auditor_fp_violation": 0.02258513472746494,
            "ave_precision_score": 0.8301321083437617,
            "fpr": 0.1525795828759605,
            "logloss": 0.7907892621503473,
            "mae": 0.26516485267395606,
            "precision": 0.7387218045112782,
            "recall": 0.8221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 18313,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.804804341757261,
            "auditor_fn_violation": 0.010142543859649125,
            "auditor_fp_violation": 0.01416384999195237,
            "ave_precision_score": 0.8069503042214816,
            "fpr": 0.12609649122807018,
            "logloss": 0.8927367521814933,
            "mae": 0.27649094591800005,
            "precision": 0.7563559322033898,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8175785610405324,
            "auditor_fn_violation": 0.012492594004473449,
            "auditor_fp_violation": 0.018640531558092904,
            "ave_precision_score": 0.8178703446384552,
            "fpr": 0.13062568605927552,
            "logloss": 0.8686024372148512,
            "mae": 0.2810184509767831,
            "precision": 0.7494736842105263,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8617314992206191,
            "auditor_fn_violation": 0.029798761609907125,
            "auditor_fp_violation": 0.010441815548044424,
            "ave_precision_score": 0.8619538815155108,
            "fpr": 0.06578947368421052,
            "logloss": 0.5109384133913552,
            "mae": 0.314357233127923,
            "precision": 0.8457583547557841,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8616327583269086,
            "auditor_fn_violation": 0.030087861515921174,
            "auditor_fp_violation": 0.015033095626205754,
            "ave_precision_score": 0.8619173094029318,
            "fpr": 0.06256860592755215,
            "logloss": 0.5507957325992984,
            "mae": 0.3100615637982398,
            "precision": 0.8488063660477454,
            "recall": 0.6694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7626061481979287,
            "auditor_fn_violation": 0.010983340704702934,
            "auditor_fp_violation": 0.018137373249637854,
            "ave_precision_score": 0.7470602877653989,
            "fpr": 0.12938596491228072,
            "logloss": 3.3533997190106732,
            "mae": 0.31202075446512473,
            "precision": 0.7268518518518519,
            "recall": 0.6596638655462185
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.762675336077543,
            "auditor_fn_violation": 0.0185459906581117,
            "auditor_fp_violation": 0.019390918793397615,
            "ave_precision_score": 0.7446308334463513,
            "fpr": 0.1350164654226125,
            "logloss": 3.271250544579791,
            "mae": 0.318840255684966,
            "precision": 0.7159353348729792,
            "recall": 0.6485355648535565
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8004107216639569,
            "auditor_fn_violation": 0.02080569069733156,
            "auditor_fp_violation": 0.015189924352164815,
            "ave_precision_score": 0.801887057177384,
            "fpr": 0.11403508771929824,
            "logloss": 1.1636017963051453,
            "mae": 0.3038483374485684,
            "precision": 0.7581395348837209,
            "recall": 0.6848739495798319
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8005469783617797,
            "auditor_fn_violation": 0.01319989528266791,
            "auditor_fp_violation": 0.017880003954743536,
            "ave_precision_score": 0.8011072558339752,
            "fpr": 0.11306256860592755,
            "logloss": 1.0652182797522607,
            "mae": 0.3138271045196763,
            "precision": 0.7553444180522565,
            "recall": 0.6652719665271967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6311639158666205,
            "auditor_fn_violation": 0.015456840630989252,
            "auditor_fp_violation": 0.01434743682600998,
            "ave_precision_score": 0.6077671593260553,
            "fpr": 0.17653508771929824,
            "logloss": 4.978796320460151,
            "mae": 0.3663244481393099,
            "precision": 0.6581740976645435,
            "recall": 0.6512605042016807
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6206597118491621,
            "auditor_fn_violation": 0.015572110283885016,
            "auditor_fp_violation": 0.009605463630302473,
            "ave_precision_score": 0.5969207613147797,
            "fpr": 0.17672886937431395,
            "logloss": 5.299310740046209,
            "mae": 0.3715724264691205,
            "precision": 0.6574468085106383,
            "recall": 0.6464435146443515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7559270525413375,
            "auditor_fn_violation": 0.011437140645731984,
            "auditor_fp_violation": 0.022342266215998715,
            "ave_precision_score": 0.748179070069533,
            "fpr": 0.16447368421052633,
            "logloss": 2.25482308270247,
            "mae": 0.3053423787867728,
            "precision": 0.7029702970297029,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7585022662637961,
            "auditor_fn_violation": 0.017590674646004903,
            "auditor_fp_violation": 0.02241021337869458,
            "ave_precision_score": 0.7510047627569689,
            "fpr": 0.17672886937431395,
            "logloss": 2.169484890296558,
            "mae": 0.30836144184849584,
            "precision": 0.6897880539499036,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 18313,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8499355531718873,
            "auditor_fn_violation": 0.013738390092879261,
            "auditor_fp_violation": 0.008975635763721231,
            "ave_precision_score": 0.8502066461558584,
            "fpr": 0.09320175438596491,
            "logloss": 0.5155812825562616,
            "mae": 0.30288315335635335,
            "precision": 0.7995283018867925,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8734280275227844,
            "auditor_fn_violation": 0.001559277817837772,
            "auditor_fp_violation": 0.012421950854706274,
            "ave_precision_score": 0.8736041174368387,
            "fpr": 0.0801317233809001,
            "logloss": 0.4833116551422117,
            "mae": 0.2882461220360311,
            "precision": 0.8253588516746412,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8506116664119588,
            "auditor_fn_violation": 0.01697948916408669,
            "auditor_fp_violation": 0.008892644455174634,
            "ave_precision_score": 0.850896730435439,
            "fpr": 0.09210526315789473,
            "logloss": 0.5143364509471945,
            "mae": 0.30107538931502187,
            "precision": 0.8023529411764706,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8730220155808248,
            "auditor_fn_violation": 0.0011252520334911775,
            "auditor_fp_violation": 0.013058258949508574,
            "ave_precision_score": 0.8732013766461437,
            "fpr": 0.08122941822173436,
            "logloss": 0.48389449972782284,
            "mae": 0.2877325753003572,
            "precision": 0.8250591016548463,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7918980527822461,
            "auditor_fn_violation": 0.00896542827657379,
            "auditor_fp_violation": 0.024726380170610015,
            "ave_precision_score": 0.7843563988965768,
            "fpr": 0.20065789473684212,
            "logloss": 1.319682831052256,
            "mae": 0.28162667054733137,
            "precision": 0.6893039049235993,
            "recall": 0.8529411764705882
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7958803736255496,
            "auditor_fn_violation": 0.01251555833168756,
            "auditor_fp_violation": 0.016794984573965117,
            "ave_precision_score": 0.7890143766171148,
            "fpr": 0.18660812294182216,
            "logloss": 1.294772769377742,
            "mae": 0.2767397677577592,
            "precision": 0.7043478260869566,
            "recall": 0.8472803347280334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7709507030311098,
            "auditor_fn_violation": 0.01754385964912281,
            "auditor_fp_violation": 0.01849197247706422,
            "ave_precision_score": 0.7539103626410414,
            "fpr": 0.13048245614035087,
            "logloss": 3.3305530511093737,
            "mae": 0.2957801186604028,
            "precision": 0.734375,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7763282580205414,
            "auditor_fn_violation": 0.019623017604453244,
            "auditor_fp_violation": 0.01945176100166556,
            "ave_precision_score": 0.7585507588671232,
            "fpr": 0.13391877058177826,
            "logloss": 3.22700429282834,
            "mae": 0.3036438896733896,
            "precision": 0.7258426966292135,
            "recall": 0.6757322175732218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8042167187814064,
            "auditor_fn_violation": 0.0070534792864514265,
            "auditor_fp_violation": 0.019736842105263157,
            "ave_precision_score": 0.804983177794667,
            "fpr": 0.1337719298245614,
            "logloss": 0.7840164453613945,
            "mae": 0.27845692709486686,
            "precision": 0.7494866529774127,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8155201227289518,
            "auditor_fn_violation": 0.012070050383733908,
            "auditor_fp_violation": 0.023388758895004098,
            "ave_precision_score": 0.8158722332137448,
            "fpr": 0.13611416026344675,
            "logloss": 0.755771800793931,
            "mae": 0.2767497010751506,
            "precision": 0.7453798767967146,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6805044954917018,
            "auditor_fn_violation": 0.0044827141382869,
            "auditor_fp_violation": 0.009415741187831969,
            "ave_precision_score": 0.6820836740731984,
            "fpr": 0.09649122807017543,
            "logloss": 2.6370471148892327,
            "mae": 0.40947692483522535,
            "precision": 0.7037037037037037,
            "recall": 0.43907563025210083
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7235665051005122,
            "auditor_fn_violation": 0.014458340414000893,
            "auditor_fp_violation": 0.01032289466946203,
            "ave_precision_score": 0.7241606410864857,
            "fpr": 0.0801317233809001,
            "logloss": 2.5500022122114907,
            "mae": 0.3880429863908878,
            "precision": 0.752542372881356,
            "recall": 0.46443514644351463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7000742462490315,
            "auditor_fn_violation": 0.002531604747162022,
            "auditor_fp_violation": 0.00883228713986802,
            "ave_precision_score": 0.6295700833277865,
            "fpr": 0.35526315789473684,
            "logloss": 5.647569122903035,
            "mae": 0.41694959730434894,
            "precision": 0.5639300134589502,
            "recall": 0.8802521008403361
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6959600944441007,
            "auditor_fn_violation": 0.0077711283292533385,
            "auditor_fp_violation": 0.010084596020412557,
            "ave_precision_score": 0.6247032506763358,
            "fpr": 0.34796926454445665,
            "logloss": 5.6861094921655235,
            "mae": 0.42167664711862574,
            "precision": 0.5663474692202463,
            "recall": 0.8661087866108786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6831674292001749,
            "auditor_fn_violation": 0.0005989237800383311,
            "auditor_fp_violation": 0.0021854377917270365,
            "ave_precision_score": 0.5443156471056056,
            "fpr": 0.4725877192982456,
            "logloss": 10.270723505830139,
            "mae": 0.4657465521115483,
            "precision": 0.5242825607064018,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6747689133453091,
            "auditor_fn_violation": 0.0005534402858599452,
            "auditor_fp_violation": 0.0008619312837959613,
            "ave_precision_score": 0.5367723217240374,
            "fpr": 0.46871569703622395,
            "logloss": 10.443891034148841,
            "mae": 0.46275536020814917,
            "precision": 0.5276548672566371,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8099572465271652,
            "auditor_fn_violation": 0.006615804216423417,
            "auditor_fp_violation": 0.016620895702559157,
            "ave_precision_score": 0.8103513302025015,
            "fpr": 0.12828947368421054,
            "logloss": 0.7934289579491608,
            "mae": 0.27330874907161395,
            "precision": 0.7572614107883817,
            "recall": 0.7668067226890757
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.820947610575216,
            "auditor_fn_violation": 0.010400543795268438,
            "auditor_fp_violation": 0.02331777631869149,
            "ave_precision_score": 0.8212794522626387,
            "fpr": 0.12733260153677278,
            "logloss": 0.7570721218588262,
            "mae": 0.2720352275772047,
            "precision": 0.7557894736842106,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 18313,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.5460558610123833,
            "auditor_fn_violation": 0.011093911248710012,
            "auditor_fp_violation": 0.032054764204088204,
            "ave_precision_score": 0.49812022282217044,
            "fpr": 0.2708333333333333,
            "logloss": 6.455819728103913,
            "mae": 0.4101831952049204,
            "precision": 0.5957446808510638,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.53228998725748,
            "auditor_fn_violation": 0.009925182221936448,
            "auditor_fp_violation": 0.02528754281136634,
            "ave_precision_score": 0.48460352298667575,
            "fpr": 0.27661909989023054,
            "logloss": 7.142362923020617,
            "mae": 0.4207136277993042,
            "precision": 0.5841584158415841,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5843695488804834,
            "auditor_fn_violation": 0.07595735662686127,
            "auditor_fp_violation": 0.07651798647996137,
            "ave_precision_score": 0.5267867074076756,
            "fpr": 0.15899122807017543,
            "logloss": 12.527763658919264,
            "mae": 0.48874315654635897,
            "precision": 0.5496894409937888,
            "recall": 0.37184873949579833
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6098643500454614,
            "auditor_fn_violation": 0.07714176797762357,
            "auditor_fp_violation": 0.08029396926961466,
            "ave_precision_score": 0.5474877823315245,
            "fpr": 0.16245883644346873,
            "logloss": 12.168525713843659,
            "mae": 0.4659740673805392,
            "precision": 0.5795454545454546,
            "recall": 0.42677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.857624056759585,
            "auditor_fn_violation": 0.007657010172490049,
            "auditor_fp_violation": 0.010215475615644615,
            "ave_precision_score": 0.8578186171801133,
            "fpr": 0.1206140350877193,
            "logloss": 0.48722264754079614,
            "mae": 0.31728538176148985,
            "precision": 0.7782258064516129,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8686279182789559,
            "auditor_fn_violation": 0.006595354775891133,
            "auditor_fp_violation": 0.0077725921062305,
            "ave_precision_score": 0.8688483254368591,
            "fpr": 0.1163556531284303,
            "logloss": 0.4714822253113782,
            "mae": 0.3116347095739959,
            "precision": 0.7823408624229979,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8084162983536021,
            "auditor_fn_violation": 0.005362671384343217,
            "auditor_fp_violation": 0.020285087719298243,
            "ave_precision_score": 0.808559222409275,
            "fpr": 0.14583333333333334,
            "logloss": 0.772134314238067,
            "mae": 0.2745270295865745,
            "precision": 0.7427466150870407,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8188554834534939,
            "auditor_fn_violation": 0.0131769309554538,
            "auditor_fp_violation": 0.0207497281113818,
            "ave_precision_score": 0.819201402486991,
            "fpr": 0.14050493962678376,
            "logloss": 0.7434835041986838,
            "mae": 0.27227580789252503,
            "precision": 0.7450199203187251,
            "recall": 0.7824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7995556460110453,
            "auditor_fn_violation": 0.016435850656051895,
            "auditor_fp_violation": 0.013965173829068086,
            "ave_precision_score": 0.8010213273035649,
            "fpr": 0.11293859649122807,
            "logloss": 1.1603139757985552,
            "mae": 0.3040532060188481,
            "precision": 0.7593457943925234,
            "recall": 0.6827731092436975
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7992116448792668,
            "auditor_fn_violation": 0.01564789256369157,
            "auditor_fp_violation": 0.017783670458319287,
            "ave_precision_score": 0.7997275855068138,
            "fpr": 0.1163556531284303,
            "logloss": 1.0595126709425555,
            "mae": 0.3142200905579236,
            "precision": 0.7511737089201878,
            "recall": 0.6694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8064958286771464,
            "auditor_fn_violation": 0.009790100250626571,
            "auditor_fp_violation": 0.02546575728311605,
            "ave_precision_score": 0.8068341846404057,
            "fpr": 0.26535087719298245,
            "logloss": 1.7450724570677252,
            "mae": 0.32352178797249875,
            "precision": 0.6371814092953523,
            "recall": 0.8928571428571429
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8064165346451773,
            "auditor_fn_violation": 0.00528179525924429,
            "auditor_fp_violation": 0.028938075307443294,
            "ave_precision_score": 0.8067625174489432,
            "fpr": 0.2689352360043908,
            "logloss": 1.804565297997311,
            "mae": 0.3167749880469381,
            "precision": 0.6402349486049926,
            "recall": 0.9121338912133892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6815087427811835,
            "auditor_fn_violation": 0.008255933952528396,
            "auditor_fp_violation": 0.011779736037341062,
            "ave_precision_score": 0.68310291030145,
            "fpr": 0.10307017543859649,
            "logloss": 1.7325042094774747,
            "mae": 0.4025636496948679,
            "precision": 0.6928104575163399,
            "recall": 0.44537815126050423
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7110075742604312,
            "auditor_fn_violation": 0.010104303974206481,
            "auditor_fp_violation": 0.0169673708307243,
            "ave_precision_score": 0.7122658311308014,
            "fpr": 0.09220636663007684,
            "logloss": 1.6577044204324545,
            "mae": 0.3891033318419342,
            "precision": 0.7254901960784313,
            "recall": 0.46443514644351463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7716789588090633,
            "auditor_fn_violation": 0.012522114108801417,
            "auditor_fp_violation": 0.021112485916626435,
            "ave_precision_score": 0.7572759960384748,
            "fpr": 0.16776315789473684,
            "logloss": 3.1798272174208244,
            "mae": 0.3034551597360794,
            "precision": 0.700587084148728,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7675914725150667,
            "auditor_fn_violation": 0.016047471857217,
            "auditor_fp_violation": 0.02046833289814254,
            "ave_precision_score": 0.7496978999067081,
            "fpr": 0.18111964873765093,
            "logloss": 3.1357614992778604,
            "mae": 0.30779339281783613,
            "precision": 0.6863117870722434,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8434224309670605,
            "auditor_fn_violation": 0.009548227185611087,
            "auditor_fp_violation": 0.015574702237244487,
            "ave_precision_score": 0.8436882484909072,
            "fpr": 0.12390350877192982,
            "logloss": 0.9621285133796329,
            "mae": 0.28010127453864553,
            "precision": 0.7616033755274262,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8462873699738066,
            "auditor_fn_violation": 0.00885963743920195,
            "auditor_fp_violation": 0.023492697667461843,
            "ave_precision_score": 0.8465465482025354,
            "fpr": 0.12733260153677278,
            "logloss": 0.8954588646320973,
            "mae": 0.28230967709519283,
            "precision": 0.7578288100208769,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8026552366713868,
            "auditor_fn_violation": 0.007788312693498447,
            "auditor_fp_violation": 0.015599851118622245,
            "ave_precision_score": 0.8015310005850808,
            "fpr": 0.13048245614035087,
            "logloss": 0.952867311190544,
            "mae": 0.27139890546157636,
            "precision": 0.7551440329218106,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.81071271533198,
            "auditor_fn_violation": 0.011192813084155075,
            "auditor_fp_violation": 0.02112238663702299,
            "ave_precision_score": 0.8110013157044238,
            "fpr": 0.12733260153677278,
            "logloss": 0.9139088404827261,
            "mae": 0.27610854699624443,
            "precision": 0.7563025210084033,
            "recall": 0.7531380753138075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7651839698230009,
            "auditor_fn_violation": 0.012835397316821472,
            "auditor_fp_violation": 0.02203293497505232,
            "ave_precision_score": 0.7473552106666113,
            "fpr": 0.1524122807017544,
            "logloss": 3.7953270168029825,
            "mae": 0.3085132512526829,
            "precision": 0.7048832271762208,
            "recall": 0.6974789915966386
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7598442655358268,
            "auditor_fn_violation": 0.017021159331095076,
            "auditor_fp_violation": 0.017238625675918908,
            "ave_precision_score": 0.7401474878113757,
            "fpr": 0.16355653128430298,
            "logloss": 3.6327914603372236,
            "mae": 0.31400033043954245,
            "precision": 0.6927835051546392,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7147901272957018,
            "auditor_fn_violation": 0.004544910069290874,
            "auditor_fp_violation": 0.015921756800257522,
            "ave_precision_score": 0.7162676819354665,
            "fpr": 0.09758771929824561,
            "logloss": 1.5669383340239729,
            "mae": 0.3790038127507367,
            "precision": 0.7303030303030303,
            "recall": 0.5063025210084033
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7595349057173988,
            "auditor_fn_violation": 0.01033854011179035,
            "auditor_fp_violation": 0.012650109135711083,
            "ave_precision_score": 0.7600129185267581,
            "fpr": 0.07464324917672886,
            "logloss": 1.4629221256569045,
            "mae": 0.3622520426098273,
            "precision": 0.7841269841269841,
            "recall": 0.5167364016736402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7807159390437091,
            "auditor_fn_violation": 0.015659553295002213,
            "auditor_fp_violation": 0.018801303718010625,
            "ave_precision_score": 0.7390347899044519,
            "fpr": 0.17105263157894737,
            "logloss": 3.6603428777754234,
            "mae": 0.30162446287037264,
            "precision": 0.6970873786407767,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7798041026635913,
            "auditor_fn_violation": 0.018095889844715225,
            "auditor_fp_violation": 0.020202148236970266,
            "ave_precision_score": 0.7389565481658631,
            "fpr": 0.18551042810098792,
            "logloss": 3.6523844246929125,
            "mae": 0.3180556585649387,
            "precision": 0.6768642447418738,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6481397550418851,
            "auditor_fn_violation": 0.0164266364440513,
            "auditor_fp_violation": 0.01434743682600998,
            "ave_precision_score": 0.6190875569884535,
            "fpr": 0.17653508771929824,
            "logloss": 5.406109551910898,
            "mae": 0.36454211401283876,
            "precision": 0.6588983050847458,
            "recall": 0.6533613445378151
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6316009914255876,
            "auditor_fn_violation": 0.015900500163046727,
            "auditor_fp_violation": 0.010703158471136712,
            "ave_precision_score": 0.6038722725495989,
            "fpr": 0.17672886937431395,
            "logloss": 5.7211720592237185,
            "mae": 0.37267949085819674,
            "precision": 0.6552462526766595,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 18313,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.41380001746326284,
            "auditor_fn_violation": 0.0035774178092289424,
            "auditor_fp_violation": 0.003450426525028167,
            "ave_precision_score": 0.5262109614268508,
            "fpr": 0.020833333333333332,
            "logloss": 15.95885813493691,
            "mae": 0.5117735003566832,
            "precision": 0.62,
            "recall": 0.06512605042016807
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.388767507771958,
            "auditor_fn_violation": 0.002298729154131969,
            "auditor_fp_violation": 0.0036733483241774265,
            "ave_precision_score": 0.5238617821603073,
            "fpr": 0.02854006586169045,
            "logloss": 16.499197517810067,
            "mae": 0.5260311221865046,
            "precision": 0.46938775510204084,
            "recall": 0.04811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8120453265806479,
            "auditor_fn_violation": 0.004971067374318144,
            "auditor_fp_violation": 0.020581844519555775,
            "ave_precision_score": 0.8123879294490035,
            "fpr": 0.1425438596491228,
            "logloss": 1.022274305834975,
            "mae": 0.3110764393162355,
            "precision": 0.7204301075268817,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8104404987166116,
            "auditor_fn_violation": 0.011870260736971186,
            "auditor_fp_violation": 0.0213150536298715,
            "ave_precision_score": 0.8107694661669014,
            "fpr": 0.14709110867178923,
            "logloss": 0.976646267185162,
            "mae": 0.3172548624727329,
            "precision": 0.7118279569892473,
            "recall": 0.6924686192468619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7997788125336913,
            "auditor_fn_violation": 0.010649325519681563,
            "auditor_fp_violation": 0.01594690568163529,
            "ave_precision_score": 0.8001638639818803,
            "fpr": 0.1524122807017544,
            "logloss": 1.035466448685215,
            "mae": 0.27505509644454895,
            "precision": 0.7295719844357976,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8132486498463096,
            "auditor_fn_violation": 0.01327797399519586,
            "auditor_fp_violation": 0.021091965532889015,
            "ave_precision_score": 0.8135883906014385,
            "fpr": 0.1437980241492865,
            "logloss": 0.9805545429739999,
            "mae": 0.2751997856876243,
            "precision": 0.7390438247011952,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7716115452091384,
            "auditor_fn_violation": 0.011925493881763232,
            "auditor_fp_violation": 0.018426585385482055,
            "ave_precision_score": 0.6523732478970573,
            "fpr": 0.3432017543859649,
            "logloss": 8.376947662632276,
            "mae": 0.3860481092202725,
            "precision": 0.5826666666666667,
            "recall": 0.9180672268907563
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7654793751106039,
            "auditor_fn_violation": 0.006783662259046797,
            "auditor_fp_violation": 0.022673862947855693,
            "ave_precision_score": 0.6368143657926516,
            "fpr": 0.3534577387486279,
            "logloss": 8.746749853514988,
            "mae": 0.37565841614020573,
            "precision": 0.5866495507060334,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8066519715681643,
            "auditor_fn_violation": 0.009840778416629812,
            "auditor_fp_violation": 0.017413085465958485,
            "ave_precision_score": 0.8071712333187293,
            "fpr": 0.14802631578947367,
            "logloss": 0.865503983120622,
            "mae": 0.2892008797949066,
            "precision": 0.7272727272727273,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8189566501734653,
            "auditor_fn_violation": 0.014001350302440194,
            "auditor_fp_violation": 0.02531035863946682,
            "ave_precision_score": 0.8192766975374175,
            "fpr": 0.14270032930845225,
            "logloss": 0.8100468715899549,
            "mae": 0.28661175863188326,
            "precision": 0.7363083164300203,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7653132520090555,
            "auditor_fn_violation": 0.01348730281586319,
            "auditor_fp_violation": 0.019419966199903438,
            "ave_precision_score": 0.7429014481321999,
            "fpr": 0.16776315789473684,
            "logloss": 3.5675825843643034,
            "mae": 0.313260010059643,
            "precision": 0.6890243902439024,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7617672822330807,
            "auditor_fn_violation": 0.018178561422686004,
            "auditor_fp_violation": 0.019938498667809147,
            "ave_precision_score": 0.7368475140532355,
            "fpr": 0.1756311745334797,
            "logloss": 3.4688932147797344,
            "mae": 0.3166858006449916,
            "precision": 0.6837944664031621,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8681685854384714,
            "auditor_fn_violation": 0.00986842105263158,
            "auditor_fp_violation": 0.012091582166425243,
            "ave_precision_score": 0.8684253844193603,
            "fpr": 0.12280701754385964,
            "logloss": 0.4681976122945174,
            "mae": 0.2864654641128717,
            "precision": 0.7786561264822134,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.875438961774893,
            "auditor_fn_violation": 0.011748549802736433,
            "auditor_fp_violation": 0.015682079181063877,
            "ave_precision_score": 0.8757135220737429,
            "fpr": 0.1251372118551043,
            "logloss": 0.46414254706662106,
            "mae": 0.2880333140165301,
            "precision": 0.7747035573122529,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7770151447138899,
            "auditor_fn_violation": 0.0009905277900633938,
            "auditor_fp_violation": 0.004727989699018193,
            "ave_precision_score": 0.5701215452700958,
            "fpr": 0.45614035087719296,
            "logloss": 13.923167840741993,
            "mae": 0.45850400016311754,
            "precision": 0.5325842696629214,
            "recall": 0.9957983193277311
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.7902062779322474,
            "auditor_fn_violation": 0.002085160911040789,
            "auditor_fp_violation": 0.0049180785016592335,
            "ave_precision_score": 0.5904682131202205,
            "fpr": 0.45554335894621295,
            "logloss": 13.345855554635836,
            "mae": 0.4588132641142253,
            "precision": 0.5331833520809899,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7972365012763227,
            "auditor_fn_violation": 0.008149970514521595,
            "auditor_fp_violation": 0.015179864799613722,
            "ave_precision_score": 0.7986971368311979,
            "fpr": 0.13815789473684212,
            "logloss": 0.8985509132129268,
            "mae": 0.28286151469569615,
            "precision": 0.7412731006160165,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8127117103040883,
            "auditor_fn_violation": 0.015510106600406925,
            "auditor_fp_violation": 0.020458192530097882,
            "ave_precision_score": 0.8130269621002617,
            "fpr": 0.13830954994511527,
            "logloss": 0.8597871793837191,
            "mae": 0.2843301772982293,
            "precision": 0.7412731006160165,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8182039766525913,
            "auditor_fn_violation": 0.008359593837535014,
            "auditor_fp_violation": 0.015350877192982457,
            "ave_precision_score": 0.8186023930160202,
            "fpr": 0.13815789473684212,
            "logloss": 0.8392173730703093,
            "mae": 0.27661213060746825,
            "precision": 0.7454545454545455,
            "recall": 0.7752100840336135
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8221861806247098,
            "auditor_fn_violation": 0.011215777411369181,
            "auditor_fp_violation": 0.023269609570479362,
            "ave_precision_score": 0.8224717191889414,
            "fpr": 0.1350164654226125,
            "logloss": 0.831305976763341,
            "mae": 0.280548453879933,
            "precision": 0.7448132780082988,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7032358472173443,
            "auditor_fn_violation": 0.01145326551673302,
            "auditor_fp_violation": 0.003983582810236601,
            "ave_precision_score": 0.7033276784980531,
            "fpr": 0.03508771929824561,
            "logloss": 5.1495401754685775,
            "mae": 0.41575461079316856,
            "precision": 0.8297872340425532,
            "recall": 0.3277310924369748
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.710953113012887,
            "auditor_fn_violation": 0.010127268301420588,
            "auditor_fp_violation": 0.003944603169372033,
            "ave_precision_score": 0.711091283125631,
            "fpr": 0.04061470911086718,
            "logloss": 5.164604169757427,
            "mae": 0.41348808859624914,
            "precision": 0.8131313131313131,
            "recall": 0.3368200836820084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8038806331767343,
            "auditor_fn_violation": 0.008191434468524257,
            "auditor_fp_violation": 0.01370614035087719,
            "ave_precision_score": 0.8053971219155065,
            "fpr": 0.12828947368421054,
            "logloss": 0.916824308362152,
            "mae": 0.27317453602730063,
            "precision": 0.7567567567567568,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8197944737528113,
            "auditor_fn_violation": 0.013431834987530367,
            "auditor_fp_violation": 0.020835921239761402,
            "ave_precision_score": 0.820087320017496,
            "fpr": 0.13062568605927552,
            "logloss": 0.8814068392145895,
            "mae": 0.2755258448457426,
            "precision": 0.7531120331950207,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 18313,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8164247368339919,
            "auditor_fn_violation": 0.012199616688780777,
            "auditor_fp_violation": 0.01062288749396427,
            "ave_precision_score": 0.8168848212432624,
            "fpr": 0.10964912280701754,
            "logloss": 0.8543183994931888,
            "mae": 0.27758348275692146,
            "precision": 0.7737556561085973,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8249600052250566,
            "auditor_fn_violation": 0.017140573832608433,
            "auditor_fp_violation": 0.018835733642952577,
            "ave_precision_score": 0.8252447048547246,
            "fpr": 0.10867178924259056,
            "logloss": 0.8310968187566655,
            "mae": 0.2799289618244999,
            "precision": 0.7734553775743707,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7531543292601869,
            "auditor_fn_violation": 0.009354728733598707,
            "auditor_fp_violation": 0.019920428939320778,
            "ave_precision_score": 0.7541144549262049,
            "fpr": 0.15899122807017543,
            "logloss": 2.191315827686088,
            "mae": 0.3064330333445475,
            "precision": 0.7016460905349794,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7566060374227161,
            "auditor_fn_violation": 0.015188606019409454,
            "auditor_fp_violation": 0.017274116964075218,
            "ave_precision_score": 0.7571444296492584,
            "fpr": 0.16794731064763996,
            "logloss": 2.021172822376387,
            "mae": 0.30891497891240777,
            "precision": 0.6933867735470942,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7622460482371082,
            "auditor_fn_violation": 0.016382868937048507,
            "auditor_fp_violation": 0.01758409785932722,
            "ave_precision_score": 0.7410480152766225,
            "fpr": 0.12828947368421054,
            "logloss": 3.7657925414515225,
            "mae": 0.31461943375980267,
            "precision": 0.7247058823529412,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7611597681412485,
            "auditor_fn_violation": 0.017652678329482988,
            "auditor_fp_violation": 0.019390918793397615,
            "ave_precision_score": 0.7398554298494767,
            "fpr": 0.1350164654226125,
            "logloss": 3.6007510781155343,
            "mae": 0.32079664127399227,
            "precision": 0.7126168224299065,
            "recall": 0.6380753138075314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8374046793283372,
            "auditor_fn_violation": 0.006878409258440218,
            "auditor_fp_violation": 0.018245513439562204,
            "ave_precision_score": 0.8378351752990001,
            "fpr": 0.2730263157894737,
            "logloss": 0.7329606359650561,
            "mae": 0.32268220238160883,
            "precision": 0.6437768240343348,
            "recall": 0.9453781512605042
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8492954605242964,
            "auditor_fn_violation": 0.00470998351161306,
            "auditor_fp_violation": 0.02389577729723702,
            "ave_precision_score": 0.8497549767871972,
            "fpr": 0.27771679473106475,
            "logloss": 0.6985080031922214,
            "mae": 0.3171925857242986,
            "precision": 0.643661971830986,
            "recall": 0.9560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8050478468080307,
            "auditor_fn_violation": 0.012061403508771936,
            "auditor_fp_violation": 0.015657693545791086,
            "ave_precision_score": 0.8064064148838593,
            "fpr": 0.14583333333333334,
            "logloss": 1.0374088123402752,
            "mae": 0.27478423169986843,
            "precision": 0.73767258382643,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8216807485061268,
            "auditor_fn_violation": 0.011443124250788826,
            "auditor_fp_violation": 0.021091965532889015,
            "ave_precision_score": 0.8219724965804637,
            "fpr": 0.1437980241492865,
            "logloss": 0.9789857662586053,
            "mae": 0.2754211928879488,
            "precision": 0.7390438247011952,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7877146939285543,
            "auditor_fn_violation": 0.013680801267875574,
            "auditor_fp_violation": 0.01688998873330114,
            "ave_precision_score": 0.7512086583754889,
            "fpr": 0.1425438596491228,
            "logloss": 3.0575962304210087,
            "mae": 0.2799885784586123,
            "precision": 0.738430583501006,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7853524046049917,
            "auditor_fn_violation": 0.014201139949202909,
            "auditor_fp_violation": 0.021971642460763118,
            "ave_precision_score": 0.7501065701021985,
            "fpr": 0.1350164654226125,
            "logloss": 2.8589314760476974,
            "mae": 0.2793842459651409,
            "precision": 0.7479508196721312,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 18313,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7609771289735353,
            "auditor_fn_violation": 0.0009905277900633938,
            "auditor_fp_violation": 0.0013027120553677869,
            "ave_precision_score": 0.5249618484545905,
            "fpr": 0.4725877192982456,
            "logloss": 16.265201980196636,
            "mae": 0.4749048094932122,
            "precision": 0.523756906077348,
            "recall": 0.9957983193277311
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7640500029795119,
            "auditor_fn_violation": 0.0010701376481773216,
            "auditor_fp_violation": 0.002441293606751468,
            "ave_precision_score": 0.5300676268860419,
            "fpr": 0.4632272228320527,
            "logloss": 16.00405242612354,
            "mae": 0.4654942255909869,
            "precision": 0.5300668151447662,
            "recall": 0.99581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.761598269709242,
            "auditor_fn_violation": 0.012236473536783136,
            "auditor_fp_violation": 0.01903267342668599,
            "ave_precision_score": 0.7418156880195301,
            "fpr": 0.17105263157894737,
            "logloss": 3.4831078471185517,
            "mae": 0.3066783757959168,
            "precision": 0.6947162426614482,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7629979214852495,
            "auditor_fn_violation": 0.016047471857217,
            "auditor_fp_violation": 0.01942133989753159,
            "ave_precision_score": 0.7414319943147187,
            "fpr": 0.18221734357848518,
            "logloss": 3.3721811532376287,
            "mae": 0.3113878143193289,
            "precision": 0.6850094876660342,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 18313,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.668728757625288,
            "auditor_fn_violation": 0.004809818664307831,
            "auditor_fp_violation": 0.010834138097537423,
            "ave_precision_score": 0.6693002841850791,
            "fpr": 0.08991228070175439,
            "logloss": 4.627757103853556,
            "mae": 0.4233604252432563,
            "precision": 0.7201365187713311,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6922656462522729,
            "auditor_fn_violation": 0.017115313072672916,
            "auditor_fp_violation": 0.01035078068158484,
            "ave_precision_score": 0.6932650678985184,
            "fpr": 0.08781558726673985,
            "logloss": 4.6040463268875556,
            "mae": 0.40872641839518886,
            "precision": 0.7306397306397306,
            "recall": 0.45397489539748953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 18313,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6575460113283891,
            "auditor_fn_violation": 0.006445341294412501,
            "auditor_fp_violation": 0.006835465958474184,
            "ave_precision_score": 0.5342932687587398,
            "fpr": 0.3574561403508772,
            "logloss": 9.487867288155504,
            "mae": 0.4358360633299528,
            "precision": 0.5564625850340136,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6452872937393187,
            "auditor_fn_violation": 0.009346481176140984,
            "auditor_fp_violation": 0.002712548451946074,
            "ave_precision_score": 0.5252822749889648,
            "fpr": 0.36663007683863885,
            "logloss": 9.609835602170879,
            "mae": 0.44620938030575696,
            "precision": 0.5498652291105122,
            "recall": 0.8535564853556485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 18313,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8086077006362491,
            "auditor_fn_violation": 0.005579205366357076,
            "auditor_fp_violation": 0.02061956784162241,
            "ave_precision_score": 0.8090495606582675,
            "fpr": 0.14583333333333334,
            "logloss": 0.7842485295338276,
            "mae": 0.2748319491954661,
            "precision": 0.7412451361867705,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8187084994643727,
            "auditor_fn_violation": 0.014012832466047247,
            "auditor_fp_violation": 0.021074219888810867,
            "ave_precision_score": 0.8190518877651243,
            "fpr": 0.14050493962678376,
            "logloss": 0.7541543658337075,
            "mae": 0.27255470991933445,
            "precision": 0.744,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.816777799825788,
            "auditor_fn_violation": 0.007481940144478847,
            "auditor_fp_violation": 0.015099388379204904,
            "ave_precision_score": 0.817275305410604,
            "fpr": 0.1787280701754386,
            "logloss": 0.839783457501917,
            "mae": 0.27661730219242686,
            "precision": 0.7099644128113879,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.822555966168276,
            "auditor_fn_violation": 0.00972768900789514,
            "auditor_fp_violation": 0.01930726075702918,
            "ave_precision_score": 0.8228663369087794,
            "fpr": 0.1734357848518112,
            "logloss": 0.8173102790702085,
            "mae": 0.27405704829304883,
            "precision": 0.7148014440433214,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 18313,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7717343132206488,
            "auditor_fn_violation": 0.01574248120300752,
            "auditor_fp_violation": 0.02022221551585386,
            "ave_precision_score": 0.7471518769211648,
            "fpr": 0.15021929824561403,
            "logloss": 3.592722179117781,
            "mae": 0.2992250021422425,
            "precision": 0.7139874739039666,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7722327037147689,
            "auditor_fn_violation": 0.01615999706056612,
            "auditor_fp_violation": 0.01960133143032427,
            "ave_precision_score": 0.7455313734538156,
            "fpr": 0.15806805708013172,
            "logloss": 3.5160772193122316,
            "mae": 0.3086955506684136,
            "precision": 0.7067209775967414,
            "recall": 0.7259414225941423
        }
    }
]