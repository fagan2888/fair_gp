[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 26311,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.663947924262154,
            "auditor_fn_violation": 0.00560138143623701,
            "auditor_fp_violation": 0.01835103279262458,
            "ave_precision_score": 0.6673477250655131,
            "fpr": 0.11732456140350878,
            "logloss": 4.613133929011702,
            "mae": 0.3907449000657359,
            "precision": 0.6843657817109144,
            "recall": 0.5032537960954447
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6959481192860622,
            "auditor_fn_violation": 0.012929642881794082,
            "auditor_fp_violation": 0.02013140825319461,
            "ave_precision_score": 0.6985755106554069,
            "fpr": 0.11086717892425905,
            "logloss": 4.658713027576475,
            "mae": 0.40247786359395626,
            "precision": 0.7097701149425287,
            "recall": 0.5010141987829615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.811777647919065,
            "auditor_fn_violation": 0.009759009780416335,
            "auditor_fp_violation": 0.015555101723266039,
            "ave_precision_score": 0.8121014587812743,
            "fpr": 0.08771929824561403,
            "logloss": 3.0605029549388973,
            "mae": 0.26296773289722847,
            "precision": 0.7953964194373402,
            "recall": 0.6746203904555315
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8433384335867997,
            "auditor_fn_violation": 0.012827221050803465,
            "auditor_fp_violation": 0.015404492670654786,
            "ave_precision_score": 0.8435375058860827,
            "fpr": 0.07903402854006586,
            "logloss": 3.1420247400618804,
            "mae": 0.2873997480080506,
            "precision": 0.8153846153846154,
            "recall": 0.6450304259634888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.702000521159377,
            "auditor_fn_violation": 0.009511645164973171,
            "auditor_fp_violation": 0.017359085074104334,
            "ave_precision_score": 0.6756521448610124,
            "fpr": 0.13815789473684212,
            "logloss": 3.7519780207644278,
            "mae": 0.31180621456316554,
            "precision": 0.7358490566037735,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7058821295866691,
            "auditor_fn_violation": 0.013167884966924441,
            "auditor_fp_violation": 0.015714368247732396,
            "ave_precision_score": 0.6841331544591451,
            "fpr": 0.141602634467618,
            "logloss": 3.7272197748538196,
            "mae": 0.3266475641186866,
            "precision": 0.7399193548387096,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8188344549993357,
            "auditor_fn_violation": 0.010577215816112956,
            "auditor_fp_violation": 0.013986949080017122,
            "ave_precision_score": 0.8019875806978667,
            "fpr": 0.09649122807017543,
            "logloss": 2.2155844603147976,
            "mae": 0.25267938005098345,
            "precision": 0.7914691943127962,
            "recall": 0.7245119305856833
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8366249029091677,
            "auditor_fn_violation": 0.012266127541898333,
            "auditor_fp_violation": 0.017865114837788017,
            "ave_precision_score": 0.8257403033413253,
            "fpr": 0.0889132821075741,
            "logloss": 1.9945496137845016,
            "mae": 0.2640879708796626,
            "precision": 0.8142201834862385,
            "recall": 0.7200811359026369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6340147206984694,
            "auditor_fn_violation": 0.008129733226776278,
            "auditor_fp_violation": 0.00839022445248376,
            "ave_precision_score": 0.6426125528698254,
            "fpr": 0.07017543859649122,
            "logloss": 7.844081116627054,
            "mae": 0.40144541645997356,
            "precision": 0.7419354838709677,
            "recall": 0.39913232104121477
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6931239220734808,
            "auditor_fn_violation": 0.015011477924755594,
            "auditor_fp_violation": 0.009858245053808059,
            "ave_precision_score": 0.6999626177566876,
            "fpr": 0.07464324917672886,
            "logloss": 7.6189263763991955,
            "mae": 0.40782617666683674,
            "precision": 0.7571428571428571,
            "recall": 0.4300202839756592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7161676952911207,
            "auditor_fn_violation": 0.00904070099326407,
            "auditor_fp_violation": 0.010242832691484812,
            "ave_precision_score": 0.6953763238027543,
            "fpr": 0.10964912280701754,
            "logloss": 3.3782885646598126,
            "mae": 0.28853935837480693,
            "precision": 0.7530864197530864,
            "recall": 0.6616052060737527
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7106061364804379,
            "auditor_fn_violation": 0.015104993509573107,
            "auditor_fp_violation": 0.015120877735702398,
            "ave_precision_score": 0.6910201674653846,
            "fpr": 0.1163556531284303,
            "logloss": 3.609986456443061,
            "mae": 0.3238084765737129,
            "precision": 0.7451923076923077,
            "recall": 0.6288032454361054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5890978560747376,
            "auditor_fn_violation": 0.0059415077824713745,
            "auditor_fp_violation": 0.004507527132687596,
            "ave_precision_score": 0.5930241530235516,
            "fpr": 0.01425438596491228,
            "logloss": 6.994160926377222,
            "mae": 0.4613205346520945,
            "precision": 0.8243243243243243,
            "recall": 0.13232104121475055
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6170252432339574,
            "auditor_fn_violation": 0.011206284247299735,
            "auditor_fp_violation": 0.0024842567450459306,
            "ave_precision_score": 0.6206167516762302,
            "fpr": 0.012074643249176729,
            "logloss": 7.119526311146112,
            "mae": 0.4902837991671851,
            "precision": 0.8571428571428571,
            "recall": 0.13387423935091278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7885862729074717,
            "auditor_fn_violation": 0.008595920386649922,
            "auditor_fp_violation": 0.008256506010036177,
            "ave_precision_score": 0.7897576823284718,
            "fpr": 0.08552631578947369,
            "logloss": 3.3627627787603878,
            "mae": 0.2736984333180112,
            "precision": 0.7974025974025974,
            "recall": 0.665943600867679
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8397163083032756,
            "auditor_fn_violation": 0.018703116963504424,
            "auditor_fp_violation": 0.013369292905950136,
            "ave_precision_score": 0.8395696397930626,
            "fpr": 0.07354555433589462,
            "logloss": 3.5739531569894263,
            "mae": 0.28842194741178384,
            "precision": 0.825065274151436,
            "recall": 0.640973630831643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7587687935819272,
            "auditor_fn_violation": 0.0033536933439890426,
            "auditor_fp_violation": 0.009049091687089119,
            "ave_precision_score": 0.7601507186371076,
            "fpr": 0.10197368421052631,
            "logloss": 3.199682501840339,
            "mae": 0.27260820334040525,
            "precision": 0.7720588235294118,
            "recall": 0.6832971800433839
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8237683888001577,
            "auditor_fn_violation": 0.012642416442711687,
            "auditor_fp_violation": 0.014548395737372571,
            "ave_precision_score": 0.823715612230677,
            "fpr": 0.08562019758507135,
            "logloss": 3.4113633621408836,
            "mae": 0.2861475805225192,
            "precision": 0.8054862842892768,
            "recall": 0.6551724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6834421666215071,
            "auditor_fn_violation": 0.016987289264375694,
            "auditor_fp_violation": 0.002511475473606412,
            "ave_precision_score": 0.6577708856173916,
            "fpr": 0.1337719298245614,
            "logloss": 4.829535499430783,
            "mae": 0.31134981285223834,
            "precision": 0.7175925925925926,
            "recall": 0.6724511930585684
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6564131855732069,
            "auditor_fn_violation": 0.017467375306987172,
            "auditor_fp_violation": 0.011166025031644076,
            "ave_precision_score": 0.6304311868627037,
            "fpr": 0.150384193194292,
            "logloss": 5.604234421397582,
            "mae": 0.3555620145012072,
            "precision": 0.7015250544662309,
            "recall": 0.6531440162271805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8066395332207656,
            "auditor_fn_violation": 0.006507592190889373,
            "auditor_fp_violation": 0.0168752674368849,
            "ave_precision_score": 0.7626805302819153,
            "fpr": 0.09649122807017543,
            "logloss": 4.186250532814859,
            "mae": 0.25411036043339297,
            "precision": 0.7884615384615384,
            "recall": 0.7114967462039046
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8138716938674091,
            "auditor_fn_violation": 0.02136385800771727,
            "auditor_fp_violation": 0.01715870356461956,
            "ave_precision_score": 0.7761724203860912,
            "fpr": 0.09659714599341383,
            "logloss": 4.101465824298541,
            "mae": 0.2777661329462221,
            "precision": 0.7939110070257611,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7173821325740544,
            "auditor_fn_violation": 0.00489020816683792,
            "auditor_fp_violation": 0.009909752207569926,
            "ave_precision_score": 0.6923419429467228,
            "fpr": 0.12609649122807018,
            "logloss": 3.5129831605385258,
            "mae": 0.28629550232439105,
            "precision": 0.7478070175438597,
            "recall": 0.7396963123644251
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7239174940418533,
            "auditor_fn_violation": 0.017536398714828677,
            "auditor_fp_violation": 0.02005787845524399,
            "ave_precision_score": 0.70282454835003,
            "fpr": 0.1251372118551043,
            "logloss": 3.5056780244565995,
            "mae": 0.31280256079647495,
            "precision": 0.7510917030567685,
            "recall": 0.6977687626774848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7554712895199719,
            "auditor_fn_violation": 0.007639761007725398,
            "auditor_fp_violation": 0.014307873341891316,
            "ave_precision_score": 0.7562981221155785,
            "fpr": 0.05482456140350877,
            "logloss": 4.988026891421004,
            "mae": 0.34948552858466536,
            "precision": 0.7991967871485943,
            "recall": 0.4316702819956616
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7832210696450124,
            "auditor_fn_violation": 0.013942728383983912,
            "auditor_fp_violation": 0.008960131093125491,
            "ave_precision_score": 0.782802455725577,
            "fpr": 0.05159165751920966,
            "logloss": 5.1249250930472705,
            "mae": 0.36606687004703414,
            "precision": 0.8206106870229007,
            "recall": 0.43610547667342797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6618519268501497,
            "auditor_fn_violation": 0.005884423640446021,
            "auditor_fp_violation": 0.013605243707939477,
            "ave_precision_score": 0.6474021062877074,
            "fpr": 0.12828947368421054,
            "logloss": 4.869733039626705,
            "mae": 0.31953031503248225,
            "precision": 0.723404255319149,
            "recall": 0.6637744034707158
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6788257043952749,
            "auditor_fn_violation": 0.012771557012221595,
            "auditor_fp_violation": 0.021273746185641734,
            "ave_precision_score": 0.6651329386905085,
            "fpr": 0.12843029637760703,
            "logloss": 4.830540082841318,
            "mae": 0.3396584587094215,
            "precision": 0.7272727272727273,
            "recall": 0.6328600405679513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.806991891337701,
            "auditor_fn_violation": 0.009005023404498236,
            "auditor_fp_violation": 0.01705761076749524,
            "ave_precision_score": 0.8042977183489572,
            "fpr": 0.08333333333333333,
            "logloss": 3.166374630443616,
            "mae": 0.26998143369903393,
            "precision": 0.7967914438502673,
            "recall": 0.6464208242950108
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8224993943662354,
            "auditor_fn_violation": 0.018012882885089388,
            "auditor_fp_violation": 0.018681820807882398,
            "ave_precision_score": 0.8191858283274694,
            "fpr": 0.08122941822173436,
            "logloss": 3.350816839657353,
            "mae": 0.3010312776275345,
            "precision": 0.8037135278514589,
            "recall": 0.6146044624746451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 26311,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7427249128096023,
            "auditor_fn_violation": 0.02284317083380903,
            "auditor_fp_violation": 0.01749037227214378,
            "ave_precision_score": 0.7433818856046813,
            "fpr": 0.1162280701754386,
            "logloss": 4.953321460274731,
            "mae": 0.32513584327096223,
            "precision": 0.7309644670050761,
            "recall": 0.6247288503253796
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7571139453564977,
            "auditor_fn_violation": 0.02775186307537134,
            "auditor_fp_violation": 0.018863019238546424,
            "ave_precision_score": 0.7585977317438006,
            "fpr": 0.12843029637760703,
            "logloss": 4.8916874735725235,
            "mae": 0.33601213500754723,
            "precision": 0.7272727272727273,
            "recall": 0.6328600405679513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.64922490357474,
            "auditor_fn_violation": 0.007475644099402512,
            "auditor_fp_violation": 0.0119179600886918,
            "ave_precision_score": 0.6518518248492526,
            "fpr": 0.07894736842105263,
            "logloss": 6.628329174666888,
            "mae": 0.3822267200156106,
            "precision": 0.740072202166065,
            "recall": 0.44468546637744033
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.705410341024371,
            "auditor_fn_violation": 0.016794953720918326,
            "auditor_fp_violation": 0.00829311078314487,
            "ave_precision_score": 0.7075996969782956,
            "fpr": 0.07793633369923161,
            "logloss": 6.542654949149093,
            "mae": 0.39496421428622835,
            "precision": 0.7641196013289037,
            "recall": 0.4665314401622718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7831063575911968,
            "auditor_fn_violation": 0.006747821288579367,
            "auditor_fp_violation": 0.018462870035398926,
            "ave_precision_score": 0.6533792868447529,
            "fpr": 0.21820175438596492,
            "logloss": 7.714338170710201,
            "mae": 0.3020646513752677,
            "precision": 0.6638513513513513,
            "recall": 0.8524945770065075
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8066997834949067,
            "auditor_fn_violation": 0.009607613059228765,
            "auditor_fp_violation": 0.019044217669210457,
            "ave_precision_score": 0.6881658930056507,
            "fpr": 0.20636663007683864,
            "logloss": 7.293773785584469,
            "mae": 0.2823799411616559,
            "precision": 0.6957928802588996,
            "recall": 0.8722109533468559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8110078828807525,
            "auditor_fn_violation": 0.005732199261711761,
            "auditor_fp_violation": 0.01585171354105886,
            "ave_precision_score": 0.8114553564722299,
            "fpr": 0.08114035087719298,
            "logloss": 2.4782222438068344,
            "mae": 0.2693077525231949,
            "precision": 0.8037135278514589,
            "recall": 0.6572668112798264
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8464068338541088,
            "auditor_fn_violation": 0.013461791090636646,
            "auditor_fp_violation": 0.015895566678396422,
            "ave_precision_score": 0.8466051533723444,
            "fpr": 0.07793633369923161,
            "logloss": 2.591506668146861,
            "mae": 0.29383680410137314,
            "precision": 0.8101604278074866,
            "recall": 0.6146044624746451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8130483576358141,
            "auditor_fn_violation": 0.01418778779921605,
            "auditor_fp_violation": 0.011580017115960635,
            "ave_precision_score": 0.800676350099052,
            "fpr": 0.08881578947368421,
            "logloss": 2.7864599251058184,
            "mae": 0.25970000932547893,
            "precision": 0.800982800982801,
            "recall": 0.7071583514099783
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8468085208024687,
            "auditor_fn_violation": 0.01339276768279514,
            "auditor_fp_violation": 0.015015835167201508,
            "ave_precision_score": 0.8412448151041498,
            "fpr": 0.08232711306256861,
            "logloss": 2.580345249302313,
            "mae": 0.26325551932411195,
            "precision": 0.8231132075471698,
            "recall": 0.7079107505070994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 26311,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6343860800095051,
            "auditor_fn_violation": 0.016927826616432634,
            "auditor_fp_violation": 0.013298906912514105,
            "ave_precision_score": 0.638452817264777,
            "fpr": 0.09320175438596491,
            "logloss": 7.323751710215655,
            "mae": 0.39978279802918615,
            "precision": 0.6996466431095406,
            "recall": 0.42950108459869846
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.684685551799805,
            "auditor_fn_violation": 0.023813075705319032,
            "auditor_fp_violation": 0.014745350553311732,
            "ave_precision_score": 0.6879661607527623,
            "fpr": 0.09330406147091108,
            "logloss": 7.303459010976032,
            "mae": 0.41440541714624207,
            "precision": 0.7292993630573248,
            "recall": 0.4645030425963489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8236459317439376,
            "auditor_fn_violation": 0.00679539140693382,
            "auditor_fp_violation": 0.025717703349282296,
            "ave_precision_score": 0.8178707751360619,
            "fpr": 0.1337719298245614,
            "logloss": 0.9850566146868016,
            "mae": 0.27466268598095517,
            "precision": 0.75,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8500840468605022,
            "auditor_fn_violation": 0.023439013366048943,
            "auditor_fp_violation": 0.02121859883717877,
            "ave_precision_score": 0.8483063042582162,
            "fpr": 0.12623490669593854,
            "logloss": 0.8645264016684048,
            "mae": 0.27933959390410096,
            "precision": 0.766260162601626,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7812164336642697,
            "auditor_fn_violation": 0.010196654869277323,
            "auditor_fp_violation": 0.013425331621737271,
            "ave_precision_score": 0.7621133958222229,
            "fpr": 0.10855263157894737,
            "logloss": 2.5518591535293362,
            "mae": 0.2729068730296968,
            "precision": 0.7681498829039812,
            "recall": 0.7114967462039046
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8047909240286539,
            "auditor_fn_violation": 0.012032338579854522,
            "auditor_fp_violation": 0.010924427124092037,
            "ave_precision_score": 0.7903268163766227,
            "fpr": 0.10757409440175632,
            "logloss": 2.32969092868195,
            "mae": 0.2865239461504235,
            "precision": 0.7787810383747178,
            "recall": 0.6997971602434077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5865343081137442,
            "auditor_fn_violation": 0.004592894927122585,
            "auditor_fp_violation": 0.004507527132687596,
            "ave_precision_score": 0.5904799581269032,
            "fpr": 0.01425438596491228,
            "logloss": 7.021262072873625,
            "mae": 0.46285787649222565,
            "precision": 0.821917808219178,
            "recall": 0.1301518438177874
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.614571783445788,
            "auditor_fn_violation": 0.01245093214999009,
            "auditor_fp_violation": 0.003009469587550355,
            "ave_precision_score": 0.618083337043791,
            "fpr": 0.013172338090010977,
            "logloss": 7.149406994291432,
            "mae": 0.493156006272771,
            "precision": 0.8461538461538461,
            "recall": 0.13387423935091278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7235941482476193,
            "auditor_fn_violation": 0.011071945046999277,
            "auditor_fp_violation": 0.012039522309098695,
            "ave_precision_score": 0.7002880587717734,
            "fpr": 0.1074561403508772,
            "logloss": 3.456616586773203,
            "mae": 0.2868796275485002,
            "precision": 0.7562189054726368,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7176917297802625,
            "auditor_fn_violation": 0.017371633160626388,
            "auditor_fp_violation": 0.017581499902835623,
            "ave_precision_score": 0.696695706454106,
            "fpr": 0.11525795828759605,
            "logloss": 3.652163797967934,
            "mae": 0.3219547452564455,
            "precision": 0.7457627118644068,
            "recall": 0.6247464503042597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6744927567561487,
            "auditor_fn_violation": 0.005313582220192568,
            "auditor_fp_violation": 0.0031557552417629457,
            "ave_precision_score": 0.6485476082309853,
            "fpr": 0.16885964912280702,
            "logloss": 4.675622118887964,
            "mae": 0.29523419978132537,
            "precision": 0.7003891050583657,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6637809959044918,
            "auditor_fn_violation": 0.011322065447550008,
            "auditor_fp_violation": 0.004926496462691508,
            "ave_precision_score": 0.6363139178029477,
            "fpr": 0.18660812294182216,
            "logloss": 5.316303387982097,
            "mae": 0.32075967552746987,
            "precision": 0.6897810218978102,
            "recall": 0.7667342799188641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6747055623130169,
            "auditor_fn_violation": 0.01619524679377403,
            "auditor_fp_violation": 0.006209398218384104,
            "ave_precision_score": 0.649705232166765,
            "fpr": 0.16228070175438597,
            "logloss": 4.675986929373626,
            "mae": 0.2972023287133066,
            "precision": 0.704,
            "recall": 0.7635574837310195
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.664016214199636,
            "auditor_fn_violation": 0.019629366565506557,
            "auditor_fp_violation": 0.014674446819573632,
            "ave_precision_score": 0.6393600307365233,
            "fpr": 0.1756311745334797,
            "logloss": 5.2565401082911505,
            "mae": 0.31692421688262995,
            "precision": 0.702048417132216,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8191739495078992,
            "auditor_fn_violation": 0.0044501845720592145,
            "auditor_fp_violation": 0.01792070253238418,
            "ave_precision_score": 0.8095142760781942,
            "fpr": 0.14802631578947367,
            "logloss": 1.230634260211959,
            "mae": 0.27894212562835474,
            "precision": 0.7438330170777988,
            "recall": 0.8503253796095445
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8420506570600661,
            "auditor_fn_violation": 0.009730073944108854,
            "auditor_fp_violation": 0.018755350605833013,
            "ave_precision_score": 0.8392958830888227,
            "fpr": 0.14928649835345773,
            "logloss": 0.9749716830076068,
            "mae": 0.2800424637194492,
            "precision": 0.7504587155963303,
            "recall": 0.8296146044624746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6557855786837097,
            "auditor_fn_violation": 0.008612569928073984,
            "auditor_fp_violation": 0.01295367020655853,
            "ave_precision_score": 0.6578774780220626,
            "fpr": 0.19407894736842105,
            "logloss": 6.437291943890487,
            "mae": 0.40167578616336136,
            "precision": 0.6049107142857143,
            "recall": 0.5878524945770065
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7071690164304789,
            "auditor_fn_violation": 0.01725807852191939,
            "auditor_fp_violation": 0.00858722997494735,
            "ave_precision_score": 0.7084901474448273,
            "fpr": 0.20087815587266739,
            "logloss": 6.461005072407162,
            "mae": 0.40400277725568634,
            "precision": 0.6280487804878049,
            "recall": 0.6267748478701826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7896173557714009,
            "auditor_fn_violation": 0.005924858241047307,
            "auditor_fp_violation": 0.017786984089936595,
            "ave_precision_score": 0.7637341466649097,
            "fpr": 0.15350877192982457,
            "logloss": 1.8904947064739968,
            "mae": 0.271531156994129,
            "precision": 0.732824427480916,
            "recall": 0.8329718004338394
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.806920268393092,
            "auditor_fn_violation": 0.010378003353201687,
            "auditor_fp_violation": 0.020682881737824253,
            "ave_precision_score": 0.7875023830396648,
            "fpr": 0.14489571899012074,
            "logloss": 1.6711593437536965,
            "mae": 0.2755003377784509,
            "precision": 0.7504725897920604,
            "recall": 0.8052738336713996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7531259063287068,
            "auditor_fn_violation": 0.006757335312250264,
            "auditor_fp_violation": 0.007906406815264324,
            "ave_precision_score": 0.7543396582510624,
            "fpr": 0.09539473684210527,
            "logloss": 3.737524105787065,
            "mae": 0.27036045694838606,
            "precision": 0.7814070351758794,
            "recall": 0.6746203904555315
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8103411212044372,
            "auditor_fn_violation": 0.015011477924755578,
            "auditor_fp_violation": 0.01521278998314067,
            "ave_precision_score": 0.8113189747079236,
            "fpr": 0.08232711306256861,
            "logloss": 3.9612748756302163,
            "mae": 0.2878626434252468,
            "precision": 0.810126582278481,
            "recall": 0.6490872210953347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6425203419911966,
            "auditor_fn_violation": 0.007073676599307383,
            "auditor_fp_violation": 0.007099233671762556,
            "ave_precision_score": 0.6247847414967349,
            "fpr": 0.05921052631578947,
            "logloss": 10.087099168896806,
            "mae": 0.40340275974686013,
            "precision": 0.7488372093023256,
            "recall": 0.3492407809110629
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6758737501872839,
            "auditor_fn_violation": 0.006267770744317266,
            "auditor_fp_violation": 0.01197485280910089,
            "ave_precision_score": 0.6594615054174177,
            "fpr": 0.06256860592755215,
            "logloss": 10.717377276395322,
            "mae": 0.4212530775459496,
            "precision": 0.7574468085106383,
            "recall": 0.36105476673427994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8207399304633168,
            "auditor_fn_violation": 0.0061222742322182885,
            "auditor_fp_violation": 0.007466351577391371,
            "ave_precision_score": 0.8140472492969344,
            "fpr": 0.10526315789473684,
            "logloss": 3.062825895932639,
            "mae": 0.26722290749326116,
            "precision": 0.7782909930715936,
            "recall": 0.7310195227765727
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8231990116243479,
            "auditor_fn_violation": 0.01199671359516214,
            "auditor_fp_violation": 0.004527334702388146,
            "ave_precision_score": 0.8187258322334906,
            "fpr": 0.10647639956092206,
            "logloss": 3.2486198678511706,
            "mae": 0.29975244252372557,
            "precision": 0.7795454545454545,
            "recall": 0.6957403651115619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6127962551765619,
            "auditor_fn_violation": 0.013067511511968654,
            "auditor_fp_violation": 0.01066343797409266,
            "ave_precision_score": 0.6164655805890517,
            "fpr": 0.08333333333333333,
            "logloss": 6.697131871064754,
            "mae": 0.38323945674941756,
            "precision": 0.7285714285714285,
            "recall": 0.44251626898047725
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6797596671966672,
            "auditor_fn_violation": 0.019762960258103014,
            "auditor_fp_violation": 0.007066738795897043,
            "ave_precision_score": 0.6829632239354981,
            "fpr": 0.0889132821075741,
            "logloss": 6.491367431772331,
            "mae": 0.396780453053833,
            "precision": 0.737012987012987,
            "recall": 0.460446247464503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7882229138623114,
            "auditor_fn_violation": 0.009264280549530013,
            "auditor_fp_violation": 0.01155084218306298,
            "ave_precision_score": 0.7855234226171688,
            "fpr": 0.07346491228070176,
            "logloss": 3.99139875230031,
            "mae": 0.2964941488606633,
            "precision": 0.8112676056338028,
            "recall": 0.6247288503253796
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8080537302225703,
            "auditor_fn_violation": 0.014590657793076736,
            "auditor_fp_violation": 0.01629998056712483,
            "ave_precision_score": 0.8073870279681554,
            "fpr": 0.0801317233809001,
            "logloss": 3.9693791661253437,
            "mae": 0.3131556186123253,
            "precision": 0.8098958333333334,
            "recall": 0.6308316430020284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8044961250122163,
            "auditor_fn_violation": 0.0075874338775354915,
            "auditor_fp_violation": 0.019603123662815584,
            "ave_precision_score": 0.7942719109079115,
            "fpr": 0.12390350877192982,
            "logloss": 1.2516077687671925,
            "mae": 0.2731718510042692,
            "precision": 0.7532751091703057,
            "recall": 0.7483731019522777
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8350392807968314,
            "auditor_fn_violation": 0.019564796280751605,
            "auditor_fp_violation": 0.019818906611904483,
            "ave_precision_score": 0.8305659422323507,
            "fpr": 0.11525795828759605,
            "logloss": 1.0310031035857057,
            "mae": 0.27689294593718694,
            "precision": 0.7737068965517241,
            "recall": 0.7281947261663286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7673071811257871,
            "auditor_fn_violation": 0.0035844084180081453,
            "auditor_fp_violation": 0.020838195822149613,
            "ave_precision_score": 0.7484894052243588,
            "fpr": 0.125,
            "logloss": 2.1015613025760365,
            "mae": 0.2880070521057842,
            "precision": 0.748898678414097,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7792421232152333,
            "auditor_fn_violation": 0.010137534706528067,
            "auditor_fp_violation": 0.021126686589740495,
            "ave_precision_score": 0.7623510236058237,
            "fpr": 0.12184412733260154,
            "logloss": 2.022366163323015,
            "mae": 0.3054973369738979,
            "precision": 0.7555066079295154,
            "recall": 0.6957403651115619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6629237626110822,
            "auditor_fn_violation": 0.009578243330669403,
            "auditor_fp_violation": 0.013050919982884044,
            "ave_precision_score": 0.6640260883882207,
            "fpr": 0.12609649122807018,
            "logloss": 4.478805490254142,
            "mae": 0.410044004363092,
            "precision": 0.6875,
            "recall": 0.5488069414316703
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7059919429341073,
            "auditor_fn_violation": 0.016774914667028854,
            "auditor_fp_violation": 0.02156523931323169,
            "ave_precision_score": 0.7073805570127627,
            "fpr": 0.12294182217343579,
            "logloss": 4.350930473832473,
            "mae": 0.40626519056861743,
            "precision": 0.7128205128205128,
            "recall": 0.563894523326572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6825002142257152,
            "auditor_fn_violation": 0.013302983597823198,
            "auditor_fp_violation": 0.009615571634185246,
            "ave_precision_score": 0.6847565303833314,
            "fpr": 0.07894736842105263,
            "logloss": 6.165801581846747,
            "mae": 0.36913256517525567,
            "precision": 0.76,
            "recall": 0.4945770065075922
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7333941065273709,
            "auditor_fn_violation": 0.015516907395078858,
            "auditor_fp_violation": 0.013017400301472176,
            "ave_precision_score": 0.7348820946274077,
            "fpr": 0.07793633369923161,
            "logloss": 6.144376483309458,
            "mae": 0.37618636476986195,
            "precision": 0.7795031055900621,
            "recall": 0.5091277890466531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6653855330114187,
            "auditor_fn_violation": 0.000249743121360893,
            "auditor_fp_violation": 0.012503889991053029,
            "ave_precision_score": 0.6575956447647322,
            "fpr": 0.11074561403508772,
            "logloss": 4.257932734843613,
            "mae": 0.3737344005780269,
            "precision": 0.7130681818181818,
            "recall": 0.544468546637744
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7109476240239054,
            "auditor_fn_violation": 0.005145583726506996,
            "auditor_fp_violation": 0.01758412596704815,
            "ave_precision_score": 0.7047313201045334,
            "fpr": 0.10318331503841932,
            "logloss": 4.1121820174285215,
            "mae": 0.3771072756454472,
            "precision": 0.7424657534246575,
            "recall": 0.5496957403651116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6147183056052886,
            "auditor_fn_violation": 0.01360981086120944,
            "auditor_fp_violation": 0.010945462325436651,
            "ave_precision_score": 0.6207016210653263,
            "fpr": 0.08662280701754387,
            "logloss": 8.006419765660489,
            "mae": 0.4070069566882505,
            "precision": 0.7007575757575758,
            "recall": 0.40130151843817785
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6771971477937857,
            "auditor_fn_violation": 0.021020967530053017,
            "auditor_fp_violation": 0.009637655659956198,
            "ave_precision_score": 0.682159092890083,
            "fpr": 0.0889132821075741,
            "logloss": 7.95367406089539,
            "mae": 0.42317131978661937,
            "precision": 0.7226027397260274,
            "recall": 0.4279918864097363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8239702272286415,
            "auditor_fn_violation": 0.006124652738136017,
            "auditor_fp_violation": 0.014553429027113245,
            "ave_precision_score": 0.81722734918048,
            "fpr": 0.10197368421052631,
            "logloss": 2.5845378472328133,
            "mae": 0.24761136112440338,
            "precision": 0.7905405405405406,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8438678959301071,
            "auditor_fn_violation": 0.009514097474411242,
            "auditor_fp_violation": 0.017316267417370888,
            "ave_precision_score": 0.8421078009157595,
            "fpr": 0.11086717892425905,
            "logloss": 2.49164263638267,
            "mae": 0.271608409233741,
            "precision": 0.7818574514038877,
            "recall": 0.7342799188640974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 26311,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5707969449620156,
            "auditor_fn_violation": 0.011564295771967903,
            "auditor_fp_violation": 0.0014320029563932024,
            "ave_precision_score": 0.5863520397382886,
            "fpr": 0.12280701754385964,
            "logloss": 9.624091433864598,
            "mae": 0.4392504923777697,
            "precision": 0.6164383561643836,
            "recall": 0.39045553145336226
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6185158975075987,
            "auditor_fn_violation": 0.01692632085197152,
            "auditor_fp_violation": 0.0027941323221235444,
            "ave_precision_score": 0.6299265331251608,
            "fpr": 0.1251372118551043,
            "logloss": 9.436707703024975,
            "mae": 0.4380099537222314,
            "precision": 0.6513761467889908,
            "recall": 0.43204868154158216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7526411157845436,
            "auditor_fn_violation": 0.005893937664116905,
            "auditor_fp_violation": 0.027701598786322792,
            "ave_precision_score": 0.6884176709400067,
            "fpr": 0.15350877192982457,
            "logloss": 5.838708619502615,
            "mae": 0.2916019783679545,
            "precision": 0.7089397089397089,
            "recall": 0.7396963123644251
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7643997634727029,
            "auditor_fn_violation": 0.008810504026736556,
            "auditor_fp_violation": 0.030514866149507085,
            "ave_precision_score": 0.7075032810937409,
            "fpr": 0.14928649835345773,
            "logloss": 6.139232604147462,
            "mae": 0.3053184334538162,
            "precision": 0.7235772357723578,
            "recall": 0.7221095334685599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6340821019141445,
            "auditor_fn_violation": 0.005677493625604149,
            "auditor_fp_violation": 0.010940599836620378,
            "ave_precision_score": 0.6339459988235209,
            "fpr": 0.10307017543859649,
            "logloss": 4.533994577531456,
            "mae": 0.36514614050724253,
            "precision": 0.7134146341463414,
            "recall": 0.5075921908893709
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6812254072428063,
            "auditor_fn_violation": 0.012050151072200728,
            "auditor_fp_violation": 0.008371892709520533,
            "ave_precision_score": 0.6807684263357574,
            "fpr": 0.09001097694840834,
            "logloss": 4.678110406253161,
            "mae": 0.3807405278153223,
            "precision": 0.7413249211356467,
            "recall": 0.4766734279918864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7623793391642806,
            "auditor_fn_violation": 0.01076511778361304,
            "auditor_fp_violation": 0.010101820515812812,
            "ave_precision_score": 0.7611005592654612,
            "fpr": 0.047149122807017545,
            "logloss": 5.1729952244284965,
            "mae": 0.34169751656166203,
            "precision": 0.8237704918032787,
            "recall": 0.4360086767895879
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7892132737775012,
            "auditor_fn_violation": 0.018293429639541982,
            "auditor_fp_violation": 0.00849269166329655,
            "ave_precision_score": 0.7886982085276207,
            "fpr": 0.048298572996706916,
            "logloss": 5.273945640000755,
            "mae": 0.36372701145798275,
            "precision": 0.8314176245210728,
            "recall": 0.44016227180527384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8268305420967668,
            "auditor_fn_violation": 0.01130266012101838,
            "auditor_fp_violation": 0.025445403975570855,
            "ave_precision_score": 0.8210355870015913,
            "fpr": 0.12938596491228072,
            "logloss": 0.9344620149116756,
            "mae": 0.27252514459406374,
            "precision": 0.7556935817805382,
            "recall": 0.7917570498915402
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8500803853774312,
            "auditor_fn_violation": 0.023327685288885226,
            "auditor_fp_violation": 0.022053687256760813,
            "ave_precision_score": 0.8482994483250785,
            "fpr": 0.1251372118551043,
            "logloss": 0.82858475478553,
            "mae": 0.28245254509624057,
            "precision": 0.7706237424547284,
            "recall": 0.7768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7531438112942512,
            "auditor_fn_violation": 0.006757335312250264,
            "auditor_fp_violation": 0.007906406815264324,
            "ave_precision_score": 0.7543574892382543,
            "fpr": 0.09539473684210527,
            "logloss": 3.7375995645052944,
            "mae": 0.27036329481879584,
            "precision": 0.7814070351758794,
            "recall": 0.6746203904555315
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8103535645041473,
            "auditor_fn_violation": 0.015011477924755578,
            "auditor_fp_violation": 0.01521278998314067,
            "ave_precision_score": 0.8113314051025236,
            "fpr": 0.08232711306256861,
            "logloss": 3.9613326054814015,
            "mae": 0.28786249991170315,
            "precision": 0.810126582278481,
            "recall": 0.6490872210953347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6502886854459777,
            "auditor_fn_violation": 0.007596947901206393,
            "auditor_fp_violation": 0.010702337884622867,
            "ave_precision_score": 0.6528834443914813,
            "fpr": 0.07017543859649122,
            "logloss": 6.6222258087770065,
            "mae": 0.3831176551321887,
            "precision": 0.7593984962406015,
            "recall": 0.43817787418655096
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.705858795152284,
            "auditor_fn_violation": 0.01644538355862426,
            "auditor_fp_violation": 0.007636594730014344,
            "ave_precision_score": 0.7080089482598473,
            "fpr": 0.07464324917672886,
            "logloss": 6.521123041458325,
            "mae": 0.3952044343390118,
            "precision": 0.7694915254237288,
            "recall": 0.460446247464503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6936262598893577,
            "auditor_fn_violation": 0.011385907828138676,
            "auditor_fp_violation": 0.006965515229314973,
            "ave_precision_score": 0.6942738314992873,
            "fpr": 0.07675438596491228,
            "logloss": 5.473221965930064,
            "mae": 0.36216544293098507,
            "precision": 0.7643097643097643,
            "recall": 0.4924078091106291
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7190619744139171,
            "auditor_fn_violation": 0.02009917105113745,
            "auditor_fp_violation": 0.011854053855324877,
            "ave_precision_score": 0.7195184518279807,
            "fpr": 0.0867178924259056,
            "logloss": 5.469491153888778,
            "mae": 0.3731221733515401,
            "precision": 0.7634730538922155,
            "recall": 0.5172413793103449
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8180784625430366,
            "auditor_fn_violation": 0.0081535182859535,
            "auditor_fp_violation": 0.023626833158283737,
            "ave_precision_score": 0.8076117221682294,
            "fpr": 0.12609649122807018,
            "logloss": 1.1451077631238773,
            "mae": 0.27577732277907735,
            "precision": 0.7584033613445378,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.848580046229119,
            "auditor_fn_violation": 0.022127568617060365,
            "auditor_fp_violation": 0.020761663664199917,
            "ave_precision_score": 0.8458437953113122,
            "fpr": 0.12294182217343579,
            "logloss": 0.8337449045902307,
            "mae": 0.2811982209623498,
            "precision": 0.7723577235772358,
            "recall": 0.77079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6718811461064892,
            "auditor_fn_violation": 0.009085892605700809,
            "auditor_fp_violation": 0.03253248142529273,
            "ave_precision_score": 0.6490702518704823,
            "fpr": 0.12390350877192982,
            "logloss": 4.515996203820164,
            "mae": 0.3230816129131978,
            "precision": 0.7290167865707434,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6931456692266518,
            "auditor_fn_violation": 0.01146011226323302,
            "auditor_fp_violation": 0.035357328557397885,
            "ave_precision_score": 0.6750376732149939,
            "fpr": 0.10867178924259056,
            "logloss": 4.596768307096711,
            "mae": 0.33511659627025325,
            "precision": 0.7567567567567568,
            "recall": 0.6247464503042597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 26311,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6363008620387249,
            "auditor_fn_violation": 0.007939452753358457,
            "auditor_fp_violation": 0.00749309526588089,
            "ave_precision_score": 0.6391845639662941,
            "fpr": 0.05482456140350877,
            "logloss": 7.330598540384822,
            "mae": 0.39084694634409706,
            "precision": 0.7652582159624414,
            "recall": 0.35357917570498915
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6919108087904298,
            "auditor_fn_violation": 0.013764603460521956,
            "auditor_fp_violation": 0.011814662892137041,
            "ave_precision_score": 0.694442107473677,
            "fpr": 0.06037321624588365,
            "logloss": 7.211073654009473,
            "mae": 0.4159612387292798,
            "precision": 0.7619047619047619,
            "recall": 0.35699797160243407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8135146719508313,
            "auditor_fn_violation": 0.002066921642501048,
            "auditor_fp_violation": 0.018825125452211464,
            "ave_precision_score": 0.7919905126128822,
            "fpr": 0.18421052631578946,
            "logloss": 1.7206568874297437,
            "mae": 0.2645301795845099,
            "precision": 0.7108433734939759,
            "recall": 0.89587852494577
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8328504774475427,
            "auditor_fn_violation": 0.011275307655141243,
            "auditor_fp_violation": 0.011896070882725223,
            "ave_precision_score": 0.8195482311057953,
            "fpr": 0.1756311745334797,
            "logloss": 1.4252646377745672,
            "mae": 0.26669222168314133,
            "precision": 0.727427597955707,
            "recall": 0.8661257606490872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8150821678603576,
            "auditor_fn_violation": 0.0028684781367736057,
            "auditor_fp_violation": 0.01866466332127436,
            "ave_precision_score": 0.7935076366725946,
            "fpr": 0.18311403508771928,
            "logloss": 1.7212384154386196,
            "mae": 0.26225560626593697,
            "precision": 0.7115716753022453,
            "recall": 0.8937093275488069
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8332609904949013,
            "auditor_fn_violation": 0.010850034400375845,
            "auditor_fp_violation": 0.014837262800750001,
            "ave_precision_score": 0.8191811718761949,
            "fpr": 0.1756311745334797,
            "logloss": 1.4489870938398297,
            "mae": 0.2651129672942738,
            "precision": 0.7278911564625851,
            "recall": 0.8681541582150102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8212879656414954,
            "auditor_fn_violation": 0.012439585949689845,
            "auditor_fp_violation": 0.024701443186680678,
            "ave_precision_score": 0.8209295955790131,
            "fpr": 0.12609649122807018,
            "logloss": 0.6528765579637453,
            "mae": 0.2767280650976122,
            "precision": 0.7578947368421053,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8528165636649474,
            "auditor_fn_violation": 0.02237917007145036,
            "auditor_fp_violation": 0.022505370301314616,
            "ave_precision_score": 0.8531047587175171,
            "fpr": 0.12403951701427003,
            "logloss": 0.6728822529766264,
            "mae": 0.2843728137255785,
            "precision": 0.77079107505071,
            "recall": 0.77079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.5832356914764167,
            "auditor_fn_violation": 0.0078585835521559,
            "auditor_fp_violation": 0.009367584704555178,
            "ave_precision_score": 0.5953763311526464,
            "fpr": 0.049342105263157895,
            "logloss": 8.699294053243083,
            "mae": 0.41812412587080827,
            "precision": 0.7513812154696132,
            "recall": 0.2950108459869848
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6277341926305521,
            "auditor_fn_violation": 0.013484056706069402,
            "auditor_fp_violation": 0.008004243719767436,
            "ave_precision_score": 0.6373953766229027,
            "fpr": 0.054884742041712405,
            "logloss": 8.543765444544501,
            "mae": 0.44054403439792683,
            "precision": 0.75,
            "recall": 0.30425963488843816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6705411049634029,
            "auditor_fn_violation": 0.008762415800890521,
            "auditor_fp_violation": 0.017310460185941574,
            "ave_precision_score": 0.6703256082189277,
            "fpr": 0.11951754385964912,
            "logloss": 4.189289963777975,
            "mae": 0.3014136150006438,
            "precision": 0.7398568019093079,
            "recall": 0.6724511930585684
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7340248324172753,
            "auditor_fn_violation": 0.019097218356663993,
            "auditor_fp_violation": 0.014207007389744692,
            "ave_precision_score": 0.7335100809991686,
            "fpr": 0.10208562019758508,
            "logloss": 4.2187232755034145,
            "mae": 0.3115200577030767,
            "precision": 0.7726161369193154,
            "recall": 0.640973630831643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7114886233986648,
            "auditor_fn_violation": 0.0029921604444951948,
            "auditor_fp_violation": 0.015832263585793756,
            "ave_precision_score": 0.7018465954499339,
            "fpr": 0.08881578947368421,
            "logloss": 4.300702838251598,
            "mae": 0.33349934216574406,
            "precision": 0.7552870090634441,
            "recall": 0.5422993492407809
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7710386495164605,
            "auditor_fn_violation": 0.013762376898978685,
            "auditor_fp_violation": 0.008001617655554918,
            "ave_precision_score": 0.7648055796035856,
            "fpr": 0.0845225027442371,
            "logloss": 3.876007745193124,
            "mae": 0.33793296901083814,
            "precision": 0.7741935483870968,
            "recall": 0.5354969574036511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.815022768469105,
            "auditor_fn_violation": 0.009081135593865355,
            "auditor_fp_violation": 0.012958532695374801,
            "ave_precision_score": 0.8026194716458603,
            "fpr": 0.08881578947368421,
            "logloss": 2.7499577809940043,
            "mae": 0.2577123383584428,
            "precision": 0.800982800982801,
            "recall": 0.7071583514099783
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8481652218185214,
            "auditor_fn_violation": 0.012036791702941061,
            "auditor_fp_violation": 0.01478999364492461,
            "ave_precision_score": 0.8425864279033027,
            "fpr": 0.08232711306256861,
            "logloss": 2.552361631397384,
            "mae": 0.26219960254621466,
            "precision": 0.8214285714285714,
            "recall": 0.6997971602434077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5484781833937,
            "auditor_fn_violation": 0.011963884766145303,
            "auditor_fp_violation": 0.0083026996537908,
            "ave_precision_score": 0.5691977245727284,
            "fpr": 0.06140350877192982,
            "logloss": 10.02936947290969,
            "mae": 0.43999258337528135,
            "precision": 0.7128205128205128,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.596012301444815,
            "auditor_fn_violation": 0.021203545576601514,
            "auditor_fp_violation": 0.006722724384056639,
            "ave_precision_score": 0.6142166031234197,
            "fpr": 0.06586169045005488,
            "logloss": 9.878349253891834,
            "mae": 0.45229094306701256,
            "precision": 0.7333333333333333,
            "recall": 0.33468559837728196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.751216452282091,
            "auditor_fn_violation": 0.009349906762568024,
            "auditor_fp_violation": 0.028593865484109384,
            "ave_precision_score": 0.6894428726295453,
            "fpr": 0.16776315789473684,
            "logloss": 5.9589719434065636,
            "mae": 0.28002107152479266,
            "precision": 0.7029126213592233,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7638396288385594,
            "auditor_fn_violation": 0.006839997060938761,
            "auditor_fp_violation": 0.025861480364917887,
            "ave_precision_score": 0.7120558850566225,
            "fpr": 0.16794731064763996,
            "logloss": 6.131297437367659,
            "mae": 0.2977027478092431,
            "precision": 0.7102272727272727,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8065813030087188,
            "auditor_fn_violation": 0.015893176542223244,
            "auditor_fp_violation": 0.016218831446687676,
            "ave_precision_score": 0.8066671946970698,
            "fpr": 0.07785087719298246,
            "logloss": 2.5908607490978697,
            "mae": 0.26545039931247527,
            "precision": 0.8070652173913043,
            "recall": 0.6442516268980477
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8463021257350638,
            "auditor_fn_violation": 0.018282296831825584,
            "auditor_fp_violation": 0.006528395632330001,
            "ave_precision_score": 0.8464991025313411,
            "fpr": 0.07025246981339188,
            "logloss": 2.67644113927661,
            "mae": 0.2858332370660144,
            "precision": 0.8265582655826558,
            "recall": 0.6186612576064908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6367681718638741,
            "auditor_fn_violation": 0.012617973893519048,
            "auditor_fp_violation": 0.007077352472089316,
            "ave_precision_score": 0.6326892805517124,
            "fpr": 0.1337719298245614,
            "logloss": 4.104884550654185,
            "mae": 0.3106846334455609,
            "precision": 0.7175925925925926,
            "recall": 0.6724511930585684
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.637816887787096,
            "auditor_fn_violation": 0.014276712615475043,
            "auditor_fp_violation": 0.008240589498894429,
            "ave_precision_score": 0.6284541197898695,
            "fpr": 0.14270032930845225,
            "logloss": 4.798084001173457,
            "mae": 0.33345936616184924,
            "precision": 0.7161572052401747,
            "recall": 0.665314401622718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7941852068869109,
            "auditor_fn_violation": 0.02066445941317502,
            "auditor_fp_violation": 0.011570292138328084,
            "ave_precision_score": 0.7946047967084624,
            "fpr": 0.0625,
            "logloss": 3.770147370220696,
            "mae": 0.28810277309754895,
            "precision": 0.8213166144200627,
            "recall": 0.5683297180043384
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8273097251305465,
            "auditor_fn_violation": 0.016267258635162304,
            "auditor_fp_violation": 0.011257937279082352,
            "ave_precision_score": 0.8275542272287165,
            "fpr": 0.05598243688254665,
            "logloss": 3.9468597713751663,
            "mae": 0.31585365199228554,
            "precision": 0.8370607028753994,
            "recall": 0.5314401622718052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7370732787374115,
            "auditor_fn_violation": 0.008876584084941219,
            "auditor_fp_violation": 0.011460886139961882,
            "ave_precision_score": 0.7368223855743634,
            "fpr": 0.06907894736842106,
            "logloss": 5.033337953537522,
            "mae": 0.33988347799229723,
            "precision": 0.7947882736156352,
            "recall": 0.5292841648590022
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7508913553396555,
            "auditor_fn_violation": 0.01511835287883276,
            "auditor_fp_violation": 0.01736353657319629,
            "ave_precision_score": 0.7507159488252233,
            "fpr": 0.08342480790340286,
            "logloss": 5.126048836525463,
            "mae": 0.35717366235896025,
            "precision": 0.7784256559766763,
            "recall": 0.5415821501014199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6707047157908099,
            "auditor_fn_violation": 0.01407124100924763,
            "auditor_fp_violation": 0.010257420157933636,
            "ave_precision_score": 0.6720215951370111,
            "fpr": 0.0668859649122807,
            "logloss": 6.39508012853069,
            "mae": 0.3677154944375909,
            "precision": 0.76171875,
            "recall": 0.4229934924078091
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7115573084023601,
            "auditor_fn_violation": 0.013711165983483396,
            "auditor_fp_violation": 0.013891879684242043,
            "ave_precision_score": 0.7129164718470553,
            "fpr": 0.07135016465422613,
            "logloss": 6.303221929356282,
            "mae": 0.385638493874198,
            "precision": 0.7670250896057348,
            "recall": 0.4340770791075051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 26311,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5920598888066042,
            "auditor_fn_violation": 0.004954427826616439,
            "auditor_fp_violation": 0.0037878787878787884,
            "ave_precision_score": 0.595677657778115,
            "fpr": 0.013157894736842105,
            "logloss": 10.670125571679387,
            "mae": 0.46200371228678094,
            "precision": 0.8260869565217391,
            "recall": 0.12364425162689804
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6154123196511067,
            "auditor_fn_violation": 0.008794918095933626,
            "auditor_fp_violation": 0.0025131434513836737,
            "ave_precision_score": 0.6183179223567723,
            "fpr": 0.012074643249176729,
            "logloss": 11.08206294039689,
            "mae": 0.49376878268576857,
            "precision": 0.8533333333333334,
            "recall": 0.12981744421906694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6614420632404632,
            "auditor_fn_violation": 0.009992103360353163,
            "auditor_fp_violation": 0.011507079783716498,
            "ave_precision_score": 0.6637536175961916,
            "fpr": 0.06798245614035088,
            "logloss": 6.3236600646919445,
            "mae": 0.3780710255909428,
            "precision": 0.7686567164179104,
            "recall": 0.44685466377440347
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7125680084564572,
            "auditor_fn_violation": 0.013742337845089206,
            "auditor_fp_violation": 0.008954878964700446,
            "ave_precision_score": 0.7144249047145823,
            "fpr": 0.07683863885839737,
            "logloss": 6.193058099724738,
            "mae": 0.3885061565703658,
            "precision": 0.7635135135135135,
            "recall": 0.45841784989858014
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6936273508255996,
            "auditor_fn_violation": 0.01771986908703429,
            "auditor_fp_violation": 0.016328237445053875,
            "ave_precision_score": 0.6837466985356778,
            "fpr": 0.11732456140350878,
            "logloss": 4.545073979669235,
            "mae": 0.29266882181847464,
            "precision": 0.7409200968523002,
            "recall": 0.6637744034707158
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.703406975322723,
            "auditor_fn_violation": 0.011800776179353987,
            "auditor_fp_violation": 0.01721647697729505,
            "ave_precision_score": 0.6923950606970481,
            "fpr": 0.1207464324917673,
            "logloss": 4.8517341729161485,
            "mae": 0.31618086778574805,
            "precision": 0.7471264367816092,
            "recall": 0.6592292089249493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.749137994549989,
            "auditor_fn_violation": 0.006450508048864029,
            "auditor_fp_violation": 0.031598883572567786,
            "ave_precision_score": 0.6865981054069765,
            "fpr": 0.13486842105263158,
            "logloss": 5.8486815996242205,
            "mae": 0.29950893257889694,
            "precision": 0.7242152466367713,
            "recall": 0.7006507592190889
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7600725442432559,
            "auditor_fn_violation": 0.017752375184526294,
            "auditor_fp_violation": 0.03627382496756811,
            "ave_precision_score": 0.7079886315891789,
            "fpr": 0.12403951701427003,
            "logloss": 6.0783138160638694,
            "mae": 0.3140685909333532,
            "precision": 0.7460674157303371,
            "recall": 0.6734279918864098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6309533590153353,
            "auditor_fn_violation": 0.014485101038931407,
            "auditor_fp_violation": 0.013298906912514105,
            "ave_precision_score": 0.6356145945338869,
            "fpr": 0.09320175438596491,
            "logloss": 7.656305847794676,
            "mae": 0.401690194064258,
            "precision": 0.6985815602836879,
            "recall": 0.42733188720173537
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6843662569426439,
            "auditor_fn_violation": 0.022824482380105225,
            "auditor_fp_violation": 0.013324649814337262,
            "ave_precision_score": 0.6874137703626546,
            "fpr": 0.09989023051591657,
            "logloss": 7.626574389011912,
            "mae": 0.41720140036253406,
            "precision": 0.7083333333333334,
            "recall": 0.4482758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.74956780816173,
            "auditor_fn_violation": 0.011326445180195611,
            "auditor_fp_violation": 0.008628486404481274,
            "ave_precision_score": 0.7480161457466383,
            "fpr": 0.07894736842105263,
            "logloss": 3.9790607907186843,
            "mae": 0.3192005915151565,
            "precision": 0.7857142857142857,
            "recall": 0.5726681127982647
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7685682525083204,
            "auditor_fn_violation": 0.01475542334727904,
            "auditor_fp_violation": 0.017636647251298588,
            "ave_precision_score": 0.7653785162761695,
            "fpr": 0.08562019758507135,
            "logloss": 3.9198041467975604,
            "mae": 0.3282911880028197,
            "precision": 0.7891891891891892,
            "recall": 0.592292089249493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.754865052067889,
            "auditor_fn_violation": 0.006885774631807285,
            "auditor_fp_violation": 0.012110028396934688,
            "ave_precision_score": 0.7564965912806232,
            "fpr": 0.09429824561403509,
            "logloss": 2.1659119923318157,
            "mae": 0.2785986514242143,
            "precision": 0.7922705314009661,
            "recall": 0.7114967462039046
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7761117419723045,
            "auditor_fn_violation": 0.010320112753076562,
            "auditor_fp_violation": 0.014146607912856688,
            "ave_precision_score": 0.7774631915363011,
            "fpr": 0.0889132821075741,
            "logloss": 2.3434287239142466,
            "mae": 0.29814977038829277,
            "precision": 0.8071428571428572,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7733266763570675,
            "auditor_fn_violation": 0.019061346424629904,
            "auditor_fp_violation": 0.01948399268681682,
            "ave_precision_score": 0.773803781538822,
            "fpr": 0.08114035087719298,
            "logloss": 2.857808597601264,
            "mae": 0.29627736448177194,
            "precision": 0.7885714285714286,
            "recall": 0.5986984815618221
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8050940977289819,
            "auditor_fn_violation": 0.022051865524589036,
            "auditor_fp_violation": 0.012452796495779917,
            "ave_precision_score": 0.8064126910968027,
            "fpr": 0.08122941822173436,
            "logloss": 2.75231240005324,
            "mae": 0.3076861632685115,
            "precision": 0.7978142076502732,
            "recall": 0.592292089249493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8023948925697363,
            "auditor_fn_violation": 0.0066788446169654065,
            "auditor_fp_violation": 0.0072329521142101404,
            "ave_precision_score": 0.7922271937488303,
            "fpr": 0.08223684210526316,
            "logloss": 3.620441736552702,
            "mae": 0.26924063945804466,
            "precision": 0.7983870967741935,
            "recall": 0.6442516268980477
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8223776856529312,
            "auditor_fn_violation": 0.013662181629531336,
            "auditor_fp_violation": 0.018547891533043766,
            "ave_precision_score": 0.8151560835491726,
            "fpr": 0.07793633369923161,
            "logloss": 3.4305160461578814,
            "mae": 0.2921178616568541,
            "precision": 0.8131578947368421,
            "recall": 0.6267748478701826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6809758037861603,
            "auditor_fn_violation": 0.014580241275640298,
            "auditor_fp_violation": 0.013191932158556036,
            "ave_precision_score": 0.6823101375833193,
            "fpr": 0.07346491228070176,
            "logloss": 6.786845340381425,
            "mae": 0.3703939530643512,
            "precision": 0.7471698113207547,
            "recall": 0.42950108459869846
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7201490190297841,
            "auditor_fn_violation": 0.0176388205458193,
            "auditor_fp_violation": 0.011919705460637926,
            "ave_precision_score": 0.7215249306556163,
            "fpr": 0.07793633369923161,
            "logloss": 6.632050281985672,
            "mae": 0.38886699585184903,
            "precision": 0.7508771929824561,
            "recall": 0.4340770791075051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8394505685346532,
            "auditor_fn_violation": 0.0030777866575332066,
            "auditor_fp_violation": 0.014013692768506635,
            "ave_precision_score": 0.8217036703554452,
            "fpr": 0.1600877192982456,
            "logloss": 1.5179996808900513,
            "mae": 0.23618936434848972,
            "precision": 0.7359855334538878,
            "recall": 0.8828633405639913
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8529312502521297,
            "auditor_fn_violation": 0.009571988074536377,
            "auditor_fp_violation": 0.01274166355915736,
            "ave_precision_score": 0.8428131505024365,
            "fpr": 0.15367727771679474,
            "logloss": 1.3129161121338313,
            "mae": 0.2482268555738384,
            "precision": 0.75,
            "recall": 0.8519269776876268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7180457206474178,
            "auditor_fn_violation": 0.00908351409978309,
            "auditor_fp_violation": 0.009797914964795578,
            "ave_precision_score": 0.696511757064407,
            "fpr": 0.1074561403508772,
            "logloss": 3.451642254758633,
            "mae": 0.28958494986420863,
            "precision": 0.7556109725685786,
            "recall": 0.6572668112798264
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7155434999676451,
            "auditor_fn_violation": 0.01545233711032391,
            "auditor_fp_violation": 0.0119879831301635,
            "ave_precision_score": 0.6956998808497792,
            "fpr": 0.11306256860592755,
            "logloss": 3.639032409526192,
            "mae": 0.3229850738391854,
            "precision": 0.7463054187192119,
            "recall": 0.6146044624746451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 26311,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.58417896891216,
            "auditor_fn_violation": 0.026444228793241244,
            "auditor_fp_violation": 0.08781897926634769,
            "ave_precision_score": 0.5871164803953485,
            "fpr": 0.2631578947368421,
            "logloss": 6.134805050340386,
            "mae": 0.4833770642490179,
            "precision": 0.5428571428571428,
            "recall": 0.6182212581344902
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6244716295666903,
            "auditor_fn_violation": 0.01668362564375461,
            "auditor_fp_violation": 0.07711174953649967,
            "ave_precision_score": 0.6266032550404441,
            "fpr": 0.24588364434687157,
            "logloss": 5.941672800118503,
            "mae": 0.47281362731163573,
            "precision": 0.5813084112149532,
            "recall": 0.6308316430020284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.642467092709771,
            "auditor_fn_violation": 0.010562944780606617,
            "auditor_fp_violation": 0.008156824989302527,
            "ave_precision_score": 0.645650373873714,
            "fpr": 0.07785087719298246,
            "logloss": 5.980711978042426,
            "mae": 0.38869314603171046,
            "precision": 0.7389705882352942,
            "recall": 0.4360086767895879
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7034126325964873,
            "auditor_fn_violation": 0.019689483727174953,
            "auditor_fp_violation": 0.007662855372139565,
            "ave_precision_score": 0.7055205234676287,
            "fpr": 0.07464324917672886,
            "logloss": 5.9977286622265575,
            "mae": 0.39720596542641334,
            "precision": 0.7687074829931972,
            "recall": 0.45841784989858014
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6547718055567694,
            "auditor_fn_violation": 0.007856205046238164,
            "auditor_fp_violation": 0.010716925351071696,
            "ave_precision_score": 0.6572907716422425,
            "fpr": 0.07456140350877193,
            "logloss": 6.5887333205129455,
            "mae": 0.3820512690844237,
            "precision": 0.7481481481481481,
            "recall": 0.43817787418655096
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7083718903980789,
            "auditor_fn_violation": 0.014668587447091342,
            "auditor_fp_violation": 0.006376083908003722,
            "ave_precision_score": 0.7103015826218514,
            "fpr": 0.07683863885839737,
            "logloss": 6.494311863869658,
            "mae": 0.3950832375678811,
            "precision": 0.7643097643097643,
            "recall": 0.460446247464503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 26311,
        "test": {
            "accuracy": 0.4298245614035088,
            "auc_prc": 0.6382412703652526,
            "auditor_fn_violation": 0.0005684629143357299,
            "auditor_fp_violation": 0.009793052475979322,
            "ave_precision_score": 0.6441550166095267,
            "fpr": 0.3991228070175439,
            "logloss": 6.57666633862877,
            "mae": 0.5336729632708644,
            "precision": 0.45590433482810166,
            "recall": 0.6616052060737527
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.6841216460516552,
            "auditor_fn_violation": 0.01948018694210718,
            "auditor_fp_violation": 0.007983235206067264,
            "ave_precision_score": 0.690094463894972,
            "fpr": 0.36882546652030734,
            "logloss": 6.35763373906319,
            "mae": 0.5122908413495229,
            "precision": 0.5036927621861153,
            "recall": 0.691683569979716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8037178075904163,
            "auditor_fn_violation": 0.024489096928873157,
            "auditor_fp_violation": 0.01636713735558408,
            "ave_precision_score": 0.8002291663195475,
            "fpr": 0.1206140350877193,
            "logloss": 1.9173541118952355,
            "mae": 0.26245795332315836,
            "precision": 0.7587719298245614,
            "recall": 0.7505422993492408
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8291089518199302,
            "auditor_fn_violation": 0.03030795572705028,
            "auditor_fp_violation": 0.022205998981087088,
            "ave_precision_score": 0.8259039596286797,
            "fpr": 0.12294182217343579,
            "logloss": 1.9576485216156885,
            "mae": 0.27815918297785686,
            "precision": 0.7637130801687764,
            "recall": 0.7342799188640974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6412631789419345,
            "auditor_fn_violation": 0.008239144498991534,
            "auditor_fp_violation": 0.007908838059672465,
            "ave_precision_score": 0.6239134957837515,
            "fpr": 0.0581140350877193,
            "logloss": 9.943730980619915,
            "mae": 0.40393701950027294,
            "precision": 0.7439613526570048,
            "recall": 0.33405639913232105
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6768276436950169,
            "auditor_fn_violation": 0.005553044488926199,
            "auditor_fp_violation": 0.011675481488873369,
            "ave_precision_score": 0.6602568341488689,
            "fpr": 0.06256860592755215,
            "logloss": 10.535271945338044,
            "mae": 0.4230643813046742,
            "precision": 0.7532467532467533,
            "recall": 0.35294117647058826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.682587386845732,
            "auditor_fn_violation": 0.010791281348707991,
            "auditor_fp_violation": 0.007456626599758823,
            "ave_precision_score": 0.6836836625835528,
            "fpr": 0.07785087719298246,
            "logloss": 6.615498464759373,
            "mae": 0.3706315874814189,
            "precision": 0.7526132404181185,
            "recall": 0.4685466377440347
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7274445612239355,
            "auditor_fn_violation": 0.01782362515391107,
            "auditor_fp_violation": 0.012045756542838987,
            "ave_precision_score": 0.7287842873613611,
            "fpr": 0.0845225027442371,
            "logloss": 6.464055563388611,
            "mae": 0.37783504932700174,
            "precision": 0.7638036809815951,
            "recall": 0.5050709939148073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7539476914148255,
            "auditor_fn_violation": 0.007049891540130155,
            "auditor_fp_violation": 0.027701598786322792,
            "ave_precision_score": 0.6880834380338535,
            "fpr": 0.15350877192982457,
            "logloss": 5.894908371417811,
            "mae": 0.29202060347221503,
            "precision": 0.7077244258872651,
            "recall": 0.735357917570499
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7649816502683879,
            "auditor_fn_violation": 0.010021753506277787,
            "auditor_fp_violation": 0.031630943439829,
            "ave_precision_score": 0.7071149665926134,
            "fpr": 0.14818880351262348,
            "logloss": 6.182585884744394,
            "mae": 0.30562917363291336,
            "precision": 0.7239263803680982,
            "recall": 0.718052738336714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 26311,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6405750313120161,
            "auditor_fn_violation": 0.010593865357537013,
            "auditor_fp_violation": 0.016425487221379396,
            "ave_precision_score": 0.637060808777368,
            "fpr": 0.09758771929824561,
            "logloss": 5.342308731795047,
            "mae": 0.3784292273220763,
            "precision": 0.7062706270627063,
            "recall": 0.4642082429501085
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6584258285548727,
            "auditor_fn_violation": 0.01292518975870754,
            "auditor_fp_violation": 0.015194407533653018,
            "ave_precision_score": 0.6534680321353087,
            "fpr": 0.10098792535675083,
            "logloss": 5.919220358911971,
            "mae": 0.4004721417149822,
            "precision": 0.7151702786377709,
            "recall": 0.4685598377281947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6482298767429187,
            "auditor_fn_violation": 0.00783241998706093,
            "auditor_fp_violation": 0.009117166530516982,
            "ave_precision_score": 0.651458204031891,
            "fpr": 0.07894736842105263,
            "logloss": 6.411330901347531,
            "mae": 0.3779886423878705,
            "precision": 0.7381818181818182,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6966234494275542,
            "auditor_fn_violation": 0.01832014837806124,
            "auditor_fp_violation": 0.013038408815172351,
            "ave_precision_score": 0.6988803905472544,
            "fpr": 0.07793633369923161,
            "logloss": 6.473385109527895,
            "mae": 0.3905506432418409,
            "precision": 0.7609427609427609,
            "recall": 0.45841784989858014
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.622228883979032,
            "auditor_fn_violation": 0.01576235871674849,
            "auditor_fp_violation": 0.03380159100634069,
            "ave_precision_score": 0.6172142892111275,
            "fpr": 0.21052631578947367,
            "logloss": 3.1512327345488496,
            "mae": 0.33330252253464665,
            "precision": 0.6583629893238434,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6758509887357581,
            "auditor_fn_violation": 0.025621043678457793,
            "auditor_fp_violation": 0.018004296241051695,
            "ave_precision_score": 0.6734107872916044,
            "fpr": 0.1734357848518112,
            "logloss": 2.8516564229753754,
            "mae": 0.3207920419202621,
            "precision": 0.7068645640074211,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6404202388386033,
            "auditor_fn_violation": 0.010691384100163643,
            "auditor_fp_violation": 0.005990586221651693,
            "ave_precision_score": 0.6436978081727509,
            "fpr": 0.0712719298245614,
            "logloss": 6.219822001237068,
            "mae": 0.3824513117942161,
            "precision": 0.7509578544061303,
            "recall": 0.42516268980477223
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.691599497320427,
            "auditor_fn_violation": 0.016895148990365674,
            "auditor_fp_violation": 0.013230111502686465,
            "ave_precision_score": 0.6939108030116172,
            "fpr": 0.07244785949506037,
            "logloss": 6.280122181401615,
            "mae": 0.3965104368328307,
            "precision": 0.7676056338028169,
            "recall": 0.4421906693711968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.655110892229213,
            "auditor_fn_violation": 0.001967024393956694,
            "auditor_fp_violation": 0.0032724549733535667,
            "ave_precision_score": 0.6556098787117373,
            "fpr": 0.10307017543859649,
            "logloss": 6.56745930584899,
            "mae": 0.36000544835154197,
            "precision": 0.7116564417177914,
            "recall": 0.5032537960954447
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6983137164608606,
            "auditor_fn_violation": 0.01963604625013638,
            "auditor_fp_violation": 0.007142894658060184,
            "ave_precision_score": 0.6995090879535851,
            "fpr": 0.09879253567508232,
            "logloss": 6.463069741255918,
            "mae": 0.3702707557370582,
            "precision": 0.7352941176470589,
            "recall": 0.5070993914807302
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7629225267463758,
            "auditor_fn_violation": 0.0033536933439890426,
            "auditor_fp_violation": 0.00921198506243436,
            "ave_precision_score": 0.7642547224677134,
            "fpr": 0.09758771929824561,
            "logloss": 3.1974887992405177,
            "mae": 0.2707805980949846,
            "precision": 0.7797029702970297,
            "recall": 0.6832971800433839
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8232353143170821,
            "auditor_fn_violation": 0.013867025291512576,
            "auditor_fp_violation": 0.008093529902993186,
            "ave_precision_score": 0.8232435475620379,
            "fpr": 0.08562019758507135,
            "logloss": 3.4106164105590615,
            "mae": 0.28578691565927483,
            "precision": 0.805,
            "recall": 0.6531440162271805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7997012426799233,
            "auditor_fn_violation": 0.005641816036838303,
            "auditor_fp_violation": 0.017718909246508742,
            "ave_precision_score": 0.7895209681879123,
            "fpr": 0.15789473684210525,
            "logloss": 1.7860228526753064,
            "mae": 0.277072027846731,
            "precision": 0.7148514851485148,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8177646919085966,
            "auditor_fn_violation": 0.013141166228405138,
            "auditor_fp_violation": 0.021260615864579127,
            "ave_precision_score": 0.8096989363889767,
            "fpr": 0.16136114160263446,
            "logloss": 1.489864780278126,
            "mae": 0.28830123335906316,
            "precision": 0.7210626185958254,
            "recall": 0.77079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.6761923090471329,
            "auditor_fn_violation": 0.010893557103170071,
            "auditor_fp_violation": 0.0045853269537480135,
            "ave_precision_score": 0.6505529790903755,
            "fpr": 0.16447368421052633,
            "logloss": 4.661170780455192,
            "mae": 0.29336193162577673,
            "precision": 0.7041420118343196,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6662310549869352,
            "auditor_fn_violation": 0.019629366565506557,
            "auditor_fp_violation": 0.014183372811831999,
            "ave_precision_score": 0.6397533602265852,
            "fpr": 0.17892425905598244,
            "logloss": 5.3037658525007,
            "mae": 0.31543023329116304,
            "precision": 0.6981481481481482,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6584206542704746,
            "auditor_fn_violation": 0.008717224188453788,
            "auditor_fp_violation": 0.017903683821527214,
            "ave_precision_score": 0.6533390670976505,
            "fpr": 0.12938596491228072,
            "logloss": 3.5913374294782434,
            "mae": 0.31011744203907865,
            "precision": 0.7268518518518519,
            "recall": 0.6811279826464208
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6765510015865528,
            "auditor_fn_violation": 0.015777415095641963,
            "auditor_fp_violation": 0.01740555360059664,
            "ave_precision_score": 0.6701623590779091,
            "fpr": 0.13611416026344675,
            "logloss": 3.7965834070015196,
            "mae": 0.32651312258877596,
            "precision": 0.7292576419213974,
            "recall": 0.6774847870182555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6127052676763931,
            "auditor_fn_violation": 0.008774308330479125,
            "auditor_fp_violation": 0.012182965729178825,
            "ave_precision_score": 0.6087355666117031,
            "fpr": 0.15789473684210525,
            "logloss": 4.59324729393279,
            "mae": 0.3272446296883583,
            "precision": 0.6929637526652452,
            "recall": 0.7049891540130152
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6763083757883048,
            "auditor_fn_violation": 0.012666908619687708,
            "auditor_fp_violation": 0.008169685765156332,
            "ave_precision_score": 0.673557570208534,
            "fpr": 0.1350164654226125,
            "logloss": 4.240886111424866,
            "mae": 0.3259020154823269,
            "precision": 0.7360515021459227,
            "recall": 0.6957403651115619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6231515894077002,
            "auditor_fn_violation": 0.0014342390683868042,
            "auditor_fp_violation": 0.02105700781888202,
            "ave_precision_score": 0.6190006677021479,
            "fpr": 0.13706140350877194,
            "logloss": 4.8522262780414875,
            "mae": 0.32376743889175263,
            "precision": 0.7086247086247086,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6765872628701485,
            "auditor_fn_violation": 0.020925225383692216,
            "auditor_fp_violation": 0.017736437691374434,
            "ave_precision_score": 0.673378166993891,
            "fpr": 0.1207464324917673,
            "logloss": 4.7996611083388645,
            "mae": 0.33519496485774236,
            "precision": 0.7368421052631579,
            "recall": 0.6247464503042597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6507650677792456,
            "auditor_fn_violation": 0.0012510941127221523,
            "auditor_fp_violation": 0.006975240206947529,
            "ave_precision_score": 0.6548259122446072,
            "fpr": 0.12171052631578948,
            "logloss": 5.45363863620804,
            "mae": 0.36753346192465847,
            "precision": 0.695054945054945,
            "recall": 0.5488069414316703
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7014096828677716,
            "auditor_fn_violation": 0.017625461176559658,
            "auditor_fp_violation": 0.010220641915136114,
            "ave_precision_score": 0.7048265455910679,
            "fpr": 0.12403951701427003,
            "logloss": 5.370501279549535,
            "mae": 0.375624837735284,
            "precision": 0.7034120734908137,
            "recall": 0.5436105476673428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7444408300731866,
            "auditor_fn_violation": 0.0024950527076911416,
            "auditor_fp_violation": 0.012409071459135647,
            "ave_precision_score": 0.7061783394118537,
            "fpr": 0.14035087719298245,
            "logloss": 3.940688265135665,
            "mae": 0.28842476181817767,
            "precision": 0.7344398340248963,
            "recall": 0.7678958785249458
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7409180324964612,
            "auditor_fn_violation": 0.00967886302861355,
            "auditor_fp_violation": 0.023093608684919567,
            "ave_precision_score": 0.7055840380576506,
            "fpr": 0.14709110867178923,
            "logloss": 4.017135783362015,
            "mae": 0.3110279551011843,
            "precision": 0.7325349301397206,
            "recall": 0.744421906693712
        }
    }
]