[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8286708733643373,
            "auditor_fn_violation": 0.01570202624329419,
            "auditor_fp_violation": 0.026151828168552226,
            "ave_precision_score": 0.8292871890456415,
            "fpr": 0.12719298245614036,
            "logloss": 0.8547922095947068,
            "mae": 0.2678652698722547,
            "precision": 0.7608247422680412,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8198073092894815,
            "auditor_fn_violation": 0.017714926314314414,
            "auditor_fp_violation": 0.021065286707438194,
            "ave_precision_score": 0.8200843950737366,
            "fpr": 0.141602634467618,
            "logloss": 0.8603745910290971,
            "mae": 0.2804130231492628,
            "precision": 0.7334710743801653,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7830986947878621,
            "auditor_fn_violation": 0.008293914020588669,
            "auditor_fp_violation": 0.003719872110182005,
            "ave_precision_score": 0.7666305900749597,
            "fpr": 0.1337719298245614,
            "logloss": 0.5957232648848791,
            "mae": 0.43026843573898077,
            "precision": 0.7182448036951501,
            "recall": 0.6425619834710744
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7846012543692736,
            "auditor_fn_violation": 0.004007753929513979,
            "auditor_fp_violation": 0.0026882322632675523,
            "ave_precision_score": 0.7643407195451191,
            "fpr": 0.12843029637760703,
            "logloss": 0.585844849440168,
            "mae": 0.4234991774502753,
            "precision": 0.7247058823529412,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8305711211654774,
            "auditor_fn_violation": 0.00783628751631144,
            "auditor_fp_violation": 0.021381578947368425,
            "ave_precision_score": 0.8317931922524362,
            "fpr": 0.13048245614035087,
            "logloss": 1.0831855658468363,
            "mae": 0.27833425463274974,
            "precision": 0.7551440329218106,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8252996502153058,
            "auditor_fn_violation": 0.01538174089730715,
            "auditor_fp_violation": 0.016637170784889157,
            "ave_precision_score": 0.8255133947943871,
            "fpr": 0.1350164654226125,
            "logloss": 0.9971107017020462,
            "mae": 0.2902157221306168,
            "precision": 0.7377398720682303,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8644108968830286,
            "auditor_fn_violation": 0.004422212556183848,
            "auditor_fp_violation": 0.018732579111329726,
            "ave_precision_score": 0.8646132356606828,
            "fpr": 0.09758771929824561,
            "logloss": 1.3522669826093872,
            "mae": 0.27344879486279594,
            "precision": 0.8086021505376344,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8548194011818355,
            "auditor_fn_violation": 0.004110516850783574,
            "auditor_fp_violation": 0.0058469051726069135,
            "ave_precision_score": 0.8548424360639346,
            "fpr": 0.10537870472008781,
            "logloss": 1.1639801672695993,
            "mae": 0.286139412923338,
            "precision": 0.7871396895787139,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8098494440140525,
            "auditor_fn_violation": 0.006189285196462229,
            "auditor_fp_violation": 0.002182734874569603,
            "ave_precision_score": 0.784320925070963,
            "fpr": 0.11951754385964912,
            "logloss": 0.5893508246511721,
            "mae": 0.3775735080095106,
            "precision": 0.7373493975903614,
            "recall": 0.6322314049586777
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7873455670030252,
            "auditor_fn_violation": 0.005203540649741932,
            "auditor_fp_violation": 0.014163001461104018,
            "ave_precision_score": 0.7565575182420492,
            "fpr": 0.14928649835345773,
            "logloss": 0.6095409317528281,
            "mae": 0.38633921234965585,
            "precision": 0.6923076923076923,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7515904626145108,
            "auditor_fn_violation": 0.013008373205741632,
            "auditor_fp_violation": 0.018450770618134122,
            "ave_precision_score": 0.7379589206501592,
            "fpr": 0.15679824561403508,
            "logloss": 0.6283216361029705,
            "mae": 0.41330103056194883,
            "precision": 0.6578947368421053,
            "recall": 0.5681818181818182
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7240285316253695,
            "auditor_fn_violation": 0.01474180816031016,
            "auditor_fp_violation": 0.003454876279088292,
            "ave_precision_score": 0.7140880856495714,
            "fpr": 0.1525795828759605,
            "logloss": 0.64316703081171,
            "mae": 0.41647956256359064,
            "precision": 0.6650602409638554,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6358992797452325,
            "auditor_fn_violation": 0.007965419747716399,
            "auditor_fp_violation": 0.005075114772913594,
            "ave_precision_score": 0.6363948024502099,
            "fpr": 0.1962719298245614,
            "logloss": 1.0214366438627325,
            "mae": 0.4169389908205408,
            "precision": 0.6517509727626459,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.633136746621215,
            "auditor_fn_violation": 0.013718849989490162,
            "auditor_fp_violation": 0.013956405833464022,
            "ave_precision_score": 0.6340837004596287,
            "fpr": 0.2074643249176729,
            "logloss": 0.9081504215297107,
            "mae": 0.42645269245347966,
            "precision": 0.6330097087378641,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7901148052198622,
            "auditor_fn_violation": 0.012831665941713786,
            "auditor_fp_violation": 0.015437981636333828,
            "ave_precision_score": 0.7689087907221436,
            "fpr": 0.0756578947368421,
            "logloss": 0.5825486894607356,
            "mae": 0.38327641479605645,
            "precision": 0.8088642659279779,
            "recall": 0.6033057851239669
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7385227762380296,
            "auditor_fn_violation": 0.008477941004741115,
            "auditor_fp_violation": 0.00406221764227096,
            "ave_precision_score": 0.7345164980824985,
            "fpr": 0.09769484083424808,
            "logloss": 0.6206917102162368,
            "mae": 0.3937631408744272,
            "precision": 0.7613941018766756,
            "recall": 0.6042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8138821176495148,
            "auditor_fn_violation": 0.04295345802522837,
            "auditor_fp_violation": 0.009699335956714218,
            "ave_precision_score": 0.8141217776684041,
            "fpr": 0.03837719298245614,
            "logloss": 1.9363654702046802,
            "mae": 0.3622432481881028,
            "precision": 0.8813559322033898,
            "recall": 0.5371900826446281
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7811486845865303,
            "auditor_fn_violation": 0.04293154588130883,
            "auditor_fp_violation": 0.013366488197913638,
            "ave_precision_score": 0.7814759163447362,
            "fpr": 0.052689352360043906,
            "logloss": 1.8420856151492828,
            "mae": 0.3644537445848808,
            "precision": 0.8383838383838383,
            "recall": 0.5297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6810506839240194,
            "auditor_fn_violation": 0.013044620849644773,
            "auditor_fp_violation": 0.018445646827348745,
            "ave_precision_score": 0.6827578228825114,
            "fpr": 0.29385964912280704,
            "logloss": 0.864068174682823,
            "mae": 0.3770337851979492,
            "precision": 0.6220028208744711,
            "recall": 0.9111570247933884
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6541544376834126,
            "auditor_fn_violation": 0.008197678492187686,
            "auditor_fp_violation": 0.0210403956679635,
            "ave_precision_score": 0.6559632326649932,
            "fpr": 0.3216245883644347,
            "logloss": 0.9258606300683858,
            "mae": 0.40597023411104954,
            "precision": 0.5832147937411095,
            "recall": 0.8723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7399341382331082,
            "auditor_fn_violation": 0.028642435116717418,
            "auditor_fp_violation": 0.0346470732907034,
            "ave_precision_score": 0.7258799389574813,
            "fpr": 0.21929824561403508,
            "logloss": 0.6327903793778261,
            "mae": 0.42310747563054685,
            "precision": 0.6316758747697975,
            "recall": 0.7086776859504132
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7417710253622346,
            "auditor_fn_violation": 0.024018497325828527,
            "auditor_fp_violation": 0.03830979885551001,
            "ave_precision_score": 0.7249536854919142,
            "fpr": 0.2030735455543359,
            "logloss": 0.6191832833200094,
            "mae": 0.41812264229018653,
            "precision": 0.6580406654343808,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.780991207067288,
            "auditor_fn_violation": 0.009913730607510513,
            "auditor_fp_violation": 0.016734300705033615,
            "ave_precision_score": 0.7697192484881041,
            "fpr": 0.15789473684210525,
            "logloss": 2.465067925243977,
            "mae": 0.31525516049804514,
            "precision": 0.7108433734939759,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7546130640871627,
            "auditor_fn_violation": 0.018268444776607426,
            "auditor_fp_violation": 0.008363389263499048,
            "ave_precision_score": 0.7445319317023659,
            "fpr": 0.18441273326015367,
            "logloss": 2.4662755641185266,
            "mae": 0.3385286433599542,
            "precision": 0.659919028340081,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8690547360558866,
            "auditor_fn_violation": 0.02063397129186603,
            "auditor_fp_violation": 0.012348335792752912,
            "ave_precision_score": 0.8526505940395359,
            "fpr": 0.05921052631578947,
            "logloss": 0.492487880440716,
            "mae": 0.34402591361778606,
            "precision": 0.8586387434554974,
            "recall": 0.6776859504132231
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8033287676726439,
            "auditor_fn_violation": 0.011957867202279475,
            "auditor_fp_violation": 0.009493442455650392,
            "ave_precision_score": 0.8012180926217044,
            "fpr": 0.0867178924259056,
            "logloss": 0.5278929511459819,
            "mae": 0.35886329670899786,
            "precision": 0.799492385786802,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7792605782872819,
            "auditor_fn_violation": 0.011927740321879083,
            "auditor_fp_violation": 0.01856861780619774,
            "ave_precision_score": 0.6638755867471905,
            "fpr": 0.13596491228070176,
            "logloss": 0.6261677659938082,
            "mae": 0.4473759125787438,
            "precision": 0.7175398633257403,
            "recall": 0.6508264462809917
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7674813716489648,
            "auditor_fn_violation": 0.02316369666254058,
            "auditor_fp_violation": 0.019803311006070932,
            "ave_precision_score": 0.6496921404409357,
            "fpr": 0.1350164654226125,
            "logloss": 0.6260801489864141,
            "mae": 0.44681466378181617,
            "precision": 0.7064439140811456,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6249071167466369,
            "auditor_fn_violation": 0.037643178193417434,
            "auditor_fp_violation": 0.04045745204131825,
            "ave_precision_score": 0.6148388666172628,
            "fpr": 0.21600877192982457,
            "logloss": 1.9719063507984265,
            "mae": 0.39050247092438695,
            "precision": 0.645045045045045,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.5991720571966919,
            "auditor_fn_violation": 0.038139056916645264,
            "auditor_fp_violation": 0.05291586081926369,
            "ave_precision_score": 0.5882136261158655,
            "fpr": 0.22941822173435786,
            "logloss": 2.002594811588371,
            "mae": 0.4109160613492755,
            "precision": 0.6193078324225865,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8301086783975539,
            "auditor_fn_violation": 0.008450231984920986,
            "auditor_fp_violation": 0.00884366289555665,
            "ave_precision_score": 0.8094618829324636,
            "fpr": 0.10087719298245613,
            "logloss": 0.5546390543060722,
            "mae": 0.3748876217981441,
            "precision": 0.7899543378995434,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7991745405300027,
            "auditor_fn_violation": 0.000987925356750825,
            "auditor_fp_violation": 0.015502139384842854,
            "ave_precision_score": 0.7739204890312987,
            "fpr": 0.11745334796926454,
            "logloss": 0.570129382239296,
            "mae": 0.3848566540836895,
            "precision": 0.7545871559633027,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 2917,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.7069379557583024,
            "auditor_fn_violation": 0.004028019428737149,
            "auditor_fp_violation": 0.013352598786686341,
            "ave_precision_score": 0.7130042637738229,
            "fpr": 0.02631578947368421,
            "logloss": 0.7540084994216513,
            "mae": 0.47210553558870105,
            "precision": 0.7073170731707317,
            "recall": 0.11983471074380166
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7062077966052727,
            "auditor_fn_violation": 0.009008104257654668,
            "auditor_fp_violation": 0.01050650776227066,
            "ave_precision_score": 0.7066125599647066,
            "fpr": 0.036223929747530186,
            "logloss": 0.724033905263511,
            "mae": 0.46064777577420624,
            "precision": 0.67,
            "recall": 0.1425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7415345327589037,
            "auditor_fn_violation": 0.004123169493982893,
            "auditor_fp_violation": 0.02196825299229382,
            "ave_precision_score": 0.7001902007956516,
            "fpr": 0.1611842105263158,
            "logloss": 0.6071313490109884,
            "mae": 0.4131322234967037,
            "precision": 0.7006109979633401,
            "recall": 0.7107438016528925
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7138813992958206,
            "auditor_fn_violation": 0.02097764906462387,
            "auditor_fp_violation": 0.020940831510064692,
            "ave_precision_score": 0.6806994356480833,
            "fpr": 0.15587266739846323,
            "logloss": 0.6174140444275557,
            "mae": 0.41422324227710977,
            "precision": 0.6965811965811965,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8569841818273456,
            "auditor_fn_violation": 0.005618384804987684,
            "auditor_fp_violation": 0.008136579767174947,
            "ave_precision_score": 0.8519845743564062,
            "fpr": 0.08333333333333333,
            "logloss": 0.4982400966329269,
            "mae": 0.3363410486071779,
            "precision": 0.8248847926267281,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8269367440128609,
            "auditor_fn_violation": 0.006516103416867137,
            "auditor_fp_violation": 0.008938372275364601,
            "ave_precision_score": 0.8209434360804637,
            "fpr": 0.11525795828759605,
            "logloss": 0.5362907124898308,
            "mae": 0.3548769040849023,
            "precision": 0.7640449438202247,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8608757379941783,
            "auditor_fn_violation": 0.005301217920835149,
            "auditor_fp_violation": 0.009125471388752254,
            "ave_precision_score": 0.861320587416164,
            "fpr": 0.09758771929824561,
            "logloss": 0.4852857302238531,
            "mae": 0.2890643721156378,
            "precision": 0.8065217391304348,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8413770130155258,
            "auditor_fn_violation": 0.016124436555573725,
            "auditor_fp_violation": 0.012963253358423507,
            "ave_precision_score": 0.8416106719325839,
            "fpr": 0.11525795828759605,
            "logloss": 0.5321555931932588,
            "mae": 0.31140997732092923,
            "precision": 0.7597254004576659,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 2917,
        "test": {
            "accuracy": 0.8114035087719298,
            "auc_prc": 0.8874351445286919,
            "auditor_fn_violation": 0.005699942003769757,
            "auditor_fp_violation": 0.004877848827676673,
            "ave_precision_score": 0.8846532521433947,
            "fpr": 0.07894736842105263,
            "logloss": 1.1516536378593232,
            "mae": 0.20254300119400678,
            "precision": 0.8421052631578947,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8674264504829966,
            "auditor_fn_violation": 0.007896396291192752,
            "auditor_fp_violation": 0.00969257077144799,
            "ave_precision_score": 0.8673445644049851,
            "fpr": 0.10647639956092206,
            "logloss": 1.26864012263015,
            "mae": 0.23239830222317118,
            "precision": 0.7863436123348018,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8347020334291452,
            "auditor_fn_violation": 0.01411845730027549,
            "auditor_fp_violation": 0.015432857845548457,
            "ave_precision_score": 0.8356093300534578,
            "fpr": 0.08333333333333333,
            "logloss": 0.5078709310997206,
            "mae": 0.32822417496425804,
            "precision": 0.8240740740740741,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8332775254371096,
            "auditor_fn_violation": 0.015169208491954134,
            "auditor_fp_violation": 0.018113209425738828,
            "ave_precision_score": 0.8318761952337276,
            "fpr": 0.10318331503841932,
            "logloss": 0.5129825304196042,
            "mae": 0.3343699225393235,
            "precision": 0.785876993166287,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6951968870394053,
            "auditor_fn_violation": 0.04686593808902421,
            "auditor_fp_violation": 0.036319990982128215,
            "ave_precision_score": 0.6476249269006096,
            "fpr": 0.15679824561403508,
            "logloss": 0.6911303462690396,
            "mae": 0.45505830696212096,
            "precision": 0.6352040816326531,
            "recall": 0.5144628099173554
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7050465810263891,
            "auditor_fn_violation": 0.03600906182123924,
            "auditor_fp_violation": 0.04723074740324231,
            "ave_precision_score": 0.6521063125867427,
            "fpr": 0.15587266739846323,
            "logloss": 0.6849565420818222,
            "mae": 0.4509750093148385,
            "precision": 0.6536585365853659,
            "recall": 0.5702127659574469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8513226087104571,
            "auditor_fn_violation": 0.027067928084674495,
            "auditor_fp_violation": 0.03962227414330218,
            "ave_precision_score": 0.8253281917897161,
            "fpr": 0.16447368421052633,
            "logloss": 0.5246361229857329,
            "mae": 0.3510837614180912,
            "precision": 0.7211895910780669,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8318521850129096,
            "auditor_fn_violation": 0.022687250391199763,
            "auditor_fp_violation": 0.043524471625459554,
            "ave_precision_score": 0.8038452593599549,
            "fpr": 0.18990120746432493,
            "logloss": 0.5397272328923256,
            "mae": 0.3620820651740719,
            "precision": 0.6921708185053381,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6520575239686894,
            "auditor_fn_violation": 0.039727417717848344,
            "auditor_fp_violation": 0.08148876865059847,
            "ave_precision_score": 0.653178529802809,
            "fpr": 0.31359649122807015,
            "logloss": 0.6758677232440239,
            "mae": 0.4884749408484551,
            "precision": 0.5949008498583569,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6293069685938815,
            "auditor_fn_violation": 0.04791087652100801,
            "auditor_fp_violation": 0.0811597233112052,
            "ave_precision_score": 0.6295720180803844,
            "fpr": 0.3336992316136114,
            "logloss": 0.6784213937661094,
            "mae": 0.4898961543644299,
            "precision": 0.5632183908045977,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8645965263806711,
            "auditor_fn_violation": 0.004086921850079751,
            "auditor_fp_violation": 0.012601963436628956,
            "ave_precision_score": 0.8651123234206821,
            "fpr": 0.09320175438596491,
            "logloss": 0.8300373071521299,
            "mae": 0.2501222972081638,
            "precision": 0.8111111111111111,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8575155197350149,
            "auditor_fn_violation": 0.005203540649741922,
            "auditor_fp_violation": 0.008659592633247962,
            "ave_precision_score": 0.8576997605153562,
            "fpr": 0.09989023051591657,
            "logloss": 0.8549427795094067,
            "mae": 0.26422526249156375,
            "precision": 0.7927107061503417,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8475369208132892,
            "auditor_fn_violation": 0.026236497752646082,
            "auditor_fp_violation": 0.026433636661747827,
            "ave_precision_score": 0.848107563667991,
            "fpr": 0.13267543859649122,
            "logloss": 0.5276184549238158,
            "mae": 0.31692426400306367,
            "precision": 0.7589641434262948,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8433842080904126,
            "auditor_fn_violation": 0.02854940794544223,
            "auditor_fp_violation": 0.02808455983930346,
            "ave_precision_score": 0.8435863078373953,
            "fpr": 0.15697036223929747,
            "logloss": 0.5330393260448953,
            "mae": 0.3226735865172437,
            "precision": 0.72552783109405,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8418441098862001,
            "auditor_fn_violation": 0.005636508626939247,
            "auditor_fp_violation": 0.0136651500245942,
            "ave_precision_score": 0.8286411720218501,
            "fpr": 0.07236842105263158,
            "logloss": 0.5296674287123533,
            "mae": 0.3475670002588773,
            "precision": 0.835820895522388,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8317285893450667,
            "auditor_fn_violation": 0.01877291729920359,
            "auditor_fp_violation": 0.015001829491401395,
            "ave_precision_score": 0.8180387252531639,
            "fpr": 0.07683863885839737,
            "logloss": 0.5419991171234072,
            "mae": 0.3530381881927358,
            "precision": 0.8200514138817481,
            "recall": 0.6787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8366433871539254,
            "auditor_fn_violation": 0.04726239669421488,
            "auditor_fp_violation": 0.015973417773405475,
            "ave_precision_score": 0.8377153843936722,
            "fpr": 0.0625,
            "logloss": 1.9664396160635493,
            "mae": 0.3332590733975189,
            "precision": 0.8475935828877005,
            "recall": 0.6549586776859504
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8133771536702071,
            "auditor_fn_violation": 0.034238736950276766,
            "auditor_fp_violation": 0.020843756456113364,
            "ave_precision_score": 0.8133066501007373,
            "fpr": 0.07793633369923161,
            "logloss": 1.9003293967248291,
            "mae": 0.3424719390803834,
            "precision": 0.8086253369272237,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.611243207959795,
            "auditor_fn_violation": 0.0018780810497317905,
            "auditor_fp_violation": 0.004460259878668635,
            "ave_precision_score": 0.6122398276261966,
            "fpr": 0.01206140350877193,
            "logloss": 2.9399924761642167,
            "mae": 0.5017448998403803,
            "precision": 0.8225806451612904,
            "recall": 0.10537190082644628
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6143252853639913,
            "auditor_fn_violation": 0.0016605553868790468,
            "auditor_fp_violation": 0.0033453557053996132,
            "ave_precision_score": 0.6150321595457899,
            "fpr": 0.015367727771679473,
            "logloss": 2.6365834689658563,
            "mae": 0.483873836600636,
            "precision": 0.7543859649122807,
            "recall": 0.09148936170212765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.610559954189465,
            "auditor_fn_violation": 0.003973647962882413,
            "auditor_fp_violation": 0.0034124446630595163,
            "ave_precision_score": 0.559720370811261,
            "fpr": 0.4517543859649123,
            "logloss": 0.700641038964592,
            "mae": 0.49095845346649486,
            "precision": 0.5328798185941043,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5616165296247553,
            "auditor_fn_violation": 0.0005885512763621928,
            "auditor_fp_violation": 0.0025762225856314092,
            "ave_precision_score": 0.5324822297377678,
            "fpr": 0.4676180021953897,
            "logloss": 0.7090649778152202,
            "mae": 0.49485997405847787,
            "precision": 0.5180995475113123,
            "recall": 0.9744680851063829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8518478602832738,
            "auditor_fn_violation": 0.03117750471219371,
            "auditor_fp_violation": 0.010511456796196104,
            "ave_precision_score": 0.8522747485926684,
            "fpr": 0.07346491228070176,
            "logloss": 1.3852123209024647,
            "mae": 0.3249350016520483,
            "precision": 0.8345679012345679,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8443679687073777,
            "auditor_fn_violation": 0.019793539949085642,
            "auditor_fp_violation": 0.019780909070543702,
            "ave_precision_score": 0.844465591026257,
            "fpr": 0.08562019758507135,
            "logloss": 1.2483975988387617,
            "mae": 0.329597831935953,
            "precision": 0.8045112781954887,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7624043497759785,
            "auditor_fn_violation": 0.010258083224590415,
            "auditor_fp_violation": 0.016995614035087717,
            "ave_precision_score": 0.7546433903040051,
            "fpr": 0.11732456140350878,
            "logloss": 0.6088124615318845,
            "mae": 0.4186264176836662,
            "precision": 0.7377450980392157,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7469410298070422,
            "auditor_fn_violation": 0.01800219538968168,
            "auditor_fp_violation": 0.014899776229555125,
            "ave_precision_score": 0.7380318104356662,
            "fpr": 0.11306256860592755,
            "logloss": 0.6133061517550512,
            "mae": 0.4207532333228512,
            "precision": 0.7324675324675325,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7121006764185696,
            "auditor_fn_violation": 0.01036229520081196,
            "auditor_fp_violation": 0.019142482374159702,
            "ave_precision_score": 0.6926335138990141,
            "fpr": 0.07456140350877193,
            "logloss": 0.7351694526847903,
            "mae": 0.430687840672602,
            "precision": 0.7290836653386454,
            "recall": 0.378099173553719
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6844294163003661,
            "auditor_fn_violation": 0.017894761426536194,
            "auditor_fp_violation": 0.010760396364912595,
            "ave_precision_score": 0.6640930809361315,
            "fpr": 0.08232711306256861,
            "logloss": 0.739829499623977,
            "mae": 0.4317925962548944,
            "precision": 0.6900826446280992,
            "recall": 0.3553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7523990079632152,
            "auditor_fn_violation": 0.006221001884877482,
            "auditor_fp_violation": 0.022390965732087233,
            "ave_precision_score": 0.7526060196753839,
            "fpr": 0.19736842105263158,
            "logloss": 1.313478733542639,
            "mae": 0.3599753763461322,
            "precision": 0.7034596375617792,
            "recall": 0.8822314049586777
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7511646936826436,
            "auditor_fn_violation": 0.005703342130462198,
            "auditor_fp_violation": 0.007663951054259975,
            "ave_precision_score": 0.7495795094199241,
            "fpr": 0.21295279912184412,
            "logloss": 1.101742145367625,
            "mae": 0.3781732789155926,
            "precision": 0.6711864406779661,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7049248323266528,
            "auditor_fn_violation": 0.009347361171523861,
            "auditor_fp_violation": 0.023277381537957043,
            "ave_precision_score": 0.6542638000577605,
            "fpr": 0.1513157894736842,
            "logloss": 0.6275049974238042,
            "mae": 0.4471138679471455,
            "precision": 0.7076271186440678,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7030443015999416,
            "auditor_fn_violation": 0.018193708106593178,
            "auditor_fp_violation": 0.018591117383653058,
            "ave_precision_score": 0.6466533862737764,
            "fpr": 0.145993413830955,
            "logloss": 0.631172604829992,
            "mae": 0.4495062920317037,
            "precision": 0.7004504504504504,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.671379507653431,
            "auditor_fn_violation": 0.02098058938668987,
            "auditor_fp_violation": 0.018299618789965583,
            "ave_precision_score": 0.5336533482466497,
            "fpr": 0.2708333333333333,
            "logloss": 0.6924945591652004,
            "mae": 0.49934991213836166,
            "precision": 0.5357142857142857,
            "recall": 0.5888429752066116
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6734821074695189,
            "auditor_fn_violation": 0.015206576826961258,
            "auditor_fp_violation": 0.005159912483105225,
            "ave_precision_score": 0.5278430653677452,
            "fpr": 0.27332601536772777,
            "logloss": 0.6917856248106616,
            "mae": 0.4989939562968182,
            "precision": 0.5354477611940298,
            "recall": 0.6106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7017830732004603,
            "auditor_fn_violation": 0.006753389154704946,
            "auditor_fp_violation": 0.023272257747171666,
            "ave_precision_score": 0.704334948408454,
            "fpr": 0.3344298245614035,
            "logloss": 0.6806252602281435,
            "mae": 0.41347005429040445,
            "precision": 0.5965608465608465,
            "recall": 0.9318181818181818
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6855810186510316,
            "auditor_fn_violation": 0.007272812200761381,
            "auditor_fp_violation": 0.03261721812764623,
            "ave_precision_score": 0.6869311044720825,
            "fpr": 0.3391877058177827,
            "logloss": 0.6709670026744927,
            "mae": 0.4096538232134412,
            "precision": 0.5912698412698413,
            "recall": 0.951063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8416789399946198,
            "auditor_fn_violation": 0.018187255328403658,
            "auditor_fp_violation": 0.03289473684210527,
            "ave_precision_score": 0.8343044228939,
            "fpr": 0.11732456140350878,
            "logloss": 0.49584068508515,
            "mae": 0.3136181549348852,
            "precision": 0.7820773930753564,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8280429716879115,
            "auditor_fn_violation": 0.020234953406357288,
            "auditor_fp_violation": 0.027519533243227774,
            "ave_precision_score": 0.8212899514087796,
            "fpr": 0.132821075740944,
            "logloss": 0.5248176661669222,
            "mae": 0.325527217795277,
            "precision": 0.7494824016563147,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8290127601182677,
            "auditor_fn_violation": 0.00700938813977092,
            "auditor_fp_violation": 0.013280865715691098,
            "ave_precision_score": 0.820123467335456,
            "fpr": 0.07456140350877193,
            "logloss": 0.5787185242925981,
            "mae": 0.37292311773553755,
            "precision": 0.8308457711442786,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7912419497986686,
            "auditor_fn_violation": 0.001854403624728497,
            "auditor_fp_violation": 0.008034827542433003,
            "ave_precision_score": 0.78311998398073,
            "fpr": 0.10098792535675083,
            "logloss": 0.587406869557482,
            "mae": 0.3784609197523408,
            "precision": 0.780952380952381,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7930556504998507,
            "auditor_fn_violation": 0.0005890242134261439,
            "auditor_fp_violation": 0.003732681587145434,
            "ave_precision_score": 0.7831048535567864,
            "fpr": 0.025219298245614034,
            "logloss": 0.7221631999606791,
            "mae": 0.4067635699910553,
            "precision": 0.8888888888888888,
            "recall": 0.38016528925619836
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7821164813587228,
            "auditor_fn_violation": 0.011437046033117716,
            "auditor_fp_violation": 0.003444919863298412,
            "ave_precision_score": 0.7715164865456133,
            "fpr": 0.031833150384193196,
            "logloss": 0.7000006026137522,
            "mae": 0.4013017419312644,
            "precision": 0.861904761904762,
            "recall": 0.3851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8621285311025864,
            "auditor_fn_violation": 0.007322024068435554,
            "auditor_fp_violation": 0.013034923757993115,
            "ave_precision_score": 0.8594735635258643,
            "fpr": 0.09100877192982457,
            "logloss": 0.4910277226690785,
            "mae": 0.3277733232499215,
            "precision": 0.8113636363636364,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.859293711944092,
            "auditor_fn_violation": 0.007291496368264946,
            "auditor_fp_violation": 0.00562288581733462,
            "ave_precision_score": 0.8563549939275843,
            "fpr": 0.09549945115257959,
            "logloss": 0.49039171746713034,
            "mae": 0.3292099245170665,
            "precision": 0.8,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8139876302341243,
            "auditor_fn_violation": 0.0072404668696534795,
            "auditor_fp_violation": 0.00038172241351041046,
            "ave_precision_score": 0.814864294383036,
            "fpr": 0.11513157894736842,
            "logloss": 0.5622680753110071,
            "mae": 0.4051490638307051,
            "precision": 0.7666666666666667,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7890839876267379,
            "auditor_fn_violation": 0.004797160006539461,
            "auditor_fp_violation": 0.005095195780470994,
            "ave_precision_score": 0.7894548765329319,
            "fpr": 0.12952799121844127,
            "logloss": 0.5819475998739796,
            "mae": 0.41430457051675745,
            "precision": 0.7342342342342343,
            "recall": 0.6936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.849008111000349,
            "auditor_fn_violation": 0.004603450775699582,
            "auditor_fp_violation": 0.01906050172159371,
            "ave_precision_score": 0.8299881522741778,
            "fpr": 0.14473684210526316,
            "logloss": 1.265528427918976,
            "mae": 0.27354492414681436,
            "precision": 0.7528089887640449,
            "recall": 0.8305785123966942
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8143337600572643,
            "auditor_fn_violation": 0.012583786813648785,
            "auditor_fp_violation": 0.019566846131061293,
            "ave_precision_score": 0.7924146063628076,
            "fpr": 0.1690450054884742,
            "logloss": 1.4969001686553804,
            "mae": 0.3016671764418487,
            "precision": 0.7072243346007605,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6905042969998278,
            "auditor_fn_violation": 0.004725786573872705,
            "auditor_fp_violation": 0.002664371208394819,
            "ave_precision_score": 0.6875521996979671,
            "fpr": 0.02631578947368421,
            "logloss": 0.7094926236372918,
            "mae": 0.4332279809832312,
            "precision": 0.816793893129771,
            "recall": 0.22107438016528927
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6973172672325787,
            "auditor_fn_violation": 0.007123338860732905,
            "auditor_fp_violation": 0.0022252589290381363,
            "ave_precision_score": 0.6719128312877012,
            "fpr": 0.021953896816684963,
            "logloss": 0.6947955102186305,
            "mae": 0.4298419620183375,
            "precision": 0.84,
            "recall": 0.22340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.818615720440458,
            "auditor_fn_violation": 0.0020683811802232953,
            "auditor_fp_violation": 0.0033176545335300875,
            "ave_precision_score": 0.8115940795393828,
            "fpr": 0.027412280701754384,
            "logloss": 0.6201755843671816,
            "mae": 0.38948064678136196,
            "precision": 0.8853211009174312,
            "recall": 0.3987603305785124
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7956100074278073,
            "auditor_fn_violation": 0.004316042693322759,
            "auditor_fp_violation": 0.0038830021580531235,
            "ave_precision_score": 0.7879866537153642,
            "fpr": 0.03293084522502744,
            "logloss": 0.6203536811638243,
            "mae": 0.3912853952722152,
            "precision": 0.8564593301435407,
            "recall": 0.38085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8740748988748019,
            "auditor_fn_violation": 0.019329056111352768,
            "auditor_fp_violation": 0.016496044433513695,
            "ave_precision_score": 0.8717186361487212,
            "fpr": 0.09758771929824561,
            "logloss": 0.46699943549961065,
            "mae": 0.3116024117181568,
            "precision": 0.8043956043956044,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8540191314075729,
            "auditor_fn_violation": 0.013081252773431118,
            "auditor_fp_violation": 0.011524551276785871,
            "ave_precision_score": 0.8516395321529842,
            "fpr": 0.10428100987925357,
            "logloss": 0.49668641162189736,
            "mae": 0.3227455196114979,
            "precision": 0.7879464285714286,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8772227895218733,
            "auditor_fn_violation": 0.011535812672176312,
            "auditor_fp_violation": 0.008679701590424659,
            "ave_precision_score": 0.877496541908211,
            "fpr": 0.08991228070175439,
            "logloss": 0.4638152467882739,
            "mae": 0.32283780426032055,
            "precision": 0.8213507625272332,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8441372230309847,
            "auditor_fn_violation": 0.0013686152696358925,
            "auditor_fp_violation": 0.007181064888450804,
            "ave_precision_score": 0.8443698462681567,
            "fpr": 0.1141602634467618,
            "logloss": 0.5055448298734687,
            "mae": 0.33882463761859877,
            "precision": 0.7714285714285715,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.5628966396231715,
            "auditor_fn_violation": 0.009587501812382195,
            "auditor_fp_violation": 0.0006276643712083943,
            "ave_precision_score": 0.5439822563127175,
            "fpr": 0.40899122807017546,
            "logloss": 0.7094190766272387,
            "mae": 0.49471070369084674,
            "precision": 0.5325814536340853,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5142714196054654,
            "auditor_fn_violation": 0.0067496555106616556,
            "auditor_fp_violation": 0.0070018494042329744,
            "ave_precision_score": 0.5087575660142217,
            "fpr": 0.43688254665203075,
            "logloss": 0.7136217906371118,
            "mae": 0.4989876939488818,
            "precision": 0.5134474327628362,
            "recall": 0.8936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8535451249447855,
            "auditor_fn_violation": 0.005595730027548216,
            "auditor_fp_violation": 0.012771048532546318,
            "ave_precision_score": 0.7516366654190734,
            "fpr": 0.0800438596491228,
            "logloss": 0.5322052432963714,
            "mae": 0.3663292597783239,
            "precision": 0.8302325581395349,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8211801461950792,
            "auditor_fn_violation": 0.0024990074036013786,
            "auditor_fp_violation": 0.005122575923893156,
            "ave_precision_score": 0.7042470115196637,
            "fpr": 0.10757409440175632,
            "logloss": 0.5638173053038369,
            "mae": 0.3809440898842921,
            "precision": 0.776255707762557,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 2917,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.867539410568918,
            "auditor_fn_violation": 0.007224608525445855,
            "auditor_fp_violation": 0.006466223971142814,
            "ave_precision_score": 0.8678057785211118,
            "fpr": 0.07017543859649122,
            "logloss": 0.780918294882704,
            "mae": 0.32822530679840595,
            "precision": 0.8403990024937655,
            "recall": 0.6962809917355371
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8138284897878222,
            "auditor_fn_violation": 0.004017096013265761,
            "auditor_fp_violation": 0.009861829839875947,
            "ave_precision_score": 0.8142426551146843,
            "fpr": 0.0845225027442371,
            "logloss": 0.7532840589477457,
            "mae": 0.34174311219102427,
            "precision": 0.8045685279187818,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6536813292200798,
            "auditor_fn_violation": 0.015976149050311736,
            "auditor_fp_violation": 0.019255205771437942,
            "ave_precision_score": 0.6511439081721655,
            "fpr": 0.07894736842105263,
            "logloss": 1.6870640452381451,
            "mae": 0.44894915242401656,
            "precision": 0.7165354330708661,
            "recall": 0.3760330578512397
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6076678151736205,
            "auditor_fn_violation": 0.017894761426536194,
            "auditor_fp_violation": 0.026449218545815695,
            "ave_precision_score": 0.601961658977648,
            "fpr": 0.09659714599341383,
            "logloss": 1.6536070057746286,
            "mae": 0.45931062016627633,
            "precision": 0.65625,
            "recall": 0.3574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7347711178364341,
            "auditor_fn_violation": 0.06464767290126142,
            "auditor_fp_violation": 0.0743257091326447,
            "ave_precision_score": 0.7265794794569783,
            "fpr": 0.2225877192982456,
            "logloss": 0.6487738676050044,
            "mae": 0.41517080151345254,
            "precision": 0.6394316163410302,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7597923517544835,
            "auditor_fn_violation": 0.06332765023238433,
            "auditor_fp_violation": 0.06592889625663657,
            "ave_precision_score": 0.7499279187301456,
            "fpr": 0.22722283205268934,
            "logloss": 0.6202432555481643,
            "mae": 0.40364996097270406,
            "precision": 0.640625,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7868471907192841,
            "auditor_fn_violation": 0.040946244744091635,
            "auditor_fp_violation": 0.050407853746515824,
            "ave_precision_score": 0.7860077589098793,
            "fpr": 0.2149122807017544,
            "logloss": 4.210124018446491,
            "mae": 0.35092163464338355,
            "precision": 0.6655290102389079,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7701472698993828,
            "auditor_fn_violation": 0.04375598477240348,
            "auditor_fp_violation": 0.0464865053229488,
            "ave_precision_score": 0.7695094008011021,
            "fpr": 0.22502744237102085,
            "logloss": 4.1552002461457045,
            "mae": 0.36642114974713746,
            "precision": 0.646551724137931,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8046193430034005,
            "auditor_fn_violation": 0.014535305205161667,
            "auditor_fp_violation": 0.017559231021478935,
            "ave_precision_score": 0.8051184224765386,
            "fpr": 0.12171052631578948,
            "logloss": 0.8895453837281543,
            "mae": 0.2814690756344863,
            "precision": 0.7648305084745762,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.791855633962019,
            "auditor_fn_violation": 0.014181283135203313,
            "auditor_fp_violation": 0.02022894778108829,
            "ave_precision_score": 0.7922517363898357,
            "fpr": 0.13830954994511527,
            "logloss": 0.8885287313897157,
            "mae": 0.2974039556250018,
            "precision": 0.728448275862069,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7718164980515307,
            "auditor_fn_violation": 0.00788386254893432,
            "auditor_fp_violation": 0.012435440236104283,
            "ave_precision_score": 0.7588278575410585,
            "fpr": 0.1118421052631579,
            "logloss": 1.6672366525474165,
            "mae": 0.33992369892782914,
            "precision": 0.7796976241900648,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.732258666818532,
            "auditor_fn_violation": 0.011677604689726048,
            "auditor_fp_violation": 0.008039805750327944,
            "ave_precision_score": 0.7186778269805587,
            "fpr": 0.1394072447859495,
            "logloss": 1.8826239975562955,
            "mae": 0.36487689146455193,
            "precision": 0.7221006564551422,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4199561403508772,
            "auc_prc": 0.5076885032494598,
            "auditor_fn_violation": 0.0077184826736262195,
            "auditor_fp_violation": 0.006333005410723069,
            "ave_precision_score": 0.5091660048282068,
            "fpr": 0.18859649122807018,
            "logloss": 0.9478238414207211,
            "mae": 0.5051468139342767,
            "precision": 0.42474916387959866,
            "recall": 0.26239669421487605
        },
        "train": {
            "accuracy": 0.4039517014270033,
            "auc_prc": 0.4737637397996607,
            "auditor_fn_violation": 0.008599388093514264,
            "auditor_fp_violation": 0.007932774280586733,
            "ave_precision_score": 0.4750781644132589,
            "fpr": 0.1964873765093304,
            "logloss": 1.002250758815902,
            "mae": 0.5206636914126698,
            "precision": 0.3719298245614035,
            "recall": 0.225531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6786334719600547,
            "auditor_fn_violation": 0.0016266130201536902,
            "auditor_fp_violation": 0.004239936874897533,
            "ave_precision_score": 0.5517512743472708,
            "fpr": 0.45285087719298245,
            "logloss": 0.6892551837467575,
            "mae": 0.49727341774524303,
            "precision": 0.5364758698092031,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6597560239477783,
            "auditor_fn_violation": 0.0027185463717682235,
            "auditor_fp_violation": 0.004704406460718216,
            "ave_precision_score": 0.5295208922714116,
            "fpr": 0.46871569703622395,
            "logloss": 0.6916288869801854,
            "mae": 0.4984518443321161,
            "precision": 0.5196850393700787,
            "recall": 0.9829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7810959475134116,
            "auditor_fn_violation": 0.010040597361171525,
            "auditor_fp_violation": 0.025854648303000497,
            "ave_precision_score": 0.6492191927979227,
            "fpr": 0.16447368421052633,
            "logloss": 0.6366491257624869,
            "mae": 0.4276458022037619,
            "precision": 0.696969696969697,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7724557774806794,
            "auditor_fn_violation": 0.01566667445173647,
            "auditor_fp_violation": 0.021558129289037244,
            "ave_precision_score": 0.6353111398082709,
            "fpr": 0.1712403951701427,
            "logloss": 0.6343521079155287,
            "mae": 0.42664671909272606,
            "precision": 0.6829268292682927,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7959394566306385,
            "auditor_fn_violation": 0.009510475569088012,
            "auditor_fp_violation": 0.020546401049352354,
            "ave_precision_score": 0.7847926312411726,
            "fpr": 0.12609649122807018,
            "logloss": 1.3874926712597533,
            "mae": 0.28059412957794083,
            "precision": 0.764344262295082,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.782280195810909,
            "auditor_fn_violation": 0.01444986804306701,
            "auditor_fp_violation": 0.018718061684974027,
            "ave_precision_score": 0.7711030309675369,
            "fpr": 0.13721185510428102,
            "logloss": 1.3406635063981196,
            "mae": 0.29643661098715235,
            "precision": 0.7362869198312236,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7513590714432472,
            "auditor_fn_violation": 0.0011214114832535883,
            "auditor_fp_violation": 0.016759919658960495,
            "ave_precision_score": 0.6750437444228161,
            "fpr": 0.16337719298245615,
            "logloss": 0.6705180336433816,
            "mae": 0.43146877908229564,
            "precision": 0.6959183673469388,
            "recall": 0.7045454545454546
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7173021346475685,
            "auditor_fn_violation": 0.011152112478688378,
            "auditor_fp_violation": 0.02444051166020745,
            "ave_precision_score": 0.6622632401672305,
            "fpr": 0.16794731064763996,
            "logloss": 0.6596504804353877,
            "mae": 0.426856893583985,
            "precision": 0.6877551020408164,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7518032352666305,
            "auditor_fn_violation": 0.011481441206321592,
            "auditor_fp_violation": 0.02444560583702247,
            "ave_precision_score": 0.7524218334550039,
            "fpr": 0.14692982456140352,
            "logloss": 0.860991876972792,
            "mae": 0.35273528320044933,
            "precision": 0.70995670995671,
            "recall": 0.6776859504132231
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7434208722041965,
            "auditor_fn_violation": 0.021575542424737845,
            "auditor_fp_violation": 0.021097645058755304,
            "ave_precision_score": 0.7439724150395386,
            "fpr": 0.14928649835345773,
            "logloss": 0.8565361810119535,
            "mae": 0.36284219871482654,
            "precision": 0.6909090909090909,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6305832087565624,
            "auditor_fn_violation": 0.0018712846164999277,
            "auditor_fp_violation": 0.01160794802426628,
            "ave_precision_score": 0.6165737386909012,
            "fpr": 0.43530701754385964,
            "logloss": 0.7483957102779331,
            "mae": 0.46812084964231443,
            "precision": 0.5468036529680366,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6137701518426517,
            "auditor_fn_violation": 0.0024522969848424694,
            "auditor_fp_violation": 0.010454236579373808,
            "ave_precision_score": 0.6005894537067841,
            "fpr": 0.4610318331503842,
            "logloss": 0.7616420246545728,
            "mae": 0.47522511764232206,
            "precision": 0.5254237288135594,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.652993140226307,
            "auditor_fn_violation": 0.007938234014789039,
            "auditor_fp_violation": 0.02028508771929825,
            "ave_precision_score": 0.6542282800787591,
            "fpr": 0.3519736842105263,
            "logloss": 1.609621270776773,
            "mae": 0.37811854100136433,
            "precision": 0.58898847631242,
            "recall": 0.9504132231404959
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6419715936545012,
            "auditor_fn_violation": 0.006994885209145901,
            "auditor_fp_violation": 0.024171688433880695,
            "ave_precision_score": 0.6429726642885832,
            "fpr": 0.3578485181119649,
            "logloss": 1.6046829715226625,
            "mae": 0.3848203415352404,
            "precision": 0.5771725032425421,
            "recall": 0.9468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7872233550749469,
            "auditor_fn_violation": 0.02252791068580542,
            "auditor_fp_violation": 0.03002541400229547,
            "ave_precision_score": 0.7600963806504195,
            "fpr": 0.12280701754385964,
            "logloss": 3.3995873945969404,
            "mae": 0.28558612127711525,
            "precision": 0.7586206896551724,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.764674336159938,
            "auditor_fn_violation": 0.0265642151481888,
            "auditor_fp_violation": 0.020293664483722506,
            "ave_precision_score": 0.7397806957545732,
            "fpr": 0.13611416026344675,
            "logloss": 3.2321971312963402,
            "mae": 0.29737038899536494,
            "precision": 0.7262693156732892,
            "recall": 0.7
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7896185468957531,
            "mae": 0.5005381909329771,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7795836382425775,
            "mae": 0.4945071576700907,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8260661696910034,
            "auditor_fn_violation": 0.01801281354211977,
            "auditor_fp_violation": 0.004918839153959666,
            "ave_precision_score": 0.8268074648918726,
            "fpr": 0.021929824561403508,
            "logloss": 1.0939974960247152,
            "mae": 0.36162812617307877,
            "precision": 0.91701244813278,
            "recall": 0.45661157024793386
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.8128103244646712,
            "auditor_fn_violation": 0.007118667818856999,
            "auditor_fp_violation": 0.0031885421567090055,
            "ave_precision_score": 0.8131011359988256,
            "fpr": 0.026344676180021953,
            "logloss": 0.9856676853256132,
            "mae": 0.3647667391557212,
            "precision": 0.8909090909090909,
            "recall": 0.41702127659574467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8427313603074905,
            "auditor_fn_violation": 0.004639698419602728,
            "auditor_fp_violation": 0.01499221183800624,
            "ave_precision_score": 0.8434467839453856,
            "fpr": 0.16666666666666666,
            "logloss": 0.6308175788835242,
            "mae": 0.2984381101376034,
            "precision": 0.7342657342657343,
            "recall": 0.8677685950413223
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8266670621368671,
            "auditor_fn_violation": 0.006749655510661656,
            "auditor_fp_violation": 0.007004338508180441,
            "ave_precision_score": 0.8269000850636523,
            "fpr": 0.18441273326015367,
            "logloss": 0.6790971412189066,
            "mae": 0.3237334248659934,
            "precision": 0.6972972972972973,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8358702787449546,
            "auditor_fn_violation": 0.031981749311294765,
            "auditor_fp_violation": 0.01909124446630596,
            "ave_precision_score": 0.8601952988439214,
            "fpr": 0.11403508771929824,
            "logloss": 0.48452151017217954,
            "mae": 0.32251802617847397,
            "precision": 0.7846790890269151,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8174438805655636,
            "auditor_fn_violation": 0.0260060256440199,
            "auditor_fp_violation": 0.023942690870713452,
            "ave_precision_score": 0.8367404214791252,
            "fpr": 0.12952799121844127,
            "logloss": 0.5070080071406076,
            "mae": 0.3306432560609672,
            "precision": 0.757700205338809,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6312614205936269,
            "auditor_fn_violation": 0.009048318109322896,
            "auditor_fp_violation": 0.008723253812100344,
            "ave_precision_score": 0.6307460555727751,
            "fpr": 0.044956140350877194,
            "logloss": 10.503879412978286,
            "mae": 0.4676724716520862,
            "precision": 0.7602339181286549,
            "recall": 0.26859504132231404
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6196421183257077,
            "auditor_fn_violation": 0.0005722026297965873,
            "auditor_fp_violation": 0.006070924527879209,
            "ave_precision_score": 0.6167095427733001,
            "fpr": 0.059275521405049394,
            "logloss": 9.38705743639081,
            "mae": 0.44888464767217595,
            "precision": 0.7286432160804021,
            "recall": 0.30851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.628753983031985,
            "auditor_fn_violation": 0.020482184283021614,
            "auditor_fp_violation": 0.043375450893589115,
            "ave_precision_score": 0.6195944476907244,
            "fpr": 0.12828947368421054,
            "logloss": 0.7758425534860014,
            "mae": 0.47982158838656913,
            "precision": 0.6073825503355704,
            "recall": 0.3739669421487603
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5917551514587209,
            "auditor_fn_violation": 0.015381740897307159,
            "auditor_fp_violation": 0.0395369271016127,
            "ave_precision_score": 0.5842207001885629,
            "fpr": 0.15916575192096596,
            "logloss": 0.7906324748804031,
            "mae": 0.48594316552289885,
            "precision": 0.5182724252491694,
            "recall": 0.33191489361702126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6721110967225425,
            "auditor_fn_violation": 0.004820936639118466,
            "auditor_fp_violation": 0.013626721593703884,
            "ave_precision_score": 0.6685603141785581,
            "fpr": 0.08223684210526316,
            "logloss": 3.8088962396553327,
            "mae": 0.4141142629796538,
            "precision": 0.7440273037542662,
            "recall": 0.45041322314049587
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6604087059267647,
            "auditor_fn_violation": 0.0014246677721465836,
            "auditor_fp_violation": 0.006889839726596821,
            "ave_precision_score": 0.6591966111477883,
            "fpr": 0.08781558726673985,
            "logloss": 3.6430751483049217,
            "mae": 0.4142598547510799,
            "precision": 0.7222222222222222,
            "recall": 0.4425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.557268369334914,
            "auditor_fn_violation": 0.0066922212556183875,
            "auditor_fp_violation": 0.0091613379242499,
            "ave_precision_score": 0.5596382712935161,
            "fpr": 0.30153508771929827,
            "logloss": 1.2324422413395781,
            "mae": 0.4917355706229022,
            "precision": 0.5521172638436482,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.576185365679013,
            "auditor_fn_violation": 0.0065464651890604275,
            "auditor_fp_violation": 0.006140619438408369,
            "ave_precision_score": 0.5781169856896158,
            "fpr": 0.305159165751921,
            "logloss": 1.1111227784967435,
            "mae": 0.4850301075845335,
            "precision": 0.5358931552587646,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7461287848887384,
            "auditor_fn_violation": 0.00694142380745252,
            "auditor_fp_violation": 0.011641252664371214,
            "ave_precision_score": 0.7008490557453378,
            "fpr": 0.17434210526315788,
            "logloss": 0.6333533462336586,
            "mae": 0.42695172588553343,
            "precision": 0.6714876033057852,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7730538129495804,
            "auditor_fn_violation": 0.010017049302847015,
            "auditor_fp_violation": 0.009000599874051345,
            "ave_precision_score": 0.7056032557886858,
            "fpr": 0.150384193194292,
            "logloss": 0.6102257227234914,
            "mae": 0.4208136933368071,
            "precision": 0.698237885462555,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8252759745797107,
            "auditor_fn_violation": 0.00672846889952153,
            "auditor_fp_violation": 0.01298368585013937,
            "ave_precision_score": 0.8076449794007644,
            "fpr": 0.0800438596491228,
            "logloss": 0.5197800159993804,
            "mae": 0.3514914202520199,
            "precision": 0.8290398126463701,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.782823062208482,
            "auditor_fn_violation": 0.000859471705163848,
            "auditor_fp_violation": 0.0032184114040786486,
            "ave_precision_score": 0.7609117566081838,
            "fpr": 0.10428100987925357,
            "logloss": 0.5518226720809022,
            "mae": 0.36611686288721607,
            "precision": 0.7800925925925926,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7253446092079603,
            "auditor_fn_violation": 0.010212773669711468,
            "auditor_fp_violation": 0.010216838826037052,
            "ave_precision_score": 0.6596292936485645,
            "fpr": 0.09868421052631579,
            "logloss": 0.6622545848516809,
            "mae": 0.4298754610251962,
            "precision": 0.7428571428571429,
            "recall": 0.5371900826446281
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.713671072319652,
            "auditor_fn_violation": 0.013851974682953027,
            "auditor_fp_violation": 0.009453616792490871,
            "ave_precision_score": 0.643637129337192,
            "fpr": 0.09879253567508232,
            "logloss": 0.6739841076922727,
            "mae": 0.4382312665524781,
            "precision": 0.7264437689969605,
            "recall": 0.5085106382978724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5467814240215427,
            "auditor_fn_violation": 0.012564339567928092,
            "auditor_fp_violation": 0.015412362682406958,
            "ave_precision_score": 0.5480166949351877,
            "fpr": 0.13815789473684212,
            "logloss": 0.6934510914943275,
            "mae": 0.49939446049954805,
            "precision": 0.5743243243243243,
            "recall": 0.3512396694214876
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5448942160752548,
            "auditor_fn_violation": 0.001298549641497543,
            "auditor_fp_violation": 0.010546333425430179,
            "ave_precision_score": 0.5452741909604348,
            "fpr": 0.13391877058177826,
            "logloss": 0.6926694316879941,
            "mae": 0.4990452049069033,
            "precision": 0.5763888888888888,
            "recall": 0.35319148936170214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7798891307070382,
            "auditor_fn_violation": 0.013130709003914755,
            "auditor_fp_violation": 0.02419454008853911,
            "ave_precision_score": 0.7358216216846825,
            "fpr": 0.14912280701754385,
            "logloss": 0.5942008317587156,
            "mae": 0.39108634417827587,
            "precision": 0.7112526539278131,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7650805199113516,
            "auditor_fn_violation": 0.018763575215451807,
            "auditor_fp_violation": 0.01803604720336726,
            "ave_precision_score": 0.7171641797724781,
            "fpr": 0.15916575192096596,
            "logloss": 0.6020163404255868,
            "mae": 0.3924618449785903,
            "precision": 0.6960167714884696,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7752814211409531,
            "auditor_fn_violation": 0.05753407278526897,
            "auditor_fp_violation": 0.02956171093621905,
            "ave_precision_score": 0.7180968889215241,
            "fpr": 0.09320175438596491,
            "logloss": 0.6137905668898009,
            "mae": 0.4341490217239449,
            "precision": 0.7592067988668555,
            "recall": 0.5537190082644629
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7287922186898005,
            "auditor_fn_violation": 0.05362589625615995,
            "auditor_fp_violation": 0.03304285490266359,
            "ave_precision_score": 0.6826801066380688,
            "fpr": 0.11086717892425905,
            "logloss": 0.617659951161748,
            "mae": 0.4342683415970347,
            "precision": 0.7209944751381215,
            "recall": 0.5553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 2917,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.7192180568088494,
            "auditor_fn_violation": 0.009718899521531108,
            "auditor_fp_violation": 0.010011887194622064,
            "ave_precision_score": 0.5201054564200028,
            "fpr": 0.4166666666666667,
            "logloss": 16.33963732954038,
            "mae": 0.5026825554301796,
            "precision": 0.5159235668789809,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.7154368456598286,
            "auditor_fn_violation": 0.010766751523927413,
            "auditor_fp_violation": 0.0164430206769865,
            "ave_precision_score": 0.5097990198624438,
            "fpr": 0.43249176728869376,
            "logloss": 16.35836268275452,
            "mae": 0.5086450689360388,
            "precision": 0.5037783375314862,
            "recall": 0.851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7202245548860565,
            "auditor_fn_violation": 0.08789600550964188,
            "auditor_fp_violation": 0.09899932365961633,
            "ave_precision_score": 0.674197249325937,
            "fpr": 0.2642543859649123,
            "logloss": 0.6902243386026086,
            "mae": 0.4388927355114567,
            "precision": 0.5983333333333334,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7239923899912887,
            "auditor_fn_violation": 0.08012004577621039,
            "auditor_fp_violation": 0.08977700117734617,
            "ave_precision_score": 0.6717786060998703,
            "fpr": 0.278814489571899,
            "logloss": 0.6817508420900971,
            "mae": 0.43539313711921157,
            "precision": 0.5883306320907618,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6600826208761974,
            "auditor_fn_violation": 0.008790053646512998,
            "auditor_fp_violation": 0.0064354812264305625,
            "ave_precision_score": 0.6626824105719494,
            "fpr": 0.03728070175438596,
            "logloss": 2.1540499640963726,
            "mae": 0.47372158507710405,
            "precision": 0.7792207792207793,
            "recall": 0.24793388429752067
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6365979307571246,
            "auditor_fn_violation": 0.0003409860569400286,
            "auditor_fp_violation": 0.00660857098053272,
            "ave_precision_score": 0.6375352288097574,
            "fpr": 0.029637760702524697,
            "logloss": 2.207304292007631,
            "mae": 0.47057664126426413,
            "precision": 0.8014705882352942,
            "recall": 0.23191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7898993617705394,
            "auditor_fn_violation": 0.009689448310859796,
            "auditor_fp_violation": 0.02174024430234465,
            "ave_precision_score": 0.7392728798186903,
            "fpr": 0.13706140350877194,
            "logloss": 4.74450381988239,
            "mae": 0.29520587364220363,
            "precision": 0.7417355371900827,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7739879046527848,
            "auditor_fn_violation": 0.013471284770067973,
            "auditor_fp_violation": 0.016047253149338775,
            "ave_precision_score": 0.7238055534015551,
            "fpr": 0.13062568605927552,
            "logloss": 4.416539629626089,
            "mae": 0.3010601218766124,
            "precision": 0.7384615384615385,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 2917,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5455429647572755,
            "auditor_fn_violation": 0.00821009134406266,
            "auditor_fp_violation": 0.022621536317429084,
            "ave_precision_score": 0.5463899836813915,
            "fpr": 0.18640350877192982,
            "logloss": 1.6796894988381679,
            "mae": 0.49734164034823386,
            "precision": 0.5454545454545454,
            "recall": 0.4214876033057851
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5484447357569914,
            "auditor_fn_violation": 0.0030782165962117817,
            "auditor_fp_violation": 0.027091407364262937,
            "ave_precision_score": 0.5506099943779323,
            "fpr": 0.2030735455543359,
            "logloss": 1.6015699700757566,
            "mae": 0.47761218381417436,
            "precision": 0.5476772616136919,
            "recall": 0.4765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7069452713775238,
            "auditor_fn_violation": 0.006470204436711617,
            "auditor_fp_violation": 0.008787301196917546,
            "ave_precision_score": 0.5411195075260598,
            "fpr": 0.40131578947368424,
            "logloss": 0.7333582931957302,
            "mae": 0.48710537822753713,
            "precision": 0.5402010050251256,
            "recall": 0.8884297520661157
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7077078075840463,
            "auditor_fn_violation": 0.006838405306303573,
            "auditor_fp_violation": 0.009958904893827284,
            "ave_precision_score": 0.5341546478481768,
            "fpr": 0.42371020856201974,
            "logloss": 0.7339370578304539,
            "mae": 0.4882141000680159,
            "precision": 0.5234567901234568,
            "recall": 0.902127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6922965083567254,
            "mae": 0.49951137314762983,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6927671684725341,
            "mae": 0.499746683334807,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6138343853930792,
            "auditor_fn_violation": 0.006225532840365375,
            "auditor_fp_violation": 0.012922200360714875,
            "ave_precision_score": 0.6159262337314197,
            "fpr": 0.29605263157894735,
            "logloss": 0.6756515259329106,
            "mae": 0.4878239489340207,
            "precision": 0.5741324921135647,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.5884811664694284,
            "auditor_fn_violation": 0.007041595627904803,
            "auditor_fp_violation": 0.015768473507222155,
            "ave_precision_score": 0.5898477748149051,
            "fpr": 0.29527991218441274,
            "logloss": 0.6774291884372782,
            "mae": 0.48834304473926154,
            "precision": 0.5689102564102564,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.649670202099339,
            "auditor_fn_violation": 0.009983960417572857,
            "auditor_fp_violation": 0.05981257173307101,
            "ave_precision_score": 0.649988940759312,
            "fpr": 0.2708333333333333,
            "logloss": 0.9952279008168808,
            "mae": 0.4180898964654562,
            "precision": 0.6399416909620991,
            "recall": 0.9070247933884298
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6629406637226325,
            "auditor_fn_violation": 0.004969988555947406,
            "auditor_fp_violation": 0.0366122299633355,
            "ave_precision_score": 0.6631897821123417,
            "fpr": 0.25466520307354557,
            "logloss": 1.0947172543715042,
            "mae": 0.41266912437972475,
            "precision": 0.6403100775193798,
            "recall": 0.8787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.704347530988866,
            "auditor_fn_violation": 0.0257856676816007,
            "auditor_fp_violation": 0.019864936874897533,
            "ave_precision_score": 0.6528254686376485,
            "fpr": 0.16885964912280702,
            "logloss": 0.6499863752529624,
            "mae": 0.4608928980469181,
            "precision": 0.6630196936542669,
            "recall": 0.6260330578512396
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6809344555343674,
            "auditor_fn_violation": 0.018480977181960442,
            "auditor_fp_violation": 0.009983795933301976,
            "ave_precision_score": 0.6196301482937063,
            "fpr": 0.18880351262349068,
            "logloss": 0.6590741316509298,
            "mae": 0.4651067570980503,
            "precision": 0.6363636363636364,
            "recall": 0.6404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8390316714724763,
            "auditor_fn_violation": 0.01239216325938815,
            "auditor_fp_violation": 0.02191701508444007,
            "ave_precision_score": 0.8036658797041702,
            "fpr": 0.09978070175438597,
            "logloss": 0.5190263702301335,
            "mae": 0.3460600878471476,
            "precision": 0.7941176470588235,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8275447635292743,
            "auditor_fn_violation": 0.0014713781909054782,
            "auditor_fp_violation": 0.01303294826895266,
            "ave_precision_score": 0.7785583479055922,
            "fpr": 0.1141602634467618,
            "logloss": 0.5308299864665625,
            "mae": 0.3523999156775904,
            "precision": 0.7683741648106904,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.865753320851545,
            "auditor_fn_violation": 0.005156227345222568,
            "auditor_fp_violation": 0.009391908509591741,
            "ave_precision_score": 0.8328574797007157,
            "fpr": 0.0625,
            "logloss": 0.4934332180208172,
            "mae": 0.3355016816864934,
            "precision": 0.8542199488491049,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7404988184221454,
            "auditor_fn_violation": 0.006959852395076724,
            "auditor_fp_violation": 0.0059589148502430635,
            "ave_precision_score": 0.7913475140911873,
            "fpr": 0.07793633369923161,
            "logloss": 0.5303855900772316,
            "mae": 0.3534626556084002,
            "precision": 0.8136482939632546,
            "recall": 0.6595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.666957205786618,
            "auditor_fn_violation": 0.008925982311149775,
            "auditor_fp_violation": 0.008067408591572395,
            "ave_precision_score": 0.6681681011193832,
            "fpr": 0.3256578947368421,
            "logloss": 0.7530402835976586,
            "mae": 0.4429077047593238,
            "precision": 0.5880721220527045,
            "recall": 0.8760330578512396
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6802914203790704,
            "auditor_fn_violation": 0.010846159235817552,
            "auditor_fp_violation": 0.010489084034638375,
            "ave_precision_score": 0.6813149170256846,
            "fpr": 0.33040614709110866,
            "logloss": 0.7270284427291176,
            "mae": 0.43816835270493276,
            "precision": 0.5748587570621468,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.732021833452493,
            "auditor_fn_violation": 0.004250036247643902,
            "auditor_fp_violation": 0.009151090342679136,
            "ave_precision_score": 0.6933253718123389,
            "fpr": 0.30153508771929827,
            "logloss": 3.4329505090875365,
            "mae": 0.4027330789436156,
            "precision": 0.5852187028657617,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6948315206911132,
            "auditor_fn_violation": 0.00016348646565616547,
            "auditor_fp_violation": 0.018680725125761986,
            "ave_precision_score": 0.657805641647135,
            "fpr": 0.3216245883644347,
            "logloss": 3.498412362186364,
            "mae": 0.4341244547642137,
            "precision": 0.5580693815987934,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8527252465355264,
            "auditor_fn_violation": 0.014197749021313615,
            "auditor_fp_violation": 0.008262112641416627,
            "ave_precision_score": 0.8454740628852666,
            "fpr": 0.0756578947368421,
            "logloss": 0.5005079404987041,
            "mae": 0.32696185653963894,
            "precision": 0.8325242718446602,
            "recall": 0.7086776859504132
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8175361937710185,
            "auditor_fn_violation": 0.01010112805661303,
            "auditor_fp_violation": 0.010255108263576198,
            "ave_precision_score": 0.8062044667493639,
            "fpr": 0.09330406147091108,
            "logloss": 0.5277862556134659,
            "mae": 0.33860432781876115,
            "precision": 0.7926829268292683,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 2917,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7726351824617308,
            "auditor_fn_violation": 0.0028680948238364507,
            "auditor_fp_violation": 0.01469759386784719,
            "ave_precision_score": 0.5518388571248647,
            "fpr": 0.4243421052631579,
            "logloss": 0.7569010993642354,
            "mae": 0.4729205077808154,
            "precision": 0.5520833333333334,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7643039759048627,
            "auditor_fn_violation": 0.003433215778779457,
            "auditor_fp_violation": 0.0054411812291693135,
            "ave_precision_score": 0.5356252927522852,
            "fpr": 0.44017563117453345,
            "logloss": 0.7729920336336574,
            "mae": 0.48019923003130766,
            "precision": 0.5358796296296297,
            "recall": 0.9851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7969213493692443,
            "auditor_fn_violation": 0.003960055096418734,
            "auditor_fp_violation": 0.01017584849975406,
            "ave_precision_score": 0.7909937116787134,
            "fpr": 0.13048245614035087,
            "logloss": 0.5599246485897775,
            "mae": 0.36044551872979164,
            "precision": 0.7418655097613883,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7874153795340522,
            "auditor_fn_violation": 0.005331994301328915,
            "auditor_fp_violation": 0.007840677434530346,
            "ave_precision_score": 0.7631064802770661,
            "fpr": 0.13830954994511527,
            "logloss": 0.583747070556787,
            "mae": 0.37198827137636953,
            "precision": 0.7278617710583153,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8585822314548726,
            "auditor_fn_violation": 0.007272183558068724,
            "auditor_fp_violation": 0.016293654697491403,
            "ave_precision_score": 0.8592617371580318,
            "fpr": 0.18421052631578946,
            "logloss": 0.5239346732987604,
            "mae": 0.3491698957605925,
            "precision": 0.7037037037037037,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8169269649121139,
            "auditor_fn_violation": 0.010379055048228511,
            "auditor_fp_violation": 0.005232096497581841,
            "ave_precision_score": 0.8178690593360934,
            "fpr": 0.18331503841931943,
            "logloss": 0.5661058606751704,
            "mae": 0.3685395964722913,
            "precision": 0.6935779816513762,
            "recall": 0.8042553191489362
        }
    }
]