[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6264654904879075,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.6277346973314475,
            "fpr": 0.3607456140350877,
            "logloss": 0.6667629816852219,
            "mae": 0.4670307508326675,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.5750789134430748,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.01918077300826161,
            "ave_precision_score": 0.5765974429941002,
            "fpr": 0.3787047200878156,
            "logloss": 0.6865584568146905,
            "mae": 0.4753003959450973,
            "precision": 0.5627376425855514,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7266441565661825,
            "auditor_fn_violation": 0.010471491228070175,
            "auditor_fp_violation": 0.005002741228070178,
            "ave_precision_score": 0.7270875851879852,
            "fpr": 0.14802631578947367,
            "logloss": 0.6522704644492704,
            "mae": 0.4715883946863183,
            "precision": 0.6616541353383458,
            "recall": 0.55
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.738721425922213,
            "auditor_fn_violation": 0.0102544150953883,
            "auditor_fp_violation": 0.01250417601298144,
            "ave_precision_score": 0.7391821204676148,
            "fpr": 0.14489571899012074,
            "logloss": 0.6447570030176746,
            "mae": 0.46817673500688617,
            "precision": 0.6641221374045801,
            "recall": 0.5506329113924051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5396279423999966,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.542947302153305,
            "fpr": 0.05592105263157895,
            "logloss": 0.6955259045151654,
            "mae": 0.5007874185971001,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5443842232197416,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.0078571841238662,
            "ave_precision_score": 0.5346514056623012,
            "fpr": 0.05598243688254665,
            "logloss": 0.6950813984676113,
            "mae": 0.5005719694099363,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.626896320122358,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.6281655306452212,
            "fpr": 0.3607456140350877,
            "logloss": 0.6666186257392819,
            "mae": 0.46679214508223693,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.5752130279695825,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.015636499734995885,
            "ave_precision_score": 0.5767298362882044,
            "fpr": 0.37760702524698136,
            "logloss": 0.6867209569612208,
            "mae": 0.4751567635623867,
            "precision": 0.5634517766497462,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6268401388835131,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.6281094895682997,
            "fpr": 0.3607456140350877,
            "logloss": 0.6665888473876438,
            "mae": 0.4668000245613879,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.5752417973648118,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.015636499734995885,
            "ave_precision_score": 0.5767588061898697,
            "fpr": 0.37760702524698136,
            "logloss": 0.6866804601766698,
            "mae": 0.4751625676546348,
            "precision": 0.5634517766497462,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6638493100108499,
            "auditor_fn_violation": 0.032223135964912296,
            "auditor_fp_violation": 0.03303179824561404,
            "ave_precision_score": 0.6654789039648671,
            "fpr": 0.14802631578947367,
            "logloss": 0.938292501998493,
            "mae": 0.3933471814566713,
            "precision": 0.6853146853146853,
            "recall": 0.6125
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6588068868951565,
            "auditor_fn_violation": 0.02163431477441676,
            "auditor_fp_violation": 0.03167992524622778,
            "ave_precision_score": 0.6604679527321817,
            "fpr": 0.1394072447859495,
            "logloss": 0.8540284556799351,
            "mae": 0.39101427566549635,
            "precision": 0.6924939467312349,
            "recall": 0.6033755274261603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5757353250512677,
            "auditor_fn_violation": 0.011650219298245624,
            "auditor_fp_violation": 0.0020939936647173495,
            "ave_precision_score": 0.5772982602123536,
            "fpr": 0.06469298245614036,
            "logloss": 0.6936503240187123,
            "mae": 0.49835209351384374,
            "precision": 0.5426356589147286,
            "recall": 0.14583333333333334
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5902786113863117,
            "auditor_fn_violation": 0.00034737178507412124,
            "auditor_fp_violation": 0.00516192882817936,
            "ave_precision_score": 0.5923064997555743,
            "fpr": 0.0570801317233809,
            "logloss": 0.6932320571142067,
            "mae": 0.4987400412706722,
            "precision": 0.5666666666666667,
            "recall": 0.14345991561181434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.970779375617635,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5137276252526206,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5157390866713936,
            "fpr": 0.05592105263157895,
            "logloss": 0.6956595377723666,
            "mae": 0.5008551485901862,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5046255165639124,
            "auditor_fn_violation": 0.014200558573830405,
            "auditor_fp_violation": 0.009030235589929343,
            "ave_precision_score": 0.5067075496219086,
            "fpr": 0.0570801317233809,
            "logloss": 0.6954206155198558,
            "mae": 0.50073154419497,
            "precision": 0.5272727272727272,
            "recall": 0.12236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8463936763225017,
            "auditor_fn_violation": 0.03457373903508772,
            "auditor_fp_violation": 0.022059271442495122,
            "ave_precision_score": 0.8466290859224577,
            "fpr": 0.13486842105263158,
            "logloss": 0.8262420122767689,
            "mae": 0.26810089393296815,
            "precision": 0.7530120481927711,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.831167576388384,
            "auditor_fn_violation": 0.02163431477441677,
            "auditor_fp_violation": 0.02558608615271774,
            "ave_precision_score": 0.831597313769581,
            "fpr": 0.1207464324917673,
            "logloss": 0.7906526811795656,
            "mae": 0.26854012576847,
            "precision": 0.7629310344827587,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.970779375617635,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.970779375617635,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 28699,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.970779375617635,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7833519976147563,
            "auditor_fn_violation": 0.015385142543859656,
            "auditor_fp_violation": 0.023386736517218978,
            "ave_precision_score": 0.7848923189169139,
            "fpr": 0.08991228070175439,
            "logloss": 0.6182819289251377,
            "mae": 0.34898121784167496,
            "precision": 0.787012987012987,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8106855612404127,
            "auditor_fn_violation": 0.013339076546846561,
            "auditor_fp_violation": 0.01600574719861746,
            "ave_precision_score": 0.8110107017036983,
            "fpr": 0.06915477497255763,
            "logloss": 0.610331551080706,
            "mae": 0.3481666480112334,
            "precision": 0.8173913043478261,
            "recall": 0.5949367088607594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6876850660624712,
            "auditor_fn_violation": 0.02561677631578949,
            "auditor_fp_violation": 0.01640168128654971,
            "ave_precision_score": 0.6926251331637111,
            "fpr": 0.09100877192982457,
            "logloss": 5.388022002044346,
            "mae": 0.4445629176624606,
            "precision": 0.7381703470031545,
            "recall": 0.4875
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7284955330141408,
            "auditor_fn_violation": 0.03913490530645139,
            "auditor_fp_violation": 0.012338391437477862,
            "ave_precision_score": 0.7329998657876313,
            "fpr": 0.0801317233809001,
            "logloss": 4.864157691708618,
            "mae": 0.4092293553229681,
            "precision": 0.7732919254658385,
            "recall": 0.5253164556962026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 28699,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5102720467980189,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.004385964912280705,
            "ave_precision_score": 0.5122895238874396,
            "fpr": 0.05701754385964912,
            "logloss": 0.695451355649226,
            "mae": 0.5007137705555611,
            "precision": 0.5315315315315315,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.497013236423762,
            "auditor_fn_violation": 0.013102863732996168,
            "auditor_fp_violation": 0.009123175427711648,
            "ave_precision_score": 0.4987786476630077,
            "fpr": 0.06037321624588365,
            "logloss": 0.6967626663815668,
            "mae": 0.5011641155482647,
            "precision": 0.5132743362831859,
            "recall": 0.12236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5769844453732692,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.5786504862314577,
            "fpr": 0.4407894736842105,
            "logloss": 0.6834535649402946,
            "mae": 0.4878343733909883,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5108103695690662,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.512451869236952,
            "fpr": 0.4500548847420417,
            "logloss": 0.6983091164644688,
            "mae": 0.49418994872682576,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8133683962592424,
            "auditor_fn_violation": 0.00910087719298246,
            "auditor_fp_violation": 0.02187906107862249,
            "ave_precision_score": 0.8136691976335428,
            "fpr": 0.1787280701754386,
            "logloss": 0.6817809763469537,
            "mae": 0.3678465819001072,
            "precision": 0.6930320150659134,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8382243898745405,
            "auditor_fn_violation": 0.016636792693150295,
            "auditor_fp_violation": 0.018615598319044885,
            "ave_precision_score": 0.8395438204910717,
            "fpr": 0.16136114160263446,
            "logloss": 0.6001854568957989,
            "mae": 0.34515040805710406,
            "precision": 0.7226415094339622,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5694363547844628,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5701325240136899,
            "fpr": 0.05592105263157895,
            "logloss": 0.6956273515764761,
            "mae": 0.5008159947761318,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5604004624187031,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.006312373306673837,
            "ave_precision_score": 0.5603582390318804,
            "fpr": 0.0570801317233809,
            "logloss": 0.6951704788007326,
            "mae": 0.5005964713025957,
            "precision": 0.5229357798165137,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.757100086254985,
            "auditor_fn_violation": 0.017680921052631582,
            "auditor_fp_violation": 0.006665245289148801,
            "ave_precision_score": 0.7576123043595688,
            "fpr": 0.10307017543859649,
            "logloss": 0.6422920883817,
            "mae": 0.46656188002803867,
            "precision": 0.739612188365651,
            "recall": 0.55625
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7715092650712128,
            "auditor_fn_violation": 0.013596131667801423,
            "auditor_fp_violation": 0.011469278359837935,
            "ave_precision_score": 0.771941603997008,
            "fpr": 0.08562019758507135,
            "logloss": 0.6355651388557477,
            "mae": 0.46355407692402045,
            "precision": 0.7685459940652819,
            "recall": 0.5464135021097046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7682836176172535,
            "auditor_fn_violation": 0.052282072368421056,
            "auditor_fp_violation": 0.054687500000000014,
            "ave_precision_score": 0.7688794402781844,
            "fpr": 0.11513157894736842,
            "logloss": 0.7864433773259436,
            "mae": 0.387561678319212,
            "precision": 0.7361809045226131,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.808720072244388,
            "auditor_fn_violation": 0.04938700458993919,
            "auditor_fp_violation": 0.05069240179147817,
            "ave_precision_score": 0.8089706525570474,
            "fpr": 0.09110867178924259,
            "logloss": 0.6999813458904394,
            "mae": 0.36955439722513833,
            "precision": 0.7792553191489362,
            "recall": 0.6181434599156118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8149417377747067,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.7118453373561006,
            "fpr": 0.02850877192982456,
            "logloss": 0.6080984955189799,
            "mae": 0.39561808347934857,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.8055674241855344,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.006543466957375782,
            "ave_precision_score": 0.7018224389221488,
            "fpr": 0.026344676180021953,
            "logloss": 0.5952237367780097,
            "mae": 0.3975197802390801,
            "precision": 0.8883720930232558,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6288617693569887,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.630127451140607,
            "fpr": 0.3607456140350877,
            "logloss": 0.6659772073930107,
            "mae": 0.4662150532791489,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5759918525395742,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.013935951892330461,
            "ave_precision_score": 0.5775161089706384,
            "fpr": 0.3754116355653128,
            "logloss": 0.6870246007407359,
            "mae": 0.47486019603147467,
            "precision": 0.5648854961832062,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7680048045653376,
            "auditor_fn_violation": 0.013760964912280713,
            "auditor_fp_violation": 0.0032336338531513994,
            "ave_precision_score": 0.7685142469868829,
            "fpr": 0.07675438596491228,
            "logloss": 0.6355125868736844,
            "mae": 0.4607398122418345,
            "precision": 0.7734627831715211,
            "recall": 0.4979166666666667
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7830696990058442,
            "auditor_fn_violation": 0.011560533007267046,
            "auditor_fp_violation": 0.011841037710967154,
            "ave_precision_score": 0.7834926700595861,
            "fpr": 0.06476399560922064,
            "logloss": 0.6280022351872956,
            "mae": 0.45748872961746745,
            "precision": 0.7965517241379311,
            "recall": 0.4873417721518987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5397458041666154,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5428909165860752,
            "fpr": 0.05592105263157895,
            "logloss": 0.6955259165345232,
            "mae": 0.5007874215054408,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5435364795072338,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.0078571841238662,
            "ave_precision_score": 0.5344044442908177,
            "fpr": 0.05598243688254665,
            "logloss": 0.6950814097393431,
            "mae": 0.5005719719943309,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8460317249427219,
            "auditor_fn_violation": 0.03181652046783626,
            "auditor_fp_violation": 0.022802956465237167,
            "ave_precision_score": 0.846268115323769,
            "fpr": 0.13596491228070176,
            "logloss": 0.8309345826073665,
            "mae": 0.2679062360983603,
            "precision": 0.752,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8307663491555072,
            "auditor_fn_violation": 0.02163431477441677,
            "auditor_fp_violation": 0.02558608615271774,
            "ave_precision_score": 0.8312857049261316,
            "fpr": 0.1207464324917673,
            "logloss": 0.795722301770831,
            "mae": 0.2685277261054898,
            "precision": 0.7629310344827587,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6681508878106683,
            "auditor_fn_violation": 0.02680007309941521,
            "auditor_fp_violation": 0.018975389863547763,
            "ave_precision_score": 0.6698596749614993,
            "fpr": 0.18859649122807018,
            "logloss": 1.0098607885197586,
            "mae": 0.403349696237856,
            "precision": 0.6460905349794238,
            "recall": 0.6541666666666667
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6844382819977596,
            "auditor_fn_violation": 0.023822757020383778,
            "auditor_fp_violation": 0.03289567879992063,
            "ave_precision_score": 0.6860937150470785,
            "fpr": 0.17014270032930845,
            "logloss": 0.9091553138305131,
            "mae": 0.37979509660351457,
            "precision": 0.6784232365145229,
            "recall": 0.689873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6279819662649953,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.629250674645699,
            "fpr": 0.3607456140350877,
            "logloss": 0.6662390237580162,
            "mae": 0.4663316134052972,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5755096625739154,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.013935951892330461,
            "ave_precision_score": 0.5770215335416539,
            "fpr": 0.3754116355653128,
            "logloss": 0.6869333989196696,
            "mae": 0.47488159927591667,
            "precision": 0.5648854961832062,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6638616734819498,
            "auditor_fn_violation": 0.02573556286549708,
            "auditor_fp_violation": 0.01694231237816764,
            "ave_precision_score": 0.6655782910455847,
            "fpr": 0.18092105263157895,
            "logloss": 1.037426148401558,
            "mae": 0.39826370367313035,
            "precision": 0.6533613445378151,
            "recall": 0.6479166666666667
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6774460288749132,
            "auditor_fn_violation": 0.026254359515902687,
            "auditor_fp_violation": 0.03218481463526138,
            "ave_precision_score": 0.6791061802874752,
            "fpr": 0.16465422612513722,
            "logloss": 0.9531039296449153,
            "mae": 0.3779605365904438,
            "precision": 0.6774193548387096,
            "recall": 0.6645569620253164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8133656986503983,
            "auditor_fn_violation": 0.00910087719298246,
            "auditor_fp_violation": 0.02187906107862249,
            "ave_precision_score": 0.8136665152026891,
            "fpr": 0.1787280701754386,
            "logloss": 0.681796647634623,
            "mae": 0.36784475656924387,
            "precision": 0.6930320150659134,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8382220862596221,
            "auditor_fn_violation": 0.016636792693150295,
            "auditor_fp_violation": 0.018615598319044885,
            "ave_precision_score": 0.8395415169275079,
            "fpr": 0.16136114160263446,
            "logloss": 0.6001906031321897,
            "mae": 0.3451458944692413,
            "precision": 0.7226415094339622,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6334060769644387,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.024457846003898654,
            "ave_precision_score": 0.6346617725650003,
            "fpr": 0.3618421052631579,
            "logloss": 0.665204487790108,
            "mae": 0.4649820925030661,
            "precision": 0.578005115089514,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.576624130458415,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.014526245456623493,
            "ave_precision_score": 0.5781393790706614,
            "fpr": 0.3721185510428101,
            "logloss": 0.6877232326557557,
            "mae": 0.4740553361033503,
            "precision": 0.5670498084291188,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6885321031870137,
            "auditor_fn_violation": 0.02561677631578949,
            "auditor_fp_violation": 0.01640168128654971,
            "ave_precision_score": 0.693529264725767,
            "fpr": 0.09100877192982457,
            "logloss": 5.3640185355238765,
            "mae": 0.4441844191619979,
            "precision": 0.7381703470031545,
            "recall": 0.4875
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7290805286924195,
            "auditor_fn_violation": 0.03913490530645139,
            "auditor_fp_violation": 0.012338391437477862,
            "ave_precision_score": 0.7335400540222794,
            "fpr": 0.0801317233809001,
            "logloss": 4.849326502622243,
            "mae": 0.40876861944275544,
            "precision": 0.7732919254658385,
            "recall": 0.5253164556962026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6824516731959158,
            "auditor_fn_violation": 0.033881578947368415,
            "auditor_fp_violation": 0.031189083820662766,
            "ave_precision_score": 0.6844053423005036,
            "fpr": 0.1513157894736842,
            "logloss": 0.798358497386219,
            "mae": 0.3930943509929644,
            "precision": 0.6827586206896552,
            "recall": 0.61875
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6823363435133496,
            "auditor_fn_violation": 0.020228616950816795,
            "auditor_fp_violation": 0.031594521070968364,
            "ave_precision_score": 0.6833803745608638,
            "fpr": 0.14270032930845225,
            "logloss": 0.7558688338362471,
            "mae": 0.3895695674018837,
            "precision": 0.6897374701670644,
            "recall": 0.609704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8099877927648487,
            "auditor_fn_violation": 0.0066840277777777775,
            "auditor_fp_violation": 0.022044042397660817,
            "ave_precision_score": 0.8102983900802369,
            "fpr": 0.16776315789473684,
            "logloss": 0.761926030556345,
            "mae": 0.37009347249908897,
            "precision": 0.701171875,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.832296926091117,
            "auditor_fn_violation": 0.01298244151417045,
            "auditor_fp_violation": 0.026163820279472613,
            "ave_precision_score": 0.8335906285517187,
            "fpr": 0.1525795828759605,
            "logloss": 0.6641942878378915,
            "mae": 0.35052252776202736,
            "precision": 0.7258382642998028,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7598256229884481,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.760724026162948,
            "fpr": 0.02850877192982456,
            "logloss": 0.6099214834038557,
            "mae": 0.39636112697087555,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7392850677047024,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.002938908383926935,
            "ave_precision_score": 0.7393439984794321,
            "fpr": 0.02305159165751921,
            "logloss": 0.5966009848816065,
            "mae": 0.39855420021452703,
            "precision": 0.9009433962264151,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8383682601408737,
            "auditor_fn_violation": 0.009777046783625731,
            "auditor_fp_violation": 0.023346125730994153,
            "ave_precision_score": 0.8385758025061522,
            "fpr": 0.1524122807017544,
            "logloss": 0.7204788384776467,
            "mae": 0.3422804166232174,
            "precision": 0.7300970873786408,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8571494634512373,
            "auditor_fn_violation": 0.01396434575997999,
            "auditor_fp_violation": 0.025352480614508167,
            "ave_precision_score": 0.8575231118420008,
            "fpr": 0.12952799121844127,
            "logloss": 0.622329061770659,
            "mae": 0.3193139471601165,
            "precision": 0.7625754527162978,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8149417377747067,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.7118453373561006,
            "fpr": 0.02850877192982456,
            "logloss": 0.6082001489942213,
            "mae": 0.3956101454341,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8090285108269104,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.002938908383926935,
            "ave_precision_score": 0.7018224389221488,
            "fpr": 0.02305159165751921,
            "logloss": 0.59407190332687,
            "mae": 0.3968958635339115,
            "precision": 0.9009433962264151,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5483216577189627,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5409688757387869,
            "fpr": 0.05592105263157895,
            "logloss": 0.6951376961780518,
            "mae": 0.5005822450641477,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5453623553207796,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.007211629034405323,
            "ave_precision_score": 0.5360253753097783,
            "fpr": 0.054884742041712405,
            "logloss": 0.694096683140552,
            "mae": 0.5000259922704896,
            "precision": 0.5327102803738317,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.758587295830232,
            "auditor_fn_violation": 0.014254385964912275,
            "auditor_fp_violation": 0.0020965318388564,
            "ave_precision_score": 0.7590787128933567,
            "fpr": 0.07785087719298246,
            "logloss": 0.642676748860572,
            "mae": 0.4655381713487339,
            "precision": 0.7717041800643086,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7701859448222874,
            "auditor_fn_violation": 0.012466015460360275,
            "auditor_fp_violation": 0.012185166299512445,
            "ave_precision_score": 0.7706114711409199,
            "fpr": 0.07464324917672886,
            "logloss": 0.6352924918061182,
            "mae": 0.46234377243777924,
            "precision": 0.7755775577557755,
            "recall": 0.4957805907172996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.546235000505539,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5391786939757942,
            "fpr": 0.05592105263157895,
            "logloss": 0.6956231154871676,
            "mae": 0.5008217584864613,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5382818268202452,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.0078571841238662,
            "ave_precision_score": 0.5299182501137872,
            "fpr": 0.05598243688254665,
            "logloss": 0.6951463139357092,
            "mae": 0.5005879402814921,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.658280331697854,
            "auditor_fn_violation": 0.028106725146198833,
            "auditor_fp_violation": 0.02399082196231319,
            "ave_precision_score": 0.6600106465928955,
            "fpr": 0.18859649122807018,
            "logloss": 1.0522783550681456,
            "mae": 0.3998060506708757,
            "precision": 0.6416666666666667,
            "recall": 0.6416666666666667
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6704983665682405,
            "auditor_fn_violation": 0.027840690667741214,
            "auditor_fp_violation": 0.035442732732657314,
            "ave_precision_score": 0.6721656281279934,
            "fpr": 0.17014270032930845,
            "logloss": 0.9713509890032896,
            "mae": 0.37989674128348905,
            "precision": 0.6695095948827292,
            "recall": 0.6624472573839663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6322543685071421,
            "auditor_fn_violation": 0.012225877192982458,
            "auditor_fp_violation": 0.02232577972709552,
            "ave_precision_score": 0.6335128513746509,
            "fpr": 0.3607456140350877,
            "logloss": 0.6654984374413023,
            "mae": 0.46543646455954824,
            "precision": 0.5787451984635084,
            "recall": 0.9416666666666667
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.5769970081159257,
            "auditor_fn_violation": 0.01347802526087621,
            "auditor_fp_violation": 0.013908321129746526,
            "ave_precision_score": 0.5785149381956705,
            "fpr": 0.3743139407244786,
            "logloss": 0.6874838527193059,
            "mae": 0.47436721740713755,
            "precision": 0.5656050955414013,
            "recall": 0.9367088607594937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5940665916138794,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.5976016002567477,
            "fpr": 0.4407894736842105,
            "logloss": 0.6784830023686121,
            "mae": 0.48703914622596484,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5330530862604674,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.5417876129174428,
            "fpr": 0.4500548847420417,
            "logloss": 0.685493083068067,
            "mae": 0.49081901213078544,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8422580136066384,
            "auditor_fn_violation": 0.013109923245614037,
            "auditor_fp_violation": 0.009183114035087724,
            "ave_precision_score": 0.8424822050760777,
            "fpr": 0.07236842105263158,
            "logloss": 0.6878702705380796,
            "mae": 0.31359109897956733,
            "precision": 0.8303341902313625,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8633885308905616,
            "auditor_fn_violation": 0.01802164820964582,
            "auditor_fp_violation": 0.011976679636379165,
            "ave_precision_score": 0.8638013534205389,
            "fpr": 0.06147091108671789,
            "logloss": 0.5965566477875685,
            "mae": 0.28923307270106885,
            "precision": 0.8571428571428571,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7791921577835295,
            "auditor_fn_violation": 0.05078125000000001,
            "auditor_fp_violation": 0.05290570175438597,
            "ave_precision_score": 0.7794692027964629,
            "fpr": 0.1118421052631579,
            "logloss": 0.8249877173458557,
            "mae": 0.38909027416499203,
            "precision": 0.7397959183673469,
            "recall": 0.6041666666666666
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8025198645581222,
            "auditor_fn_violation": 0.048368047353721744,
            "auditor_fp_violation": 0.0485824162850691,
            "ave_precision_score": 0.8032200045552922,
            "fpr": 0.08781558726673985,
            "logloss": 0.7249505261062206,
            "mae": 0.37025388875555,
            "precision": 0.784366576819407,
            "recall": 0.6139240506329114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5901124393790871,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.5949034142228455,
            "fpr": 0.4407894736842105,
            "logloss": 0.6815243245622481,
            "mae": 0.4895321324859795,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5256241793016292,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.5353875278833741,
            "fpr": 0.4500548847420417,
            "logloss": 0.684530871239774,
            "mae": 0.49158912082534983,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.689087930368981,
            "auditor_fn_violation": 0.02670413011695908,
            "auditor_fp_violation": 0.0180921052631579,
            "ave_precision_score": 0.6939715754410464,
            "fpr": 0.09320175438596491,
            "logloss": 5.33429513749025,
            "mae": 0.44357484728549934,
            "precision": 0.734375,
            "recall": 0.4895833333333333
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7295877576107122,
            "auditor_fn_violation": 0.03969764759827147,
            "auditor_fp_violation": 0.01221028517458874,
            "ave_precision_score": 0.7340475785697378,
            "fpr": 0.08232711306256861,
            "logloss": 4.830744431228669,
            "mae": 0.40807898896044537,
            "precision": 0.7692307692307693,
            "recall": 0.5274261603375527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7696875793681939,
            "auditor_fn_violation": 0.05278234649122807,
            "auditor_fp_violation": 0.055875365497076036,
            "ave_precision_score": 0.7702598757197873,
            "fpr": 0.11732456140350878,
            "logloss": 0.7531318678825168,
            "mae": 0.38397211358782796,
            "precision": 0.7331670822942643,
            "recall": 0.6125
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8114764343490222,
            "auditor_fn_violation": 0.05040596182615663,
            "auditor_fp_violation": 0.05139573029361453,
            "ave_precision_score": 0.8117268099408151,
            "fpr": 0.09220636663007684,
            "logloss": 0.6765129414196094,
            "mae": 0.3673594456433458,
            "precision": 0.7783641160949868,
            "recall": 0.6223628691983122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6276700546221146,
            "auditor_fn_violation": 0.015250365497076023,
            "auditor_fp_violation": 0.02706455084470437,
            "ave_precision_score": 0.6289195034957948,
            "fpr": 0.35635964912280704,
            "logloss": 0.6704665664585961,
            "mae": 0.46430169500557605,
            "precision": 0.576271186440678,
            "recall": 0.9208333333333333
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.5773601478259649,
            "auditor_fn_violation": 0.013943503452875544,
            "auditor_fp_violation": 0.015201943196175908,
            "ave_precision_score": 0.5788902008868253,
            "fpr": 0.3600439077936334,
            "logloss": 0.6879122324624382,
            "mae": 0.47222347571039175,
            "precision": 0.5644090305444888,
            "recall": 0.8966244725738397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7931407689907018,
            "auditor_fn_violation": 0.012733004385964922,
            "auditor_fp_violation": 0.019924666991552962,
            "ave_precision_score": 0.7946258082892527,
            "fpr": 0.07785087719298246,
            "logloss": 0.6171463340185003,
            "mae": 0.34656309355213716,
            "precision": 0.8081081081081081,
            "recall": 0.6229166666666667
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8180761399205034,
            "auditor_fn_violation": 0.011004738151148418,
            "auditor_fp_violation": 0.014119319680387437,
            "ave_precision_score": 0.8183544338587471,
            "fpr": 0.06476399560922064,
            "logloss": 0.6114421405256621,
            "mae": 0.34633370711438516,
            "precision": 0.8238805970149253,
            "recall": 0.5822784810126582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5483241165697349,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5409688757387869,
            "fpr": 0.05592105263157895,
            "logloss": 0.6951406905571693,
            "mae": 0.5005828071581689,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5453605099152203,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.007211629034405323,
            "ave_precision_score": 0.536020307696648,
            "fpr": 0.054884742041712405,
            "logloss": 0.6940994359862545,
            "mae": 0.5000264484979188,
            "precision": 0.5327102803738317,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5483216577189627,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5409688757387869,
            "fpr": 0.05592105263157895,
            "logloss": 0.6951491108520012,
            "mae": 0.5005843743289772,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5453623553207796,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.007211629034405323,
            "ave_precision_score": 0.5360253753097783,
            "fpr": 0.054884742041712405,
            "logloss": 0.6941071874484211,
            "mae": 0.5000277240765736,
            "precision": 0.5327102803738317,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8411229608581751,
            "auditor_fn_violation": 0.013530244883040936,
            "auditor_fp_violation": 0.011190809779077323,
            "ave_precision_score": 0.8413449502825864,
            "fpr": 0.07346491228070176,
            "logloss": 0.6485089766324998,
            "mae": 0.3143640870800084,
            "precision": 0.8282051282051283,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.862324195659485,
            "auditor_fn_violation": 0.015312148286067615,
            "auditor_fp_violation": 0.012165071199451406,
            "ave_precision_score": 0.8627396643399137,
            "fpr": 0.06476399560922064,
            "logloss": 0.5707793574066743,
            "mae": 0.2898057391140604,
            "precision": 0.850632911392405,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7644355444176505,
            "auditor_fn_violation": 0.006391630116959065,
            "auditor_fp_violation": 0.004061078622482133,
            "ave_precision_score": 0.7650435329609115,
            "fpr": 0.047149122807017545,
            "logloss": 0.6732651727124459,
            "mae": 0.39049888509848196,
            "precision": 0.8185654008438819,
            "recall": 0.4041666666666667
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7714997767302137,
            "auditor_fn_violation": 0.006919645958676646,
            "auditor_fp_violation": 0.00570198464231978,
            "ave_precision_score": 0.7719442019930286,
            "fpr": 0.03951701427003293,
            "logloss": 0.6760454203762997,
            "mae": 0.38803544384350697,
            "precision": 0.8348623853211009,
            "recall": 0.38396624472573837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8469466307140985,
            "auditor_fn_violation": 0.03457373903508772,
            "auditor_fp_violation": 0.02645285087719299,
            "ave_precision_score": 0.84718006305763,
            "fpr": 0.13815789473684212,
            "logloss": 0.8190248232117401,
            "mae": 0.26831184641852146,
            "precision": 0.7485029940119761,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8317785303192229,
            "auditor_fn_violation": 0.02120820538472583,
            "auditor_fp_violation": 0.02558608615271774,
            "ave_precision_score": 0.8322071902266333,
            "fpr": 0.1207464324917673,
            "logloss": 0.7816205196871481,
            "mae": 0.26847133590893,
            "precision": 0.7634408602150538,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5483228857783206,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5409688757387869,
            "fpr": 0.05592105263157895,
            "logloss": 0.6951309645067334,
            "mae": 0.5005809829423302,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5453654842120347,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.007211629034405323,
            "ave_precision_score": 0.5360264875547732,
            "fpr": 0.054884742041712405,
            "logloss": 0.694090489911661,
            "mae": 0.5000249656769892,
            "precision": 0.5327102803738317,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5483228857783206,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5409688757387869,
            "fpr": 0.05592105263157895,
            "logloss": 0.6951409833643748,
            "mae": 0.500582861861116,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.545363599844283,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.007211629034405323,
            "ave_precision_score": 0.5360266198332817,
            "fpr": 0.054884742041712405,
            "logloss": 0.6940997068880054,
            "mae": 0.500026493741181,
            "precision": 0.5327102803738317,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7599809516724323,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.7609114212480603,
            "fpr": 0.02850877192982456,
            "logloss": 0.6099214822882508,
            "mae": 0.39636112599462076,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7393128380242643,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.002938908383926935,
            "ave_precision_score": 0.739436059121261,
            "fpr": 0.02305159165751921,
            "logloss": 0.596600984353804,
            "mae": 0.39855419931591834,
            "precision": 0.9009433962264151,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5938619063100588,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.5980369700579761,
            "fpr": 0.4407894736842105,
            "logloss": 0.6784820613314348,
            "mae": 0.48703830898330924,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5331013447736899,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.5418042834649771,
            "fpr": 0.4500548847420417,
            "logloss": 0.685492998526914,
            "mae": 0.4908185334289375,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8100065595279001,
            "auditor_fn_violation": 0.005756578947368419,
            "auditor_fp_violation": 0.023092308317089028,
            "ave_precision_score": 0.8103163071102977,
            "fpr": 0.16885964912280702,
            "logloss": 0.7620696974831153,
            "mae": 0.3701610645287139,
            "precision": 0.7003891050583657,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8314175415748879,
            "auditor_fn_violation": 0.01298244151417045,
            "auditor_fp_violation": 0.026163820279472613,
            "ave_precision_score": 0.8327133614873868,
            "fpr": 0.1525795828759605,
            "logloss": 0.6649513191796426,
            "mae": 0.3507435973384402,
            "precision": 0.7258382642998028,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.811799257168776,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.6991440466271459,
            "fpr": 0.02850877192982456,
            "logloss": 0.6108381877255983,
            "mae": 0.3926851917379903,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8083076701862008,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.002938908383926935,
            "ave_precision_score": 0.6933727289987115,
            "fpr": 0.02305159165751921,
            "logloss": 0.59507701348375,
            "mae": 0.3941516169100493,
            "precision": 0.9009433962264151,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8525912532597733,
            "auditor_fn_violation": 0.02652823464912281,
            "auditor_fp_violation": 0.018757106887589352,
            "ave_precision_score": 0.8528369328818711,
            "fpr": 0.11732456140350878,
            "logloss": 0.6922496748576112,
            "mae": 0.27318249145687995,
            "precision": 0.7723404255319148,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8465374249023205,
            "auditor_fn_violation": 0.024427183926412768,
            "auditor_fp_violation": 0.019688174284802833,
            "ave_precision_score": 0.8468853533439936,
            "fpr": 0.10976948408342481,
            "logloss": 0.6550238631045752,
            "mae": 0.2680403107035988,
            "precision": 0.7782705099778271,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8422196233755095,
            "auditor_fn_violation": 0.013441154970760236,
            "auditor_fp_violation": 0.00843689083820663,
            "ave_precision_score": 0.8424432098778443,
            "fpr": 0.07456140350877193,
            "logloss": 0.6837241506032463,
            "mae": 0.3135405102346698,
            "precision": 0.8256410256410256,
            "recall": 0.6708333333333333
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8640532939766965,
            "auditor_fn_violation": 0.019990088325065894,
            "auditor_fp_violation": 0.011976679636379165,
            "ave_precision_score": 0.8644564825143651,
            "fpr": 0.06147091108671789,
            "logloss": 0.5945293218637078,
            "mae": 0.28811695022508377,
            "precision": 0.8575063613231552,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8394402363610212,
            "auditor_fn_violation": 0.015350877192982455,
            "auditor_fp_violation": 0.009310022742040288,
            "ave_precision_score": 0.8396733012450586,
            "fpr": 0.0712719298245614,
            "logloss": 0.7129338691246323,
            "mae": 0.3151213461083141,
            "precision": 0.8311688311688312,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8642698179114036,
            "auditor_fn_violation": 0.011643902235684811,
            "auditor_fp_violation": 0.0094220900411196,
            "ave_precision_score": 0.864640714934079,
            "fpr": 0.06037321624588365,
            "logloss": 0.6048707167182183,
            "mae": 0.28970763080523965,
            "precision": 0.8604060913705583,
            "recall": 0.7151898734177216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7915627289382456,
            "auditor_fn_violation": 0.012198464912280702,
            "auditor_fp_violation": 0.0208561769005848,
            "ave_precision_score": 0.7923256284082962,
            "fpr": 0.07785087719298246,
            "logloss": 0.62660303925223,
            "mae": 0.3467530800436068,
            "precision": 0.8086253369272237,
            "recall": 0.625
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8168385276580561,
            "auditor_fn_violation": 0.01457572010171046,
            "auditor_fp_violation": 0.0105072254444157,
            "ave_precision_score": 0.8171212623002608,
            "fpr": 0.06915477497255763,
            "logloss": 0.6167299618355228,
            "mae": 0.3471540043853289,
            "precision": 0.8141592920353983,
            "recall": 0.5822784810126582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7845470588878589,
            "auditor_fn_violation": 0.015385142543859656,
            "auditor_fp_violation": 0.023386736517218978,
            "ave_precision_score": 0.7860942458366248,
            "fpr": 0.08991228070175439,
            "logloss": 0.6172032562331313,
            "mae": 0.3491131114046367,
            "precision": 0.787012987012987,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8132069525391918,
            "auditor_fn_violation": 0.013339076546846561,
            "auditor_fp_violation": 0.016573433775341807,
            "ave_precision_score": 0.8135098287682283,
            "fpr": 0.07025246981339188,
            "logloss": 0.6095433752213839,
            "mae": 0.3483387074974068,
            "precision": 0.815028901734104,
            "recall": 0.5949367088607594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7818522626836107,
            "auditor_fn_violation": 0.017516447368421055,
            "auditor_fp_violation": 0.025534031838856403,
            "ave_precision_score": 0.783397415150395,
            "fpr": 0.09320175438596491,
            "logloss": 0.6206862758500515,
            "mae": 0.34946840409017904,
            "precision": 0.782608695652174,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8119283484917719,
            "auditor_fn_violation": 0.014881407272575696,
            "auditor_fp_violation": 0.014832695732554316,
            "ave_precision_score": 0.8122507192576757,
            "fpr": 0.07025246981339188,
            "logloss": 0.6108584593738193,
            "mae": 0.3477013324163486,
            "precision": 0.815028901734104,
            "recall": 0.5949367088607594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7541336085698076,
            "auditor_fn_violation": 0.011239035087719305,
            "auditor_fp_violation": 0.022569444444444454,
            "ave_precision_score": 0.7406631989498182,
            "fpr": 0.1206140350877193,
            "logloss": 1.4527264548606704,
            "mae": 0.34819759975211956,
            "precision": 0.7684210526315789,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7702659694513347,
            "auditor_fn_violation": 0.014950881629590523,
            "auditor_fp_violation": 0.026831982356502155,
            "ave_precision_score": 0.7558022138404865,
            "fpr": 0.13391877058177826,
            "logloss": 1.4111346208488698,
            "mae": 0.3307480401489268,
            "precision": 0.7510204081632653,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8301146199659398,
            "auditor_fn_violation": 0.005126096491228073,
            "auditor_fp_violation": 0.022569444444444448,
            "ave_precision_score": 0.8303426663791236,
            "fpr": 0.14692982456140352,
            "logloss": 0.6474225699686084,
            "mae": 0.33907888104860767,
            "precision": 0.7346534653465346,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8526724882173483,
            "auditor_fn_violation": 0.013394656032458424,
            "auditor_fp_violation": 0.019369164571333843,
            "ave_precision_score": 0.8531565098758942,
            "fpr": 0.13062568605927552,
            "logloss": 0.5640497226067036,
            "mae": 0.31402012162535675,
            "precision": 0.762,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.851716414799613,
            "auditor_fn_violation": 0.01206140350877193,
            "auditor_fp_violation": 0.021835912118258614,
            "ave_precision_score": 0.8519191201148509,
            "fpr": 0.15021929824561403,
            "logloss": 0.7524333656605311,
            "mae": 0.2659402655321641,
            "precision": 0.7400379506641366,
            "recall": 0.8125
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8309535030591152,
            "auditor_fn_violation": 0.016013839291917353,
            "auditor_fp_violation": 0.01799265021715268,
            "ave_precision_score": 0.8313854077582364,
            "fpr": 0.13172338090010977,
            "logloss": 0.7521522996675365,
            "mae": 0.26932954344246884,
            "precision": 0.754601226993865,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.546235000505539,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.5391786939757942,
            "fpr": 0.05592105263157895,
            "logloss": 0.6956231154871676,
            "mae": 0.5008217584864613,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5382818268202452,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.0078571841238662,
            "ave_precision_score": 0.5299182501137872,
            "fpr": 0.05598243688254665,
            "logloss": 0.6951463139357092,
            "mae": 0.5005879402814921,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 28699,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6899561949934747,
            "auditor_fn_violation": 0.02833744517543862,
            "auditor_fp_violation": 0.013076673164392464,
            "ave_precision_score": 0.6948379517580194,
            "fpr": 0.08771929824561403,
            "logloss": 5.230551598795684,
            "mae": 0.44323434300975967,
            "precision": 0.746031746031746,
            "recall": 0.4895833333333333
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7303956409664784,
            "auditor_fn_violation": 0.04149471763305498,
            "auditor_fp_violation": 0.015224550183744573,
            "ave_precision_score": 0.7353750834662995,
            "fpr": 0.08232711306256861,
            "logloss": 4.75847400848059,
            "mae": 0.40596685202534705,
            "precision": 0.7692307692307693,
            "recall": 0.5274261603375527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7768267870369636,
            "auditor_fn_violation": 0.05078125000000001,
            "auditor_fp_violation": 0.05290570175438597,
            "ave_precision_score": 0.7772724779031077,
            "fpr": 0.1118421052631579,
            "logloss": 0.7616224382338752,
            "mae": 0.3882316753014924,
            "precision": 0.7397959183673469,
            "recall": 0.6041666666666666
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8118477786887721,
            "auditor_fn_violation": 0.048368047353721744,
            "auditor_fp_violation": 0.0485824162850691,
            "ave_precision_score": 0.8122607553723462,
            "fpr": 0.08781558726673985,
            "logloss": 0.677059087179681,
            "mae": 0.3691807183505161,
            "precision": 0.784366576819407,
            "recall": 0.6139240506329114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5668844038894066,
            "auditor_fn_violation": 0.00759320175438597,
            "auditor_fp_violation": 0.0035077566601689424,
            "ave_precision_score": 0.5689322886070871,
            "fpr": 0.05482456140350877,
            "logloss": 0.718024858409649,
            "mae": 0.5009444486636351,
            "precision": 0.5495495495495496,
            "recall": 0.12708333333333333
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5933262983598051,
            "auditor_fn_violation": 0.0011671691978490779,
            "auditor_fp_violation": 0.007384949272431784,
            "ave_precision_score": 0.595166571931671,
            "fpr": 0.04720087815587267,
            "logloss": 0.6931946662980867,
            "mae": 0.4989438683416134,
            "precision": 0.5567010309278351,
            "recall": 0.11392405063291139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8294788234085311,
            "auditor_fn_violation": 0.012127649853801168,
            "auditor_fp_violation": 0.020754649935022747,
            "ave_precision_score": 0.8297151889210468,
            "fpr": 0.11074561403508772,
            "logloss": 0.6366025754063929,
            "mae": 0.33234413774846217,
            "precision": 0.7725225225225225,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8506508098504627,
            "auditor_fn_violation": 0.007609757905023924,
            "auditor_fp_violation": 0.018198624992778325,
            "ave_precision_score": 0.8510518896333926,
            "fpr": 0.10098792535675083,
            "logloss": 0.558219525621629,
            "mae": 0.3086811235581958,
            "precision": 0.7960088691796009,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5944412309043159,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.597812775365054,
            "fpr": 0.4407894736842105,
            "logloss": 0.678484556756735,
            "mae": 0.4870403620103995,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5332119120436359,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.5416302811308598,
            "fpr": 0.4500548847420417,
            "logloss": 0.6854933433226568,
            "mae": 0.49081970216414017,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5940719319163085,
            "auditor_fn_violation": 0.0007721125730994153,
            "auditor_fp_violation": 0.006457115009746601,
            "ave_precision_score": 0.5974026584385497,
            "fpr": 0.4407894736842105,
            "logloss": 0.6784782527223738,
            "mae": 0.487034659832716,
            "precision": 0.5405714285714286,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5328244097426664,
            "auditor_fn_violation": 0.0024663396740263166,
            "auditor_fp_violation": 0.0067620011705395765,
            "ave_precision_score": 0.5416429570976502,
            "fpr": 0.4500548847420417,
            "logloss": 0.6854927728456374,
            "mae": 0.4908164025301729,
            "precision": 0.5335608646188851,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8499222181704984,
            "auditor_fn_violation": 0.011951754385964916,
            "auditor_fp_violation": 0.021335891812865503,
            "ave_precision_score": 0.850130583414351,
            "fpr": 0.15679824561403508,
            "logloss": 0.7693310144188228,
            "mae": 0.2658752164756087,
            "precision": 0.7327102803738318,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8265774377190069,
            "auditor_fn_violation": 0.018959552029345968,
            "auditor_fp_violation": 0.01932646248370413,
            "ave_precision_score": 0.8270241716238647,
            "fpr": 0.132821075740944,
            "logloss": 0.783491420761607,
            "mae": 0.2715935759533495,
            "precision": 0.7520491803278688,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5294896190859741,
            "auditor_fn_violation": 0.008755939327485383,
            "auditor_fp_violation": 0.0045458698830409365,
            "ave_precision_score": 0.530970450157777,
            "fpr": 0.05592105263157895,
            "logloss": 0.6956214801377082,
            "mae": 0.5008209887565228,
            "precision": 0.5363636363636364,
            "recall": 0.12291666666666666
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5209961370192093,
            "auditor_fn_violation": 0.013728132946129588,
            "auditor_fp_violation": 0.0078571841238662,
            "ave_precision_score": 0.5226114847795229,
            "fpr": 0.05598243688254665,
            "logloss": 0.6951432586871312,
            "mae": 0.5005866692173494,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.831950783863911,
            "auditor_fn_violation": 0.013395467836257318,
            "auditor_fp_violation": 0.023087231968810924,
            "ave_precision_score": 0.8321857689634662,
            "fpr": 0.1118421052631579,
            "logloss": 0.6409790301166884,
            "mae": 0.3309857320432636,
            "precision": 0.7713004484304933,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.852063290796722,
            "auditor_fn_violation": 0.008614820269838406,
            "auditor_fp_violation": 0.020733119487976848,
            "ave_precision_score": 0.8524241802395637,
            "fpr": 0.10757409440175632,
            "logloss": 0.5575840917846396,
            "mae": 0.3090187058006139,
            "precision": 0.7874186550976139,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5707198896062541,
            "auditor_fn_violation": 0.010252192982456138,
            "auditor_fp_violation": 0.0036524325860948785,
            "ave_precision_score": 0.5722240591694936,
            "fpr": 0.3344298245614035,
            "logloss": 0.7155494662004189,
            "mae": 0.49566658131875957,
            "precision": 0.5151033386327504,
            "recall": 0.675
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5898580153901808,
            "auditor_fn_violation": 0.005784898127434501,
            "auditor_fp_violation": 0.01766861672866843,
            "ave_precision_score": 0.5913692571462393,
            "fpr": 0.3150384193194292,
            "logloss": 0.7038376337710075,
            "mae": 0.4946858189858867,
            "precision": 0.5310457516339869,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8436096218384768,
            "auditor_fn_violation": 0.007236842105263158,
            "auditor_fp_violation": 0.02375730994152047,
            "ave_precision_score": 0.8438176030962021,
            "fpr": 0.12280701754385964,
            "logloss": 0.6040689200669555,
            "mae": 0.3220724169376561,
            "precision": 0.7666666666666667,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8611197285523212,
            "auditor_fn_violation": 0.013524341498886094,
            "auditor_fp_violation": 0.015752046560346847,
            "ave_precision_score": 0.8615246450408425,
            "fpr": 0.1207464324917673,
            "logloss": 0.5340217571207859,
            "mae": 0.2990705232298179,
            "precision": 0.7750511247443763,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8498557894779537,
            "auditor_fn_violation": 0.011951754385964916,
            "auditor_fp_violation": 0.02169377436647174,
            "ave_precision_score": 0.8500645273971592,
            "fpr": 0.15460526315789475,
            "logloss": 0.7699133048637083,
            "mae": 0.2658396044161701,
            "precision": 0.7354596622889306,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8267566970253487,
            "auditor_fn_violation": 0.018341230251914024,
            "auditor_fp_violation": 0.019783626010092766,
            "ave_precision_score": 0.8272034935169583,
            "fpr": 0.13172338090010977,
            "logloss": 0.7808511831276505,
            "mae": 0.2713601316926604,
            "precision": 0.7540983606557377,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.4632176337434628,
            "auditor_fn_violation": 0.008728527046783629,
            "auditor_fp_violation": 0.010987755847953216,
            "ave_precision_score": 0.4651442464668665,
            "fpr": 0.09539473684210527,
            "logloss": 0.702052348027159,
            "mae": 0.5034410953031558,
            "precision": 0.45625,
            "recall": 0.15208333333333332
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.47040604403365155,
            "auditor_fn_violation": 0.003737720407397646,
            "auditor_fp_violation": 0.011316053221872515,
            "ave_precision_score": 0.4716198214200207,
            "fpr": 0.10208562019758508,
            "logloss": 0.6963472888464697,
            "mae": 0.500643180865226,
            "precision": 0.45614035087719296,
            "recall": 0.16455696202531644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7662895822647833,
            "auditor_fn_violation": 0.04066611842105263,
            "auditor_fp_violation": 0.0426819363222872,
            "ave_precision_score": 0.7679728807457702,
            "fpr": 0.10964912280701754,
            "logloss": 0.6255518698490092,
            "mae": 0.35084209165928004,
            "precision": 0.7607655502392344,
            "recall": 0.6625
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8012977098900831,
            "auditor_fn_violation": 0.04068418346788202,
            "auditor_fp_violation": 0.030577206630378263,
            "ave_precision_score": 0.8016253376581925,
            "fpr": 0.07793633369923161,
            "logloss": 0.6022743763082083,
            "mae": 0.34641543575731215,
            "precision": 0.8044077134986226,
            "recall": 0.6160337552742616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8135144638307795,
            "auditor_fn_violation": 0.004824561403508772,
            "auditor_fp_violation": 0.014642726608187134,
            "ave_precision_score": 0.8138048353464523,
            "fpr": 0.16776315789473684,
            "logloss": 0.6929620565480381,
            "mae": 0.3699048797433087,
            "precision": 0.7080152671755725,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8363227420508844,
            "auditor_fn_violation": 0.013709606450925631,
            "auditor_fp_violation": 0.010047550030519442,
            "ave_precision_score": 0.8376308908466857,
            "fpr": 0.16245883644346873,
            "logloss": 0.6085275248144105,
            "mae": 0.3485536687177923,
            "precision": 0.7191650853889943,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8149417377747067,
            "auditor_fn_violation": 0.004676078216374281,
            "auditor_fp_violation": 0.0063149772579597155,
            "ave_precision_score": 0.7118453373561006,
            "fpr": 0.02850877192982456,
            "logloss": 0.6177798324539309,
            "mae": 0.3897959641681314,
            "precision": 0.8893617021276595,
            "recall": 0.4354166666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8090285108269104,
            "auditor_fn_violation": 0.005708476334718204,
            "auditor_fp_violation": 0.002938908383926935,
            "ave_precision_score": 0.7018224389221488,
            "fpr": 0.02305159165751921,
            "logloss": 0.6099238976655158,
            "mae": 0.3914721408523067,
            "precision": 0.9009433962264151,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5727960243105814,
            "auditor_fn_violation": 0.004815423976608188,
            "auditor_fp_violation": 0.001324926900584809,
            "ave_precision_score": 0.5743241292918506,
            "fpr": 0.37609649122807015,
            "logloss": 0.7125260807435365,
            "mae": 0.49445618459354007,
            "precision": 0.53077975376197,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5886013656459166,
            "auditor_fn_violation": 0.009066403590434773,
            "auditor_fp_violation": 0.019040107307834328,
            "ave_precision_score": 0.5901250085021759,
            "fpr": 0.35016465422612514,
            "logloss": 0.7032711717506984,
            "mae": 0.49473818204777853,
            "precision": 0.5455840455840456,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.834540946935173,
            "auditor_fn_violation": 0.004742324561403509,
            "auditor_fp_violation": 0.023757309941520477,
            "ave_precision_score": 0.8347639478250917,
            "fpr": 0.14912280701754385,
            "logloss": 0.6251573211335967,
            "mae": 0.33426896082088414,
            "precision": 0.7322834645669292,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8526207355134755,
            "auditor_fn_violation": 0.0140407675526963,
            "auditor_fp_violation": 0.020594965675057215,
            "ave_precision_score": 0.853110165973088,
            "fpr": 0.132821075740944,
            "logloss": 0.5578082163597197,
            "mae": 0.3114029519754008,
            "precision": 0.7589641434262948,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7938496830246161,
            "auditor_fn_violation": 0.016001918859649127,
            "auditor_fp_violation": 0.016965155945419107,
            "ave_precision_score": 0.7953300379929265,
            "fpr": 0.07456140350877193,
            "logloss": 0.6180913252861284,
            "mae": 0.34642249601484654,
            "precision": 0.8126721763085399,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8180442700532575,
            "auditor_fn_violation": 0.011115897122372133,
            "auditor_fp_violation": 0.013380824753144258,
            "ave_precision_score": 0.8183212158344045,
            "fpr": 0.06366630076838639,
            "logloss": 0.613462111903941,
            "mae": 0.3464562808399617,
            "precision": 0.8253012048192772,
            "recall": 0.5780590717299579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8518225117435176,
            "auditor_fn_violation": 0.014983095760233921,
            "auditor_fp_violation": 0.02089932586094867,
            "ave_precision_score": 0.8520250080933663,
            "fpr": 0.15021929824561403,
            "logloss": 0.7477755692104696,
            "mae": 0.2658571637850095,
            "precision": 0.740530303030303,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8308577252527881,
            "auditor_fn_violation": 0.0171115341327516,
            "auditor_fp_violation": 0.018577920006430434,
            "ave_precision_score": 0.8312992781192758,
            "fpr": 0.12952799121844127,
            "logloss": 0.7474342210594821,
            "mae": 0.2695792946591781,
            "precision": 0.757700205338809,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6098503011017304,
            "auditor_fn_violation": 0.004696637426900586,
            "auditor_fp_violation": 0.009827810266406755,
            "ave_precision_score": 0.6114228538668504,
            "fpr": 0.38706140350877194,
            "logloss": 0.7110139373111002,
            "mae": 0.49427618286272673,
            "precision": 0.5318302387267905,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6338650881586134,
            "auditor_fn_violation": 0.006440272895274357,
            "auditor_fp_violation": 0.008256574237579344,
            "ave_precision_score": 0.6353573510077937,
            "fpr": 0.3754116355653128,
            "logloss": 0.7061880435032878,
            "mae": 0.49679500308296254,
            "precision": 0.5308641975308642,
            "recall": 0.8164556962025317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 28699,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.45874224103070316,
            "auditor_fn_violation": 0.007766812865497077,
            "auditor_fp_violation": 0.009058743502274216,
            "ave_precision_score": 0.46020326975393,
            "fpr": 0.3607456140350877,
            "logloss": 0.6965170019260052,
            "mae": 0.5006858760719759,
            "precision": 0.5111441307578009,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.47630788689936987,
            "auditor_fn_violation": 0.0057895297512354895,
            "auditor_fp_violation": 0.017512879703195382,
            "ave_precision_score": 0.4774073520724417,
            "fpr": 0.3391877058177827,
            "logloss": 0.690330118904569,
            "mae": 0.49749525521118215,
            "precision": 0.5353383458646617,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 28699,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5780862252623005,
            "auditor_fn_violation": 0.009119152046783626,
            "auditor_fp_violation": 0.0044214993502274345,
            "ave_precision_score": 0.5794979777566863,
            "fpr": 0.35635964912280704,
            "logloss": 0.7119623403696971,
            "mae": 0.4941520717032688,
            "precision": 0.5142002989536621,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5818707128118826,
            "auditor_fn_violation": 0.003381085374721529,
            "auditor_fp_violation": 0.012627258500855307,
            "ave_precision_score": 0.5839584129621341,
            "fpr": 0.3424807903402854,
            "logloss": 0.7052095262871034,
            "mae": 0.4949414643219211,
            "precision": 0.5301204819277109,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8034043157790924,
            "auditor_fn_violation": 0.005854806286549712,
            "auditor_fp_violation": 0.01821393762183236,
            "ave_precision_score": 0.803720346557558,
            "fpr": 0.20614035087719298,
            "logloss": 0.7669072474902763,
            "mae": 0.37739761184903936,
            "precision": 0.6648841354723708,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8169539677190809,
            "auditor_fn_violation": 0.015050461541311774,
            "auditor_fp_violation": 0.019007452770235148,
            "ave_precision_score": 0.8182993246330611,
            "fpr": 0.20197585071350166,
            "logloss": 0.6867864194609975,
            "mae": 0.3635138655152474,
            "precision": 0.6731793960923623,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 28699,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6648645637075241,
            "auditor_fn_violation": 0.026658442982456145,
            "auditor_fp_violation": 0.04663133528265108,
            "ave_precision_score": 0.6662415792598111,
            "fpr": 0.3201754385964912,
            "logloss": 0.6781779795326287,
            "mae": 0.4627101571322158,
            "precision": 0.5955678670360111,
            "recall": 0.8958333333333334
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.589522343904309,
            "auditor_fn_violation": 0.027671636399005127,
            "auditor_fp_violation": 0.037658217514386846,
            "ave_precision_score": 0.5907852110516832,
            "fpr": 0.3446761800219539,
            "logloss": 0.7035303708135487,
            "mae": 0.4774358414583815,
            "precision": 0.5692729766803841,
            "recall": 0.8755274261603375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7709290948222378,
            "auditor_fn_violation": 0.05328262061403509,
            "auditor_fp_violation": 0.05884502923976608,
            "ave_precision_score": 0.7714315714437525,
            "fpr": 0.12280701754385964,
            "logloss": 0.7741546345752471,
            "mae": 0.3820022631801956,
            "precision": 0.7248157248157249,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.805600527709229,
            "auditor_fn_violation": 0.05142491906237408,
            "auditor_fp_violation": 0.05491237280429634,
            "ave_precision_score": 0.8058634878121199,
            "fpr": 0.09769484083424808,
            "logloss": 0.6952861943013119,
            "mae": 0.36559224557762243,
            "precision": 0.7694300518134715,
            "recall": 0.6265822784810127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7249015427009109,
            "auditor_fn_violation": 0.016904239766081873,
            "auditor_fp_violation": 0.006386046133853156,
            "ave_precision_score": 0.7253413845666541,
            "fpr": 0.14692982456140352,
            "logloss": 0.6522680630772522,
            "mae": 0.4711514946988277,
            "precision": 0.654639175257732,
            "recall": 0.5291666666666667
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7419800627264435,
            "auditor_fn_violation": 0.010990843279745453,
            "auditor_fp_violation": 0.009316590765799146,
            "ave_precision_score": 0.7424398224313975,
            "fpr": 0.14928649835345773,
            "logloss": 0.6424770898396548,
            "mae": 0.466618125790037,
            "precision": 0.6650246305418719,
            "recall": 0.569620253164557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8179609731773474,
            "auditor_fn_violation": 0.03507401315789473,
            "auditor_fp_violation": 0.03319170321637428,
            "ave_precision_score": 0.8193925642944386,
            "fpr": 0.14583333333333334,
            "logloss": 0.5207199914221288,
            "mae": 0.33441625475033854,
            "precision": 0.7334669338677354,
            "recall": 0.7625
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8446631140070164,
            "auditor_fn_violation": 0.031247249973368165,
            "auditor_fp_violation": 0.02758554860879111,
            "ave_precision_score": 0.8448766590666505,
            "fpr": 0.1251372118551043,
            "logloss": 0.5078745077920186,
            "mae": 0.33262849827711066,
            "precision": 0.7537796976241901,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 28699,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7771034624984032,
            "auditor_fn_violation": 0.019556377923976617,
            "auditor_fp_violation": 0.023919753086419755,
            "ave_precision_score": 0.7784846034134787,
            "fpr": 0.07785087719298246,
            "logloss": 0.6489517039259859,
            "mae": 0.3618547390358065,
            "precision": 0.7994350282485876,
            "recall": 0.5895833333333333
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8079507295169386,
            "auditor_fn_violation": 0.014839722658366802,
            "auditor_fp_violation": 0.014121831567895064,
            "ave_precision_score": 0.8078925672300095,
            "fpr": 0.05817782656421515,
            "logloss": 0.6393900103803339,
            "mae": 0.35843399460769937,
            "precision": 0.8322784810126582,
            "recall": 0.5548523206751055
        }
    }
]