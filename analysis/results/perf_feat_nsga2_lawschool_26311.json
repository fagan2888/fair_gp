[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.458745524181825,
            "mae": 0.5054824561403509,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.691127072108635,
            "mae": 0.5411635565312843,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.458745524181825,
            "mae": 0.5054824561403509,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.691127072108635,
            "mae": 0.5411635565312843,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 26311,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5254492884892147,
            "auditor_fn_violation": 0.08132587433877536,
            "auditor_fp_violation": 0.08948195044151398,
            "ave_precision_score": 0.5256584199075234,
            "fpr": 0.28399122807017546,
            "logloss": 0.6891659141821004,
            "mae": 0.496929063412704,
            "precision": 0.5399644760213144,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5540168480585986,
            "auditor_fn_violation": 0.07901844260926295,
            "auditor_fp_violation": 0.08181765660533932,
            "ave_precision_score": 0.5566946788681448,
            "fpr": 0.27442371020856204,
            "logloss": 0.688134003837482,
            "mae": 0.496371928900971,
            "precision": 0.5812395309882747,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7078825573554922,
            "auditor_fn_violation": 0.09036895383795715,
            "auditor_fp_violation": 0.10833868207103124,
            "ave_precision_score": 0.538527015602393,
            "fpr": 0.3081140350877193,
            "logloss": 0.6862098638117988,
            "mae": 0.49299645799685987,
            "precision": 0.5475040257648953,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7320355009048978,
            "auditor_fn_violation": 0.09462886558915931,
            "auditor_fp_violation": 0.10127154029170321,
            "ave_precision_score": 0.5751646001724791,
            "fpr": 0.29308452250274425,
            "logloss": 0.6823497016221197,
            "mae": 0.49101102482997755,
            "precision": 0.5795275590551181,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.808038486877962,
            "auditor_fn_violation": 0.015300928568710289,
            "auditor_fp_violation": 0.00326272999572101,
            "ave_precision_score": 0.8049830746962775,
            "fpr": 0.03618421052631579,
            "logloss": 0.5819547208556102,
            "mae": 0.41366654180251716,
            "precision": 0.8613445378151261,
            "recall": 0.44468546637744033
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8294635419680887,
            "auditor_fn_violation": 0.004103552924254606,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.8264230245890055,
            "fpr": 0.03951701427003293,
            "logloss": 0.5788508583095661,
            "mae": 0.41060512413962874,
            "precision": 0.856,
            "recall": 0.4340770791075051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6300522002301658,
            "auditor_fn_violation": 0.006890531643642729,
            "auditor_fp_violation": 0.0035277356362080374,
            "ave_precision_score": 0.6314598205564427,
            "fpr": 0.019736842105263157,
            "logloss": 0.6524366404734108,
            "mae": 0.4608928692249352,
            "precision": 0.8487394957983193,
            "recall": 0.21908893709327548
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7040903055576536,
            "auditor_fn_violation": 0.008187066794619727,
            "auditor_fp_violation": 0.001318284234686107,
            "ave_precision_score": 0.7045623009648874,
            "fpr": 0.013172338090010977,
            "logloss": 0.6369117872620105,
            "mae": 0.45225160757466154,
            "precision": 0.9090909090909091,
            "recall": 0.2434077079107505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 26311,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6627672319212912,
            "auditor_fn_violation": 0.02166343189861857,
            "auditor_fp_violation": 0.019836523125996812,
            "ave_precision_score": 0.6598823463011247,
            "fpr": 0.16666666666666666,
            "logloss": 1.2176756715170451,
            "mae": 0.3861478778284468,
            "precision": 0.67170626349892,
            "recall": 0.6746203904555315
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6639641144691886,
            "auditor_fn_violation": 0.02255729499491231,
            "auditor_fp_violation": 0.02209570428416116,
            "ave_precision_score": 0.6650528719726114,
            "fpr": 0.14270032930845225,
            "logloss": 1.426328759134787,
            "mae": 0.39831626726034314,
            "precision": 0.7142857142857143,
            "recall": 0.6592292089249493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6639048201366857,
            "auditor_fn_violation": 0.015817064352856115,
            "auditor_fp_violation": 0.04025654490994671,
            "ave_precision_score": 0.6625766147573784,
            "fpr": 0.20614035087719298,
            "logloss": 1.8138319348516545,
            "mae": 0.321720233667524,
            "precision": 0.6618705035971223,
            "recall": 0.7982646420824295
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7042507272348921,
            "auditor_fn_violation": 0.02453002852225337,
            "auditor_fp_violation": 0.03899180142752851,
            "ave_precision_score": 0.701817182992752,
            "fpr": 0.1734357848518112,
            "logloss": 1.701760626178223,
            "mae": 0.3076123293252326,
            "precision": 0.7132486388384754,
            "recall": 0.7971602434077079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7795215624020283,
            "auditor_fn_violation": 0.031467633291471626,
            "auditor_fp_violation": 0.007490664021472751,
            "ave_precision_score": 0.6523186128734708,
            "fpr": 0.047149122807017545,
            "logloss": 0.6175552362212927,
            "mae": 0.43102326296400606,
            "precision": 0.8293650793650794,
            "recall": 0.45336225596529284
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8129145404106828,
            "auditor_fn_violation": 0.02029510846694559,
            "auditor_fp_violation": 0.008555717204397082,
            "ave_precision_score": 0.6979435788993528,
            "fpr": 0.04500548847420417,
            "logloss": 0.5962407505982843,
            "mae": 0.4176465049140671,
            "precision": 0.8566433566433567,
            "recall": 0.4969574036511156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6606137722255001,
            "auditor_fn_violation": 0.016844578909312333,
            "auditor_fp_violation": 0.0389266542186953,
            "ave_precision_score": 0.6573086630550394,
            "fpr": 0.19956140350877194,
            "logloss": 1.8638777253643364,
            "mae": 0.321534835339702,
            "precision": 0.6702898550724637,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7014801745076603,
            "auditor_fn_violation": 0.02467475502256621,
            "auditor_fp_violation": 0.03908108761075426,
            "ave_precision_score": 0.6983775717687534,
            "fpr": 0.1778265642151482,
            "logloss": 1.7343670031786103,
            "mae": 0.3082508513460689,
            "precision": 0.7091561938958707,
            "recall": 0.8012170385395537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7433863488683696,
            "auditor_fn_violation": 0.01404745595007041,
            "auditor_fp_violation": 0.0036249854125335514,
            "ave_precision_score": 0.6970216592661822,
            "fpr": 0.03508771929824561,
            "logloss": 0.6165761832658696,
            "mae": 0.42848550031582516,
            "precision": 0.8638297872340426,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7711152814135798,
            "auditor_fn_violation": 0.003689412477205585,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.7283185157296503,
            "fpr": 0.03951701427003293,
            "logloss": 0.6033454818545769,
            "mae": 0.42193685830228284,
            "precision": 0.8554216867469879,
            "recall": 0.43204868154158216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6984923273958077,
            "auditor_fn_violation": 0.0067620923240857035,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.6994577309715839,
            "fpr": 0.01864035087719298,
            "logloss": 0.6523551693049007,
            "mae": 0.46097552942994396,
            "precision": 0.8547008547008547,
            "recall": 0.21691973969631237
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7277752275550187,
            "auditor_fn_violation": 0.007051520407549833,
            "auditor_fp_violation": 0.001381309775786638,
            "ave_precision_score": 0.7287913094936689,
            "fpr": 0.013172338090010977,
            "logloss": 0.6368164566758638,
            "mae": 0.4532277053293622,
            "precision": 0.9076923076923077,
            "recall": 0.23935091277890466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6642878207297335,
            "auditor_fn_violation": 0.01683744339155916,
            "auditor_fp_violation": 0.03939831563387405,
            "ave_precision_score": 0.6625731211874055,
            "fpr": 0.22587719298245615,
            "logloss": 1.8912858957877174,
            "mae": 0.323623394954247,
            "precision": 0.6496598639455783,
            "recall": 0.8286334056399133
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.702202118100484,
            "auditor_fn_violation": 0.02646491050335877,
            "auditor_fp_violation": 0.04172816033697657,
            "ave_precision_score": 0.6998136642128316,
            "fpr": 0.19209659714599342,
            "logloss": 1.7209636419092862,
            "mae": 0.303155262238015,
            "precision": 0.7008547008547008,
            "recall": 0.8316430020283976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5158195711412906,
            "auditor_fn_violation": 0.0869510408341896,
            "auditor_fp_violation": 0.0980496557357918,
            "ave_precision_score": 0.5190244273101602,
            "fpr": 0.30043859649122806,
            "logloss": 0.6904283026424516,
            "mae": 0.49688178251840565,
            "precision": 0.5371621621621622,
            "recall": 0.6898047722342733
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5063995560501838,
            "auditor_fn_violation": 0.08138527752976357,
            "auditor_fp_violation": 0.08544162521861985,
            "ave_precision_score": 0.5477275237296833,
            "fpr": 0.2854006586169045,
            "logloss": 0.6847849280204344,
            "mae": 0.4939881056776162,
            "precision": 0.5799676898222941,
            "recall": 0.7281947261663286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5726834476097558,
            "auditor_fn_violation": 0.09036895383795715,
            "auditor_fp_violation": 0.10767252110320147,
            "ave_precision_score": 0.5738368660622393,
            "fpr": 0.30701754385964913,
            "logloss": 0.6886157371980972,
            "mae": 0.4916015409848146,
            "precision": 0.5483870967741935,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.583188448420943,
            "auditor_fn_violation": 0.0953858965138726,
            "auditor_fp_violation": 0.10127154029170321,
            "ave_precision_score": 0.5850229190828881,
            "fpr": 0.29308452250274425,
            "logloss": 0.6834376140954769,
            "mae": 0.4889628785436423,
            "precision": 0.5788643533123028,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7412909317251283,
            "auditor_fn_violation": 0.007758686303611534,
            "auditor_fp_violation": 0.0024117944528727593,
            "ave_precision_score": 0.6009006073434702,
            "fpr": 0.021929824561403508,
            "logloss": 0.6453857930612178,
            "mae": 0.4529012121064098,
            "precision": 0.8484848484848485,
            "recall": 0.24295010845986983
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7715633883994677,
            "auditor_fn_violation": 0.003571404715412051,
            "auditor_fp_violation": 0.0028440275421614605,
            "ave_precision_score": 0.6393416368048198,
            "fpr": 0.020856201975850714,
            "logloss": 0.6400826155829646,
            "mae": 0.44727314339641944,
            "precision": 0.8766233766233766,
            "recall": 0.2738336713995943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7159100554699479,
            "auditor_fn_violation": 0.0067620923240857035,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.7165884137995133,
            "fpr": 0.01864035087719298,
            "logloss": 0.638916098359768,
            "mae": 0.45350684439600036,
            "precision": 0.8547008547008547,
            "recall": 0.21691973969631237
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7634854327258268,
            "auditor_fn_violation": 0.007051520407549833,
            "auditor_fp_violation": 0.001381309775786638,
            "ave_precision_score": 0.7637468851694265,
            "fpr": 0.013172338090010977,
            "logloss": 0.6250126655401349,
            "mae": 0.44613087967316223,
            "precision": 0.9076923076923077,
            "recall": 0.23935091277890466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7099449532854483,
            "auditor_fn_violation": 0.09036895383795715,
            "auditor_fp_violation": 0.10833868207103124,
            "ave_precision_score": 0.5386578303939933,
            "fpr": 0.3081140350877193,
            "logloss": 0.6867027931491785,
            "mae": 0.49336090634920093,
            "precision": 0.5475040257648953,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7323263963659523,
            "auditor_fn_violation": 0.09462886558915931,
            "auditor_fp_violation": 0.10127154029170321,
            "ave_precision_score": 0.5713398768229817,
            "fpr": 0.29308452250274425,
            "logloss": 0.6833183548968076,
            "mae": 0.49165291699829267,
            "precision": 0.5795275590551181,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7421424052541362,
            "auditor_fn_violation": 0.0122469269703543,
            "auditor_fp_violation": 0.0016483837087174701,
            "ave_precision_score": 0.736196832196046,
            "fpr": 0.05482456140350877,
            "logloss": 0.5841708711196357,
            "mae": 0.40874619608777657,
            "precision": 0.8422712933753943,
            "recall": 0.579175704989154
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7712743353860266,
            "auditor_fn_violation": 0.016692531889927704,
            "auditor_fp_violation": 0.006271041339502833,
            "ave_precision_score": 0.7648673196734531,
            "fpr": 0.042810098792535674,
            "logloss": 0.5687397542301966,
            "mae": 0.4025248193910957,
            "precision": 0.8773584905660378,
            "recall": 0.565922920892495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7376639637481635,
            "auditor_fn_violation": 0.007758686303611534,
            "auditor_fp_violation": 0.0024117944528727593,
            "ave_precision_score": 0.5951522085008761,
            "fpr": 0.021929824561403508,
            "logloss": 0.6498032141083407,
            "mae": 0.4557354229322651,
            "precision": 0.8484848484848485,
            "recall": 0.24295010845986983
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7719972462372172,
            "auditor_fn_violation": 0.003571404715412051,
            "auditor_fp_violation": 0.0028440275421614605,
            "ave_precision_score": 0.6407188806076838,
            "fpr": 0.020856201975850714,
            "logloss": 0.6415896151971954,
            "mae": 0.44975858494950177,
            "precision": 0.8766233766233766,
            "recall": 0.2738336713995943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 26311,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5226869496367162,
            "auditor_fn_violation": 0.005734577767629505,
            "auditor_fp_violation": 0.003447504570739487,
            "ave_precision_score": 0.518743891499805,
            "fpr": 0.05921052631578947,
            "logloss": 0.6937718734789847,
            "mae": 0.4992847657974875,
            "precision": 0.509090909090909,
            "recall": 0.12147505422993492
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5527019144792386,
            "auditor_fn_violation": 0.006873395484087891,
            "auditor_fp_violation": 0.008350884195820358,
            "ave_precision_score": 0.5505609345916479,
            "fpr": 0.052689352360043906,
            "logloss": 0.6970060506749117,
            "mae": 0.5008762731706533,
            "precision": 0.5555555555555556,
            "recall": 0.12170385395537525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6843419965566154,
            "auditor_fn_violation": 0.007413802945541725,
            "auditor_fp_violation": 0.006678628389154707,
            "ave_precision_score": 0.6852907825023256,
            "fpr": 0.0581140350877193,
            "logloss": 0.8299137662229553,
            "mae": 0.38868141150107893,
            "precision": 0.7913385826771654,
            "recall": 0.4360086767895879
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6833393623673856,
            "auditor_fn_violation": 0.019048234002711963,
            "auditor_fp_violation": 0.0014285789316120388,
            "ave_precision_score": 0.684469073733158,
            "fpr": 0.05817782656421515,
            "logloss": 0.915674021071869,
            "mae": 0.40993171940568135,
            "precision": 0.79296875,
            "recall": 0.4117647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6442694171077936,
            "auditor_fn_violation": 0.00770160216158618,
            "auditor_fp_violation": 0.003430485859882523,
            "ave_precision_score": 0.6437749707978996,
            "fpr": 0.023026315789473683,
            "logloss": 0.6515933255540348,
            "mae": 0.45530950908728857,
            "precision": 0.8432835820895522,
            "recall": 0.24511930585683298
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7078543521577917,
            "auditor_fn_violation": 0.0023356630588947784,
            "auditor_fp_violation": 0.0028440275421614605,
            "ave_precision_score": 0.7047318664383775,
            "fpr": 0.020856201975850714,
            "logloss": 0.6398733228874874,
            "mae": 0.4481134911596317,
            "precision": 0.8782051282051282,
            "recall": 0.2778904665314402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7464696188033174,
            "auditor_fn_violation": 0.01000875290177722,
            "auditor_fp_violation": 0.008920235733457817,
            "ave_precision_score": 0.7400476438688742,
            "fpr": 0.06578947368421052,
            "logloss": 0.5941945692149107,
            "mae": 0.42540049307832595,
            "precision": 0.8045602605863192,
            "recall": 0.5357917570498916
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7555437546781618,
            "auditor_fn_violation": 0.011671635609844085,
            "auditor_fp_violation": 2.6260642125223086e-05,
            "ave_precision_score": 0.749139799294697,
            "fpr": 0.06586169045005488,
            "logloss": 0.5892506288407415,
            "mae": 0.4222538365883309,
            "precision": 0.8142414860681114,
            "recall": 0.5334685598377282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7764925569773462,
            "auditor_fn_violation": 0.01404745595007041,
            "auditor_fp_violation": 0.0033478235500058367,
            "ave_precision_score": 0.6780682933381621,
            "fpr": 0.03399122807017544,
            "logloss": 0.614960607205727,
            "mae": 0.42854256369173527,
            "precision": 0.8675213675213675,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7974157651657623,
            "auditor_fn_violation": 0.003689412477205585,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.7069244731309543,
            "fpr": 0.03951701427003293,
            "logloss": 0.6027605213644491,
            "mae": 0.4220441219639176,
            "precision": 0.8554216867469879,
            "recall": 0.43204868154158216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.638905325478962,
            "auditor_fn_violation": 0.009361799292156647,
            "auditor_fp_violation": 0.001334753180067686,
            "ave_precision_score": 0.639679099631099,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6679098206339448,
            "mae": 0.4775721747101399,
            "precision": 0.8974358974358975,
            "recall": 0.07592190889370933
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6637349169678314,
            "auditor_fn_violation": 0.00956753495144984,
            "auditor_fp_violation": 3.6764898975309764e-05,
            "ave_precision_score": 0.6642180255554602,
            "fpr": 0.005488474204171241,
            "logloss": 0.6778541094477906,
            "mae": 0.4820324250555196,
            "precision": 0.8780487804878049,
            "recall": 0.07302231237322515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.717698968914237,
            "auditor_fn_violation": 0.006645545534117292,
            "auditor_fp_violation": 0.002810518535807369,
            "ave_precision_score": 0.7186308387563418,
            "fpr": 0.0668859649122807,
            "logloss": 0.6863910554172541,
            "mae": 0.3552130921090251,
            "precision": 0.8140243902439024,
            "recall": 0.579175704989154
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7076073313939502,
            "auditor_fn_violation": 0.014005072107195581,
            "auditor_fp_violation": 0.004025756437796421,
            "ave_precision_score": 0.7086248857438144,
            "fpr": 0.06695938529088913,
            "logloss": 0.7582145002244979,
            "mae": 0.37571878586900875,
            "precision": 0.8151515151515152,
            "recall": 0.5456389452332657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7036657642587573,
            "auditor_fn_violation": 0.003912642234653875,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.63853193196974,
            "fpr": 0.01864035087719298,
            "logloss": 0.6376508935975914,
            "mae": 0.4480081478035764,
            "precision": 0.8583333333333333,
            "recall": 0.22342733188720174
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7647455581767576,
            "auditor_fn_violation": 0.007316481231199476,
            "auditor_fp_violation": 0.001877635911953319,
            "ave_precision_score": 0.7036639454857613,
            "fpr": 0.012074643249176729,
            "logloss": 0.6317045010245883,
            "mae": 0.4440817646314232,
            "precision": 0.917910447761194,
            "recall": 0.24949290060851928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7395311509818264,
            "auditor_fn_violation": 0.0049520493206987246,
            "auditor_fp_violation": 0.004475920955381803,
            "ave_precision_score": 0.5889916921872038,
            "fpr": 0.01644736842105263,
            "logloss": 0.653405633189939,
            "mae": 0.45949953258560416,
            "precision": 0.8672566371681416,
            "recall": 0.21258134490238612
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7774979202748897,
            "auditor_fn_violation": 0.004744802648717619,
            "auditor_fp_violation": 0.001877635911953319,
            "ave_precision_score": 0.6325300704778074,
            "fpr": 0.012074643249176729,
            "logloss": 0.6486576199868267,
            "mae": 0.45714195918304074,
            "precision": 0.9098360655737705,
            "recall": 0.22515212981744423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6807492812425123,
            "auditor_fn_violation": 0.0071926018951935355,
            "auditor_fp_violation": 0.0030439179989886064,
            "ave_precision_score": 0.6741095595907135,
            "fpr": 0.06907894736842106,
            "logloss": 0.6342082134853056,
            "mae": 0.45408502609975504,
            "precision": 0.7576923076923077,
            "recall": 0.42733188720173537
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.712725417453851,
            "auditor_fn_violation": 0.014886790478332227,
            "auditor_fp_violation": 0.004669142169864337,
            "ave_precision_score": 0.7069704674214246,
            "fpr": 0.06805708013172337,
            "logloss": 0.623376960785495,
            "mae": 0.4479687391533941,
            "precision": 0.7801418439716312,
            "recall": 0.4462474645030426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5097594070312279,
            "auditor_fn_violation": 0.007018970963199749,
            "auditor_fp_violation": 0.0028615746683782637,
            "ave_precision_score": 0.5124666415638093,
            "fpr": 0.06030701754385965,
            "logloss": 0.6939789991987434,
            "mae": 0.499285929427858,
            "precision": 0.5132743362831859,
            "recall": 0.12581344902386118
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.5432139506600371,
            "auditor_fn_violation": 0.006873395484087891,
            "auditor_fp_violation": 0.009065173661626373,
            "ave_precision_score": 0.5451795572395559,
            "fpr": 0.05378704720087816,
            "logloss": 0.6970460751189981,
            "mae": 0.5008006185849333,
            "precision": 0.5504587155963303,
            "recall": 0.12170385395537525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7464696188033174,
            "auditor_fn_violation": 0.01000875290177722,
            "auditor_fp_violation": 0.008920235733457817,
            "ave_precision_score": 0.7400476438688742,
            "fpr": 0.06578947368421052,
            "logloss": 0.5941946031060152,
            "mae": 0.4254005073912834,
            "precision": 0.8045602605863192,
            "recall": 0.5357917570498916
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7555437546781618,
            "auditor_fn_violation": 0.011671635609844085,
            "auditor_fp_violation": 2.6260642125223086e-05,
            "ave_precision_score": 0.749139799294697,
            "fpr": 0.06586169045005488,
            "logloss": 0.5892506425749425,
            "mae": 0.4222538424768249,
            "precision": 0.8142414860681114,
            "recall": 0.5334685598377282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6692213643093647,
            "auditor_fn_violation": 0.01639979830269818,
            "auditor_fp_violation": 0.03694519002606295,
            "ave_precision_score": 0.6677459030701097,
            "fpr": 0.19956140350877194,
            "logloss": 1.769335033059453,
            "mae": 0.3195681094614309,
            "precision": 0.668488160291439,
            "recall": 0.7960954446854663
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7064280964112472,
            "auditor_fn_violation": 0.02277995114923975,
            "auditor_fp_violation": 0.03680428993849758,
            "ave_precision_score": 0.7048494274040422,
            "fpr": 0.17233809001097694,
            "logloss": 1.6691091732614078,
            "mae": 0.3070228118349655,
            "precision": 0.7145454545454546,
            "recall": 0.7971602434077079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5206129196683472,
            "auditor_fn_violation": 0.007306770179244218,
            "auditor_fp_violation": 0.010369257400707979,
            "ave_precision_score": 0.5166483543665149,
            "fpr": 0.07675438596491228,
            "logloss": 0.6942153459869435,
            "mae": 0.4993772377635826,
            "precision": 0.5205479452054794,
            "recall": 0.1648590021691974
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.551398303436056,
            "auditor_fn_violation": 0.009721167697935774,
            "auditor_fp_violation": 0.005336162479844957,
            "ave_precision_score": 0.5490080462881938,
            "fpr": 0.06586169045005488,
            "logloss": 0.697394871905576,
            "mae": 0.5009328280989608,
            "precision": 0.5683453237410072,
            "recall": 0.16024340770791076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7178476482395488,
            "auditor_fn_violation": 0.006645545534117292,
            "auditor_fp_violation": 0.002810518535807369,
            "ave_precision_score": 0.7187823093451613,
            "fpr": 0.0668859649122807,
            "logloss": 0.6857472146923448,
            "mae": 0.35500064614563853,
            "precision": 0.8140243902439024,
            "recall": 0.579175704989154
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7076458940351027,
            "auditor_fn_violation": 0.013887064345402036,
            "auditor_fp_violation": 0.004025756437796421,
            "ave_precision_score": 0.7086634289771327,
            "fpr": 0.06695938529088913,
            "logloss": 0.757511742646152,
            "mae": 0.37553731138428464,
            "precision": 0.8157099697885196,
            "recall": 0.5476673427991886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7098600722400634,
            "auditor_fn_violation": 0.08447977318567569,
            "auditor_fp_violation": 0.09840461741937993,
            "ave_precision_score": 0.5559451122269807,
            "fpr": 0.2817982456140351,
            "logloss": 0.6879658081785031,
            "mae": 0.4854569660761116,
            "precision": 0.5576592082616179,
            "recall": 0.702819956616052
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7422367803077543,
            "auditor_fn_violation": 0.0966349975396495,
            "auditor_fp_violation": 0.09053618979091277,
            "ave_precision_score": 0.5991274718824445,
            "fpr": 0.2623490669593853,
            "logloss": 0.6691390394284928,
            "mae": 0.47695469336111906,
            "precision": 0.6016666666666667,
            "recall": 0.7322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7321147283853124,
            "auditor_fn_violation": 0.013571754766525865,
            "auditor_fp_violation": 0.0034888357256778304,
            "ave_precision_score": 0.7324774272612022,
            "fpr": 0.02850877192982456,
            "logloss": 0.646608345827692,
            "mae": 0.45394440051658375,
            "precision": 0.8074074074074075,
            "recall": 0.23644251626898047
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7775942317608505,
            "auditor_fn_violation": 0.006492653460187971,
            "auditor_fp_violation": 0.0018041061140026994,
            "ave_precision_score": 0.7778407840909619,
            "fpr": 0.01646542261251372,
            "logloss": 0.6214398176998389,
            "mae": 0.44305695799454375,
            "precision": 0.8936170212765957,
            "recall": 0.25557809330628806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6658920936857492,
            "auditor_fn_violation": 0.015317578110134338,
            "auditor_fp_violation": 0.03645650990002724,
            "ave_precision_score": 0.6642189524445912,
            "fpr": 0.19517543859649122,
            "logloss": 1.7717043720389016,
            "mae": 0.31922940880240114,
            "precision": 0.6703703703703704,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7077383163220651,
            "auditor_fn_violation": 0.026139832518040716,
            "auditor_fp_violation": 0.03660733512255842,
            "ave_precision_score": 0.705314476365452,
            "fpr": 0.16245883644346873,
            "logloss": 1.693611895851778,
            "mae": 0.3084075079406688,
            "precision": 0.7212806026365348,
            "recall": 0.7768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7288059280105321,
            "auditor_fn_violation": 0.012891502074057168,
            "auditor_fp_violation": 0.0034888357256778304,
            "ave_precision_score": 0.7291913925317234,
            "fpr": 0.02850877192982456,
            "logloss": 0.6442031351214073,
            "mae": 0.4522865184974906,
            "precision": 0.8088235294117647,
            "recall": 0.2386117136659436
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.776220886001847,
            "auditor_fn_violation": 0.006109684874744778,
            "auditor_fp_violation": 0.0018041061140026994,
            "ave_precision_score": 0.7764699635815412,
            "fpr": 0.01646542261251372,
            "logloss": 0.6190623143065928,
            "mae": 0.44129568623004706,
            "precision": 0.8943661971830986,
            "recall": 0.25760649087221094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7321247119044949,
            "auditor_fn_violation": 0.013571754766525865,
            "auditor_fp_violation": 0.0029904306220095694,
            "ave_precision_score": 0.7324949353827839,
            "fpr": 0.029605263157894735,
            "logloss": 0.6475437633366325,
            "mae": 0.4545226168018161,
            "precision": 0.8014705882352942,
            "recall": 0.23644251626898047
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7771854960469089,
            "auditor_fn_violation": 0.006492653460187971,
            "auditor_fp_violation": 0.0018041061140026994,
            "ave_precision_score": 0.7774359635776642,
            "fpr": 0.01646542261251372,
            "logloss": 0.6222319070254436,
            "mae": 0.4435981332961343,
            "precision": 0.8936170212765957,
            "recall": 0.25557809330628806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6652263385639259,
            "auditor_fn_violation": 0.015817064352856115,
            "auditor_fp_violation": 0.03838934920449683,
            "ave_precision_score": 0.6620038300783451,
            "fpr": 0.20285087719298245,
            "logloss": 1.8880762005303031,
            "mae": 0.32008429505017294,
            "precision": 0.6654611211573237,
            "recall": 0.7982646420824295
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7021296220163162,
            "auditor_fn_violation": 0.027823113044756122,
            "auditor_fp_violation": 0.03764200442229214,
            "ave_precision_score": 0.6999434527330721,
            "fpr": 0.17672886937431395,
            "logloss": 1.808555796220308,
            "mae": 0.3087699180855769,
            "precision": 0.7093862815884476,
            "recall": 0.7971602434077079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6650429482654139,
            "auditor_fn_violation": 0.016806522814628765,
            "auditor_fp_violation": 0.039546621542770465,
            "ave_precision_score": 0.6633038299995676,
            "fpr": 0.22807017543859648,
            "logloss": 1.8564043023093915,
            "mae": 0.32287835381672075,
            "precision": 0.6504201680672269,
            "recall": 0.8394793926247288
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.702773851990605,
            "auditor_fn_violation": 0.025881551379020894,
            "auditor_fp_violation": 0.04240568490380727,
            "ave_precision_score": 0.7004050798535573,
            "fpr": 0.19319429198682767,
            "logloss": 1.6839546993043781,
            "mae": 0.3017485790361565,
            "precision": 0.7001703577512777,
            "recall": 0.8336713995943205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7944636465324868,
            "auditor_fn_violation": 0.006773984853674319,
            "auditor_fp_violation": 0.0217304625199362,
            "ave_precision_score": 0.794883934740335,
            "fpr": 0.17434210526315788,
            "logloss": 0.9122725105886028,
            "mae": 0.2909384888780996,
            "precision": 0.6994328922495274,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8172429800484861,
            "auditor_fn_violation": 0.01669030532838443,
            "auditor_fp_violation": 0.02585622823649284,
            "ave_precision_score": 0.8176237052790224,
            "fpr": 0.16136114160263446,
            "logloss": 0.8993970784097088,
            "mae": 0.29287962866323836,
            "precision": 0.724202626641651,
            "recall": 0.7829614604462475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7282455889086772,
            "auditor_fn_violation": 0.017743654146211527,
            "auditor_fp_violation": 0.0023339946318123475,
            "ave_precision_score": 0.7177882637403495,
            "fpr": 0.023026315789473683,
            "logloss": 0.6060006918800023,
            "mae": 0.4342845281618729,
            "precision": 0.8944723618090452,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7186583539226381,
            "auditor_fn_violation": 0.004188162262899028,
            "auditor_fp_violation": 0.00483195815104071,
            "ave_precision_score": 0.7113437213119176,
            "fpr": 0.026344676180021953,
            "logloss": 0.6159578018506013,
            "mae": 0.43818160224170244,
            "precision": 0.8823529411764706,
            "recall": 0.36511156186612576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6671876399884341,
            "auditor_fn_violation": 0.00794658827111164,
            "auditor_fp_violation": 0.0061802232854864456,
            "ave_precision_score": 0.6682956962611536,
            "fpr": 0.05701754385964912,
            "logloss": 0.9047449027907508,
            "mae": 0.3975849415315966,
            "precision": 0.7777777777777778,
            "recall": 0.3947939262472885
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6648163467764296,
            "auditor_fn_violation": 0.013497416075329036,
            "auditor_fp_violation": 0.001538873628537965,
            "ave_precision_score": 0.6665222315121964,
            "fpr": 0.05817782656421515,
            "logloss": 1.0005692011618441,
            "mae": 0.4219427651983331,
            "precision": 0.7827868852459017,
            "recall": 0.38742393509127787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6657524520817197,
            "auditor_fn_violation": 0.016913555580926283,
            "auditor_fp_violation": 0.0390676663943673,
            "ave_precision_score": 0.6642535868184809,
            "fpr": 0.20065789473684212,
            "logloss": 1.7903721600802844,
            "mae": 0.32048447481368686,
            "precision": 0.6678765880217786,
            "recall": 0.7982646420824295
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7047307056431728,
            "auditor_fn_violation": 0.02613983251804072,
            "auditor_fp_violation": 0.03967457812278427,
            "ave_precision_score": 0.7023348551183597,
            "fpr": 0.1734357848518112,
            "logloss": 1.6863722065398938,
            "mae": 0.30777888966865213,
            "precision": 0.7137681159420289,
            "recall": 0.7991886409736308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6935638054696353,
            "auditor_fn_violation": 0.015619648361685126,
            "auditor_fp_violation": 0.016982242190842968,
            "ave_precision_score": 0.6919313996112361,
            "fpr": 0.10526315789473684,
            "logloss": 0.7828671101252391,
            "mae": 0.39702756264269784,
            "precision": 0.7280453257790368,
            "recall": 0.5574837310195228
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7159670029223405,
            "auditor_fn_violation": 0.016280618004421966,
            "auditor_fp_violation": 0.013931270647429873,
            "ave_precision_score": 0.7156994390962885,
            "fpr": 0.09110867178924259,
            "logloss": 0.8061171417167903,
            "mae": 0.4057640604784938,
            "precision": 0.7565982404692082,
            "recall": 0.5233265720081136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7101134456132228,
            "auditor_fn_violation": 0.003976861894432387,
            "auditor_fp_violation": 0.0024117944528727593,
            "ave_precision_score": 0.6476281899920869,
            "fpr": 0.021929824561403508,
            "logloss": 0.6324539696440651,
            "mae": 0.44126617415857156,
            "precision": 0.8518518518518519,
            "recall": 0.24945770065075923
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7613510790016751,
            "auditor_fn_violation": 0.0022688662125965628,
            "auditor_fp_violation": 0.0028440275421614605,
            "ave_precision_score": 0.7085691196651018,
            "fpr": 0.020856201975850714,
            "logloss": 0.6301978062961036,
            "mae": 0.438111306463586,
            "precision": 0.8789808917197452,
            "recall": 0.2799188640973631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7958133546209025,
            "auditor_fn_violation": 0.00454056779693268,
            "auditor_fp_violation": 0.01993620414673047,
            "ave_precision_score": 0.7962229393238136,
            "fpr": 0.17543859649122806,
            "logloss": 0.9104252778927878,
            "mae": 0.2906167751598104,
            "precision": 0.6963946869070209,
            "recall": 0.7960954446854663
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8176336892601732,
            "auditor_fn_violation": 0.01634964141226346,
            "auditor_fp_violation": 0.02602429634609426,
            "ave_precision_score": 0.8180067974959158,
            "fpr": 0.16245883644346873,
            "logloss": 0.8994090911414178,
            "mae": 0.29235631359708647,
            "precision": 0.7238805970149254,
            "recall": 0.7870182555780934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7433863488683696,
            "auditor_fn_violation": 0.01404745595007041,
            "auditor_fp_violation": 0.0036249854125335514,
            "ave_precision_score": 0.6970216592661822,
            "fpr": 0.03508771929824561,
            "logloss": 0.6166686444297105,
            "mae": 0.42847564179254205,
            "precision": 0.8638297872340426,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7711152814135798,
            "auditor_fn_violation": 0.003689412477205585,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.7283185157296503,
            "fpr": 0.03951701427003293,
            "logloss": 0.6033550938349181,
            "mae": 0.42190538791675863,
            "precision": 0.8554216867469879,
            "recall": 0.43204868154158216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7781851914893599,
            "auditor_fn_violation": 0.016649541424059083,
            "auditor_fp_violation": 0.00652545999144202,
            "ave_precision_score": 0.7791001158148626,
            "fpr": 0.03618421052631579,
            "logloss": 0.5684409523799687,
            "mae": 0.387001297843087,
            "precision": 0.8493150684931506,
            "recall": 0.403470715835141
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7957525406977253,
            "auditor_fn_violation": 0.010059605052513469,
            "auditor_fp_violation": 0.007358231923486993,
            "ave_precision_score": 0.7961673943887466,
            "fpr": 0.03512623490669594,
            "logloss": 0.5734732332280881,
            "mae": 0.38598150489637145,
            "precision": 0.8626609442060086,
            "recall": 0.4077079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.52962189266771,
            "auditor_fn_violation": 0.006904802679149062,
            "auditor_fp_violation": 0.014434298051114491,
            "ave_precision_score": 0.5204395587792167,
            "fpr": 0.11074561403508772,
            "logloss": 0.6929380845835889,
            "mae": 0.4986679334716316,
            "precision": 0.5120772946859904,
            "recall": 0.2299349240780911
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5577650429786764,
            "auditor_fn_violation": 0.010351284614682417,
            "auditor_fp_violation": 0.0107773675281908,
            "ave_precision_score": 0.5512005787781173,
            "fpr": 0.10428100987925357,
            "logloss": 0.6954449383596532,
            "mae": 0.49987392027736627,
            "precision": 0.525,
            "recall": 0.2129817444219067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8061802097313958,
            "auditor_fn_violation": 0.015300928568710289,
            "auditor_fp_violation": 0.00326272999572101,
            "ave_precision_score": 0.8035221703081781,
            "fpr": 0.03618421052631579,
            "logloss": 0.5807384170489301,
            "mae": 0.4128829847302353,
            "precision": 0.8613445378151261,
            "recall": 0.44468546637744033
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8293070701839171,
            "auditor_fn_violation": 0.004103552924254606,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.8262818077605121,
            "fpr": 0.03951701427003293,
            "logloss": 0.5781523954358575,
            "mae": 0.4101591458141346,
            "precision": 0.856,
            "recall": 0.4340770791075051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5482758922289829,
            "auditor_fn_violation": 0.006802526924686991,
            "auditor_fp_violation": 0.009192535107169254,
            "ave_precision_score": 0.5418957214714136,
            "fpr": 0.05921052631578947,
            "logloss": 0.691287781339687,
            "mae": 0.49688559375180485,
            "precision": 0.55,
            "recall": 0.14316702819956617
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5951667534140925,
            "auditor_fn_violation": 0.007256364069531085,
            "auditor_fp_violation": 0.01033093661206204,
            "ave_precision_score": 0.591033249167409,
            "fpr": 0.038419319429198684,
            "logloss": 0.6942381135100576,
            "mae": 0.49830552317308413,
            "precision": 0.65,
            "recall": 0.13184584178498987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.612054999494534,
            "auditor_fn_violation": 0.0061056246907942235,
            "auditor_fp_violation": 0.01755358462675536,
            "ave_precision_score": 0.6049552303434556,
            "fpr": 0.08771929824561403,
            "logloss": 11.544774479952173,
            "mae": 0.45880910742011305,
            "precision": 0.6078431372549019,
            "recall": 0.26898047722342733
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6480271376896487,
            "auditor_fn_violation": 0.008855035257602043,
            "auditor_fp_violation": 0.014403962205683853,
            "ave_precision_score": 0.6409681873803701,
            "fpr": 0.07793633369923161,
            "logloss": 12.048635583438445,
            "mae": 0.4757525158110313,
            "precision": 0.6650943396226415,
            "recall": 0.28600405679513186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5284038486811342,
            "auditor_fn_violation": 0.006904802679149062,
            "auditor_fp_violation": 0.013279456957248997,
            "ave_precision_score": 0.5197575611883275,
            "fpr": 0.10964912280701754,
            "logloss": 0.6927671175228735,
            "mae": 0.4991610906037845,
            "precision": 0.5145631067961165,
            "recall": 0.2299349240780911
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.559668343760899,
            "auditor_fn_violation": 0.009634331797748048,
            "auditor_fp_violation": 0.012626116733806382,
            "ave_precision_score": 0.5528265725088967,
            "fpr": 0.10208562019758508,
            "logloss": 0.6945222914841015,
            "mae": 0.5000104058194501,
            "precision": 0.5279187817258884,
            "recall": 0.21095334685598377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6563997404203605,
            "auditor_fn_violation": 0.01735833618754044,
            "auditor_fp_violation": 0.03886344186408372,
            "ave_precision_score": 0.6515354842288097,
            "fpr": 0.20175438596491227,
            "logloss": 2.0266644119139,
            "mae": 0.32122359029560693,
            "precision": 0.6684684684684684,
            "recall": 0.8047722342733189
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6990730937660294,
            "auditor_fn_violation": 0.025115614208134525,
            "auditor_fp_violation": 0.03666510853523391,
            "ave_precision_score": 0.6951598059181181,
            "fpr": 0.17233809001097694,
            "logloss": 1.8201797032453468,
            "mae": 0.3070765039183193,
            "precision": 0.7140255009107468,
            "recall": 0.795131845841785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.52962189266771,
            "auditor_fn_violation": 0.006904802679149062,
            "auditor_fp_violation": 0.014434298051114491,
            "ave_precision_score": 0.5204395587792167,
            "fpr": 0.11074561403508772,
            "logloss": 0.6929243764334022,
            "mae": 0.4986710332399398,
            "precision": 0.5120772946859904,
            "recall": 0.2299349240780911
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5579504674063803,
            "auditor_fn_violation": 0.010351284614682417,
            "auditor_fp_violation": 0.0107773675281908,
            "ave_precision_score": 0.5512005787781173,
            "fpr": 0.10428100987925357,
            "logloss": 0.695413854281463,
            "mae": 0.49986863672798737,
            "precision": 0.525,
            "recall": 0.2129817444219067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7340802926032628,
            "auditor_fn_violation": 0.00943315446968833,
            "auditor_fp_violation": 0.003257867506904734,
            "ave_precision_score": 0.7349613219672351,
            "fpr": 0.06140350877192982,
            "logloss": 0.7787185494757389,
            "mae": 0.3440601090949617,
            "precision": 0.8318318318318318,
            "recall": 0.6008676789587852
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7203282077129591,
            "auditor_fn_violation": 0.008881753996121332,
            "auditor_fp_violation": 0.0012421283725229655,
            "ave_precision_score": 0.7211912355817481,
            "fpr": 0.06037321624588365,
            "logloss": 0.8834343891320314,
            "mae": 0.36421257339450647,
            "precision": 0.8297213622291022,
            "recall": 0.5436105476673428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6656942448176828,
            "auditor_fn_violation": 0.016982532252540247,
            "auditor_fp_violation": 0.03640545376745633,
            "ave_precision_score": 0.6642823371914213,
            "fpr": 0.19956140350877194,
            "logloss": 1.787893588954307,
            "mae": 0.320247088281576,
            "precision": 0.6678832116788321,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.704734392059734,
            "auditor_fn_violation": 0.027253113289677885,
            "auditor_fp_violation": 0.039154617408704885,
            "ave_precision_score": 0.7023442346219473,
            "fpr": 0.17014270032930845,
            "logloss": 1.685392439030664,
            "mae": 0.3078203238348876,
            "precision": 0.7161172161172161,
            "recall": 0.7931034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5723240971355117,
            "auditor_fn_violation": 0.09036895383795715,
            "auditor_fp_violation": 0.10767252110320147,
            "ave_precision_score": 0.5734781966190787,
            "fpr": 0.30701754385964913,
            "logloss": 0.688633648357314,
            "mae": 0.4916069711182724,
            "precision": 0.5483870967741935,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5822155064215182,
            "auditor_fn_violation": 0.0953858965138726,
            "auditor_fp_violation": 0.10127154029170321,
            "ave_precision_score": 0.5840536265772382,
            "fpr": 0.29308452250274425,
            "logloss": 0.6834702943236975,
            "mae": 0.48897584392786286,
            "precision": 0.5788643533123028,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7153688246448803,
            "auditor_fn_violation": 0.0067620923240857035,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.7161419786165462,
            "fpr": 0.01864035087719298,
            "logloss": 0.6391704414077504,
            "mae": 0.4536592209254179,
            "precision": 0.8547008547008547,
            "recall": 0.21691973969631237
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.763796809559288,
            "auditor_fn_violation": 0.007051520407549833,
            "auditor_fp_violation": 0.001381309775786638,
            "ave_precision_score": 0.7640741929589275,
            "fpr": 0.013172338090010977,
            "logloss": 0.6251573024196674,
            "mae": 0.4462458916278362,
            "precision": 0.9076923076923077,
            "recall": 0.23935091277890466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6619257422226026,
            "auditor_fn_violation": 0.014068862503329912,
            "auditor_fp_violation": 0.036670459407943376,
            "ave_precision_score": 0.6603399183005135,
            "fpr": 0.20175438596491227,
            "logloss": 1.846824716415176,
            "mae": 0.322975632160575,
            "precision": 0.6684684684684684,
            "recall": 0.8047722342733189
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7028207420165516,
            "auditor_fn_violation": 0.021383897061606736,
            "auditor_fp_violation": 0.037894106586694266,
            "ave_precision_score": 0.7004871301201446,
            "fpr": 0.1734357848518112,
            "logloss": 1.7225134698279534,
            "mae": 0.3078222820486739,
            "precision": 0.7111517367458866,
            "recall": 0.7890466531440162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7082904616320701,
            "auditor_fn_violation": 0.013835768923393084,
            "auditor_fp_violation": 0.0027400124479713705,
            "ave_precision_score": 0.709046032197791,
            "fpr": 0.047149122807017545,
            "logloss": 0.6313158649685486,
            "mae": 0.4402879466580456,
            "precision": 0.8088888888888889,
            "recall": 0.3947939262472885
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7583433677345246,
            "auditor_fn_violation": 0.012413080603754437,
            "auditor_fp_violation": 0.0035609430721800016,
            "ave_precision_score": 0.7586784285836998,
            "fpr": 0.03732162458836443,
            "logloss": 0.6153336456038587,
            "mae": 0.43137423545285714,
            "precision": 0.8540772532188842,
            "recall": 0.40365111561866124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7944221825930774,
            "auditor_fn_violation": 0.00689053164364273,
            "auditor_fp_violation": 0.020933014354066987,
            "ave_precision_score": 0.7948360355656494,
            "fpr": 0.17214912280701755,
            "logloss": 0.9157413661640766,
            "mae": 0.29177080605139005,
            "precision": 0.6986564299424184,
            "recall": 0.789587852494577
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8155835974186931,
            "auditor_fn_violation": 0.016774914667028854,
            "auditor_fp_violation": 0.02792031470753523,
            "ave_precision_score": 0.8159613279990623,
            "fpr": 0.16465422612513722,
            "logloss": 0.9095881585429638,
            "mae": 0.29354083210831505,
            "precision": 0.719626168224299,
            "recall": 0.7809330628803245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6907965822718253,
            "auditor_fn_violation": 0.005767876850477615,
            "auditor_fp_violation": 0.0054970436067997095,
            "ave_precision_score": 0.6918514637716734,
            "fpr": 0.0625,
            "logloss": 0.7935834462108571,
            "mae": 0.378839116481239,
            "precision": 0.7934782608695652,
            "recall": 0.4750542299349241
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6839832102029841,
            "auditor_fn_violation": 0.013207963074703385,
            "auditor_fp_violation": 0.0075368042899385,
            "ave_precision_score": 0.6851478636923038,
            "fpr": 0.06366630076838639,
            "logloss": 0.8816436435722566,
            "mae": 0.40241343658887724,
            "precision": 0.7972027972027972,
            "recall": 0.46247464503042596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6148517181346176,
            "auditor_fn_violation": 0.009492617117631387,
            "auditor_fp_violation": 0.018732738164702223,
            "ave_precision_score": 0.6078874137798483,
            "fpr": 0.08662280701754387,
            "logloss": 11.540555071061284,
            "mae": 0.4580423775798596,
            "precision": 0.6146341463414634,
            "recall": 0.27331887201735355
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6486971066432254,
            "auditor_fn_violation": 0.00905319923495345,
            "auditor_fp_violation": 0.014259528673995138,
            "ave_precision_score": 0.6416164858418655,
            "fpr": 0.07793633369923161,
            "logloss": 12.047073222435866,
            "mae": 0.4767674577818091,
            "precision": 0.6666666666666666,
            "recall": 0.2880324543610548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.615650246993678,
            "auditor_fn_violation": 0.009492617117631387,
            "auditor_fp_violation": 0.018732738164702223,
            "ave_precision_score": 0.6078928367013148,
            "fpr": 0.08662280701754387,
            "logloss": 11.541194027533983,
            "mae": 0.45804186454845863,
            "precision": 0.6146341463414634,
            "recall": 0.27331887201735355
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6479859999260897,
            "auditor_fn_violation": 0.00905319923495345,
            "auditor_fp_violation": 0.014259528673995138,
            "ave_precision_score": 0.6414656906480085,
            "fpr": 0.07793633369923161,
            "logloss": 12.047532150164526,
            "mae": 0.4767675318539801,
            "precision": 0.6666666666666666,
            "recall": 0.2880324543610548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7189260263635251,
            "auditor_fn_violation": 9.751874262664817e-05,
            "auditor_fp_violation": 0.0058957676897343145,
            "ave_precision_score": 0.7194433372407237,
            "fpr": 0.0581140350877193,
            "logloss": 0.7516643632952622,
            "mae": 0.44231766319744853,
            "precision": 0.7568807339449541,
            "recall": 0.3579175704989154
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.7667234198530508,
            "auditor_fn_violation": 0.0057912865740565615,
            "auditor_fp_violation": 0.00961664714625602,
            "ave_precision_score": 0.7680663383509554,
            "fpr": 0.054884742041712405,
            "logloss": 0.6442459887363692,
            "mae": 0.4331700089860117,
            "precision": 0.7925311203319502,
            "recall": 0.38742393509127787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7282455889086772,
            "auditor_fn_violation": 0.017743654146211527,
            "auditor_fp_violation": 0.0023339946318123475,
            "ave_precision_score": 0.7177882637403495,
            "fpr": 0.023026315789473683,
            "logloss": 0.606000707614431,
            "mae": 0.4342845369195729,
            "precision": 0.8944723618090452,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7186583539226381,
            "auditor_fn_violation": 0.004188162262899028,
            "auditor_fp_violation": 0.00483195815104071,
            "ave_precision_score": 0.7113437213119176,
            "fpr": 0.026344676180021953,
            "logloss": 0.6159577973154301,
            "mae": 0.43818160148928376,
            "precision": 0.8823529411764706,
            "recall": 0.36511156186612576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7038864511553315,
            "auditor_fn_violation": 0.003912642234653875,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.6382466025013076,
            "fpr": 0.01864035087719298,
            "logloss": 0.6366788737208381,
            "mae": 0.44710001090476126,
            "precision": 0.8583333333333333,
            "recall": 0.22342733188720174
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7647540999738043,
            "auditor_fn_violation": 0.007316481231199476,
            "auditor_fp_violation": 0.001877635911953319,
            "ave_precision_score": 0.703668209149975,
            "fpr": 0.012074643249176729,
            "logloss": 0.6307489460584655,
            "mae": 0.4431175922506727,
            "precision": 0.917910447761194,
            "recall": 0.24949290060851928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7153685830574765,
            "auditor_fn_violation": 0.034340868440080684,
            "auditor_fp_violation": 0.012190259462403237,
            "ave_precision_score": 0.7148769866931528,
            "fpr": 0.043859649122807015,
            "logloss": 0.6200537609090974,
            "mae": 0.42041225041867347,
            "precision": 0.841897233201581,
            "recall": 0.46203904555314534
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7414007633777616,
            "auditor_fn_violation": 0.020210499128301154,
            "auditor_fp_violation": 0.010091964768722525,
            "ave_precision_score": 0.7464219516731809,
            "fpr": 0.042810098792535674,
            "logloss": 0.600983168683492,
            "mae": 0.4081166244626176,
            "precision": 0.8612099644128114,
            "recall": 0.4908722109533469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6491394481230506,
            "auditor_fn_violation": 0.016844578909312333,
            "auditor_fp_violation": 0.04164964795580971,
            "ave_precision_score": 0.6459354666348354,
            "fpr": 0.21052631578947367,
            "logloss": 2.0434030718945015,
            "mae": 0.3265984813035111,
            "precision": 0.6583629893238434,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6947027450909715,
            "auditor_fn_violation": 0.025990652894641336,
            "auditor_fp_violation": 0.03966932599435921,
            "ave_precision_score": 0.6915542656006646,
            "fpr": 0.17453347969264543,
            "logloss": 1.8261158094992318,
            "mae": 0.3083979077037528,
            "precision": 0.7129963898916968,
            "recall": 0.8012170385395537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.770604419882975,
            "auditor_fn_violation": 0.014368554248962991,
            "auditor_fp_violation": 0.0043956898899132546,
            "ave_precision_score": 0.7716755828142541,
            "fpr": 0.03399122807017544,
            "logloss": 0.5728735809259121,
            "mae": 0.39317348629661036,
            "precision": 0.8516746411483254,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7923365833498326,
            "auditor_fn_violation": 0.01268472111203393,
            "auditor_fp_violation": 0.00515233798496841,
            "ave_precision_score": 0.7927719323363813,
            "fpr": 0.029637760702524697,
            "logloss": 0.5737043789641801,
            "mae": 0.3901813494841007,
            "precision": 0.8772727272727273,
            "recall": 0.39148073022312374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 26311,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5254492884892147,
            "auditor_fn_violation": 0.08132587433877536,
            "auditor_fp_violation": 0.08948195044151398,
            "ave_precision_score": 0.5256584199075234,
            "fpr": 0.28399122807017546,
            "logloss": 0.6891659245468932,
            "mae": 0.49692906409894166,
            "precision": 0.5399644760213144,
            "recall": 0.6594360086767896
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5540168480585986,
            "auditor_fn_violation": 0.07901844260926295,
            "auditor_fp_violation": 0.08181765660533932,
            "ave_precision_score": 0.5566946788681448,
            "fpr": 0.27442371020856204,
            "logloss": 0.688134063958042,
            "mae": 0.4963719546467753,
            "precision": 0.5812395309882747,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6187959853770444,
            "auditor_fn_violation": 0.002399912470982238,
            "auditor_fp_violation": 0.003525304391799899,
            "ave_precision_score": 0.6201664945383422,
            "fpr": 0.013157894736842105,
            "logloss": 7.042541577395349,
            "mae": 0.45186024831674076,
            "precision": 0.8899082568807339,
            "recall": 0.210412147505423
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6223341437249801,
            "auditor_fn_violation": 0.005715583481585239,
            "auditor_fp_violation": 0.002158624782693187,
            "ave_precision_score": 0.6240538334226311,
            "fpr": 0.01756311745334797,
            "logloss": 7.57616204149509,
            "mae": 0.48831736056391545,
            "precision": 0.8415841584158416,
            "recall": 0.1724137931034483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7150201029611567,
            "auditor_fn_violation": 0.009632948966777029,
            "auditor_fp_violation": 0.014631228848173656,
            "ave_precision_score": 0.7139604416503045,
            "fpr": 0.1875,
            "logloss": 1.3570099126574835,
            "mae": 0.30198599817907396,
            "precision": 0.6815642458100558,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7573735726699482,
            "auditor_fn_violation": 0.016040149357748324,
            "auditor_fp_violation": 0.020764289728412436,
            "ave_precision_score": 0.7547349055544412,
            "fpr": 0.17014270032930845,
            "logloss": 1.3296987277273553,
            "mae": 0.30169277376548126,
            "precision": 0.710820895522388,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6165073667667632,
            "auditor_fn_violation": 0.009720953685732779,
            "auditor_fp_violation": 0.007621951219512195,
            "ave_precision_score": 0.6088838665522548,
            "fpr": 0.09429824561403509,
            "logloss": 11.366446105466146,
            "mae": 0.4593951929194164,
            "precision": 0.5981308411214953,
            "recall": 0.27765726681127983
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6528898772199669,
            "auditor_fn_violation": 0.01377128314515179,
            "auditor_fp_violation": 0.011898696946937749,
            "ave_precision_score": 0.6457267371737452,
            "fpr": 0.09110867178924259,
            "logloss": 11.907480864142038,
            "mae": 0.4716062092619301,
            "precision": 0.6437768240343348,
            "recall": 0.30425963488843816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7713107877881987,
            "auditor_fn_violation": 0.014368554248962991,
            "auditor_fp_violation": 0.0033210798615163194,
            "ave_precision_score": 0.7723803263619432,
            "fpr": 0.03289473684210526,
            "logloss": 0.5721556401823815,
            "mae": 0.392212404144454,
            "precision": 0.8557692307692307,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7922474896602396,
            "auditor_fn_violation": 0.01268472111203393,
            "auditor_fp_violation": 0.005010530517492213,
            "ave_precision_score": 0.7926831078287522,
            "fpr": 0.02854006586169045,
            "logloss": 0.5735851259100371,
            "mae": 0.38947778415347883,
            "precision": 0.8812785388127854,
            "recall": 0.39148073022312374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6306899139025004,
            "auditor_fn_violation": 0.006890531643642729,
            "auditor_fp_violation": 0.0035277356362080374,
            "ave_precision_score": 0.6320931674456572,
            "fpr": 0.019736842105263157,
            "logloss": 0.652405735588357,
            "mae": 0.4608636093897778,
            "precision": 0.8487394957983193,
            "recall": 0.21908893709327548
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7044095159500975,
            "auditor_fn_violation": 0.008187066794619727,
            "auditor_fp_violation": 0.001318284234686107,
            "ave_precision_score": 0.7048791475369591,
            "fpr": 0.013172338090010977,
            "logloss": 0.6368408177623378,
            "mae": 0.45219877169239536,
            "precision": 0.9090909090909091,
            "recall": 0.2434077079107505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7081545267264953,
            "auditor_fn_violation": 0.013835768923393084,
            "auditor_fp_violation": 0.0027400124479713705,
            "ave_precision_score": 0.7089949769478183,
            "fpr": 0.047149122807017545,
            "logloss": 0.6312877030065875,
            "mae": 0.44029199462710766,
            "precision": 0.8088888888888889,
            "recall": 0.3947939262472885
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7578133608603366,
            "auditor_fn_violation": 0.012413080603754437,
            "auditor_fp_violation": 0.0035609430721800016,
            "ave_precision_score": 0.7582434697786044,
            "fpr": 0.03732162458836443,
            "logloss": 0.6153287497562077,
            "mae": 0.43137567437179264,
            "precision": 0.8540772532188842,
            "recall": 0.40365111561866124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6321780874668865,
            "auditor_fn_violation": 0.010631921452220599,
            "auditor_fp_violation": 0.01247228381374723,
            "ave_precision_score": 0.6278571143665314,
            "fpr": 0.07785087719298246,
            "logloss": 9.915509378360932,
            "mae": 0.44910610048351407,
            "precision": 0.6485148514851485,
            "recall": 0.2841648590021692
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6641425504523246,
            "auditor_fn_violation": 0.015432298056434453,
            "auditor_fp_violation": 0.009296267312328323,
            "ave_precision_score": 0.6591109891126474,
            "fpr": 0.08122941822173436,
            "logloss": 10.58646780961318,
            "mae": 0.4684231121932704,
            "precision": 0.6621004566210046,
            "recall": 0.29411764705882354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7098600722400634,
            "auditor_fn_violation": 0.08447977318567569,
            "auditor_fp_violation": 0.09840461741937993,
            "ave_precision_score": 0.5559451122269807,
            "fpr": 0.2817982456140351,
            "logloss": 0.6880411981508867,
            "mae": 0.4854447045363486,
            "precision": 0.5576592082616179,
            "recall": 0.702819956616052
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7422367803077543,
            "auditor_fn_violation": 0.0966349975396495,
            "auditor_fp_violation": 0.09053618979091277,
            "ave_precision_score": 0.5991274718824445,
            "fpr": 0.2623490669593853,
            "logloss": 0.6691465052098114,
            "mae": 0.4769228346294158,
            "precision": 0.6016666666666667,
            "recall": 0.7322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6164641678223682,
            "auditor_fn_violation": 0.0011678464056018578,
            "auditor_fp_violation": 0.016350118644727116,
            "ave_precision_score": 0.6088551929786309,
            "fpr": 0.09868421052631579,
            "logloss": 11.45754693102103,
            "mae": 0.45848602306873454,
            "precision": 0.6103896103896104,
            "recall": 0.30585683297180044
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6521967041318171,
            "auditor_fn_violation": 0.012301752526590727,
            "auditor_fp_violation": 0.013608264749289653,
            "ave_precision_score": 0.6450326140267464,
            "fpr": 0.09330406147091108,
            "logloss": 11.977102919456758,
            "mae": 0.4715001426547261,
            "precision": 0.6428571428571429,
            "recall": 0.3103448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6883936014315541,
            "auditor_fn_violation": 0.011454884499752651,
            "auditor_fp_violation": 0.006678628389154707,
            "ave_precision_score": 0.6893453807294425,
            "fpr": 0.0581140350877193,
            "logloss": 0.8040779439866877,
            "mae": 0.38431486642066537,
            "precision": 0.7969348659003831,
            "recall": 0.4511930585683297
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6870323813483222,
            "auditor_fn_violation": 0.018168742193118592,
            "auditor_fp_violation": 0.005257380553469294,
            "ave_precision_score": 0.6881508982802238,
            "fpr": 0.06037321624588365,
            "logloss": 0.8862807734286584,
            "mae": 0.40525202245045655,
            "precision": 0.7955390334572491,
            "recall": 0.4340770791075051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7446455399688465,
            "auditor_fn_violation": 0.0122469269703543,
            "auditor_fp_violation": 0.0016483837087174701,
            "ave_precision_score": 0.738655960759474,
            "fpr": 0.05482456140350877,
            "logloss": 0.5868835338305205,
            "mae": 0.41035362917995244,
            "precision": 0.8422712933753943,
            "recall": 0.579175704989154
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7722252606166201,
            "auditor_fn_violation": 0.016692531889927704,
            "auditor_fp_violation": 0.006271041339502833,
            "ave_precision_score": 0.7659867656309897,
            "fpr": 0.042810098792535674,
            "logloss": 0.5705098299182988,
            "mae": 0.4036633830300801,
            "precision": 0.8773584905660378,
            "recall": 0.565922920892495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7034540823179831,
            "auditor_fn_violation": 0.003912642234653875,
            "auditor_fp_violation": 0.0035471855914731404,
            "ave_precision_score": 0.6383744992803898,
            "fpr": 0.01864035087719298,
            "logloss": 0.635950165773611,
            "mae": 0.4461309019590548,
            "precision": 0.8583333333333333,
            "recall": 0.22342733188720174
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7647682959961453,
            "auditor_fn_violation": 0.007316481231199476,
            "auditor_fp_violation": 0.001877635911953319,
            "ave_precision_score": 0.7035585367637531,
            "fpr": 0.012074643249176729,
            "logloss": 0.6297628932106022,
            "mae": 0.4419566839769826,
            "precision": 0.917910447761194,
            "recall": 0.24949290060851928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7643027441039583,
            "auditor_fn_violation": 0.004276553640065458,
            "auditor_fp_violation": 0.006479266347687402,
            "ave_precision_score": 0.7618947816022344,
            "fpr": 0.044956140350877194,
            "logloss": 0.5833330312579925,
            "mae": 0.37951553390737164,
            "precision": 0.8642384105960265,
            "recall": 0.5661605206073753
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7990727312249924,
            "auditor_fn_violation": 0.005134450918790633,
            "auditor_fp_violation": 0.009574630118855667,
            "ave_precision_score": 0.7958604025800957,
            "fpr": 0.03951701427003293,
            "logloss": 0.5661068078060599,
            "mae": 0.37379375178649055,
            "precision": 0.8842443729903537,
            "recall": 0.5578093306288032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6147858267673607,
            "auditor_fn_violation": 0.009492617117631387,
            "auditor_fp_violation": 0.018732738164702223,
            "ave_precision_score": 0.6078217797130551,
            "fpr": 0.08662280701754387,
            "logloss": 11.540575679199947,
            "mae": 0.4580450434481747,
            "precision": 0.6146341463414634,
            "recall": 0.27331887201735355
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6482486773942352,
            "auditor_fn_violation": 0.00905319923495345,
            "auditor_fp_violation": 0.014259528673995138,
            "ave_precision_score": 0.6415747191782385,
            "fpr": 0.07793633369923161,
            "logloss": 12.047081571613074,
            "mae": 0.4767660064866454,
            "precision": 0.6666666666666666,
            "recall": 0.2880324543610548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5410265257895284,
            "auditor_fn_violation": 0.006305419187882951,
            "auditor_fp_violation": 0.003447504570739487,
            "ave_precision_score": 0.5425604496666044,
            "fpr": 0.05921052631578947,
            "logloss": 0.6937803726263925,
            "mae": 0.49931048471153827,
            "precision": 0.5135135135135135,
            "recall": 0.12364425162689804
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5643542211400167,
            "auditor_fn_violation": 0.006873395484087891,
            "auditor_fp_violation": 0.008350884195820358,
            "ave_precision_score": 0.5666768333280352,
            "fpr": 0.052689352360043906,
            "logloss": 0.6974264700273307,
            "mae": 0.5010854923437246,
            "precision": 0.5555555555555556,
            "recall": 0.12170385395537525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6218962213906598,
            "auditor_fn_violation": 0.008027457472314202,
            "auditor_fp_violation": 0.010850643793519276,
            "ave_precision_score": 0.6142778159771352,
            "fpr": 0.09539473684210527,
            "logloss": 11.366308207723067,
            "mae": 0.4573497295441215,
            "precision": 0.6063348416289592,
            "recall": 0.29067245119305857
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6538000641959989,
            "auditor_fn_violation": 0.012936322566423904,
            "auditor_fp_violation": 0.014779489388074522,
            "ave_precision_score": 0.6466240105585708,
            "fpr": 0.09330406147091108,
            "logloss": 11.910928118084989,
            "mae": 0.4728185910129054,
            "precision": 0.6443514644351465,
            "recall": 0.31237322515212984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7929841588200874,
            "auditor_fn_violation": 0.007489915134908856,
            "auditor_fp_violation": 0.025812521881199674,
            "ave_precision_score": 0.7933843072405875,
            "fpr": 0.18311403508771928,
            "logloss": 0.9499745511203007,
            "mae": 0.289215338355068,
            "precision": 0.6895910780669146,
            "recall": 0.8047722342733189
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8124232738450403,
            "auditor_fn_violation": 0.017438430006924608,
            "auditor_fp_violation": 0.023335206592471607,
            "ave_precision_score": 0.8129371406062269,
            "fpr": 0.16136114160263446,
            "logloss": 0.9447284571577091,
            "mae": 0.291914625602061,
            "precision": 0.7231638418079096,
            "recall": 0.7789046653144016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7662075501033582,
            "auditor_fn_violation": 0.004542946302850406,
            "auditor_fp_violation": 0.0070603337612323526,
            "ave_precision_score": 0.7666731932370499,
            "fpr": 0.043859649122807015,
            "logloss": 0.58255899368221,
            "mae": 0.38189625965529367,
            "precision": 0.8657718120805369,
            "recall": 0.559652928416486
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.792363923752739,
            "auditor_fn_violation": 0.0056599194430033625,
            "auditor_fp_violation": 0.009574630118855667,
            "ave_precision_score": 0.7926816014330298,
            "fpr": 0.03951701427003293,
            "logloss": 0.5658668709395325,
            "mae": 0.3752420650290082,
            "precision": 0.8838709677419355,
            "recall": 0.5557809330628803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7947126645225053,
            "auditor_fn_violation": 0.006683601628800857,
            "auditor_fp_violation": 0.021032695374800646,
            "ave_precision_score": 0.7951288416185336,
            "fpr": 0.17543859649122806,
            "logloss": 0.9093432560331705,
            "mae": 0.29099409883266725,
            "precision": 0.6975425330812854,
            "recall": 0.8004338394793926
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8172018448674148,
            "auditor_fn_violation": 0.0162939773736816,
            "auditor_fp_violation": 0.02453269187338169,
            "ave_precision_score": 0.8175366961463605,
            "fpr": 0.1602634467618002,
            "logloss": 0.8951705006544195,
            "mae": 0.29334936755158125,
            "precision": 0.7250470809792844,
            "recall": 0.7809330628803245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7777225131518013,
            "auditor_fn_violation": 0.015393690299501482,
            "auditor_fp_violation": 0.004118528027385538,
            "ave_precision_score": 0.7785182958542212,
            "fpr": 0.03728070175438596,
            "logloss": 0.5685196438878646,
            "mae": 0.3863969815633537,
            "precision": 0.8425925925925926,
            "recall": 0.3947939262472885
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7966273399075984,
            "auditor_fn_violation": 0.004185935701355763,
            "auditor_fp_violation": 0.006738480769331773,
            "ave_precision_score": 0.7970051726489684,
            "fpr": 0.03293084522502744,
            "logloss": 0.5720284495917283,
            "mae": 0.38472637556632316,
            "precision": 0.868995633187773,
            "recall": 0.40365111561866124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7958981475858975,
            "auditor_fn_violation": 0.005496727175857217,
            "auditor_fp_violation": 0.01993620414673047,
            "ave_precision_score": 0.796307589750223,
            "fpr": 0.17543859649122806,
            "logloss": 0.9103310102949099,
            "mae": 0.29056088143081704,
            "precision": 0.696969696969697,
            "recall": 0.7982646420824295
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8177496962271308,
            "auditor_fn_violation": 0.01634964141226346,
            "auditor_fp_violation": 0.02602429634609426,
            "ave_precision_score": 0.8181225637593084,
            "fpr": 0.16245883644346873,
            "logloss": 0.8992258936258998,
            "mae": 0.2922975827548724,
            "precision": 0.7238805970149254,
            "recall": 0.7870182555780934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5284038486811342,
            "auditor_fn_violation": 0.006904802679149062,
            "auditor_fp_violation": 0.013279456957248997,
            "ave_precision_score": 0.5197575611883275,
            "fpr": 0.10964912280701754,
            "logloss": 0.6927671222607723,
            "mae": 0.4991610906691405,
            "precision": 0.5145631067961165,
            "recall": 0.2299349240780911
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.559668343760899,
            "auditor_fn_violation": 0.009634331797748048,
            "auditor_fp_violation": 0.012626116733806382,
            "ave_precision_score": 0.5528265725088967,
            "fpr": 0.10208562019758508,
            "logloss": 0.694522305289896,
            "mae": 0.500010410366676,
            "precision": 0.5279187817258884,
            "recall": 0.21095334685598377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7636971485490551,
            "auditor_fn_violation": 0.014898961068615149,
            "auditor_fp_violation": 0.0006272610572995693,
            "ave_precision_score": 0.7620196490105895,
            "fpr": 0.04057017543859649,
            "logloss": 0.6191508559804532,
            "mae": 0.4357904636611541,
            "precision": 0.8287037037037037,
            "recall": 0.3882863340563991
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7881791866825276,
            "auditor_fn_violation": 0.012214916626403019,
            "auditor_fp_violation": 0.00418857241897279,
            "ave_precision_score": 0.7854104441097437,
            "fpr": 0.036223929747530186,
            "logloss": 0.6098210025904258,
            "mae": 0.42948557745612154,
            "precision": 0.8558951965065502,
            "recall": 0.3975659229208925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7803727530097936,
            "auditor_fn_violation": 0.0026686836396848986,
            "auditor_fp_violation": 0.01971496090558992,
            "ave_precision_score": 0.7808150259552756,
            "fpr": 0.15350877192982457,
            "logloss": 0.8801820205270804,
            "mae": 0.3017233373604994,
            "precision": 0.7071129707112971,
            "recall": 0.7331887201735358
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7977798908166576,
            "auditor_fn_violation": 0.01801733600817594,
            "auditor_fp_violation": 0.025278494109737974,
            "ave_precision_score": 0.7982224574072215,
            "fpr": 0.1350164654226125,
            "logloss": 0.9115594317303991,
            "mae": 0.3086747887010693,
            "precision": 0.7415966386554622,
            "recall": 0.716024340770791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7764925569773462,
            "auditor_fn_violation": 0.01404745595007041,
            "auditor_fp_violation": 0.0033478235500058367,
            "ave_precision_score": 0.6780682933381621,
            "fpr": 0.03399122807017544,
            "logloss": 0.6149762587061635,
            "mae": 0.42854047968591513,
            "precision": 0.8675213675213675,
            "recall": 0.4403470715835141
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7974157651657623,
            "auditor_fn_violation": 0.003689412477205585,
            "auditor_fp_violation": 0.0050525475448925695,
            "ave_precision_score": 0.7069244731309543,
            "fpr": 0.03951701427003293,
            "logloss": 0.6027617288947249,
            "mae": 0.42203816068159367,
            "precision": 0.8554216867469879,
            "recall": 0.43204868154158216
        }
    }
]