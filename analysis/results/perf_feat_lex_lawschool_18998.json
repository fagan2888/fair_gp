[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8333272644220011,
            "auditor_fn_violation": 0.007612919359803018,
            "auditor_fp_violation": 0.008125096183441061,
            "ave_precision_score": 0.8346485929333044,
            "fpr": 0.07346491228070176,
            "logloss": 0.6305522133523491,
            "mae": 0.3173078421775246,
            "precision": 0.8227513227513228,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8640699013502968,
            "auditor_fn_violation": 0.004108640930351489,
            "auditor_fp_violation": 0.008808137294248666,
            "ave_precision_score": 0.8643247843407246,
            "fpr": 0.05817782656421515,
            "logloss": 0.5724104951733037,
            "mae": 0.3157866486842898,
            "precision": 0.8644501278772379,
            "recall": 0.678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.834785091175176,
            "auditor_fn_violation": 0.009199946137273011,
            "auditor_fp_violation": 0.021631655894121273,
            "ave_precision_score": 0.8350300155133519,
            "fpr": 0.13706140350877194,
            "logloss": 0.677742194299463,
            "mae": 0.2747177451880269,
            "precision": 0.7368421052631579,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8335203124428733,
            "auditor_fn_violation": 0.007101953367807122,
            "auditor_fp_violation": 0.02495195923910877,
            "ave_precision_score": 0.8338922113497129,
            "fpr": 0.13721185510428102,
            "logloss": 0.7236436985687684,
            "mae": 0.2784776642636698,
            "precision": 0.7572815533980582,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8375745469574833,
            "auditor_fn_violation": 0.010695598645737152,
            "auditor_fp_violation": 0.01993882733148662,
            "ave_precision_score": 0.837803544956802,
            "fpr": 0.17105263157894737,
            "logloss": 0.6643170118002572,
            "mae": 0.28059289567787254,
            "precision": 0.7056603773584905,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8378287669120339,
            "auditor_fn_violation": 0.004831620664876856,
            "auditor_fp_violation": 0.025823736255558248,
            "ave_precision_score": 0.8381763752975661,
            "fpr": 0.15148188803512624,
            "logloss": 0.6883423531873925,
            "mae": 0.2774875320138042,
            "precision": 0.7463235294117647,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8172364163856837,
            "auditor_fn_violation": 0.004068559556786707,
            "auditor_fp_violation": 0.00684345183133272,
            "ave_precision_score": 0.8176995635719165,
            "fpr": 0.06798245614035088,
            "logloss": 0.5454543674212866,
            "mae": 0.3252433397216935,
            "precision": 0.8248587570621468,
            "recall": 0.6403508771929824
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8511918091696964,
            "auditor_fn_violation": 0.011539021067805808,
            "auditor_fp_violation": 0.007933702421041721,
            "ave_precision_score": 0.851564709198981,
            "fpr": 0.04939626783754116,
            "logloss": 0.5540619079741507,
            "mae": 0.3247651079726844,
            "precision": 0.8783783783783784,
            "recall": 0.6526104417670683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8301833491555817,
            "auditor_fn_violation": 0.009522160664819944,
            "auditor_fp_violation": 0.00358042859341336,
            "ave_precision_score": 0.8306646370427673,
            "fpr": 0.11074561403508772,
            "logloss": 0.4993990041181251,
            "mae": 0.3083585060023899,
            "precision": 0.7730337078651686,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8292132334975236,
            "auditor_fn_violation": 0.011483915905113315,
            "auditor_fp_violation": 0.006665904747729529,
            "ave_precision_score": 0.8300144938900693,
            "fpr": 0.08562019758507135,
            "logloss": 0.5088965672594672,
            "mae": 0.30479598304862004,
            "precision": 0.827433628318584,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8065711449407429,
            "auditor_fn_violation": 0.010522468451831335,
            "auditor_fp_violation": 0.007420552477685442,
            "ave_precision_score": 0.8069471160074997,
            "fpr": 0.07675438596491228,
            "logloss": 0.6108281785568209,
            "mae": 0.3786250171241383,
            "precision": 0.7839506172839507,
            "recall": 0.5570175438596491
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8362379489162823,
            "auditor_fn_violation": 0.010692605768849272,
            "auditor_fp_violation": 0.00848387876983758,
            "ave_precision_score": 0.8365763735660475,
            "fpr": 0.05378704720087816,
            "logloss": 0.6221468927053737,
            "mae": 0.37647764082501195,
            "precision": 0.8567251461988304,
            "recall": 0.5883534136546185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8628062350257767,
            "auditor_fn_violation": 0.007057459987688525,
            "auditor_fp_violation": 0.0057108918128655,
            "ave_precision_score": 0.8630145560516528,
            "fpr": 0.09758771929824561,
            "logloss": 0.48135869828502215,
            "mae": 0.2825808983711077,
            "precision": 0.7958715596330275,
            "recall": 0.7609649122807017
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8653884915352884,
            "auditor_fn_violation": 0.010271602325878707,
            "auditor_fp_violation": 0.014400267911961157,
            "ave_precision_score": 0.8657073985692467,
            "fpr": 0.09220636663007684,
            "logloss": 0.5107193936048535,
            "mae": 0.28532551695456865,
            "precision": 0.8208955223880597,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8458426944557474,
            "auditor_fn_violation": 0.01263850415512466,
            "auditor_fp_violation": 0.005727723915050786,
            "ave_precision_score": 0.8462621494017759,
            "fpr": 0.10635964912280702,
            "logloss": 0.6571886660121192,
            "mae": 0.2982212281151612,
            "precision": 0.780045351473923,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8699058557972204,
            "auditor_fn_violation": 0.01764246888762515,
            "auditor_fp_violation": 0.011851383281549424,
            "ave_precision_score": 0.8700892805115793,
            "fpr": 0.08342480790340286,
            "logloss": 0.6058945069925284,
            "mae": 0.2969014135338375,
            "precision": 0.8325991189427313,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7828403811305326,
            "auditor_fn_violation": 0.0055329524469067415,
            "auditor_fp_violation": 0.01312663511849802,
            "ave_precision_score": 0.7833588854653164,
            "fpr": 0.2817982456140351,
            "logloss": 0.6102689136726526,
            "mae": 0.3724132555408256,
            "precision": 0.6141141141141141,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7574291543900775,
            "auditor_fn_violation": 0.0023011915940380667,
            "auditor_fp_violation": 0.017395672477627497,
            "ave_precision_score": 0.7587026542322939,
            "fpr": 0.25686059275521406,
            "logloss": 0.6225387669016548,
            "mae": 0.3729641758126302,
            "precision": 0.6438356164383562,
            "recall": 0.8493975903614458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8434421739867332,
            "auditor_fn_violation": 0.012176823638042482,
            "auditor_fp_violation": 0.00815635580178517,
            "ave_precision_score": 0.843887119601596,
            "fpr": 0.09649122807017543,
            "logloss": 0.6555831154730698,
            "mae": 0.3057940325428582,
            "precision": 0.7924528301886793,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8674256963669442,
            "auditor_fn_violation": 0.007710314363932132,
            "auditor_fp_violation": 0.01434445292005433,
            "ave_precision_score": 0.8680880682682153,
            "fpr": 0.0801317233809001,
            "logloss": 0.6038298105737566,
            "mae": 0.30020498950076363,
            "precision": 0.8381374722838137,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8297205235981711,
            "auditor_fn_violation": 0.00672081794398277,
            "auditor_fp_violation": 0.005530547860880273,
            "ave_precision_score": 0.8302020719747341,
            "fpr": 0.11074561403508772,
            "logloss": 0.5026731838854118,
            "mae": 0.31196355097314443,
            "precision": 0.7725225225225225,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8274854393178822,
            "auditor_fn_violation": 0.010346545347140487,
            "auditor_fp_violation": 0.00822872452112066,
            "ave_precision_score": 0.8283126937036581,
            "fpr": 0.09001097694840834,
            "logloss": 0.5142698086697105,
            "mae": 0.3087701432230043,
            "precision": 0.8185840707964602,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8497690523712071,
            "auditor_fn_violation": 0.0005193905817174604,
            "auditor_fp_violation": 0.0068314289012003735,
            "ave_precision_score": 0.8499839677588326,
            "fpr": 0.12609649122807018,
            "logloss": 0.6201421935828527,
            "mae": 0.27474801744610505,
            "precision": 0.7472527472527473,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8464155300641119,
            "auditor_fn_violation": 0.00815115566547199,
            "auditor_fp_violation": 0.02044954989195813,
            "ave_precision_score": 0.8467752410632017,
            "fpr": 0.1141602634467618,
            "logloss": 0.6714680113304862,
            "mae": 0.2759348170901774,
            "precision": 0.7860082304526749,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8303304797318414,
            "auditor_fn_violation": 0.0050688673437980945,
            "auditor_fp_violation": 0.011445829485995691,
            "ave_precision_score": 0.8306048166464803,
            "fpr": 0.08771929824561403,
            "logloss": 0.5344480117937345,
            "mae": 0.3465474559552763,
            "precision": 0.7883597883597884,
            "recall": 0.6535087719298246
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.840966827275831,
            "auditor_fn_violation": 0.009405349168352888,
            "auditor_fp_violation": 0.010838739856954152,
            "ave_precision_score": 0.841360290535565,
            "fpr": 0.06805708013172337,
            "logloss": 0.5564049343845772,
            "mae": 0.3541587578668438,
            "precision": 0.8414322250639387,
            "recall": 0.6606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7704418451409532,
            "auditor_fn_violation": 0.0060787934749153595,
            "auditor_fp_violation": 0.013626789012003693,
            "ave_precision_score": 0.7494490126321459,
            "fpr": 0.11513157894736842,
            "logloss": 2.768008531379033,
            "mae": 0.2971978581443627,
            "precision": 0.7558139534883721,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.78925362791361,
            "auditor_fn_violation": 0.015195799664078934,
            "auditor_fp_violation": 0.018942545110473816,
            "ave_precision_score": 0.7630036636928992,
            "fpr": 0.10867178924259056,
            "logloss": 2.9318866588267753,
            "mae": 0.2972852212156861,
            "precision": 0.7824175824175824,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8126441030817884,
            "auditor_fn_violation": 0.001825080794090497,
            "auditor_fp_violation": 0.009320175438596492,
            "ave_precision_score": 0.8131375020223033,
            "fpr": 0.10635964912280702,
            "logloss": 0.5186848361062195,
            "mae": 0.32110827495451205,
            "precision": 0.7775229357798165,
            "recall": 0.743421052631579
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8431607371381599,
            "auditor_fn_violation": 0.011184143820066224,
            "auditor_fp_violation": 0.011418152630082157,
            "ave_precision_score": 0.8436164314819571,
            "fpr": 0.0889132821075741,
            "logloss": 0.5195762252686343,
            "mae": 0.3186715091315418,
            "precision": 0.8191964285714286,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7995826096816875,
            "auditor_fn_violation": 0.0004953447214527621,
            "auditor_fp_violation": 5.5305478608805894e-05,
            "ave_precision_score": 0.8002213217898222,
            "fpr": 0.07785087719298246,
            "logloss": 0.5550916309039411,
            "mae": 0.35141509156643513,
            "precision": 0.8033240997229917,
            "recall": 0.6359649122807017
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.821441632102678,
            "auditor_fn_violation": 0.006669928892298076,
            "auditor_fp_violation": 0.013092602387286944,
            "ave_precision_score": 0.8219392022313361,
            "fpr": 0.06586169045005488,
            "logloss": 0.5853149499180554,
            "mae": 0.35953419978099616,
            "precision": 0.8369565217391305,
            "recall": 0.6184738955823293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8359645474755016,
            "auditor_fn_violation": 0.003075465527854729,
            "auditor_fp_violation": 0.012450946445060024,
            "ave_precision_score": 0.8362792781659198,
            "fpr": 0.09539473684210527,
            "logloss": 0.5058346672491827,
            "mae": 0.3298351798046241,
            "precision": 0.7846534653465347,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8612729942390012,
            "auditor_fn_violation": 0.008120296774364202,
            "auditor_fp_violation": 0.011067315538096395,
            "ave_precision_score": 0.861483647560249,
            "fpr": 0.07574094401756312,
            "logloss": 0.5178109257249068,
            "mae": 0.32966052337767376,
            "precision": 0.8376470588235294,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8361986715830171,
            "auditor_fn_violation": 0.016930690212373038,
            "auditor_fp_violation": 0.00538627269929209,
            "ave_precision_score": 0.8365115569004989,
            "fpr": 0.12719298245614036,
            "logloss": 0.5058197670586339,
            "mae": 0.3192718783485409,
            "precision": 0.7526652452025586,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8582578801103373,
            "auditor_fn_violation": 0.01492688647013962,
            "auditor_fp_violation": 0.008627403034740848,
            "ave_precision_score": 0.8586270229949251,
            "fpr": 0.10647639956092206,
            "logloss": 0.4939379875307128,
            "mae": 0.31342982615290044,
            "precision": 0.8012295081967213,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7691887984252341,
            "auditor_fn_violation": 0.005381463527239153,
            "auditor_fp_violation": 0.01716153047091413,
            "ave_precision_score": 0.7458467290936455,
            "fpr": 0.12171052631578948,
            "logloss": 3.1027643261501336,
            "mae": 0.29523017055334533,
            "precision": 0.7465753424657534,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7884745204395389,
            "auditor_fn_violation": 0.01273590520148652,
            "auditor_fp_violation": 0.02081899198124617,
            "ave_precision_score": 0.7602731445811941,
            "fpr": 0.11525795828759605,
            "logloss": 3.2671170052853746,
            "mae": 0.2975973686587366,
            "precision": 0.7741935483870968,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8587327215911138,
            "auditor_fn_violation": 0.007223376423514933,
            "auditor_fp_violation": 0.0037920321637426916,
            "ave_precision_score": 0.8589645263905503,
            "fpr": 0.10416666666666667,
            "logloss": 0.47677790082522314,
            "mae": 0.29678772108628326,
            "precision": 0.7821100917431193,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8675925801207673,
            "auditor_fn_violation": 0.005977808048880489,
            "auditor_fp_violation": 0.005536315625805667,
            "ave_precision_score": 0.8678436016817878,
            "fpr": 0.0801317233809001,
            "logloss": 0.48475086221416974,
            "mae": 0.29388622016921734,
            "precision": 0.8366890380313199,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 18998,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8587324336940007,
            "auditor_fn_violation": 0.014658356417359195,
            "auditor_fp_violation": 0.00798563019390582,
            "ave_precision_score": 0.8589419562012284,
            "fpr": 0.10855263157894737,
            "logloss": 0.5313400361652092,
            "mae": 0.27355971411653274,
            "precision": 0.7765237020316027,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8547586708363434,
            "auditor_fn_violation": 0.011876264663483791,
            "auditor_fp_violation": 0.01787940240748665,
            "ave_precision_score": 0.8551225674601082,
            "fpr": 0.09769484083424808,
            "logloss": 0.5705108644175633,
            "mae": 0.277818733186812,
            "precision": 0.8102345415778252,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8027557403262572,
            "auditor_fn_violation": 0.011489112034472145,
            "auditor_fp_violation": 0.013655644044321338,
            "ave_precision_score": 0.7979525086806338,
            "fpr": 0.13048245614035087,
            "logloss": 0.9614515890173359,
            "mae": 0.26881767881933594,
            "precision": 0.7551440329218106,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8049808237601755,
            "auditor_fn_violation": 0.005695669615894977,
            "auditor_fp_violation": 0.01845615732385719,
            "ave_precision_score": 0.7923413117606697,
            "fpr": 0.11964873765093303,
            "logloss": 1.3124403437031282,
            "mae": 0.26829442070668275,
            "precision": 0.7837301587301587,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7838563324523489,
            "auditor_fn_violation": 0.004970279316712838,
            "auditor_fp_violation": 0.012739496768236389,
            "ave_precision_score": 0.775779702018709,
            "fpr": 0.16337719298245615,
            "logloss": 1.303306218278455,
            "mae": 0.2951484154874224,
            "precision": 0.7188679245283018,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7953318948821169,
            "auditor_fn_violation": 0.009330406147091111,
            "auditor_fp_violation": 0.018395026618435426,
            "ave_precision_score": 0.7816960336182196,
            "fpr": 0.14489571899012074,
            "logloss": 1.4785746445254948,
            "mae": 0.2827775824126936,
            "precision": 0.7586837294332724,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8219889685244322,
            "auditor_fn_violation": 0.002690731763619584,
            "auditor_fp_violation": 0.007963988919667594,
            "ave_precision_score": 0.822326233867755,
            "fpr": 0.07894736842105263,
            "logloss": 0.5322898130915904,
            "mae": 0.33832552055664883,
            "precision": 0.808,
            "recall": 0.6644736842105263
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8523548936165624,
            "auditor_fn_violation": 0.009160682245998268,
            "auditor_fp_violation": 0.013395598057638283,
            "ave_precision_score": 0.8526779260457017,
            "fpr": 0.07025246981339188,
            "logloss": 0.5553753478628115,
            "mae": 0.3429932042585254,
            "precision": 0.8333333333333334,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8474040882691031,
            "auditor_fn_violation": 0.008945060018467224,
            "auditor_fp_violation": 0.007925515543244074,
            "ave_precision_score": 0.8477817605405563,
            "fpr": 0.08442982456140351,
            "logloss": 0.49522873198194983,
            "mae": 0.322856964681322,
            "precision": 0.8060453400503779,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8651479352985536,
            "auditor_fn_violation": 0.013483131207596586,
            "auditor_fp_violation": 0.009772939297209519,
            "ave_precision_score": 0.8654740470667526,
            "fpr": 0.06695938529088913,
            "logloss": 0.5040442614231182,
            "mae": 0.32319062161458706,
            "precision": 0.8533653846153846,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8325656258425067,
            "auditor_fn_violation": 0.01159972299168975,
            "auditor_fp_violation": 0.018048822714681445,
            "ave_precision_score": 0.8328030382097869,
            "fpr": 0.15570175438596492,
            "logloss": 0.6676769835286873,
            "mae": 0.28044602402481067,
            "precision": 0.7171314741035857,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8309148840197799,
            "auditor_fn_violation": 0.005052041315646783,
            "auditor_fp_violation": 0.02468883142011945,
            "ave_precision_score": 0.8312601168573639,
            "fpr": 0.1437980241492865,
            "logloss": 0.708260592745258,
            "mae": 0.28351560220544986,
            "precision": 0.7509505703422054,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8215159031554364,
            "auditor_fn_violation": 0.0017361111111111167,
            "auditor_fp_violation": 0.007447002923976614,
            "ave_precision_score": 0.8217286624181224,
            "fpr": 0.08662280701754387,
            "logloss": 2.7191673248757375,
            "mae": 0.27200341583617266,
            "precision": 0.7974358974358975,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8349662686873341,
            "auditor_fn_violation": 0.005219561010231927,
            "auditor_fp_violation": 0.01650794832063321,
            "ave_precision_score": 0.8353289260216071,
            "fpr": 0.07793633369923161,
            "logloss": 2.437610207909759,
            "mae": 0.2720521071994457,
            "precision": 0.831353919239905,
            "recall": 0.7028112449799196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7716620684210539,
            "auditor_fn_violation": 0.012765947214527559,
            "auditor_fp_violation": 0.007819713758079414,
            "ave_precision_score": 0.7731468914408139,
            "fpr": 0.07456140350877193,
            "logloss": 0.6116592827779607,
            "mae": 0.3736040437647158,
            "precision": 0.8062678062678063,
            "recall": 0.6206140350877193
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8029980025748434,
            "auditor_fn_violation": 0.009129823354890477,
            "auditor_fp_violation": 0.007176213245163368,
            "ave_precision_score": 0.8045768983986931,
            "fpr": 0.05817782656421515,
            "logloss": 0.6293564361870571,
            "mae": 0.38054343781604727,
            "precision": 0.8519553072625698,
            "recall": 0.6124497991967871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8379810570710975,
            "auditor_fn_violation": 0.0071945213911973034,
            "auditor_fp_violation": 0.00411184210526316,
            "ave_precision_score": 0.8383104607584669,
            "fpr": 0.041666666666666664,
            "logloss": 0.6048510074205361,
            "mae": 0.35214179036669074,
            "precision": 0.8671328671328671,
            "recall": 0.543859649122807
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8466483409000247,
            "auditor_fn_violation": 0.012643328528163158,
            "auditor_fp_violation": 0.008677902313132738,
            "ave_precision_score": 0.8472185184254265,
            "fpr": 0.03951701427003293,
            "logloss": 0.6417221315146954,
            "mae": 0.36737494659328956,
            "precision": 0.8811881188118812,
            "recall": 0.536144578313253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8337040213520011,
            "auditor_fn_violation": 0.013533010156971384,
            "auditor_fp_violation": 0.004513407971683596,
            "ave_precision_score": 0.8335622184520812,
            "fpr": 0.03837719298245614,
            "logloss": 1.7349271956171162,
            "mae": 0.3241301686442835,
            "precision": 0.8698884758364313,
            "recall": 0.5131578947368421
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8537112701564924,
            "auditor_fn_violation": 0.00040998241043207963,
            "auditor_fp_violation": 0.004047915841623633,
            "ave_precision_score": 0.8536818077601277,
            "fpr": 0.03402854006586169,
            "logloss": 1.7002956813039052,
            "mae": 0.3368333996622457,
            "precision": 0.8980263157894737,
            "recall": 0.5481927710843374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8325044569517748,
            "auditor_fn_violation": 0.012645717913204067,
            "auditor_fp_violation": 0.013388734995383202,
            "ave_precision_score": 0.8327533475777011,
            "fpr": 0.1206140350877193,
            "logloss": 0.7645257144248226,
            "mae": 0.3289801375177153,
            "precision": 0.7582417582417582,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8445023599871355,
            "auditor_fn_violation": 0.010769752996618745,
            "auditor_fp_violation": 0.011566992608500358,
            "ave_precision_score": 0.8447651242613011,
            "fpr": 0.10098792535675083,
            "logloss": 1.0263167950832024,
            "mae": 0.33168124721469333,
            "precision": 0.7995642701525054,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8105966584998925,
            "auditor_fn_violation": 0.009753000923361035,
            "auditor_fp_violation": 0.006100434749153592,
            "ave_precision_score": 0.8111978874526715,
            "fpr": 0.11951754385964912,
            "logloss": 0.5174014461588573,
            "mae": 0.3203677432509466,
            "precision": 0.7614879649890591,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8233746285752649,
            "auditor_fn_violation": 0.010862329669942118,
            "auditor_fp_violation": 0.005719707742070952,
            "ave_precision_score": 0.8241576392429774,
            "fpr": 0.09769484083424808,
            "logloss": 0.5134890792085982,
            "mae": 0.31313079067134797,
            "precision": 0.8122362869198312,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7756847287474768,
            "auditor_fn_violation": 0.004660087719298244,
            "auditor_fp_violation": 0.01087353801169591,
            "ave_precision_score": 0.7523719994207723,
            "fpr": 0.1337719298245614,
            "logloss": 2.9360421901636764,
            "mae": 0.2828707446984702,
            "precision": 0.7370689655172413,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7944265108052455,
            "auditor_fn_violation": 0.010897596974065313,
            "auditor_fp_violation": 0.022182472497827205,
            "ave_precision_score": 0.7660511278714541,
            "fpr": 0.12623490669593854,
            "logloss": 3.0973473980459696,
            "mae": 0.2826117078976866,
            "precision": 0.7695390781563126,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8442329368041176,
            "auditor_fn_violation": 0.017216835949522932,
            "auditor_fp_violation": 0.011368882733148665,
            "ave_precision_score": 0.8445280830648174,
            "fpr": 0.10526315789473684,
            "logloss": 0.5177406051430303,
            "mae": 0.30704576957092894,
            "precision": 0.7798165137614679,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8633954152455137,
            "auditor_fn_violation": 0.012017333879976548,
            "auditor_fp_violation": 0.012040091111329648,
            "ave_precision_score": 0.8636257906098416,
            "fpr": 0.07903402854006586,
            "logloss": 0.5404781012381378,
            "mae": 0.3069669548377372,
            "precision": 0.8396436525612472,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8375444669138647,
            "auditor_fn_violation": 0.0092480378578024,
            "auditor_fp_violation": 0.001789012003693445,
            "ave_precision_score": 0.8378659311782357,
            "fpr": 0.039473684210526314,
            "logloss": 0.611728339300021,
            "mae": 0.35536355813842657,
            "precision": 0.8709677419354839,
            "recall": 0.5328947368421053
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8395460352974118,
            "auditor_fn_violation": 0.01170654076239096,
            "auditor_fp_violation": 0.006610089755822701,
            "ave_precision_score": 0.8402933559886534,
            "fpr": 0.04061470911086718,
            "logloss": 0.653935077587234,
            "mae": 0.37225040626782685,
            "precision": 0.8774834437086093,
            "recall": 0.5321285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 18998,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7817725800050359,
            "auditor_fn_violation": 0.0037800092336103394,
            "auditor_fp_violation": 0.009753000923361038,
            "ave_precision_score": 0.7657175415288363,
            "fpr": 0.13157894736842105,
            "logloss": 2.514214759189844,
            "mae": 0.28236803781700454,
            "precision": 0.7435897435897436,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7958844357094566,
            "auditor_fn_violation": 0.0038353193233967757,
            "auditor_fp_violation": 0.019242882924067693,
            "ave_precision_score": 0.7724886200703802,
            "fpr": 0.1207464324917673,
            "logloss": 2.733565226680886,
            "mae": 0.28119202959569006,
            "precision": 0.7759674134419552,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8526892194168232,
            "auditor_fn_violation": 0.004602377654662973,
            "auditor_fp_violation": 0.006528451061865195,
            "ave_precision_score": 0.8529536615277462,
            "fpr": 0.12171052631578948,
            "logloss": 0.4791323643240148,
            "mae": 0.29533547685142575,
            "precision": 0.7612903225806451,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.876185084851165,
            "auditor_fn_violation": 0.005726528507002768,
            "auditor_fp_violation": 0.009297182937622762,
            "ave_precision_score": 0.8763838221334784,
            "fpr": 0.09879253567508232,
            "logloss": 0.4717024358639038,
            "mae": 0.2877105498956322,
            "precision": 0.8132780082987552,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8357643768180757,
            "auditor_fn_violation": 0.00806979070483226,
            "auditor_fp_violation": 0.01794783010156972,
            "ave_precision_score": 0.8359926938409097,
            "fpr": 0.14692982456140352,
            "logloss": 0.6516243207640905,
            "mae": 0.2765032057037635,
            "precision": 0.7259713701431493,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8333681161102189,
            "auditor_fn_violation": 0.007068890270191633,
            "auditor_fp_violation": 0.02588220910422254,
            "ave_precision_score": 0.8337151482659375,
            "fpr": 0.13391877058177826,
            "logloss": 0.6916461717074824,
            "mae": 0.27721755879732535,
            "precision": 0.761252446183953,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8528685745656557,
            "auditor_fn_violation": 0.0035972606955986474,
            "auditor_fp_violation": 0.007293109418282547,
            "ave_precision_score": 0.8531100494052053,
            "fpr": 0.11513157894736842,
            "logloss": 0.4806978962914398,
            "mae": 0.2949931874833981,
            "precision": 0.7702407002188184,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8653985954764716,
            "auditor_fn_violation": 0.007549407288870078,
            "auditor_fp_violation": 0.007144318964073751,
            "ave_precision_score": 0.8657066715928609,
            "fpr": 0.09220636663007684,
            "logloss": 0.48210633133308456,
            "mae": 0.289321486090727,
            "precision": 0.8224101479915433,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 18998,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.792077894187602,
            "auditor_fn_violation": 0.003335160818713463,
            "auditor_fp_violation": 0.0057108918128655,
            "ave_precision_score": 0.7928298709285129,
            "fpr": 0.09758771929824561,
            "logloss": 0.5317805521329324,
            "mae": 0.3258924449011765,
            "precision": 0.7839805825242718,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.806362421564282,
            "auditor_fn_violation": 0.004668509383307105,
            "auditor_fp_violation": 0.0091696058132643,
            "ave_precision_score": 0.807511525978821,
            "fpr": 0.07244785949506037,
            "logloss": 0.5271679808864295,
            "mae": 0.32141687513178807,
            "precision": 0.8428571428571429,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8587390950812881,
            "auditor_fn_violation": 0.006011465066174211,
            "auditor_fp_violation": 0.007079101261926751,
            "ave_precision_score": 0.8589520331753789,
            "fpr": 0.10087719298245613,
            "logloss": 0.49336069945129035,
            "mae": 0.2844659624093414,
            "precision": 0.7875288683602771,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8588093423507238,
            "auditor_fn_violation": 0.009852803089415848,
            "auditor_fp_violation": 0.016441501901696513,
            "ave_precision_score": 0.8591417614774204,
            "fpr": 0.09440175631174534,
            "logloss": 0.5253909155558834,
            "mae": 0.28825498561329926,
            "precision": 0.8154506437768241,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8400203643118371,
            "auditor_fn_violation": 0.006627039088950449,
            "auditor_fp_violation": 0.01567790089258234,
            "ave_precision_score": 0.8400496219282843,
            "fpr": 0.14692982456140352,
            "logloss": 1.5923031602791966,
            "mae": 0.29540476312632286,
            "precision": 0.7231404958677686,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8549459381210615,
            "auditor_fn_violation": 0.005984420668403589,
            "auditor_fp_violation": 0.020595732013618858,
            "ave_precision_score": 0.8550448534833182,
            "fpr": 0.14050493962678376,
            "logloss": 1.4834564726683956,
            "mae": 0.29695203781806373,
            "precision": 0.7543186180422264,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7805704480884974,
            "auditor_fn_violation": 0.004890927977839336,
            "auditor_fp_violation": 0.00530932594644506,
            "ave_precision_score": 0.7815231560588375,
            "fpr": 0.05043859649122807,
            "logloss": 0.6291252006151532,
            "mae": 0.39303609334571155,
            "precision": 0.8374558303886925,
            "recall": 0.5197368421052632
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8131026227306344,
            "auditor_fn_violation": 0.007950572873271354,
            "auditor_fp_violation": 0.007633364607447847,
            "ave_precision_score": 0.8136742672316065,
            "fpr": 0.04500548847420417,
            "logloss": 0.6870513863740814,
            "mae": 0.4130515659674716,
            "precision": 0.8651315789473685,
            "recall": 0.5281124497991968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8321504949647378,
            "auditor_fn_violation": 0.009098953524161284,
            "auditor_fp_violation": 0.005569021237303788,
            "ave_precision_score": 0.8326509274853506,
            "fpr": 0.11842105263157894,
            "logloss": 0.4939422122015976,
            "mae": 0.3051096743423075,
            "precision": 0.762114537444934,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8313836982812831,
            "auditor_fn_violation": 0.007952777079779056,
            "auditor_fp_violation": 0.006639326180154846,
            "ave_precision_score": 0.8321807577259596,
            "fpr": 0.0889132821075741,
            "logloss": 0.5011029749463584,
            "mae": 0.3004858872416694,
            "precision": 0.8265524625267666,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.841322711274441,
            "auditor_fn_violation": 0.005275661742074489,
            "auditor_fp_violation": 0.009442809325946443,
            "ave_precision_score": 0.8415518824760045,
            "fpr": 0.13486842105263158,
            "logloss": 0.6323928302450745,
            "mae": 0.27045081689839245,
            "precision": 0.7399577167019028,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8359693563660088,
            "auditor_fn_violation": 0.008142338839441186,
            "auditor_fp_violation": 0.020284762772995114,
            "ave_precision_score": 0.8363417015470916,
            "fpr": 0.11964873765093303,
            "logloss": 0.6849722674771727,
            "mae": 0.27136905721058735,
            "precision": 0.7806841046277666,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7965569043834376,
            "auditor_fn_violation": 0.0028277931671283596,
            "auditor_fp_violation": 0.01154682209910742,
            "ave_precision_score": 0.7900479214786122,
            "fpr": 0.11293859649122807,
            "logloss": 0.9706730487663842,
            "mae": 0.2877779908814231,
            "precision": 0.7632183908045977,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8008435301887704,
            "auditor_fn_violation": 0.015116448229801755,
            "auditor_fp_violation": 0.014456082903867986,
            "ave_precision_score": 0.7868227284751685,
            "fpr": 0.10318331503841932,
            "logloss": 1.335468253967396,
            "mae": 0.2869571771965445,
            "precision": 0.7929515418502202,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7695217559231547,
            "auditor_fn_violation": 0.005381463527239153,
            "auditor_fp_violation": 0.016586834410587874,
            "ave_precision_score": 0.7461798648407182,
            "fpr": 0.12390350877192982,
            "logloss": 3.01704789970575,
            "mae": 0.2950557357004766,
            "precision": 0.7431818181818182,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7886843851588675,
            "auditor_fn_violation": 0.01210109372726912,
            "auditor_fp_violation": 0.018974439391563434,
            "ave_precision_score": 0.7603262130108801,
            "fpr": 0.11964873765093303,
            "logloss": 3.1888478204739994,
            "mae": 0.29712349008086625,
            "precision": 0.7690677966101694,
            "recall": 0.7289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6582857348108819,
            "auditor_fn_violation": 0.002262715450907978,
            "auditor_fp_violation": 0.00787501923668821,
            "ave_precision_score": 0.6603723673541196,
            "fpr": 0.15899122807017543,
            "logloss": 0.6399196964956152,
            "mae": 0.39138645041461323,
            "precision": 0.6658986175115207,
            "recall": 0.6337719298245614
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7044039972972453,
            "auditor_fn_violation": 0.010970335788819391,
            "auditor_fp_violation": 0.021284116913803046,
            "ave_precision_score": 0.7053156257969369,
            "fpr": 0.145993413830955,
            "logloss": 0.6446537601814224,
            "mae": 0.3957389904987108,
            "precision": 0.7004504504504504,
            "recall": 0.6244979919678715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7659580632626123,
            "auditor_fn_violation": 0.01781317328408742,
            "auditor_fp_violation": 0.006564519852262236,
            "ave_precision_score": 0.7663935484272679,
            "fpr": 0.07236842105263158,
            "logloss": 1.3125372422323784,
            "mae": 0.34136785539114856,
            "precision": 0.7857142857142857,
            "recall": 0.5307017543859649
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.804960877131712,
            "auditor_fn_violation": 0.01136268454718986,
            "auditor_fp_violation": 0.013786303000986065,
            "ave_precision_score": 0.8054334415527957,
            "fpr": 0.05378704720087816,
            "logloss": 1.5351998047819075,
            "mae": 0.34596130936502456,
            "precision": 0.8487654320987654,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8097067643966371,
            "auditor_fn_violation": 0.007704293628808867,
            "auditor_fp_violation": 0.01555286241920591,
            "ave_precision_score": 0.8050421239633048,
            "fpr": 0.1611842105263158,
            "logloss": 0.9162384021440847,
            "mae": 0.27635389763459545,
            "precision": 0.7292817679558011,
            "recall": 0.868421052631579
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8093002866864106,
            "auditor_fn_violation": 0.006489183958666721,
            "auditor_fp_violation": 0.024521386444398968,
            "ave_precision_score": 0.7967487533586045,
            "fpr": 0.141602634467618,
            "logloss": 1.2542312571655965,
            "mae": 0.26914086611788113,
            "precision": 0.7692307692307693,
            "recall": 0.8634538152610441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8387769313589561,
            "auditor_fn_violation": 0.00903883887349954,
            "auditor_fp_violation": 0.012508656509695302,
            "ave_precision_score": 0.838625901017544,
            "fpr": 0.14692982456140352,
            "logloss": 1.625391841890204,
            "mae": 0.29435022638415353,
            "precision": 0.7248459958932238,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8531173287215394,
            "auditor_fn_violation": 0.005382672291801672,
            "auditor_fp_violation": 0.023888816536121606,
            "ave_precision_score": 0.8530502141489247,
            "fpr": 0.14050493962678376,
            "logloss": 1.5352514798381651,
            "mae": 0.2981509292303996,
            "precision": 0.752895752895753,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8110711220831974,
            "auditor_fn_violation": 0.004631232686980616,
            "auditor_fp_violation": 0.0024598915050784874,
            "ave_precision_score": 0.8122693446227237,
            "fpr": 0.12390350877192982,
            "logloss": 0.5209669223199037,
            "mae": 0.2967452073179741,
            "precision": 0.7595744680851064,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8296969425302293,
            "auditor_fn_violation": 0.0012475808833578024,
            "auditor_fp_violation": 0.008268592372482677,
            "ave_precision_score": 0.8308628451321569,
            "fpr": 0.09659714599341383,
            "logloss": 0.5127462710316993,
            "mae": 0.28958891959233224,
            "precision": 0.8207739307535642,
            "recall": 0.8092369477911646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7232586261076771,
            "auditor_fn_violation": 0.009560634041243455,
            "auditor_fp_violation": 0.009522160664819946,
            "ave_precision_score": 0.7487067744460258,
            "fpr": 0.07017543859649122,
            "logloss": 0.6718920666933993,
            "mae": 0.40181390753142504,
            "precision": 0.7922077922077922,
            "recall": 0.5350877192982456
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7715462099708701,
            "auditor_fn_violation": 0.008212873447687567,
            "auditor_fp_violation": 0.006195464101657705,
            "ave_precision_score": 0.7905634294821353,
            "fpr": 0.04610318331503842,
            "logloss": 0.6918569947885782,
            "mae": 0.40746780301308266,
            "precision": 0.8679245283018868,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8251223018705133,
            "auditor_fn_violation": 0.0010483995075407813,
            "auditor_fp_violation": 0.011123614958448757,
            "ave_precision_score": 0.8254528076627886,
            "fpr": 0.08223684210526316,
            "logloss": 0.5674129031016344,
            "mae": 0.32444537824899206,
            "precision": 0.8036649214659686,
            "recall": 0.6732456140350878
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8540679050530626,
            "auditor_fn_violation": 0.00724743099731528,
            "auditor_fp_violation": 0.009251999372745805,
            "ave_precision_score": 0.8547353901031665,
            "fpr": 0.06476399560922064,
            "logloss": 0.5525223437547938,
            "mae": 0.32235785190664523,
            "precision": 0.850632911392405,
            "recall": 0.6746987951807228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7042719881626129,
            "auditor_fn_violation": 0.003700657894736844,
            "auditor_fp_violation": 0.007651392736226543,
            "ave_precision_score": 0.7050323354127321,
            "fpr": 0.3048245614035088,
            "logloss": 0.7611456505186761,
            "mae": 0.40525634151376916,
            "precision": 0.5893648449039882,
            "recall": 0.875
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.756108069601026,
            "auditor_fn_violation": 0.008825642856827971,
            "auditor_fp_violation": 0.004316359374127897,
            "ave_precision_score": 0.7566768284419683,
            "fpr": 0.27442371020856204,
            "logloss": 0.7062353623278991,
            "mae": 0.381323246446844,
            "precision": 0.6392496392496393,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8339044423438211,
            "auditor_fn_violation": 0.014071637426900591,
            "auditor_fp_violation": 0.018698060941828264,
            "ave_precision_score": 0.8341408782992347,
            "fpr": 0.15789473684210525,
            "logloss": 0.6575907827278318,
            "mae": 0.28018351604634373,
            "precision": 0.7148514851485148,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8320787443104976,
            "auditor_fn_violation": 0.006083609961250051,
            "auditor_fp_violation": 0.022660886714171432,
            "ave_precision_score": 0.8324345577352461,
            "fpr": 0.145993413830955,
            "logloss": 0.6930900301236845,
            "mae": 0.282270341099274,
            "precision": 0.7490566037735849,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8329850029233641,
            "auditor_fn_violation": 0.0058768082486919055,
            "auditor_fp_violation": 0.011686288088642659,
            "ave_precision_score": 0.8328494657093624,
            "fpr": 0.13486842105263158,
            "logloss": 1.6420311823924378,
            "mae": 0.2968532579101819,
            "precision": 0.734341252699784,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8488178292506338,
            "auditor_fn_violation": 0.007137220671930317,
            "auditor_fp_violation": 0.02379579154961023,
            "ave_precision_score": 0.8488319698584812,
            "fpr": 0.13062568605927552,
            "logloss": 1.561300386575583,
            "mae": 0.2991744484739252,
            "precision": 0.7615230460921844,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8222211680462281,
            "auditor_fn_violation": 0.04291224222837797,
            "auditor_fp_violation": 0.02179276315789474,
            "ave_precision_score": 0.8230582057064151,
            "fpr": 0.10416666666666667,
            "logloss": 0.5570542056824151,
            "mae": 0.3234849531961393,
            "precision": 0.7705314009661836,
            "recall": 0.6995614035087719
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.845474723597217,
            "auditor_fn_violation": 0.046737994789255825,
            "auditor_fp_violation": 0.02490943353098928,
            "ave_precision_score": 0.8457085183840852,
            "fpr": 0.08232711306256861,
            "logloss": 0.5859603023290668,
            "mae": 0.3280690336296714,
            "precision": 0.8251748251748252,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8440956636154622,
            "auditor_fn_violation": 0.015451869806094181,
            "auditor_fp_violation": 0.010493613419513699,
            "ave_precision_score": 0.8443911489301934,
            "fpr": 0.10087719298245613,
            "logloss": 0.48796557525579803,
            "mae": 0.3147496249416451,
            "precision": 0.7875288683602771,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8606277471789315,
            "auditor_fn_violation": 0.01629129029840548,
            "auditor_fp_violation": 0.011173629808395109,
            "ave_precision_score": 0.861842995559486,
            "fpr": 0.08342480790340286,
            "logloss": 0.4935940902098284,
            "mae": 0.3165970803079994,
            "precision": 0.8299776286353467,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8045803804723939,
            "auditor_fn_violation": 0.010128116343490317,
            "auditor_fp_violation": 0.011301554324407517,
            "ave_precision_score": 0.8049161876656821,
            "fpr": 0.11293859649122807,
            "logloss": 0.7379380263784675,
            "mae": 0.2988048167624169,
            "precision": 0.7481662591687042,
            "recall": 0.6710526315789473
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7966046256577046,
            "auditor_fn_violation": 0.022125824924285508,
            "auditor_fp_violation": 0.02035120919193181,
            "ave_precision_score": 0.7979665918326607,
            "fpr": 0.10208562019758508,
            "logloss": 0.8066980187869319,
            "mae": 0.3125994706921202,
            "precision": 0.7785714285714286,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6836234747158991,
            "auditor_fn_violation": 0.01279239766081872,
            "auditor_fp_violation": 0.01565385503231764,
            "ave_precision_score": 0.6841520379199405,
            "fpr": 0.2050438596491228,
            "logloss": 1.4257518174152284,
            "mae": 0.3986009162142774,
            "precision": 0.6128364389233955,
            "recall": 0.6491228070175439
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7087733246296114,
            "auditor_fn_violation": 0.015023871556478385,
            "auditor_fp_violation": 0.016438844044939047,
            "ave_precision_score": 0.7091963079193018,
            "fpr": 0.16794731064763996,
            "logloss": 1.4080663933116546,
            "mae": 0.40848814201650263,
            "precision": 0.6577181208053692,
            "recall": 0.5903614457831325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8291424381073457,
            "auditor_fn_violation": 0.009733764235149286,
            "auditor_fp_violation": 0.0052011195752539275,
            "ave_precision_score": 0.8305169393118402,
            "fpr": 0.06907894736842106,
            "logloss": 0.544447136090729,
            "mae": 0.3469629868458581,
            "precision": 0.8079268292682927,
            "recall": 0.581140350877193
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8663014649604733,
            "auditor_fn_violation": 0.007789665798209301,
            "auditor_fp_violation": 0.00911910653487241,
            "ave_precision_score": 0.8664802323932219,
            "fpr": 0.048298572996706916,
            "logloss": 0.5585970621552743,
            "mae": 0.34980829280078346,
            "precision": 0.872093023255814,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8401762913741004,
            "auditor_fn_violation": 0.008608417974761466,
            "auditor_fp_violation": 0.010027123730378583,
            "ave_precision_score": 0.8403901183484204,
            "fpr": 0.08552631578947369,
            "logloss": 0.5119358948378712,
            "mae": 0.32751526959851107,
            "precision": 0.7963446475195822,
            "recall": 0.668859649122807
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8628405239794162,
            "auditor_fn_violation": 0.005885231375557125,
            "auditor_fp_violation": 0.009448680772798434,
            "ave_precision_score": 0.8630454883667603,
            "fpr": 0.07354555433589462,
            "logloss": 0.5264657057993489,
            "mae": 0.32855543061072656,
            "precision": 0.8385542168674699,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8114901561535429,
            "auditor_fn_violation": 0.00434749153585719,
            "auditor_fp_violation": 0.00018755771006463413,
            "ave_precision_score": 0.8126839836939084,
            "fpr": 0.1206140350877193,
            "logloss": 0.5205677549391869,
            "mae": 0.2955798180396015,
            "precision": 0.7639484978540773,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.829666931252208,
            "auditor_fn_violation": 0.00019837858569293906,
            "auditor_fp_violation": 0.0060147298421498905,
            "ave_precision_score": 0.8308569509479704,
            "fpr": 0.09440175631174534,
            "logloss": 0.5130786895293399,
            "mae": 0.28865680075020544,
            "precision": 0.8237704918032787,
            "recall": 0.8072289156626506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8386938463334472,
            "auditor_fn_violation": 0.0007502308402585435,
            "auditor_fp_violation": 0.00996941366574331,
            "ave_precision_score": 0.8389411872950792,
            "fpr": 0.12171052631578948,
            "logloss": 0.5835388240395363,
            "mae": 0.2788342859072073,
            "precision": 0.7516778523489933,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8369827315210968,
            "auditor_fn_violation": 0.007454626409039009,
            "auditor_fp_violation": 0.018527919456308817,
            "ave_precision_score": 0.8373543160174542,
            "fpr": 0.10976948408342481,
            "logloss": 0.6301845598669534,
            "mae": 0.2816818401782943,
            "precision": 0.7916666666666666,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6761183952037209,
            "auditor_fn_violation": 0.00890658664204371,
            "auditor_fp_violation": 0.0005722914742997867,
            "ave_precision_score": 0.6773752411411672,
            "fpr": 0.14692982456140352,
            "logloss": 0.7390266134790625,
            "mae": 0.3546754400298947,
            "precision": 0.7124463519313304,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7079741817052123,
            "auditor_fn_violation": 0.015447079205956648,
            "auditor_fp_violation": 0.015707933436635367,
            "ave_precision_score": 0.709086117245556,
            "fpr": 0.1350164654226125,
            "logloss": 0.7494547965536872,
            "mae": 0.3582407581905142,
            "precision": 0.7399577167019028,
            "recall": 0.7028112449799196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7940929342613197,
            "auditor_fn_violation": 0.015062326869806098,
            "auditor_fp_violation": 0.012119113573407203,
            "ave_precision_score": 0.7951269556762364,
            "fpr": 0.15789473684210525,
            "logloss": 0.5560227089983696,
            "mae": 0.34051061176956354,
            "precision": 0.7142857142857143,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8095563192678639,
            "auditor_fn_violation": 0.011633801947636878,
            "auditor_fp_violation": 0.011439415484141907,
            "ave_precision_score": 0.8107571228909918,
            "fpr": 0.12184412733260154,
            "logloss": 0.5480526647770276,
            "mae": 0.3317177841515494,
            "precision": 0.7793240556660039,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8545942949767491,
            "auditor_fn_violation": 0.00767543859649123,
            "auditor_fp_violation": 0.0062038319482917844,
            "ave_precision_score": 0.8548091117804948,
            "fpr": 0.1118421052631579,
            "logloss": 0.5179519586123611,
            "mae": 0.2784842647626423,
            "precision": 0.7702702702702703,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8535304101680774,
            "auditor_fn_violation": 0.009136435974413569,
            "auditor_fp_violation": 0.01615179551513251,
            "ave_precision_score": 0.8538835456516254,
            "fpr": 0.09549945115257959,
            "logloss": 0.5553068273286988,
            "mae": 0.28231580491719255,
            "precision": 0.8133047210300429,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8285693530698317,
            "auditor_fn_violation": 0.014429920744844574,
            "auditor_fp_violation": 0.020943944290550943,
            "ave_precision_score": 0.828811400570435,
            "fpr": 0.1699561403508772,
            "logloss": 0.690440443787927,
            "mae": 0.2838454299367874,
            "precision": 0.7030651340996169,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8216887422390629,
            "auditor_fn_violation": 0.0069432504992527734,
            "auditor_fp_violation": 0.023330666617053346,
            "ave_precision_score": 0.8223196385931046,
            "fpr": 0.15477497255762898,
            "logloss": 0.7210827202465326,
            "mae": 0.2830832886910765,
            "precision": 0.7431693989071039,
            "recall": 0.8192771084337349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8275819489587407,
            "auditor_fn_violation": 0.003780009233610347,
            "auditor_fp_violation": 0.0057132963988919695,
            "ave_precision_score": 0.8280373896496664,
            "fpr": 0.11293859649122807,
            "logloss": 0.5033065964428959,
            "mae": 0.31005440917521665,
            "precision": 0.7669683257918553,
            "recall": 0.743421052631579
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8254984817485238,
            "auditor_fn_violation": 0.008600813793042651,
            "auditor_fp_violation": 0.00656224833418828,
            "ave_precision_score": 0.8263266546864388,
            "fpr": 0.0867178924259056,
            "logloss": 0.5142819373411514,
            "mae": 0.30650602684854134,
            "precision": 0.8252212389380531,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8073307187242398,
            "auditor_fn_violation": 0.01096491228070176,
            "auditor_fp_violation": 0.012205678670360117,
            "ave_precision_score": 0.8076733497730494,
            "fpr": 0.17105263157894737,
            "logloss": 0.5775925691616037,
            "mae": 0.3185912789531836,
            "precision": 0.7094972067039106,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8625347027622822,
            "auditor_fn_violation": 0.016300107124436275,
            "auditor_fp_violation": 0.023227010203512092,
            "ave_precision_score": 0.8627313931496684,
            "fpr": 0.15148188803512624,
            "logloss": 0.5176790435438964,
            "mae": 0.2963332191301851,
            "precision": 0.7531305903398927,
            "recall": 0.8453815261044176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8177219022932477,
            "auditor_fn_violation": 0.009983841181902134,
            "auditor_fp_violation": 0.007170475530932598,
            "ave_precision_score": 0.8180873853012198,
            "fpr": 0.06907894736842106,
            "logloss": 0.5792497583181881,
            "mae": 0.3572386608064877,
            "precision": 0.8184438040345822,
            "recall": 0.6228070175438597
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8356949219827274,
            "auditor_fn_violation": 0.0018823923575751983,
            "auditor_fp_violation": 0.008595508753651232,
            "ave_precision_score": 0.8362013772326296,
            "fpr": 0.050493962678375415,
            "logloss": 0.5978204875731506,
            "mae": 0.3630768330808643,
            "precision": 0.8729281767955801,
            "recall": 0.6345381526104418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8448593420348324,
            "auditor_fn_violation": 0.01366045321637428,
            "auditor_fp_violation": 0.009005174669128964,
            "ave_precision_score": 0.8454355101524389,
            "fpr": 0.09320175438596491,
            "logloss": 0.48718222402450945,
            "mae": 0.32081780812229244,
            "precision": 0.7916666666666666,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.863168926085,
            "auditor_fn_violation": 0.011763850131591135,
            "auditor_fp_violation": 0.010976948408342482,
            "ave_precision_score": 0.863471474885357,
            "fpr": 0.07683863885839737,
            "logloss": 0.5075624188904413,
            "mae": 0.3250403977433704,
            "precision": 0.833729216152019,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8486995633918358,
            "auditor_fn_violation": 0.009120594798399518,
            "auditor_fp_violation": 0.007576850569405972,
            "ave_precision_score": 0.8489414384314474,
            "fpr": 0.09978070175438597,
            "logloss": 0.5046847380918024,
            "mae": 0.3207129439864283,
            "precision": 0.7843601895734598,
            "recall": 0.7258771929824561
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8627690369446244,
            "auditor_fn_violation": 0.009694100220861498,
            "auditor_fp_violation": 0.01248395318982679,
            "ave_precision_score": 0.8630290561284676,
            "fpr": 0.0845225027442371,
            "logloss": 0.5065838787619147,
            "mae": 0.3187400937588638,
            "precision": 0.8285077951002228,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 18998,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8376648862901614,
            "auditor_fn_violation": 0.007819713758079421,
            "auditor_fp_violation": 0.00411184210526316,
            "ave_precision_score": 0.8379910212962233,
            "fpr": 0.041666666666666664,
            "logloss": 0.6038086025886467,
            "mae": 0.35156235760159527,
            "precision": 0.867595818815331,
            "recall": 0.5460526315789473
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8454073258807869,
            "auditor_fn_violation": 0.014170843637998764,
            "auditor_fp_violation": 0.008677902313132738,
            "ave_precision_score": 0.8461467450050415,
            "fpr": 0.03951701427003293,
            "logloss": 0.6403568398135306,
            "mae": 0.3667270921131864,
            "precision": 0.8811881188118812,
            "recall": 0.536144578313253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7983694855423619,
            "auditor_fn_violation": 0.011373691905201603,
            "auditor_fp_violation": 0.016000115420129277,
            "ave_precision_score": 0.7910119806353983,
            "fpr": 0.12828947368421054,
            "logloss": 1.0543973441818801,
            "mae": 0.27067626617032436,
            "precision": 0.7536842105263157,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8013890985026108,
            "auditor_fn_violation": 0.00836496369671882,
            "auditor_fp_violation": 0.01985153212152785,
            "ave_precision_score": 0.7874691528024138,
            "fpr": 0.1163556531284303,
            "logloss": 1.3842201215769212,
            "mae": 0.27117691530028726,
            "precision": 0.7849898580121704,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 18998,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8465845656729437,
            "auditor_fn_violation": 0.009276892890120039,
            "auditor_fp_violation": 0.011267890120036931,
            "ave_precision_score": 0.8468134881208436,
            "fpr": 0.1206140350877193,
            "logloss": 0.6125820757092497,
            "mae": 0.31693620556435365,
            "precision": 0.7634408602150538,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8606116066344209,
            "auditor_fn_violation": 0.01350076485965817,
            "auditor_fp_violation": 0.011545729754440619,
            "ave_precision_score": 0.861170732113739,
            "fpr": 0.0889132821075741,
            "logloss": 0.5443019130967872,
            "mae": 0.31198523797148425,
            "precision": 0.8261802575107297,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8460348295905707,
            "auditor_fn_violation": 0.004934210526315793,
            "auditor_fp_violation": 0.005092913204062786,
            "ave_precision_score": 0.8463184562477769,
            "fpr": 0.1074561403508772,
            "logloss": 0.4902928600119048,
            "mae": 0.3139950067760717,
            "precision": 0.7772727272727272,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8688039172947875,
            "auditor_fn_violation": 0.006475958719620528,
            "auditor_fp_violation": 0.014761736430976792,
            "ave_precision_score": 0.8691052322137783,
            "fpr": 0.08122941822173436,
            "logloss": 0.48517512503593524,
            "mae": 0.3065568382589046,
            "precision": 0.838074398249453,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8386149373902358,
            "auditor_fn_violation": 0.011888273314866117,
            "auditor_fp_violation": 0.018996229609110495,
            "ave_precision_score": 0.838844140036077,
            "fpr": 0.15350877192982457,
            "logloss": 0.6408848996804221,
            "mae": 0.2778416885786248,
            "precision": 0.7216699801192843,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8368354300957371,
            "auditor_fn_violation": 0.005118167510877764,
            "auditor_fp_violation": 0.021358536903012156,
            "ave_precision_score": 0.8371836718952506,
            "fpr": 0.13611416026344675,
            "logloss": 0.6778640360780201,
            "mae": 0.27992496155222735,
            "precision": 0.7615384615384615,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8507122665743106,
            "auditor_fn_violation": 0.004260926438904284,
            "auditor_fp_violation": 0.007711507386888274,
            "ave_precision_score": 0.8511345624808504,
            "fpr": 0.08442982456140351,
            "logloss": 0.4916433853919722,
            "mae": 0.3127638302087833,
            "precision": 0.8045685279187818,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8640167989275009,
            "auditor_fn_violation": 0.008653714749227432,
            "auditor_fp_violation": 0.011256023367876612,
            "ave_precision_score": 0.8646793441564278,
            "fpr": 0.06915477497255763,
            "logloss": 0.5077980868227678,
            "mae": 0.31428998940635544,
            "precision": 0.8481927710843373,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8352340250579238,
            "auditor_fn_violation": 0.00672081794398277,
            "auditor_fp_violation": 0.005020775623268698,
            "ave_precision_score": 0.8356153795258062,
            "fpr": 0.1118421052631579,
            "logloss": 0.5019682525637111,
            "mae": 0.3124683912518728,
            "precision": 0.7707865168539326,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8303574061351955,
            "auditor_fn_violation": 0.010346545347140487,
            "auditor_fp_violation": 0.00822872452112066,
            "ave_precision_score": 0.831134628673278,
            "fpr": 0.09001097694840834,
            "logloss": 0.5122246158587366,
            "mae": 0.30871778878288264,
            "precision": 0.8185840707964602,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7837318070912448,
            "auditor_fn_violation": 0.006564519852262235,
            "auditor_fp_violation": 0.010164185133887355,
            "ave_precision_score": 0.7756417026278184,
            "fpr": 0.17214912280701755,
            "logloss": 1.3086023653870484,
            "mae": 0.2990712143117623,
            "precision": 0.70817843866171,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.794035771879586,
            "auditor_fn_violation": 0.009407553374860584,
            "auditor_fp_violation": 0.018945202967231286,
            "ave_precision_score": 0.7802703635674505,
            "fpr": 0.14818880351262348,
            "logloss": 1.4863917922259644,
            "mae": 0.28669457089215544,
            "precision": 0.755877034358047,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.855581857399027,
            "auditor_fn_violation": 0.003700657894736845,
            "auditor_fp_violation": 0.007127192982456144,
            "ave_precision_score": 0.8559426950105469,
            "fpr": 0.125,
            "logloss": 0.4734394926006729,
            "mae": 0.29840141459339575,
            "precision": 0.76,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.8807628974330513,
            "auditor_fn_violation": 0.003566406129457461,
            "auditor_fp_violation": 0.014278006501117636,
            "ave_precision_score": 0.881902461369816,
            "fpr": 0.09879253567508232,
            "logloss": 0.4578885322342494,
            "mae": 0.28839800363400403,
            "precision": 0.82,
            "recall": 0.8232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8476327029302947,
            "auditor_fn_violation": 0.006273564943059411,
            "auditor_fp_violation": 0.010253154816866731,
            "ave_precision_score": 0.8479536730733797,
            "fpr": 0.09649122807017543,
            "logloss": 0.5125999211853223,
            "mae": 0.2911032796237203,
            "precision": 0.7929411764705883,
            "recall": 0.7390350877192983
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8804663175811526,
            "auditor_fn_violation": 0.005786042082710642,
            "auditor_fp_violation": 0.013275994503552229,
            "ave_precision_score": 0.8809298374130127,
            "fpr": 0.07354555433589462,
            "logloss": 0.49387276563964394,
            "mae": 0.2814125731490866,
            "precision": 0.8484162895927602,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8144787253434151,
            "auditor_fn_violation": 0.010835064635272392,
            "auditor_fp_violation": 0.008194829178208681,
            "ave_precision_score": 0.814768976792829,
            "fpr": 0.10526315789473684,
            "logloss": 0.6539286471812276,
            "mae": 0.3018351955364471,
            "precision": 0.7611940298507462,
            "recall": 0.6710526315789473
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8067385167478676,
            "auditor_fn_violation": 0.018594686098951242,
            "auditor_fp_violation": 0.02048144417304774,
            "ave_precision_score": 0.808071340848038,
            "fpr": 0.09549945115257959,
            "logloss": 0.7137749233863371,
            "mae": 0.3165369757425292,
            "precision": 0.7872860635696821,
            "recall": 0.6465863453815262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.838627259207363,
            "auditor_fn_violation": 0.011888273314866117,
            "auditor_fp_violation": 0.018996229609110495,
            "ave_precision_score": 0.8388564451598051,
            "fpr": 0.15350877192982457,
            "logloss": 0.640938289828279,
            "mae": 0.27785313672129713,
            "precision": 0.7216699801192843,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8368541408643263,
            "auditor_fn_violation": 0.005118167510877764,
            "auditor_fp_violation": 0.021358536903012156,
            "ave_precision_score": 0.837202370897019,
            "fpr": 0.13611416026344675,
            "logloss": 0.6778288181168944,
            "mae": 0.27990863449486314,
            "precision": 0.7615384615384615,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7638551897934021,
            "auditor_fn_violation": 0.011878654970760237,
            "auditor_fp_violation": 0.010205063096337338,
            "ave_precision_score": 0.7643644299543702,
            "fpr": 0.11293859649122807,
            "logloss": 0.7690017071629781,
            "mae": 0.3406730733787307,
            "precision": 0.7296587926509186,
            "recall": 0.6096491228070176
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7557751137903432,
            "auditor_fn_violation": 0.017616018409532766,
            "auditor_fp_violation": 0.01405474653349033,
            "ave_precision_score": 0.7572532317952028,
            "fpr": 0.10208562019758508,
            "logloss": 0.8327986547497468,
            "mae": 0.3609082497646466,
            "precision": 0.7615384615384615,
            "recall": 0.5963855421686747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 18998,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.837487375271893,
            "auditor_fn_violation": 0.01041666666666667,
            "auditor_fp_violation": 0.010928843490304709,
            "ave_precision_score": 0.8380158308700738,
            "fpr": 0.10635964912280702,
            "logloss": 0.6066613891868073,
            "mae": 0.3010281533182148,
            "precision": 0.7790432801822323,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8654079133872696,
            "auditor_fn_violation": 0.009125414941875076,
            "auditor_fp_violation": 0.011051368397551588,
            "ave_precision_score": 0.8665702970716885,
            "fpr": 0.0801317233809001,
            "logloss": 0.5465926941168734,
            "mae": 0.29345187325387867,
            "precision": 0.8392070484581498,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8331922363292499,
            "auditor_fn_violation": 0.01201571637426901,
            "auditor_fp_violation": 0.01627423822714681,
            "ave_precision_score": 0.8334973719756719,
            "fpr": 0.14144736842105263,
            "logloss": 0.6147073969522893,
            "mae": 0.2796256526098181,
            "precision": 0.736734693877551,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8248419493198276,
            "auditor_fn_violation": 0.005118167510877764,
            "auditor_fp_violation": 0.021076804086720552,
            "ave_precision_score": 0.825467544466471,
            "fpr": 0.1350164654226125,
            "logloss": 0.6602558413017704,
            "mae": 0.281083019463541,
            "precision": 0.7630057803468208,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8310575300335057,
            "auditor_fn_violation": 0.008591585872576179,
            "auditor_fp_violation": 0.019390581717451526,
            "ave_precision_score": 0.831292851541377,
            "fpr": 0.15789473684210525,
            "logloss": 0.6872032277694619,
            "mae": 0.2808346889016805,
            "precision": 0.7125748502994012,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.835005528709287,
            "auditor_fn_violation": 0.0048360290778922494,
            "auditor_fp_violation": 0.023591136579285202,
            "ave_precision_score": 0.835305990331878,
            "fpr": 0.1437980241492865,
            "logloss": 0.7167990738518,
            "mae": 0.28290040764144603,
            "precision": 0.7495219885277247,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8256986308131358,
            "auditor_fn_violation": 0.01177285318559557,
            "auditor_fp_violation": 0.00548245614035088,
            "ave_precision_score": 0.825952093993319,
            "fpr": 0.08333333333333333,
            "logloss": 0.5613015540870532,
            "mae": 0.3141290401517038,
            "precision": 0.7912087912087912,
            "recall": 0.631578947368421
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8273557203165354,
            "auditor_fn_violation": 0.023078042135611602,
            "auditor_fp_violation": 0.01567869701230322,
            "ave_precision_score": 0.8277036466958121,
            "fpr": 0.08562019758507135,
            "logloss": 0.6120301944846872,
            "mae": 0.32963827799629464,
            "precision": 0.792,
            "recall": 0.5963855421686747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8316256436011304,
            "auditor_fn_violation": 0.009829947676208066,
            "auditor_fp_violation": 0.017204813019390593,
            "ave_precision_score": 0.8318670055067836,
            "fpr": 0.14802631578947367,
            "logloss": 0.6801672059483348,
            "mae": 0.27883384957818125,
            "precision": 0.725050916496945,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8314650338400551,
            "auditor_fn_violation": 0.0033327602396413312,
            "auditor_fp_violation": 0.02561908128523322,
            "ave_precision_score": 0.8318058540995014,
            "fpr": 0.141602634467618,
            "logloss": 0.7227256424394571,
            "mae": 0.2829836751464559,
            "precision": 0.7514450867052023,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7401005036101469,
            "auditor_fn_violation": 0.017861265004616815,
            "auditor_fp_violation": 0.007776431209602958,
            "ave_precision_score": 0.7411027799739999,
            "fpr": 0.05921052631578947,
            "logloss": 1.8093544830551782,
            "mae": 0.3632422214634077,
            "precision": 0.7890625,
            "recall": 0.44298245614035087
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7773679610486381,
            "auditor_fn_violation": 0.013992302910875123,
            "auditor_fp_violation": 0.006641984036912315,
            "ave_precision_score": 0.7776838494197456,
            "fpr": 0.043907793633369926,
            "logloss": 2.1824633395935424,
            "mae": 0.37915803492564026,
            "precision": 0.8507462686567164,
            "recall": 0.4578313253012048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8514017129324065,
            "auditor_fn_violation": 0.005893640350877194,
            "auditor_fp_violation": 0.011811326562019086,
            "ave_precision_score": 0.8517607366233948,
            "fpr": 0.09649122807017543,
            "logloss": 0.5130986160485321,
            "mae": 0.29036995863842957,
            "precision": 0.7929411764705883,
            "recall": 0.7390350877192983
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8773461311446018,
            "auditor_fn_violation": 0.005726528507002768,
            "auditor_fp_violation": 0.011309180503025972,
            "ave_precision_score": 0.8777515254422522,
            "fpr": 0.07025246981339188,
            "logloss": 0.4947248692113586,
            "mae": 0.28004792041703575,
            "precision": 0.8558558558558559,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8064052519307725,
            "auditor_fn_violation": 0.019352108341028008,
            "auditor_fp_violation": 0.013061711295783327,
            "ave_precision_score": 0.8076112530391129,
            "fpr": 0.11403508771929824,
            "logloss": 0.5419080853136709,
            "mae": 0.28981968549905696,
            "precision": 0.7719298245614035,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8200851683665833,
            "auditor_fn_violation": 0.02262838400804095,
            "auditor_fp_violation": 0.01701559896130958,
            "ave_precision_score": 0.821334551541361,
            "fpr": 0.09659714599341383,
            "logloss": 0.554447978378885,
            "mae": 0.29545172737557307,
            "precision": 0.811965811965812,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8387456308863902,
            "auditor_fn_violation": 0.011599722991689751,
            "auditor_fp_violation": 0.018149815327793167,
            "ave_precision_score": 0.8389768132516344,
            "fpr": 0.15350877192982457,
            "logloss": 0.6380266220992112,
            "mae": 0.2783691169929306,
            "precision": 0.7216699801192843,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8378382776519817,
            "auditor_fn_violation": 0.005118167510877764,
            "auditor_fp_violation": 0.021060856946175748,
            "ave_precision_score": 0.8381733268448339,
            "fpr": 0.1394072447859495,
            "logloss": 0.6740525205276113,
            "mae": 0.2800382124871037,
            "precision": 0.7571701720841301,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8268885314536663,
            "auditor_fn_violation": 0.009349030470914128,
            "auditor_fp_violation": 0.005674823022468453,
            "ave_precision_score": 0.8282537300296904,
            "fpr": 0.06798245614035088,
            "logloss": 0.5506298505969255,
            "mae": 0.3507652295377563,
            "precision": 0.8080495356037152,
            "recall": 0.5723684210526315
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8651413492878044,
            "auditor_fn_violation": 0.006215862351712003,
            "auditor_fp_violation": 0.007489840342544579,
            "ave_precision_score": 0.8653313991182314,
            "fpr": 0.04720087815587267,
            "logloss": 0.5596690458171157,
            "mae": 0.35204245206418433,
            "precision": 0.8746355685131195,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 18998,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8406442906072478,
            "auditor_fn_violation": 0.011924342105263162,
            "auditor_fp_violation": 0.013694117420744847,
            "ave_precision_score": 0.8408563085743916,
            "fpr": 0.1524122807017544,
            "logloss": 0.7896116634717837,
            "mae": 0.2794628555445723,
            "precision": 0.722,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8381073080392613,
            "auditor_fn_violation": 0.006773526598159937,
            "auditor_fp_violation": 0.024484176449794424,
            "ave_precision_score": 0.8385145610269611,
            "fpr": 0.13391877058177826,
            "logloss": 0.7573667111576363,
            "mae": 0.27518972566522576,
            "precision": 0.7676190476190476,
            "recall": 0.8092369477911646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8488582436324567,
            "auditor_fn_violation": 0.010142543859649123,
            "auditor_fp_violation": 0.0077523853493382585,
            "ave_precision_score": 0.8493452708323868,
            "fpr": 0.09649122807017543,
            "logloss": 0.48227947503369406,
            "mae": 0.2940926530601134,
            "precision": 0.7953488372093023,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8695663785053558,
            "auditor_fn_violation": 0.008631672684150434,
            "auditor_fp_violation": 0.00978622858099686,
            "ave_precision_score": 0.8707264358621647,
            "fpr": 0.07793633369923161,
            "logloss": 0.4810471440547769,
            "mae": 0.28954707807989055,
            "precision": 0.8422222222222222,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 18998,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7841860435997338,
            "auditor_fn_violation": 0.008098645737149891,
            "auditor_fp_violation": 0.013056902123730384,
            "ave_precision_score": 0.7761436737663684,
            "fpr": 0.16885964912280702,
            "logloss": 1.2946131205549427,
            "mae": 0.2996683859700528,
            "precision": 0.7094339622641509,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.79449321257848,
            "auditor_fn_violation": 0.0071151786068533234,
            "auditor_fp_violation": 0.01873523228339132,
            "ave_precision_score": 0.7808129436845128,
            "fpr": 0.14928649835345773,
            "logloss": 1.4719261706627667,
            "mae": 0.28758514754664627,
            "precision": 0.7536231884057971,
            "recall": 0.8353413654618473
        }
    }
]