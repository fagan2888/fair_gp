[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8048342648350271,
            "auditor_fn_violation": 0.011192316005619807,
            "auditor_fp_violation": 0.007500000000000002,
            "ave_precision_score": 0.8054549060711833,
            "fpr": 0.06359649122807018,
            "logloss": 0.6363509628256858,
            "mae": 0.35442346562514987,
            "precision": 0.8289085545722714,
            "recall": 0.5770020533880903
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8508317978633803,
            "auditor_fn_violation": 0.01537948039310169,
            "auditor_fp_violation": 0.009849586139377578,
            "ave_precision_score": 0.8511142963253312,
            "fpr": 0.052689352360043906,
            "logloss": 0.5256073574300149,
            "mae": 0.3126210667781326,
            "precision": 0.865546218487395,
            "recall": 0.6616702355460385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8369626519384451,
            "auditor_fn_violation": 0.009012842681652804,
            "auditor_fp_violation": 0.02027089783281734,
            "ave_precision_score": 0.8372597653987705,
            "fpr": 0.12719298245614036,
            "logloss": 0.6879865460020391,
            "mae": 0.2742747878956184,
            "precision": 0.7656565656565657,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8381712966786519,
            "auditor_fn_violation": 0.006849427764862957,
            "auditor_fp_violation": 0.016287418043729792,
            "ave_precision_score": 0.8384807427912853,
            "fpr": 0.1350164654226125,
            "logloss": 0.6454325664949887,
            "mae": 0.2588042971331638,
            "precision": 0.7564356435643564,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8217065614964878,
            "auditor_fn_violation": 0.014769984509528447,
            "auditor_fp_violation": 0.019035087719298245,
            "ave_precision_score": 0.8219847656436117,
            "fpr": 0.11074561403508772,
            "logloss": 1.5190682169716596,
            "mae": 0.2779948739775522,
            "precision": 0.7789934354485777,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7983072541383722,
            "auditor_fn_violation": 0.00753813138020436,
            "auditor_fp_violation": 0.0196695048506245,
            "ave_precision_score": 0.7976654268023269,
            "fpr": 0.13172338090010977,
            "logloss": 1.5685581055351272,
            "mae": 0.27366175332138426,
            "precision": 0.7473684210526316,
            "recall": 0.7601713062098501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8210582633599075,
            "auditor_fn_violation": 0.018273352786483663,
            "auditor_fp_violation": 0.01452012383900929,
            "ave_precision_score": 0.8216125730741062,
            "fpr": 0.07785087719298246,
            "logloss": 0.6002643267208589,
            "mae": 0.32612629173332885,
            "precision": 0.8136482939632546,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8830613450097593,
            "auditor_fn_violation": 0.016728681332371192,
            "auditor_fp_violation": 0.004613285074316908,
            "ave_precision_score": 0.8832239690435634,
            "fpr": 0.059275521405049394,
            "logloss": 0.4624299424349323,
            "mae": 0.2798085185750645,
            "precision": 0.8615384615384616,
            "recall": 0.7194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.845300418806219,
            "auditor_fn_violation": 0.01735022875463814,
            "auditor_fp_violation": 0.016609907120743034,
            "ave_precision_score": 0.845616973921614,
            "fpr": 0.10526315789473684,
            "logloss": 0.6384702322543154,
            "mae": 0.2755736889969723,
            "precision": 0.7922077922077922,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8490454081803732,
            "auditor_fn_violation": 0.006541509083601098,
            "auditor_fp_violation": 0.007355049890724977,
            "ave_precision_score": 0.8493814719514751,
            "fpr": 0.11306256860592755,
            "logloss": 0.5833386352457156,
            "mae": 0.2564198306192576,
            "precision": 0.7827004219409283,
            "recall": 0.7944325481798715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8438627144392614,
            "auditor_fn_violation": 0.014121546165207688,
            "auditor_fp_violation": 0.01504385964912281,
            "ave_precision_score": 0.844237867711324,
            "fpr": 0.1118421052631579,
            "logloss": 0.6981916595724976,
            "mae": 0.2768959368401884,
            "precision": 0.7777777777777778,
            "recall": 0.7330595482546202
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8522878204658229,
            "auditor_fn_violation": 0.0039465302735775245,
            "auditor_fp_violation": 0.010784110125493221,
            "ave_precision_score": 0.8525305300847175,
            "fpr": 0.11525795828759605,
            "logloss": 0.6292712744816107,
            "mae": 0.2603881698460425,
            "precision": 0.7756410256410257,
            "recall": 0.7773019271948608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8150121858920775,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7614107492020191,
            "fpr": 0.46600877192982454,
            "logloss": 7.336852234614963,
            "mae": 0.46599709013836427,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.8064911166347791,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7504866685282935,
            "fpr": 0.48737650933040616,
            "logloss": 7.615568113546666,
            "mae": 0.4873594762072474,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7441676804577027,
            "auditor_fn_violation": 0.016505907993803814,
            "auditor_fp_violation": 0.0065144478844169264,
            "ave_precision_score": 0.7447157034026775,
            "fpr": 0.04276315789473684,
            "logloss": 2.528613506625853,
            "mae": 0.4036386007927661,
            "precision": 0.821917808219178,
            "recall": 0.36960985626283366
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7447359089640264,
            "auditor_fn_violation": 0.012185117890545506,
            "auditor_fp_violation": 0.009913865566993998,
            "ave_precision_score": 0.7451054800967232,
            "fpr": 0.050493962678375415,
            "logloss": 2.4646473325300113,
            "mae": 0.37974951216683084,
            "precision": 0.8050847457627118,
            "recall": 0.4068522483940043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8407113115004374,
            "auditor_fn_violation": 0.018403941064159372,
            "auditor_fp_violation": 0.022827657378740974,
            "ave_precision_score": 0.8412425927616033,
            "fpr": 0.14364035087719298,
            "logloss": 0.7280409366296183,
            "mae": 0.27568086580925705,
            "precision": 0.745136186770428,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8447786259624182,
            "auditor_fn_violation": 0.0062876524608813985,
            "auditor_fp_violation": 0.018660812294182216,
            "ave_precision_score": 0.8450248096513715,
            "fpr": 0.15367727771679474,
            "logloss": 0.7013538458427869,
            "mae": 0.2638886317613237,
            "precision": 0.7338403041825095,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7998415479338432,
            "auditor_fn_violation": 0.012304567887892217,
            "auditor_fp_violation": 0.02059081527347782,
            "ave_precision_score": 0.800161613577364,
            "fpr": 0.13486842105263158,
            "logloss": 0.9650972024477261,
            "mae": 0.2923138192923433,
            "precision": 0.7448132780082988,
            "recall": 0.7371663244353183
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7737921100847933,
            "auditor_fn_violation": 0.007641554448719787,
            "auditor_fp_violation": 0.023251846797401145,
            "ave_precision_score": 0.7724799125106242,
            "fpr": 0.15477497255762898,
            "logloss": 1.0492399798849432,
            "mae": 0.29324708540360855,
            "precision": 0.7168674698795181,
            "recall": 0.7644539614561028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8399052297909737,
            "auditor_fn_violation": 0.012471180518030194,
            "auditor_fp_violation": 0.018072755417956658,
            "ave_precision_score": 0.8402386127633218,
            "fpr": 0.12390350877192982,
            "logloss": 0.7302131827284524,
            "mae": 0.27579566430639235,
            "precision": 0.7650727650727651,
            "recall": 0.75564681724846
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8419059321269086,
            "auditor_fn_violation": 0.003006320559800867,
            "auditor_fp_violation": 0.015085887204438249,
            "ave_precision_score": 0.8421536246269918,
            "fpr": 0.13830954994511527,
            "logloss": 0.6862703899016629,
            "mae": 0.26280130478776326,
            "precision": 0.748,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8358624266373632,
            "auditor_fn_violation": 0.022630047912388783,
            "auditor_fp_violation": 0.018663570691434477,
            "ave_precision_score": 0.8361598246924319,
            "fpr": 0.08881578947368421,
            "logloss": 0.9346123207845153,
            "mae": 0.27950230615495153,
            "precision": 0.80622009569378,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8266179545275808,
            "auditor_fn_violation": 0.008257391811243502,
            "auditor_fp_violation": 0.01765211973773994,
            "ave_precision_score": 0.8269972728392417,
            "fpr": 0.09879253567508232,
            "logloss": 0.9090553375280167,
            "mae": 0.2625420600855075,
            "precision": 0.7945205479452054,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8481577947691147,
            "auditor_fn_violation": 0.014493047299974785,
            "auditor_fp_violation": 0.016584107327141388,
            "ave_precision_score": 0.8484254321091198,
            "fpr": 0.11074561403508772,
            "logloss": 0.6938683707017037,
            "mae": 0.2690537904265946,
            "precision": 0.7860169491525424,
            "recall": 0.7618069815195072
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8504822001504535,
            "auditor_fn_violation": 0.0052769270185714905,
            "auditor_fp_violation": 0.013172338090010978,
            "ave_precision_score": 0.8507394970734874,
            "fpr": 0.1251372118551043,
            "logloss": 0.65616080216853,
            "mae": 0.25741048960776053,
            "precision": 0.7654320987654321,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8154128986487037,
            "auditor_fn_violation": 0.010235419143340894,
            "auditor_fp_violation": 0.0025128998968008244,
            "ave_precision_score": 0.815859677180035,
            "fpr": 0.08662280701754387,
            "logloss": 0.566803093088546,
            "mae": 0.33978071320279124,
            "precision": 0.8005050505050505,
            "recall": 0.6509240246406571
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8862737311968232,
            "auditor_fn_violation": 0.004792719015976517,
            "auditor_fp_violation": 0.012262536960670879,
            "ave_precision_score": 0.8864281583668794,
            "fpr": 0.07683863885839737,
            "logloss": 0.4459356536318098,
            "mae": 0.292256064549432,
            "precision": 0.8333333333333334,
            "recall": 0.7494646680942184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6325762505186541,
            "auditor_fn_violation": 0.005989048596851475,
            "auditor_fp_violation": 0.022871517027863785,
            "ave_precision_score": 0.627094151624982,
            "fpr": 0.20833333333333334,
            "logloss": 1.7038906267814475,
            "mae": 0.3661600966946009,
            "precision": 0.6752136752136753,
            "recall": 0.811088295687885
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.673042444504677,
            "auditor_fn_violation": 0.009545479119117524,
            "auditor_fp_violation": 0.02121221111341859,
            "ave_precision_score": 0.6698064336241134,
            "fpr": 0.2239297475301866,
            "logloss": 1.4056532555540093,
            "mae": 0.341528830226842,
            "precision": 0.6655737704918033,
            "recall": 0.8693790149892934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8597976450031198,
            "auditor_fn_violation": 0.014553838394754855,
            "auditor_fp_violation": 0.017799277605779158,
            "ave_precision_score": 0.8600078031154761,
            "fpr": 0.10635964912280702,
            "logloss": 0.6233097006829201,
            "mae": 0.26841698644374157,
            "precision": 0.7940552016985138,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.866399404724258,
            "auditor_fn_violation": 0.008946095426584904,
            "auditor_fp_violation": 0.014302172644653438,
            "ave_precision_score": 0.8666054542876096,
            "fpr": 0.11745334796926454,
            "logloss": 0.5675470415951804,
            "mae": 0.25204614156216304,
            "precision": 0.7775467775467776,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8419582010640922,
            "auditor_fn_violation": 0.015861972693540838,
            "auditor_fp_violation": 0.01522703818369453,
            "ave_precision_score": 0.8424941466007442,
            "fpr": 0.11951754385964912,
            "logloss": 0.7344905982532923,
            "mae": 0.27090222410850895,
            "precision": 0.7733887733887734,
            "recall": 0.7638603696098563
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8455004929952388,
            "auditor_fn_violation": 0.007300728427475756,
            "auditor_fp_violation": 0.011229121547453055,
            "ave_precision_score": 0.845736209736387,
            "fpr": 0.13391877058177826,
            "logloss": 0.6992559840232407,
            "mae": 0.2622217767782853,
            "precision": 0.7520325203252033,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7997059464221166,
            "auditor_fn_violation": 0.012626535538023712,
            "auditor_fp_violation": 0.026958204334365337,
            "ave_precision_score": 0.8000401601042344,
            "fpr": 0.14035087719298245,
            "logloss": 0.9058824180540503,
            "mae": 0.2988255504899887,
            "precision": 0.7387755102040816,
            "recall": 0.7433264887063655
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.781272139710889,
            "auditor_fn_violation": 0.0070609749504626975,
            "auditor_fp_violation": 0.024881083058909622,
            "ave_precision_score": 0.7817872529384138,
            "fpr": 0.16245883644346873,
            "logloss": 0.9024846378090766,
            "mae": 0.2987860642118491,
            "precision": 0.7069306930693069,
            "recall": 0.7644539614561028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8460622000814013,
            "auditor_fn_violation": 0.017978403400698877,
            "auditor_fp_violation": 0.006132610939112491,
            "ave_precision_score": 0.8464142696818172,
            "fpr": 0.11293859649122807,
            "logloss": 0.5275849362908797,
            "mae": 0.3073347945924309,
            "precision": 0.7799145299145299,
            "recall": 0.7494866529774127
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8934144267221978,
            "auditor_fn_violation": 0.014733086214880235,
            "auditor_fp_violation": 0.009849586139377576,
            "ave_precision_score": 0.8935566647800919,
            "fpr": 0.1141602634467618,
            "logloss": 0.4330753204762303,
            "mae": 0.2732829094131433,
            "precision": 0.7877551020408163,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 31658,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8458579193072276,
            "auditor_fn_violation": 0.016096130984545553,
            "auditor_fp_violation": 0.021075851393188863,
            "ave_precision_score": 0.8462166364312318,
            "fpr": 0.13486842105263158,
            "logloss": 0.6950329792764022,
            "mae": 0.2747151588454987,
            "precision": 0.7535070140280561,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8454941712967884,
            "auditor_fn_violation": 0.006771860463476378,
            "auditor_fp_violation": 0.01601299433352123,
            "ave_precision_score": 0.8457852683214959,
            "fpr": 0.13721185510428102,
            "logloss": 0.6584412395810616,
            "mae": 0.26247078936284557,
            "precision": 0.7529644268774703,
            "recall": 0.815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8009223732060758,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6527023910759926,
            "fpr": 0.46600877192982454,
            "logloss": 11.505946504389463,
            "mae": 0.466008304634638,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7928261183844865,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6358873315156411,
            "fpr": 0.48737650933040616,
            "logloss": 11.976716051319595,
            "mae": 0.4873757038498553,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8454830923629346,
            "auditor_fn_violation": 0.013283979970460031,
            "auditor_fp_violation": 0.01807275541795666,
            "ave_precision_score": 0.8457779970454243,
            "fpr": 0.12609649122807018,
            "logloss": 0.6505024089070748,
            "mae": 0.2719937269985645,
            "precision": 0.766260162601626,
            "recall": 0.7741273100616016
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8451804652356206,
            "auditor_fn_violation": 0.009482014963437594,
            "auditor_fp_violation": 0.010576438128578638,
            "ave_precision_score": 0.845489725224397,
            "fpr": 0.1251372118551043,
            "logloss": 0.6234142939800092,
            "mae": 0.25907390033409,
            "precision": 0.7715430861723447,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.832343948667579,
            "auditor_fn_violation": 0.0075471018408444146,
            "auditor_fp_violation": 0.007474200206398352,
            "ave_precision_score": 0.8336264821944571,
            "fpr": 0.07894736842105263,
            "logloss": 0.5363812017899491,
            "mae": 0.32939182357503133,
            "precision": 0.817258883248731,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8932807194889184,
            "auditor_fn_violation": 0.009296323544966704,
            "auditor_fp_violation": 0.008363742447167258,
            "ave_precision_score": 0.8934154239973395,
            "fpr": 0.07793633369923161,
            "logloss": 0.4399164415259934,
            "mae": 0.28942024699615726,
            "precision": 0.8305489260143198,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7619233693078424,
            "auditor_fn_violation": 0.01866736914153969,
            "auditor_fp_violation": 0.009558823529411767,
            "ave_precision_score": 0.7622738696366722,
            "fpr": 0.06578947368421052,
            "logloss": 2.170905130658337,
            "mae": 0.38527380942335615,
            "precision": 0.7841726618705036,
            "recall": 0.44763860369609854
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.753988265091759,
            "auditor_fn_violation": 0.01590834835710106,
            "auditor_fp_violation": 0.009933643852414435,
            "ave_precision_score": 0.7543642649988266,
            "fpr": 0.07354555433589462,
            "logloss": 2.139043044002291,
            "mae": 0.36820473449678986,
            "precision": 0.7697594501718213,
            "recall": 0.4796573875802998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6444565607700061,
            "auditor_fn_violation": 0.018759681544724235,
            "auditor_fp_violation": 0.034468524251805986,
            "ave_precision_score": 0.640490584319229,
            "fpr": 0.12390350877192982,
            "logloss": 1.547224821913008,
            "mae": 0.375120034454734,
            "precision": 0.7230392156862745,
            "recall": 0.6057494866529775
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6939716415879758,
            "auditor_fn_violation": 0.021638926562569785,
            "auditor_fp_violation": 0.03779135886709981,
            "ave_precision_score": 0.6913648230472735,
            "fpr": 0.1163556531284303,
            "logloss": 1.225444925808419,
            "mae": 0.33305691277627203,
            "precision": 0.7476190476190476,
            "recall": 0.6723768736616702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8215792103240617,
            "auditor_fn_violation": 0.019678302532511984,
            "auditor_fp_violation": 0.026831785345717243,
            "ave_precision_score": 0.8218221998480573,
            "fpr": 0.10964912280701754,
            "logloss": 0.9009140177463371,
            "mae": 0.33023677223616177,
            "precision": 0.7607655502392344,
            "recall": 0.6529774127310062
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8249042413611293,
            "auditor_fn_violation": 0.01464376629207145,
            "auditor_fp_violation": 0.018858595148386587,
            "ave_precision_score": 0.8252670607248361,
            "fpr": 0.11306256860592755,
            "logloss": 0.8383377002088318,
            "mae": 0.31031557177603275,
            "precision": 0.7565011820330969,
            "recall": 0.6852248394004282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.803467481499874,
            "auditor_fn_violation": 0.012716596419179368,
            "auditor_fp_violation": 0.01780185758513933,
            "ave_precision_score": 0.8038269042558915,
            "fpr": 0.16447368421052633,
            "logloss": 0.7599940654976993,
            "mae": 0.30885668156521495,
            "precision": 0.7175141242937854,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8106606297610779,
            "auditor_fn_violation": 0.008182175034141367,
            "auditor_fp_violation": 0.011006615836473136,
            "ave_precision_score": 0.81102072913918,
            "fpr": 0.15697036223929747,
            "logloss": 0.7192117458008555,
            "mae": 0.28421822549370407,
            "precision": 0.7346938775510204,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8478838174557763,
            "auditor_fn_violation": 0.022154976764292667,
            "auditor_fp_violation": 0.010887512899896803,
            "ave_precision_score": 0.8482651708964575,
            "fpr": 0.10635964912280702,
            "logloss": 0.5277201295804981,
            "mae": 0.3058460477061504,
            "precision": 0.7815315315315315,
            "recall": 0.7125256673511293
        },
        "train": {
            "accuracy": 0.8057080131723381,
            "auc_prc": 0.8935986552606738,
            "auditor_fn_violation": 0.01108272200114236,
            "auditor_fp_violation": 0.01919729828621157,
            "ave_precision_score": 0.8937471294042308,
            "fpr": 0.09769484083424808,
            "logloss": 0.42995167030457365,
            "mae": 0.2698926544767671,
            "precision": 0.8098290598290598,
            "recall": 0.8115631691648822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8352209903584551,
            "auditor_fn_violation": 0.006238967542058442,
            "auditor_fp_violation": 0.005668214654282769,
            "ave_precision_score": 0.8354997370972951,
            "fpr": 0.10307017543859649,
            "logloss": 0.5443697301071173,
            "mae": 0.32156634085843333,
            "precision": 0.7824074074074074,
            "recall": 0.6940451745379876
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.889370292092494,
            "auditor_fn_violation": 0.0017958005533134148,
            "auditor_fp_violation": 0.011295873260747031,
            "ave_precision_score": 0.8895344065175979,
            "fpr": 0.10208562019758508,
            "logloss": 0.444219403996122,
            "mae": 0.27899216785009756,
            "precision": 0.7973856209150327,
            "recall": 0.7837259100642399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 31658,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8320406572857757,
            "auditor_fn_violation": 0.0109784214128751,
            "auditor_fp_violation": 0.02350877192982456,
            "ave_precision_score": 0.8323361205345979,
            "fpr": 0.14912280701754385,
            "logloss": 0.903022961669852,
            "mae": 0.27522794911248866,
            "precision": 0.7354085603112841,
            "recall": 0.7761806981519507
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8184831255541041,
            "auditor_fn_violation": 0.006619076384987673,
            "auditor_fp_violation": 0.018571810009790246,
            "ave_precision_score": 0.8187726901779551,
            "fpr": 0.1690450054884742,
            "logloss": 0.9143770827233442,
            "mae": 0.2729032782678881,
            "precision": 0.7105263157894737,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6279624583627856,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0007069143446852536,
            "ave_precision_score": 0.6085338414581597,
            "fpr": 0.46271929824561403,
            "logloss": 3.329500634176957,
            "mae": 0.4511139067216662,
            "precision": 0.5357535753575358,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6860891772315165,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016539591182840462,
            "ave_precision_score": 0.6673491749572766,
            "fpr": 0.4840834248079034,
            "logloss": 3.0517329026538125,
            "mae": 0.46132337712528415,
            "precision": 0.51431718061674,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6732789419924325,
            "auditor_fn_violation": 0.012437407687596816,
            "auditor_fp_violation": 0.013147574819401452,
            "ave_precision_score": 0.5906872486007593,
            "fpr": 0.2817982456140351,
            "logloss": 6.251399563339633,
            "mae": 0.34416267244493903,
            "precision": 0.6280752532561505,
            "recall": 0.891170431211499
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6702892742024134,
            "auditor_fn_violation": 0.004498903480421309,
            "auditor_fp_violation": 0.01763728602367461,
            "ave_precision_score": 0.5744566384351315,
            "fpr": 0.300768386388584,
            "logloss": 6.906985949566927,
            "mae": 0.3497759258784891,
            "precision": 0.6102418207681366,
            "recall": 0.9186295503211992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7996509882518569,
            "auditor_fn_violation": 0.0014769984509528495,
            "auditor_fp_violation": 0.011336429308565531,
            "ave_precision_score": 0.8006267244141079,
            "fpr": 0.09429824561403509,
            "logloss": 0.6055742230317049,
            "mae": 0.33261341228307634,
            "precision": 0.7876543209876543,
            "recall": 0.6550308008213552
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8791888963666171,
            "auditor_fn_violation": 0.003695024175142268,
            "auditor_fp_violation": 0.011770552110837513,
            "ave_precision_score": 0.8793550985975411,
            "fpr": 0.08232711306256861,
            "logloss": 0.4595901577284627,
            "mae": 0.28140116351725825,
            "precision": 0.8247663551401869,
            "recall": 0.7558886509635975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7796977334170365,
            "auditor_fn_violation": 0.012741363161497186,
            "auditor_fp_violation": 0.00974974200206399,
            "ave_precision_score": 0.7806742866969467,
            "fpr": 0.10197368421052631,
            "logloss": 0.6081217208399431,
            "mae": 0.3466031282712305,
            "precision": 0.7759036144578313,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8757840684966997,
            "auditor_fn_violation": 0.00884267235806947,
            "auditor_fp_violation": 0.006952067325283572,
            "ave_precision_score": 0.8759491596035667,
            "fpr": 0.08122941822173436,
            "logloss": 0.4589465089474334,
            "mae": 0.29229865120734067,
            "precision": 0.8271028037383178,
            "recall": 0.7580299785867237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.760499438135169,
            "auditor_fn_violation": 0.022922745776144695,
            "auditor_fp_violation": 0.009213106295149641,
            "ave_precision_score": 0.7610038662800929,
            "fpr": 0.0537280701754386,
            "logloss": 1.8480363949446152,
            "mae": 0.3875124374199764,
            "precision": 0.807843137254902,
            "recall": 0.42299794661190965
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.764257951161977,
            "auditor_fn_violation": 0.012666975368856038,
            "auditor_fp_violation": 0.010821194410656541,
            "ave_precision_score": 0.764602951288345,
            "fpr": 0.05598243688254665,
            "logloss": 1.7689921937175876,
            "mae": 0.36311611804662497,
            "precision": 0.8097014925373134,
            "recall": 0.46466809421841543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8066153146558386,
            "auditor_fn_violation": 0.010501098742750101,
            "auditor_fp_violation": 0.0084391124871001,
            "ave_precision_score": 0.8073306044009272,
            "fpr": 0.12171052631578948,
            "logloss": 0.5652982364679496,
            "mae": 0.34398433010771934,
            "precision": 0.7592190889370932,
            "recall": 0.7186858316221766
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8873049872707709,
            "auditor_fn_violation": 0.009641850614779632,
            "auditor_fp_violation": 0.017506254882764218,
            "ave_precision_score": 0.8874436784508964,
            "fpr": 0.11306256860592755,
            "logloss": 0.4638496686917215,
            "mae": 0.3038220577489924,
            "precision": 0.7854166666666667,
            "recall": 0.8072805139186295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8141823863886051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7664920687231072,
            "fpr": 0.46600877192982454,
            "logloss": 7.2885921014959685,
            "mae": 0.4660021432005523,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.8112473895136824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.764122521638739,
            "fpr": 0.48737650933040616,
            "logloss": 7.472865513261066,
            "mae": 0.48736772566019637,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7977537278356752,
            "auditor_fn_violation": 0.019759357325552077,
            "auditor_fp_violation": 0.007886996904024767,
            "ave_precision_score": 0.7981675935126051,
            "fpr": 0.09539473684210527,
            "logloss": 0.601385356870515,
            "mae": 0.3489715055656505,
            "precision": 0.7716535433070866,
            "recall": 0.6036960985626283
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8762534494246721,
            "auditor_fn_violation": 0.011146186156822285,
            "auditor_fp_violation": 0.010081980993067714,
            "ave_precision_score": 0.8764048471521837,
            "fpr": 0.0801317233809001,
            "logloss": 0.46325899878834287,
            "mae": 0.2949250547622221,
            "precision": 0.8232445520581114,
            "recall": 0.728051391862955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8446628454746982,
            "auditor_fn_violation": 0.01657570517669945,
            "auditor_fp_violation": 0.014809081527347787,
            "ave_precision_score": 0.844994107112156,
            "fpr": 0.11513157894736842,
            "logloss": 0.649582872929834,
            "mae": 0.2780370468598161,
            "precision": 0.7784810126582279,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8591880519664101,
            "auditor_fn_violation": 0.004219191090572754,
            "auditor_fp_violation": 0.008603554157890058,
            "ave_precision_score": 0.8594089453912823,
            "fpr": 0.12623490669593854,
            "logloss": 0.5798792516674331,
            "mae": 0.25864621064070265,
            "precision": 0.7653061224489796,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8138473684654506,
            "auditor_fn_violation": 0.00978961778162038,
            "auditor_fp_violation": 0.013253353973168213,
            "ave_precision_score": 0.8142729423470503,
            "fpr": 0.14473684210526316,
            "logloss": 0.5994585243157624,
            "mae": 0.3189935951642774,
            "precision": 0.7421875,
            "recall": 0.7802874743326489
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8543489028418381,
            "auditor_fn_violation": 0.009735871586157291,
            "auditor_fp_violation": 0.015783071765508652,
            "ave_precision_score": 0.8546860575674557,
            "fpr": 0.15806805708013172,
            "logloss": 0.5131020948420301,
            "mae": 0.2885684734839091,
            "precision": 0.7328385899814471,
            "recall": 0.8458244111349036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7861084556429568,
            "auditor_fn_violation": 0.011194567527648693,
            "auditor_fp_violation": 0.012100103199174407,
            "ave_precision_score": 0.7855056522012972,
            "fpr": 0.17214912280701755,
            "logloss": 0.9514772834490923,
            "mae": 0.31460658292155386,
            "precision": 0.7135036496350365,
            "recall": 0.8028747433264887
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7730491176197658,
            "auditor_fn_violation": 0.01693787799368649,
            "auditor_fp_violation": 0.013543180941644178,
            "ave_precision_score": 0.7707609490686722,
            "fpr": 0.1942919868276619,
            "logloss": 1.0363371887155437,
            "mae": 0.3071523058084049,
            "precision": 0.6937716262975778,
            "recall": 0.8586723768736617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8487810059391204,
            "auditor_fn_violation": 0.014506556432148139,
            "auditor_fp_violation": 0.019638802889576885,
            "ave_precision_score": 0.8490590159661797,
            "fpr": 0.1162280701754386,
            "logloss": 0.6870367105706319,
            "mae": 0.2741550583066796,
            "precision": 0.7773109243697479,
            "recall": 0.7597535934291582
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8565718994765019,
            "auditor_fn_violation": 0.012067591676323408,
            "auditor_fp_violation": 0.018364138012875668,
            "ave_precision_score": 0.8567853555951981,
            "fpr": 0.12294182217343579,
            "logloss": 0.6172950366707204,
            "mae": 0.2594887512561954,
            "precision": 0.768595041322314,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8181607652344871,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7942445165399897,
            "fpr": 0.46600877192982454,
            "logloss": 5.89393441730366,
            "mae": 0.4659556096190946,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.8251111181471503,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8026919552049228,
            "fpr": 0.48737650933040616,
            "logloss": 5.990602973437304,
            "mae": 0.4873057424564131,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7484308689966793,
            "auditor_fn_violation": 0.01442775316113694,
            "auditor_fp_violation": 0.007378740970072239,
            "ave_precision_score": 0.7489748872384829,
            "fpr": 0.049342105263157895,
            "logloss": 2.2436151976693797,
            "mae": 0.3976527900365252,
            "precision": 0.810126582278481,
            "recall": 0.3942505133470226
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7516068719841245,
            "auditor_fn_violation": 0.011444702740946378,
            "auditor_fp_violation": 0.011703800397543538,
            "ave_precision_score": 0.7519698188013534,
            "fpr": 0.054884742041712405,
            "logloss": 2.1733993477823947,
            "mae": 0.3727361996749881,
            "precision": 0.8015873015873016,
            "recall": 0.43254817987152033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.8032355086339684,
            "auditor_fn_violation": 0.0005921502935984725,
            "auditor_fp_violation": 0.005712074303405584,
            "ave_precision_score": 0.8024143516795603,
            "fpr": 0.45614035087719296,
            "logloss": 2.103254266726952,
            "mae": 0.4332530584897062,
            "precision": 0.5388026607538803,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.8004221123608621,
            "auditor_fn_violation": 0.00052886796399937,
            "auditor_fp_violation": 0.01059127184264397,
            "ave_precision_score": 0.7969282395989412,
            "fpr": 0.4676180021953897,
            "logloss": 2.2535731450515746,
            "mae": 0.4468836372249998,
            "precision": 0.5224215246636771,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8382580770490379,
            "auditor_fn_violation": 0.020146619114521425,
            "auditor_fp_violation": 0.018802889576883388,
            "ave_precision_score": 0.8385923636903623,
            "fpr": 0.10526315789473684,
            "logloss": 0.7048646433075247,
            "mae": 0.2784916458012562,
            "precision": 0.788546255506608,
            "recall": 0.7351129363449692
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8460462431752559,
            "auditor_fn_violation": 0.009992078733161436,
            "auditor_fp_violation": 0.014072250076640862,
            "ave_precision_score": 0.8462993781576262,
            "fpr": 0.12294182217343579,
            "logloss": 0.6317127733159253,
            "mae": 0.2614059913534226,
            "precision": 0.7661795407098121,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8476799588687167,
            "auditor_fn_violation": 0.0086413415468857,
            "auditor_fp_violation": 0.00805727554179567,
            "ave_precision_score": 0.8479725755263408,
            "fpr": 0.1337719298245614,
            "logloss": 0.5144414326067247,
            "mae": 0.31197345071459975,
            "precision": 0.761252446183953,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8937826232670637,
            "auditor_fn_violation": 0.005723526632615409,
            "auditor_fp_violation": 0.01799823973259759,
            "ave_precision_score": 0.8939434005895552,
            "fpr": 0.13611416026344675,
            "logloss": 0.4396771759728587,
            "mae": 0.27911778440101953,
            "precision": 0.7660377358490567,
            "recall": 0.8693790149892934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.8032283114362719,
            "auditor_fn_violation": 0.011671890197773718,
            "auditor_fp_violation": 0.005482456140350878,
            "ave_precision_score": 0.8038472568449392,
            "fpr": 0.027412280701754384,
            "logloss": 2.5657288085487635,
            "mae": 0.3723421865765465,
            "precision": 0.8724489795918368,
            "recall": 0.351129363449692
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.8109690842019475,
            "auditor_fn_violation": 0.006966953979085032,
            "auditor_fp_violation": 0.0037380959444625744,
            "ave_precision_score": 0.8113382587692616,
            "fpr": 0.029637760702524697,
            "logloss": 2.1612263501153746,
            "mae": 0.34468351833387567,
            "precision": 0.8720379146919431,
            "recall": 0.39400428265524623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8635902928753283,
            "auditor_fn_violation": 0.011910551532836202,
            "auditor_fp_violation": 0.016909184726522194,
            "ave_precision_score": 0.8637906333365889,
            "fpr": 0.1337719298245614,
            "logloss": 0.56069491210561,
            "mae": 0.2723199367138206,
            "precision": 0.7598425196850394,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8768533620038197,
            "auditor_fn_violation": 0.004802121113114283,
            "auditor_fp_violation": 0.009918810138349107,
            "ave_precision_score": 0.8770393394002769,
            "fpr": 0.14050493962678376,
            "logloss": 0.5101746571883732,
            "mae": 0.2580677664779437,
            "precision": 0.752895752895753,
            "recall": 0.8351177730192719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8257176527028395,
            "auditor_fn_violation": 0.023807593933499054,
            "auditor_fp_violation": 0.007959236326109391,
            "ave_precision_score": 0.8259930355916241,
            "fpr": 0.10416666666666667,
            "logloss": 0.6260549242938099,
            "mae": 0.32186262921012504,
            "precision": 0.7732696897374701,
            "recall": 0.6652977412731006
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8679409791651225,
            "auditor_fn_violation": 0.0036832715537200573,
            "auditor_fp_violation": 0.01590668604938638,
            "ave_precision_score": 0.8681181053400229,
            "fpr": 0.09769484083424808,
            "logloss": 0.48825587625745237,
            "mae": 0.2754806106891964,
            "precision": 0.8008948545861297,
            "recall": 0.7665952890792291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 31658,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8318023075621993,
            "auditor_fn_violation": 0.010931139450268388,
            "auditor_fp_violation": 0.01729876160990712,
            "ave_precision_score": 0.832129368662253,
            "fpr": 0.12609649122807018,
            "logloss": 0.7099853610810899,
            "mae": 0.27587109214813643,
            "precision": 0.7648261758691206,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8264752810659439,
            "auditor_fn_violation": 0.0011682105693675002,
            "auditor_fp_violation": 0.01225017553228311,
            "ave_precision_score": 0.8269073083591705,
            "fpr": 0.13721185510428102,
            "logloss": 0.6931690500497767,
            "mae": 0.2635732288733043,
            "precision": 0.7529644268774703,
            "recall": 0.815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8499794914022849,
            "auditor_fn_violation": 0.014664162974170543,
            "auditor_fp_violation": 0.01292827657378741,
            "ave_precision_score": 0.8502856216084833,
            "fpr": 0.09539473684210527,
            "logloss": 0.6626639559666548,
            "mae": 0.27460799229849675,
            "precision": 0.8044943820224719,
            "recall": 0.7351129363449692
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8628572929702043,
            "auditor_fn_violation": 0.01043397729863646,
            "auditor_fp_violation": 0.009627080428397668,
            "ave_precision_score": 0.8630563478352113,
            "fpr": 0.1119648737650933,
            "logloss": 0.5867332011598108,
            "mae": 0.25553068903699,
            "precision": 0.7796976241900648,
            "recall": 0.7730192719486081
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 31658,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8270132520467957,
            "auditor_fn_violation": 0.012092924817176416,
            "auditor_fp_violation": 0.010294117647058829,
            "ave_precision_score": 0.8273096871614198,
            "fpr": 0.1425438596491228,
            "logloss": 0.6815623820084774,
            "mae": 0.28851258591085005,
            "precision": 0.746588693957115,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8263270534647528,
            "auditor_fn_violation": 0.007021016037627194,
            "auditor_fp_violation": 0.011216760119065283,
            "ave_precision_score": 0.8266535687916188,
            "fpr": 0.145993413830955,
            "logloss": 0.6632189153024768,
            "mae": 0.26933800174167705,
            "precision": 0.7476280834914611,
            "recall": 0.8436830835117773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8570643197133536,
            "auditor_fn_violation": 0.020164631290752553,
            "auditor_fp_violation": 0.017340041279669767,
            "ave_precision_score": 0.8574833020243064,
            "fpr": 0.1074561403508772,
            "logloss": 0.5931728925463416,
            "mae": 0.27794852455242125,
            "precision": 0.7883369330453563,
            "recall": 0.7494866529774127
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8669746111480696,
            "auditor_fn_violation": 0.014293538173689644,
            "auditor_fp_violation": 0.021627555107247756,
            "ave_precision_score": 0.8671650538054188,
            "fpr": 0.12294182217343579,
            "logloss": 0.5431776441495361,
            "mae": 0.2576650291010384,
            "precision": 0.7714285714285715,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7981969405818778,
            "auditor_fn_violation": 0.020972927699124608,
            "auditor_fp_violation": 0.012613519091847266,
            "ave_precision_score": 0.7987028597892057,
            "fpr": 0.06907894736842106,
            "logloss": 0.6785156063702873,
            "mae": 0.35695713287337605,
            "precision": 0.8037383177570093,
            "recall": 0.5297741273100616
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8623638063238652,
            "auditor_fn_violation": 0.015741461132905695,
            "auditor_fp_violation": 0.01060363327103174,
            "ave_precision_score": 0.8625524826215984,
            "fpr": 0.04720087815587267,
            "logloss": 0.5339013987998154,
            "mae": 0.3086476553491352,
            "precision": 0.8727810650887574,
            "recall": 0.6316916488222698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8356836948958704,
            "auditor_fn_violation": 0.006993227421737099,
            "auditor_fp_violation": 0.020162538699690407,
            "ave_precision_score": 0.836033921610021,
            "fpr": 0.11513157894736842,
            "logloss": 0.729654942311509,
            "mae": 0.2795404779341995,
            "precision": 0.776595744680851,
            "recall": 0.7494866529774127
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8446590489932747,
            "auditor_fn_violation": 0.0124342734646963,
            "auditor_fp_violation": 0.005238773350738229,
            "ave_precision_score": 0.8449169586291357,
            "fpr": 0.132821075740944,
            "logloss": 0.670301827593896,
            "mae": 0.2661925381409996,
            "precision": 0.753061224489796,
            "recall": 0.7901498929336188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7182061412412746,
            "auditor_fn_violation": 0.021821751504016707,
            "auditor_fp_violation": 0.007915376676986587,
            "ave_precision_score": 0.7169404673178577,
            "fpr": 0.06798245614035088,
            "logloss": 6.299289721954227,
            "mae": 0.40888292827523187,
            "precision": 0.7587548638132295,
            "recall": 0.4004106776180698
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6934666910946796,
            "auditor_fn_violation": 0.019546959949416718,
            "auditor_fp_violation": 0.013812660080497623,
            "ave_precision_score": 0.6917872500020615,
            "fpr": 0.0801317233809001,
            "logloss": 6.1716383119356495,
            "mae": 0.3952064923632852,
            "precision": 0.7265917602996255,
            "recall": 0.41541755888650966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6665231192004479,
            "auditor_fn_violation": 0.019252764869051486,
            "auditor_fp_violation": 0.008833849329205373,
            "ave_precision_score": 0.664299677487397,
            "fpr": 0.17324561403508773,
            "logloss": 8.732639445592149,
            "mae": 0.45732539086683804,
            "precision": 0.5885416666666666,
            "recall": 0.46406570841889117
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6680956656326484,
            "auditor_fn_violation": 0.015887193638541085,
            "auditor_fp_violation": 0.0300629938390641,
            "ave_precision_score": 0.6678339996625688,
            "fpr": 0.19538968166849616,
            "logloss": 8.523263523877537,
            "mae": 0.4696989493027902,
            "precision": 0.5412371134020618,
            "recall": 0.44967880085653106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8013012283036663,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6541192090248116,
            "fpr": 0.46600877192982454,
            "logloss": 11.450761763080408,
            "mae": 0.4660082537876932,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7946189792398815,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6394374827068803,
            "fpr": 0.48737650933040616,
            "logloss": 11.882219960411637,
            "mae": 0.4873756070168429,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8256018553628054,
            "auditor_fn_violation": 0.02170692388054325,
            "auditor_fp_violation": 0.017497420020639837,
            "ave_precision_score": 0.8259478990382307,
            "fpr": 0.10307017543859649,
            "logloss": 0.7754177700170276,
            "mae": 0.2915906108639106,
            "precision": 0.7793427230046949,
            "recall": 0.6817248459958932
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.837252134165007,
            "auditor_fn_violation": 0.010520946697160805,
            "auditor_fp_violation": 0.014818880351262347,
            "ave_precision_score": 0.8375692838888058,
            "fpr": 0.10867178924259056,
            "logloss": 0.6705516062289628,
            "mae": 0.26866465342821955,
            "precision": 0.7775280898876404,
            "recall": 0.7408993576017131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7886754211242892,
            "auditor_fn_violation": 0.0020061061277423537,
            "auditor_fp_violation": 0.010113519091847278,
            "ave_precision_score": 0.7867393468784257,
            "fpr": 0.44846491228070173,
            "logloss": 2.1107608972966645,
            "mae": 0.4274938524815074,
            "precision": 0.541993281075028,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.782882862108937,
            "auditor_fn_violation": 0.00052886796399937,
            "auditor_fp_violation": 0.014339256929816765,
            "ave_precision_score": 0.7764822140045944,
            "fpr": 0.45993413830954993,
            "logloss": 2.3221453257844775,
            "mae": 0.4434686442581542,
            "precision": 0.5265536723163842,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7238878253600405,
            "auditor_fn_violation": 0.010125094563925218,
            "auditor_fp_violation": 0.012030443756449955,
            "ave_precision_score": 0.725532659887021,
            "fpr": 0.20614035087719298,
            "logloss": 0.7308382879570001,
            "mae": 0.3678142983209048,
            "precision": 0.6797274275979557,
            "recall": 0.8193018480492813
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7608611809754116,
            "auditor_fn_violation": 0.013499060965548369,
            "auditor_fp_violation": 0.019464305139387475,
            "ave_precision_score": 0.7621211307071484,
            "fpr": 0.22502744237102085,
            "logloss": 0.6904659123001337,
            "mae": 0.3461152630337769,
            "precision": 0.6661237785016286,
            "recall": 0.8758029978586723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 31658,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8326664834156452,
            "auditor_fn_violation": 0.011336413415468862,
            "auditor_fp_violation": 0.019344685242518058,
            "ave_precision_score": 0.8329605841316653,
            "fpr": 0.1337719298245614,
            "logloss": 0.6622272889259203,
            "mae": 0.2839267780948655,
            "precision": 0.757455268389662,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8309961756031415,
            "auditor_fn_violation": 0.007232563223226941,
            "auditor_fp_violation": 0.012210618961442234,
            "ave_precision_score": 0.8313694684076675,
            "fpr": 0.1437980241492865,
            "logloss": 0.6419745550565618,
            "mae": 0.26706044425222814,
            "precision": 0.7495219885277247,
            "recall": 0.8394004282655246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7734904843911963,
            "auditor_fn_violation": 0.004966857595734716,
            "auditor_fp_violation": 0.01044891640866875,
            "ave_precision_score": 0.7740034953599145,
            "fpr": 0.41118421052631576,
            "logloss": 1.8328196336015006,
            "mae": 0.41660265892053433,
            "precision": 0.5588235294117647,
            "recall": 0.9753593429158111
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.8127968822749572,
            "auditor_fn_violation": 0.0005993836925326201,
            "auditor_fp_violation": 0.015189723202895543,
            "ave_precision_score": 0.8130694852124487,
            "fpr": 0.42151481888035125,
            "logloss": 1.8113449334997647,
            "mae": 0.4254525129252901,
            "precision": 0.5434007134363853,
            "recall": 0.9785867237687366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8272540555788468,
            "auditor_fn_violation": 0.013142134082639867,
            "auditor_fp_violation": 0.01759029927760578,
            "ave_precision_score": 0.8276291126195109,
            "fpr": 0.14035087719298245,
            "logloss": 0.7204896088071849,
            "mae": 0.28269096351077516,
            "precision": 0.747534516765286,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8164136420306964,
            "auditor_fn_violation": 0.010121357568805724,
            "auditor_fp_violation": 0.014774379209066366,
            "ave_precision_score": 0.8167587470348163,
            "fpr": 0.14818880351262348,
            "logloss": 0.7249430477163384,
            "mae": 0.27196878188521767,
            "precision": 0.7413793103448276,
            "recall": 0.828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.625437403424779,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011351909184726644,
            "ave_precision_score": 0.6058447234109641,
            "fpr": 0.46381578947368424,
            "logloss": 3.689118313016938,
            "mae": 0.4577109851923428,
            "precision": 0.5351648351648352,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6834294499136386,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0004103994224740659,
            "ave_precision_score": 0.6644535407142366,
            "fpr": 0.4862788144895719,
            "logloss": 3.4197603151237086,
            "mae": 0.472963740908092,
            "precision": 0.5131868131868131,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8427205112304865,
            "auditor_fn_violation": 0.014553838394754855,
            "auditor_fp_violation": 0.020415376676986587,
            "ave_precision_score": 0.842975964751756,
            "fpr": 0.1162280701754386,
            "logloss": 0.6886620241398774,
            "mae": 0.2709012317031681,
            "precision": 0.7791666666666667,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8441944933715524,
            "auditor_fn_violation": 0.007662709167279761,
            "auditor_fp_violation": 0.01707360488919216,
            "ave_precision_score": 0.844474814006406,
            "fpr": 0.12843029637760703,
            "logloss": 0.6439865346075994,
            "mae": 0.2558990122368905,
            "precision": 0.7636363636363637,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.833529434059347,
            "auditor_fn_violation": 0.01242389855542347,
            "auditor_fp_violation": 0.015162538699690411,
            "ave_precision_score": 0.8337904799215277,
            "fpr": 0.12280701754385964,
            "logloss": 0.7453604044777279,
            "mae": 0.2803142376800339,
            "precision": 0.7642105263157895,
            "recall": 0.7453798767967146
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8349191249529966,
            "auditor_fn_violation": 0.007300728427475756,
            "auditor_fp_violation": 0.00963449728543033,
            "ave_precision_score": 0.8351933327403629,
            "fpr": 0.1350164654226125,
            "logloss": 0.6889573180857077,
            "mae": 0.2676067780977706,
            "precision": 0.7505070993914807,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8127609613826947,
            "auditor_fn_violation": 0.014051748982312049,
            "auditor_fp_violation": 0.020214138286893703,
            "ave_precision_score": 0.8132570845118573,
            "fpr": 0.14802631578947367,
            "logloss": 0.7573330799508067,
            "mae": 0.2859326666223416,
            "precision": 0.7383720930232558,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8201529663191786,
            "auditor_fn_violation": 0.0047480590545721235,
            "auditor_fp_violation": 0.015046330633597378,
            "ave_precision_score": 0.820556736997156,
            "fpr": 0.145993413830955,
            "logloss": 0.711711157364238,
            "mae": 0.2673145080611169,
            "precision": 0.7432432432432432,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7718736075332052,
            "auditor_fn_violation": 0.01479024820778847,
            "auditor_fp_violation": 0.0012125902992776137,
            "ave_precision_score": 0.7725934466012555,
            "fpr": 0.14364035087719298,
            "logloss": 0.6330917225300472,
            "mae": 0.3524167475795063,
            "precision": 0.7253668763102725,
            "recall": 0.7104722792607803
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8402665254916241,
            "auditor_fn_violation": 0.013090069740055525,
            "auditor_fp_violation": 0.007352577605047417,
            "ave_precision_score": 0.840641416247134,
            "fpr": 0.1437980241492865,
            "logloss": 0.5140850263768302,
            "mae": 0.3099510739245641,
            "precision": 0.7405940594059406,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.859705754186364,
            "auditor_fn_violation": 0.008513004791238876,
            "auditor_fp_violation": 0.018472652218782255,
            "ave_precision_score": 0.8599303458084413,
            "fpr": 0.1337719298245614,
            "logloss": 0.598771140923953,
            "mae": 0.2638581600318466,
            "precision": 0.7631067961165049,
            "recall": 0.8069815195071869
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8718901564276504,
            "auditor_fn_violation": 0.0041016648763506705,
            "auditor_fp_violation": 0.018408639155071654,
            "ave_precision_score": 0.8720883429495888,
            "fpr": 0.14709110867178923,
            "logloss": 0.5732624119404633,
            "mae": 0.256780296167235,
            "precision": 0.7462121212121212,
            "recall": 0.8436830835117773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.84904764572818,
            "auditor_fn_violation": 0.021117025108973664,
            "auditor_fp_violation": 0.02005417956656348,
            "ave_precision_score": 0.8493169885932148,
            "fpr": 0.11293859649122807,
            "logloss": 0.6722206657613504,
            "mae": 0.2720083673028345,
            "precision": 0.7803837953091685,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8555368037002701,
            "auditor_fn_violation": 0.007888359498586163,
            "auditor_fp_violation": 0.016272584329664466,
            "ave_precision_score": 0.8557546713813463,
            "fpr": 0.1163556531284303,
            "logloss": 0.6128076418591607,
            "mae": 0.25688713513376693,
            "precision": 0.7800829875518672,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8047091507170605,
            "auditor_fn_violation": 0.01276838142584387,
            "auditor_fp_violation": 0.019233746130030965,
            "ave_precision_score": 0.7731920898348793,
            "fpr": 0.14473684210526316,
            "logloss": 2.0779446764057545,
            "mae": 0.30080322131081566,
            "precision": 0.7480916030534351,
            "recall": 0.8049281314168378
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.7993182304409444,
            "auditor_fn_violation": 0.006708396307796455,
            "auditor_fp_violation": 0.015182306345862888,
            "ave_precision_score": 0.7617802070612951,
            "fpr": 0.15477497255762898,
            "logloss": 2.3109955220586587,
            "mae": 0.289011864226749,
            "precision": 0.7417582417582418,
            "recall": 0.867237687366167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8478533955276677,
            "auditor_fn_violation": 0.01369375697971829,
            "auditor_fp_violation": 0.01818885448916409,
            "ave_precision_score": 0.8480951903738776,
            "fpr": 0.11293859649122807,
            "logloss": 0.6620729122385979,
            "mae": 0.2709350405602173,
            "precision": 0.7849686847599165,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8509515727151254,
            "auditor_fn_violation": 0.009623046420504097,
            "auditor_fp_violation": 0.012623490669593859,
            "ave_precision_score": 0.8512417630086986,
            "fpr": 0.12843029637760703,
            "logloss": 0.6118722237925271,
            "mae": 0.25456643415647934,
            "precision": 0.7626774847870182,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7979914857071082,
            "auditor_fn_violation": 0.011915054576893984,
            "auditor_fp_violation": 0.021372549019607855,
            "ave_precision_score": 0.7711221490161584,
            "fpr": 0.12828947368421054,
            "logloss": 3.116575165078084,
            "mae": 0.27746643563747164,
            "precision": 0.7577639751552795,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7857911289562826,
            "auditor_fn_violation": 0.010074347083116896,
            "auditor_fp_violation": 0.021093541400895966,
            "ave_precision_score": 0.7586509745625505,
            "fpr": 0.1394072447859495,
            "logloss": 3.1663209703658297,
            "mae": 0.2751048215213237,
            "precision": 0.742914979757085,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 31658,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.74697048958871,
            "auditor_fn_violation": 0.01818104038329911,
            "auditor_fp_violation": 0.010141898864809084,
            "ave_precision_score": 0.7475184605747913,
            "fpr": 0.0537280701754386,
            "logloss": 2.254732271745399,
            "mae": 0.39737609106297916,
            "precision": 0.7983539094650206,
            "recall": 0.39835728952772076
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7507336653560417,
            "auditor_fn_violation": 0.011444702740946378,
            "auditor_fp_violation": 0.00772836502803572,
            "ave_precision_score": 0.7510971873165374,
            "fpr": 0.05598243688254665,
            "logloss": 2.186548687222778,
            "mae": 0.37284966996492475,
            "precision": 0.7984189723320159,
            "recall": 0.43254817987152033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7236928677745169,
            "auditor_fn_violation": 0.011784466299218274,
            "auditor_fp_violation": 0.008697110423116616,
            "ave_precision_score": 0.7217075833985942,
            "fpr": 0.20614035087719298,
            "logloss": 1.1698766905696227,
            "mae": 0.33615173375897267,
            "precision": 0.6684303350970018,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7141152769672179,
            "auditor_fn_violation": 0.001896873097544411,
            "auditor_fp_violation": 0.012435596958099713,
            "ave_precision_score": 0.71212606564165,
            "fpr": 0.21844127332601537,
            "logloss": 1.2178523989660326,
            "mae": 0.3294530131462573,
            "precision": 0.6598290598290598,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8233811236026367,
            "auditor_fn_violation": 0.013720775244064991,
            "auditor_fp_violation": 0.013139834881320952,
            "ave_precision_score": 0.8237210992061861,
            "fpr": 0.14364035087719298,
            "logloss": 0.7333853533390796,
            "mae": 0.28537081973371914,
            "precision": 0.745136186770428,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8158466134508966,
            "auditor_fn_violation": 0.010755999125604968,
            "auditor_fp_violation": 0.01285588552328399,
            "ave_precision_score": 0.8158701708789106,
            "fpr": 0.150384193194292,
            "logloss": 0.7280211313539597,
            "mae": 0.2725066171854767,
            "precision": 0.7375478927203065,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 31658,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5910912777737416,
            "auditor_fn_violation": 0.016161425123383408,
            "auditor_fp_violation": 0.019189886480908157,
            "ave_precision_score": 0.588511204871689,
            "fpr": 0.07236842105263158,
            "logloss": 7.005310476016202,
            "mae": 0.4654339993060199,
            "precision": 0.6748768472906403,
            "recall": 0.2813141683778234
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6020409242699774,
            "auditor_fn_violation": 0.013656546092605963,
            "auditor_fp_violation": 0.019486555710485458,
            "ave_precision_score": 0.5984097294869424,
            "fpr": 0.06366630076838639,
            "logloss": 6.811694999752705,
            "mae": 0.43180133404686305,
            "precision": 0.7184466019417476,
            "recall": 0.3169164882226981
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.8133236182600969,
            "auditor_fn_violation": 0.002854929932634461,
            "auditor_fp_violation": 0.012474200206398367,
            "ave_precision_score": 0.8094565405182242,
            "fpr": 0.4276315789473684,
            "logloss": 1.9786598972240115,
            "mae": 0.4044132075939715,
            "precision": 0.5532646048109966,
            "recall": 0.9917864476386037
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7993603171228034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.013750852938558768,
            "ave_precision_score": 0.7911878597169424,
            "fpr": 0.4500548847420417,
            "logloss": 2.272421989417919,
            "mae": 0.420855346899559,
            "precision": 0.5324971493728621,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8576485791739787,
            "auditor_fn_violation": 0.02167315105010988,
            "auditor_fp_violation": 0.016609907120743037,
            "ave_precision_score": 0.8580163365607393,
            "fpr": 0.10307017543859649,
            "logloss": 0.5932167322463836,
            "mae": 0.2783246233482698,
            "precision": 0.7943107221006565,
            "recall": 0.7453798767967146
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8664778634118149,
            "auditor_fn_violation": 0.015170283731786378,
            "auditor_fp_violation": 0.02277716794731065,
            "ave_precision_score": 0.8666787901596054,
            "fpr": 0.12184412733260154,
            "logloss": 0.5408449016613803,
            "mae": 0.25748328453519564,
            "precision": 0.7711340206185567,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6728874438838117,
            "auditor_fn_violation": 0.011111261212579708,
            "auditor_fp_violation": 0.008263673890608884,
            "ave_precision_score": 0.5902932678398191,
            "fpr": 0.24780701754385964,
            "logloss": 6.2446605115508245,
            "mae": 0.3384699002160952,
            "precision": 0.6485225505443235,
            "recall": 0.8562628336755647
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6699257192442765,
            "auditor_fn_violation": 0.007439409360257804,
            "auditor_fp_violation": 0.014176086075098147,
            "ave_precision_score": 0.5740932166603658,
            "fpr": 0.265642151481888,
            "logloss": 6.879749465384481,
            "mae": 0.34105546086526006,
            "precision": 0.6310975609756098,
            "recall": 0.8865096359743041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8134153624721399,
            "auditor_fn_violation": 0.005808926834540152,
            "auditor_fp_violation": 0.018485552115583073,
            "ave_precision_score": 0.8137640507904937,
            "fpr": 0.15350877192982457,
            "logloss": 0.7653144130928033,
            "mae": 0.2957043052507256,
            "precision": 0.7297297297297297,
            "recall": 0.7761806981519507
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8096821203206779,
            "auditor_fn_violation": 0.010640823435667326,
            "auditor_fp_violation": 0.017340611742368058,
            "ave_precision_score": 0.8098599646966699,
            "fpr": 0.150384193194292,
            "logloss": 0.7522879204400825,
            "mae": 0.2742747901142733,
            "precision": 0.7400379506641366,
            "recall": 0.8351177730192719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7460463073639683,
            "auditor_fn_violation": 0.006939190893043702,
            "auditor_fp_violation": 0.008862229102167185,
            "ave_precision_score": 0.7476714523046313,
            "fpr": 0.12828947368421054,
            "logloss": 0.6296884878001889,
            "mae": 0.3639496186237043,
            "precision": 0.7411504424778761,
            "recall": 0.6878850102669405
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8668077583461097,
            "auditor_fn_violation": 0.008123411927030326,
            "auditor_fp_violation": 0.01516005577476489,
            "ave_precision_score": 0.8670770875704585,
            "fpr": 0.09549945115257959,
            "logloss": 0.4593910213166477,
            "mae": 0.30290530796896803,
            "precision": 0.8112798264642083,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6989907198831129,
            "auditor_fn_violation": 0.004471522749378581,
            "auditor_fp_violation": 0.010392156862745111,
            "ave_precision_score": 0.6992438665051852,
            "fpr": 0.39035087719298245,
            "logloss": 3.227883160987736,
            "mae": 0.4249871072947097,
            "precision": 0.5615763546798029,
            "recall": 0.9363449691991786
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.711655027268436,
            "auditor_fn_violation": 0.0028394333356055066,
            "auditor_fp_violation": 0.017192274601714783,
            "ave_precision_score": 0.7118751087141546,
            "fpr": 0.40285400658616904,
            "logloss": 3.245287221336962,
            "mae": 0.4379290238318083,
            "precision": 0.5406758448060075,
            "recall": 0.9250535331905781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8427127328451359,
            "auditor_fn_violation": 0.014898321265175265,
            "auditor_fp_violation": 0.01665376676986584,
            "ave_precision_score": 0.8431627010874412,
            "fpr": 0.12609649122807018,
            "logloss": 0.7086690180768025,
            "mae": 0.27460685790512424,
            "precision": 0.7628865979381443,
            "recall": 0.7597535934291582
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.843106249032926,
            "auditor_fn_violation": 0.004440140373310271,
            "auditor_fp_violation": 0.009018898151719228,
            "ave_precision_score": 0.8434300750873677,
            "fpr": 0.12952799121844127,
            "logloss": 0.6715224407616582,
            "mae": 0.2634691376420277,
            "precision": 0.7591836734693878,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.5878788438297673,
            "auditor_fn_violation": 0.00833738607298534,
            "auditor_fp_violation": 0.044032507739938075,
            "ave_precision_score": 0.5761601806595786,
            "fpr": 0.24342105263157895,
            "logloss": 3.293167321523785,
            "mae": 0.36828407305554783,
            "precision": 0.6413570274636511,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6003434610184357,
            "auditor_fn_violation": 0.015186737401777468,
            "auditor_fp_violation": 0.026789687601981783,
            "ave_precision_score": 0.5898177324471199,
            "fpr": 0.23600439077936333,
            "logloss": 2.993914255427042,
            "mae": 0.3420764065238225,
            "precision": 0.6521035598705501,
            "recall": 0.8629550321199143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.8141805615287335,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7505355275251229,
            "fpr": 0.46600877192982454,
            "logloss": 7.9292574593979905,
            "mae": 0.46600359776302386,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.8067650102475101,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7448850195017439,
            "fpr": 0.48737650933040616,
            "logloss": 8.067670045657305,
            "mae": 0.48737019195776476,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8446310515955109,
            "auditor_fn_violation": 0.013175906913073238,
            "auditor_fp_violation": 0.019035087719298252,
            "ave_precision_score": 0.8449180784425429,
            "fpr": 0.13048245614035087,
            "logloss": 0.7019575370250744,
            "mae": 0.2700016934949589,
            "precision": 0.7638888888888888,
            "recall": 0.7905544147843943
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8491277261378976,
            "auditor_fn_violation": 0.008280897054087915,
            "auditor_fp_violation": 0.01760761859554396,
            "ave_precision_score": 0.849386207863357,
            "fpr": 0.1437980241492865,
            "logloss": 0.6733288056474532,
            "mae": 0.26081398411627216,
            "precision": 0.745136186770428,
            "recall": 0.8201284796573876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8540065117330564,
            "auditor_fn_violation": 0.01107298533808855,
            "auditor_fp_violation": 0.013684210526315794,
            "ave_precision_score": 0.854242943367653,
            "fpr": 0.1118421052631579,
            "logloss": 0.6383163850154175,
            "mae": 0.2699965302701613,
            "precision": 0.7866108786610879,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8627975728133261,
            "auditor_fn_violation": 0.005105338745807251,
            "auditor_fp_violation": 0.010798943839558553,
            "ave_precision_score": 0.8630048424427804,
            "fpr": 0.1251372118551043,
            "logloss": 0.5852826894832437,
            "mae": 0.2546671273261357,
            "precision": 0.7682926829268293,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8327592488331113,
            "auditor_fn_violation": 0.011338664937497748,
            "auditor_fp_violation": 0.02001289989680083,
            "ave_precision_score": 0.8328754913453837,
            "fpr": 0.2675438596491228,
            "logloss": 1.4007475035680084,
            "mae": 0.3133937488020574,
            "precision": 0.6524216524216524,
            "recall": 0.9404517453798767
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8230105377828074,
            "auditor_fn_violation": 0.0020731624188775315,
            "auditor_fp_violation": 0.03230041237725103,
            "ave_precision_score": 0.8228534999843398,
            "fpr": 0.2864983534577388,
            "logloss": 1.5254571120233327,
            "mae": 0.32092798758473134,
            "precision": 0.6271428571428571,
            "recall": 0.9400428265524625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8411514771291253,
            "auditor_fn_violation": 0.017293940703915853,
            "auditor_fp_violation": 0.009649122807017546,
            "ave_precision_score": 0.8415218233488315,
            "fpr": 0.10087719298245613,
            "logloss": 0.5574500148059438,
            "mae": 0.3018735378621769,
            "precision": 0.7909090909090909,
            "recall": 0.7145790554414785
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8847508191730078,
            "auditor_fn_violation": 0.011510517420910735,
            "auditor_fp_violation": 0.011095618120865106,
            "ave_precision_score": 0.8849332671348,
            "fpr": 0.09769484083424808,
            "logloss": 0.44405182562700346,
            "mae": 0.2645767741456133,
            "precision": 0.8056768558951966,
            "recall": 0.7901498929336188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.838023148803357,
            "auditor_fn_violation": 0.014664162974170546,
            "auditor_fp_violation": 0.015634674922600622,
            "ave_precision_score": 0.8383156818236241,
            "fpr": 0.11842105263157894,
            "logloss": 0.6445750735453798,
            "mae": 0.2795013971791425,
            "precision": 0.773109243697479,
            "recall": 0.75564681724846
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8358790859190702,
            "auditor_fn_violation": 0.007032768659049401,
            "auditor_fp_violation": 0.009263654433797138,
            "ave_precision_score": 0.8362727887538544,
            "fpr": 0.11745334796926454,
            "logloss": 0.6005742747371361,
            "mae": 0.2607908584309755,
            "precision": 0.7784679089026915,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.822809513281779,
            "auditor_fn_violation": 0.009467650131488885,
            "auditor_fp_violation": 0.016099071207430343,
            "ave_precision_score": 0.8231570574250607,
            "fpr": 0.12719298245614036,
            "logloss": 0.7115023817075552,
            "mae": 0.2898436868836527,
            "precision": 0.7588357588357588,
            "recall": 0.7494866529774127
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8389827485938162,
            "auditor_fn_violation": 0.01213340635628777,
            "auditor_fp_violation": 0.013469012371317535,
            "ave_precision_score": 0.8392761734261576,
            "fpr": 0.14050493962678376,
            "logloss": 0.6349783002876932,
            "mae": 0.2654197061992374,
            "precision": 0.746031746031746,
            "recall": 0.8051391862955032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8036199214084752,
            "auditor_fn_violation": 0.01289896970351958,
            "auditor_fp_violation": 0.02381836945304438,
            "ave_precision_score": 0.7725653589099798,
            "fpr": 0.15789473684210525,
            "logloss": 3.3909530785415805,
            "mae": 0.2685210336598289,
            "precision": 0.7348066298342542,
            "recall": 0.8193018480492813
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7859272608470796,
            "auditor_fn_violation": 0.004646986510341138,
            "auditor_fp_violation": 0.025407679908228755,
            "ave_precision_score": 0.7489077194083806,
            "fpr": 0.17233809001097694,
            "logloss": 3.61902571249344,
            "mae": 0.2754977096507148,
            "precision": 0.7087198515769945,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8368631753470845,
            "auditor_fn_violation": 0.016109640116718907,
            "auditor_fp_violation": 0.01982714138286894,
            "ave_precision_score": 0.8371690298796844,
            "fpr": 0.1425438596491228,
            "logloss": 0.6907830811004947,
            "mae": 0.27423598204742966,
            "precision": 0.748062015503876,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8330496398947822,
            "auditor_fn_violation": 0.006703695259227575,
            "auditor_fp_violation": 0.014566707212151786,
            "ave_precision_score": 0.8333808625179311,
            "fpr": 0.14050493962678376,
            "logloss": 0.6760509999646624,
            "mae": 0.2631355422751431,
            "precision": 0.7524177949709865,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 31658,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8521405728834779,
            "auditor_fn_violation": 0.018439965416621643,
            "auditor_fp_violation": 0.015619195046439627,
            "ave_precision_score": 0.8524463671826957,
            "fpr": 0.09649122807017543,
            "logloss": 0.6668661322413261,
            "mae": 0.2883982569282691,
            "precision": 0.7977011494252874,
            "recall": 0.7125256673511293
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8778103812476027,
            "auditor_fn_violation": 0.008095205635617027,
            "auditor_fp_violation": 0.011192037262289732,
            "ave_precision_score": 0.877958788613936,
            "fpr": 0.09989023051591657,
            "logloss": 0.5654963208019933,
            "mae": 0.2617066992741424,
            "precision": 0.796875,
            "recall": 0.7644539614561028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.853264371904717,
            "auditor_fn_violation": 0.01524730717965345,
            "auditor_fp_violation": 0.01581527347781218,
            "ave_precision_score": 0.8534860675685423,
            "fpr": 0.1206140350877193,
            "logloss": 0.6813707881645764,
            "mae": 0.2692716464829936,
            "precision": 0.772256728778468,
            "recall": 0.7659137577002053
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8524921343761644,
            "auditor_fn_violation": 0.006724849977787547,
            "auditor_fp_violation": 0.012037558964013413,
            "ave_precision_score": 0.8527216668964904,
            "fpr": 0.12843029637760703,
            "logloss": 0.6496525127067583,
            "mae": 0.25998331075673176,
            "precision": 0.7636363636363637,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6739951777303906,
            "auditor_fn_violation": 0.011052721639828523,
            "auditor_fp_violation": 0.037120743034055735,
            "ave_precision_score": 0.6579187161613678,
            "fpr": 0.1875,
            "logloss": 2.4514687187869004,
            "mae": 0.3145628858084514,
            "precision": 0.6913357400722022,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6784466014818438,
            "auditor_fn_violation": 0.02026386985617142,
            "auditor_fp_violation": 0.03648599202935098,
            "ave_precision_score": 0.6654181803343111,
            "fpr": 0.19538968166849616,
            "logloss": 2.1398470172091133,
            "mae": 0.3084949989685928,
            "precision": 0.677536231884058,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 31658,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6141957995243698,
            "auditor_fn_violation": 0.015168503908642252,
            "auditor_fp_violation": 0.022868937048503617,
            "ave_precision_score": 0.5984556979030782,
            "fpr": 0.16666666666666666,
            "logloss": 2.522548932973833,
            "mae": 0.40870070208579096,
            "precision": 0.6481481481481481,
            "recall": 0.5749486652977412
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6334189084290067,
            "auditor_fn_violation": 0.009185848903597955,
            "auditor_fp_violation": 0.023051591657519212,
            "ave_precision_score": 0.6204498648726875,
            "fpr": 0.16245883644346873,
            "logloss": 2.194205409127508,
            "mae": 0.37465540518873436,
            "precision": 0.6621004566210046,
            "recall": 0.6209850107066381
        }
    }
]