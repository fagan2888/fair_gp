[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5097511946266426,
            "auditor_fn_violation": 0.01090927636215274,
            "auditor_fp_violation": 0.01610268552931303,
            "ave_precision_score": 0.5173780684218604,
            "fpr": 0.11074561403508772,
            "logloss": 0.6986248167792307,
            "mae": 0.5009628808158532,
            "precision": 0.5097087378640777,
            "recall": 0.2219873150105708
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5658994165375791,
            "auditor_fn_violation": 0.015771661216227653,
            "auditor_fp_violation": 0.0005565057565159676,
            "ave_precision_score": 0.5693290768485892,
            "fpr": 0.10647639956092206,
            "logloss": 0.6933746821733543,
            "mae": 0.4983480798753242,
            "precision": 0.5745614035087719,
            "recall": 0.27234927234927236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 9296,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.5302156809669601,
            "auditor_fn_violation": 0.010097919216646285,
            "auditor_fp_violation": 0.017486412500499544,
            "ave_precision_score": 0.5332817306325558,
            "fpr": 0.09868421052631579,
            "logloss": 0.6957623614780354,
            "mae": 0.49612586048284646,
            "precision": 0.5238095238095238,
            "recall": 0.20930232558139536
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5802883485768551,
            "auditor_fn_violation": 0.01587663826961303,
            "auditor_fp_violation": 0.0015367727771679511,
            "ave_precision_score": 0.583328626884304,
            "fpr": 0.09440175631174534,
            "logloss": 0.6903523811988365,
            "mae": 0.4940476820739773,
            "precision": 0.5943396226415094,
            "recall": 0.26195426195426197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5295718000001404,
            "auditor_fn_violation": 0.010002874522458374,
            "auditor_fp_violation": 0.01876024057866763,
            "ave_precision_score": 0.5327291250911312,
            "fpr": 0.10526315789473684,
            "logloss": 0.693108476162208,
            "mae": 0.49580826477980927,
            "precision": 0.5126903553299492,
            "recall": 0.2135306553911205
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5818140687973916,
            "auditor_fn_violation": 0.008158542735930231,
            "auditor_fp_violation": 0.009802670206519795,
            "ave_precision_score": 0.5849583632779718,
            "fpr": 0.10098792535675083,
            "logloss": 0.6885202225817965,
            "mae": 0.49408324916655877,
            "precision": 0.5855855855855856,
            "recall": 0.2702702702702703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5209848301555073,
            "auditor_fn_violation": 0.013575164125959745,
            "auditor_fp_violation": 0.024762218758741957,
            "ave_precision_score": 0.5247026863754835,
            "fpr": 0.12609649122807018,
            "logloss": 0.6959049102175129,
            "mae": 0.5003058208119974,
            "precision": 0.4956140350877193,
            "recall": 0.23890063424947147
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5783431060283812,
            "auditor_fn_violation": 0.014493679696753251,
            "auditor_fp_violation": 0.015316672197687186,
            "ave_precision_score": 0.5820103266274502,
            "fpr": 0.12623490669593854,
            "logloss": 0.6904409779966634,
            "mae": 0.49756649215056525,
            "precision": 0.5593869731800766,
            "recall": 0.30353430353430355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6804825058112667,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.618949871171409,
            "fpr": 0.008771929824561403,
            "logloss": 0.6356034026388061,
            "mae": 0.44971442372913945,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7268249860590409,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6621567289279914,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6054909472536855,
            "mae": 0.4333455945016524,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7801781467446768,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.620162799124893,
            "fpr": 0.008771929824561403,
            "logloss": 0.6338871577705139,
            "mae": 0.44936364634256615,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8157963773209613,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6579737799035736,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6050702921150699,
            "mae": 0.43376248198204587,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5213330486651364,
            "auditor_fn_violation": 0.009193835540224776,
            "auditor_fp_violation": 0.014294349198737163,
            "ave_precision_score": 0.5246810118552743,
            "fpr": 0.0756578947368421,
            "logloss": 0.6967801742774118,
            "mae": 0.5005099872748057,
            "precision": 0.5241379310344828,
            "recall": 0.160676532769556
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5620405601518531,
            "auditor_fn_violation": 0.012841432160861385,
            "auditor_fp_violation": 0.007704286115436657,
            "ave_precision_score": 0.5648490741866995,
            "fpr": 0.07574094401756312,
            "logloss": 0.6938543737412921,
            "mae": 0.4990571248544427,
            "precision": 0.5792682926829268,
            "recall": 0.19750519750519752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7801781467446768,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.620162799124893,
            "fpr": 0.008771929824561403,
            "logloss": 0.6338871818300625,
            "mae": 0.4493636698380374,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8157963773209613,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6579737799035736,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6050703222367424,
            "mae": 0.4337625062884405,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.779725752104464,
            "auditor_fn_violation": 0.0076383479841252095,
            "auditor_fp_violation": 0.0005919554010310518,
            "ave_precision_score": 0.6635449571935135,
            "fpr": 0.025219298245614034,
            "logloss": 0.621470758109768,
            "mae": 0.43701787913839024,
            "precision": 0.8756756756756757,
            "recall": 0.34249471458773784
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8227716637674924,
            "auditor_fn_violation": 0.004479781647728957,
            "auditor_fp_violation": 0.004416307150333138,
            "ave_precision_score": 0.7052602688780685,
            "fpr": 0.01646542261251372,
            "logloss": 0.588638689736951,
            "mae": 0.42015037149943324,
            "precision": 0.9238578680203046,
            "recall": 0.3783783783783784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.511815223999531,
            "auditor_fn_violation": 0.0055589555283557775,
            "auditor_fp_violation": 0.004723154697678138,
            "ave_precision_score": 0.5152208426706194,
            "fpr": 0.05921052631578947,
            "logloss": 0.6983913274388106,
            "mae": 0.5012436478088299,
            "precision": 0.5221238938053098,
            "recall": 0.12473572938689217
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.555016161111092,
            "auditor_fn_violation": 0.0028891510779546037,
            "auditor_fp_violation": 0.003650473540448783,
            "ave_precision_score": 0.5565925137997683,
            "fpr": 0.06366630076838639,
            "logloss": 0.695793281997143,
            "mae": 0.49995482533875724,
            "precision": 0.5538461538461539,
            "recall": 0.1496881496881497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8104445504723039,
            "auditor_fn_violation": 0.03063220948777864,
            "auditor_fp_violation": 0.013727370818846663,
            "ave_precision_score": 0.7726878934020791,
            "fpr": 0.10416666666666667,
            "logloss": 2.0952145668224005,
            "mae": 0.3205349710238934,
            "precision": 0.7738095238095238,
            "recall": 0.6871035940803383
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.846886937191762,
            "auditor_fn_violation": 0.033019847509419414,
            "auditor_fp_violation": 0.01379266331401731,
            "ave_precision_score": 0.8235028405872734,
            "fpr": 0.07793633369923161,
            "logloss": 1.3749461917260957,
            "mae": 0.3059568647724606,
            "precision": 0.8207070707070707,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7876230896841758,
            "auditor_fn_violation": 0.008936519416935589,
            "auditor_fp_violation": 0.0009241497822003763,
            "ave_precision_score": 0.6475740899509159,
            "fpr": 0.007675438596491228,
            "logloss": 1.2180358349758174,
            "mae": 0.4189964762905188,
            "precision": 0.9375,
            "recall": 0.2219873150105708
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.8321518208130789,
            "auditor_fn_violation": 0.003112797843862625,
            "auditor_fp_violation": 0.0011947004314196003,
            "ave_precision_score": 0.6948662916789048,
            "fpr": 0.0021953896816684962,
            "logloss": 1.0673593725627606,
            "mae": 0.3958634768503296,
            "precision": 0.9849624060150376,
            "recall": 0.27234927234927236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.733730803211021,
            "auditor_fn_violation": 0.009931011460999254,
            "auditor_fp_violation": 0.0005120289333812909,
            "ave_precision_score": 0.7300221013538085,
            "fpr": 0.03179824561403509,
            "logloss": 0.6720698507743106,
            "mae": 0.4235098018033201,
            "precision": 0.8342857142857143,
            "recall": 0.3086680761099366
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7726909156969043,
            "auditor_fn_violation": 0.0032771097535093147,
            "auditor_fp_violation": 0.0021902841242692674,
            "ave_precision_score": 0.7685608590970471,
            "fpr": 0.01756311745334797,
            "logloss": 0.6364831076895706,
            "mae": 0.40762266937876374,
            "precision": 0.9139784946236559,
            "recall": 0.35343035343035345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7952099231575899,
            "auditor_fn_violation": 0.006859445124439014,
            "auditor_fp_violation": 0.002700015985293531,
            "ave_precision_score": 0.6783581974133664,
            "fpr": 0.01206140350877193,
            "logloss": 0.614523726288735,
            "mae": 0.4304716356360076,
            "precision": 0.9166666666666666,
            "recall": 0.2558139534883721
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8272238006635974,
            "auditor_fn_violation": 0.009007487602438198,
            "auditor_fp_violation": 0.0025629898144129888,
            "ave_precision_score": 0.7149454229475225,
            "fpr": 0.006586169045005488,
            "logloss": 0.5870732205751968,
            "mae": 0.41565260961733586,
            "precision": 0.9605263157894737,
            "recall": 0.30353430353430355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7753640653013217,
            "auditor_fn_violation": 0.008445068803085942,
            "auditor_fp_violation": 0.0034018702793430057,
            "ave_precision_score": 0.6575999561220689,
            "fpr": 0.02850877192982456,
            "logloss": 0.6216088997582532,
            "mae": 0.44136664140642734,
            "precision": 0.8594594594594595,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8028974632851077,
            "auditor_fn_violation": 0.00109997695069048,
            "auditor_fp_violation": 0.0023408980675465253,
            "ave_precision_score": 0.6925613103808199,
            "fpr": 0.029637760702524697,
            "logloss": 0.5957945407929865,
            "mae": 0.42697293207491005,
            "precision": 0.8720379146919431,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7074292317705082,
            "auditor_fn_violation": 0.008484477578724827,
            "auditor_fp_violation": 0.0321254445909763,
            "ave_precision_score": 0.6708356383227758,
            "fpr": 0.26973684210526316,
            "logloss": 3.821802418618677,
            "mae": 0.34520450429156163,
            "precision": 0.6191950464396285,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7576237498907599,
            "auditor_fn_violation": 0.010534219096238856,
            "auditor_fp_violation": 0.041980445715160956,
            "ave_precision_score": 0.7255095601585728,
            "fpr": 0.27332601536772777,
            "logloss": 3.1113891314966273,
            "mae": 0.3279731521138788,
            "precision": 0.6322008862629247,
            "recall": 0.8898128898128899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7585455243704184,
            "auditor_fn_violation": 0.014866381068951467,
            "auditor_fp_violation": 0.009161571354353996,
            "ave_precision_score": 0.7584342906959329,
            "fpr": 0.05592105263157895,
            "logloss": 0.6689177352075835,
            "mae": 0.3960286063272835,
            "precision": 0.7951807228915663,
            "recall": 0.4186046511627907
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.8014352578288568,
            "auditor_fn_violation": 0.009562040297495852,
            "auditor_fp_violation": 0.003104178898731269,
            "ave_precision_score": 0.8011449186799806,
            "fpr": 0.050493962678375415,
            "logloss": 0.6049310155590683,
            "mae": 0.3825699515828847,
            "precision": 0.8250950570342205,
            "recall": 0.45114345114345117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7745406761910804,
            "auditor_fn_violation": 0.007782074107043525,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.621076077916875,
            "fpr": 0.008771929824561403,
            "logloss": 0.6325000898124705,
            "mae": 0.44812599422508165,
            "precision": 0.9310344827586207,
            "recall": 0.22832980972515857
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.8118383634622902,
            "auditor_fn_violation": 0.0029576143736407194,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6583987914832994,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6043446352399716,
            "mae": 0.43298048657721927,
            "precision": 0.9712230215827338,
            "recall": 0.2806652806652807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7609723267721221,
            "auditor_fn_violation": 0.006769036756796861,
            "auditor_fp_violation": 0.014833852855373057,
            "ave_precision_score": 0.7603138545009835,
            "fpr": 0.09210526315789473,
            "logloss": 0.619609338215161,
            "mae": 0.3998685765811324,
            "precision": 0.7358490566037735,
            "recall": 0.49471458773784355
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.8049392228444923,
            "auditor_fn_violation": 0.013617349511970812,
            "auditor_fp_violation": 0.010453628774921501,
            "ave_precision_score": 0.8039177569387881,
            "fpr": 0.09330406147091108,
            "logloss": 0.5868910018870267,
            "mae": 0.3864614038414329,
            "precision": 0.7625698324022346,
            "recall": 0.5675675675675675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 9296,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6623061473270462,
            "auditor_fn_violation": 7.418122473202531e-05,
            "auditor_fp_violation": 0.0034018702793430057,
            "ave_precision_score": 0.6638654181640222,
            "fpr": 0.02850877192982456,
            "logloss": 0.6229621317839829,
            "mae": 0.4272637429867724,
            "precision": 0.8531073446327684,
            "recall": 0.3192389006342495
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7355437954813702,
            "auditor_fn_violation": 0.0017024539527283828,
            "auditor_fp_violation": 0.0013785004977918463,
            "ave_precision_score": 0.7356446887649377,
            "fpr": 0.02305159165751921,
            "logloss": 0.5818390239487419,
            "mae": 0.4063822243129579,
            "precision": 0.895,
            "recall": 0.37214137214137216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7146140083378166,
            "auditor_fn_violation": 0.05176922220985869,
            "auditor_fp_violation": 0.04777854373975942,
            "ave_precision_score": 0.7161611754883936,
            "fpr": 0.32894736842105265,
            "logloss": 1.1561966523602305,
            "mae": 0.4260990319729101,
            "precision": 0.5626822157434402,
            "recall": 0.8160676532769556
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7729508515719443,
            "auditor_fn_violation": 0.03883694553288407,
            "auditor_fp_violation": 0.0479258673065632,
            "ave_precision_score": 0.7727689203686243,
            "fpr": 0.3391877058177827,
            "logloss": 0.8746596226166479,
            "mae": 0.40809103480886294,
            "precision": 0.5732044198895028,
            "recall": 0.8627858627858628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7801781467446768,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.620162799124893,
            "fpr": 0.008771929824561403,
            "logloss": 0.63388717955098,
            "mae": 0.44936367124319077,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8157963773209613,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6579737799035736,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6050703214706596,
            "mae": 0.43376250838212727,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7004955136993176,
            "auditor_fn_violation": 0.025715385186009427,
            "auditor_fp_violation": 0.01558815889381769,
            "ave_precision_score": 0.6681175845383842,
            "fpr": 0.1699561403508772,
            "logloss": 3.512593672137596,
            "mae": 0.331397818458121,
            "precision": 0.6887550200803213,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7447497791505804,
            "auditor_fn_violation": 0.01198335885492856,
            "auditor_fp_violation": 0.017425267403568787,
            "ave_precision_score": 0.7149564367993354,
            "fpr": 0.14928649835345773,
            "logloss": 2.9034127733091957,
            "mae": 0.30696884824855347,
            "precision": 0.7317554240631163,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.52145449897398,
            "auditor_fn_violation": 0.010624142279589048,
            "auditor_fp_violation": 0.008494684889901294,
            "ave_precision_score": 0.524288478157005,
            "fpr": 0.11732456140350878,
            "logloss": 0.6960463651736639,
            "mae": 0.500268799432537,
            "precision": 0.5091743119266054,
            "recall": 0.2346723044397463
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5670464339674324,
            "auditor_fn_violation": 0.01672786524597722,
            "auditor_fp_violation": 0.0010568503816404213,
            "ave_precision_score": 0.5698073103744361,
            "fpr": 0.11855104281009879,
            "logloss": 0.692050915751091,
            "mae": 0.49827083709734593,
            "precision": 0.5537190082644629,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5302315548097369,
            "auditor_fn_violation": 0.0009759467378806425,
            "auditor_fp_violation": 0.0016085201614514657,
            "ave_precision_score": 0.5327494606043035,
            "fpr": 0.4682017543859649,
            "logloss": 2.494778033866176,
            "mae": 0.47868922408343406,
            "precision": 0.5207631874298541,
            "recall": 0.9809725158562368
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5742616478066167,
            "auditor_fn_violation": 0.003103669404437791,
            "auditor_fp_violation": 0.004753273938682254,
            "ave_precision_score": 0.5766930717215877,
            "fpr": 0.45334796926454446,
            "logloss": 2.41460018198908,
            "mae": 0.4615361938982973,
            "precision": 0.5354330708661418,
            "recall": 0.9896049896049897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5606924536333887,
            "auditor_fn_violation": 0.007721801861948746,
            "auditor_fp_violation": 0.026967689725452586,
            "ave_precision_score": 0.5605576231079187,
            "fpr": 0.17434210526315788,
            "logloss": 9.867706811742051,
            "mae": 0.4846036307566287,
            "precision": 0.5377906976744186,
            "recall": 0.39112050739957716
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5497453428337834,
            "auditor_fn_violation": 0.013726890785068608,
            "auditor_fp_violation": 0.013887116125903045,
            "ave_precision_score": 0.5495366770260536,
            "fpr": 0.1756311745334797,
            "logloss": 10.5877881725672,
            "mae": 0.49882052935685506,
            "precision": 0.5335276967930029,
            "recall": 0.3804573804573805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6920921825527224,
            "auditor_fn_violation": 0.010939412484700125,
            "auditor_fp_violation": 0.019197338448627265,
            "ave_precision_score": 0.6638189130558826,
            "fpr": 0.2236842105263158,
            "logloss": 3.2038173477370484,
            "mae": 0.32517345308722306,
            "precision": 0.6577181208053692,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7360907102628937,
            "auditor_fn_violation": 0.010468037910408933,
            "auditor_fp_violation": 0.030087049753656857,
            "ave_precision_score": 0.7112695642274309,
            "fpr": 0.22283205268935236,
            "logloss": 2.6336864558295328,
            "mae": 0.3123799051662476,
            "precision": 0.6683006535947712,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.722704331801116,
            "auditor_fn_violation": 0.05430065650383889,
            "auditor_fp_violation": 0.04884006713823283,
            "ave_precision_score": 0.7243816390799849,
            "fpr": 0.3256578947368421,
            "logloss": 1.185573084720177,
            "mae": 0.4208313595317159,
            "precision": 0.5625920471281296,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7833695490178438,
            "auditor_fn_violation": 0.04035911280697231,
            "auditor_fp_violation": 0.052913996885609986,
            "ave_precision_score": 0.7833952778358697,
            "fpr": 0.3336992316136114,
            "logloss": 0.8895053287117926,
            "mae": 0.4023143071602662,
            "precision": 0.5748251748251748,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.72459968434858,
            "auditor_fn_violation": 0.020096157412558883,
            "auditor_fp_violation": 0.012248731167326062,
            "ave_precision_score": 0.7250443347351447,
            "fpr": 0.08552631578947369,
            "logloss": 1.7099019312531774,
            "mae": 0.35164923823827465,
            "precision": 0.7515923566878981,
            "recall": 0.4989429175475687
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7460373805868888,
            "auditor_fn_violation": 0.009012051822150615,
            "auditor_fp_violation": 0.027263676511883186,
            "ave_precision_score": 0.7473531818391512,
            "fpr": 0.08342480790340286,
            "logloss": 1.5779854859280242,
            "mae": 0.3488324071364968,
            "precision": 0.7771260997067448,
            "recall": 0.5509355509355509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.756264981130151,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.6149168590742182,
            "fpr": 0.008771929824561403,
            "logloss": 0.6369672386192919,
            "mae": 0.4496770441662847,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8095830505225938,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6541124186002008,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6072493420022198,
            "mae": 0.43360371856605706,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5107901309558822,
            "auditor_fn_violation": 0.015007789028596875,
            "auditor_fp_violation": 0.01310544299244695,
            "ave_precision_score": 0.5152899954584141,
            "fpr": 0.08333333333333333,
            "logloss": 0.7008459993710748,
            "mae": 0.5012424421545706,
            "precision": 0.5128205128205128,
            "recall": 0.16913319238900634
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5566830798553555,
            "auditor_fn_violation": 0.012202441401124175,
            "auditor_fp_violation": 0.008745819824879384,
            "ave_precision_score": 0.5595066670666906,
            "fpr": 0.08122941822173436,
            "logloss": 0.6966079514894795,
            "mae": 0.4991140779757997,
            "precision": 0.5647058823529412,
            "recall": 0.1995841995841996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7015191767805737,
            "auditor_fn_violation": 0.023070360891658332,
            "auditor_fp_violation": 0.031613415657595026,
            "ave_precision_score": 0.6378510617868692,
            "fpr": 0.17982456140350878,
            "logloss": 6.749035437094304,
            "mae": 0.3419243319650602,
            "precision": 0.6758893280632411,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7338943127144575,
            "auditor_fn_violation": 0.01369037702736935,
            "auditor_fp_violation": 0.04350956015623005,
            "ave_precision_score": 0.6658013904330284,
            "fpr": 0.18331503841931943,
            "logloss": 6.379653572887859,
            "mae": 0.3331747304056437,
            "precision": 0.6812977099236641,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7794266049159243,
            "auditor_fn_violation": 0.013259893920848635,
            "auditor_fp_violation": 0.01784857930703753,
            "ave_precision_score": 0.7802914813486297,
            "fpr": 0.19078947368421054,
            "logloss": 0.7649729054121965,
            "mae": 0.29832219490879397,
            "precision": 0.6947368421052632,
            "recall": 0.8372093023255814
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8208570591097109,
            "auditor_fn_violation": 0.014178748536597058,
            "auditor_fp_violation": 0.02958159957113318,
            "ave_precision_score": 0.8223146517499138,
            "fpr": 0.19099890230515917,
            "logloss": 0.6940637036661353,
            "mae": 0.2907936772132948,
            "precision": 0.702054794520548,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7147688856611761,
            "auditor_fn_violation": 0.05240208078335374,
            "auditor_fp_violation": 0.050058945769891706,
            "ave_precision_score": 0.7160382985295606,
            "fpr": 0.3267543859649123,
            "logloss": 1.1445712347880577,
            "mae": 0.4247545487872604,
            "precision": 0.5636896046852123,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.773165962746506,
            "auditor_fn_violation": 0.040801842119075935,
            "auditor_fp_violation": 0.04809435070073777,
            "ave_precision_score": 0.7729889681401698,
            "fpr": 0.3402854006586169,
            "logloss": 0.8619044661119775,
            "mae": 0.40658752204001053,
            "precision": 0.5706371191135734,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.733730803211021,
            "auditor_fn_violation": 0.009931011460999254,
            "auditor_fp_violation": 0.0005120289333812909,
            "ave_precision_score": 0.7300221013538085,
            "fpr": 0.03179824561403509,
            "logloss": 0.6720698836683109,
            "mae": 0.4235098233054343,
            "precision": 0.8342857142857143,
            "recall": 0.3086680761099366
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7727242252216213,
            "auditor_fn_violation": 0.0032771097535093147,
            "auditor_fp_violation": 0.0021902841242692674,
            "ave_precision_score": 0.7686274781464812,
            "fpr": 0.01756311745334797,
            "logloss": 0.636483159639682,
            "mae": 0.40762270083313584,
            "precision": 0.9139784946236559,
            "recall": 0.35343035343035345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.701441059118425,
            "auditor_fn_violation": 0.049321241793702016,
            "auditor_fp_violation": 0.04655466970387244,
            "ave_precision_score": 0.7030159561694487,
            "fpr": 0.33114035087719296,
            "logloss": 1.1424518800912782,
            "mae": 0.4293977999910342,
            "precision": 0.5623188405797102,
            "recall": 0.8202959830866807
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7692227032763013,
            "auditor_fn_violation": 0.04014687659034531,
            "auditor_fp_violation": 0.043856738059377634,
            "ave_precision_score": 0.768980348848058,
            "fpr": 0.3468715697036224,
            "logloss": 0.8581940231799159,
            "mae": 0.41049591464440444,
            "precision": 0.5665294924554184,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7878115908520197,
            "auditor_fn_violation": 0.0006189495938577946,
            "auditor_fp_violation": 0.0035067737681333264,
            "ave_precision_score": 0.7875628600726929,
            "fpr": 0.47478070175438597,
            "logloss": 4.273304702330475,
            "mae": 0.4752099215934625,
            "precision": 0.5215469613259669,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8296877164521181,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002501723125622253,
            "ave_precision_score": 0.8293012008287944,
            "fpr": 0.4654226125137212,
            "logloss": 4.22809286714203,
            "mae": 0.4649697964686055,
            "precision": 0.5314917127071823,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6944004004429805,
            "auditor_fn_violation": 0.03030534846630319,
            "auditor_fp_violation": 0.012958078567717706,
            "ave_precision_score": 0.6633587413010856,
            "fpr": 0.13157894736842105,
            "logloss": 3.536883260200662,
            "mae": 0.34512112002681994,
            "precision": 0.7058823529411765,
            "recall": 0.6088794926004228
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7396700233588017,
            "auditor_fn_violation": 0.020922383161680644,
            "auditor_fp_violation": 0.015015444311132671,
            "ave_precision_score": 0.7118259953278347,
            "fpr": 0.11745334796926454,
            "logloss": 2.883222133296529,
            "mae": 0.3218193038915921,
            "precision": 0.7383863080684596,
            "recall": 0.6278586278586279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7700005439404013,
            "auditor_fn_violation": 0.012072994325136317,
            "auditor_fp_violation": 0.008234923870039565,
            "ave_precision_score": 0.7670879960763368,
            "fpr": 0.0581140350877193,
            "logloss": 3.3226323299938003,
            "mae": 0.37677532571948363,
            "precision": 0.7953667953667953,
            "recall": 0.4355179704016913
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.8153340267975405,
            "auditor_fn_violation": 0.012065514809751918,
            "auditor_fp_violation": 0.013205524213105967,
            "ave_precision_score": 0.8126996413887515,
            "fpr": 0.05159165751920966,
            "logloss": 3.0632807326590785,
            "mae": 0.3574071433389532,
            "precision": 0.8384879725085911,
            "recall": 0.5072765072765073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7781691610103482,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.6107873409739994,
            "fpr": 0.008771929824561403,
            "logloss": 0.6369023505082904,
            "mae": 0.44968846557955994,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8152504405546929,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6514114237590589,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6072098743996537,
            "mae": 0.4336295778547239,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7938392573012619,
            "auditor_fn_violation": 0.011032139015615151,
            "auditor_fp_violation": 0.020069036486432486,
            "ave_precision_score": 0.7947018227050222,
            "fpr": 0.18421052631578946,
            "logloss": 0.9886683820168739,
            "mae": 0.28740629269756945,
            "precision": 0.6956521739130435,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8342615981336124,
            "auditor_fn_violation": 0.013843278387735029,
            "auditor_fp_violation": 0.019952518316187176,
            "ave_precision_score": 0.8346175137424422,
            "fpr": 0.18221734357848518,
            "logloss": 0.8665890513863129,
            "mae": 0.2773043541654991,
            "precision": 0.7077464788732394,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7070592917009537,
            "auditor_fn_violation": 0.008551704313638222,
            "auditor_fp_violation": 0.03165587659353396,
            "ave_precision_score": 0.6704665883253369,
            "fpr": 0.2642543859649123,
            "logloss": 3.822932794526649,
            "mae": 0.34427611740755615,
            "precision": 0.6234375,
            "recall": 0.8435517970401691
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7563017862351592,
            "auditor_fn_violation": 0.010981512628054892,
            "auditor_fp_violation": 0.040972098128813216,
            "ave_precision_score": 0.7235851310113595,
            "fpr": 0.270032930845225,
            "logloss": 3.133594116427812,
            "mae": 0.3266445022128785,
            "precision": 0.6344725111441307,
            "recall": 0.8877338877338877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7781691610103482,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.6107873409739994,
            "fpr": 0.008771929824561403,
            "logloss": 0.6369023505082904,
            "mae": 0.44968846557955994,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8152504405546929,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6514114237590589,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6072098743996537,
            "mae": 0.4336295778547239,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 9296,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5157805050231711,
            "auditor_fn_violation": 0.00615704165275769,
            "auditor_fp_violation": 0.005235183631059428,
            "ave_precision_score": 0.5178362468255411,
            "fpr": 0.07236842105263158,
            "logloss": 0.7638825284198343,
            "mae": 0.49372029020467606,
            "precision": 0.5074626865671642,
            "recall": 0.14376321353065538
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5566721445934419,
            "auditor_fn_violation": 0.007551501514179884,
            "auditor_fp_violation": 0.00698184974344574,
            "ave_precision_score": 0.5582970682857373,
            "fpr": 0.08232711306256861,
            "logloss": 0.7243128268018337,
            "mae": 0.49318012444649834,
            "precision": 0.5664739884393064,
            "recall": 0.20374220374220375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7018297747731684,
            "auditor_fn_violation": 0.01473192759912466,
            "auditor_fp_violation": 0.025486552371817937,
            "ave_precision_score": 0.6675643699238227,
            "fpr": 0.23684210526315788,
            "logloss": 3.647325752893668,
            "mae": 0.337789270104717,
            "precision": 0.6447368421052632,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7474225815851302,
            "auditor_fn_violation": 0.006996948819122256,
            "auditor_fp_violation": 0.0362239297475302,
            "ave_precision_score": 0.7148078196584509,
            "fpr": 0.23600439077936333,
            "logloss": 3.0563705198782802,
            "mae": 0.3186813008899471,
            "precision": 0.6576433121019108,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7713867975375372,
            "auditor_fn_violation": 0.010480416156670749,
            "auditor_fp_violation": 0.022132138432641977,
            "ave_precision_score": 0.7720461740090453,
            "fpr": 0.18969298245614036,
            "logloss": 0.7606680846280061,
            "mae": 0.3005935437502462,
            "precision": 0.6959578207381371,
            "recall": 0.8372093023255814
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8167738344787006,
            "auditor_fn_violation": 0.010812636498695776,
            "auditor_fp_violation": 0.0362086130753325,
            "ave_precision_score": 0.8176772239519585,
            "fpr": 0.1877058177826564,
            "logloss": 0.7026280216978431,
            "mae": 0.2957168306731624,
            "precision": 0.7066895368782161,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7141292644776741,
            "auditor_fn_violation": 0.023561811505507957,
            "auditor_fp_violation": 0.03991827518682811,
            "ave_precision_score": 0.7137261723052797,
            "fpr": 0.16447368421052633,
            "logloss": 1.2928259377398919,
            "mae": 0.33141330226061516,
            "precision": 0.6932515337423313,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7242008636119682,
            "auditor_fn_violation": 0.017430755081688128,
            "auditor_fp_violation": 0.04729788374645802,
            "ave_precision_score": 0.7237726840404537,
            "fpr": 0.14928649835345773,
            "logloss": 1.1926044751786145,
            "mae": 0.3081083941033415,
            "precision": 0.7285429141716567,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.756264981130151,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.6149168590742182,
            "fpr": 0.008771929824561403,
            "logloss": 0.6369672351343546,
            "mae": 0.4496770458655399,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8095830505225938,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6541124186002008,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6072493403288879,
            "mae": 0.43360372115045165,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7728439597197782,
            "auditor_fn_violation": 0.010709914320685436,
            "auditor_fp_violation": 0.02183990728529753,
            "ave_precision_score": 0.7734570024740579,
            "fpr": 0.18311403508771928,
            "logloss": 0.7705676618131273,
            "mae": 0.2990639250555225,
            "precision": 0.7023172905525846,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.819063614093414,
            "auditor_fn_violation": 0.010502269558251998,
            "auditor_fp_violation": 0.03633114645291401,
            "ave_precision_score": 0.8197749293543818,
            "fpr": 0.18441273326015367,
            "logloss": 0.7093057896701785,
            "mae": 0.29387877189347766,
            "precision": 0.7083333333333334,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7986459781293694,
            "auditor_fn_violation": 0.007202533288824607,
            "auditor_fp_violation": 0.004485872996842905,
            "ave_precision_score": 0.6679093406124169,
            "fpr": 0.017543859649122806,
            "logloss": 0.6059736033212105,
            "mae": 0.4290893843822312,
            "precision": 0.9101123595505618,
            "recall": 0.34249471458773784
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8138119175981007,
            "auditor_fn_violation": 0.008998359163013392,
            "auditor_fp_violation": 0.0027825287825798376,
            "ave_precision_score": 0.6959244986534987,
            "fpr": 0.021953896816684963,
            "logloss": 0.5891216065010989,
            "mae": 0.418536006357484,
            "precision": 0.9019607843137255,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7753640653013217,
            "auditor_fn_violation": 0.008445068803085942,
            "auditor_fp_violation": 0.0034018702793430057,
            "ave_precision_score": 0.6575999561220689,
            "fpr": 0.02850877192982456,
            "logloss": 0.6216088998722474,
            "mae": 0.44136664147178334,
            "precision": 0.8594594594594595,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8028974632851077,
            "auditor_fn_violation": 0.00109997695069048,
            "auditor_fp_violation": 0.0023408980675465253,
            "ave_precision_score": 0.6925613103808199,
            "fpr": 0.029637760702524697,
            "logloss": 0.5957945406396427,
            "mae": 0.42697293200948233,
            "precision": 0.8720379146919431,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7731850354436127,
            "auditor_fn_violation": 0.009641241051889769,
            "auditor_fp_violation": 0.01987421572153619,
            "ave_precision_score": 0.7737902926068378,
            "fpr": 0.18859649122807018,
            "logloss": 0.7751196213919301,
            "mae": 0.2994574586155706,
            "precision": 0.6977152899824253,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8190582950691767,
            "auditor_fn_violation": 0.010237544814932305,
            "auditor_fp_violation": 0.033579251014729534,
            "ave_precision_score": 0.8197707824231273,
            "fpr": 0.19099890230515917,
            "logloss": 0.7154763835534435,
            "mae": 0.294744318027653,
            "precision": 0.702054794520548,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7301766074541678,
            "auditor_fn_violation": 0.020376655168576834,
            "auditor_fp_violation": 0.01878022219558007,
            "ave_precision_score": 0.7291879395465497,
            "fpr": 0.15570175438596492,
            "logloss": 1.2694384915654486,
            "mae": 0.3204713943176187,
            "precision": 0.7035490605427975,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7593710496017265,
            "auditor_fn_violation": 0.007711249204114195,
            "auditor_fp_violation": 0.03785004977918464,
            "ave_precision_score": 0.7572866155151947,
            "fpr": 0.1525795828759605,
            "logloss": 1.1360885051699081,
            "mae": 0.30177266354699,
            "precision": 0.7225548902195609,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7744974053551499,
            "auditor_fn_violation": 0.008857701865657803,
            "auditor_fp_violation": 0.023570814850337688,
            "ave_precision_score": 0.7753991785027701,
            "fpr": 0.19846491228070176,
            "logloss": 0.762781840000205,
            "mae": 0.3004902796355246,
            "precision": 0.6895368782161235,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.81361324641903,
            "auditor_fn_violation": 0.013786225641329926,
            "auditor_fp_violation": 0.0331861230949889,
            "ave_precision_score": 0.815118685507698,
            "fpr": 0.1964873765093304,
            "logloss": 0.7070786220519392,
            "mae": 0.2957724295754937,
            "precision": 0.6986531986531986,
            "recall": 0.8627858627858628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7185110874866893,
            "auditor_fn_violation": 0.016897092095990517,
            "auditor_fp_violation": 0.03455071334372378,
            "ave_precision_score": 0.7172799886579388,
            "fpr": 0.16776315789473684,
            "logloss": 1.235648517817974,
            "mae": 0.3295826141844794,
            "precision": 0.6909090909090909,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7439476829866287,
            "auditor_fn_violation": 0.010725916324160019,
            "auditor_fp_violation": 0.04125800934317005,
            "ave_precision_score": 0.7422674010857546,
            "fpr": 0.16245883644346873,
            "logloss": 1.1441631076912393,
            "mae": 0.3097631840460299,
            "precision": 0.7126213592233009,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7731884448387808,
            "auditor_fn_violation": 0.011166592485441933,
            "auditor_fp_violation": 0.02059355393038405,
            "ave_precision_score": 0.773793724691692,
            "fpr": 0.18530701754385964,
            "logloss": 0.772346767163697,
            "mae": 0.29908847551205164,
            "precision": 0.700354609929078,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8189999485899497,
            "auditor_fn_violation": 0.010237544814932305,
            "auditor_fp_violation": 0.03316059530799276,
            "ave_precision_score": 0.8197123414741496,
            "fpr": 0.18660812294182216,
            "logloss": 0.7125855200325242,
            "mae": 0.29424198376073357,
            "precision": 0.7068965517241379,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7196069017904927,
            "auditor_fn_violation": 0.03197674418604651,
            "auditor_fp_violation": 0.007970167445949724,
            "ave_precision_score": 0.6657603678558215,
            "fpr": 0.15679824561403508,
            "logloss": 6.125594896653971,
            "mae": 0.32480801685080357,
            "precision": 0.6976744186046512,
            "recall": 0.6976744186046512
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.758619336445039,
            "auditor_fn_violation": 0.018900433829083668,
            "auditor_fp_violation": 0.013733949403926185,
            "ave_precision_score": 0.7078305951521335,
            "fpr": 0.14270032930845225,
            "logloss": 5.543034740953169,
            "mae": 0.31747954889744323,
            "precision": 0.723404255319149,
            "recall": 0.7068607068607069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7297980900287411,
            "auditor_fn_violation": 0.018241626794258375,
            "auditor_fp_violation": 0.025106901650481555,
            "ave_precision_score": 0.7300786649191435,
            "fpr": 0.21052631578947367,
            "logloss": 1.193479699665772,
            "mae": 0.3194925485554179,
            "precision": 0.6683937823834197,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7443996444288581,
            "auditor_fn_violation": 0.010468037910408933,
            "auditor_fp_violation": 0.041605187246317614,
            "ave_precision_score": 0.744770531878389,
            "fpr": 0.21185510428100987,
            "logloss": 1.0835674508517736,
            "mae": 0.308901426024055,
            "precision": 0.6767169179229481,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7185078076123927,
            "auditor_fn_violation": 0.0511780905752754,
            "auditor_fp_violation": 0.04716660672181593,
            "ave_precision_score": 0.7206569323087217,
            "fpr": 0.3300438596491228,
            "logloss": 1.2106888751372649,
            "mae": 0.4209718206238089,
            "precision": 0.5612244897959183,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7806684424028192,
            "auditor_fn_violation": 0.03964481242198037,
            "auditor_fp_violation": 0.05229367166160367,
            "ave_precision_score": 0.7809190454862696,
            "fpr": 0.33479692645444564,
            "logloss": 0.9104558208054843,
            "mae": 0.4027539114012425,
            "precision": 0.5757997218358831,
            "recall": 0.8607068607068608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6942189255846968,
            "auditor_fn_violation": 0.01801676495678944,
            "auditor_fp_violation": 0.014226911241657675,
            "ave_precision_score": 0.6947801922646941,
            "fpr": 0.0712719298245614,
            "logloss": 2.2826235659183602,
            "mae": 0.38449323848158995,
            "precision": 0.7619047619047619,
            "recall": 0.4397463002114165
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7193130241506835,
            "auditor_fn_violation": 0.011914895559242446,
            "auditor_fp_violation": 0.02117785209200215,
            "ave_precision_score": 0.7207425599134718,
            "fpr": 0.07025246981339188,
            "logloss": 2.102172320609067,
            "mae": 0.38339422163159836,
            "precision": 0.7714285714285715,
            "recall": 0.4490644490644491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7744891839929279,
            "auditor_fn_violation": 0.008857701865657803,
            "auditor_fp_violation": 0.023570814850337688,
            "ave_precision_score": 0.7753871874480274,
            "fpr": 0.19846491228070176,
            "logloss": 0.762534610303742,
            "mae": 0.3004772782858852,
            "precision": 0.6895368782161235,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8136087943146059,
            "auditor_fn_violation": 0.013786225641329926,
            "auditor_fp_violation": 0.0331861230949889,
            "ave_precision_score": 0.8151142972107661,
            "fpr": 0.1964873765093304,
            "logloss": 0.7068709443321931,
            "mae": 0.29575455991390776,
            "precision": 0.6986531986531986,
            "recall": 0.8627858627858628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7805175999456966,
            "auditor_fn_violation": 0.006859445124439014,
            "auditor_fp_violation": 0.002700015985293531,
            "ave_precision_score": 0.6437507044515576,
            "fpr": 0.01206140350877193,
            "logloss": 0.6246928951234583,
            "mae": 0.43783566427596826,
            "precision": 0.9166666666666666,
            "recall": 0.2558139534883721
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8124155791303577,
            "auditor_fn_violation": 0.009007487602438198,
            "auditor_fp_violation": 0.0025629898144129888,
            "ave_precision_score": 0.6791904922533523,
            "fpr": 0.006586169045005488,
            "logloss": 0.5984882767076776,
            "mae": 0.4233860363355714,
            "precision": 0.9605263157894737,
            "recall": 0.30353430353430355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7041915762958311,
            "auditor_fn_violation": 0.009300471050777049,
            "auditor_fp_violation": 0.02903578707589018,
            "ave_precision_score": 0.6672732003019115,
            "fpr": 0.2598684210526316,
            "logloss": 3.8267436357174986,
            "mae": 0.34289054421528004,
            "precision": 0.6267716535433071,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7533756217462387,
            "auditor_fn_violation": 0.008395882160975466,
            "auditor_fp_violation": 0.04023179230592502,
            "ave_precision_score": 0.7213027030281655,
            "fpr": 0.25686059275521406,
            "logloss": 3.105734037183603,
            "mae": 0.3244800799758285,
            "precision": 0.6443768996960486,
            "recall": 0.8814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7558347647257238,
            "auditor_fn_violation": 0.007703256555765764,
            "auditor_fp_violation": 0.005177736482436158,
            "ave_precision_score": 0.7562218869714952,
            "fpr": 0.07894736842105263,
            "logloss": 0.6517812661241442,
            "mae": 0.4012980372277366,
            "precision": 0.75,
            "recall": 0.45665961945031713
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7960916459308984,
            "auditor_fn_violation": 0.007225159804742687,
            "auditor_fp_violation": 0.01350419932096087,
            "ave_precision_score": 0.7966519115303481,
            "fpr": 0.07683863885839737,
            "logloss": 0.5890474989071363,
            "mae": 0.38567979849720413,
            "precision": 0.7819314641744548,
            "recall": 0.5218295218295218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7016292156111378,
            "auditor_fn_violation": 0.02437548681428731,
            "auditor_fp_violation": 0.022022239539623553,
            "ave_precision_score": 0.6650361786452507,
            "fpr": 0.17982456140350878,
            "logloss": 3.8053269132171423,
            "mae": 0.33615448077786575,
            "precision": 0.6746031746031746,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7481724584819397,
            "auditor_fn_violation": 0.00816767117535504,
            "auditor_fp_violation": 0.01914584024710898,
            "ave_precision_score": 0.7149523942142104,
            "fpr": 0.15697036223929747,
            "logloss": 3.1493576836178008,
            "mae": 0.3097713296799506,
            "precision": 0.7223300970873786,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6637740173461043,
            "auditor_fn_violation": 0.021749007826119212,
            "auditor_fp_violation": 0.030436997961875073,
            "ave_precision_score": 0.6057803315262849,
            "fpr": 0.2741228070175439,
            "logloss": 6.906502976465014,
            "mae": 0.38172211193927963,
            "precision": 0.5980707395498392,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.677025185797558,
            "auditor_fn_violation": 0.023471499871060793,
            "auditor_fp_violation": 0.032496872846092976,
            "ave_precision_score": 0.614176516206393,
            "fpr": 0.29088913282107576,
            "logloss": 6.908310112634427,
            "mae": 0.40028792148867676,
            "precision": 0.5878693623639192,
            "recall": 0.7858627858627859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7702216339018912,
            "auditor_fn_violation": 0.011440135751641264,
            "auditor_fp_violation": 0.018120828837469537,
            "ave_precision_score": 0.7709560488652538,
            "fpr": 0.18311403508771928,
            "logloss": 0.7491757375675395,
            "mae": 0.30005616607530483,
            "precision": 0.7023172905525846,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8157296870186235,
            "auditor_fn_violation": 0.010237544814932303,
            "auditor_fp_violation": 0.03619329640313482,
            "ave_precision_score": 0.8166358625362349,
            "fpr": 0.18551042810098792,
            "logloss": 0.6910376185155358,
            "mae": 0.29475167489832454,
            "precision": 0.7086206896551724,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7762978019959217,
            "auditor_fn_violation": 0.009465060643151219,
            "auditor_fp_violation": 0.01987421572153619,
            "ave_precision_score": 0.7768945612495677,
            "fpr": 0.18859649122807018,
            "logloss": 0.7678077920205894,
            "mae": 0.29899667767517313,
            "precision": 0.6977152899824253,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8210578948796532,
            "auditor_fn_violation": 0.00963963203260679,
            "auditor_fp_violation": 0.03250963673959106,
            "ave_precision_score": 0.8217593991858414,
            "fpr": 0.18990120746432493,
            "logloss": 0.7071205631391078,
            "mae": 0.29375319017508067,
            "precision": 0.7027491408934707,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7728485915657737,
            "auditor_fn_violation": 0.010709914320685436,
            "auditor_fp_violation": 0.02183990728529753,
            "ave_precision_score": 0.7734615863368353,
            "fpr": 0.18311403508771928,
            "logloss": 0.771657567645711,
            "mae": 0.2991326469885902,
            "precision": 0.7023172905525846,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8188989460844297,
            "auditor_fn_violation": 0.010502269558251998,
            "auditor_fp_violation": 0.03419447068133664,
            "ave_precision_score": 0.8196116508222653,
            "fpr": 0.18551042810098792,
            "logloss": 0.7108418960471664,
            "mae": 0.29407324216765085,
            "precision": 0.707105719237435,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7241737739986411,
            "auditor_fn_violation": 0.022103686806869187,
            "auditor_fp_violation": 0.03524007912720298,
            "ave_precision_score": 0.7236282043328743,
            "fpr": 0.16228070175438597,
            "logloss": 1.2649136758553046,
            "mae": 0.32543006005136293,
            "precision": 0.6948453608247422,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7380404267868328,
            "auditor_fn_violation": 0.01824775041020925,
            "auditor_fp_violation": 0.04267224874275649,
            "ave_precision_score": 0.737715471855699,
            "fpr": 0.14489571899012074,
            "logloss": 1.1539323391631835,
            "mae": 0.3023211496041898,
            "precision": 0.7327935222672065,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7061952147102278,
            "auditor_fn_violation": 0.010007510849004116,
            "auditor_fp_violation": 0.031071414298845065,
            "ave_precision_score": 0.6697856607865569,
            "fpr": 0.26206140350877194,
            "logloss": 3.8073516718968357,
            "mae": 0.3404088195982853,
            "precision": 0.6271450858034321,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7535312005614644,
            "auditor_fn_violation": 0.009703531108580507,
            "auditor_fp_violation": 0.039473617032139495,
            "ave_precision_score": 0.7208831121645249,
            "fpr": 0.2623490669593853,
            "logloss": 3.1305062333545575,
            "mae": 0.3246933891536816,
            "precision": 0.6389728096676737,
            "recall": 0.8794178794178794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8148577586700706,
            "auditor_fn_violation": 0.02183014354066986,
            "auditor_fp_violation": 0.013834772009751037,
            "ave_precision_score": 0.8152361042733212,
            "fpr": 0.1611842105263158,
            "logloss": 1.1743652428885611,
            "mae": 0.2859804038066802,
            "precision": 0.7247191011235955,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8295291233991396,
            "auditor_fn_violation": 0.025388472150272373,
            "auditor_fp_violation": 0.021780307865111172,
            "ave_precision_score": 0.8300649208713208,
            "fpr": 0.15697036223929747,
            "logloss": 1.1940732584840095,
            "mae": 0.28663537099945474,
            "precision": 0.7286527514231499,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7730283250079797,
            "auditor_fn_violation": 0.0007580393902303329,
            "auditor_fp_violation": 0.005784678096151559,
            "ave_precision_score": 0.7742583706672407,
            "fpr": 0.45394736842105265,
            "logloss": 3.400589904059485,
            "mae": 0.4579681719966302,
            "precision": 0.5311438278595696,
            "recall": 0.9915433403805497
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.8112625776488853,
            "auditor_fn_violation": 0.000963050359318197,
            "auditor_fp_violation": 0.004789012840476866,
            "ave_precision_score": 0.8119016169502374,
            "fpr": 0.4478594950603732,
            "logloss": 3.415225268481395,
            "mae": 0.45038190774280173,
            "precision": 0.5400225479143179,
            "recall": 0.9958419958419958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7735604518949306,
            "auditor_fn_violation": 0.01100200289306777,
            "auditor_fp_violation": 0.02275906166326979,
            "ave_precision_score": 0.7742265794122951,
            "fpr": 0.17982456140350878,
            "logloss": 0.7560841027488597,
            "mae": 0.296191289154649,
            "precision": 0.7055655296229802,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8199834129293019,
            "auditor_fn_violation": 0.011351214424759982,
            "auditor_fp_violation": 0.03333163148086692,
            "ave_precision_score": 0.8205997792088722,
            "fpr": 0.18331503841931943,
            "logloss": 0.695911956415216,
            "mae": 0.29166047783140664,
            "precision": 0.7085514834205934,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7185737352750676,
            "auditor_fn_violation": 0.03300137235265754,
            "auditor_fp_violation": 0.007415677576629508,
            "ave_precision_score": 0.6647315237137952,
            "fpr": 0.15460526315789475,
            "logloss": 6.170732558085359,
            "mae": 0.3272261572455562,
            "precision": 0.6993603411513859,
            "recall": 0.693446088794926
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7596598364133396,
            "auditor_fn_violation": 0.021059309753052896,
            "auditor_fp_violation": 0.014356827406632121,
            "ave_precision_score": 0.7087449148054324,
            "fpr": 0.13611416026344675,
            "logloss": 5.58545145358215,
            "mae": 0.3141618202339241,
            "precision": 0.7292576419213974,
            "recall": 0.6943866943866944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7127284855895217,
            "auditor_fn_violation": 0.024034716813174584,
            "auditor_fp_violation": 0.037085880989489665,
            "ave_precision_score": 0.7122030836058126,
            "fpr": 0.16447368421052633,
            "logloss": 1.2492247412908726,
            "mae": 0.3272594453187848,
            "precision": 0.6975806451612904,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7221440339292671,
            "auditor_fn_violation": 0.019009975102181473,
            "auditor_fp_violation": 0.04439282158629669,
            "ave_precision_score": 0.7225026397168227,
            "fpr": 0.15916575192096596,
            "logloss": 1.1709570751000002,
            "mae": 0.30592028812976874,
            "precision": 0.7195357833655706,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7801781467446768,
            "auditor_fn_violation": 0.0080787990059716,
            "auditor_fp_violation": 8.991727610598264e-05,
            "ave_precision_score": 0.620162799124893,
            "fpr": 0.008771929824561403,
            "logloss": 0.6338871828078471,
            "mae": 0.4493636705242751,
            "precision": 0.9298245614035088,
            "recall": 0.22410147991543342
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.8157963773209613,
            "auditor_fn_violation": 0.002496628182687466,
            "auditor_fp_violation": 0.0023485564036453683,
            "ave_precision_score": 0.6579737799035736,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6050703228888404,
            "mae": 0.43376250677914835,
            "precision": 0.9710144927536232,
            "recall": 0.2785862785862786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7041915762958311,
            "auditor_fn_violation": 0.009300471050777049,
            "auditor_fp_violation": 0.02903578707589018,
            "ave_precision_score": 0.6672732003019115,
            "fpr": 0.2598684210526316,
            "logloss": 3.8267557449386174,
            "mae": 0.34289059747559714,
            "precision": 0.6267716535433071,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7533756217462387,
            "auditor_fn_violation": 0.008395882160975466,
            "auditor_fp_violation": 0.04023179230592502,
            "ave_precision_score": 0.7213027030281655,
            "fpr": 0.25686059275521406,
            "logloss": 3.105735176701503,
            "mae": 0.3244801251907396,
            "precision": 0.6443768996960486,
            "recall": 0.8814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7934832419619513,
            "auditor_fn_violation": 0.010216145543562925,
            "auditor_fp_violation": 0.015315909363385682,
            "ave_precision_score": 0.7943636051437174,
            "fpr": 0.18640350877192982,
            "logloss": 1.0177754768672829,
            "mae": 0.2879820249536368,
            "precision": 0.6942446043165468,
            "recall": 0.8160676532769556
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.833944871922043,
            "auditor_fn_violation": 0.013843278387735029,
            "auditor_fp_violation": 0.019837643274704518,
            "ave_precision_score": 0.8342836539552924,
            "fpr": 0.18551042810098792,
            "logloss": 0.8909327806618028,
            "mae": 0.27837275081010865,
            "precision": 0.7040280210157618,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7728924036582858,
            "auditor_fn_violation": 0.010709914320685436,
            "auditor_fp_violation": 0.02183990728529753,
            "ave_precision_score": 0.7735049485296415,
            "fpr": 0.18311403508771928,
            "logloss": 0.770594107043415,
            "mae": 0.2990623259940644,
            "precision": 0.7023172905525846,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8190164895888232,
            "auditor_fn_violation": 0.010502269558251998,
            "auditor_fp_violation": 0.03633114645291401,
            "ave_precision_score": 0.819728026164253,
            "fpr": 0.18441273326015367,
            "logloss": 0.7094017562543992,
            "mae": 0.2938689391069808,
            "precision": 0.7083333333333334,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8107314711830585,
            "auditor_fn_violation": 0.03129752234709396,
            "auditor_fp_violation": 0.01328277984254486,
            "ave_precision_score": 0.7729746089103542,
            "fpr": 0.10307017543859649,
            "logloss": 2.094518957833082,
            "mae": 0.31973885803630475,
            "precision": 0.7751196172248804,
            "recall": 0.6849894291754757
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8471060765122368,
            "auditor_fn_violation": 0.03465840238617408,
            "auditor_fp_violation": 0.01379266331401731,
            "ave_precision_score": 0.8237522425681925,
            "fpr": 0.07793633369923161,
            "logloss": 1.375070010826158,
            "mae": 0.3055387831668234,
            "precision": 0.8202531645569621,
            "recall": 0.6735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7756348573383806,
            "auditor_fn_violation": 0.006122269203664551,
            "auditor_fp_violation": 0.0034018702793430057,
            "ave_precision_score": 0.6579096426217922,
            "fpr": 0.02850877192982456,
            "logloss": 0.6209985195671285,
            "mae": 0.44087785596779566,
            "precision": 0.8594594594594595,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8028974632851077,
            "auditor_fn_violation": 0.00109997695069048,
            "auditor_fp_violation": 0.0023408980675465253,
            "ave_precision_score": 0.6925613103808199,
            "fpr": 0.029637760702524697,
            "logloss": 0.5957130200218821,
            "mae": 0.426846597903908,
            "precision": 0.8720379146919431,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.663319689881716,
            "auditor_fn_violation": 0.02181855272430548,
            "auditor_fp_violation": 0.034558206450065944,
            "ave_precision_score": 0.6058353134208729,
            "fpr": 0.2565789473684211,
            "logloss": 6.839638981265216,
            "mae": 0.37527624874610327,
            "precision": 0.6086956521739131,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6754368412150564,
            "auditor_fn_violation": 0.023325444840263727,
            "auditor_fp_violation": 0.035340668317463554,
            "ave_precision_score": 0.6129099745817137,
            "fpr": 0.2810098792535675,
            "logloss": 6.864758458513936,
            "mae": 0.3960339811306587,
            "precision": 0.5923566878980892,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7413619964699057,
            "auditor_fn_violation": 0.017075590668001933,
            "auditor_fp_violation": 0.021392818606881667,
            "ave_precision_score": 0.7370330546720345,
            "fpr": 0.15570175438596492,
            "logloss": 1.333893786321757,
            "mae": 0.3161254276066786,
            "precision": 0.7053941908713693,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.76923872837454,
            "auditor_fn_violation": 0.01616646622135097,
            "auditor_fp_violation": 0.035869093508283774,
            "ave_precision_score": 0.7669289071322634,
            "fpr": 0.145993413830955,
            "logloss": 1.1543584833426568,
            "mae": 0.29476916297980826,
            "precision": 0.7318548387096774,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.786742908228198,
            "auditor_fn_violation": 0.011273227995994216,
            "auditor_fp_violation": 0.02037875154857531,
            "ave_precision_score": 0.7872556982563913,
            "fpr": 0.18421052631578946,
            "logloss": 0.7307041866219307,
            "mae": 0.2957728760069139,
            "precision": 0.704225352112676,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8238467726461738,
            "auditor_fn_violation": 0.009856432468946193,
            "auditor_fp_violation": 0.032711306256860605,
            "ave_precision_score": 0.8245704914528913,
            "fpr": 0.18880351262349068,
            "logloss": 0.6758899205052142,
            "mae": 0.29265215175196174,
            "precision": 0.7039586919104991,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7243474714084323,
            "auditor_fn_violation": 0.022103686806869187,
            "auditor_fp_violation": 0.03338928186068817,
            "ave_precision_score": 0.7237312379671861,
            "fpr": 0.1611842105263158,
            "logloss": 1.2668632961392463,
            "mae": 0.32512634322958855,
            "precision": 0.6962809917355371,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7383590053597777,
            "auditor_fn_violation": 0.0185421425816596,
            "auditor_fp_violation": 0.042296990273913156,
            "ave_precision_score": 0.7380595281898434,
            "fpr": 0.145993413830955,
            "logloss": 1.155503793153229,
            "mae": 0.302093475719398,
            "precision": 0.7323943661971831,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6567313571980696,
            "auditor_fn_violation": 0.033233188679945104,
            "auditor_fp_violation": 0.038661931023458426,
            "ave_precision_score": 0.6021989608609815,
            "fpr": 0.2138157894736842,
            "logloss": 6.636453193070292,
            "mae": 0.3638629826847369,
            "precision": 0.6395563770794824,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6682354333331068,
            "auditor_fn_violation": 0.020981718017941953,
            "auditor_fp_violation": 0.04596533326525924,
            "ave_precision_score": 0.6101580704081331,
            "fpr": 0.2349066959385291,
            "logloss": 6.572994439920886,
            "mae": 0.38185205837562897,
            "precision": 0.6232394366197183,
            "recall": 0.735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7095675326666476,
            "auditor_fn_violation": 0.008551704313638222,
            "auditor_fp_violation": 0.03233774927067099,
            "ave_precision_score": 0.6734446232801441,
            "fpr": 0.26535087719298245,
            "logloss": 3.7818411241059513,
            "mae": 0.3434186496840304,
            "precision": 0.6224648985959438,
            "recall": 0.8435517970401691
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7577128096129727,
            "auditor_fn_violation": 0.010981512628054892,
            "auditor_fp_violation": 0.04237612641360122,
            "ave_precision_score": 0.7255389043859131,
            "fpr": 0.2722283205268935,
            "logloss": 3.1106152217550473,
            "mae": 0.3272914862284048,
            "precision": 0.6325925925925926,
            "recall": 0.8877338877338877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7713915314330635,
            "auditor_fn_violation": 0.008057935536515713,
            "auditor_fp_violation": 0.023328537745274342,
            "ave_precision_score": 0.7721052882985766,
            "fpr": 0.1875,
            "logloss": 0.7545746169724723,
            "mae": 0.29892697022130543,
            "precision": 0.6994727592267135,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8180661226130688,
            "auditor_fn_violation": 0.010812636498695776,
            "auditor_fp_violation": 0.03600439077936334,
            "ave_precision_score": 0.8189401706686037,
            "fpr": 0.18880351262349068,
            "logloss": 0.6953368231126269,
            "mae": 0.2939126849787309,
            "precision": 0.7054794520547946,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7986459781293694,
            "auditor_fn_violation": 0.007202533288824607,
            "auditor_fp_violation": 0.004485872996842905,
            "ave_precision_score": 0.6679093406124169,
            "fpr": 0.017543859649122806,
            "logloss": 0.6059736141774771,
            "mae": 0.4290893934013551,
            "precision": 0.9101123595505618,
            "recall": 0.34249471458773784
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8138119175981007,
            "auditor_fn_violation": 0.008998359163013392,
            "auditor_fp_violation": 0.0027825287825798376,
            "ave_precision_score": 0.6959244986534987,
            "fpr": 0.021953896816684963,
            "logloss": 0.589121616818138,
            "mae": 0.41853601466680335,
            "precision": 0.9019607843137255,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6959394336922888,
            "auditor_fn_violation": 0.01736072475056563,
            "auditor_fp_violation": 0.01835811053830476,
            "ave_precision_score": 0.6588662987406788,
            "fpr": 0.18311403508771928,
            "logloss": 3.91586496770668,
            "mae": 0.33852284506286373,
            "precision": 0.6769825918762089,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7456526512611852,
            "auditor_fn_violation": 0.002729403388020296,
            "auditor_fp_violation": 0.025453756413856492,
            "ave_precision_score": 0.7109068987762369,
            "fpr": 0.16575192096597147,
            "logloss": 3.2636028515033066,
            "mae": 0.3108364668830061,
            "precision": 0.7140151515151515,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7275579390430148,
            "auditor_fn_violation": 0.022555728645079934,
            "auditor_fp_violation": 0.029245594053470814,
            "ave_precision_score": 0.726954302725191,
            "fpr": 0.1524122807017544,
            "logloss": 1.2655791669719811,
            "mae": 0.3222160433890423,
            "precision": 0.707983193277311,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7449173064875088,
            "auditor_fn_violation": 0.015618759855861943,
            "auditor_fp_violation": 0.04267224874275649,
            "ave_precision_score": 0.7439138447343616,
            "fpr": 0.14489571899012074,
            "logloss": 1.1500825186452934,
            "mae": 0.3003510412894342,
            "precision": 0.7311608961303462,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7753640653013217,
            "auditor_fn_violation": 0.008445068803085942,
            "auditor_fp_violation": 0.0034018702793430057,
            "ave_precision_score": 0.6575999561220689,
            "fpr": 0.02850877192982456,
            "logloss": 0.621608900790367,
            "mae": 0.44136664212534304,
            "precision": 0.8594594594594595,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8028974632851077,
            "auditor_fn_violation": 0.00109997695069048,
            "auditor_fp_violation": 0.0023408980675465253,
            "ave_precision_score": 0.6925613103808199,
            "fpr": 0.029637760702524697,
            "logloss": 0.5957945413664026,
            "mae": 0.426972932532904,
            "precision": 0.8720379146919431,
            "recall": 0.38253638253638256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 9296,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5115421089718806,
            "auditor_fn_violation": 0.002065483476132198,
            "auditor_fp_violation": 0.005634815969308235,
            "ave_precision_score": 0.514783256793829,
            "fpr": 0.05592105263157895,
            "logloss": 0.6986501018144678,
            "mae": 0.5012652563225282,
            "precision": 0.5188679245283019,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5569650872992369,
            "auditor_fn_violation": 0.002462396534844422,
            "auditor_fp_violation": 0.0013019171368034127,
            "ave_precision_score": 0.5595753536692618,
            "fpr": 0.054884742041712405,
            "logloss": 0.6957480253554724,
            "mae": 0.49982327059254816,
            "precision": 0.5652173913043478,
            "recall": 0.13513513513513514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7175952014013187,
            "auditor_fn_violation": 0.03621202848559031,
            "auditor_fp_violation": 0.014778903408863845,
            "ave_precision_score": 0.7197747067176038,
            "fpr": 0.05921052631578947,
            "logloss": 1.2093152569850016,
            "mae": 0.40617963780407523,
            "precision": 0.7804878048780488,
            "recall": 0.4059196617336152
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7682848408038849,
            "auditor_fn_violation": 0.023526270507609703,
            "auditor_fp_violation": 0.01157429862405228,
            "ave_precision_score": 0.7698708304559989,
            "fpr": 0.048298572996706916,
            "logloss": 0.8965202276764093,
            "mae": 0.3887095067699596,
            "precision": 0.8339622641509434,
            "recall": 0.4594594594594595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7144890377467845,
            "auditor_fn_violation": 0.024245669671006272,
            "auditor_fp_violation": 0.037752767453942376,
            "ave_precision_score": 0.7139594152860385,
            "fpr": 0.16228070175438597,
            "logloss": 1.2915183648230881,
            "mae": 0.3312528230277195,
            "precision": 0.6935817805383023,
            "recall": 0.7082452431289641
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7250159822724178,
            "auditor_fn_violation": 0.018256878849634072,
            "auditor_fp_violation": 0.04649886401347868,
            "ave_precision_score": 0.7245868891901315,
            "fpr": 0.14818880351262348,
            "logloss": 1.189410188833605,
            "mae": 0.30739979816499935,
            "precision": 0.7289156626506024,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8101056126066718,
            "auditor_fn_violation": 0.03063220948777864,
            "auditor_fp_violation": 0.011841605722735089,
            "ave_precision_score": 0.7723435643953651,
            "fpr": 0.10526315789473684,
            "logloss": 2.094179968501671,
            "mae": 0.32361022796351135,
            "precision": 0.7719714964370546,
            "recall": 0.6871035940803383
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8458558951956727,
            "auditor_fn_violation": 0.03175327653922605,
            "auditor_fp_violation": 0.014137288438465272,
            "ave_precision_score": 0.8224996825829273,
            "fpr": 0.0801317233809001,
            "logloss": 1.3752516374570534,
            "mae": 0.30883385600066215,
            "precision": 0.8179551122194514,
            "recall": 0.681912681912682
        }
    }
]