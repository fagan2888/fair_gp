[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5050534853677281,
            "auditor_fn_violation": 0.0022727687201371414,
            "auditor_fp_violation": 0.0019131355069809208,
            "ave_precision_score": 0.5067389450597919,
            "fpr": 0.4682017543859649,
            "logloss": 2.083617736530755,
            "mae": 0.4800086286387548,
            "precision": 0.5244988864142539,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5646703245030755,
            "auditor_fn_violation": 0.00105824280638566,
            "auditor_fp_violation": 0.0004009844167430993,
            "ave_precision_score": 0.5666324363787507,
            "fpr": 0.47200878155872666,
            "logloss": 2.0154888343851245,
            "mae": 0.47464760293804303,
            "precision": 0.5227524972253053,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.21617483108776,
            "mae": 0.5274122807017544,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.932866338960213,
            "mae": 0.5192096597145993,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6220253208603737,
            "auditor_fn_violation": 0.02248376919429551,
            "auditor_fp_violation": 0.0200828346969512,
            "ave_precision_score": 0.6155644865648009,
            "fpr": 0.3530701754385965,
            "logloss": 0.7877762174208599,
            "mae": 0.4555377649361729,
            "precision": 0.5589041095890411,
            "recall": 0.8482328482328483
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6382924644864721,
            "auditor_fn_violation": 0.018161860093803016,
            "auditor_fp_violation": 0.011345352841225217,
            "ave_precision_score": 0.6337755059871004,
            "fpr": 0.3589462129527991,
            "logloss": 0.7901622178222166,
            "mae": 0.4584229617928274,
            "precision": 0.561662198391421,
            "recall": 0.8858350951374208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5884751914096906,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5650432268529897,
            "fpr": 0.2631578947368421,
            "logloss": 1.9664354228643683,
            "mae": 0.46338145126663494,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6122046706474177,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5845731530562182,
            "fpr": 0.27442371020856204,
            "logloss": 1.622540173797396,
            "mae": 0.4494496579457452,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5885208964999441,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5650668361356942,
            "fpr": 0.2631578947368421,
            "logloss": 1.981468480415718,
            "mae": 0.4634196895723264,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6122113942181503,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5845116256098493,
            "fpr": 0.27442371020856204,
            "logloss": 1.6210350270429785,
            "mae": 0.4493902364494412,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7607514714074779,
            "auditor_fn_violation": 0.0016527154685049422,
            "auditor_fp_violation": 0.008125737778320508,
            "ave_precision_score": 0.7625549428945257,
            "fpr": 0.42105263157894735,
            "logloss": 0.6858822983636801,
            "mae": 0.49621617924748807,
            "precision": 0.5529685681024447,
            "recall": 0.9875259875259875
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7639655825353187,
            "auditor_fn_violation": 6.730052935347415e-05,
            "auditor_fp_violation": 0.013164819632197051,
            "ave_precision_score": 0.7650315490718673,
            "fpr": 0.44017563117453345,
            "logloss": 0.6864813923553974,
            "mae": 0.49652315661491075,
            "precision": 0.5385500575373993,
            "recall": 0.9894291754756871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6426974407845537,
            "auditor_fn_violation": 0.07005461939672467,
            "auditor_fp_violation": 0.019383217324052595,
            "ave_precision_score": 0.594898011111009,
            "fpr": 0.29276315789473684,
            "logloss": 0.701710067302187,
            "mae": 0.4711992234455338,
            "precision": 0.526595744680851,
            "recall": 0.6174636174636174
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6592138394561118,
            "auditor_fn_violation": 0.06602878141948419,
            "auditor_fp_violation": 0.009728884411229582,
            "ave_precision_score": 0.6055939291709442,
            "fpr": 0.3029637760702525,
            "logloss": 0.6867649612426017,
            "mae": 0.467733525705428,
            "precision": 0.5329949238578681,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5884140022396491,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5649560837858103,
            "fpr": 0.2631578947368421,
            "logloss": 2.015508280407633,
            "mae": 0.4633663271583747,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6127950555102195,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5850016123907309,
            "fpr": 0.27442371020856204,
            "logloss": 1.633019567850778,
            "mae": 0.4491181400301598,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6426974407845537,
            "auditor_fn_violation": 0.07005461939672467,
            "auditor_fp_violation": 0.019383217324052595,
            "ave_precision_score": 0.594898011111009,
            "fpr": 0.29276315789473684,
            "logloss": 0.7061585791841593,
            "mae": 0.47195037501355247,
            "precision": 0.526595744680851,
            "recall": 0.6174636174636174
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6592138394561118,
            "auditor_fn_violation": 0.06602878141948419,
            "auditor_fp_violation": 0.009728884411229582,
            "ave_precision_score": 0.6055939291709442,
            "fpr": 0.3029637760702525,
            "logloss": 0.6923277185942911,
            "mae": 0.4689406783502895,
            "precision": 0.5329949238578681,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.768123172003839,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012923840924817921,
            "ave_precision_score": 0.769787725949284,
            "fpr": 0.47039473684210525,
            "logloss": 0.6887325298489482,
            "mae": 0.4976799476957112,
            "precision": 0.5285714285714286,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.767030492465056,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.76798572625838,
            "fpr": 0.4807903402854007,
            "logloss": 0.6891137930457529,
            "mae": 0.49787561155438553,
            "precision": 0.5192096597145993,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5907941244800274,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5687538793725144,
            "fpr": 0.2631578947368421,
            "logloss": 1.9696403318434572,
            "mae": 0.4626597213619203,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6165581056285957,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.590684654489004,
            "fpr": 0.27442371020856204,
            "logloss": 1.6185890766658095,
            "mae": 0.4479826223075935,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6046826408048293,
            "auditor_fn_violation": 0.0022727687201371414,
            "auditor_fp_violation": 0.0019131355069809208,
            "ave_precision_score": 0.6056313660119317,
            "fpr": 0.4682017543859649,
            "logloss": 2.1168488680948285,
            "mae": 0.47968426879557674,
            "precision": 0.5244988864142539,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5927461702181149,
            "auditor_fn_violation": 0.00105824280638566,
            "auditor_fp_violation": 0.0004009844167430993,
            "ave_precision_score": 0.5945538850002883,
            "fpr": 0.47200878155872666,
            "logloss": 2.076015408806436,
            "mae": 0.47485513131612905,
            "precision": 0.5227524972253053,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.594692453141549,
            "auditor_fn_violation": 0.08171253237042711,
            "auditor_fp_violation": 0.028964159238002204,
            "ave_precision_score": 0.5654244082871178,
            "fpr": 0.2850877192982456,
            "logloss": 0.7011388039333736,
            "mae": 0.488415439218714,
            "precision": 0.5246800731261426,
            "recall": 0.5966735966735967
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6124907463326297,
            "auditor_fn_violation": 0.07054952042571065,
            "auditor_fp_violation": 0.020450205253898318,
            "ave_precision_score": 0.5729778080053236,
            "fpr": 0.305159165751921,
            "logloss": 0.6910835818838987,
            "mae": 0.48766140185429946,
            "precision": 0.5190311418685121,
            "recall": 0.6342494714587738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7607514714074779,
            "auditor_fn_violation": 0.0016527154685049422,
            "auditor_fp_violation": 0.008125737778320508,
            "ave_precision_score": 0.7625549428945257,
            "fpr": 0.42105263157894735,
            "logloss": 0.6858822986034234,
            "mae": 0.4962161793782,
            "precision": 0.5529685681024447,
            "recall": 0.9875259875259875
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7639655825353187,
            "auditor_fn_violation": 6.730052935347415e-05,
            "auditor_fp_violation": 0.013164819632197051,
            "ave_precision_score": 0.7650315490718673,
            "fpr": 0.44017563117453345,
            "logloss": 0.6864813923841371,
            "mae": 0.4965231566476246,
            "precision": 0.5385500575373993,
            "recall": 0.9894291754756871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.503021313599033,
            "auditor_fn_violation": 0.0022727687201371414,
            "auditor_fp_violation": 0.0019131355069809208,
            "ave_precision_score": 0.5048446682352452,
            "fpr": 0.4682017543859649,
            "logloss": 0.7331128784234947,
            "mae": 0.4984874082239051,
            "precision": 0.5244988864142539,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5640093634304756,
            "auditor_fn_violation": 0.00105824280638566,
            "auditor_fp_violation": 0.0004009844167430993,
            "ave_precision_score": 0.5652660385750526,
            "fpr": 0.47200878155872666,
            "logloss": 0.708444889119276,
            "mae": 0.4893753912328496,
            "precision": 0.5227524972253053,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 1318,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6385515049485369,
            "auditor_fn_violation": 0.06868001604843711,
            "auditor_fp_violation": 0.017813530345585554,
            "ave_precision_score": 0.5884745264671675,
            "fpr": 0.30372807017543857,
            "logloss": 0.703723641277373,
            "mae": 0.47011475230817124,
            "precision": 0.5199306759098787,
            "recall": 0.6237006237006237
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6540062309035406,
            "auditor_fn_violation": 0.0641188388105908,
            "auditor_fp_violation": 0.009713847495601719,
            "ave_precision_score": 0.5964071755520762,
            "fpr": 0.3172338090010977,
            "logloss": 0.6898094435854626,
            "mae": 0.4670524853315261,
            "precision": 0.5262295081967213,
            "recall": 0.678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5884873994426332,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5650249093685974,
            "fpr": 0.2631578947368421,
            "logloss": 1.9835197062119156,
            "mae": 0.4634180103176709,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6122044837275378,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5845351886808097,
            "fpr": 0.27442371020856204,
            "logloss": 1.6209900381313962,
            "mae": 0.449387559374022,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7869267184233945,
            "auditor_fn_violation": 0.01024227668964511,
            "auditor_fp_violation": 0.021108092156144426,
            "ave_precision_score": 0.7865423793406494,
            "fpr": 0.2138157894736842,
            "logloss": 2.0292958581128726,
            "mae": 0.31188641667440126,
            "precision": 0.6694915254237288,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7939026605398087,
            "auditor_fn_violation": 0.012483087841115058,
            "auditor_fp_violation": 0.02792605847355257,
            "ave_precision_score": 0.7933614840021328,
            "fpr": 0.20965971459934138,
            "logloss": 1.9212331418495194,
            "mae": 0.2865752947848058,
            "precision": 0.6795302013422819,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.5736761926827941,
            "auditor_fn_violation": 0.0770826494510705,
            "auditor_fp_violation": 0.0955244840639883,
            "ave_precision_score": 0.5776888431251013,
            "fpr": 0.31030701754385964,
            "logloss": 0.6852373843080772,
            "mae": 0.49223791735998373,
            "precision": 0.5692541856925418,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5777395985329477,
            "auditor_fn_violation": 0.07652302258280867,
            "auditor_fp_violation": 0.09590544787453201,
            "ave_precision_score": 0.5801833435194713,
            "fpr": 0.31613611416026344,
            "logloss": 0.6823829419929449,
            "mae": 0.49069426361671786,
            "precision": 0.5603053435114503,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5928660175698135,
            "auditor_fn_violation": 0.05529188094977569,
            "auditor_fp_violation": 0.017167338299344657,
            "ave_precision_score": 0.569829684044426,
            "fpr": 0.2543859649122807,
            "logloss": 2.177780810316231,
            "mae": 0.4589627624922418,
            "precision": 0.5350701402805611,
            "recall": 0.5550935550935551
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6142230420255801,
            "auditor_fn_violation": 0.055102888585134006,
            "auditor_fp_violation": 0.00957099679713697,
            "ave_precision_score": 0.5873578690075674,
            "fpr": 0.2667398463227223,
            "logloss": 1.8366527368232237,
            "mae": 0.44662514646787727,
            "precision": 0.5466417910447762,
            "recall": 0.6194503171247357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7266445910007859,
            "auditor_fn_violation": 0.02374211255790204,
            "auditor_fp_violation": 0.014964179590507597,
            "ave_precision_score": 0.7270479000043395,
            "fpr": 0.10526315789473684,
            "logloss": 1.3091316084628029,
            "mae": 0.4339633770654281,
            "precision": 0.7037037037037037,
            "recall": 0.47401247401247404
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7121057707091746,
            "auditor_fn_violation": 0.007013179300213748,
            "auditor_fp_violation": 0.009508342982020867,
            "ave_precision_score": 0.7126753156366169,
            "fpr": 0.08122941822173436,
            "logloss": 1.2504379061908717,
            "mae": 0.43691300683456086,
            "precision": 0.725925925925926,
            "recall": 0.4143763213530655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7607514714074779,
            "auditor_fn_violation": 0.0016527154685049422,
            "auditor_fp_violation": 0.008125737778320508,
            "ave_precision_score": 0.7625549428945257,
            "fpr": 0.42105263157894735,
            "logloss": 0.6858822985370869,
            "mae": 0.49621617934552203,
            "precision": 0.5529685681024447,
            "recall": 0.9875259875259875
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7639655825353187,
            "auditor_fn_violation": 6.730052935347415e-05,
            "auditor_fp_violation": 0.013164819632197051,
            "ave_precision_score": 0.7650315490718673,
            "fpr": 0.44017563117453345,
            "logloss": 0.6864813923828277,
            "mae": 0.4965231566476246,
            "precision": 0.5385500575373993,
            "recall": 0.9894291754756871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.589989517461905,
            "auditor_fn_violation": 0.009898055950687544,
            "auditor_fp_violation": 0.009252757764480807,
            "ave_precision_score": 0.5559780948981484,
            "fpr": 0.10635964912280702,
            "logloss": 0.7785088021255967,
            "mae": 0.48044911974616217,
            "precision": 0.592436974789916,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5760712478637433,
            "auditor_fn_violation": 0.004715678470560663,
            "auditor_fp_violation": 0.006225283069936699,
            "ave_precision_score": 0.5447240335188136,
            "fpr": 0.09879253567508232,
            "logloss": 0.7709965468797216,
            "mae": 0.4807657405783133,
            "precision": 0.5964125560538116,
            "recall": 0.28118393234672306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6318000649041701,
            "auditor_fn_violation": 0.060644399460188944,
            "auditor_fp_violation": 0.023033947978996216,
            "ave_precision_score": 0.5823625095359606,
            "fpr": 0.2894736842105263,
            "logloss": 0.8075020828218551,
            "mae": 0.45376688667702664,
            "precision": 0.5285714285714286,
            "recall": 0.6153846153846154
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.6318136104303724,
            "auditor_fn_violation": 0.061162256934855413,
            "auditor_fp_violation": 0.010428100987925364,
            "ave_precision_score": 0.5749284736113169,
            "fpr": 0.29747530186608123,
            "logloss": 0.8087752308417046,
            "mae": 0.4582621836591795,
            "precision": 0.5295138888888888,
            "recall": 0.6448202959830867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.6083379654737039,
            "auditor_fn_violation": 0.07123317649633439,
            "auditor_fp_violation": 0.02039321040420077,
            "ave_precision_score": 0.6090486132645196,
            "fpr": 0.3201754385964912,
            "logloss": 0.7093757024408538,
            "mae": 0.4756189507640712,
            "precision": 0.5100671140939598,
            "recall": 0.632016632016632
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6344336033276027,
            "auditor_fn_violation": 0.06471526074313709,
            "auditor_fp_violation": 0.005413289626031931,
            "ave_precision_score": 0.6359986038981258,
            "fpr": 0.32930845225027444,
            "logloss": 0.6930122974037832,
            "mae": 0.47101570889822514,
            "precision": 0.5176848874598071,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6860441998851813,
            "auditor_fn_violation": 0.025884943648101556,
            "auditor_fp_violation": 0.013280009769202591,
            "ave_precision_score": 0.6864754545046331,
            "fpr": 0.09429824561403509,
            "logloss": 2.2592133806344887,
            "mae": 0.4627257328336159,
            "precision": 0.6884057971014492,
            "recall": 0.39501039501039503
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6683205917729427,
            "auditor_fn_violation": 0.015560346528104953,
            "auditor_fp_violation": 0.024028991173330537,
            "ave_precision_score": 0.668919533605587,
            "fpr": 0.09769484083424808,
            "logloss": 2.123699041185882,
            "mae": 0.4634716256805152,
            "precision": 0.6550387596899225,
            "recall": 0.3572938689217759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628575478064962,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325557216604101,
            "fpr": 0.45614035087719296,
            "logloss": 15.886224322360121,
            "mae": 0.4638157892527514,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447525660554,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716299395086,
            "fpr": 0.4654226125137212,
            "logloss": 16.20896933851577,
            "mae": 0.4731064764585947,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7867209176675384,
            "auditor_fn_violation": 0.01024227668964511,
            "auditor_fp_violation": 0.021108092156144426,
            "ave_precision_score": 0.7862963851830957,
            "fpr": 0.2138157894736842,
            "logloss": 2.0327742826379085,
            "mae": 0.31189621037863596,
            "precision": 0.6694915254237288,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7943141624085124,
            "auditor_fn_violation": 0.012483087841115058,
            "auditor_fp_violation": 0.02792605847355257,
            "ave_precision_score": 0.7936487086900816,
            "fpr": 0.20965971459934138,
            "logloss": 1.9245859101402372,
            "mae": 0.2865867581279846,
            "precision": 0.6795302013422819,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628538643008296,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325509489784519,
            "fpr": 0.45614035087719296,
            "logloss": 15.895435215722074,
            "mae": 0.4638157889067257,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582410484055766,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235679259547646,
            "fpr": 0.4654226125137212,
            "logloss": 16.202517953562356,
            "mae": 0.4731064760405122,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7001884652743476,
            "auditor_fn_violation": 0.025458657037604412,
            "auditor_fp_violation": 0.017093560467293524,
            "ave_precision_score": 0.7005495243172997,
            "fpr": 0.06578947368421052,
            "logloss": 2.215589419600863,
            "mae": 0.45574170425222765,
            "precision": 0.75,
            "recall": 0.37422037422037424
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6880728501624833,
            "auditor_fn_violation": 0.015845793600880013,
            "auditor_fp_violation": 0.01822474174097409,
            "ave_precision_score": 0.6886206565413939,
            "fpr": 0.06366630076838639,
            "logloss": 2.079779220467737,
            "mae": 0.4551789360037065,
            "precision": 0.7375565610859729,
            "recall": 0.34460887949260044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5884905759865323,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.014175520006512808,
            "ave_precision_score": 0.5650541874852351,
            "fpr": 0.26535087719298245,
            "logloss": 1.987010579717133,
            "mae": 0.4634148132100625,
            "precision": 0.5264187866927593,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.612206108559525,
            "auditor_fn_violation": 0.05639088147448497,
            "auditor_fp_violation": 0.013869048514102133,
            "ave_precision_score": 0.5845259892644878,
            "fpr": 0.27552140504939626,
            "logloss": 1.6208400013376105,
            "mae": 0.4493818520621969,
            "precision": 0.541970802919708,
            "recall": 0.627906976744186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628544305043811,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325509133251192,
            "fpr": 0.45614035087719296,
            "logloss": 15.896718554612445,
            "mae": 0.4638157888756099,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582422654976088,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235691429926034,
            "fpr": 0.4654226125137212,
            "logloss": 16.203785964870374,
            "mae": 0.47310647645107046,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6325138271620045,
            "auditor_fn_violation": 0.009898055950687544,
            "auditor_fp_violation": 0.009252757764480807,
            "ave_precision_score": 0.5588213024186242,
            "fpr": 0.10635964912280702,
            "logloss": 0.7694168371622628,
            "mae": 0.47385716340259504,
            "precision": 0.592436974789916,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6284943395725153,
            "auditor_fn_violation": 0.004715678470560663,
            "auditor_fp_violation": 0.006225283069936699,
            "ave_precision_score": 0.5534156565484634,
            "fpr": 0.09879253567508232,
            "logloss": 0.7624310048663159,
            "mae": 0.47427344937225074,
            "precision": 0.5964125560538116,
            "recall": 0.28118393234672306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5884826117923831,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.014175520006512808,
            "ave_precision_score": 0.5650607013108904,
            "fpr": 0.26535087719298245,
            "logloss": 1.9829030887277268,
            "mae": 0.4633083780058109,
            "precision": 0.5264187866927593,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6122827650251639,
            "auditor_fn_violation": 0.05639088147448497,
            "auditor_fp_violation": 0.013869048514102133,
            "ave_precision_score": 0.5846143779573476,
            "fpr": 0.27552140504939626,
            "logloss": 1.6235952520860462,
            "mae": 0.44946071479049754,
            "precision": 0.541970802919708,
            "recall": 0.627906976744186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7866790846229788,
            "auditor_fn_violation": 0.022581792318634428,
            "auditor_fp_violation": 0.024244922049904343,
            "ave_precision_score": 0.786982095892045,
            "fpr": 0.18201754385964913,
            "logloss": 1.15793143331378,
            "mae": 0.3407870318078543,
            "precision": 0.6666666666666666,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8068269469514804,
            "auditor_fn_violation": 0.023348642269837995,
            "auditor_fp_violation": 0.02090131272273431,
            "ave_precision_score": 0.8072750648021134,
            "fpr": 0.1778265642151482,
            "logloss": 1.0147124427092558,
            "mae": 0.31817534030448424,
            "precision": 0.6772908366533864,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 1318,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.6333271608638917,
            "auditor_fn_violation": 0.07123317649633439,
            "auditor_fp_violation": 0.022461533764806446,
            "ave_precision_score": 0.5814670688912515,
            "fpr": 0.31798245614035087,
            "logloss": 0.7049292081376239,
            "mae": 0.47476701753105754,
            "precision": 0.5117845117845118,
            "recall": 0.632016632016632
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6502560002658719,
            "auditor_fn_violation": 0.06531168267568341,
            "auditor_fp_violation": 0.006270393816820303,
            "ave_precision_score": 0.5911056185533452,
            "fpr": 0.32711306256860595,
            "logloss": 0.693698136410575,
            "mae": 0.4704386533643594,
            "precision": 0.5201288244766505,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628550624218593,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325521470368323,
            "fpr": 0.45614035087719296,
            "logloss": 15.897660468906766,
            "mae": 0.46381578903601184,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582398339988007,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235667116005815,
            "fpr": 0.4654226125137212,
            "logloss": 16.204660313198833,
            "mae": 0.4731064763838371,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762866104223353,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325631881237411,
            "fpr": 0.45614035087719296,
            "logloss": 15.891387891675414,
            "mae": 0.46381578502821996,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582374797592435,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235643574332719,
            "fpr": 0.4654226125137212,
            "logloss": 16.198090861051085,
            "mae": 0.4731064704662238,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628696570557573,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325667407784836,
            "fpr": 0.45614035087719296,
            "logloss": 15.907442035640315,
            "mae": 0.46381578908429955,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582386141022371,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235654917585725,
            "fpr": 0.4654226125137212,
            "logloss": 16.21261516216078,
            "mae": 0.4731064751613998,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628604791284419,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325580496880276,
            "fpr": 0.45614035087719296,
            "logloss": 15.900201432552342,
            "mae": 0.46381578931077305,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582373997212554,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235642774301773,
            "fpr": 0.4654226125137212,
            "logloss": 16.206550558414996,
            "mae": 0.47310647649899895,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672662166527,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643500678321,
            "fpr": 0.45614035087719296,
            "logloss": 15.911823218929657,
            "mae": 0.4638157884742824,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758242310191912,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523569187674665,
            "fpr": 0.4654226125137212,
            "logloss": 16.21213947300277,
            "mae": 0.47310647463314187,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628611854798375,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325582697041293,
            "fpr": 0.45614035087719296,
            "logloss": 15.902033125078653,
            "mae": 0.46381578750432867,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447695930727,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716469561165,
            "fpr": 0.4654226125137212,
            "logloss": 16.206443726370736,
            "mae": 0.47310647397088373,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762866026727231,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325631106642456,
            "fpr": 0.45614035087719296,
            "logloss": 15.90699419589139,
            "mae": 0.46381578863453127,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447501051105,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716274800023,
            "fpr": 0.4654226125137212,
            "logloss": 16.210795981252446,
            "mae": 0.4731064748914407,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672417432716,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643256083168,
            "fpr": 0.45614035087719296,
            "logloss": 15.916729168687295,
            "mae": 0.4638157890866548,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582435273910804,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235704048208907,
            "fpr": 0.4654226125137212,
            "logloss": 16.21613089908711,
            "mae": 0.47310647585876064,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7146628842914137,
            "auditor_fn_violation": 0.011176915782178947,
            "auditor_fp_violation": 0.004075589205031139,
            "ave_precision_score": 0.7150138735671043,
            "fpr": 0.039473684210526314,
            "logloss": 2.0353801142966925,
            "mae": 0.4326997541625591,
            "precision": 0.8163265306122449,
            "recall": 0.33264033264033266
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.713717503620539,
            "auditor_fn_violation": 0.02373620049059765,
            "auditor_fp_violation": 0.004385767058127703,
            "ave_precision_score": 0.7142422405041888,
            "fpr": 0.03402854006586169,
            "logloss": 1.9036307297661237,
            "mae": 0.4292038176336306,
            "precision": 0.8268156424581006,
            "recall": 0.3128964059196617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.590739810632249,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5687226200228155,
            "fpr": 0.2631578947368421,
            "logloss": 1.981504467145659,
            "mae": 0.46269025811694986,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6171328857423536,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5912089226546065,
            "fpr": 0.27442371020856204,
            "logloss": 1.6175937855254854,
            "mae": 0.4479369753407736,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6589739515119581,
            "auditor_fn_violation": 0.016711802896013428,
            "auditor_fp_violation": 0.009163715553384624,
            "ave_precision_score": 0.6591806732978657,
            "fpr": 0.044956140350877194,
            "logloss": 3.365067451261325,
            "mae": 0.45802195826662334,
            "precision": 0.7722222222222223,
            "recall": 0.288981288981289
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6876559939687169,
            "auditor_fn_violation": 0.008911518369563474,
            "auditor_fp_violation": 0.01089675152499386,
            "ave_precision_score": 0.6875181392450511,
            "fpr": 0.03512623490669594,
            "logloss": 2.701819866468065,
            "mae": 0.44127317858191123,
            "precision": 0.8095238095238095,
            "recall": 0.28752642706131076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635789469714,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606630424762,
            "fpr": 0.45614035087719296,
            "logloss": 15.893991862248381,
            "mae": 0.4638157855076948,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582472811933559,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235741584228008,
            "fpr": 0.4654226125137212,
            "logloss": 16.197028869571813,
            "mae": 0.47310646116907856,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5923787992238541,
            "auditor_fn_violation": 0.0562082831819674,
            "auditor_fp_violation": 0.012931473114340378,
            "ave_precision_score": 0.5701794782277643,
            "fpr": 0.2532894736842105,
            "logloss": 1.967468721767524,
            "mae": 0.4599420839033391,
            "precision": 0.5342741935483871,
            "recall": 0.5509355509355509
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6181614998537794,
            "auditor_fn_violation": 0.05569931051768032,
            "auditor_fp_violation": 0.010428100987925364,
            "ave_precision_score": 0.5920196750181821,
            "fpr": 0.2579582875960483,
            "logloss": 1.6153830347035196,
            "mae": 0.44435568153781685,
            "precision": 0.555765595463138,
            "recall": 0.6215644820295984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672662166527,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643500678321,
            "fpr": 0.45614035087719296,
            "logloss": 15.911699324807973,
            "mae": 0.4638157884592087,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758242310191912,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523569187674665,
            "fpr": 0.4654226125137212,
            "logloss": 16.212138278823836,
            "mae": 0.4731064746143758,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.786020329725552,
            "auditor_fn_violation": 0.018585640296166613,
            "auditor_fp_violation": 0.006126104123417596,
            "ave_precision_score": 0.7863269699088022,
            "fpr": 0.08223684210526316,
            "logloss": 0.9588114203179011,
            "mae": 0.35194062767534695,
            "precision": 0.7813411078717201,
            "recall": 0.5571725571725572
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8052758806236742,
            "auditor_fn_violation": 0.02590838309317876,
            "auditor_fp_violation": 0.00506744056659098,
            "ave_precision_score": 0.8056611354234933,
            "fpr": 0.07244785949506037,
            "logloss": 0.8540299582388294,
            "mae": 0.33550037585222314,
            "precision": 0.8018018018018018,
            "recall": 0.5644820295983086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5906905852107949,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.012577848333129804,
            "ave_precision_score": 0.5686987340016765,
            "fpr": 0.2631578947368421,
            "logloss": 1.9709979180690267,
            "mae": 0.4626712923682644,
            "precision": 0.5284872298624754,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6169532317518449,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.009894290483136094,
            "ave_precision_score": 0.5910378027844173,
            "fpr": 0.27442371020856204,
            "logloss": 1.6182967606719603,
            "mae": 0.44797199012362066,
            "precision": 0.5421245421245421,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628587037234259,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325557881211364,
            "fpr": 0.45614035087719296,
            "logloss": 15.891170896580645,
            "mae": 0.46381578667823353,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582312995727349,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235581775495584,
            "fpr": 0.4654226125137212,
            "logloss": 16.19542549049843,
            "mae": 0.4731064760263397,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635485844022,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606326949249,
            "fpr": 0.45614035087719296,
            "logloss": 15.907840154214858,
            "mae": 0.46381578818321084,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582423129883966,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235691904680778,
            "fpr": 0.4654226125137212,
            "logloss": 16.210859983605044,
            "mae": 0.4731064753915837,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.668191452112583,
            "auditor_fn_violation": 0.001242386110807162,
            "auditor_fp_violation": 0.002528798795131683,
            "ave_precision_score": 0.6683948390239891,
            "fpr": 0.02850877192982456,
            "logloss": 3.441374895549969,
            "mae": 0.446090753680898,
            "precision": 0.821917808219178,
            "recall": 0.2494802494802495
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6949794286561761,
            "auditor_fn_violation": 0.00831509643701715,
            "auditor_fp_violation": 0.0032905783698981006,
            "ave_precision_score": 0.6948422607596711,
            "fpr": 0.012074643249176729,
            "logloss": 2.7702639479258693,
            "mae": 0.4313513309446924,
            "precision": 0.9112903225806451,
            "recall": 0.23890063424947147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7761486115188743,
            "auditor_fn_violation": 0.022659298975088452,
            "auditor_fp_violation": 0.015439919404078645,
            "ave_precision_score": 0.7764482857547874,
            "fpr": 0.16228070175438597,
            "logloss": 1.0715774404019311,
            "mae": 0.36169559902767057,
            "precision": 0.6810344827586207,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7933830221318974,
            "auditor_fn_violation": 0.030173844229443757,
            "auditor_fp_violation": 0.012889142845686164,
            "ave_precision_score": 0.7937444485013634,
            "fpr": 0.16575192096597147,
            "logloss": 0.9684792260469777,
            "mae": 0.34545465207798853,
            "precision": 0.688659793814433,
            "recall": 0.7061310782241015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.589989517461905,
            "auditor_fn_violation": 0.009898055950687544,
            "auditor_fp_violation": 0.009252757764480807,
            "ave_precision_score": 0.5559780948981484,
            "fpr": 0.10635964912280702,
            "logloss": 0.7785088021255967,
            "mae": 0.48044911974616217,
            "precision": 0.592436974789916,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5760712478637433,
            "auditor_fn_violation": 0.004715678470560663,
            "auditor_fp_violation": 0.006225283069936699,
            "ave_precision_score": 0.5447240335188136,
            "fpr": 0.09879253567508232,
            "logloss": 0.7709965468797216,
            "mae": 0.4807657405783133,
            "precision": 0.5964125560538116,
            "recall": 0.28118393234672306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635485844022,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606326949249,
            "fpr": 0.45614035087719296,
            "logloss": 15.906600649681701,
            "mae": 0.4638157883805578,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582410735710186,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235679511130452,
            "fpr": 0.4654226125137212,
            "logloss": 16.211708502283013,
            "mae": 0.4731064755809731,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7745169560946228,
            "auditor_fn_violation": 0.016549950760477092,
            "auditor_fp_violation": 0.002862071070948836,
            "ave_precision_score": 0.7748494967114592,
            "fpr": 0.06469298245614036,
            "logloss": 1.1745938401826759,
            "mae": 0.3581440100835107,
            "precision": 0.8108974358974359,
            "recall": 0.525987525987526
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7959770455379317,
            "auditor_fn_violation": 0.021123083385355887,
            "auditor_fp_violation": 0.009844167431043214,
            "ave_precision_score": 0.7964796447045124,
            "fpr": 0.05159165751920966,
            "logloss": 1.0449827720789326,
            "mae": 0.3409180586807132,
            "precision": 0.8412162162162162,
            "recall": 0.5264270613107822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623891613464,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594733168934,
            "fpr": 0.45614035087719296,
            "logloss": 15.903169569724627,
            "mae": 0.4638157878843432,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447529396937,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716303114963,
            "fpr": 0.4654226125137212,
            "logloss": 16.20771547476208,
            "mae": 0.47310647446378395,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7842666932175453,
            "auditor_fn_violation": 0.006909490462122045,
            "auditor_fp_violation": 0.024491696177799484,
            "ave_precision_score": 0.7824271042393832,
            "fpr": 0.21929824561403508,
            "logloss": 2.1759574173030263,
            "mae": 0.3111263032459307,
            "precision": 0.666110183639399,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7930832399778422,
            "auditor_fn_violation": 0.01063348363784889,
            "auditor_fp_violation": 0.028810730342992044,
            "ave_precision_score": 0.7915272937427347,
            "fpr": 0.21405049396267836,
            "logloss": 2.0877963352810798,
            "mae": 0.28894521967266507,
            "precision": 0.6755407653910149,
            "recall": 0.8583509513742071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7875791980102413,
            "auditor_fn_violation": 0.017908596855965287,
            "auditor_fp_violation": 0.004856616599503401,
            "ave_precision_score": 0.7878827389520409,
            "fpr": 0.08114035087719298,
            "logloss": 0.9434218541593308,
            "mae": 0.3512205739298663,
            "precision": 0.782991202346041,
            "recall": 0.5550935550935551
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8069841982896798,
            "auditor_fn_violation": 0.022183646899650276,
            "auditor_fp_violation": 0.00506744056659098,
            "ave_precision_score": 0.8073689176539824,
            "fpr": 0.07244785949506037,
            "logloss": 0.8392191445492584,
            "mae": 0.33489606861263116,
            "precision": 0.8,
            "recall": 0.5581395348837209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623891613464,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594733168934,
            "fpr": 0.45614035087719296,
            "logloss": 15.895630535847639,
            "mae": 0.46381578334690793,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758245986730096,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235728640429923,
            "fpr": 0.4654226125137212,
            "logloss": 16.199145571075874,
            "mae": 0.4731064688853207,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7869134798106537,
            "auditor_fn_violation": 0.020721632563737834,
            "auditor_fp_violation": 0.025132800097692032,
            "ave_precision_score": 0.7872209178653153,
            "fpr": 0.1875,
            "logloss": 1.1600188937702103,
            "mae": 0.33562091393659144,
            "precision": 0.6730401529636711,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8077015574088646,
            "auditor_fn_violation": 0.020580037734710597,
            "auditor_fp_violation": 0.02059054979975841,
            "ave_precision_score": 0.8081146283249263,
            "fpr": 0.1800219538968167,
            "logloss": 1.0184414497538978,
            "mae": 0.3128036552498011,
            "precision": 0.6809338521400778,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623724790026,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.532559456643707,
            "fpr": 0.45614035087719296,
            "logloss": 15.89598914288051,
            "mae": 0.4638157872526346,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582423709270792,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235692483879677,
            "fpr": 0.4654226125137212,
            "logloss": 16.199698692739148,
            "mae": 0.47310646741997436,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628636147459925,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606988231134,
            "fpr": 0.45614035087719296,
            "logloss": 15.891184398294767,
            "mae": 0.4638157869661488,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582460556224879,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235729329086035,
            "fpr": 0.4654226125137212,
            "logloss": 16.194759058809584,
            "mae": 0.47310646202085227,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672662166527,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643500678321,
            "fpr": 0.45614035087719296,
            "logloss": 15.902903408467537,
            "mae": 0.463815788087762,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582545481295923,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235814250512884,
            "fpr": 0.4654226125137212,
            "logloss": 16.2082652022223,
            "mae": 0.4731064736904245,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628575478064962,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325557216604101,
            "fpr": 0.45614035087719296,
            "logloss": 15.886224277298464,
            "mae": 0.4638157892527495,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447525660554,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716299395086,
            "fpr": 0.4654226125137212,
            "logloss": 16.208969299036728,
            "mae": 0.4731064764585952,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5886848700543892,
            "auditor_fn_violation": 0.056568461173724334,
            "auditor_fp_violation": 0.011847702202141076,
            "ave_precision_score": 0.5663613097858398,
            "fpr": 0.26535087719298245,
            "logloss": 1.9865789942865844,
            "mae": 0.4663168003423779,
            "precision": 0.5264187866927593,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6154299194305989,
            "auditor_fn_violation": 0.05579445954193867,
            "auditor_fp_violation": 0.0009773995158113317,
            "ave_precision_score": 0.5892138012800079,
            "fpr": 0.27661909989023054,
            "logloss": 1.6231711136411846,
            "mae": 0.4505180784860692,
            "precision": 0.5401459854014599,
            "recall": 0.6257928118393234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762866026727231,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325631106642456,
            "fpr": 0.45614035087719296,
            "logloss": 15.907497489929568,
            "mae": 0.4638157886625005,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582447501051105,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235716274800023,
            "fpr": 0.4654226125137212,
            "logloss": 16.21114833306288,
            "mae": 0.4731064749409558,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 1318,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7790009376449575,
            "auditor_fn_violation": 0.015772604588394065,
            "auditor_fp_violation": 0.009123010542597796,
            "ave_precision_score": 0.7792989712958378,
            "fpr": 0.08771929824561403,
            "logloss": 1.0887438972606465,
            "mae": 0.3582666096279946,
            "precision": 0.7714285714285715,
            "recall": 0.5613305613305614
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7959146062384658,
            "auditor_fn_violation": 0.012898494556779605,
            "auditor_fp_violation": 0.003383306016269943,
            "ave_precision_score": 0.7962961524605455,
            "fpr": 0.07683863885839737,
            "logloss": 0.9777512992172589,
            "mae": 0.34235135861472693,
            "precision": 0.7910447761194029,
            "recall": 0.5602536997885835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623891613464,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594733168934,
            "fpr": 0.45614035087719296,
            "logloss": 15.895639178866931,
            "mae": 0.4638157831811455,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582434995901646,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523570377030051,
            "fpr": 0.4654226125137212,
            "logloss": 16.20128796693127,
            "mae": 0.473106469722713,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7867811842019643,
            "auditor_fn_violation": 0.010782543677280524,
            "auditor_fp_violation": 0.02028381568771116,
            "ave_precision_score": 0.7860922271734903,
            "fpr": 0.21600877192982457,
            "logloss": 2.093972408453415,
            "mae": 0.31108589702674044,
            "precision": 0.6683501683501684,
            "recall": 0.8253638253638254
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7941438419685816,
            "auditor_fn_violation": 0.01041765780233603,
            "auditor_fp_violation": 0.027231854202066075,
            "ave_precision_score": 0.7930511596754832,
            "fpr": 0.2074643249176729,
            "logloss": 1.991045137671862,
            "mae": 0.2865529378007437,
            "precision": 0.6812816188870152,
            "recall": 0.854122621564482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635485844022,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606326949249,
            "fpr": 0.45614035087719296,
            "logloss": 15.909067662053921,
            "mae": 0.4638157883145233,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582423129883966,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235691904680778,
            "fpr": 0.4654226125137212,
            "logloss": 16.211677889400818,
            "mae": 0.47310647552606305,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762866026727231,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325631106642456,
            "fpr": 0.45614035087719296,
            "logloss": 15.906150487888002,
            "mae": 0.46381578856099587,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758243541207611,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235704186317781,
            "fpr": 0.4654226125137212,
            "logloss": 16.209181531620935,
            "mae": 0.47310647330762934,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628696570557573,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325667407784836,
            "fpr": 0.45614035087719296,
            "logloss": 15.907515131859327,
            "mae": 0.4638157890865882,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582386141022371,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235654917585725,
            "fpr": 0.4654226125137212,
            "logloss": 16.212683761741555,
            "mae": 0.47310647516448523,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6325138271620045,
            "auditor_fn_violation": 0.009898055950687544,
            "auditor_fp_violation": 0.009252757764480807,
            "ave_precision_score": 0.5588213024186242,
            "fpr": 0.10635964912280702,
            "logloss": 0.7694168371622628,
            "mae": 0.47385716340259504,
            "precision": 0.592436974789916,
            "recall": 0.29313929313929316
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6284943395725153,
            "auditor_fn_violation": 0.004715678470560663,
            "auditor_fp_violation": 0.006225283069936699,
            "ave_precision_score": 0.5534156565484634,
            "fpr": 0.09879253567508232,
            "logloss": 0.7624310048663159,
            "mae": 0.47427344937225074,
            "precision": 0.5964125560538116,
            "recall": 0.28118393234672306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762859953802941,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325570381096989,
            "fpr": 0.45614035087719296,
            "logloss": 15.903835745456028,
            "mae": 0.4638157889204361,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582435717349698,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523570449144686,
            "fpr": 0.4654226125137212,
            "logloss": 16.209960965236693,
            "mae": 0.4731064754209169,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7815447653455857,
            "auditor_fn_violation": 0.008252179304810887,
            "auditor_fp_violation": 0.02027363943501445,
            "ave_precision_score": 0.7816561390656258,
            "fpr": 0.2050438596491228,
            "logloss": 1.8298285181508047,
            "mae": 0.31179178340527564,
            "precision": 0.6764705882352942,
            "recall": 0.8128898128898129
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7971473973931301,
            "auditor_fn_violation": 0.011615143083246118,
            "auditor_fp_violation": 0.02532467206993168,
            "ave_precision_score": 0.7972904846904119,
            "fpr": 0.2030735455543359,
            "logloss": 1.7081433322087132,
            "mae": 0.28482622591832657,
            "precision": 0.6832191780821918,
            "recall": 0.8435517970401691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623971102089,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594812635392,
            "fpr": 0.45614035087719296,
            "logloss": 15.8943137273894,
            "mae": 0.46381578198157225,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582496575223625,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235765346675687,
            "fpr": 0.4654226125137212,
            "logloss": 16.20173096922683,
            "mae": 0.4731064699024022,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628604791284419,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325580496880276,
            "fpr": 0.45614035087719296,
            "logloss": 15.898615071659746,
            "mae": 0.46381578951490066,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582337257105929,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523560603583829,
            "fpr": 0.4654226125137212,
            "logloss": 16.206812366979857,
            "mae": 0.47310647740262535,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628550624218593,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325521470368323,
            "fpr": 0.45614035087719296,
            "logloss": 15.897653256774523,
            "mae": 0.4638157890096791,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582398339988007,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235667116005815,
            "fpr": 0.4654226125137212,
            "logloss": 16.204574981612108,
            "mae": 0.47310647637614467,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7805337733896069,
            "auditor_fn_violation": 0.00925064740854215,
            "auditor_fp_violation": 0.02307210892660887,
            "ave_precision_score": 0.7807433657049876,
            "fpr": 0.21820175438596492,
            "logloss": 2.241493352326343,
            "mae": 0.311184451020734,
            "precision": 0.667779632721202,
            "recall": 0.8316008316008316
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7926679994828321,
            "auditor_fn_violation": 0.011731178478683137,
            "auditor_fp_violation": 0.026946152805136608,
            "ave_precision_score": 0.7906903866070374,
            "fpr": 0.21514818880351264,
            "logloss": 2.1362043171284393,
            "mae": 0.2895247730044495,
            "precision": 0.6744186046511628,
            "recall": 0.8583509513742071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6079754714068455,
            "auditor_fn_violation": 0.0022682095050516105,
            "auditor_fp_violation": 0.0016739935686083019,
            "ave_precision_score": 0.6088704951264783,
            "fpr": 0.46381578947368424,
            "logloss": 0.7132197178187162,
            "mae": 0.49191290388504666,
            "precision": 0.5273743016759777,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5764499982708022,
            "auditor_fn_violation": 0.00018333592479049808,
            "auditor_fp_violation": 0.0017292452972046445,
            "ave_precision_score": 0.578097794077062,
            "fpr": 0.4774972557628979,
            "logloss": 0.7211442652863415,
            "mae": 0.4953783918028998,
            "precision": 0.5182724252491694,
            "recall": 0.9894291754756871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7862173213260379,
            "auditor_fn_violation": 0.018569683043367254,
            "auditor_fp_violation": 0.00520769731753979,
            "ave_precision_score": 0.7865238556970017,
            "fpr": 0.07894736842105263,
            "logloss": 0.9602691054872328,
            "mae": 0.3527055438619479,
            "precision": 0.7869822485207101,
            "recall": 0.553014553014553
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8056573737810168,
            "auditor_fn_violation": 0.021619714877826355,
            "auditor_fp_violation": 0.007099930328957594,
            "ave_precision_score": 0.8060431024458207,
            "fpr": 0.07135016465422613,
            "logloss": 0.8543900399062884,
            "mae": 0.3361801111038077,
            "precision": 0.801829268292683,
            "recall": 0.5560253699788583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628660495266766,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.532563133454479,
            "fpr": 0.45614035087719296,
            "logloss": 15.893366474654696,
            "mae": 0.4638157860016067,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582472840219,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235741612482455,
            "fpr": 0.4654226125137212,
            "logloss": 16.195368012967027,
            "mae": 0.47310645991461986,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7868984458212616,
            "auditor_fn_violation": 0.01024227668964511,
            "auditor_fp_violation": 0.021108092156144426,
            "ave_precision_score": 0.7865318978582342,
            "fpr": 0.2138157894736842,
            "logloss": 2.029225582605844,
            "mae": 0.31188617377094596,
            "precision": 0.6694915254237288,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7938829968134045,
            "auditor_fn_violation": 0.012483087841115058,
            "auditor_fp_violation": 0.02792605847355257,
            "ave_precision_score": 0.7933143882337167,
            "fpr": 0.20965971459934138,
            "logloss": 1.9210714349519733,
            "mae": 0.28657460343164354,
            "precision": 0.6795302013422819,
            "recall": 0.8562367864693446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.532493951634923,
            "auditor_fn_violation": 0.0022727687201371414,
            "auditor_fp_violation": 0.0019131355069809208,
            "ave_precision_score": 0.5340633606777953,
            "fpr": 0.4682017543859649,
            "logloss": 2.071625493116061,
            "mae": 0.4797833546320984,
            "precision": 0.5244988864142539,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5273507123420538,
            "auditor_fn_violation": 0.00105824280638566,
            "auditor_fp_violation": 0.0004009844167430993,
            "ave_precision_score": 0.5291113919617372,
            "fpr": 0.47200878155872666,
            "logloss": 2.0301429413701526,
            "mae": 0.47494372424046466,
            "precision": 0.5227524972253053,
            "recall": 0.9957716701902748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623971102089,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594812635392,
            "fpr": 0.45614035087719296,
            "logloss": 15.894486844211032,
            "mae": 0.46381578212783786,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582496575223625,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235765346675687,
            "fpr": 0.4654226125137212,
            "logloss": 16.201767208724526,
            "mae": 0.47310646999222616,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 1318,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7795511698776042,
            "auditor_fn_violation": 0.01754158004158004,
            "auditor_fp_violation": 0.0031673586518500426,
            "ave_precision_score": 0.7798814062443614,
            "fpr": 0.07346491228070176,
            "logloss": 1.0531304439024831,
            "mae": 0.3554017482356916,
            "precision": 0.7932098765432098,
            "recall": 0.5343035343035343
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8005200726059039,
            "auditor_fn_violation": 0.02180305080261685,
            "auditor_fp_violation": 0.006691427454400553,
            "ave_precision_score": 0.8011082189581518,
            "fpr": 0.06037321624588365,
            "logloss": 0.933743220886448,
            "mae": 0.33823902780349774,
            "precision": 0.8231511254019293,
            "recall": 0.5412262156448203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635485844022,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606326949249,
            "fpr": 0.45614035087719296,
            "logloss": 15.907834008466423,
            "mae": 0.46381578818146557,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582423129883966,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235691904680778,
            "fpr": 0.4654226125137212,
            "logloss": 16.210851908869458,
            "mae": 0.47310647539019735,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.762866026727231,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325631106642456,
            "fpr": 0.45614035087719296,
            "logloss": 15.912284209564008,
            "mae": 0.4638157886406017,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582410735457309,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235679510891408,
            "fpr": 0.4654226125137212,
            "logloss": 16.21215814622333,
            "mae": 0.4731064749670424,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7849113553750808,
            "auditor_fn_violation": 0.01964793741109531,
            "auditor_fp_violation": 0.02460109089428909,
            "ave_precision_score": 0.7852215473420918,
            "fpr": 0.18640350877192982,
            "logloss": 1.124764940048947,
            "mae": 0.3407717746399546,
            "precision": 0.6653543307086615,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.802062052701618,
            "auditor_fn_violation": 0.022638505649763403,
            "auditor_fp_violation": 0.019898851680876555,
            "ave_precision_score": 0.8033544051251463,
            "fpr": 0.17892425905598244,
            "logloss": 0.9898993608115128,
            "mae": 0.31836406193358396,
            "precision": 0.6778656126482213,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628623971102089,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325594812635392,
            "fpr": 0.45614035087719296,
            "logloss": 15.890125148516718,
            "mae": 0.46381578638163157,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758232511199883,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235593891244603,
            "fpr": 0.4654226125137212,
            "logloss": 16.19598947420311,
            "mae": 0.4731064758588024,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672662166527,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643500678321,
            "fpr": 0.45614035087719296,
            "logloss": 15.911425132276674,
            "mae": 0.463815788425337,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.758242310191912,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.523569187674665,
            "fpr": 0.4654226125137212,
            "logloss": 16.211864497338247,
            "mae": 0.4731064745579177,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628635485844022,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325606326949249,
            "fpr": 0.45614035087719296,
            "logloss": 15.90665201060891,
            "mae": 0.4638157883838627,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582410735710186,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235679511130452,
            "fpr": 0.4654226125137212,
            "logloss": 16.211753748809766,
            "mae": 0.47310647558260926,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6569444794698445,
            "auditor_fn_violation": 0.009624503045555677,
            "auditor_fp_violation": 0.0008090120893882034,
            "ave_precision_score": 0.6571526813661769,
            "fpr": 0.02850877192982456,
            "logloss": 3.3889895659216425,
            "mae": 0.45993804689372964,
            "precision": 0.8266666666666667,
            "recall": 0.2577962577962578
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6845173944267436,
            "auditor_fn_violation": 0.0037873953070644826,
            "auditor_fp_violation": 0.0029622723786896844,
            "ave_precision_score": 0.6843857452188787,
            "fpr": 0.013172338090010977,
            "logloss": 2.7308117380966292,
            "mae": 0.44296110520262,
            "precision": 0.9069767441860465,
            "recall": 0.24735729386892177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7628672417432716,
            "auditor_fn_violation": 0.002019732282890178,
            "auditor_fp_violation": 0.004294378638010354,
            "ave_precision_score": 0.5325643256083168,
            "fpr": 0.45614035087719296,
            "logloss": 15.898623473270048,
            "mae": 0.4638157873002494,
            "precision": 0.5325842696629214,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7582423017561846,
            "auditor_fn_violation": 0.0029148091333780456,
            "auditor_fp_violation": 0.004250434817476928,
            "ave_precision_score": 0.5235691792413617,
            "fpr": 0.4654226125137212,
            "logloss": 16.200486451935078,
            "mae": 0.4731064738305752,
            "precision": 0.5235955056179775,
            "recall": 0.985200845665962
        }
    }
]