[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7380886306553858,
            "auditor_fn_violation": 0.0034378361336745676,
            "auditor_fp_violation": 0.010318007433161502,
            "ave_precision_score": 0.7385139370120466,
            "fpr": 0.4024122807017544,
            "logloss": 1.3414448998570423,
            "mae": 0.4261604283625886,
            "precision": 0.5507955936352509,
            "recall": 0.9513742071881607
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7501259559014011,
            "auditor_fn_violation": 0.004511731185715819,
            "auditor_fp_violation": 0.0039312791974063736,
            "ave_precision_score": 0.7505272215502039,
            "fpr": 0.3896816684961581,
            "logloss": 1.1012332724536256,
            "mae": 0.4112150627878478,
            "precision": 0.5676004872107187,
            "recall": 0.9688149688149689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7383509772089536,
            "auditor_fn_violation": 0.0034378361336745676,
            "auditor_fp_violation": 0.010872497302481722,
            "ave_precision_score": 0.7387756834544101,
            "fpr": 0.40131578947368424,
            "logloss": 1.339532465864154,
            "mae": 0.4261416736173269,
            "precision": 0.5514705882352942,
            "recall": 0.9513742071881607
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.75065649257752,
            "auditor_fn_violation": 0.004511731185715819,
            "auditor_fp_violation": 0.0039312791974063736,
            "ave_precision_score": 0.7510565768643116,
            "fpr": 0.3896816684961581,
            "logloss": 1.098648146554108,
            "mae": 0.41116229659836134,
            "precision": 0.5676004872107187,
            "recall": 0.9688149688149689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7416017432380202,
            "auditor_fn_violation": 0.08595981232150143,
            "auditor_fp_violation": 0.1049934060664189,
            "ave_precision_score": 0.6249521490078618,
            "fpr": 0.2982456140350877,
            "logloss": 0.6895116654735206,
            "mae": 0.4970921728629292,
            "precision": 0.5612903225806452,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.7415285934762745,
            "auditor_fn_violation": 0.09187546070092721,
            "auditor_fp_violation": 0.09630357644295817,
            "ave_precision_score": 0.6287800808309272,
            "fpr": 0.3018660812294182,
            "logloss": 0.6917938688405901,
            "mae": 0.49833874108369997,
            "precision": 0.5614035087719298,
            "recall": 0.7318087318087318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 12669,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6928014300700878,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6931270197037853,
            "fpr": 0.48135964912280704,
            "logloss": 2.724051471378679,
            "mae": 0.47957763827422206,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7076572402931378,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.70906311655931,
            "fpr": 0.47200878155872666,
            "logloss": 2.6346379778652937,
            "mae": 0.4704348281369382,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7832034245215858,
            "auditor_fn_violation": 0.04970142057045362,
            "auditor_fp_violation": 0.09754026295807856,
            "ave_precision_score": 0.7832955584512299,
            "fpr": 0.3059210526315789,
            "logloss": 0.764868982220881,
            "mae": 0.4878431867742934,
            "precision": 0.5927007299270073,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.8028997288886698,
            "auditor_fn_violation": 0.04511274763744577,
            "auditor_fp_violation": 0.08830061521966662,
            "ave_precision_score": 0.8031587114284207,
            "fpr": 0.31284302963776073,
            "logloss": 0.7629956699642543,
            "mae": 0.4859844185780092,
            "precision": 0.5916905444126075,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8240572226882215,
            "auditor_fn_violation": 0.006796854716071367,
            "auditor_fp_violation": 0.022102166007273317,
            "ave_precision_score": 0.8243999500043158,
            "fpr": 0.1513157894736842,
            "logloss": 0.8075247151685135,
            "mae": 0.2783808064158642,
            "precision": 0.7283464566929134,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8581305522678218,
            "auditor_fn_violation": 0.016091156596096227,
            "auditor_fp_violation": 0.017450795190564937,
            "ave_precision_score": 0.8583992219223473,
            "fpr": 0.1437980241492865,
            "logloss": 0.6619525175800035,
            "mae": 0.2469518950660806,
            "precision": 0.7555970149253731,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7233289627286692,
            "auditor_fn_violation": 0.026846648863172735,
            "auditor_fp_violation": 0.02593364105023379,
            "ave_precision_score": 0.7238471932514408,
            "fpr": 0.15350877192982457,
            "logloss": 1.2876971549478315,
            "mae": 0.4229409336806847,
            "precision": 0.680365296803653,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7661576461825238,
            "auditor_fn_violation": 0.017282417941034856,
            "auditor_fp_violation": 0.024164603170551146,
            "ave_precision_score": 0.7665419096550612,
            "fpr": 0.150384193194292,
            "logloss": 1.0121187508979357,
            "mae": 0.41206718995578334,
            "precision": 0.6955555555555556,
            "recall": 0.6507276507276507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6129670856586191,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.586330531443915,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873640076802154,
            "mae": 0.495990232319424,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5993184633357301,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5786733170464403,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878052971651508,
            "mae": 0.49619834810397234,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6129670856586191,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.586330531443915,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873640221262742,
            "mae": 0.49599023905108897,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5993184633357301,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5786733170464403,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878053106149556,
            "mae": 0.496198354515888,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8242742670153893,
            "auditor_fn_violation": 0.006796854716071367,
            "auditor_fp_violation": 0.022102166007273317,
            "ave_precision_score": 0.8246154905370862,
            "fpr": 0.1513157894736842,
            "logloss": 0.8055518853080114,
            "mae": 0.27822777168108115,
            "precision": 0.7283464566929134,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8584154772822487,
            "auditor_fn_violation": 0.016839688628931225,
            "auditor_fp_violation": 0.01695045056544048,
            "ave_precision_score": 0.858683741164215,
            "fpr": 0.14270032930845225,
            "logloss": 0.659919576288305,
            "mae": 0.24674135323302296,
            "precision": 0.7565543071161048,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 12669,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.507407830025389,
            "auditor_fn_violation": 0.014687882496940025,
            "auditor_fp_violation": 0.08093803700595453,
            "ave_precision_score": 0.5003159217411457,
            "fpr": 0.2236842105263158,
            "logloss": 2.357511987152755,
            "mae": 0.5168049943617039,
            "precision": 0.4925373134328358,
            "recall": 0.4186046511627907
        },
        "train": {
            "accuracy": 0.446761800219539,
            "auc_prc": 0.5133772852962801,
            "auditor_fn_violation": 0.03508287481942806,
            "auditor_fp_violation": 0.07536313277002017,
            "ave_precision_score": 0.505674452633265,
            "fpr": 0.2349066959385291,
            "logloss": 2.2538091844168378,
            "mae": 0.5186158518105516,
            "precision": 0.47160493827160493,
            "recall": 0.3970893970893971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7858386635088314,
            "auditor_fn_violation": 0.044237509736285756,
            "auditor_fp_violation": 0.03151350757303282,
            "ave_precision_score": 0.7861789996188587,
            "fpr": 0.12171052631578948,
            "logloss": 1.2634800623484936,
            "mae": 0.31937825986012647,
            "precision": 0.7286063569682152,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8310521689561841,
            "auditor_fn_violation": 0.051224237832360776,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.831341715031506,
            "fpr": 0.11306256860592755,
            "logloss": 1.0111414494763578,
            "mae": 0.2752610305457212,
            "precision": 0.7700892857142857,
            "recall": 0.7172557172557172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.8394951978911425,
            "auditor_fn_violation": 0.006762082266978229,
            "auditor_fp_violation": 0.02690274947048716,
            "ave_precision_score": 0.8398032144099993,
            "fpr": 0.32127192982456143,
            "logloss": 1.2290154013044718,
            "mae": 0.3524682752841077,
            "precision": 0.6024423337856174,
            "recall": 0.9386892177589852
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.8662521725689606,
            "auditor_fn_violation": 0.0008603554157890056,
            "auditor_fp_violation": 0.021106374288412947,
            "ave_precision_score": 0.8665487925520132,
            "fpr": 0.32711306256860595,
            "logloss": 1.2019488956383402,
            "mae": 0.3406631673943158,
            "precision": 0.6109660574412533,
            "recall": 0.972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.4086961857545783,
            "auditor_fn_violation": 0.1011576907384741,
            "auditor_fp_violation": 0.09629890500739319,
            "ave_precision_score": 0.5493951018584097,
            "fpr": 0.2741228070175439,
            "logloss": 0.6942357281310341,
            "mae": 0.49188656408927944,
            "precision": 0.5606326889279437,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.3771992775661249,
            "auditor_fn_violation": 0.10823818836991177,
            "auditor_fp_violation": 0.08702422586985935,
            "ave_precision_score": 0.562579156549233,
            "fpr": 0.2678375411635565,
            "logloss": 0.6892730822833361,
            "mae": 0.4897765761607303,
            "precision": 0.5734265734265734,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6995329837993576,
            "auditor_fn_violation": 0.021598327213382295,
            "auditor_fp_violation": 0.015972805019382166,
            "ave_precision_score": 0.7009367999328446,
            "fpr": 0.2631578947368421,
            "logloss": 0.6906040954819074,
            "mae": 0.46096034547346726,
            "precision": 0.6091205211726385,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7302584598021671,
            "auditor_fn_violation": 0.017789046329112195,
            "auditor_fp_violation": 0.017767339749317136,
            "ave_precision_score": 0.7315497980874061,
            "fpr": 0.2414928649835346,
            "logloss": 0.6652722070903876,
            "mae": 0.4536187424683283,
            "precision": 0.6333333333333333,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.4086961857545783,
            "auditor_fn_violation": 0.1011576907384741,
            "auditor_fp_violation": 0.09629890500739319,
            "ave_precision_score": 0.5493951018584097,
            "fpr": 0.2741228070175439,
            "logloss": 0.6944532226081446,
            "mae": 0.4918204796288097,
            "precision": 0.5606326889279437,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.3771992775661249,
            "auditor_fn_violation": 0.10823818836991177,
            "auditor_fp_violation": 0.08702422586985935,
            "ave_precision_score": 0.562579156549233,
            "fpr": 0.2678375411635565,
            "logloss": 0.6894174302335402,
            "mae": 0.4896771508697359,
            "precision": 0.5734265734265734,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7230873124581937,
            "auditor_fn_violation": 0.02570379436964505,
            "auditor_fp_violation": 0.026048535347480323,
            "ave_precision_score": 0.7236058978185035,
            "fpr": 0.1513157894736842,
            "logloss": 1.2879361880161626,
            "mae": 0.42297906649968864,
            "precision": 0.6827586206896552,
            "recall": 0.627906976744186
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7657724608267528,
            "auditor_fn_violation": 0.01815646601596108,
            "auditor_fp_violation": 0.024164603170551146,
            "ave_precision_score": 0.7661575358655467,
            "fpr": 0.150384193194292,
            "logloss": 1.012479148997278,
            "mae": 0.412174380784108,
            "precision": 0.6948775055679287,
            "recall": 0.6486486486486487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5994508967331695,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5998195432505222,
            "fpr": 0.30043859649122806,
            "logloss": 0.6864653240071592,
            "mae": 0.4948226803669684,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.602228905891605,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09667372935440227,
            "ave_precision_score": 0.6064020361944793,
            "fpr": 0.3029637760702525,
            "logloss": 0.6864948535965092,
            "mae": 0.4949822957115299,
            "precision": 0.5639810426540285,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.23617063221958,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7102002938287841,
            "auditor_fn_violation": 0.01564296576536479,
            "auditor_fp_violation": 0.012735783079566803,
            "ave_precision_score": 0.6606512522686822,
            "fpr": 0.19736842105263158,
            "logloss": 3.6208288919030402,
            "mae": 0.31598570075296806,
            "precision": 0.6779964221824687,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7151833350347856,
            "auditor_fn_violation": 0.010515962217389223,
            "auditor_fp_violation": 0.004166134837770924,
            "ave_precision_score": 0.6603913997575686,
            "fpr": 0.21514818880351264,
            "logloss": 3.9085354650317576,
            "mae": 0.3017940203727927,
            "precision": 0.6776315789473685,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6129670856586191,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.586330531443915,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873640140115089,
            "mae": 0.49599023114301655,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5993184633357301,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5786733170464403,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878053032069512,
            "mae": 0.4961983473188398,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5908378741239995,
            "auditor_fn_violation": 0.09696645154111495,
            "auditor_fp_violation": 0.08530901570555091,
            "ave_precision_score": 0.5921504568239853,
            "fpr": 0.22697368421052633,
            "logloss": 0.6985970176344843,
            "mae": 0.47440617834217846,
            "precision": 0.593320235756385,
            "recall": 0.638477801268499
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6144638947403054,
            "auditor_fn_violation": 0.10076427859084282,
            "auditor_fp_violation": 0.07689479998978889,
            "ave_precision_score": 0.6157135268325786,
            "fpr": 0.22063666300768386,
            "logloss": 0.6722397152804025,
            "mae": 0.46510665417821623,
            "precision": 0.6097087378640776,
            "recall": 0.6528066528066528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7491740895274144,
            "auditor_fn_violation": 0.09865871073031417,
            "auditor_fp_violation": 0.09964332813811294,
            "ave_precision_score": 0.7498958483750033,
            "fpr": 0.26864035087719296,
            "logloss": 0.7449630257702907,
            "mae": 0.48130333540612574,
            "precision": 0.5671378091872792,
            "recall": 0.678646934460888
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7741086114179337,
            "auditor_fn_violation": 0.10109062030028003,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.7747715293298654,
            "fpr": 0.25686059275521406,
            "logloss": 0.7200536459734798,
            "mae": 0.4776530941075544,
            "precision": 0.5828877005347594,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7861215739654452,
            "auditor_fn_violation": 0.0285435443789177,
            "auditor_fp_violation": 0.048482895735922966,
            "ave_precision_score": 0.7863823420779663,
            "fpr": 0.27521929824561403,
            "logloss": 1.8152591598067824,
            "mae": 0.3472181944953358,
            "precision": 0.6202723146747352,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8280942276887145,
            "auditor_fn_violation": 0.02586999732993147,
            "auditor_fp_violation": 0.0408291425216348,
            "ave_precision_score": 0.8284003658774061,
            "fpr": 0.265642151481888,
            "logloss": 1.5943353578271944,
            "mae": 0.32038655449006276,
            "precision": 0.639344262295082,
            "recall": 0.8918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7001190610774909,
            "auditor_fn_violation": 0.021598327213382295,
            "auditor_fp_violation": 0.015972805019382166,
            "ave_precision_score": 0.7015219407425723,
            "fpr": 0.2631578947368421,
            "logloss": 0.6910699774904437,
            "mae": 0.46093893828883503,
            "precision": 0.6091205211726385,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7310464342206922,
            "auditor_fn_violation": 0.019112670045710663,
            "auditor_fp_violation": 0.017767339749317136,
            "ave_precision_score": 0.7323363980688959,
            "fpr": 0.2414928649835346,
            "logloss": 0.6653186405326655,
            "mae": 0.45339869239196817,
            "precision": 0.6327212020033389,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8389990390475863,
            "auditor_fn_violation": 0.009886966358814586,
            "auditor_fp_violation": 0.03146105582863765,
            "ave_precision_score": 0.8393012750462838,
            "fpr": 0.15679824561403508,
            "logloss": 0.6876184189420185,
            "mae": 0.2805241727870859,
            "precision": 0.7270992366412213,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8658246861731815,
            "auditor_fn_violation": 0.014685376924674401,
            "auditor_fp_violation": 0.0037525846884333674,
            "ave_precision_score": 0.8661063513639271,
            "fpr": 0.14928649835345773,
            "logloss": 0.6010269154632627,
            "mae": 0.2536982004965857,
            "precision": 0.7509157509157509,
            "recall": 0.8523908523908524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7670526234025699,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.7672331575104628,
            "fpr": 0.2631578947368421,
            "logloss": 0.7795534887436368,
            "mae": 0.481398683956318,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.8028343831596085,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.8029676824801301,
            "fpr": 0.25686059275521406,
            "logloss": 0.7738148469325457,
            "mae": 0.47814718575823073,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6995329837993576,
            "auditor_fn_violation": 0.021598327213382295,
            "auditor_fp_violation": 0.015972805019382166,
            "ave_precision_score": 0.7009367999328446,
            "fpr": 0.2631578947368421,
            "logloss": 0.6906040869275725,
            "mae": 0.4609603465355018,
            "precision": 0.6091205211726385,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7302584598021671,
            "auditor_fn_violation": 0.017789046329112195,
            "auditor_fp_violation": 0.017767339749317136,
            "ave_precision_score": 0.7315497980874061,
            "fpr": 0.2414928649835346,
            "logloss": 0.6652722124576376,
            "mae": 0.45361874250104217,
            "precision": 0.6333333333333333,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6790750026891816,
            "auditor_fn_violation": 0.01935434516523868,
            "auditor_fp_violation": 0.015483255405027391,
            "ave_precision_score": 0.6806108143874665,
            "fpr": 0.28618421052631576,
            "logloss": 0.684627143122664,
            "mae": 0.46561120947202045,
            "precision": 0.6033434650455927,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7019150228710779,
            "auditor_fn_violation": 0.010956409419636645,
            "auditor_fp_violation": 0.016026344676180027,
            "ave_precision_score": 0.7033830414306682,
            "fpr": 0.283205268935236,
            "logloss": 0.6670123537154125,
            "mae": 0.46065439660057145,
            "precision": 0.6149253731343284,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.398723251190976,
            "mae": 0.47478070175438597,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.4665203073545554,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7859689091163519,
            "auditor_fn_violation": 0.044237509736285756,
            "auditor_fp_violation": 0.03151350757303282,
            "ave_precision_score": 0.7863091364960677,
            "fpr": 0.12171052631578948,
            "logloss": 1.2614028862643694,
            "mae": 0.3192961189855769,
            "precision": 0.7286063569682152,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.831081883534716,
            "auditor_fn_violation": 0.051224237832360776,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.8313722792717269,
            "fpr": 0.11306256860592755,
            "logloss": 1.0094639918817798,
            "mae": 0.2751945421052885,
            "precision": 0.7700892857142857,
            "recall": 0.7172557172557172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8234010929938169,
            "auditor_fn_violation": 0.005542728385445641,
            "auditor_fp_violation": 0.006778763537545459,
            "ave_precision_score": 0.823376943242221,
            "fpr": 0.09210526315789473,
            "logloss": 0.6129619893792447,
            "mae": 0.33076597756439374,
            "precision": 0.7990430622009569,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8818489215542747,
            "auditor_fn_violation": 0.010976948408342483,
            "auditor_fp_violation": 0.004564368314910783,
            "ave_precision_score": 0.8807702546466151,
            "fpr": 0.07903402854006586,
            "logloss": 0.5289121014592432,
            "mae": 0.3071563125340895,
            "precision": 0.8371040723981901,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6599764356936342,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.6653744475360684,
            "fpr": 0.30043859649122806,
            "logloss": 0.6863587749130269,
            "mae": 0.49501817922035096,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6799490973291509,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09704388226584638,
            "ave_precision_score": 0.6979458588866879,
            "fpr": 0.3040614709110867,
            "logloss": 0.6866743613570564,
            "mae": 0.4953025479020978,
            "precision": 0.5637795275590551,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.837292272886645,
            "auditor_fn_violation": 0.013438392492860055,
            "auditor_fp_violation": 0.030052351836310606,
            "ave_precision_score": 0.8376288177889195,
            "fpr": 0.16666666666666666,
            "logloss": 0.7076365059358328,
            "mae": 0.2809526106365248,
            "precision": 0.7169459962756052,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8663232989855434,
            "auditor_fn_violation": 0.012222980389830006,
            "auditor_fp_violation": 0.007285630408699875,
            "ave_precision_score": 0.8665708397823952,
            "fpr": 0.16575192096597147,
            "logloss": 0.6189732634527694,
            "mae": 0.2545797245720147,
            "precision": 0.7336860670194003,
            "recall": 0.8648648648648649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7264379591303975,
            "auditor_fn_violation": 0.02088201476206373,
            "auditor_fp_violation": 0.015503237021939818,
            "ave_precision_score": 0.7277684865332199,
            "fpr": 0.2993421052631579,
            "logloss": 0.6770811783724777,
            "mae": 0.46484337175232276,
            "precision": 0.5925373134328358,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7492579661157577,
            "auditor_fn_violation": 0.01707474594412026,
            "auditor_fp_violation": 0.00800551400199117,
            "ave_precision_score": 0.750480037103151,
            "fpr": 0.300768386388584,
            "logloss": 0.6649270692160694,
            "mae": 0.4628315634052264,
            "precision": 0.6017441860465116,
            "recall": 0.8607068607068608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5902372282914985,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5914859137434394,
            "fpr": 0.30043859649122806,
            "logloss": 0.6853632951656479,
            "mae": 0.4950121486617675,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5848877098896311,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09704388226584638,
            "ave_precision_score": 0.5864536752384777,
            "fpr": 0.3040614709110867,
            "logloss": 0.6870670867678323,
            "mae": 0.4960129104644616,
            "precision": 0.5630914826498423,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.4086961857545783,
            "auditor_fn_violation": 0.1011576907384741,
            "auditor_fp_violation": 0.09629890500739319,
            "ave_precision_score": 0.5493951018584097,
            "fpr": 0.2741228070175439,
            "logloss": 0.6944531821009368,
            "mae": 0.49182047257036493,
            "precision": 0.5606326889279437,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.3771992775661249,
            "auditor_fn_violation": 0.10823818836991177,
            "auditor_fp_violation": 0.08702422586985935,
            "ave_precision_score": 0.562579156549233,
            "fpr": 0.2678375411635565,
            "logloss": 0.6894174019072353,
            "mae": 0.48967714700950093,
            "precision": 0.5734265734265734,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6878143143121038,
            "auditor_fn_violation": 0.020042839657282742,
            "auditor_fp_violation": 0.015575670383247414,
            "ave_precision_score": 0.6892796627966091,
            "fpr": 0.2642543859649123,
            "logloss": 0.6813109969286908,
            "mae": 0.4604404221468589,
            "precision": 0.608130081300813,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7112070831588264,
            "auditor_fn_violation": 0.018690479722312872,
            "auditor_fp_violation": 0.018308528833635433,
            "ave_precision_score": 0.712607589848544,
            "fpr": 0.24259055982436883,
            "logloss": 0.6585045626448388,
            "mae": 0.452548546992594,
            "precision": 0.6304347826086957,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5972281728998844,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5480082188733638,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873639109266205,
            "mae": 0.4959906575580438,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5824332229276878,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5384280914171633,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878052333196255,
            "mae": 0.49619872889325073,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.8373931783271704,
            "auditor_fn_violation": 0.006884944920440638,
            "auditor_fp_violation": 0.0231811733205451,
            "ave_precision_score": 0.837690613691709,
            "fpr": 0.3223684210526316,
            "logloss": 1.2562924415793824,
            "mae": 0.353756270747659,
            "precision": 0.6021650879566982,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.8658648742912476,
            "auditor_fn_violation": 0.0017937383469765473,
            "auditor_fp_violation": 0.01580680570801318,
            "ave_precision_score": 0.8661312223865636,
            "fpr": 0.33040614709110866,
            "logloss": 1.2279668017792935,
            "mae": 0.34272859349336315,
            "precision": 0.6090909090909091,
            "recall": 0.975051975051975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7670556933504666,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.7672362270729589,
            "fpr": 0.2631578947368421,
            "logloss": 0.7801579144940896,
            "mae": 0.4811747552206122,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.8028381048798721,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.8029714032414146,
            "fpr": 0.25686059275521406,
            "logloss": 0.7742369393734132,
            "mae": 0.4778376093091348,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.501241000876312,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5467785306871539,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873639125920032,
            "mae": 0.4959906560548565,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5027962713164421,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5369421798299309,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878052356657693,
            "mae": 0.4961987279772628,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6586598606036413,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.6619820159796325,
            "fpr": 0.30043859649122806,
            "logloss": 0.6863605893134167,
            "mae": 0.4950206196775091,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6811873674091239,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09704388226584638,
            "ave_precision_score": 0.6987025297313316,
            "fpr": 0.3040614709110867,
            "logloss": 0.686686607899914,
            "mae": 0.4953109020393845,
            "precision": 0.5637795275590551,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.398723251190976,
            "mae": 0.4747807017543864,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.4665203073545555,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6935956145031859,
            "auditor_fn_violation": 0.023183950892029234,
            "auditor_fp_violation": 0.015892878551732405,
            "ave_precision_score": 0.6950054780601287,
            "fpr": 0.28399122807017546,
            "logloss": 0.6934131571918409,
            "mae": 0.465815057978034,
            "precision": 0.5965732087227414,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7196594977267419,
            "auditor_fn_violation": 0.01661832397287941,
            "auditor_fp_violation": 0.01269241569448344,
            "ave_precision_score": 0.7209326471899868,
            "fpr": 0.265642151481888,
            "logloss": 0.675741178538536,
            "mae": 0.46248995734360293,
            "precision": 0.6164817749603804,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6738466326227124,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.6758306139921492,
            "fpr": 0.2631578947368421,
            "logloss": 0.7719251302556603,
            "mae": 0.480589863305032,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7241852173974827,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.7249388808560031,
            "fpr": 0.25686059275521406,
            "logloss": 0.7673849371587704,
            "mae": 0.47751009307237563,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6473392905415687,
            "auditor_fn_violation": 0.030027168873558104,
            "auditor_fp_violation": 0.021632598009830962,
            "ave_precision_score": 0.6489579422389041,
            "fpr": 0.30701754385964913,
            "logloss": 0.6901047339884083,
            "mae": 0.4676250853951563,
            "precision": 0.5870206489675516,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6685042662161333,
            "auditor_fn_violation": 0.019119516375279276,
            "auditor_fp_violation": 0.02088172976284687,
            "ave_precision_score": 0.6700739023085103,
            "fpr": 0.31394072447859495,
            "logloss": 0.6792248729855992,
            "mae": 0.46697388044696475,
            "precision": 0.5843023255813954,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8347210423870679,
            "auditor_fn_violation": 0.009727013092986167,
            "auditor_fp_violation": 0.025541501818327147,
            "ave_precision_score": 0.8350508856803589,
            "fpr": 0.31359649122807015,
            "logloss": 1.1854662220407897,
            "mae": 0.34628261577355707,
            "precision": 0.607681755829904,
            "recall": 0.9365750528541226
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.8608616178946442,
            "auditor_fn_violation": 0.0021360548254071863,
            "auditor_fp_violation": 0.021213590993796758,
            "ave_precision_score": 0.8610744280082017,
            "fpr": 0.3238199780461032,
            "logloss": 1.1777157903440003,
            "mae": 0.3355236982073826,
            "precision": 0.6133682830930537,
            "recall": 0.972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.4086961857545783,
            "auditor_fn_violation": 0.1011576907384741,
            "auditor_fp_violation": 0.09629890500739319,
            "ave_precision_score": 0.5493951018584097,
            "fpr": 0.2741228070175439,
            "logloss": 0.6946820823409617,
            "mae": 0.49174173829848306,
            "precision": 0.5606326889279437,
            "recall": 0.6744186046511628
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.3771992775661249,
            "auditor_fn_violation": 0.10823818836991177,
            "auditor_fp_violation": 0.08702422586985935,
            "ave_precision_score": 0.562579156549233,
            "fpr": 0.2678375411635565,
            "logloss": 0.6895963059248698,
            "mae": 0.48956999342999,
            "precision": 0.5734265734265734,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7857061709587003,
            "auditor_fn_violation": 0.04433950892029228,
            "auditor_fp_violation": 0.032162910122687134,
            "ave_precision_score": 0.78604649674092,
            "fpr": 0.12280701754385964,
            "logloss": 1.259079915115567,
            "mae": 0.3191950000884826,
            "precision": 0.7274939172749392,
            "recall": 0.6321353065539113
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.83091971993808,
            "auditor_fn_violation": 0.05094582042990386,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.8312093573893959,
            "fpr": 0.11306256860592755,
            "logloss": 1.007406262145146,
            "mae": 0.27475733650324224,
            "precision": 0.7706013363028953,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.39726994271691,
            "mae": 0.47478070175438764,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.46652030735455574,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5904482697007727,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5919347370555721,
            "fpr": 0.30043859649122806,
            "logloss": 0.6853607449796206,
            "mae": 0.49500957879980934,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.585073415994396,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09667372935440227,
            "ave_precision_score": 0.5864323344718878,
            "fpr": 0.3029637760702525,
            "logloss": 0.687046245099282,
            "mae": 0.4959999925807593,
            "precision": 0.5639810426540285,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7673023900602913,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.767482937604934,
            "fpr": 0.2631578947368421,
            "logloss": 0.781696332176481,
            "mae": 0.48015962011720004,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.8035159276702319,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.803648964428639,
            "fpr": 0.25686059275521406,
            "logloss": 0.776412977144069,
            "mae": 0.47696111479653486,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6998626142161344,
            "auditor_fn_violation": 0.022122232113052195,
            "auditor_fp_violation": 0.01656476042041322,
            "ave_precision_score": 0.7012705720936048,
            "fpr": 0.2642543859649123,
            "logloss": 0.6914619449045086,
            "mae": 0.4612258077811515,
            "precision": 0.6087662337662337,
            "recall": 0.7928118393234672
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7291496494510388,
            "auditor_fn_violation": 0.018608323767489523,
            "auditor_fp_violation": 0.01768309805222987,
            "ave_precision_score": 0.7304164224683962,
            "fpr": 0.24259055982436883,
            "logloss": 0.666030578917135,
            "mae": 0.45396970400564235,
            "precision": 0.6341059602649006,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6738466326227124,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.6758306139921492,
            "fpr": 0.2631578947368421,
            "logloss": 0.7718041975305517,
            "mae": 0.48058895397474133,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7241852173974827,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.7249388808560031,
            "fpr": 0.25686059275521406,
            "logloss": 0.7672003025704548,
            "mae": 0.47750878409287434,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7904010665796771,
            "auditor_fn_violation": 0.04136994176773859,
            "auditor_fp_violation": 0.03249760220597051,
            "ave_precision_score": 0.7907397967082945,
            "fpr": 0.12390350877192982,
            "logloss": 1.15819263902588,
            "mae": 0.31533854110022796,
            "precision": 0.7296650717703349,
            "recall": 0.6448202959830867
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8354237541995877,
            "auditor_fn_violation": 0.04857699039916384,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.8357079486495158,
            "fpr": 0.11306256860592755,
            "logloss": 0.9246061755121928,
            "mae": 0.2718488997063037,
            "precision": 0.7721238938053098,
            "recall": 0.7255717255717256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 12669,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7644992877863186,
            "auditor_fn_violation": 0.08185434516523868,
            "auditor_fp_violation": 0.0894227310873996,
            "ave_precision_score": 0.7647156367012957,
            "fpr": 0.24232456140350878,
            "logloss": 0.7848970424045906,
            "mae": 0.4756709117965217,
            "precision": 0.6102292768959435,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.80398121929558,
            "auditor_fn_violation": 0.07205305448993704,
            "auditor_fp_violation": 0.0797794399203533,
            "ave_precision_score": 0.8041564573140705,
            "fpr": 0.23819978046103182,
            "logloss": 0.7679941656493027,
            "mae": 0.4668674370361866,
            "precision": 0.6212914485165794,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5900722511764791,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5913217413887514,
            "fpr": 0.30043859649122806,
            "logloss": 0.6853678938848106,
            "mae": 0.4950165487196321,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5848392741513654,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09704388226584638,
            "ave_precision_score": 0.5865082537520014,
            "fpr": 0.3040614709110867,
            "logloss": 0.6870994539546398,
            "mae": 0.49603295234634115,
            "precision": 0.5630914826498423,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5972281728998844,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5480082188733638,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873639160189758,
            "mae": 0.49599065680645016,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5824332229276878,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5384280914171633,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878052397040275,
            "mae": 0.49619872918767544,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.398723251190976,
            "mae": 0.4747807017543864,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.4665203073545555,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.3910872987953,
            "mae": 0.47478070175693016,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.113413607843164,
            "mae": 0.46652030735483035,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5907325360350568,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5919642680870902,
            "fpr": 0.30043859649122806,
            "logloss": 0.685360047233951,
            "mae": 0.49500622045123976,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5853663001756432,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09667372935440227,
            "ave_precision_score": 0.5868875226914241,
            "fpr": 0.3029637760702525,
            "logloss": 0.6869932669896269,
            "mae": 0.4959670510695088,
            "precision": 0.5639810426540285,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.398723251190976,
            "mae": 0.4747807017543864,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.4665203073545555,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8368061948257699,
            "auditor_fn_violation": 0.011644134119654318,
            "auditor_fp_violation": 0.02532669943651841,
            "ave_precision_score": 0.8370969590768618,
            "fpr": 0.16666666666666666,
            "logloss": 0.700611700442801,
            "mae": 0.28177634928626083,
            "precision": 0.7137476459510358,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8651863228791169,
            "auditor_fn_violation": 0.011031719044891385,
            "auditor_fp_violation": 0.00824036964235571,
            "ave_precision_score": 0.8654532242566582,
            "fpr": 0.15697036223929747,
            "logloss": 0.6130403891981823,
            "mae": 0.25494567175464256,
            "precision": 0.7428057553956835,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7102530436782513,
            "auditor_fn_violation": 0.01564296576536479,
            "auditor_fp_violation": 0.012645865803460818,
            "ave_precision_score": 0.6616883432545079,
            "fpr": 0.20175438596491227,
            "logloss": 3.5886487263131985,
            "mae": 0.3160196263322951,
            "precision": 0.6731793960923623,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7160964092072861,
            "auditor_fn_violation": 0.012159081313856287,
            "auditor_fp_violation": 0.0056671687131442635,
            "ave_precision_score": 0.6621005038043769,
            "fpr": 0.21514818880351264,
            "logloss": 3.8746599437699474,
            "mae": 0.3016105329783887,
            "precision": 0.6786885245901639,
            "recall": 0.8607068607068608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8367256637084848,
            "auditor_fn_violation": 0.006884944920440638,
            "auditor_fp_violation": 0.025319206330176244,
            "ave_precision_score": 0.8370254391784756,
            "fpr": 0.3125,
            "logloss": 1.246672557671841,
            "mae": 0.3510475268884204,
            "precision": 0.6095890410958904,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.8647789337707914,
            "auditor_fn_violation": 0.0008306879876583509,
            "auditor_fp_violation": 0.017808184208510977,
            "ave_precision_score": 0.8650557713353335,
            "fpr": 0.3227222832052689,
            "logloss": 1.216544866289073,
            "mae": 0.3395547249883673,
            "precision": 0.6141732283464567,
            "recall": 0.972972972972973
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6814849255731985,
            "auditor_fn_violation": 0.01986897741181707,
            "auditor_fp_violation": 0.01562312672341447,
            "ave_precision_score": 0.6831053513722275,
            "fpr": 0.2993421052631579,
            "logloss": 0.6853173698722812,
            "mae": 0.46848132111654994,
            "precision": 0.5943536404160475,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6983062645486119,
            "auditor_fn_violation": 0.014128542119760563,
            "auditor_fp_violation": 0.011640670870242268,
            "ave_precision_score": 0.6997958646450189,
            "fpr": 0.3040614709110867,
            "logloss": 0.675749509919887,
            "mae": 0.46781503841788,
            "precision": 0.5956204379562043,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7049050497161025,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10096960796067618,
            "ave_precision_score": 0.5547998903537884,
            "fpr": 0.26864035087719296,
            "logloss": 0.6873109775354859,
            "mae": 0.48988237637176846,
            "precision": 0.5648312611012434,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7123930073458873,
            "auditor_fn_violation": 0.10823818836991177,
            "auditor_fp_violation": 0.08920685165802977,
            "ave_precision_score": 0.5666849253321524,
            "fpr": 0.2645444566410538,
            "logloss": 0.6837889253838065,
            "mae": 0.488121517239758,
            "precision": 0.5764499121265377,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7366430299680344,
            "auditor_fn_violation": 0.025189162123066655,
            "auditor_fp_violation": 0.024774707269312232,
            "ave_precision_score": 0.737122414048372,
            "fpr": 0.1425438596491228,
            "logloss": 1.2834206417911571,
            "mae": 0.42172523517684457,
            "precision": 0.6912114014251781,
            "recall": 0.6152219873150105
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7696955105027093,
            "auditor_fn_violation": 0.02560299047675558,
            "auditor_fp_violation": 0.02297500829653078,
            "ave_precision_score": 0.7700650890104823,
            "fpr": 0.14050493962678376,
            "logloss": 1.0117467191622975,
            "mae": 0.4123508768109145,
            "precision": 0.7070938215102975,
            "recall": 0.6424116424116424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 12669,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7645054454925763,
            "auditor_fn_violation": 0.08185434516523868,
            "auditor_fp_violation": 0.0894227310873996,
            "ave_precision_score": 0.7647218279280092,
            "fpr": 0.24232456140350878,
            "logloss": 0.7844348648968462,
            "mae": 0.4755449324290742,
            "precision": 0.6102292768959435,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.8040663479782706,
            "auditor_fn_violation": 0.07205305448993704,
            "auditor_fp_violation": 0.0797794399203533,
            "ave_precision_score": 0.8042415428033185,
            "fpr": 0.23819978046103182,
            "logloss": 0.7676023225919674,
            "mae": 0.46677097877739027,
            "precision": 0.6212914485165794,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.398723251190976,
            "mae": 0.4747807017543864,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.4665203073545555,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.677707577814275,
            "auditor_fn_violation": 0.018795667816475653,
            "auditor_fp_violation": 0.014444211325580486,
            "ave_precision_score": 0.6792126984480313,
            "fpr": 0.30372807017543857,
            "logloss": 0.6873669804220321,
            "mae": 0.46960894675239134,
            "precision": 0.5914454277286135,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6972648402012565,
            "auditor_fn_violation": 0.012841432160861362,
            "auditor_fp_violation": 0.01072932887447988,
            "ave_precision_score": 0.698808591222497,
            "fpr": 0.3062568605927552,
            "logloss": 0.6765774247550344,
            "mae": 0.4682215911169607,
            "precision": 0.5962373371924746,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6567933801798278,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.6588296740429384,
            "fpr": 0.2631578947368421,
            "logloss": 0.7617584601946371,
            "mae": 0.4819077363140116,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7018455763102276,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.7028999418177384,
            "fpr": 0.25686059275521406,
            "logloss": 0.756219663223553,
            "mae": 0.47883114647266795,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8319006666994587,
            "auditor_fn_violation": 0.007645302473943846,
            "auditor_fp_violation": 0.013072972864964234,
            "ave_precision_score": 0.8321463445282857,
            "fpr": 0.09868421052631579,
            "logloss": 0.6015412820120809,
            "mae": 0.3258995031137189,
            "precision": 0.7902097902097902,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8856639914709517,
            "auditor_fn_violation": 0.01737826655499543,
            "auditor_fp_violation": 0.007285630408699873,
            "ave_precision_score": 0.8856569904144543,
            "fpr": 0.07574094401756312,
            "logloss": 0.5227336673900262,
            "mae": 0.3048689050762095,
            "precision": 0.8410138248847926,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.391003513867783,
            "mae": 0.47478070175706444,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784318,
            "mae": 0.4665203073548461,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5974594875589445,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5466108594228688,
            "fpr": 0.30043859649122806,
            "logloss": 0.6873639211609216,
            "mae": 0.49599065847302737,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5786617508645471,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09853725780512088,
            "ave_precision_score": 0.5379173764008692,
            "fpr": 0.30735455543358947,
            "logloss": 0.6878052443282279,
            "mae": 0.49619873092150973,
            "precision": 0.5611285266457681,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5908378741239995,
            "auditor_fn_violation": 0.09696645154111495,
            "auditor_fp_violation": 0.08530901570555091,
            "ave_precision_score": 0.5921504568239853,
            "fpr": 0.22697368421052633,
            "logloss": 0.7020038025233178,
            "mae": 0.4743172444051883,
            "precision": 0.593320235756385,
            "recall": 0.638477801268499
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6144638947403054,
            "auditor_fn_violation": 0.10076427859084282,
            "auditor_fp_violation": 0.07689479998978889,
            "ave_precision_score": 0.6157135268325786,
            "fpr": 0.22063666300768386,
            "logloss": 0.6743506143826212,
            "mae": 0.46490310029863785,
            "precision": 0.6097087378640776,
            "recall": 0.6528066528066528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6738466326227124,
            "auditor_fn_violation": 0.10187863951633842,
            "auditor_fp_violation": 0.10190624625344682,
            "ave_precision_score": 0.6758306139921492,
            "fpr": 0.2631578947368421,
            "logloss": 0.7719251255334368,
            "mae": 0.480589863272354,
            "precision": 0.5698924731182796,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7241868253322794,
            "auditor_fn_violation": 0.10256029904767557,
            "auditor_fp_violation": 0.08542108084650142,
            "ave_precision_score": 0.7249388808560031,
            "fpr": 0.25686059275521406,
            "logloss": 0.7673849342665351,
            "mae": 0.47751009395564975,
            "precision": 0.5813953488372093,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8234010929938169,
            "auditor_fn_violation": 0.005542728385445641,
            "auditor_fp_violation": 0.006778763537545459,
            "ave_precision_score": 0.823376943242221,
            "fpr": 0.09210526315789473,
            "logloss": 0.6129619978186428,
            "mae": 0.33076597844502115,
            "precision": 0.7990430622009569,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8818489215542747,
            "auditor_fn_violation": 0.010976948408342483,
            "auditor_fp_violation": 0.004564368314910783,
            "ave_precision_score": 0.8807702546466151,
            "fpr": 0.07903402854006586,
            "logloss": 0.5289121092136362,
            "mae": 0.3071563133321972,
            "precision": 0.8371040723981901,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6594210029517491,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.6631346429406826,
            "fpr": 0.30043859649122806,
            "logloss": 0.6863588194902943,
            "mae": 0.49501825823571316,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6812912067942527,
            "auditor_fn_violation": 0.09263083906333085,
            "auditor_fp_violation": 0.09704388226584638,
            "ave_precision_score": 0.6992116790542267,
            "fpr": 0.3040614709110867,
            "logloss": 0.6866747989016773,
            "mae": 0.4953028487714271,
            "precision": 0.5637795275590551,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7645080454504722,
            "auditor_fn_violation": 0.09185721968769704,
            "auditor_fp_violation": 0.0894227310873996,
            "ave_precision_score": 0.7647244134893207,
            "fpr": 0.24232456140350878,
            "logloss": 0.7837103375326417,
            "mae": 0.47570402392496663,
            "precision": 0.5967153284671532,
            "recall": 0.6913319238900634
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.8041077817715009,
            "auditor_fn_violation": 0.092398063857998,
            "auditor_fp_violation": 0.07975901769075638,
            "ave_precision_score": 0.8042829477577773,
            "fpr": 0.2349066959385291,
            "logloss": 0.7671587634632748,
            "mae": 0.46706686974487766,
            "precision": 0.6058931860036832,
            "recall": 0.683991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6761380446957646,
            "auditor_fn_violation": 0.021837098030488486,
            "auditor_fp_violation": 0.014444211325580486,
            "ave_precision_score": 0.6776668064315108,
            "fpr": 0.30372807017543857,
            "logloss": 0.686406634485133,
            "mae": 0.46946226671468794,
            "precision": 0.587183308494784,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.696771433864973,
            "auditor_fn_violation": 0.017494654157661844,
            "auditor_fp_violation": 0.011339442983687748,
            "ave_precision_score": 0.6981521380696301,
            "fpr": 0.3029637760702525,
            "logloss": 0.6758815819428197,
            "mae": 0.46818724111066035,
            "precision": 0.5941176470588235,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7177857837033558,
            "auditor_fn_violation": 0.06066865101442825,
            "auditor_fp_violation": 0.07330505934540224,
            "ave_precision_score": 0.7180748501299378,
            "fpr": 0.28618421052631576,
            "logloss": 0.7738700845558774,
            "mae": 0.476015958738957,
            "precision": 0.5876777251184834,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7442876361428198,
            "auditor_fn_violation": 0.043866715655958254,
            "auditor_fp_violation": 0.0570954483955786,
            "ave_precision_score": 0.7445388767358874,
            "fpr": 0.278814489571899,
            "logloss": 0.7553061978456931,
            "mae": 0.466863407637889,
            "precision": 0.6086286594761171,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 12669,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7644992877863186,
            "auditor_fn_violation": 0.08185434516523868,
            "auditor_fp_violation": 0.0894227310873996,
            "ave_precision_score": 0.7647156367012957,
            "fpr": 0.24232456140350878,
            "logloss": 0.784897340521166,
            "mae": 0.47567086392327357,
            "precision": 0.6102292768959435,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.80398121929558,
            "auditor_fn_violation": 0.07205305448993704,
            "auditor_fp_violation": 0.0797794399203533,
            "ave_precision_score": 0.8041564573140705,
            "fpr": 0.23819978046103182,
            "logloss": 0.7679943367390755,
            "mae": 0.46686733366040317,
            "precision": 0.6212914485165794,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7236127468843623,
            "auditor_fn_violation": 0.025386206001261086,
            "auditor_fp_violation": 0.027095072533269395,
            "ave_precision_score": 0.7241636117241992,
            "fpr": 0.15899122807017543,
            "logloss": 1.2122062218987149,
            "mae": 0.4230559545023934,
            "precision": 0.6784922394678492,
            "recall": 0.6469344608879493
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7672694976336739,
            "auditor_fn_violation": 0.020459114860871177,
            "auditor_fp_violation": 0.023781686365608967,
            "ave_precision_score": 0.7676552174492277,
            "fpr": 0.15477497255762898,
            "logloss": 0.9657522986110535,
            "mae": 0.4120145010609779,
            "precision": 0.6980728051391863,
            "recall": 0.6777546777546778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7861907161196782,
            "auditor_fn_violation": 0.04433950892029228,
            "auditor_fp_violation": 0.032162910122687134,
            "ave_precision_score": 0.7865308480279709,
            "fpr": 0.12280701754385964,
            "logloss": 1.2462755256747104,
            "mae": 0.3188110744328766,
            "precision": 0.7274939172749392,
            "recall": 0.6321353065539113
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8312764979842533,
            "auditor_fn_violation": 0.05094582042990386,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.831566014305978,
            "fpr": 0.11306256860592755,
            "logloss": 0.9968127596003343,
            "mae": 0.2744408870884365,
            "precision": 0.7706013363028953,
            "recall": 0.7193347193347194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5908767747002694,
            "auditor_fn_violation": 0.09696645154111495,
            "auditor_fp_violation": 0.08530901570555091,
            "ave_precision_score": 0.5921893548865402,
            "fpr": 0.22697368421052633,
            "logloss": 0.6780464544393299,
            "mae": 0.4782279367934455,
            "precision": 0.593320235756385,
            "recall": 0.638477801268499
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6144943410278514,
            "auditor_fn_violation": 0.10076427859084282,
            "auditor_fp_violation": 0.07689479998978889,
            "ave_precision_score": 0.615743970036464,
            "fpr": 0.22063666300768386,
            "logloss": 0.6629251951706333,
            "mae": 0.47083734166445507,
            "precision": 0.6097087378640776,
            "recall": 0.6528066528066528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6820297728459079,
            "auditor_fn_violation": 0.018123400467341715,
            "auditor_fp_violation": 0.010874995004595794,
            "ave_precision_score": 0.6836337456818604,
            "fpr": 0.29605263157894735,
            "logloss": 0.6855225550240963,
            "mae": 0.4657691969748652,
            "precision": 0.5982142857142857,
            "recall": 0.8498942917547568
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7017621601943528,
            "auditor_fn_violation": 0.007626811139434631,
            "auditor_fp_violation": 0.011666198657238397,
            "ave_precision_score": 0.7032882213003625,
            "fpr": 0.29637760702524696,
            "logloss": 0.6675774922156882,
            "mae": 0.4606309441847545,
            "precision": 0.6098265895953757,
            "recall": 0.8773388773388774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7605512790920497,
            "auditor_fn_violation": 0.0006444493898594266,
            "auditor_fp_violation": 0.0020855812652359955,
            "ave_precision_score": 0.5221189388919375,
            "fpr": 0.47368421052631576,
            "logloss": 16.39785096558515,
            "mae": 0.47478070175438697,
            "precision": 0.5221238938053098,
            "recall": 0.9978858350951374
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7654525386313467,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012508615628111194,
            "ave_precision_score": 0.5309050772626932,
            "fpr": 0.4665203073545554,
            "logloss": 16.11341360784289,
            "mae": 0.46652030735455563,
            "precision": 0.5309050772626932,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7071957790148896,
            "auditor_fn_violation": 0.007552575943028824,
            "auditor_fp_violation": 0.012121348359509255,
            "ave_precision_score": 0.6536254259719074,
            "fpr": 0.19736842105263158,
            "logloss": 3.8019839490147818,
            "mae": 0.3162925213317287,
            "precision": 0.6739130434782609,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7087642228211876,
            "auditor_fn_violation": 0.008290905107590072,
            "auditor_fp_violation": 0.003890434738212552,
            "ave_precision_score": 0.6516700067057325,
            "fpr": 0.2074643249176729,
            "logloss": 4.072218926742123,
            "mae": 0.30387546927869924,
            "precision": 0.6802030456852792,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7712323722881886,
            "auditor_fn_violation": 0.005635454916360669,
            "auditor_fp_violation": 0.021005674779203135,
            "ave_precision_score": 0.7703958827852819,
            "fpr": 0.33771929824561403,
            "logloss": 1.792607087864097,
            "mae": 0.36867034948540467,
            "precision": 0.5942028985507246,
            "recall": 0.9534883720930233
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7883979831903232,
            "auditor_fn_violation": 0.0017937383469765473,
            "auditor_fp_violation": 0.009338064483189953,
            "ave_precision_score": 0.7882649388515679,
            "fpr": 0.3468715697036224,
            "logloss": 1.842490583755303,
            "mae": 0.3627367065361499,
            "precision": 0.597452229299363,
            "recall": 0.975051975051975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5904449633746678,
            "auditor_fn_violation": 0.09014641519231482,
            "auditor_fp_violation": 0.10853514766414898,
            "ave_precision_score": 0.5919466663123467,
            "fpr": 0.30043859649122806,
            "logloss": 0.6853614617742595,
            "mae": 0.49501004609496885,
            "precision": 0.5608974358974359,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5845944169736398,
            "auditor_fn_violation": 0.092286240475044,
            "auditor_fp_violation": 0.09667372935440227,
            "ave_precision_score": 0.5861603054762647,
            "fpr": 0.3029637760702525,
            "logloss": 0.6870478460120619,
            "mae": 0.4960009871146812,
            "precision": 0.5639810426540285,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7054513759577244,
            "auditor_fn_violation": 0.0048333704239457,
            "auditor_fp_violation": 0.010432901730408024,
            "ave_precision_score": 0.6518821527902569,
            "fpr": 0.20833333333333334,
            "logloss": 3.8083682114895745,
            "mae": 0.31850827679442517,
            "precision": 0.6654929577464789,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7068113589269882,
            "auditor_fn_violation": 0.011321546996629328,
            "auditor_fp_violation": 0.004615423888903071,
            "ave_precision_score": 0.6497182634144137,
            "fpr": 0.21514818880351264,
            "logloss": 4.086583280428927,
            "mae": 0.3075893567043855,
            "precision": 0.6760330578512397,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8404196394628973,
            "auditor_fn_violation": 0.010301917584659325,
            "auditor_fp_violation": 0.028116632697917924,
            "ave_precision_score": 0.8407133048623985,
            "fpr": 0.16228070175438597,
            "logloss": 0.6803799556700707,
            "mae": 0.2804457363657735,
            "precision": 0.7196969696969697,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8684587098467778,
            "auditor_fn_violation": 0.013548886216284682,
            "auditor_fp_violation": 0.007206494269011817,
            "ave_precision_score": 0.8687255749651656,
            "fpr": 0.15477497255762898,
            "logloss": 0.5955414503141894,
            "mae": 0.2539894099768245,
            "precision": 0.7454873646209387,
            "recall": 0.8586278586278586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7070810193081987,
            "auditor_fn_violation": 0.008781202477652907,
            "auditor_fp_violation": 0.012121348359509255,
            "ave_precision_score": 0.653510737313346,
            "fpr": 0.19736842105263158,
            "logloss": 3.8009972261429628,
            "mae": 0.3165091886493669,
            "precision": 0.674502712477396,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7088614384558036,
            "auditor_fn_violation": 0.008290905107590072,
            "auditor_fp_violation": 0.003890434738212552,
            "ave_precision_score": 0.6517671752070319,
            "fpr": 0.2074643249176729,
            "logloss": 4.069951617330869,
            "mae": 0.3038745462691997,
            "precision": 0.6802030456852792,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8191765952975781,
            "auditor_fn_violation": 0.010158191461741038,
            "auditor_fp_violation": 0.0046732006553970385,
            "ave_precision_score": 0.818505744084187,
            "fpr": 0.10635964912280702,
            "logloss": 0.6234811100133625,
            "mae": 0.338490376525238,
            "precision": 0.7805429864253394,
            "recall": 0.7293868921775899
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8783052094267529,
            "auditor_fn_violation": 0.005438267787334753,
            "auditor_fp_violation": 0.006022004952390681,
            "ave_precision_score": 0.8769699043878663,
            "fpr": 0.0889132821075741,
            "logloss": 0.5456084052192794,
            "mae": 0.3142617569204721,
            "precision": 0.824295010845987,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7862685122776674,
            "auditor_fn_violation": 0.04433950892029228,
            "auditor_fp_violation": 0.032162910122687134,
            "ave_precision_score": 0.7866086740905311,
            "fpr": 0.12280701754385964,
            "logloss": 1.2522862560089196,
            "mae": 0.3188403562646175,
            "precision": 0.7274939172749392,
            "recall": 0.6321353065539113
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8310734184276218,
            "auditor_fn_violation": 0.050051233366271784,
            "auditor_fp_violation": 0.028596226993081977,
            "ave_precision_score": 0.8313633755566239,
            "fpr": 0.11306256860592755,
            "logloss": 1.002491376615239,
            "mae": 0.2745192921572063,
            "precision": 0.7711111111111111,
            "recall": 0.7214137214137214
        }
    }
]