[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 14289,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7563691826321078,
            "auditor_fn_violation": 0.019727909386500878,
            "auditor_fp_violation": 0.03168104346376631,
            "ave_precision_score": 0.6949880681184915,
            "fpr": 0.1962719298245614,
            "logloss": 4.9482453293732656,
            "mae": 0.31087637313389643,
            "precision": 0.6859649122807018,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7057812831341377,
            "auditor_fn_violation": 0.032269383323099254,
            "auditor_fp_violation": 0.02618786263133135,
            "ave_precision_score": 0.6377908228733913,
            "fpr": 0.24039517014270034,
            "logloss": 5.672089626872993,
            "mae": 0.3533369536497409,
            "precision": 0.6217616580310881,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 14289,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7713990155315593,
            "auditor_fn_violation": 0.0066749740951155935,
            "auditor_fp_violation": 0.01811684793932575,
            "ave_precision_score": 0.7730393037044667,
            "fpr": 0.20285087719298245,
            "logloss": 1.0829342257238928,
            "mae": 0.3390547958647326,
            "precision": 0.669051878354204,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7815972955773332,
            "auditor_fn_violation": 0.01438857449033056,
            "auditor_fp_violation": 0.020892955151325086,
            "ave_precision_score": 0.7829377831090604,
            "fpr": 0.2491767288693743,
            "logloss": 1.032780200366933,
            "mae": 0.3542137628042958,
            "precision": 0.6152542372881356,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8329954144493777,
            "auditor_fn_violation": 0.013917175831636121,
            "auditor_fp_violation": 0.01916906279951661,
            "ave_precision_score": 0.8332473258698206,
            "fpr": 0.17653508771929824,
            "logloss": 0.9980340779188368,
            "mae": 0.2798048379124149,
            "precision": 0.7145390070921985,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8271589563580497,
            "auditor_fn_violation": 0.009234387483907987,
            "auditor_fp_violation": 0.025141622236161208,
            "ave_precision_score": 0.8274548610917528,
            "fpr": 0.1964873765093304,
            "logloss": 0.9905583450411034,
            "mae": 0.27943654786471533,
            "precision": 0.6897746967071057,
            "recall": 0.8596112311015118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8361763000917966,
            "auditor_fn_violation": 0.013419176760638876,
            "auditor_fp_violation": 0.017101095970329626,
            "ave_precision_score": 0.8364342222238839,
            "fpr": 0.15460526315789475,
            "logloss": 0.942721138782352,
            "mae": 0.27550518717375794,
            "precision": 0.7374301675977654,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8314474138265616,
            "auditor_fn_violation": 0.0064510316671922,
            "auditor_fp_violation": 0.027126293711776706,
            "ave_precision_score": 0.8317287025722173,
            "fpr": 0.18111964873765093,
            "logloss": 0.924502541227588,
            "mae": 0.27289154386858394,
            "precision": 0.701627486437613,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8274812167615565,
            "auditor_fn_violation": 0.014048933433379786,
            "auditor_fp_violation": 0.014626828353544195,
            "ave_precision_score": 0.8276704500315168,
            "fpr": 0.13596491228070176,
            "logloss": 1.7903854244333912,
            "mae": 0.291762546702658,
            "precision": 0.7432712215320911,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8132362176698574,
            "auditor_fn_violation": 0.013188933908338928,
            "auditor_fp_violation": 0.024600125450838953,
            "ave_precision_score": 0.8135001225775473,
            "fpr": 0.16245883644346873,
            "logloss": 1.645184280390123,
            "mae": 0.28620999945232545,
            "precision": 0.7063492063492064,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7745049588356561,
            "auditor_fn_violation": 0.02080206881766535,
            "auditor_fp_violation": 0.0020888027670125553,
            "ave_precision_score": 0.7547795862189942,
            "fpr": 0.1425438596491228,
            "logloss": 3.370873241030711,
            "mae": 0.3161797101729017,
            "precision": 0.7180043383947939,
            "recall": 0.6741344195519349
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.78070972353847,
            "auditor_fn_violation": 0.009578158006415472,
            "auditor_fp_violation": 0.014740473576917051,
            "ave_precision_score": 0.7657524990775874,
            "fpr": 0.1668496158068057,
            "logloss": 3.229897386411584,
            "mae": 0.32134080819913385,
            "precision": 0.678646934460888,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6143340025241594,
            "auditor_fn_violation": 0.004725408225247438,
            "auditor_fp_violation": 0.021961078468141854,
            "ave_precision_score": 0.5834439410151808,
            "fpr": 0.2412280701754386,
            "logloss": 4.655656469048476,
            "mae": 0.444259291542229,
            "precision": 0.5801526717557252,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5633999500608542,
            "auditor_fn_violation": 0.0010668740353680572,
            "auditor_fp_violation": 0.02250764466049867,
            "ave_precision_score": 0.5305061258169967,
            "fpr": 0.24368825466520308,
            "logloss": 4.960446999517524,
            "mae": 0.453544043999174,
            "precision": 0.5487804878048781,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8213243596352183,
            "auditor_fn_violation": 0.03492916354021511,
            "auditor_fp_violation": 0.01752823269575364,
            "ave_precision_score": 0.8217589932093222,
            "fpr": 0.13925438596491227,
            "logloss": 0.612978267797739,
            "mae": 0.31197819228170526,
            "precision": 0.7449799196787149,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8380035534770862,
            "auditor_fn_violation": 0.03447425632952657,
            "auditor_fp_violation": 0.015159459777324762,
            "ave_precision_score": 0.838251992936461,
            "fpr": 0.16355653128430298,
            "logloss": 0.5799912238069624,
            "mae": 0.3022130369534414,
            "precision": 0.7134615384615385,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8222247142724851,
            "auditor_fn_violation": 0.0058397648908421786,
            "auditor_fp_violation": 0.018489290327957663,
            "ave_precision_score": 0.8224815323181546,
            "fpr": 0.13157894736842105,
            "logloss": 1.4243176491928937,
            "mae": 0.29224857886816463,
            "precision": 0.7424892703862661,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8018938786904485,
            "auditor_fn_violation": 0.011138164929242547,
            "auditor_fp_violation": 0.022414536615963623,
            "ave_precision_score": 0.8022428589440953,
            "fpr": 0.13611416026344675,
            "logloss": 1.2858123002454356,
            "mae": 0.2823694810051026,
            "precision": 0.7356076759061834,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7930987430437062,
            "auditor_fn_violation": 0.013164594275913818,
            "auditor_fp_violation": 0.007154540150852193,
            "ave_precision_score": 0.7888877985670057,
            "fpr": 0.14144736842105263,
            "logloss": 1.4025105396249349,
            "mae": 0.28951982448035257,
            "precision": 0.7378048780487805,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7980972910706791,
            "auditor_fn_violation": 0.006500819122176044,
            "auditor_fp_violation": 0.010839736553238201,
            "ave_precision_score": 0.7920856577347494,
            "fpr": 0.13830954994511527,
            "logloss": 1.260918897389695,
            "mae": 0.26840636806674795,
            "precision": 0.7412731006160165,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8372188704316332,
            "auditor_fn_violation": 0.021806999678422125,
            "auditor_fp_violation": 0.013131849814560155,
            "ave_precision_score": 0.8376956801045012,
            "fpr": 0.12280701754385964,
            "logloss": 0.9031184330426353,
            "mae": 0.2731057431507267,
            "precision": 0.7666666666666667,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8327810520777017,
            "auditor_fn_violation": 0.00701528949034242,
            "auditor_fp_violation": 0.019315018817625845,
            "ave_precision_score": 0.8331833259039252,
            "fpr": 0.12623490669593854,
            "logloss": 0.8228687158101466,
            "mae": 0.25810538888283535,
            "precision": 0.7578947368421053,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7126341464211235,
            "auditor_fn_violation": 0.0023269732375745893,
            "auditor_fp_violation": 0.005453806725840737,
            "ave_precision_score": 0.7136134567541706,
            "fpr": 0.16557017543859648,
            "logloss": 1.140884965422483,
            "mae": 0.36530888503480674,
            "precision": 0.6827731092436975,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6750502518584256,
            "auditor_fn_violation": 0.015007361430844047,
            "auditor_fp_violation": 0.012104045789556225,
            "ave_precision_score": 0.67683665104544,
            "fpr": 0.1712403951701427,
            "logloss": 1.1976632993617755,
            "mae": 0.3598032007513986,
            "precision": 0.6578947368421053,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7369689736564868,
            "auditor_fn_violation": 0.014345946332225681,
            "auditor_fp_violation": 0.016272867441763563,
            "ave_precision_score": 0.7357456018328699,
            "fpr": 0.20285087719298245,
            "logloss": 1.6869588340128086,
            "mae": 0.31689432406214446,
            "precision": 0.6788194444444444,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7121132011362828,
            "auditor_fn_violation": 0.0042011128681604505,
            "auditor_fp_violation": 0.016230202289477812,
            "ave_precision_score": 0.7117384869944681,
            "fpr": 0.2283205268935236,
            "logloss": 1.7340350306302,
            "mae": 0.32809884025533387,
            "precision": 0.6486486486486487,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7622266495691853,
            "auditor_fn_violation": 0.043448744059742035,
            "auditor_fp_violation": 0.016324957286327463,
            "ave_precision_score": 0.7638591177211127,
            "fpr": 0.14035087719298245,
            "logloss": 1.8412349817079787,
            "mae": 0.3379510777007609,
            "precision": 0.7247311827956989,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7656765990634349,
            "auditor_fn_violation": 0.04809231068320242,
            "auditor_fp_violation": 0.020067233809001106,
            "ave_precision_score": 0.7666805546349318,
            "fpr": 0.19978046103183314,
            "logloss": 1.7123129513707116,
            "mae": 0.34958017041369,
            "precision": 0.649325626204239,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.5219130741492982,
            "auditor_fn_violation": 0.024667702862043093,
            "auditor_fp_violation": 0.015944701421010964,
            "ave_precision_score": 0.5088896586093534,
            "fpr": 0.20723684210526316,
            "logloss": 6.028825835011877,
            "mae": 0.5376117092918725,
            "precision": 0.4973404255319149,
            "recall": 0.38085539714867617
        },
        "train": {
            "accuracy": 0.43907793633369924,
            "auc_prc": 0.4842174530082761,
            "auditor_fn_violation": 0.019021178635017674,
            "auditor_fp_violation": 0.01833248392661126,
            "ave_precision_score": 0.4690009243010938,
            "fpr": 0.22941822173435786,
            "logloss": 6.144920768006082,
            "mae": 0.5551056160106453,
            "precision": 0.43513513513513513,
            "recall": 0.34773218142548595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8377102211402382,
            "auditor_fn_violation": 0.01612579054561046,
            "auditor_fp_violation": 0.010391923990498817,
            "ave_precision_score": 0.8379076739057011,
            "fpr": 0.11951754385964912,
            "logloss": 1.2931065146916272,
            "mae": 0.2948257362891501,
            "precision": 0.7577777777777778,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8272289796942158,
            "auditor_fn_violation": 0.00977019533278172,
            "auditor_fp_violation": 0.026396130625686055,
            "ave_precision_score": 0.827475988370981,
            "fpr": 0.11525795828759605,
            "logloss": 1.142461072103039,
            "mae": 0.2752906437286357,
            "precision": 0.7645739910313901,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8259603772891209,
            "auditor_fn_violation": 0.018146818165576877,
            "auditor_fp_violation": 0.006831583114555986,
            "ave_precision_score": 0.8262013115880738,
            "fpr": 0.09539473684210527,
            "logloss": 1.3988739398208256,
            "mae": 0.2923051700964406,
            "precision": 0.7898550724637681,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7983371518105458,
            "auditor_fn_violation": 0.021726297022473126,
            "auditor_fp_violation": 0.01961394464481732,
            "ave_precision_score": 0.7991591951491824,
            "fpr": 0.09549945115257959,
            "logloss": 1.2437831381661144,
            "mae": 0.2842950049698898,
            "precision": 0.779746835443038,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7835866895933703,
            "auditor_fn_violation": 0.023356826383678142,
            "auditor_fp_violation": 0.018713276659582452,
            "ave_precision_score": 0.7736979445498603,
            "fpr": 0.1425438596491228,
            "logloss": 2.8896415938880216,
            "mae": 0.3293387792614782,
            "precision": 0.7111111111111111,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7744501550923484,
            "auditor_fn_violation": 0.013904924927630383,
            "auditor_fp_violation": 0.03005674690293242,
            "ave_precision_score": 0.7641393349584695,
            "fpr": 0.1350164654226125,
            "logloss": 2.5185953954398452,
            "mae": 0.29063120585987523,
            "precision": 0.7248322147651006,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8414652945668992,
            "auditor_fn_violation": 0.022432289991781904,
            "auditor_fp_violation": 0.01822623661290995,
            "ave_precision_score": 0.8418440608704415,
            "fpr": 0.11074561403508772,
            "logloss": 0.8472926783790762,
            "mae": 0.28148013822847295,
            "precision": 0.7760532150776053,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8378502793425451,
            "auditor_fn_violation": 0.024936402453336122,
            "auditor_fp_violation": 0.028628273482828915,
            "ave_precision_score": 0.8380814442957568,
            "fpr": 0.10867178924259056,
            "logloss": 0.7620833678224707,
            "mae": 0.26692075364024576,
            "precision": 0.7729357798165137,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7430966016746992,
            "auditor_fn_violation": 0.022834262336084616,
            "auditor_fp_violation": 0.006378401466850022,
            "ave_precision_score": 0.7404596657669799,
            "fpr": 0.043859649122807015,
            "logloss": 5.052363008642507,
            "mae": 0.4066328759131932,
            "precision": 0.8086124401913876,
            "recall": 0.34419551934826886
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7727670441072397,
            "auditor_fn_violation": 0.02487950250478315,
            "auditor_fp_violation": 0.009276501489728712,
            "ave_precision_score": 0.769886716532242,
            "fpr": 0.029637760702524697,
            "logloss": 4.147803848307267,
            "mae": 0.3550616404611534,
            "precision": 0.8789237668161435,
            "recall": 0.42332613390928725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8423903521707372,
            "auditor_fn_violation": 0.01705702647657841,
            "auditor_fp_violation": 0.00999864566404134,
            "ave_precision_score": 0.8426087224518891,
            "fpr": 0.1162280701754386,
            "logloss": 1.3380924404773027,
            "mae": 0.2848754867993115,
            "precision": 0.7680525164113785,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8348001507931798,
            "auditor_fn_violation": 0.009708553721849344,
            "auditor_fp_violation": 0.02740071742198526,
            "ave_precision_score": 0.8350259101585474,
            "fpr": 0.11745334796926454,
            "logloss": 1.185443637330598,
            "mae": 0.2682456855723253,
            "precision": 0.7663755458515283,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7591926345487714,
            "auditor_fn_violation": 0.024727998713688498,
            "auditor_fp_violation": 0.0017814726840855077,
            "ave_precision_score": 0.7596830755866706,
            "fpr": 0.14035087719298245,
            "logloss": 1.0525560913948817,
            "mae": 0.3272298299351848,
            "precision": 0.7293868921775899,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.754889407663309,
            "auditor_fn_violation": 0.024642419385812474,
            "auditor_fp_violation": 0.0124544260624118,
            "ave_precision_score": 0.7553675229612408,
            "fpr": 0.17233809001097694,
            "logloss": 1.1027941648755792,
            "mae": 0.3264158580026927,
            "precision": 0.6847389558232931,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8438227339554927,
            "auditor_fn_violation": 0.01907135455747312,
            "auditor_fp_violation": 0.013884548068508569,
            "ave_precision_score": 0.8440527908786946,
            "fpr": 0.13048245614035087,
            "logloss": 1.3157541883083597,
            "mae": 0.28450079768672154,
            "precision": 0.7510460251046025,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8333291088263024,
            "auditor_fn_violation": 0.012899692503194697,
            "auditor_fp_violation": 0.02516122392974753,
            "ave_precision_score": 0.83357018854724,
            "fpr": 0.13062568605927552,
            "logloss": 1.183284719308547,
            "mae": 0.26881365317406775,
            "precision": 0.7525987525987526,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7512995679221836,
            "auditor_fn_violation": 0.008901454246614503,
            "auditor_fp_violation": 0.015361295161895244,
            "ave_precision_score": 0.7517130355824492,
            "fpr": 0.18859649122807018,
            "logloss": 1.1791572927167604,
            "mae": 0.3323506198061009,
            "precision": 0.6884057971014492,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7339067850930581,
            "auditor_fn_violation": 0.001109548996782781,
            "auditor_fp_violation": 0.013343852908891332,
            "ave_precision_score": 0.7356083663821599,
            "fpr": 0.23380900109769484,
            "logloss": 1.1328634741021555,
            "mae": 0.35072662498149354,
            "precision": 0.634020618556701,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7143740196741479,
            "auditor_fn_violation": 0.013923875370707833,
            "auditor_fp_violation": 0.019791536442055255,
            "ave_precision_score": 0.6963192088172163,
            "fpr": 0.20723684210526316,
            "logloss": 2.143699319899307,
            "mae": 0.3128081037057359,
            "precision": 0.6926829268292682,
            "recall": 0.8676171079429735
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6684557036684976,
            "auditor_fn_violation": 0.007231035128605739,
            "auditor_fp_violation": 0.023620040771522664,
            "ave_precision_score": 0.6474594775889324,
            "fpr": 0.23710208562019758,
            "logloss": 2.557486632118919,
            "mae": 0.3249010200215847,
            "precision": 0.6549520766773163,
            "recall": 0.8855291576673866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 14289,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7437172170214478,
            "auditor_fn_violation": 0.028604798656519104,
            "auditor_fp_violation": 0.03889548693586699,
            "ave_precision_score": 0.6854857141847552,
            "fpr": 0.22149122807017543,
            "logloss": 4.154765258322566,
            "mae": 0.323149884193509,
            "precision": 0.672077922077922,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.6880664977135362,
            "auditor_fn_violation": 0.016323172741131316,
            "auditor_fp_violation": 0.035287948878783136,
            "ave_precision_score": 0.6240112320395651,
            "fpr": 0.265642151481888,
            "logloss": 4.774582473999553,
            "mae": 0.363295666568595,
            "precision": 0.6182965299684543,
            "recall": 0.8466522678185745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8104629892172726,
            "auditor_fn_violation": 0.016016364740772514,
            "auditor_fp_violation": 0.019195107721798565,
            "ave_precision_score": 0.8102905638928835,
            "fpr": 0.13267543859649122,
            "logloss": 1.244415848588171,
            "mae": 0.27945680532508255,
            "precision": 0.7525562372188139,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8074042530630321,
            "auditor_fn_violation": 0.007894867861723642,
            "auditor_fp_violation": 0.022894778108828607,
            "ave_precision_score": 0.8076196529720125,
            "fpr": 0.15916575192096596,
            "logloss": 1.238744017780798,
            "mae": 0.27848584119934156,
            "precision": 0.7140039447731755,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7744091534274982,
            "auditor_fn_violation": 0.012950209025619042,
            "auditor_fp_violation": 0.018171542276117846,
            "ave_precision_score": 0.6661269271901319,
            "fpr": 0.17653508771929824,
            "logloss": 10.200090980371222,
            "mae": 0.3338846737772161,
            "precision": 0.6830708661417323,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7720757144824106,
            "auditor_fn_violation": 0.011780660181653094,
            "auditor_fp_violation": 0.027373765093304067,
            "ave_precision_score": 0.659512591543028,
            "fpr": 0.17672886937431395,
            "logloss": 9.479578741648382,
            "mae": 0.31636541483987174,
            "precision": 0.6754032258064516,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7398441463676735,
            "auditor_fn_violation": 0.0509075642262479,
            "auditor_fp_violation": 0.01759334500145852,
            "ave_precision_score": 0.7405046612271655,
            "fpr": 0.2225877192982456,
            "logloss": 1.0282276083627713,
            "mae": 0.341690393750996,
            "precision": 0.6535836177474402,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7083613986390913,
            "auditor_fn_violation": 0.034827510176792885,
            "auditor_fp_violation": 0.022799219852595264,
            "ave_precision_score": 0.7101130506259756,
            "fpr": 0.2711306256860593,
            "logloss": 1.092778645780445,
            "mae": 0.3560127588437041,
            "precision": 0.6097946287519748,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8362631708708583,
            "auditor_fn_violation": 0.01956042090970808,
            "auditor_fp_violation": 0.008576592907446763,
            "ave_precision_score": 0.8363407706435423,
            "fpr": 0.1118421052631579,
            "logloss": 2.0753110859487633,
            "mae": 0.2866030752471359,
            "precision": 0.7676537585421412,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8247508287093116,
            "auditor_fn_violation": 0.023442778803820837,
            "auditor_fp_violation": 0.025442998275050966,
            "ave_precision_score": 0.8251345248021233,
            "fpr": 0.11855104281009879,
            "logloss": 1.912891781954907,
            "mae": 0.27602551342029014,
            "precision": 0.7551020408163265,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7534424277404366,
            "auditor_fn_violation": 0.02036213241862293,
            "auditor_fp_violation": 0.016140038338125603,
            "ave_precision_score": 0.7407806966291332,
            "fpr": 0.12719298245614036,
            "logloss": 3.2257811128731313,
            "mae": 0.311490691131294,
            "precision": 0.7375565610859729,
            "recall": 0.6639511201629328
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7268847081537455,
            "auditor_fn_violation": 0.006026652884234693,
            "auditor_fp_violation": 0.010212482358475775,
            "ave_precision_score": 0.7137453729140851,
            "fpr": 0.1602634467618002,
            "logloss": 3.4516931131347808,
            "mae": 0.3265372809536524,
            "precision": 0.6846652267818575,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 14289,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7634433583856391,
            "auditor_fn_violation": 0.021947689998928075,
            "auditor_fp_violation": 0.004563070383797972,
            "ave_precision_score": 0.7573524438721999,
            "fpr": 0.14692982456140352,
            "logloss": 2.862201252028436,
            "mae": 0.31078873531384643,
            "precision": 0.7208333333333333,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7491051816392902,
            "auditor_fn_violation": 0.014438361945314407,
            "auditor_fp_violation": 0.01481888035126235,
            "ave_precision_score": 0.7450896044772886,
            "fpr": 0.18551042810098792,
            "logloss": 2.882389516967325,
            "mae": 0.3318609445081585,
            "precision": 0.6626746506986028,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8329571770106184,
            "auditor_fn_violation": 0.03021715439311109,
            "auditor_fp_violation": 0.012306225778222274,
            "ave_precision_score": 0.8336724544582941,
            "fpr": 0.11074561403508772,
            "logloss": 0.7649929788853324,
            "mae": 0.3200856892384563,
            "precision": 0.773542600896861,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8375634507050859,
            "auditor_fn_violation": 0.028919398852043546,
            "auditor_fp_violation": 0.02472508624745178,
            "ave_precision_score": 0.8379027723368697,
            "fpr": 0.12843029637760703,
            "logloss": 0.7044904012683638,
            "mae": 0.31301731640132285,
            "precision": 0.7521186440677966,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.5951376296878497,
            "auditor_fn_violation": 0.013218190588487515,
            "auditor_fp_violation": 0.01751000125015627,
            "ave_precision_score": 0.5894108022860851,
            "fpr": 0.25109649122807015,
            "logloss": 2.487747541010564,
            "mae": 0.4060228884872258,
            "precision": 0.6125211505922166,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.5519647411088785,
            "auditor_fn_violation": 0.003186397118965937,
            "auditor_fp_violation": 0.021233534577387494,
            "ave_precision_score": 0.5491086374312085,
            "fpr": 0.27991218441273324,
            "logloss": 2.937153123472793,
            "mae": 0.4141319900534094,
            "precision": 0.5785123966942148,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7402054860429134,
            "auditor_fn_violation": 0.01862025225997785,
            "auditor_fp_violation": 0.043661707713464185,
            "ave_precision_score": 0.6807439544035248,
            "fpr": 0.23574561403508773,
            "logloss": 4.223090901175599,
            "mae": 0.32014823373045936,
            "precision": 0.6640625,
            "recall": 0.8655804480651731
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.690663798462905,
            "auditor_fn_violation": 0.013606200197727325,
            "auditor_fp_violation": 0.041812862631331355,
            "ave_precision_score": 0.6265669904452805,
            "fpr": 0.29088913282107576,
            "logloss": 4.771887628118843,
            "mae": 0.3714356893753666,
            "precision": 0.5984848484848485,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6210972220886772,
            "auditor_fn_violation": 0.006221638617929762,
            "auditor_fp_violation": 0.02078905696545402,
            "ave_precision_score": 0.5819125301369035,
            "fpr": 0.2642543859649123,
            "logloss": 5.1134022091311335,
            "mae": 0.44428837535171034,
            "precision": 0.5704099821746881,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5680477457692846,
            "auditor_fn_violation": 0.005066466252403436,
            "auditor_fp_violation": 0.01708777638387958,
            "ave_precision_score": 0.5282764062511358,
            "fpr": 0.2623490669593853,
            "logloss": 5.397490593994957,
            "mae": 0.45094311810748033,
            "precision": 0.5473484848484849,
            "recall": 0.6241900647948164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.786164338151385,
            "auditor_fn_violation": 0.045668524672169225,
            "auditor_fp_violation": 0.019916552069008633,
            "ave_precision_score": 0.7877416494034343,
            "fpr": 0.24780701754385964,
            "logloss": 0.8888691682855765,
            "mae": 0.34698781278287544,
            "precision": 0.6384,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.8010118502526715,
            "auditor_fn_violation": 0.023596882831151775,
            "auditor_fp_violation": 0.02716794731064764,
            "ave_precision_score": 0.8023937393302223,
            "fpr": 0.27661909989023054,
            "logloss": 0.877277736009999,
            "mae": 0.3514594993295348,
            "precision": 0.6086956521739131,
            "recall": 0.8466522678185745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8072243216871235,
            "auditor_fn_violation": 0.050032157787544225,
            "auditor_fp_violation": 0.03333229153644206,
            "ave_precision_score": 0.8078034710520621,
            "fpr": 0.1118421052631579,
            "logloss": 1.5201995140432456,
            "mae": 0.30719446251445737,
            "precision": 0.7553956834532374,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.785075183637477,
            "auditor_fn_violation": 0.043601956409897745,
            "auditor_fp_violation": 0.033857025246981344,
            "ave_precision_score": 0.7855835896863002,
            "fpr": 0.11525795828759605,
            "logloss": 1.4881264569749584,
            "mae": 0.2837152020526949,
            "precision": 0.7575057736720554,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5727736570135323,
            "auditor_fn_violation": 0.01207256940722479,
            "auditor_fp_violation": 0.045492665749885405,
            "ave_precision_score": 0.5375136064041405,
            "fpr": 0.24232456140350878,
            "logloss": 7.4234709160401895,
            "mae": 0.4687710465721682,
            "precision": 0.5606361829025845,
            "recall": 0.5743380855397149
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5178719087826174,
            "auditor_fn_violation": 0.013935745733096569,
            "auditor_fp_violation": 0.05182687784224558,
            "ave_precision_score": 0.48038253289202204,
            "fpr": 0.2854006586169045,
            "logloss": 8.130196078174599,
            "mae": 0.4921690719246639,
            "precision": 0.5085066162570888,
            "recall": 0.5809935205183585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8437229278904474,
            "auditor_fn_violation": 0.005243505913459827,
            "auditor_fp_violation": 0.014587760970121268,
            "ave_precision_score": 0.8439923941038054,
            "fpr": 0.1337719298245614,
            "logloss": 0.8487151704596158,
            "mae": 0.26933076058857575,
            "precision": 0.7564870259481038,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8318096026886421,
            "auditor_fn_violation": 0.012603338604481347,
            "auditor_fp_violation": 0.027628587109926297,
            "ave_precision_score": 0.8320770177714915,
            "fpr": 0.14489571899012074,
            "logloss": 0.8158085105651811,
            "mae": 0.2581491898867601,
            "precision": 0.7386138613861386,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8512788876171455,
            "auditor_fn_violation": 0.017354039375424308,
            "auditor_fp_violation": 0.01212651581447681,
            "ave_precision_score": 0.8524801762159141,
            "fpr": 0.11293859649122807,
            "logloss": 0.6943100233674183,
            "mae": 0.27357779986418035,
            "precision": 0.7822410147991543,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8493467433646613,
            "auditor_fn_violation": 0.012380480472648909,
            "auditor_fp_violation": 0.01915820526893524,
            "ave_precision_score": 0.8495319629020441,
            "fpr": 0.11525795828759605,
            "logloss": 0.6310872703872037,
            "mae": 0.25621802791847065,
            "precision": 0.7741935483870968,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.859028743752632,
            "auditor_fn_violation": 0.005125147389859578,
            "auditor_fp_violation": 0.007584281368504397,
            "ave_precision_score": 0.859359292112376,
            "fpr": 0.07675438596491228,
            "logloss": 0.5014126835193565,
            "mae": 0.31050900990253705,
            "precision": 0.8325358851674641,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8667211646165398,
            "auditor_fn_violation": 0.0018705858086786739,
            "auditor_fp_violation": 0.011839422926140819,
            "ave_precision_score": 0.8669529873859867,
            "fpr": 0.08781558726673985,
            "logloss": 0.46745864698977657,
            "mae": 0.3015927422139231,
            "precision": 0.8090692124105012,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7700660363941428,
            "auditor_fn_violation": 0.007135009111373143,
            "auditor_fp_violation": 0.027045047297578863,
            "ave_precision_score": 0.7717026115230784,
            "fpr": 0.20723684210526316,
            "logloss": 1.1679946367773513,
            "mae": 0.34112045108770855,
            "precision": 0.6637010676156584,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7802959954140851,
            "auditor_fn_violation": 0.014936236495152837,
            "auditor_fp_violation": 0.023747451779833784,
            "ave_precision_score": 0.7816370905536473,
            "fpr": 0.2513721185510428,
            "logloss": 1.1293916453613546,
            "mae": 0.35742045202584044,
            "precision": 0.6138279932546374,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8408418290566833,
            "auditor_fn_violation": 0.026916514810447715,
            "auditor_fp_violation": 0.024643705463182897,
            "ave_precision_score": 0.841359661330595,
            "fpr": 0.13706140350877194,
            "logloss": 0.7702645542037607,
            "mae": 0.2774540774088127,
            "precision": 0.7433264887063655,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8354866993448228,
            "auditor_fn_violation": 0.0193839158070428,
            "auditor_fp_violation": 0.036841383095499454,
            "ave_precision_score": 0.8358103590841504,
            "fpr": 0.12733260153677278,
            "logloss": 0.7295135444076571,
            "mae": 0.2531327347088345,
            "precision": 0.7603305785123967,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8101419595784674,
            "auditor_fn_violation": 0.05036266838174867,
            "auditor_fp_violation": 0.03306663332916615,
            "ave_precision_score": 0.8107001877414253,
            "fpr": 0.1118421052631579,
            "logloss": 1.4885412331549066,
            "mae": 0.3064274881700914,
            "precision": 0.7571428571428571,
            "recall": 0.6476578411405295
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7879186271912448,
            "auditor_fn_violation": 0.04350712316230949,
            "auditor_fp_violation": 0.035900501803355814,
            "ave_precision_score": 0.788440783299029,
            "fpr": 0.11855104281009879,
            "logloss": 1.4511425835513858,
            "mae": 0.28353750648272785,
            "precision": 0.7534246575342466,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8437215344184067,
            "auditor_fn_violation": 0.005243505913459827,
            "auditor_fp_violation": 0.014587760970121268,
            "ave_precision_score": 0.8439634568071207,
            "fpr": 0.1337719298245614,
            "logloss": 0.8489086530476754,
            "mae": 0.2694632821257562,
            "precision": 0.7564870259481038,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8318288617961649,
            "auditor_fn_violation": 0.012603338604481347,
            "auditor_fp_violation": 0.027628587109926297,
            "ave_precision_score": 0.832079102228468,
            "fpr": 0.14489571899012074,
            "logloss": 0.8154606017741319,
            "mae": 0.25814227834191217,
            "precision": 0.7386138613861386,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7460104939576115,
            "auditor_fn_violation": 0.02732072033444099,
            "auditor_fp_violation": 0.0416458307288411,
            "ave_precision_score": 0.7046746875225547,
            "fpr": 0.19078947368421054,
            "logloss": 3.1994265724391378,
            "mae": 0.29380735120822177,
            "precision": 0.6979166666666666,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7479891863190365,
            "auditor_fn_violation": 0.021107510081959633,
            "auditor_fp_violation": 0.03885790732319273,
            "ave_precision_score": 0.7065975189816043,
            "fpr": 0.20087815587266739,
            "logloss": 3.027424175868677,
            "mae": 0.2935193862771915,
            "precision": 0.6822916666666666,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.842286649763845,
            "auditor_fn_violation": 0.011936345446099986,
            "auditor_fp_violation": 0.013780368379380762,
            "ave_precision_score": 0.8425033934395993,
            "fpr": 0.11842105263157894,
            "logloss": 0.8525373967217615,
            "mae": 0.27593937518529793,
            "precision": 0.7672413793103449,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.84226241111735,
            "auditor_fn_violation": 0.00408731297105452,
            "auditor_fp_violation": 0.019160655480633528,
            "ave_precision_score": 0.8424808423827034,
            "fpr": 0.11855104281009879,
            "logloss": 0.7770644525128357,
            "mae": 0.2621700265812718,
            "precision": 0.762114537444934,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 14289,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8187454600645598,
            "auditor_fn_violation": 0.018291974845463976,
            "auditor_fp_violation": 0.015106054923532106,
            "ave_precision_score": 0.818981724068506,
            "fpr": 0.12171052631578948,
            "logloss": 1.30088505537706,
            "mae": 0.30461150982963464,
            "precision": 0.750561797752809,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7951500250509578,
            "auditor_fn_violation": 0.019685011368135562,
            "auditor_fp_violation": 0.029039909048141764,
            "ave_precision_score": 0.7955089319144135,
            "fpr": 0.12403951701427003,
            "logloss": 1.1715794651412021,
            "mae": 0.29172650676372175,
            "precision": 0.744920993227991,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7979156447757995,
            "auditor_fn_violation": 0.015185621895880238,
            "auditor_fp_violation": 0.013887152560736771,
            "ave_precision_score": 0.7982420651976958,
            "fpr": 0.11951754385964912,
            "logloss": 1.7953573056117884,
            "mae": 0.3079414806074674,
            "precision": 0.7488479262672811,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7700960036427003,
            "auditor_fn_violation": 0.016626639133413786,
            "auditor_fp_violation": 0.020429865140348127,
            "ave_precision_score": 0.7706510359620987,
            "fpr": 0.1163556531284303,
            "logloss": 1.642561034840307,
            "mae": 0.29326718098445526,
            "precision": 0.7523364485981309,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8340942713820647,
            "auditor_fn_violation": 0.004944259834923366,
            "auditor_fp_violation": 0.018606492478226447,
            "ave_precision_score": 0.8343177861178579,
            "fpr": 0.11951754385964912,
            "logloss": 1.3172747220246417,
            "mae": 0.28787227578425784,
            "precision": 0.7588495575221239,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8316230935814151,
            "auditor_fn_violation": 1.8966649517657616e-05,
            "auditor_fp_violation": 0.014674317861063197,
            "ave_precision_score": 0.8318458361414625,
            "fpr": 0.12184412733260154,
            "logloss": 1.166402073967215,
            "mae": 0.27489742648861054,
            "precision": 0.7602591792656588,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8264567262997777,
            "auditor_fn_violation": 0.014928806231464609,
            "auditor_fp_violation": 0.012785452348210189,
            "ave_precision_score": 0.8267754291072837,
            "fpr": 0.11074561403508772,
            "logloss": 1.2629328053669817,
            "mae": 0.29682318873827757,
            "precision": 0.7725225225225225,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7980643038164957,
            "auditor_fn_violation": 0.01862762065752633,
            "auditor_fp_violation": 0.002388956405833464,
            "ave_precision_score": 0.7985965732998442,
            "fpr": 0.11964873765093303,
            "logloss": 1.1823584563220357,
            "mae": 0.29243754159577984,
            "precision": 0.7566964285714286,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8017162873442958,
            "auditor_fn_violation": 0.07161583949690929,
            "auditor_fp_violation": 0.04033316664583073,
            "ave_precision_score": 0.8019570870738018,
            "fpr": 0.20833333333333334,
            "logloss": 1.2912848313559178,
            "mae": 0.34186423273251776,
            "precision": 0.6619217081850534,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7968591908207138,
            "auditor_fn_violation": 0.06487779550632657,
            "auditor_fp_violation": 0.04906303904657362,
            "ave_precision_score": 0.7971425923844528,
            "fpr": 0.21953896816684962,
            "logloss": 1.2465057087832834,
            "mae": 0.3405469782046611,
            "precision": 0.6422182468694096,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.8040150449252512,
            "auditor_fn_violation": 0.07480482009504412,
            "auditor_fp_violation": 0.042862128599408265,
            "ave_precision_score": 0.8044261345354623,
            "fpr": 0.21052631578947367,
            "logloss": 1.2854826853211192,
            "mae": 0.342179949429147,
            "precision": 0.6595744680851063,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7989524684048356,
            "auditor_fn_violation": 0.06563883231822244,
            "auditor_fp_violation": 0.0536155323819978,
            "ave_precision_score": 0.799232798112408,
            "fpr": 0.22283205268935236,
            "logloss": 1.2400028661142255,
            "mae": 0.3400948284857002,
            "precision": 0.6381461675579323,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8108872300664878,
            "auditor_fn_violation": 0.012199860649587307,
            "auditor_fp_violation": 0.012238508980289208,
            "ave_precision_score": 0.8111548657143218,
            "fpr": 0.13596491228070176,
            "logloss": 1.6192947067344525,
            "mae": 0.2999280647658629,
            "precision": 0.7405857740585774,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7742145848798785,
            "auditor_fn_violation": 0.013565896067502308,
            "auditor_fp_violation": 0.006997804610318335,
            "ave_precision_score": 0.774304292567848,
            "fpr": 0.13830954994511527,
            "logloss": 1.5423027789885468,
            "mae": 0.30009744845398173,
            "precision": 0.7330508474576272,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7533504998936789,
            "auditor_fn_violation": 0.03690999392575124,
            "auditor_fp_violation": 0.04486758761511856,
            "ave_precision_score": 0.69746067119799,
            "fpr": 0.1875,
            "logloss": 3.7924715851030792,
            "mae": 0.2981318861814034,
            "precision": 0.6978798586572438,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7050366236762688,
            "auditor_fn_violation": 0.022622471212182277,
            "auditor_fp_violation": 0.05254233965814648,
            "ave_precision_score": 0.6436917379083221,
            "fpr": 0.20087815587266739,
            "logloss": 4.274282455728134,
            "mae": 0.31685841569483814,
            "precision": 0.6749555950266429,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.826853287507979,
            "auditor_fn_violation": 0.013566566620216533,
            "auditor_fp_violation": 0.011884298037254666,
            "ave_precision_score": 0.8270713486361503,
            "fpr": 0.1337719298245614,
            "logloss": 1.7810347750017634,
            "mae": 0.2916247257268004,
            "precision": 0.7468879668049793,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8111188510161592,
            "auditor_fn_violation": 0.014500003556246789,
            "auditor_fp_violation": 0.021368296220793483,
            "ave_precision_score": 0.8113896346421433,
            "fpr": 0.15916575192096596,
            "logloss": 1.6401006612734832,
            "mae": 0.2858353175947998,
            "precision": 0.7094188376753507,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8334179477756328,
            "auditor_fn_violation": 0.021972254975524352,
            "auditor_fp_violation": 0.014970621327665959,
            "ave_precision_score": 0.8336318794693558,
            "fpr": 0.11403508771929824,
            "logloss": 1.3600000560097845,
            "mae": 0.2906435437911809,
            "precision": 0.7668161434977578,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8168413541710726,
            "auditor_fn_violation": 0.01712925534563163,
            "auditor_fp_violation": 0.028780186608122944,
            "ave_precision_score": 0.8171052782519796,
            "fpr": 0.11525795828759605,
            "logloss": 1.2153223071481125,
            "mae": 0.27793744513172447,
            "precision": 0.7640449438202247,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 14289,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8266315639066072,
            "auditor_fn_violation": 0.016237449530138993,
            "auditor_fp_violation": 0.0190127932658249,
            "ave_precision_score": 0.8161222041457883,
            "fpr": 0.16228070175438597,
            "logloss": 4.256843875627166,
            "mae": 0.2943660441454429,
            "precision": 0.7148362235067437,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8206340743565663,
            "auditor_fn_violation": 0.013333554610911041,
            "auditor_fp_violation": 0.03116669280225812,
            "ave_precision_score": 0.8107204030108326,
            "fpr": 0.15697036223929747,
            "logloss": 3.639711863705779,
            "mae": 0.2717092809062137,
            "precision": 0.717948717948718,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8045347480654119,
            "auditor_fn_violation": 0.04526655232786652,
            "auditor_fp_violation": 0.026935658623994663,
            "ave_precision_score": 0.805141195773026,
            "fpr": 0.09429824561403509,
            "logloss": 1.54140891024582,
            "mae": 0.3075629400391878,
            "precision": 0.7844611528822055,
            "recall": 0.6374745417515275
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7797779003819336,
            "auditor_fn_violation": 0.03663882520572888,
            "auditor_fp_violation": 0.024124784381370556,
            "ave_precision_score": 0.7804288525110648,
            "fpr": 0.09769484083424808,
            "logloss": 1.5014093674137168,
            "mae": 0.2823858025243851,
            "precision": 0.785024154589372,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7668950995177052,
            "auditor_fn_violation": 0.00011835852360024595,
            "auditor_fp_violation": 0.015587885985748218,
            "ave_precision_score": 0.767377441217669,
            "fpr": 0.08881578947368421,
            "logloss": 0.8007130875991835,
            "mae": 0.37735820545032933,
            "precision": 0.7828418230563002,
            "recall": 0.594704684317719
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7462643153463532,
            "auditor_fn_violation": 0.0053035493713741114,
            "auditor_fp_violation": 0.021267837541163553,
            "ave_precision_score": 0.7467851816338624,
            "fpr": 0.13172338090010977,
            "logloss": 0.7099859336831169,
            "mae": 0.37179507452319865,
            "precision": 0.7101449275362319,
            "recall": 0.6349892008639308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7930074434753547,
            "auditor_fn_violation": 0.025114338800157218,
            "auditor_fp_violation": 0.02189075717798059,
            "ave_precision_score": 0.7873449440573231,
            "fpr": 0.1425438596491228,
            "logloss": 1.5481631946280872,
            "mae": 0.2858247490289475,
            "precision": 0.7346938775510204,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7974146687650231,
            "auditor_fn_violation": 0.0202943149838902,
            "auditor_fp_violation": 0.01828347969264545,
            "ave_precision_score": 0.790232381107981,
            "fpr": 0.145993413830955,
            "logloss": 1.376015365699225,
            "mae": 0.2682985201713461,
            "precision": 0.7296747967479674,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7939709955201663,
            "auditor_fn_violation": 0.015835477185836284,
            "auditor_fp_violation": 0.030970017085469016,
            "ave_precision_score": 0.7926075004988178,
            "fpr": 0.2576754385964912,
            "logloss": 1.459949012951003,
            "mae": 0.3172941721373612,
            "precision": 0.6528803545051699,
            "recall": 0.90020366598778
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7853120952624624,
            "auditor_fn_violation": 0.010810990225063004,
            "auditor_fp_violation": 0.030845715069782037,
            "ave_precision_score": 0.7845457054558191,
            "fpr": 0.27991218441273324,
            "logloss": 1.5239928270381093,
            "mae": 0.32678034375843734,
            "precision": 0.626099706744868,
            "recall": 0.9222462203023758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6202732045962215,
            "auditor_fn_violation": 0.006632543680994753,
            "auditor_fp_violation": 0.021252656582072763,
            "ave_precision_score": 0.580800440472343,
            "fpr": 0.26535087719298245,
            "logloss": 5.121136583739497,
            "mae": 0.44444188720849076,
            "precision": 0.5709219858156028,
            "recall": 0.6558044806517311
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5674241390690572,
            "auditor_fn_violation": 0.004755887366551851,
            "auditor_fp_violation": 0.019383624745177984,
            "ave_precision_score": 0.5268700915156923,
            "fpr": 0.2645444566410538,
            "logloss": 5.435185970994491,
            "mae": 0.45108436136302327,
            "precision": 0.5469924812030075,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8070695759144931,
            "auditor_fn_violation": 0.027394415264229824,
            "auditor_fp_violation": 0.003964037171313088,
            "ave_precision_score": 0.8069969630247564,
            "fpr": 0.14473684210526316,
            "logloss": 1.0578589073366107,
            "mae": 0.2928001458549527,
            "precision": 0.7370517928286853,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.791227285495409,
            "auditor_fn_violation": 0.030334785072298497,
            "auditor_fp_violation": 0.025097518425591978,
            "ave_precision_score": 0.7905493873317477,
            "fpr": 0.16794731064763996,
            "logloss": 1.202207724096864,
            "mae": 0.3030165721489891,
            "precision": 0.6952191235059761,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7799537375460011,
            "auditor_fn_violation": 0.018870368385321756,
            "auditor_fp_violation": 0.025307850981372674,
            "ave_precision_score": 0.7415472025680427,
            "fpr": 0.14473684210526316,
            "logloss": 4.3275627604869396,
            "mae": 0.322951731730221,
            "precision": 0.7136659436008677,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.763828336377915,
            "auditor_fn_violation": 0.02445749455301534,
            "auditor_fp_violation": 0.03524384506821389,
            "ave_precision_score": 0.7203025193180429,
            "fpr": 0.14489571899012074,
            "logloss": 4.378133914366801,
            "mae": 0.30759346143805955,
            "precision": 0.7053571428571429,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8136451014958281,
            "auditor_fn_violation": 0.017689016329009894,
            "auditor_fp_violation": 0.01898935283577114,
            "ave_precision_score": 0.7945863652703997,
            "fpr": 0.14473684210526316,
            "logloss": 1.6376463453624406,
            "mae": 0.28801897695393464,
            "precision": 0.7338709677419355,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7785522194877468,
            "auditor_fn_violation": 0.02780273736169164,
            "auditor_fp_violation": 0.01662223616120433,
            "ave_precision_score": 0.7538642557092703,
            "fpr": 0.14050493962678376,
            "logloss": 1.9546826964907675,
            "mae": 0.28026911575393926,
            "precision": 0.732776617954071,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7376812791783145,
            "auditor_fn_violation": 0.020138814449565876,
            "auditor_fp_violation": 0.033689106971704796,
            "ave_precision_score": 0.676296854876688,
            "fpr": 0.2565789473684211,
            "logloss": 4.488221829089004,
            "mae": 0.33421333203696546,
            "precision": 0.6459909228441755,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6831895167646531,
            "auditor_fn_violation": 0.014030578980684839,
            "auditor_fp_violation": 0.039242590559824375,
            "ave_precision_score": 0.6158005270360347,
            "fpr": 0.30735455543358947,
            "logloss": 5.185234161732063,
            "mae": 0.38639528613478386,
            "precision": 0.5857988165680473,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8293699613690229,
            "auditor_fn_violation": 0.024288062314646086,
            "auditor_fp_violation": 0.01769752469058633,
            "ave_precision_score": 0.8296022164242814,
            "fpr": 0.12171052631578948,
            "logloss": 2.0157077178942555,
            "mae": 0.2885794198842143,
            "precision": 0.7592190889370932,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8110661619467994,
            "auditor_fn_violation": 0.019727686329550277,
            "auditor_fp_violation": 0.027442371020856206,
            "ave_precision_score": 0.8114260760076306,
            "fpr": 0.12294182217343579,
            "logloss": 1.809466523472513,
            "mae": 0.27162005161021735,
            "precision": 0.7565217391304347,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7892879945369515,
            "auditor_fn_violation": 0.02889064565691214,
            "auditor_fp_violation": 0.02083854231778972,
            "ave_precision_score": 0.790589286567071,
            "fpr": 0.2138157894736842,
            "logloss": 1.115746245678647,
            "mae": 0.3456376712504339,
            "precision": 0.656084656084656,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8000323360143929,
            "auditor_fn_violation": 0.023691716078740047,
            "auditor_fp_violation": 0.04683824682452564,
            "ave_precision_score": 0.800344676152034,
            "fpr": 0.2678375411635565,
            "logloss": 1.1241239549375819,
            "mae": 0.36335359852861704,
            "precision": 0.601957585644372,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7927955555246988,
            "auditor_fn_violation": 0.0030371243791760443,
            "auditor_fp_violation": 0.003682752010668001,
            "ave_precision_score": 0.7935030069546617,
            "fpr": 0.03399122807017544,
            "logloss": 0.8176027131404199,
            "mae": 0.3706258696740342,
            "precision": 0.8803088803088803,
            "recall": 0.46435845213849286
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7920413373563739,
            "auditor_fn_violation": 0.002709860049834882,
            "auditor_fp_violation": 0.007852928493021796,
            "ave_precision_score": 0.7923617706402816,
            "fpr": 0.04500548847420417,
            "logloss": 0.7557441596953951,
            "mae": 0.35960432226461914,
            "precision": 0.8435114503816794,
            "recall": 0.4773218142548596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8247125821956848,
            "auditor_fn_violation": 0.018651516775645836,
            "auditor_fp_violation": 0.01864555986164938,
            "ave_precision_score": 0.8250605198945045,
            "fpr": 0.1206140350877193,
            "logloss": 0.9625927131821733,
            "mae": 0.28225160618096556,
            "precision": 0.7629310344827587,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.825510955537059,
            "auditor_fn_violation": 0.009151408392268242,
            "auditor_fp_violation": 0.017854692645444575,
            "ave_precision_score": 0.8257700763894789,
            "fpr": 0.12403951701427003,
            "logloss": 0.8452328587782044,
            "mae": 0.2701473157228908,
            "precision": 0.754880694143167,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7438188360549709,
            "auditor_fn_violation": 0.016183853217565297,
            "auditor_fp_violation": 0.04527909738717341,
            "ave_precision_score": 0.6849272719784159,
            "fpr": 0.2324561403508772,
            "logloss": 4.510546646937857,
            "mae": 0.31532968737283784,
            "precision": 0.6677115987460815,
            "recall": 0.8676171079429735
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6934097806538476,
            "auditor_fn_violation": 0.013485287807052278,
            "auditor_fp_violation": 0.04564009330406147,
            "ave_precision_score": 0.6291925592747721,
            "fpr": 0.2864983534577388,
            "logloss": 5.163134680584527,
            "mae": 0.3670906212718704,
            "precision": 0.6009174311926605,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7845800194155834,
            "auditor_fn_violation": 0.017883302962089554,
            "auditor_fp_violation": 0.009594949368671092,
            "ave_precision_score": 0.7833980441367606,
            "fpr": 0.10197368421052631,
            "logloss": 1.2584871222396878,
            "mae": 0.3010542952343118,
            "precision": 0.7759036144578313,
            "recall": 0.6558044806517311
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7462333883426011,
            "auditor_fn_violation": 0.023106120774882468,
            "auditor_fp_violation": 0.008534087345146624,
            "ave_precision_score": 0.7419229635401485,
            "fpr": 0.10428100987925357,
            "logloss": 1.4478148521097631,
            "mae": 0.28889626239035704,
            "precision": 0.7630922693266833,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7933469917879555,
            "auditor_fn_violation": 0.027845517561725087,
            "auditor_fp_violation": 0.01279847480935117,
            "ave_precision_score": 0.7939614053537061,
            "fpr": 0.17324561403508773,
            "logloss": 1.5129431847264379,
            "mae": 0.33021911801299075,
            "precision": 0.6961538461538461,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7530274194725582,
            "auditor_fn_violation": 0.019542761496753144,
            "auditor_fp_violation": 0.011280774658930542,
            "ave_precision_score": 0.753686935092601,
            "fpr": 0.1800219538968167,
            "logloss": 1.475465609575799,
            "mae": 0.33423288378096605,
            "precision": 0.6852207293666027,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 14289,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7192911319753913,
            "auditor_fn_violation": 0.012876514095830231,
            "auditor_fp_violation": 0.022383006209109473,
            "ave_precision_score": 0.7199553240251866,
            "fpr": 0.12171052631578948,
            "logloss": 2.5719216203906248,
            "mae": 0.3766798770216866,
            "precision": 0.7008086253369272,
            "recall": 0.5295315682281059
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6868781530256066,
            "auditor_fn_violation": 0.01386224996621566,
            "auditor_fp_violation": 0.010668221734357853,
            "ave_precision_score": 0.688649811270777,
            "fpr": 0.1163556531284303,
            "logloss": 2.4330869625027196,
            "mae": 0.3734324403407893,
            "precision": 0.6873156342182891,
            "recall": 0.5032397408207343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8474314349960086,
            "auditor_fn_violation": 0.03647452388608997,
            "auditor_fp_violation": 0.021552173188315208,
            "ave_precision_score": 0.8476021401722955,
            "fpr": 0.12390350877192982,
            "logloss": 0.8966696570187284,
            "mae": 0.30358357285706195,
            "precision": 0.7580299785867237,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8431647452032988,
            "auditor_fn_violation": 0.026427655271661694,
            "auditor_fp_violation": 0.037321624588364445,
            "ave_precision_score": 0.843449494434947,
            "fpr": 0.14050493962678376,
            "logloss": 0.8115868241151338,
            "mae": 0.2967506883617538,
            "precision": 0.7366255144032922,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8435120595716745,
            "auditor_fn_violation": 0.01938399971415301,
            "auditor_fp_violation": 0.012480726757511362,
            "ave_precision_score": 0.8437410174505684,
            "fpr": 0.12719298245614036,
            "logloss": 1.3347610783315629,
            "mae": 0.2846848969374407,
            "precision": 0.7552742616033755,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8325131635632156,
            "auditor_fn_violation": 0.012522730344031315,
            "auditor_fp_violation": 0.02607515289320998,
            "ave_precision_score": 0.8327557275719348,
            "fpr": 0.12843029637760703,
            "logloss": 1.1984307067873052,
            "mae": 0.26840088660923234,
            "precision": 0.7542016806722689,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8621864493378829,
            "auditor_fn_violation": 0.010420016436202526,
            "auditor_fp_violation": 0.019234175105221487,
            "ave_precision_score": 0.8624244930871009,
            "fpr": 0.16666666666666666,
            "logloss": 0.5503159590755968,
            "mae": 0.28487039662924646,
            "precision": 0.7374784110535406,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8731307837714875,
            "auditor_fn_violation": 0.009360041536962444,
            "auditor_fp_violation": 0.02218911713972087,
            "ave_precision_score": 0.8733396741029508,
            "fpr": 0.20197585071350166,
            "logloss": 0.5382608708533319,
            "mae": 0.2909488408636142,
            "precision": 0.6938435940099834,
            "recall": 0.9006479481641468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.784714745566867,
            "auditor_fn_violation": 0.010272626576624862,
            "auditor_fp_violation": 0.019244593074134266,
            "ave_precision_score": 0.7862588800190944,
            "fpr": 0.17214912280701755,
            "logloss": 1.2164628212518984,
            "mae": 0.312710368487334,
            "precision": 0.7065420560747664,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.800951959940121,
            "auditor_fn_violation": 0.0174350925691038,
            "auditor_fp_violation": 0.025795828759604834,
            "ave_precision_score": 0.8017642867897845,
            "fpr": 0.2074643249176729,
            "logloss": 1.1420277373686285,
            "mae": 0.32574706694719674,
            "precision": 0.657608695652174,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8413041646104924,
            "auditor_fn_violation": 0.0227293028906278,
            "auditor_fp_violation": 0.015418593990915531,
            "ave_precision_score": 0.8417126985531728,
            "fpr": 0.11074561403508772,
            "logloss": 0.8403625409490858,
            "mae": 0.2824536520126493,
            "precision": 0.7740492170022372,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8383305575307213,
            "auditor_fn_violation": 0.021297176577136187,
            "auditor_fp_violation": 0.02872628195076055,
            "ave_precision_score": 0.8385599095896648,
            "fpr": 0.10647639956092206,
            "logloss": 0.7526006040512769,
            "mae": 0.26753306291730033,
            "precision": 0.7754629629629629,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 14289,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5523520267003333,
            "auditor_fn_violation": 0.02294815450030372,
            "auditor_fp_violation": 0.011733237488019339,
            "ave_precision_score": 0.5446203330908239,
            "fpr": 0.19298245614035087,
            "logloss": 4.7847256472868125,
            "mae": 0.5000067749524569,
            "precision": 0.5428571428571428,
            "recall": 0.4256619144602851
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5156930655355895,
            "auditor_fn_violation": 0.02661969259802796,
            "auditor_fp_violation": 0.021405049396267844,
            "ave_precision_score": 0.5071860082913873,
            "fpr": 0.21405049396267836,
            "logloss": 4.749704967665965,
            "mae": 0.5192073736561702,
            "precision": 0.48,
            "recall": 0.38876889848812096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.821418948496481,
            "auditor_fn_violation": 0.023082145281737958,
            "auditor_fp_violation": 0.01600200025003126,
            "ave_precision_score": 0.8217402665194825,
            "fpr": 0.125,
            "logloss": 0.9000293963152851,
            "mae": 0.29561885569626756,
            "precision": 0.7537796976241901,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.809597876669581,
            "auditor_fn_violation": 0.017940079612511352,
            "auditor_fp_violation": 0.027148345617061323,
            "ave_precision_score": 0.8100961314974957,
            "fpr": 0.11855104281009879,
            "logloss": 0.792688614873431,
            "mae": 0.2764266438843971,
            "precision": 0.757847533632287,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 14289,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8115158372111044,
            "auditor_fn_violation": 0.014136027441312043,
            "auditor_fp_violation": 0.026250677167979335,
            "ave_precision_score": 0.812435222971829,
            "fpr": 0.17324561403508773,
            "logloss": 0.9500320195076992,
            "mae": 0.2833423611530006,
            "precision": 0.7188612099644128,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8369533895073444,
            "auditor_fn_violation": 0.006109631975874425,
            "auditor_fp_violation": 0.032009565626470136,
            "ave_precision_score": 0.8371537233778082,
            "fpr": 0.2052689352360044,
            "logloss": 0.9061513651953208,
            "mae": 0.28870518775269066,
            "precision": 0.6764705882352942,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7507257081307326,
            "auditor_fn_violation": 0.02151891949833852,
            "auditor_fp_violation": 0.02715183147893487,
            "ave_precision_score": 0.744905298781362,
            "fpr": 0.15679824561403508,
            "logloss": 1.8478482949894512,
            "mae": 0.3240402660767324,
            "precision": 0.7051546391752578,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7502338291061125,
            "auditor_fn_violation": 0.029272652699309853,
            "auditor_fp_violation": 0.014701270189744391,
            "ave_precision_score": 0.7430455545613401,
            "fpr": 0.15477497255762898,
            "logloss": 1.6886855835446037,
            "mae": 0.3126285179040681,
            "precision": 0.7,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 14289,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8371044493372614,
            "auditor_fn_violation": 0.015951602529745965,
            "auditor_fp_violation": 0.009886652498228943,
            "ave_precision_score": 0.8374719411413172,
            "fpr": 0.09868421052631579,
            "logloss": 0.8664935541385852,
            "mae": 0.2882908921248875,
            "precision": 0.7887323943661971,
            "recall": 0.6843177189409368
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8320077131292705,
            "auditor_fn_violation": 0.009841320268472925,
            "auditor_fp_violation": 0.021493257017406307,
            "ave_precision_score": 0.8322518982968078,
            "fpr": 0.09879253567508232,
            "logloss": 0.769926562634294,
            "mae": 0.27352492391264255,
            "precision": 0.7815533980582524,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7759443621443053,
            "auditor_fn_violation": 0.02087799692714475,
            "auditor_fp_violation": 0.015788431887319248,
            "ave_precision_score": 0.7754684493446915,
            "fpr": 0.1162280701754386,
            "logloss": 2.180275372772024,
            "mae": 0.30314248581226577,
            "precision": 0.7540603248259861,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7510213579476428,
            "auditor_fn_violation": 0.009805757800627327,
            "auditor_fp_violation": 0.02024854947467462,
            "ave_precision_score": 0.7499240485716973,
            "fpr": 0.14270032930845225,
            "logloss": 2.1804438307859386,
            "mae": 0.30929297755900653,
            "precision": 0.7111111111111111,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.702492761486292,
            "auditor_fn_violation": 0.022081680780362323,
            "auditor_fp_violation": 0.011472788265199816,
            "ave_precision_score": 0.7029710349199191,
            "fpr": 0.08114035087719298,
            "logloss": 4.753071724072932,
            "mae": 0.4490309723429337,
            "precision": 0.6890756302521008,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7302226011798226,
            "auditor_fn_violation": 0.014587724310265941,
            "auditor_fp_violation": 0.015127607025246981,
            "ave_precision_score": 0.7307673550408054,
            "fpr": 0.06037321624588365,
            "logloss": 3.9258718352894224,
            "mae": 0.38659433372027546,
            "precision": 0.7698744769874477,
            "recall": 0.39740820734341253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.84911483935843,
            "auditor_fn_violation": 0.025590006074248765,
            "auditor_fp_violation": 0.012327061716047838,
            "ave_precision_score": 0.8493041505875815,
            "fpr": 0.09429824561403509,
            "logloss": 0.9270107284765253,
            "mae": 0.2952772949624342,
            "precision": 0.8004640371229699,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8560629582198742,
            "auditor_fn_violation": 0.023307641426007546,
            "auditor_fp_violation": 0.024306100047044067,
            "ave_precision_score": 0.8562400072090306,
            "fpr": 0.10537870472008781,
            "logloss": 0.8128975623009134,
            "mae": 0.28382450000901105,
            "precision": 0.7788018433179723,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.812845800902384,
            "auditor_fn_violation": 0.006873727087576378,
            "auditor_fp_violation": 0.017707942659499105,
            "ave_precision_score": 0.8131626395863094,
            "fpr": 0.13815789473684212,
            "logloss": 1.853089385422484,
            "mae": 0.299771709117427,
            "precision": 0.7352941176470589,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7883329495662822,
            "auditor_fn_violation": 0.01139658552892059,
            "auditor_fp_violation": 0.016499725576289793,
            "ave_precision_score": 0.7888069497993458,
            "fpr": 0.13830954994511527,
            "logloss": 1.7012471498295483,
            "mae": 0.2897950200169838,
            "precision": 0.7313432835820896,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7870988471617806,
            "auditor_fn_violation": 0.011563404437774687,
            "auditor_fp_violation": 0.01977851398091429,
            "ave_precision_score": 0.7847239850306758,
            "fpr": 0.17982456140350878,
            "logloss": 1.5730752644510186,
            "mae": 0.30403693776156776,
            "precision": 0.703971119133574,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7578107395577985,
            "auditor_fn_violation": 0.006130969456581786,
            "auditor_fp_violation": 0.014831131409753812,
            "ave_precision_score": 0.7548859481033571,
            "fpr": 0.21405049396267836,
            "logloss": 1.850571184802086,
            "mae": 0.3273901758498308,
            "precision": 0.6524064171122995,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8424538747940273,
            "auditor_fn_violation": 0.024812859541930184,
            "auditor_fp_violation": 0.018132474892694924,
            "ave_precision_score": 0.8427905715630817,
            "fpr": 0.12280701754385964,
            "logloss": 0.9763593185227056,
            "mae": 0.2723061762360244,
            "precision": 0.7656903765690377,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8396309810777701,
            "auditor_fn_violation": 0.015095082184863197,
            "auditor_fp_violation": 0.026805315979300613,
            "ave_precision_score": 0.8398749108262148,
            "fpr": 0.11855104281009879,
            "logloss": 0.8471838833140871,
            "mae": 0.25213382693536435,
            "precision": 0.7697228144989339,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8540188775114981,
            "auditor_fn_violation": 0.02949807053274735,
            "auditor_fp_violation": 0.020359315747801816,
            "ave_precision_score": 0.8542419871743532,
            "fpr": 0.11951754385964912,
            "logloss": 0.741098227439649,
            "mae": 0.26646045007566854,
            "precision": 0.7705263157894737,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8607954780833402,
            "auditor_fn_violation": 0.03411151915750143,
            "auditor_fp_violation": 0.020150541006742986,
            "ave_precision_score": 0.8609673341796311,
            "fpr": 0.11855104281009879,
            "logloss": 0.7129037853922711,
            "mae": 0.25650639628274496,
            "precision": 0.7641921397379913,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8438138086602088,
            "auditor_fn_violation": 0.020174545324615,
            "auditor_fp_violation": 0.014486185773221659,
            "ave_precision_score": 0.8440441126158835,
            "fpr": 0.1206140350877193,
            "logloss": 1.3296326174074513,
            "mae": 0.2841830764849968,
            "precision": 0.7603485838779956,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8335513862538603,
            "auditor_fn_violation": 0.011745097713807487,
            "auditor_fp_violation": 0.025572859495060375,
            "ave_precision_score": 0.8337920330262728,
            "fpr": 0.12184412733260154,
            "logloss": 1.190136262752182,
            "mae": 0.2675997905399216,
            "precision": 0.7607758620689655,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7723669261265929,
            "auditor_fn_violation": 0.009386054239468327,
            "auditor_fp_violation": 0.014249176980455896,
            "ave_precision_score": 0.7727404297320386,
            "fpr": 0.13486842105263158,
            "logloss": 1.5704634259868262,
            "mae": 0.3325122082177484,
            "precision": 0.713953488372093,
            "recall": 0.6252545824847251
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7372854546082073,
            "auditor_fn_violation": 0.010097370036961257,
            "auditor_fp_violation": 0.02291437980241493,
            "ave_precision_score": 0.738173415835542,
            "fpr": 0.14270032930845225,
            "logloss": 1.4807250456161636,
            "mae": 0.32202259356244006,
            "precision": 0.7018348623853211,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8089617993636907,
            "auditor_fn_violation": 0.032211383856790655,
            "auditor_fp_violation": 0.024174896862107772,
            "ave_precision_score": 0.8095257872443435,
            "fpr": 0.14473684210526316,
            "logloss": 2.0407454324907275,
            "mae": 0.33343391393968047,
            "precision": 0.7278350515463917,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8183992905192634,
            "auditor_fn_violation": 0.03923962702083724,
            "auditor_fp_violation": 0.03830660969107731,
            "ave_precision_score": 0.8187010303327185,
            "fpr": 0.16465422612513722,
            "logloss": 1.8814598788613517,
            "mae": 0.32000761630631314,
            "precision": 0.7023809523809523,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7948398537546343,
            "auditor_fn_violation": 0.019011058705827706,
            "auditor_fp_violation": 0.017827749301996088,
            "ave_precision_score": 0.7870194495583271,
            "fpr": 0.125,
            "logloss": 1.2526810318997892,
            "mae": 0.2763917597131974,
            "precision": 0.7625,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.768408238670259,
            "auditor_fn_violation": 0.01142029384081766,
            "auditor_fp_violation": 0.01885682923004548,
            "ave_precision_score": 0.7568290014453467,
            "fpr": 0.132821075740944,
            "logloss": 1.336820297876512,
            "mae": 0.2654766966410534,
            "precision": 0.75,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8015353483277994,
            "auditor_fn_violation": 0.07090345517561726,
            "auditor_fp_violation": 0.04043995082718673,
            "ave_precision_score": 0.8019933881973051,
            "fpr": 0.20833333333333334,
            "logloss": 1.286044022058848,
            "mae": 0.3409372958455911,
            "precision": 0.6625222024866785,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7961053820316114,
            "auditor_fn_violation": 0.06487779550632657,
            "auditor_fp_violation": 0.050116630076838635,
            "ave_precision_score": 0.7963870824170405,
            "fpr": 0.22283205268935236,
            "logloss": 1.246758588260762,
            "mae": 0.34075006132681335,
            "precision": 0.6387900355871886,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7416390535130633,
            "auditor_fn_violation": 0.03561028334583915,
            "auditor_fp_violation": 0.013876734591823979,
            "ave_precision_score": 0.7385584323874351,
            "fpr": 0.11513157894736842,
            "logloss": 2.8696778971725916,
            "mae": 0.3309445627496297,
            "precision": 0.7361809045226131,
            "recall": 0.5967413441955194
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7296417405219954,
            "auditor_fn_violation": 0.03725998297743207,
            "auditor_fp_violation": 0.020366159636192573,
            "ave_precision_score": 0.7278859951967084,
            "fpr": 0.13172338090010977,
            "logloss": 2.886896858420622,
            "mae": 0.32885270174047776,
            "precision": 0.7108433734939759,
            "recall": 0.6371490280777538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8254213413315018,
            "auditor_fn_violation": 0.012559402579769187,
            "auditor_fp_violation": 0.008295307746801685,
            "ave_precision_score": 0.8256656287529387,
            "fpr": 0.1074561403508772,
            "logloss": 1.9911802227871667,
            "mae": 0.2886181065312004,
            "precision": 0.7715617715617715,
            "recall": 0.6741344195519349
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8100738589500136,
            "auditor_fn_violation": 0.010564423781333498,
            "auditor_fp_violation": 0.01929786733573781,
            "ave_precision_score": 0.8106866792826148,
            "fpr": 0.11964873765093303,
            "logloss": 1.804942205056029,
            "mae": 0.27888960480096814,
            "precision": 0.745920745920746,
            "recall": 0.6911447084233261
        }
    }
]