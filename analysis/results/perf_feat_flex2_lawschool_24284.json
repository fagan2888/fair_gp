[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.802778639231809,
            "auditor_fn_violation": 0.004056344849854699,
            "auditor_fp_violation": 0.013061984156609023,
            "ave_precision_score": 0.8031074450973186,
            "fpr": 0.3300438596491228,
            "logloss": 1.551718666909448,
            "mae": 0.359937662075146,
            "precision": 0.6055045871559633,
            "recall": 0.9447852760736196
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.8128429177023491,
            "auditor_fn_violation": 0.005948797847101733,
            "auditor_fp_violation": 0.012729322234965769,
            "ave_precision_score": 0.8132384411499469,
            "fpr": 0.3172338090010977,
            "logloss": 1.585478640390129,
            "mae": 0.35476002836211373,
            "precision": 0.6035665294924554,
            "recall": 0.946236559139785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8373075005263437,
            "auditor_fn_violation": 0.007193341226276329,
            "auditor_fp_violation": 0.018772551947243997,
            "ave_precision_score": 0.8376437175323092,
            "fpr": 0.11513157894736842,
            "logloss": 0.7444981499182096,
            "mae": 0.29634186200362084,
            "precision": 0.7717391304347826,
            "recall": 0.7259713701431493
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.824714162246393,
            "auditor_fn_violation": 0.006621578556000145,
            "auditor_fp_violation": 0.011134465156802999,
            "ave_precision_score": 0.824830472156883,
            "fpr": 0.132821075740944,
            "logloss": 0.8403398122718335,
            "mae": 0.29785014413904715,
            "precision": 0.7430997876857749,
            "recall": 0.7526881720430108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7918762040470118,
            "auditor_fn_violation": 0.009247300254726797,
            "auditor_fp_violation": 0.005910165484633573,
            "ave_precision_score": 0.7754052563299982,
            "fpr": 0.32894736842105265,
            "logloss": 2.600773089146831,
            "mae": 0.3732000850875982,
            "precision": 0.5978552278820375,
            "recall": 0.9120654396728016
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7646605278913645,
            "auditor_fn_violation": 0.0035338691972663884,
            "auditor_fp_violation": 0.02045256530792065,
            "ave_precision_score": 0.738666992000697,
            "fpr": 0.32711306256860595,
            "logloss": 2.9818055837077324,
            "mae": 0.3723152405057477,
            "precision": 0.5872576177285319,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6513393263051188,
            "auditor_fn_violation": 0.04556380726868296,
            "auditor_fp_violation": 0.022717846626021325,
            "ave_precision_score": 0.6526033453883746,
            "fpr": 0.06798245614035088,
            "logloss": 5.396252301640492,
            "mae": 0.4377920355563891,
            "precision": 0.7129629629629629,
            "recall": 0.3149284253578732
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6134263853286304,
            "auditor_fn_violation": 0.04335540526185334,
            "auditor_fp_violation": 0.032950534818585,
            "ave_precision_score": 0.6144293475508605,
            "fpr": 0.09330406147091108,
            "logloss": 5.072608338988084,
            "mae": 0.43344395929088425,
            "precision": 0.6516393442622951,
            "recall": 0.3419354838709677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8272922158531175,
            "auditor_fn_violation": 0.0008475944462382974,
            "auditor_fp_violation": 0.021852059226079384,
            "ave_precision_score": 0.8276531411886693,
            "fpr": 0.17105263157894737,
            "logloss": 0.89989640493298,
            "mae": 0.2718681147554157,
            "precision": 0.723404255319149,
            "recall": 0.8343558282208589
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8183079613175261,
            "auditor_fn_violation": 0.008396775373865425,
            "auditor_fp_violation": 0.018759260261970046,
            "ave_precision_score": 0.8186056661364034,
            "fpr": 0.18441273326015367,
            "logloss": 0.98663887520395,
            "mae": 0.28153949478447887,
            "precision": 0.6994633273703041,
            "recall": 0.8408602150537634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8583134170642215,
            "auditor_fn_violation": 0.005116959064327488,
            "auditor_fp_violation": 0.031111318485338647,
            "ave_precision_score": 0.858686778480857,
            "fpr": 0.23903508771929824,
            "logloss": 0.8411869989268259,
            "mae": 0.29916090343386603,
            "precision": 0.6760772659732541,
            "recall": 0.9304703476482618
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.815756040116422,
            "auditor_fn_violation": 0.011781924624954263,
            "auditor_fp_violation": 0.03521976047609438,
            "ave_precision_score": 0.816171833803925,
            "fpr": 0.25466520307354557,
            "logloss": 0.9329330013702783,
            "mae": 0.30811722718434675,
            "precision": 0.6516516516516516,
            "recall": 0.9333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8734874686354199,
            "auditor_fn_violation": 0.0008879560865353559,
            "auditor_fp_violation": 0.019176931690929447,
            "ave_precision_score": 0.873656130590352,
            "fpr": 0.19736842105263158,
            "logloss": 0.5929014632413974,
            "mae": 0.2871910381873421,
            "precision": 0.7110754414125201,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8409367001233495,
            "auditor_fn_violation": 0.00726131038797021,
            "auditor_fp_violation": 0.02244859785481879,
            "ave_precision_score": 0.8412804935780593,
            "fpr": 0.22502744237102085,
            "logloss": 0.6609002703458664,
            "mae": 0.29746252774330517,
            "precision": 0.6725239616613419,
            "recall": 0.9053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8577442446337875,
            "auditor_fn_violation": 0.008523033042729528,
            "auditor_fp_violation": 0.0032117083488863996,
            "ave_precision_score": 0.8579678266490326,
            "fpr": 0.17105263157894737,
            "logloss": 0.7402830664677426,
            "mae": 0.2661969927839572,
            "precision": 0.7291666666666666,
            "recall": 0.8588957055214724
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8472991260134375,
            "auditor_fn_violation": 0.005460146595375519,
            "auditor_fp_violation": 0.009308255354338848,
            "ave_precision_score": 0.8475590769277783,
            "fpr": 0.18660812294182216,
            "logloss": 0.7967754982782685,
            "mae": 0.2678727501375775,
            "precision": 0.7058823529411765,
            "recall": 0.8774193548387097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8028967893308674,
            "auditor_fn_violation": 0.005854680156423789,
            "auditor_fp_violation": 0.011797001368669903,
            "ave_precision_score": 0.8039616359502559,
            "fpr": 0.0800438596491228,
            "logloss": 0.6653700143363244,
            "mae": 0.31404216884430264,
            "precision": 0.810880829015544,
            "recall": 0.6400817995910021
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7969670253775787,
            "auditor_fn_violation": 0.014199213908855932,
            "auditor_fp_violation": 0.015810743626724688,
            "ave_precision_score": 0.7973648071693877,
            "fpr": 0.09001097694840834,
            "logloss": 0.6858199961233805,
            "mae": 0.31577541575603874,
            "precision": 0.7853403141361257,
            "recall": 0.6451612903225806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 24284,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7831389341180539,
            "auditor_fn_violation": 0.01925026010834859,
            "auditor_fp_violation": 0.0008502343328771122,
            "ave_precision_score": 0.783847726136083,
            "fpr": 0.08442982456140351,
            "logloss": 1.0197298224823912,
            "mae": 0.32270718947213173,
            "precision": 0.7884615384615384,
            "recall": 0.5869120654396728
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7338439040700104,
            "auditor_fn_violation": 0.027397518973596317,
            "auditor_fp_violation": 0.010125373486977797,
            "ave_precision_score": 0.7337064417443724,
            "fpr": 0.1119648737650933,
            "logloss": 1.2383201842031422,
            "mae": 0.3428503614465456,
            "precision": 0.7228260869565217,
            "recall": 0.5720430107526882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6668665227546284,
            "auditor_fn_violation": 0.008834714598356835,
            "auditor_fp_violation": 0.008743415868275897,
            "ave_precision_score": 0.5364801316806371,
            "fpr": 0.37390350877192985,
            "logloss": 9.972278875403894,
            "mae": 0.428383033842292,
            "precision": 0.5650510204081632,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6659333985991149,
            "auditor_fn_violation": 0.003951701427003293,
            "auditor_fp_violation": 0.006236678759358711,
            "ave_precision_score": 0.5320193463773149,
            "fpr": 0.3896816684961581,
            "logloss": 9.950972230433198,
            "mae": 0.42969290750372346,
            "precision": 0.5489199491740788,
            "recall": 0.9290322580645162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5196285946779853,
            "auditor_fn_violation": 0.013346249058228395,
            "auditor_fp_violation": 0.006361204429513507,
            "ave_precision_score": 0.5210434112901641,
            "fpr": 0.38706140350877194,
            "logloss": 1.696616533834623,
            "mae": 0.46355767556981353,
            "precision": 0.5415584415584416,
            "recall": 0.852760736196319
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5068843311779361,
            "auditor_fn_violation": 0.006000731796560557,
            "auditor_fp_violation": 0.012593956279257516,
            "ave_precision_score": 0.5088273317959334,
            "fpr": 0.407244785949506,
            "logloss": 1.7996544383736743,
            "mae": 0.4718489028530619,
            "precision": 0.520671834625323,
            "recall": 0.8666666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8486984148509419,
            "auditor_fn_violation": 0.01169590643274854,
            "auditor_fp_violation": 0.01077049894239144,
            "ave_precision_score": 0.848981738464348,
            "fpr": 0.125,
            "logloss": 0.8797407181243468,
            "mae": 0.25989070758917693,
            "precision": 0.7678207739307535,
            "recall": 0.7709611451942741
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.820692994570615,
            "auditor_fn_violation": 0.020070110831769416,
            "auditor_fp_violation": 0.03027767249314556,
            "ave_precision_score": 0.8209723627885255,
            "fpr": 0.15587266739846323,
            "logloss": 0.9865496430071544,
            "mae": 0.27590917163147705,
            "precision": 0.7221135029354208,
            "recall": 0.7935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7555002923938301,
            "auditor_fn_violation": 0.009664370537796436,
            "auditor_fp_violation": 0.011794409190825767,
            "ave_precision_score": 0.7569831241432574,
            "fpr": 0.22587719298245615,
            "logloss": 1.0712883119080487,
            "mae": 0.3467893733526682,
            "precision": 0.6633986928104575,
            "recall": 0.8302658486707567
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.778729051754119,
            "auditor_fn_violation": 0.006704200748321001,
            "auditor_fp_violation": 0.00713501646542262,
            "ave_precision_score": 0.7791068464800032,
            "fpr": 0.22063666300768386,
            "logloss": 1.061163958216527,
            "mae": 0.3328541448688234,
            "precision": 0.662751677852349,
            "recall": 0.8494623655913979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.5652461368876222,
            "auditor_fn_violation": 0.002724410720051664,
            "auditor_fp_violation": 0.01071865538550868,
            "ave_precision_score": 0.5461890986655827,
            "fpr": 0.3892543859649123,
            "logloss": 4.324802674395787,
            "mae": 0.4091511901994333,
            "precision": 0.56865127582017,
            "recall": 0.9570552147239264
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.5515415241781363,
            "auditor_fn_violation": 0.00480625095900759,
            "auditor_fp_violation": 0.006477876280438891,
            "ave_precision_score": 0.5337302350637533,
            "fpr": 0.38529088913282106,
            "logloss": 4.72885759241224,
            "mae": 0.40981604604552246,
            "precision": 0.5595984943538268,
            "recall": 0.9591397849462365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.648629738503456,
            "auditor_fn_violation": 0.010496268790585865,
            "auditor_fp_violation": 0.007947617270125669,
            "ave_precision_score": 0.649840394136892,
            "fpr": 0.10416666666666667,
            "logloss": 3.70266822620638,
            "mae": 0.4282560515526752,
            "precision": 0.6735395189003437,
            "recall": 0.40081799591002043
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.651963653552601,
            "auditor_fn_violation": 0.014303081807773572,
            "auditor_fp_violation": 0.009657745639985624,
            "ave_precision_score": 0.6527916629262615,
            "fpr": 0.10208562019758508,
            "logloss": 3.5017946607451673,
            "mae": 0.4118948292216545,
            "precision": 0.6690391459074733,
            "recall": 0.4043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8574862063307447,
            "auditor_fn_violation": 0.009787697772037455,
            "auditor_fp_violation": 0.02998631330098296,
            "ave_precision_score": 0.8581763585203441,
            "fpr": 0.22916666666666666,
            "logloss": 0.7832347923277497,
            "mae": 0.2897896564111426,
            "precision": 0.6828528072837633,
            "recall": 0.9202453987730062
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8214347183024249,
            "auditor_fn_violation": 0.01218795368435962,
            "auditor_fp_violation": 0.03450601270963264,
            "ave_precision_score": 0.8218033605231644,
            "fpr": 0.24368825466520308,
            "logloss": 0.8566528438156811,
            "mae": 0.2971119280273192,
            "precision": 0.6605504587155964,
            "recall": 0.9290322580645162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6571231170244578,
            "auditor_fn_violation": 0.043886556883005065,
            "auditor_fp_violation": 0.01841742358259716,
            "ave_precision_score": 0.6581905350473826,
            "fpr": 0.0581140350877193,
            "logloss": 5.206918041483051,
            "mae": 0.44224958015578403,
            "precision": 0.7225130890052356,
            "recall": 0.2822085889570552
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.625290749461253,
            "auditor_fn_violation": 0.04034087555917519,
            "auditor_fp_violation": 0.025394653290869443,
            "ave_precision_score": 0.626265546800308,
            "fpr": 0.07574094401756312,
            "logloss": 4.880094815462227,
            "mae": 0.4283718900656957,
            "precision": 0.6863636363636364,
            "recall": 0.3247311827956989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8458925194759869,
            "auditor_fn_violation": 0.0060542460445592505,
            "auditor_fp_violation": 0.024887499481564438,
            "ave_precision_score": 0.8461658803408033,
            "fpr": 0.2807017543859649,
            "logloss": 0.8465112697615391,
            "mae": 0.32892552068695197,
            "precision": 0.641958041958042,
            "recall": 0.9386503067484663
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8304013128699672,
            "auditor_fn_violation": 0.00747140681987182,
            "auditor_fp_violation": 0.026502192928482472,
            "ave_precision_score": 0.8306455519169494,
            "fpr": 0.2843029637760702,
            "logloss": 0.9097662511717256,
            "mae": 0.33501275610199155,
            "precision": 0.6268011527377522,
            "recall": 0.9354838709677419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6494021022335844,
            "auditor_fn_violation": 0.010390880063143544,
            "auditor_fp_violation": 0.009233337480817888,
            "ave_precision_score": 0.650607045983295,
            "fpr": 0.11732456140350878,
            "logloss": 3.3931418799241264,
            "mae": 0.4223718870797651,
            "precision": 0.664576802507837,
            "recall": 0.4335378323108384
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6480789794040216,
            "auditor_fn_violation": 0.011574188827118971,
            "auditor_fp_violation": 0.01135597308432561,
            "ave_precision_score": 0.6488790011808911,
            "fpr": 0.11855104281009879,
            "logloss": 3.2266897400703973,
            "mae": 0.4138554049227506,
            "precision": 0.6593059936908517,
            "recall": 0.44946236559139785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8099243566965729,
            "auditor_fn_violation": 0.0034509202453987756,
            "auditor_fp_violation": 0.013658185060760674,
            "ave_precision_score": 0.8102341246820727,
            "fpr": 0.23574561403508773,
            "logloss": 1.0339179549192645,
            "mae": 0.31950440460401736,
            "precision": 0.6717557251908397,
            "recall": 0.8997955010224948
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8156418412309157,
            "auditor_fn_violation": 0.005939355310836492,
            "auditor_fp_violation": 0.011419964263387712,
            "ave_precision_score": 0.8159998472529414,
            "fpr": 0.23161361141602635,
            "logloss": 1.0698243680731565,
            "mae": 0.31763186839980156,
            "precision": 0.6618589743589743,
            "recall": 0.8881720430107527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8299635144227399,
            "auditor_fn_violation": 0.008601514009973834,
            "auditor_fp_violation": 0.001267574965783253,
            "ave_precision_score": 0.8305259093289716,
            "fpr": 0.01644736842105263,
            "logloss": 1.2342405717192522,
            "mae": 0.40520929054278976,
            "precision": 0.8920863309352518,
            "recall": 0.25357873210633947
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.8072640377519982,
            "auditor_fn_violation": 0.014954616810075184,
            "auditor_fp_violation": 0.0029829734239710964,
            "ave_precision_score": 0.8080016623798256,
            "fpr": 0.015367727771679473,
            "logloss": 1.1642544979048206,
            "mae": 0.3979867619507094,
            "precision": 0.8842975206611571,
            "recall": 0.23010752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8741073003971644,
            "auditor_fn_violation": 0.002995730635381913,
            "auditor_fp_violation": 0.021058852805773298,
            "ave_precision_score": 0.8742717333652097,
            "fpr": 0.19078947368421054,
            "logloss": 0.5922550504246328,
            "mae": 0.28395292009161077,
            "precision": 0.7161500815660685,
            "recall": 0.8977505112474438
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8432176260803268,
            "auditor_fn_violation": 0.006373711979037571,
            "auditor_fp_violation": 0.022064650780446268,
            "ave_precision_score": 0.8435394910058067,
            "fpr": 0.21844127332601537,
            "logloss": 0.6619815865042656,
            "mae": 0.29382888844949184,
            "precision": 0.6758957654723127,
            "recall": 0.8924731182795699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6654840584857915,
            "auditor_fn_violation": 0.011478402037814377,
            "auditor_fp_violation": 0.008683795777860734,
            "ave_precision_score": 0.5342744663935727,
            "fpr": 0.36622807017543857,
            "logloss": 10.089453351285544,
            "mae": 0.43296025311337066,
            "precision": 0.5651041666666666,
            "recall": 0.8875255623721882
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6645303994852618,
            "auditor_fn_violation": 0.004501729164453574,
            "auditor_fp_violation": 0.008592046388682432,
            "ave_precision_score": 0.5277830119525153,
            "fpr": 0.3809001097694841,
            "logloss": 10.161213740811753,
            "mae": 0.432733545832838,
            "precision": 0.5487646293888166,
            "recall": 0.9075268817204301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6917442804450701,
            "auditor_fn_violation": 0.01571637426900585,
            "auditor_fp_violation": 0.006944444444444445,
            "ave_precision_score": 0.6927470729121354,
            "fpr": 0.051535087719298246,
            "logloss": 2.3665336487429105,
            "mae": 0.429746354726535,
            "precision": 0.7513227513227513,
            "recall": 0.2903885480572597
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6847064380493174,
            "auditor_fn_violation": 0.013455614177968214,
            "auditor_fp_violation": 0.005988097640694454,
            "ave_precision_score": 0.6851953856462818,
            "fpr": 0.04939626783754116,
            "logloss": 2.2933580456482265,
            "mae": 0.41044160316850514,
            "precision": 0.7692307692307693,
            "recall": 0.3225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8420280364085647,
            "auditor_fn_violation": 0.01311977540989488,
            "auditor_fp_violation": 0.017307971465306302,
            "ave_precision_score": 0.8423092212936949,
            "fpr": 0.19956140350877194,
            "logloss": 0.8911320294399361,
            "mae": 0.2760782768876094,
            "precision": 0.7011494252873564,
            "recall": 0.8732106339468303
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8130920479374474,
            "auditor_fn_violation": 0.010457608913754237,
            "auditor_fp_violation": 0.024769508695416758,
            "ave_precision_score": 0.8134508072506279,
            "fpr": 0.21734357848518113,
            "logloss": 1.0148177233760036,
            "mae": 0.28573838614671493,
            "precision": 0.6721854304635762,
            "recall": 0.8731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6109700017451669,
            "auditor_fn_violation": 0.011778872026692502,
            "auditor_fp_violation": 0.005062523329600599,
            "ave_precision_score": 0.6127939331777992,
            "fpr": 0.07894736842105263,
            "logloss": 7.3512718622723785,
            "mae": 0.46343072574184774,
            "precision": 0.6666666666666666,
            "recall": 0.294478527607362
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6108263743945497,
            "auditor_fn_violation": 0.016564569243298768,
            "auditor_fp_violation": 0.0016096242733309382,
            "ave_precision_score": 0.6117445117159084,
            "fpr": 0.06915477497255763,
            "logloss": 7.0259194995210645,
            "mae": 0.4414536005999829,
            "precision": 0.6684210526315789,
            "recall": 0.2731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7732334493756696,
            "auditor_fn_violation": 0.01947449144333226,
            "auditor_fp_violation": 0.022401600929036546,
            "ave_precision_score": 0.7722009035809627,
            "fpr": 0.19188596491228072,
            "logloss": 1.2423142993491394,
            "mae": 0.30943315800863114,
            "precision": 0.6902654867256637,
            "recall": 0.7975460122699386
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7026532213180775,
            "auditor_fn_violation": 0.015084451683722248,
            "auditor_fp_violation": 0.0201301482134155,
            "ave_precision_score": 0.7008278246214692,
            "fpr": 0.24039517014270034,
            "logloss": 1.543818380284758,
            "mae": 0.3347469528437727,
            "precision": 0.6368159203980099,
            "recall": 0.8258064516129032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7714077017341185,
            "auditor_fn_violation": 0.01842060416890898,
            "auditor_fp_violation": 0.02468271743187759,
            "ave_precision_score": 0.7717618943313268,
            "fpr": 0.27960526315789475,
            "logloss": 1.1239243408501587,
            "mae": 0.35809621228280963,
            "precision": 0.6210995542347697,
            "recall": 0.8548057259713702
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7771230504359017,
            "auditor_fn_violation": 0.01931234729648384,
            "auditor_fp_violation": 0.024865495464009898,
            "ave_precision_score": 0.7775474972684492,
            "fpr": 0.27332601536772777,
            "logloss": 1.1207959851344982,
            "mae": 0.35256203712497053,
            "precision": 0.6175115207373272,
            "recall": 0.864516129032258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6697572559170941,
            "auditor_fn_violation": 0.006827844150252935,
            "auditor_fp_violation": 0.01238024138360086,
            "ave_precision_score": 0.6442114690270612,
            "fpr": 0.3618421052631579,
            "logloss": 3.3663772227540316,
            "mae": 0.3925228766817281,
            "precision": 0.5828065739570164,
            "recall": 0.9427402862985685
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6439459676850653,
            "auditor_fn_violation": 0.0034890171500064917,
            "auditor_fp_violation": 0.013386462419949506,
            "ave_precision_score": 0.6170231320946005,
            "fpr": 0.3765093304061471,
            "logloss": 3.7543432080146886,
            "mae": 0.40575866559362345,
            "precision": 0.5630573248407643,
            "recall": 0.9505376344086022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8105679666407966,
            "auditor_fn_violation": 0.004641588634162094,
            "auditor_fp_violation": 0.01320196176019246,
            "ave_precision_score": 0.8108732550689541,
            "fpr": 0.23464912280701755,
            "logloss": 1.0294478949267325,
            "mae": 0.31894532743951,
            "precision": 0.6722817764165391,
            "recall": 0.8977505112474438
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8155290438668266,
            "auditor_fn_violation": 0.006416203392231155,
            "auditor_fp_violation": 0.011419964263387712,
            "ave_precision_score": 0.8158978816067652,
            "fpr": 0.23161361141602635,
            "logloss": 1.0667333427534207,
            "mae": 0.317336001341503,
            "precision": 0.6624,
            "recall": 0.8903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.8265345675916207,
            "auditor_fn_violation": 0.00014799268108922617,
            "auditor_fp_violation": 0.01688803865455602,
            "ave_precision_score": 0.826732087704789,
            "fpr": 0.3442982456140351,
            "logloss": 1.5633453557799386,
            "mae": 0.3697246061862659,
            "precision": 0.6030341340075853,
            "recall": 0.9754601226993865
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8246122206050771,
            "auditor_fn_violation": 0.0016264768716877356,
            "auditor_fp_violation": 0.015306197791812099,
            "ave_precision_score": 0.8249512957785327,
            "fpr": 0.35016465422612514,
            "logloss": 1.6266093722237107,
            "mae": 0.3747555225695004,
            "precision": 0.5873221216041398,
            "recall": 0.9763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8144709369983867,
            "auditor_fn_violation": 0.006800936390054894,
            "auditor_fp_violation": 0.01183329185848783,
            "ave_precision_score": 0.8147663142531892,
            "fpr": 0.23135964912280702,
            "logloss": 0.9991798124504571,
            "mae": 0.3157893956529815,
            "precision": 0.6743827160493827,
            "recall": 0.8936605316973415
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8162099631435856,
            "auditor_fn_violation": 0.006975673665946675,
            "auditor_fp_violation": 0.010420717390341273,
            "ave_precision_score": 0.8165629442621416,
            "fpr": 0.2327113062568606,
            "logloss": 1.0460992786560737,
            "mae": 0.3162932159776378,
            "precision": 0.6597110754414125,
            "recall": 0.8838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7906440867114901,
            "auditor_fn_violation": 0.007534172855451512,
            "auditor_fp_violation": 0.007099975115092714,
            "ave_precision_score": 0.7692810082944004,
            "fpr": 0.33881578947368424,
            "logloss": 2.806152659190984,
            "mae": 0.3793174927393501,
            "precision": 0.5918097754293263,
            "recall": 0.9161554192229039
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.764866567081447,
            "auditor_fn_violation": 0.006361908808706021,
            "auditor_fp_violation": 0.01775509099053424,
            "ave_precision_score": 0.7346907688107427,
            "fpr": 0.3358946212952799,
            "logloss": 3.1776289414102883,
            "mae": 0.3742115448111162,
            "precision": 0.5842391304347826,
            "recall": 0.9247311827956989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8266420935853692,
            "auditor_fn_violation": 0.0019037240340114092,
            "auditor_fp_violation": 0.019192484757994278,
            "ave_precision_score": 0.8268809131220396,
            "fpr": 0.3399122807017544,
            "logloss": 1.5583522098914893,
            "mae": 0.36484677215278344,
            "precision": 0.6055979643765903,
            "recall": 0.9734151329243353
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.8265000431960743,
            "auditor_fn_violation": 0.002443256258631069,
            "auditor_fp_violation": 0.010730828488872931,
            "ave_precision_score": 0.8267358339782779,
            "fpr": 0.3534577387486279,
            "logloss": 1.6224381967381791,
            "mae": 0.37356834621429363,
            "precision": 0.584516129032258,
            "recall": 0.9741935483870968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8601202553700109,
            "auditor_fn_violation": 0.0019822050012556955,
            "auditor_fp_violation": 0.021999813363195224,
            "ave_precision_score": 0.8603906145702098,
            "fpr": 0.25548245614035087,
            "logloss": 0.9192081354975378,
            "mae": 0.3095649849487688,
            "precision": 0.6637806637806638,
            "recall": 0.9406952965235174
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8399123165088118,
            "auditor_fn_violation": 0.008337759522207664,
            "auditor_fp_violation": 0.020095691424689782,
            "ave_precision_score": 0.8401958634835129,
            "fpr": 0.2557628979143798,
            "logloss": 0.9759255501256373,
            "mae": 0.31511919783573605,
            "precision": 0.6522388059701493,
            "recall": 0.9397849462365592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7911140895117675,
            "auditor_fn_violation": 0.007982635525418866,
            "auditor_fp_violation": 0.010145784081954294,
            "ave_precision_score": 0.7917911612748955,
            "fpr": 0.2741228070175439,
            "logloss": 1.124002487126774,
            "mae": 0.3519689464560822,
            "precision": 0.638728323699422,
            "recall": 0.9038854805725971
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8014094010199757,
            "auditor_fn_violation": 0.005894503263576598,
            "auditor_fp_violation": 0.01042810098792536,
            "ave_precision_score": 0.8017439683857982,
            "fpr": 0.28210757409440174,
            "logloss": 1.1238496400497224,
            "mae": 0.34440176430045927,
            "precision": 0.6248175182481752,
            "recall": 0.9204301075268817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6414828131982299,
            "auditor_fn_violation": 0.0004955512503139252,
            "auditor_fp_violation": 0.004178590684749701,
            "ave_precision_score": 0.6425205131091223,
            "fpr": 0.041666666666666664,
            "logloss": 4.631544074260663,
            "mae": 0.47462467009223236,
            "precision": 0.7054263565891473,
            "recall": 0.18609406952965235
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6446923681593899,
            "auditor_fn_violation": 0.010665344711589529,
            "auditor_fp_violation": 0.0004208650622929517,
            "ave_precision_score": 0.6453920906809334,
            "fpr": 0.038419319429198684,
            "logloss": 4.359455312819163,
            "mae": 0.44037631645076314,
            "precision": 0.7388059701492538,
            "recall": 0.2129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7368904212335458,
            "auditor_fn_violation": 0.010296702902450413,
            "auditor_fp_violation": 0.00467110447513583,
            "ave_precision_score": 0.7383776735499915,
            "fpr": 0.07017543859649122,
            "logloss": 1.557897370819283,
            "mae": 0.3782191518561979,
            "precision": 0.7777777777777778,
            "recall": 0.45807770961145194
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7228303306988021,
            "auditor_fn_violation": 0.012187953684359628,
            "auditor_fp_violation": 0.010487169768598058,
            "ave_precision_score": 0.7232410019748754,
            "fpr": 0.08232711306256861,
            "logloss": 1.522297355468825,
            "mae": 0.37049772854171464,
            "precision": 0.7466216216216216,
            "recall": 0.4752688172043011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8369708982923483,
            "auditor_fn_violation": 0.009047734366591325,
            "auditor_fp_violation": 0.02033563518725893,
            "ave_precision_score": 0.8371998968716368,
            "fpr": 0.17105263157894737,
            "logloss": 0.6585741464620751,
            "mae": 0.3047418953930837,
            "precision": 0.717391304347826,
            "recall": 0.8098159509202454
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8196733989732521,
            "auditor_fn_violation": 0.0058779788251124305,
            "auditor_fp_violation": 0.0257589107716844,
            "ave_precision_score": 0.8199953271606719,
            "fpr": 0.1756311745334797,
            "logloss": 0.67851126834979,
            "mae": 0.3001118948002573,
            "precision": 0.7096188747731398,
            "recall": 0.8408602150537634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8107748087944922,
            "auditor_fn_violation": 0.00638610842033509,
            "auditor_fp_violation": 0.013251213139231072,
            "ave_precision_score": 0.8110752892333013,
            "fpr": 0.24561403508771928,
            "logloss": 1.0395251567145154,
            "mae": 0.3200531152307611,
            "precision": 0.6621417797888386,
            "recall": 0.8977505112474438
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8200178026870203,
            "auditor_fn_violation": 0.007138557416522079,
            "auditor_fp_violation": 0.01297544215443533,
            "ave_precision_score": 0.8203333043133849,
            "fpr": 0.2502744237102086,
            "logloss": 1.0703678644567283,
            "mae": 0.31789733358496486,
            "precision": 0.6448598130841121,
            "recall": 0.8903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7381051273135023,
            "auditor_fn_violation": 0.020512682524306682,
            "auditor_fp_violation": 0.007416220812077477,
            "ave_precision_score": 0.7388685860588415,
            "fpr": 0.11403508771929824,
            "logloss": 1.4030694392826966,
            "mae": 0.354502761911195,
            "precision": 0.7373737373737373,
            "recall": 0.5971370143149284
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7013988711953789,
            "auditor_fn_violation": 0.02803252953743377,
            "auditor_fp_violation": 0.022446136655624095,
            "ave_precision_score": 0.7006673616771236,
            "fpr": 0.13721185510428102,
            "logloss": 1.637022235320293,
            "mae": 0.36709042063998626,
            "precision": 0.6875,
            "recall": 0.5913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6935750757768688,
            "auditor_fn_violation": 0.014442740286298581,
            "auditor_fp_violation": 0.00961438762390611,
            "ave_precision_score": 0.6943178561476677,
            "fpr": 0.13596491228070176,
            "logloss": 2.101578477357604,
            "mae": 0.3866928040960619,
            "precision": 0.6852791878172588,
            "recall": 0.5521472392638037
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6990774423894479,
            "auditor_fn_violation": 0.014730356573775721,
            "auditor_fp_violation": 0.008786481125063379,
            "ave_precision_score": 0.6996200072017178,
            "fpr": 0.132821075740944,
            "logloss": 1.9560951364629273,
            "mae": 0.3702860032750323,
            "precision": 0.6781914893617021,
            "recall": 0.5483870967741935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.859523790916997,
            "auditor_fn_violation": 0.004944300936390056,
            "auditor_fp_violation": 0.01939985898552529,
            "ave_precision_score": 0.8597161581830096,
            "fpr": 0.24890350877192982,
            "logloss": 0.9544670258791585,
            "mae": 0.3055273978188297,
            "precision": 0.6661764705882353,
            "recall": 0.9263803680981595
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8387582171537018,
            "auditor_fn_violation": 0.0037746538720300287,
            "auditor_fp_violation": 0.026871372807686835,
            "ave_precision_score": 0.8389806653346451,
            "fpr": 0.27661909989023054,
            "logloss": 1.0616116108219895,
            "mae": 0.32424903325154425,
            "precision": 0.6299559471365639,
            "recall": 0.9225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8337091030609193,
            "auditor_fn_violation": 0.009002888099594592,
            "auditor_fp_violation": 0.019029177553813614,
            "ave_precision_score": 0.8341540013732709,
            "fpr": 0.22587719298245615,
            "logloss": 0.8367189054958326,
            "mae": 0.30542113995611625,
            "precision": 0.6776212832550861,
            "recall": 0.885480572597137
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8210888854265693,
            "auditor_fn_violation": 0.004008356644594739,
            "auditor_fp_violation": 0.02633975378163256,
            "ave_precision_score": 0.8212137855390782,
            "fpr": 0.2349066959385291,
            "logloss": 0.9747628756134614,
            "mae": 0.31607507792167683,
            "precision": 0.6592356687898089,
            "recall": 0.8903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8171802077033627,
            "auditor_fn_violation": 0.00343298173860008,
            "auditor_fp_violation": 0.009005225830533781,
            "ave_precision_score": 0.8174479868373974,
            "fpr": 0.3157894736842105,
            "logloss": 1.6395411167418572,
            "mae": 0.3538954436448158,
            "precision": 0.6200527704485488,
            "recall": 0.9611451942740287
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.813808307180525,
            "auditor_fn_violation": 0.0037982602126931304,
            "auditor_fp_violation": 0.01390085305164089,
            "ave_precision_score": 0.8140410999836759,
            "fpr": 0.3194291986827662,
            "logloss": 1.7211864466306748,
            "mae": 0.36411805349298876,
            "precision": 0.6051560379918589,
            "recall": 0.9591397849462365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7771834692907618,
            "auditor_fn_violation": 0.002300613496932515,
            "auditor_fp_violation": 0.01688285429886774,
            "ave_precision_score": 0.7774078483704832,
            "fpr": 0.39364035087719296,
            "logloss": 1.5414693152604655,
            "mae": 0.39855512829212547,
            "precision": 0.5700598802395209,
            "recall": 0.9734151329243353
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7750725677482998,
            "auditor_fn_violation": 0.004423828240265337,
            "auditor_fp_violation": 0.011567636215069444,
            "ave_precision_score": 0.77476491369572,
            "fpr": 0.40175631174533477,
            "logloss": 1.578347062226316,
            "mae": 0.4055187142230202,
            "precision": 0.5492610837438424,
            "recall": 0.9591397849462365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8395361151885065,
            "auditor_fn_violation": 0.004592257740465685,
            "auditor_fp_violation": 0.01974461863879557,
            "ave_precision_score": 0.839754226703461,
            "fpr": 0.15679824561403508,
            "logloss": 0.8395391714121693,
            "mae": 0.269450238659098,
            "precision": 0.7380952380952381,
            "recall": 0.8241308793456033
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8142814666139253,
            "auditor_fn_violation": 0.007655536277044017,
            "auditor_fp_violation": 0.02167085890929497,
            "ave_precision_score": 0.8145969152837762,
            "fpr": 0.18551042810098792,
            "logloss": 0.9400534892010938,
            "mae": 0.2815572283851334,
            "precision": 0.6960431654676259,
            "recall": 0.832258064516129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.6605395506958516,
            "auditor_fn_violation": 0.0012130915222616904,
            "auditor_fp_violation": 0.0009072622454481357,
            "ave_precision_score": 0.6615579348558391,
            "fpr": 0.0021929824561403508,
            "logloss": 6.648940431039011,
            "mae": 0.5254450507423516,
            "precision": 0.7142857142857143,
            "recall": 0.010224948875255624
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6395898802465214,
            "auditor_fn_violation": 0.0012747423958075262,
            "auditor_fp_violation": 0.0005193130300807766,
            "ave_precision_score": 0.6404460066296483,
            "fpr": 0.0010976948408342481,
            "logloss": 6.2195474116432115,
            "mae": 0.4946595783317587,
            "precision": 0.8571428571428571,
            "recall": 0.012903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6239796444774433,
            "auditor_fn_violation": 0.012099522835719159,
            "auditor_fp_violation": 0.005241383600846089,
            "ave_precision_score": 0.6251989909510086,
            "fpr": 0.08991228070175439,
            "logloss": 6.1466033282426515,
            "mae": 0.4502898290305192,
            "precision": 0.6611570247933884,
            "recall": 0.32719836400818
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6306829367706352,
            "auditor_fn_violation": 0.014033969524214214,
            "auditor_fp_violation": 0.0015751674846052012,
            "ave_precision_score": 0.6314591929608817,
            "fpr": 0.0845225027442371,
            "logloss": 5.808428699421629,
            "mae": 0.4243682109058446,
            "precision": 0.6709401709401709,
            "recall": 0.33763440860215055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6462183990302838,
            "auditor_fn_violation": 0.007020683098338888,
            "auditor_fp_violation": 0.0003292065862054689,
            "ave_precision_score": 0.6471884444091726,
            "fpr": 0.03728070175438596,
            "logloss": 4.403866538724318,
            "mae": 0.47021308679275936,
            "precision": 0.7235772357723578,
            "recall": 0.18200408997955012
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6474346209883208,
            "auditor_fn_violation": 0.0075847172550547156,
            "auditor_fp_violation": 0.004666433673142902,
            "ave_precision_score": 0.6481106251886588,
            "fpr": 0.030735455543358946,
            "logloss": 4.178827761896371,
            "mae": 0.4380836145679926,
            "precision": 0.7741935483870968,
            "recall": 0.2064516129032258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4550438596491228,
            "auc_prc": 0.46793501487160516,
            "auditor_fn_violation": 0.003202023463566904,
            "auditor_fp_violation": 0.005583551076272258,
            "ave_precision_score": 0.4597856802396075,
            "fpr": 0.37609649122807015,
            "logloss": 6.26357731768018,
            "mae": 0.542241704552019,
            "precision": 0.4941002949852507,
            "recall": 0.6850715746421268
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.45354067258696534,
            "auditor_fn_violation": 0.011472681562267627,
            "auditor_fp_violation": 0.0006546789857890525,
            "ave_precision_score": 0.44231646751211706,
            "fpr": 0.3907793633369923,
            "logloss": 6.540743372486853,
            "mae": 0.5367226928547272,
            "precision": 0.4833091436865022,
            "recall": 0.7161290322580646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.8736175989772641,
            "auditor_fn_violation": 0.0007601442255946618,
            "auditor_fp_violation": 0.015724150802538264,
            "ave_precision_score": 0.8737894987107822,
            "fpr": 0.3190789473684211,
            "logloss": 0.9122423590427173,
            "mae": 0.3399445203951409,
            "precision": 0.6196078431372549,
            "recall": 0.9693251533742331
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.8470834585350631,
            "auditor_fn_violation": 0.005736340781133813,
            "auditor_fp_violation": 0.011993423675751777,
            "ave_precision_score": 0.8473401644069929,
            "fpr": 0.33479692645444564,
            "logloss": 1.0192414603536903,
            "mae": 0.35458673555441006,
            "precision": 0.5965608465608465,
            "recall": 0.9698924731182795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.6495433217392613,
            "auditor_fn_violation": 0.004343360958633824,
            "auditor_fp_violation": 0.0025532951764754676,
            "ave_precision_score": 0.650389582343185,
            "fpr": 0.008771929824561403,
            "logloss": 4.7088864699739625,
            "mae": 0.503662017960263,
            "precision": 0.7837837837837838,
            "recall": 0.05930470347648262
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6215078499095371,
            "auditor_fn_violation": 0.006373711979037569,
            "auditor_fp_violation": 0.0027220863093333596,
            "ave_precision_score": 0.6223296929709701,
            "fpr": 0.009879253567508232,
            "logloss": 4.563317168999667,
            "mae": 0.47599777182462943,
            "precision": 0.8125,
            "recall": 0.08387096774193549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8707399491900774,
            "auditor_fn_violation": 0.0023006134969325155,
            "auditor_fp_violation": 0.02104070756086434,
            "ave_precision_score": 0.8709156629627984,
            "fpr": 0.19188596491228072,
            "logloss": 0.6077730717848888,
            "mae": 0.28164533254895713,
            "precision": 0.7145187601957586,
            "recall": 0.8957055214723927
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8420408607349881,
            "auditor_fn_violation": 0.0046976617919573214,
            "auditor_fp_violation": 0.021451812180967065,
            "ave_precision_score": 0.8423362657450473,
            "fpr": 0.21624588364434688,
            "logloss": 0.6790525369481758,
            "mae": 0.2917074524718446,
            "precision": 0.6770491803278689,
            "recall": 0.8881720430107527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6125101024368063,
            "auditor_fn_violation": 0.009702489864743674,
            "auditor_fp_violation": 0.006485628966032104,
            "ave_precision_score": 0.6174641984522906,
            "fpr": 0.05921052631578947,
            "logloss": 10.094610413849292,
            "mae": 0.4598039897663282,
            "precision": 0.7032967032967034,
            "recall": 0.261758691206544
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6105725052115081,
            "auditor_fn_violation": 0.007825501929818353,
            "auditor_fp_violation": 0.006721535000713749,
            "ave_precision_score": 0.6149449242627698,
            "fpr": 0.04939626783754116,
            "logloss": 9.751941009511462,
            "mae": 0.4394142943638761,
            "precision": 0.7272727272727273,
            "recall": 0.25806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8552253143544887,
            "auditor_fn_violation": 0.027504215549097696,
            "auditor_fp_violation": 0.024947119571979596,
            "ave_precision_score": 0.8554402636030725,
            "fpr": 0.13157894736842105,
            "logloss": 0.6201076468262234,
            "mae": 0.2831660503003118,
            "precision": 0.7556008146639511,
            "recall": 0.7586912065439673
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8038887616737678,
            "auditor_fn_violation": 0.016373357883927624,
            "auditor_fp_violation": 0.03171501282284781,
            "ave_precision_score": 0.8044687180847916,
            "fpr": 0.14709110867178923,
            "logloss": 0.6334583747503278,
            "mae": 0.2842694600572775,
            "precision": 0.7335984095427436,
            "recall": 0.7935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8225806797536691,
            "auditor_fn_violation": 0.0015741039715854064,
            "auditor_fp_violation": 0.009697337314918496,
            "ave_precision_score": 0.8227574236912212,
            "fpr": 0.31469298245614036,
            "logloss": 1.5307087741275167,
            "mae": 0.3577184387413262,
            "precision": 0.6198675496688741,
            "recall": 0.9570552147239264
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8173308712226248,
            "auditor_fn_violation": 0.004877069980996897,
            "auditor_fp_violation": 0.014336485309102013,
            "ave_precision_score": 0.8176142944746873,
            "fpr": 0.3172338090010977,
            "logloss": 1.6140430372260908,
            "mae": 0.36487912852828247,
            "precision": 0.6046511627906976,
            "recall": 0.9505376344086022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7974421734845016,
            "auditor_fn_violation": 0.01905742116026263,
            "auditor_fp_violation": 0.011828107502799555,
            "ave_precision_score": 0.798554811271118,
            "fpr": 0.07346491228070176,
            "logloss": 0.678597214932261,
            "mae": 0.3183255745239604,
            "precision": 0.8154269972451791,
            "recall": 0.6053169734151329
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7913509508672238,
            "auditor_fn_violation": 0.014456523022083726,
            "auditor_fp_violation": 0.01558923569920208,
            "ave_precision_score": 0.7917679613841972,
            "fpr": 0.08562019758507135,
            "logloss": 0.6994230473259753,
            "mae": 0.31982469848031975,
            "precision": 0.7857142857142857,
            "recall": 0.6150537634408603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 24284,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.8150869242433159,
            "auditor_fn_violation": 0.0006143938578552721,
            "auditor_fp_violation": 0.012919414375181447,
            "ave_precision_score": 0.8152330550842427,
            "fpr": 0.4298245614035088,
            "logloss": 2.131761860508516,
            "mae": 0.4102805634682769,
            "precision": 0.5545454545454546,
            "recall": 0.9979550102249489
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.8129344194709265,
            "auditor_fn_violation": 0.0020608335398888144,
            "auditor_fp_violation": 0.012729322234965788,
            "ave_precision_score": 0.8128629727043422,
            "fpr": 0.442371020856202,
            "logloss": 2.206038241446632,
            "mae": 0.4246437391583142,
            "precision": 0.5341040462427745,
            "recall": 0.9935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6456264368092968,
            "auditor_fn_violation": 0.002980034441933075,
            "auditor_fp_violation": 0.0013038654556011796,
            "ave_precision_score": 0.6473498693618348,
            "fpr": 0.03837719298245614,
            "logloss": 4.236799230705355,
            "mae": 0.46780763068035564,
            "precision": 0.7388059701492538,
            "recall": 0.20245398773006135
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6476671149349251,
            "auditor_fn_violation": 0.006406760855965922,
            "auditor_fp_violation": 0.004405546558505167,
            "ave_precision_score": 0.6482580440438092,
            "fpr": 0.029637760702524697,
            "logloss": 4.044432262704068,
            "mae": 0.4375767707194319,
            "precision": 0.7938931297709924,
            "recall": 0.22365591397849463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8364894820620745,
            "auditor_fn_violation": 0.02973980195888494,
            "auditor_fp_violation": 0.025727365103065,
            "ave_precision_score": 0.8367924798998212,
            "fpr": 0.1524122807017544,
            "logloss": 1.7898164027636467,
            "mae": 0.2844449988165791,
            "precision": 0.7387218045112782,
            "recall": 0.803680981595092
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8037213811691646,
            "auditor_fn_violation": 0.028530623325425213,
            "auditor_fp_violation": 0.04140229285316978,
            "ave_precision_score": 0.8039065463714712,
            "fpr": 0.18221734357848518,
            "logloss": 1.6416868498181605,
            "mae": 0.2949933779295,
            "precision": 0.6942909760589319,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8623028199899933,
            "auditor_fn_violation": 0.020792971693036268,
            "auditor_fp_violation": 0.025408527228236076,
            "ave_precision_score": 0.8625990987843981,
            "fpr": 0.20175438596491227,
            "logloss": 0.6916549666554366,
            "mae": 0.27963136824594886,
            "precision": 0.7032258064516129,
            "recall": 0.8916155419222904
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.814649630229509,
            "auditor_fn_violation": 0.011057209966597032,
            "auditor_fp_violation": 0.03755789971105522,
            "ave_precision_score": 0.8150572957195374,
            "fpr": 0.22941822173435786,
            "logloss": 0.7714946193471005,
            "mae": 0.29099722915512033,
            "precision": 0.669826224328594,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6410136969580951,
            "auditor_fn_violation": 0.01279912460086822,
            "auditor_fp_violation": 0.007468064368960226,
            "ave_precision_score": 0.6428365051155667,
            "fpr": 0.09978070175438597,
            "logloss": 3.7248391309062443,
            "mae": 0.4311625797344737,
            "precision": 0.6795774647887324,
            "recall": 0.3946830265848671
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6405546163915262,
            "auditor_fn_violation": 0.0140080025494848,
            "auditor_fp_violation": 0.008328698074849991,
            "ave_precision_score": 0.6415475448554513,
            "fpr": 0.10318331503841932,
            "logloss": 3.531891140298763,
            "mae": 0.4171468853182049,
            "precision": 0.6606498194945848,
            "recall": 0.3935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8623411775807546,
            "auditor_fn_violation": 0.015480931367272988,
            "auditor_fp_violation": 0.02521411388992577,
            "ave_precision_score": 0.8625547580340451,
            "fpr": 0.2050438596491228,
            "logloss": 0.6992884305180255,
            "mae": 0.28693381445829574,
            "precision": 0.6983870967741935,
            "recall": 0.885480572597137
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8047730843934939,
            "auditor_fn_violation": 0.009355192804787369,
            "auditor_fp_violation": 0.03704597027855853,
            "ave_precision_score": 0.8053632291027353,
            "fpr": 0.22722283205268934,
            "logloss": 0.774722664748873,
            "mae": 0.29636366857863905,
            "precision": 0.6693290734824281,
            "recall": 0.9010752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8126523439454763,
            "auditor_fn_violation": 0.011545671438309478,
            "auditor_fp_violation": 0.012849425573389741,
            "ave_precision_score": 0.812984051467902,
            "fpr": 0.21271929824561403,
            "logloss": 0.9627304503233325,
            "mae": 0.30343573314462446,
            "precision": 0.6819672131147541,
            "recall": 0.8507157464212679
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8184094755688632,
            "auditor_fn_violation": 0.007917566658404452,
            "auditor_fp_violation": 0.00677814258219175,
            "ave_precision_score": 0.8187356162491499,
            "fpr": 0.21624588364434688,
            "logloss": 1.009414693883835,
            "mae": 0.3086772321328503,
            "precision": 0.6661016949152543,
            "recall": 0.8451612903225807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8384781551937932,
            "auditor_fn_violation": 0.0077427079969863335,
            "auditor_fp_violation": 0.025558873543196053,
            "ave_precision_score": 0.8388206316258275,
            "fpr": 0.17653508771929824,
            "logloss": 0.8856588549611216,
            "mae": 0.27087236164853407,
            "precision": 0.7228915662650602,
            "recall": 0.8588957055214724
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8234595438181846,
            "auditor_fn_violation": 0.011012357919337135,
            "auditor_fp_violation": 0.024523388775947192,
            "ave_precision_score": 0.8236245799980346,
            "fpr": 0.19099890230515917,
            "logloss": 1.0193215259175503,
            "mae": 0.2804139998364093,
            "precision": 0.6963350785340314,
            "recall": 0.8580645161290322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8436338061332374,
            "auditor_fn_violation": 0.007998331718867721,
            "auditor_fp_violation": 0.022163120567375894,
            "ave_precision_score": 0.8439254933365263,
            "fpr": 0.22039473684210525,
            "logloss": 0.8187623135809428,
            "mae": 0.29776576544782873,
            "precision": 0.6829652996845426,
            "recall": 0.885480572597137
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8373739618661511,
            "auditor_fn_violation": 0.002879973560898458,
            "auditor_fp_violation": 0.02363489586666208,
            "ave_precision_score": 0.8374614531512178,
            "fpr": 0.22502744237102085,
            "logloss": 0.9428504555697924,
            "mae": 0.30544766947734026,
            "precision": 0.6666666666666666,
            "recall": 0.8817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8097489316727727,
            "auditor_fn_violation": 0.006260538872744235,
            "auditor_fp_violation": 0.015586765376798976,
            "ave_precision_score": 0.8100971465911639,
            "fpr": 0.21929824561403508,
            "logloss": 0.9599357610230981,
            "mae": 0.30741561518349153,
            "precision": 0.68,
            "recall": 0.869120654396728
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8243995778956434,
            "auditor_fn_violation": 0.005686767465741297,
            "auditor_fp_violation": 0.009524840883472059,
            "ave_precision_score": 0.8246748460166526,
            "fpr": 0.21734357848518113,
            "logloss": 0.9835798495838232,
            "mae": 0.30470128949055303,
            "precision": 0.6683417085427136,
            "recall": 0.8580645161290322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8416531524244677,
            "auditor_fn_violation": 0.002143651562443943,
            "auditor_fp_violation": 0.013181224337439349,
            "ave_precision_score": 0.8418448434962547,
            "fpr": 0.3706140350877193,
            "logloss": 1.0938708157796584,
            "mae": 0.3693979004129416,
            "precision": 0.5842558425584256,
            "recall": 0.9713701431492843
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.8242654141616221,
            "auditor_fn_violation": 0.0017563117453347976,
            "auditor_fp_violation": 0.01796183172288867,
            "ave_precision_score": 0.8245212859261336,
            "fpr": 0.3754116355653128,
            "logloss": 1.1475558703876818,
            "mae": 0.3718970608258565,
            "precision": 0.5665399239543726,
            "recall": 0.9612903225806452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8616338647741474,
            "auditor_fn_violation": 0.011177932048936247,
            "auditor_fp_violation": 0.019840529219028673,
            "ave_precision_score": 0.8618423894377165,
            "fpr": 0.18530701754385964,
            "logloss": 0.647820052661205,
            "mae": 0.2761727759115104,
            "precision": 0.7183333333333334,
            "recall": 0.8813905930470347
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8315952848573356,
            "auditor_fn_violation": 0.005394048841518832,
            "auditor_fp_violation": 0.022630726595226257,
            "ave_precision_score": 0.8318983007316919,
            "fpr": 0.21185510428100987,
            "logloss": 0.7301092594869799,
            "mae": 0.2863233240929687,
            "precision": 0.6799336650082919,
            "recall": 0.8817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8314851187940638,
            "auditor_fn_violation": 0.0018566354536648383,
            "auditor_fp_violation": 0.016063726100120284,
            "ave_precision_score": 0.8316987491905283,
            "fpr": 0.30372807017543857,
            "logloss": 1.4057643195851872,
            "mae": 0.34484777253594967,
            "precision": 0.628686327077748,
            "recall": 0.9591002044989775
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.8251461982029238,
            "auditor_fn_violation": 0.003965865231401156,
            "auditor_fp_violation": 0.011316593897210476,
            "ave_precision_score": 0.8254700295231304,
            "fpr": 0.3084522502744237,
            "logloss": 1.488707226671205,
            "mae": 0.35182766009911354,
            "precision": 0.6124137931034482,
            "recall": 0.9548387096774194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8564425158966622,
            "auditor_fn_violation": 0.011978437914827977,
            "auditor_fp_violation": 0.01292719090871387,
            "ave_precision_score": 0.8566714433020819,
            "fpr": 0.13267543859649122,
            "logloss": 0.6733225052669548,
            "mae": 0.26850539866245826,
            "precision": 0.7570281124497992,
            "recall": 0.7709611451942741
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8276728047064577,
            "auditor_fn_violation": 0.011536418682058005,
            "auditor_fp_violation": 0.017166864383001974,
            "ave_precision_score": 0.8280484333495889,
            "fpr": 0.1394072447859495,
            "logloss": 0.7260943349878051,
            "mae": 0.27412820697857604,
            "precision": 0.742393509127789,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8256332362889696,
            "auditor_fn_violation": 0.012718401320274101,
            "auditor_fp_violation": 0.01782640703413381,
            "ave_precision_score": 0.825580891669449,
            "fpr": 0.2050438596491228,
            "logloss": 0.9428685650629606,
            "mae": 0.29288507587676704,
            "precision": 0.6944444444444444,
            "recall": 0.869120654396728
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8002329445083526,
            "auditor_fn_violation": 0.01052370666761092,
            "auditor_fp_violation": 0.021707776897215408,
            "ave_precision_score": 0.8005618094279149,
            "fpr": 0.20965971459934138,
            "logloss": 1.1164159600926424,
            "mae": 0.3051230071213978,
            "precision": 0.6827242524916943,
            "recall": 0.8838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.611359629338953,
            "auditor_fn_violation": 0.010648746098374776,
            "auditor_fp_violation": 0.0056198415660901726,
            "ave_precision_score": 0.6121083334443473,
            "fpr": 0.14912280701754385,
            "logloss": 3.9557590024671763,
            "mae": 0.4577077917822046,
            "precision": 0.6034985422740525,
            "recall": 0.4233128834355828
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5894715072196421,
            "auditor_fn_violation": 0.008996376426708226,
            "auditor_fp_violation": 0.013959921832313585,
            "ave_precision_score": 0.5904095343655994,
            "fpr": 0.13830954994511527,
            "logloss": 3.7336909846690194,
            "mae": 0.4446016841893757,
            "precision": 0.60625,
            "recall": 0.4172043010752688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8663873498239294,
            "auditor_fn_violation": 0.012987478922254513,
            "auditor_fp_violation": 0.02659315250300692,
            "ave_precision_score": 0.8666029669132257,
            "fpr": 0.21162280701754385,
            "logloss": 0.7266623690142417,
            "mae": 0.288175216920392,
            "precision": 0.6965408805031447,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8197890174892668,
            "auditor_fn_violation": 0.010143644582934977,
            "auditor_fp_violation": 0.03991080614118424,
            "ave_precision_score": 0.820199094018793,
            "fpr": 0.2349066959385291,
            "logloss": 0.8102054740678274,
            "mae": 0.29738504168425167,
            "precision": 0.6692426584234931,
            "recall": 0.9311827956989247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.63484325531372,
            "auditor_fn_violation": 0.008267409320848147,
            "auditor_fp_violation": 0.004471506781137245,
            "ave_precision_score": 0.6360257121986224,
            "fpr": 0.09210526315789473,
            "logloss": 5.047773972100759,
            "mae": 0.4437711036001857,
            "precision": 0.6612903225806451,
            "recall": 0.33537832310838445
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.647346044015874,
            "auditor_fn_violation": 0.014229902151717964,
            "auditor_fp_violation": 0.002808228281147708,
            "ave_precision_score": 0.6479940601926714,
            "fpr": 0.0845225027442371,
            "logloss": 4.678052555235873,
            "mae": 0.4150766829138761,
            "precision": 0.6831275720164609,
            "recall": 0.35698924731182796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8402658121784163,
            "auditor_fn_violation": 0.0020158397015032476,
            "auditor_fp_violation": 0.02642984529882627,
            "ave_precision_score": 0.8405206633202463,
            "fpr": 0.23903508771929824,
            "logloss": 0.878287775222407,
            "mae": 0.29588326548816657,
            "precision": 0.678939617083947,
            "recall": 0.9427402862985685
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7990308345367634,
            "auditor_fn_violation": 0.008854738382729602,
            "auditor_fp_violation": 0.026398822562305257,
            "ave_precision_score": 0.7995003530149849,
            "fpr": 0.25905598243688255,
            "logloss": 0.9895719789713097,
            "mae": 0.31152694651272594,
            "precision": 0.6477611940298508,
            "recall": 0.9333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 24284,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8296294972767654,
            "auditor_fn_violation": 0.00596679582391562,
            "auditor_fp_violation": 0.022712662270333042,
            "ave_precision_score": 0.8296809854649198,
            "fpr": 0.1699561403508772,
            "logloss": 0.9216768635379383,
            "mae": 0.26792663281360346,
            "precision": 0.7256637168141593,
            "recall": 0.8384458077709611
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.818616660727217,
            "auditor_fn_violation": 0.010294725163178833,
            "auditor_fp_violation": 0.020021855448848908,
            "ave_precision_score": 0.8188931750410149,
            "fpr": 0.18111964873765093,
            "logloss": 1.0170571339633403,
            "mae": 0.2793449595818861,
            "precision": 0.701627486437613,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 24284,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8308149401956367,
            "auditor_fn_violation": 0.006052003731209415,
            "auditor_fp_violation": 0.02486157770312306,
            "ave_precision_score": 0.8311929448902211,
            "fpr": 0.16228070175438597,
            "logloss": 0.9044207665983901,
            "mae": 0.26592942175624135,
            "precision": 0.7342908438061041,
            "recall": 0.83640081799591
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8196267990158155,
            "auditor_fn_violation": 0.009815516447717857,
            "auditor_fp_violation": 0.018355623594039958,
            "ave_precision_score": 0.8199353855605871,
            "fpr": 0.1778265642151482,
            "logloss": 0.9945408282592479,
            "mae": 0.2774853965311293,
            "precision": 0.7032967032967034,
            "recall": 0.8258064516129032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8440488981964279,
            "auditor_fn_violation": 0.00349800882574535,
            "auditor_fp_violation": 0.014376218323586746,
            "ave_precision_score": 0.8448256606283681,
            "fpr": 0.10307017543859649,
            "logloss": 0.709183747058662,
            "mae": 0.26368891534293315,
            "precision": 0.7956521739130434,
            "recall": 0.7484662576687117
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8278536901541702,
            "auditor_fn_violation": 0.011876349987606673,
            "auditor_fp_violation": 0.01590426919612312,
            "ave_precision_score": 0.8281275863624857,
            "fpr": 0.12294182217343579,
            "logloss": 0.7803191689046974,
            "mae": 0.27093406778212226,
            "precision": 0.7611940298507462,
            "recall": 0.7677419354838709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.770808445258004,
            "auditor_fn_violation": 0.007919850751623434,
            "auditor_fp_violation": 0.012867570818298703,
            "ave_precision_score": 0.7723332015607235,
            "fpr": 0.16885964912280702,
            "logloss": 0.830689263793217,
            "mae": 0.3211808370687507,
            "precision": 0.7032755298651252,
            "recall": 0.7464212678936605
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7522383090061247,
            "auditor_fn_violation": 0.016819517722460254,
            "auditor_fp_violation": 0.014821341550457051,
            "ave_precision_score": 0.7527930086478134,
            "fpr": 0.19319429198682767,
            "logloss": 0.9163223477795768,
            "mae": 0.3314084098789231,
            "precision": 0.6685499058380414,
            "recall": 0.7634408602150538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6482664972625298,
            "auditor_fn_violation": 0.005058658917231751,
            "auditor_fp_violation": 0.0032168927045746754,
            "ave_precision_score": 0.6492635782398096,
            "fpr": 0.03179824561403509,
            "logloss": 4.417175315118931,
            "mae": 0.4792143226538948,
            "precision": 0.7289719626168224,
            "recall": 0.15950920245398773
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6507817025740988,
            "auditor_fn_violation": 0.005453064693176591,
            "auditor_fp_violation": 0.0029386718384665747,
            "ave_precision_score": 0.6515251448385062,
            "fpr": 0.026344676180021953,
            "logloss": 4.178809057124971,
            "mae": 0.4455519924971551,
            "precision": 0.7837837837837838,
            "recall": 0.1870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7841866408751076,
            "auditor_fn_violation": 0.006659670649015177,
            "auditor_fp_violation": 0.015451972128903826,
            "ave_precision_score": 0.7845052149364448,
            "fpr": 0.2675438596491228,
            "logloss": 1.4015586209233242,
            "mae": 0.34438576399628673,
            "precision": 0.6406480117820325,
            "recall": 0.8895705521472392
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7912319958314205,
            "auditor_fn_violation": 0.010622853298395948,
            "auditor_fp_violation": 0.01768125501469336,
            "ave_precision_score": 0.7914162956437255,
            "fpr": 0.265642151481888,
            "logloss": 1.4243779343502314,
            "mae": 0.34349761063626094,
            "precision": 0.6259659969088099,
            "recall": 0.8709677419354839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6768977482471287,
            "auditor_fn_violation": 0.0038769597818677625,
            "auditor_fp_violation": 0.002778814648915434,
            "ave_precision_score": 0.6776899568614394,
            "fpr": 0.1425438596491228,
            "logloss": 2.5327186703498317,
            "mae": 0.39945903855793685,
            "precision": 0.6658097686375322,
            "recall": 0.5296523517382413
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6801250382211668,
            "auditor_fn_violation": 0.01586110029153831,
            "auditor_fp_violation": 0.011279675909290045,
            "ave_precision_score": 0.6807229687442314,
            "fpr": 0.132821075740944,
            "logloss": 2.3255239393119203,
            "mae": 0.379362558173926,
            "precision": 0.6764705882352942,
            "recall": 0.5440860215053763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.8059106206129566,
            "auditor_fn_violation": 0.0019216625408101033,
            "auditor_fp_violation": 0.01470024055410393,
            "ave_precision_score": 0.8060909277334991,
            "fpr": 0.32785087719298245,
            "logloss": 1.5506045386129301,
            "mae": 0.360483947385316,
            "precision": 0.6096605744125326,
            "recall": 0.9550102249488752
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8175454675019708,
            "auditor_fn_violation": 0.0004886512517262143,
            "auditor_fp_violation": 0.012862226991479339,
            "ave_precision_score": 0.8180080440997514,
            "fpr": 0.32821075740944017,
            "logloss": 1.5825786551147005,
            "mae": 0.3545110427325125,
            "precision": 0.599195710455764,
            "recall": 0.9612903225806452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7646797734308652,
            "auditor_fn_violation": 0.008213593800452054,
            "auditor_fp_violation": 0.017077267637178054,
            "ave_precision_score": 0.7618816927757031,
            "fpr": 0.22697368421052633,
            "logloss": 1.2392564667841834,
            "mae": 0.31999975804763525,
            "precision": 0.6693290734824281,
            "recall": 0.8568507157464212
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.772501816756108,
            "auditor_fn_violation": 0.004589072624907054,
            "auditor_fp_violation": 0.008712645149222516,
            "ave_precision_score": 0.7695818989737979,
            "fpr": 0.2283205268935236,
            "logloss": 1.2695258404011731,
            "mae": 0.31307076432662145,
            "precision": 0.657331136738056,
            "recall": 0.8580645161290322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6234201724867778,
            "auditor_fn_violation": 0.00651840490797548,
            "auditor_fp_violation": 0.00125979843225084,
            "ave_precision_score": 0.6247002358506376,
            "fpr": 0.13706140350877194,
            "logloss": 5.8014740950800725,
            "mae": 0.44365140210897774,
            "precision": 0.6268656716417911,
            "recall": 0.4294478527607362
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6331191746443843,
            "auditor_fn_violation": 0.00616125491306965,
            "auditor_fp_violation": 0.008013664577928955,
            "ave_precision_score": 0.6338370997834839,
            "fpr": 0.1141602634467618,
            "logloss": 5.423891872835407,
            "mae": 0.4140412733935094,
            "precision": 0.6578947368421053,
            "recall": 0.43010752688172044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6416834696215998,
            "auditor_fn_violation": 0.0032177196570157564,
            "auditor_fp_violation": 0.0073488241881299,
            "ave_precision_score": 0.6427500764340565,
            "fpr": 0.1337719298245614,
            "logloss": 3.915951566445715,
            "mae": 0.42245848856904966,
            "precision": 0.6534090909090909,
            "recall": 0.4703476482617587
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6565793380239583,
            "auditor_fn_violation": 0.013689316950532932,
            "auditor_fp_violation": 0.006915969737094703,
            "ave_precision_score": 0.6571665268988611,
            "fpr": 0.11745334796926454,
            "logloss": 3.5823988172272374,
            "mae": 0.4032668971397181,
            "precision": 0.6687306501547987,
            "recall": 0.4645161290322581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 24284,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7963797400753208,
            "auditor_fn_violation": 0.020005919707243577,
            "auditor_fp_violation": 0.013678922483513751,
            "ave_precision_score": 0.7966869957994651,
            "fpr": 0.14692982456140352,
            "logloss": 0.7492019213397847,
            "mae": 0.346863628844084,
            "precision": 0.7124463519313304,
            "recall": 0.6789366053169734
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7708432399912463,
            "auditor_fn_violation": 0.013214829503204564,
            "auditor_fp_violation": 0.017922452535773528,
            "ave_precision_score": 0.771422352302605,
            "fpr": 0.14928649835345773,
            "logloss": 0.7699581936606696,
            "mae": 0.33994702511236435,
            "precision": 0.7068965517241379,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.8065490964127594,
            "auditor_fn_violation": 0.0069623829512431385,
            "auditor_fp_violation": 0.019270250093318408,
            "ave_precision_score": 0.8067928289429965,
            "fpr": 0.29605263157894735,
            "logloss": 0.928926137967396,
            "mae": 0.35069089438694756,
            "precision": 0.6197183098591549,
            "recall": 0.8997955010224948
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7767144698828472,
            "auditor_fn_violation": 0.009397684217980951,
            "auditor_fp_violation": 0.024570151560646413,
            "ave_precision_score": 0.7770897351724599,
            "fpr": 0.3040614709110867,
            "logloss": 1.0026952781387337,
            "mae": 0.35191683158325493,
            "precision": 0.6059743954480796,
            "recall": 0.9161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.788455005073378,
            "auditor_fn_violation": 0.0042671223047393535,
            "auditor_fp_violation": 0.008854879515573809,
            "ave_precision_score": 0.7599244013113664,
            "fpr": 0.39364035087719296,
            "logloss": 3.377631878533087,
            "mae": 0.4095214551665488,
            "precision": 0.5679903730445247,
            "recall": 0.9652351738241309
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7655694040177962,
            "auditor_fn_violation": 0.0027265323465882935,
            "auditor_fp_violation": 0.012724399836576389,
            "ave_precision_score": 0.7316437651229706,
            "fpr": 0.40175631174533477,
            "logloss": 3.683965701273686,
            "mae": 0.41539792067826364,
            "precision": 0.5514705882352942,
            "recall": 0.967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.82274763821594,
            "auditor_fn_violation": 0.013009902055752889,
            "auditor_fp_violation": 0.012281738625523621,
            "ave_precision_score": 0.8230150755554296,
            "fpr": 0.1074561403508772,
            "logloss": 0.7065004235388096,
            "mae": 0.3147356320505024,
            "precision": 0.7710280373831776,
            "recall": 0.6748466257668712
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8025098123729119,
            "auditor_fn_violation": 0.008257497963953121,
            "auditor_fp_violation": 0.013657194331366022,
            "ave_precision_score": 0.8028340130135379,
            "fpr": 0.11086717892425905,
            "logloss": 0.7087992774430625,
            "mae": 0.3081409385644338,
            "precision": 0.7589498806682577,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8653867283304177,
            "auditor_fn_violation": 0.00350922039249453,
            "auditor_fp_violation": 0.0189591887520219,
            "ave_precision_score": 0.8655818558932131,
            "fpr": 0.19407894736842105,
            "logloss": 0.6323103667656199,
            "mae": 0.2779818219733357,
            "precision": 0.7117263843648208,
            "recall": 0.8936605316973415
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8359338116711023,
            "auditor_fn_violation": 0.008158351333168092,
            "auditor_fp_violation": 0.020575625267655426,
            "ave_precision_score": 0.8362703335298904,
            "fpr": 0.21295279912184412,
            "logloss": 0.7095264569633697,
            "mae": 0.2883386221561841,
            "precision": 0.680921052631579,
            "recall": 0.8903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6447965878869136,
            "auditor_fn_violation": 0.011736268073045602,
            "auditor_fp_violation": 0.006252332960059723,
            "ave_precision_score": 0.6458941518430587,
            "fpr": 0.05921052631578947,
            "logloss": 3.94548890091875,
            "mae": 0.44849430560686404,
            "precision": 0.7216494845360825,
            "recall": 0.28629856850715746
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6520325300093175,
            "auditor_fn_violation": 0.012846570588860176,
            "auditor_fp_violation": 0.010095839096641447,
            "ave_precision_score": 0.6526307954247547,
            "fpr": 0.0570801317233809,
            "logloss": 3.744965577354401,
            "mae": 0.42244180957766075,
            "precision": 0.7277486910994765,
            "recall": 0.2989247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8228644865828535,
            "auditor_fn_violation": 0.010790011839414484,
            "auditor_fp_violation": 0.009992845589150185,
            "ave_precision_score": 0.8231328306609227,
            "fpr": 0.10526315789473684,
            "logloss": 0.7026991738973927,
            "mae": 0.3146733490492519,
            "precision": 0.7746478873239436,
            "recall": 0.6748466257668712
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8027675573941342,
            "auditor_fn_violation": 0.007273113558301769,
            "auditor_fp_violation": 0.016563870580301544,
            "ave_precision_score": 0.8030912850562506,
            "fpr": 0.10757409440175632,
            "logloss": 0.7041437998813007,
            "mae": 0.3080514526851776,
            "precision": 0.7644230769230769,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6404749839593045,
            "auditor_fn_violation": 0.010218221935206119,
            "auditor_fp_violation": 0.012014744307577457,
            "ave_precision_score": 0.6422772466820099,
            "fpr": 0.10855263157894737,
            "logloss": 3.592504632139943,
            "mae": 0.4285953967121249,
            "precision": 0.67,
            "recall": 0.4110429447852761
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6399332968335195,
            "auditor_fn_violation": 0.012190314318425929,
            "auditor_fp_violation": 0.010720983692094142,
            "ave_precision_score": 0.6406535795744788,
            "fpr": 0.1119648737650933,
            "logloss": 3.4240623643461565,
            "mae": 0.41923880689298976,
            "precision": 0.6588628762541806,
            "recall": 0.4236559139784946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8658555824720574,
            "auditor_fn_violation": 0.013850769561941664,
            "auditor_fp_violation": 0.044823939280826175,
            "ave_precision_score": 0.8660383682077646,
            "fpr": 0.27960526315789475,
            "logloss": 0.8904577469996016,
            "mae": 0.3274847766154524,
            "precision": 0.6443514644351465,
            "recall": 0.9447852760736196
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.8166571801591604,
            "auditor_fn_violation": 0.008654084487093235,
            "auditor_fp_violation": 0.05115110286335915,
            "ave_precision_score": 0.8171451692823996,
            "fpr": 0.3018660812294182,
            "logloss": 1.0077725042397436,
            "mae": 0.33802840175962284,
            "precision": 0.6175243393602226,
            "recall": 0.9548387096774194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 24284,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7916760700724836,
            "auditor_fn_violation": 0.012431385211494997,
            "auditor_fp_violation": 0.017437580357513173,
            "ave_precision_score": 0.79190822080826,
            "fpr": 0.18530701754385964,
            "logloss": 1.1680047961978137,
            "mae": 0.31416805854417906,
            "precision": 0.6976744186046512,
            "recall": 0.7975460122699386
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7958742084851432,
            "auditor_fn_violation": 0.014149640593463401,
            "auditor_fp_violation": 0.0104084113943678,
            "ave_precision_score": 0.7960519873833316,
            "fpr": 0.18990120746432493,
            "logloss": 1.2532772890209283,
            "mae": 0.31278259547088944,
            "precision": 0.6790352504638218,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8662097504402363,
            "auditor_fn_violation": 0.00858133318982528,
            "auditor_fp_violation": 0.023570673136742562,
            "ave_precision_score": 0.8664351820022904,
            "fpr": 0.15570175438596492,
            "logloss": 0.5931652341383608,
            "mae": 0.27238577657701907,
            "precision": 0.7422867513611615,
            "recall": 0.83640081799591
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8405953600972278,
            "auditor_fn_violation": 0.0075917991572536404,
            "auditor_fp_violation": 0.02644312414780978,
            "ave_precision_score": 0.8408428934010929,
            "fpr": 0.18221734357848518,
            "logloss": 0.6560650195056266,
            "mae": 0.27832009015746956,
            "precision": 0.7025089605734767,
            "recall": 0.843010752688172
        }
    }
]