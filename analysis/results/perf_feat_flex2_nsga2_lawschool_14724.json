[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6157699638143683,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5211061872882539,
            "fpr": 0.4616228070175439,
            "logloss": 0.6929980741155707,
            "mae": 0.49989971008739975,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6224983511920184,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5111874268305143,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929947935853047,
            "mae": 0.49989872889513504,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6157699638143683,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5211061872882539,
            "fpr": 0.4616228070175439,
            "logloss": 0.6929980741155707,
            "mae": 0.49989971008739975,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6224983511920184,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5111874268305143,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929947935853047,
            "mae": 0.49989872889513504,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6914545135994823,
            "mae": 0.4989757811029752,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930639007772993,
            "mae": 0.4997802836049663,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 14724,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5194376013378923,
            "auditor_fn_violation": 0.002527959409725947,
            "auditor_fp_violation": 0.010144497228820281,
            "ave_precision_score": 0.5207234596819474,
            "fpr": 0.3848684210526316,
            "logloss": 0.6936383385931352,
            "mae": 0.4998865891247988,
            "precision": 0.5084033613445378,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5440353389748043,
            "auditor_fn_violation": 0.0075676931575441005,
            "auditor_fp_violation": 0.012716598714128915,
            "ave_precision_score": 0.5441890943307613,
            "fpr": 0.3929747530186608,
            "logloss": 0.6919782165623294,
            "mae": 0.49912686503679377,
            "precision": 0.49577464788732395,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5236959912376883,
            "auditor_fn_violation": 0.0009937649623039304,
            "auditor_fp_violation": 0.006539879984998134,
            "ave_precision_score": 0.5256020728064269,
            "fpr": 0.31359649122807015,
            "logloss": 0.6944286035759943,
            "mae": 0.5001690423998394,
            "precision": 0.5303776683087028,
            "recall": 0.6578411405295316
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5309282593014409,
            "auditor_fn_violation": 0.006365681744362765,
            "auditor_fp_violation": 0.000862474517798364,
            "ave_precision_score": 0.533029328087878,
            "fpr": 0.31394072447859495,
            "logloss": 0.691741345290055,
            "mae": 0.49887499703926524,
            "precision": 0.5241264559068219,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7708694803511918,
            "auditor_fn_violation": 0.005944724336299005,
            "auditor_fp_violation": 0.0019689961245155647,
            "ave_precision_score": 0.7595187561374708,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6616416358567968,
            "mae": 0.4734944929613879,
            "precision": 0.9393939393939394,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7255540555548534,
            "auditor_fn_violation": 0.005761119790987525,
            "auditor_fp_violation": 0.0012251058491453662,
            "ave_precision_score": 0.7147481769710292,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6565940678661385,
            "mae": 0.470720413258518,
            "precision": 0.9411764705882353,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7303619702006771,
            "mae": 0.5055810582789331,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7138740752787297,
            "mae": 0.4990840912719884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6022660859203458,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5398481949853287,
            "fpr": 0.4616228070175439,
            "logloss": 0.6925453082072636,
            "mae": 0.499678905269033,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5846422013826895,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5121031924016505,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929852982995942,
            "mae": 0.4998982600401576,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 14724,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5194376013378923,
            "auditor_fn_violation": 0.002527959409725947,
            "auditor_fp_violation": 0.010144497228820281,
            "ave_precision_score": 0.5207234596819474,
            "fpr": 0.3848684210526316,
            "logloss": 0.693638337002789,
            "mae": 0.49988658847123907,
            "precision": 0.5084033613445378,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5440353389748043,
            "auditor_fn_violation": 0.0075676931575441005,
            "auditor_fp_violation": 0.012716598714128915,
            "ave_precision_score": 0.5441890943307613,
            "fpr": 0.3929747530186608,
            "logloss": 0.6919782154312033,
            "mae": 0.49912686454608596,
            "precision": 0.49577464788732395,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7053460838804272,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018361670208776157,
            "ave_precision_score": 0.7013186397026143,
            "fpr": 0.4583333333333333,
            "logloss": 0.6914324974821804,
            "mae": 0.49901482371384637,
            "precision": 0.5401540154015402,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.663158125642342,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015656852752077854,
            "ave_precision_score": 0.6570275328907261,
            "fpr": 0.4884742041712404,
            "logloss": 0.6927336485841871,
            "mae": 0.4996663393160383,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5205648131236023,
            "auditor_fn_violation": 0.005406528030871476,
            "auditor_fp_violation": 0.009165208151018903,
            "ave_precision_score": 0.5218839157608449,
            "fpr": 0.26973684210526316,
            "logloss": 0.6944351188552242,
            "mae": 0.5003835665748307,
            "precision": 0.515748031496063,
            "recall": 0.5336048879837068
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.546745158205748,
            "auditor_fn_violation": 0.0036463383697690607,
            "auditor_fp_violation": 0.012949368825466517,
            "ave_precision_score": 0.5482115389373756,
            "fpr": 0.2711306256860593,
            "logloss": 0.6919799852762272,
            "mae": 0.4992071824591979,
            "precision": 0.519455252918288,
            "recall": 0.5766738660907127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 14724,
        "test": {
            "accuracy": 0.42653508771929827,
            "auc_prc": 0.5525430119805748,
            "auditor_fn_violation": 0.0014002036659877847,
            "auditor_fp_violation": 0.006209109472017335,
            "ave_precision_score": 0.5522745589905196,
            "fpr": 0.09978070175438597,
            "logloss": 0.7151812965260472,
            "mae": 0.5033704448336115,
            "precision": 0.3933333333333333,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.43468715697036225,
            "auc_prc": 0.5059452700617296,
            "auditor_fn_violation": 0.006778206371371742,
            "auditor_fp_violation": 0.014897287125607658,
            "ave_precision_score": 0.5056281678048209,
            "fpr": 0.10867178924259056,
            "logloss": 0.7130517071709759,
            "mae": 0.5023819104932927,
            "precision": 0.3219178082191781,
            "recall": 0.10151187904967603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6857652901583461,
            "auditor_fn_violation": 0.0073404616429056345,
            "auditor_fp_violation": 0.0030472559069883737,
            "ave_precision_score": 0.6862873333363508,
            "fpr": 0.006578947368421052,
            "logloss": 0.6256112290748532,
            "mae": 0.44706518343535434,
            "precision": 0.9495798319327731,
            "recall": 0.23014256619144602
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6576083119361535,
            "auditor_fn_violation": 0.007968363628604558,
            "auditor_fp_violation": 0.0006591069468402076,
            "ave_precision_score": 0.6583933448598813,
            "fpr": 0.009879253567508232,
            "logloss": 0.6365900922525498,
            "mae": 0.4534144758376672,
            "precision": 0.9158878504672897,
            "recall": 0.21166306695464362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5194376013378923,
            "auditor_fn_violation": 0.0032961732232822368,
            "auditor_fp_violation": 0.006969621202650335,
            "ave_precision_score": 0.5207234596819474,
            "fpr": 0.25877192982456143,
            "logloss": 0.6943077692731207,
            "mae": 0.5003522474057319,
            "precision": 0.5232323232323233,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5440353389748043,
            "auditor_fn_violation": 0.00623054436654947,
            "auditor_fp_violation": 0.01180021953896818,
            "ave_precision_score": 0.5441890943307613,
            "fpr": 0.23710208562019758,
            "logloss": 0.6920514242828921,
            "mae": 0.4992714519362026,
            "precision": 0.5443037974683544,
            "recall": 0.5572354211663066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.519468479707266,
            "auditor_fn_violation": 0.005609747382713403,
            "auditor_fp_violation": 0.010204400550068764,
            "ave_precision_score": 0.5207549993121249,
            "fpr": 0.41118421052631576,
            "logloss": 0.6974964086004173,
            "mae": 0.4992347912729632,
            "precision": 0.508519003931848,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5469258759772956,
            "auditor_fn_violation": 0.004521175078770867,
            "auditor_fp_violation": 0.014647365532382,
            "ave_precision_score": 0.5470508492676175,
            "fpr": 0.411635565312843,
            "logloss": 0.6888474912428107,
            "mae": 0.49687185676121304,
            "precision": 0.4952893674293405,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8368034128282986,
            "mae": 0.5151981141856308,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.8039684890838369,
            "mae": 0.5017554226406041,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5942778873247629,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5342195836771391,
            "fpr": 0.4616228070175439,
            "logloss": 0.6925109789658423,
            "mae": 0.49962629678479414,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5706446651957332,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5021111408032172,
            "fpr": 0.49176728869374314,
            "logloss": 0.6933147458813573,
            "mae": 0.5000239966598745,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7700978844758772,
            "auditor_fn_violation": 0.005944724336299005,
            "auditor_fp_violation": 0.0019689961245155647,
            "ave_precision_score": 0.7588440894406815,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6656258530143154,
            "mae": 0.47287741058359023,
            "precision": 0.9393939393939394,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7280090427506192,
            "auditor_fn_violation": 0.005761119790987525,
            "auditor_fp_violation": 0.0012251058491453662,
            "ave_precision_score": 0.7173699560590808,
            "fpr": 0.0043907793633369925,
            "logloss": 0.652352826861941,
            "mae": 0.46700510201090384,
            "precision": 0.9411764705882353,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6022660859203458,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5398481949853287,
            "fpr": 0.4616228070175439,
            "logloss": 0.6925453082072636,
            "mae": 0.499678905269033,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5846422013826895,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5121031924016505,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929852982995942,
            "mae": 0.4998982600401576,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5236959912376883,
            "auditor_fn_violation": 0.0009937649623039304,
            "auditor_fp_violation": 0.006539879984998134,
            "ave_precision_score": 0.5256020728064269,
            "fpr": 0.31359649122807015,
            "logloss": 0.6944286037041502,
            "mae": 0.5001690424651953,
            "precision": 0.5303776683087028,
            "recall": 0.6578411405295316
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5309301821104033,
            "auditor_fn_violation": 0.006365681744362765,
            "auditor_fp_violation": 0.000862474517798364,
            "ave_precision_score": 0.5330293280878781,
            "fpr": 0.31394072447859495,
            "logloss": 0.6917413452199112,
            "mae": 0.49887499700655136,
            "precision": 0.5241264559068219,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5163906794198295,
            "auditor_fn_violation": 0.006241737235144888,
            "auditor_fp_violation": 0.00830051673125809,
            "ave_precision_score": 0.5225512154046956,
            "fpr": 0.2883771929824561,
            "logloss": 0.6931094356636172,
            "mae": 0.4997139143381725,
            "precision": 0.5328596802841918,
            "recall": 0.6109979633401222
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5200648628469753,
            "auditor_fn_violation": 0.007131460218638051,
            "auditor_fp_violation": 0.004748510271287448,
            "ave_precision_score": 0.5229135842935574,
            "fpr": 0.30954994511525796,
            "logloss": 0.6926888864750104,
            "mae": 0.4995018192101781,
            "precision": 0.5087108013937283,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4418859649122807,
            "auc_prc": 0.5505048299279955,
            "auditor_fn_violation": 0.004506556615571511,
            "auditor_fp_violation": 0.009079259907488441,
            "ave_precision_score": 0.5513385790659042,
            "fpr": 0.1074561403508772,
            "logloss": 0.7168319376233129,
            "mae": 0.5017293731502274,
            "precision": 0.449438202247191,
            "recall": 0.1629327902240326
        },
        "train": {
            "accuracy": 0.4434687156970362,
            "auc_prc": 0.5116376089866148,
            "auditor_fn_violation": 0.00404700884082952,
            "auditor_fp_violation": 0.013691782970048609,
            "ave_precision_score": 0.5123345712077656,
            "fpr": 0.11855104281009879,
            "logloss": 0.7053454894022831,
            "mae": 0.4994753292965182,
            "precision": 0.37209302325581395,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7091727180368553,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018361670208776157,
            "ave_precision_score": 0.7039334859848867,
            "fpr": 0.4583333333333333,
            "logloss": 0.6915068010884959,
            "mae": 0.4990634630646622,
            "precision": 0.5401540154015402,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.656817253978874,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015656852752077854,
            "ave_precision_score": 0.6524960529601292,
            "fpr": 0.4884742041712404,
            "logloss": 0.6927493129434954,
            "mae": 0.4996856203063521,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 14724,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7889600173029501,
            "auditor_fn_violation": 0.008955050559188195,
            "auditor_fp_violation": 0.0026461641038463143,
            "ave_precision_score": 0.7891437153641356,
            "fpr": 0.01644736842105263,
            "logloss": 0.636028346997365,
            "mae": 0.42628173716908796,
            "precision": 0.9162011173184358,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745744063965101,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750704108207549,
            "fpr": 0.018660812294182216,
            "logloss": 0.6415842249462135,
            "mae": 0.4253589209119408,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7387012583700108,
            "auditor_fn_violation": 0.003084021152678043,
            "auditor_fp_violation": 0.004945930741342668,
            "ave_precision_score": 0.7390343878530486,
            "fpr": 0.010964912280701754,
            "logloss": 0.6302892254371306,
            "mae": 0.4503450443674075,
            "precision": 0.9193548387096774,
            "recall": 0.23217922606924643
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6880147742454072,
            "auditor_fn_violation": 0.007968363628604558,
            "auditor_fp_violation": 0.003185275207777952,
            "ave_precision_score": 0.6888802723210679,
            "fpr": 0.013172338090010977,
            "logloss": 0.6398016824143073,
            "mae": 0.45555184007868676,
            "precision": 0.8909090909090909,
            "recall": 0.21166306695464362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7302793364728368,
            "mae": 0.5055302560304928,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7139298638911197,
            "mae": 0.4990845797072307,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5628365319959223,
            "auditor_fn_violation": 0.0018379068853396222,
            "auditor_fp_violation": 0.008399487435929493,
            "ave_precision_score": 0.5636931357253167,
            "fpr": 0.4375,
            "logloss": 1.7884081769278275,
            "mae": 0.4481126172357012,
            "precision": 0.5476190476190477,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5748848080587285,
            "auditor_fn_violation": 0.0013561154405122894,
            "auditor_fp_violation": 0.004959228477340441,
            "ave_precision_score": 0.575774773116039,
            "fpr": 0.4632272228320527,
            "logloss": 1.8808441585008953,
            "mae": 0.4716218203261728,
            "precision": 0.5193621867881549,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 14724,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7889492635717744,
            "auditor_fn_violation": 0.008955050559188195,
            "auditor_fp_violation": 0.0026461641038463143,
            "ave_precision_score": 0.7891354367591412,
            "fpr": 0.01644736842105263,
            "logloss": 0.6360614577518965,
            "mae": 0.4263275591559872,
            "precision": 0.9162011173184358,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745535204330607,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750545342510061,
            "fpr": 0.018660812294182216,
            "logloss": 0.6416815473503927,
            "mae": 0.4254128642333563,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7889862990351729,
            "auditor_fn_violation": 0.007291331689713099,
            "auditor_fp_violation": 0.0034952285702379462,
            "ave_precision_score": 0.7892019830103205,
            "fpr": 0.01425438596491228,
            "logloss": 0.637244771867042,
            "mae": 0.4263028575766057,
            "precision": 0.9261363636363636,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745404924626111,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750494969868944,
            "fpr": 0.018660812294182216,
            "logloss": 0.6431758374115644,
            "mae": 0.42531977305036067,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7335494131358783,
            "auditor_fn_violation": 0.0073404616429056345,
            "auditor_fp_violation": 0.004945930741342668,
            "ave_precision_score": 0.7338558261106084,
            "fpr": 0.010964912280701754,
            "logloss": 0.6291195417801875,
            "mae": 0.44996933145611956,
            "precision": 0.9186991869918699,
            "recall": 0.23014256619144602
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6775327315149922,
            "auditor_fn_violation": 0.007968363628604558,
            "auditor_fp_violation": 0.000955582562333386,
            "ave_precision_score": 0.6784072954922271,
            "fpr": 0.010976948408342482,
            "logloss": 0.6399977543458741,
            "mae": 0.4557642263455396,
            "precision": 0.9074074074074074,
            "recall": 0.21166306695464362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.703835054196502,
            "auditor_fn_violation": 0.0073404616429056345,
            "auditor_fp_violation": 0.0030472559069883737,
            "ave_precision_score": 0.7043271768206396,
            "fpr": 0.006578947368421052,
            "logloss": 0.6255484830209925,
            "mae": 0.44703373498397697,
            "precision": 0.9495798319327731,
            "recall": 0.23014256619144602
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6690938925811623,
            "auditor_fn_violation": 0.007968363628604558,
            "auditor_fp_violation": 0.0006591069468402076,
            "ave_precision_score": 0.6699220830102384,
            "fpr": 0.009879253567508232,
            "logloss": 0.6365909255202636,
            "mae": 0.4534149712562954,
            "precision": 0.9158878504672897,
            "recall": 0.21166306695464362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5628074501691664,
            "auditor_fn_violation": 0.0018379068853396222,
            "auditor_fp_violation": 0.008399487435929493,
            "ave_precision_score": 0.563666157718419,
            "fpr": 0.4375,
            "logloss": 1.6353897922272906,
            "mae": 0.4490389000854656,
            "precision": 0.5476190476190477,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5748314744489478,
            "auditor_fn_violation": 0.0013561154405122894,
            "auditor_fp_violation": 0.004959228477340441,
            "ave_precision_score": 0.5757196531384197,
            "fpr": 0.4632272228320527,
            "logloss": 1.712842862847915,
            "mae": 0.47192153057557773,
            "precision": 0.5193621867881549,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8212195306328889,
            "auditor_fn_violation": 0.0061859077428806225,
            "auditor_fp_violation": 0.013267283410426305,
            "ave_precision_score": 0.8218522076339896,
            "fpr": 0.25877192982456143,
            "logloss": 0.6425668361663168,
            "mae": 0.330481228391874,
            "precision": 0.6614060258249641,
            "recall": 0.9389002036659878
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8373311988984358,
            "auditor_fn_violation": 0.008729400440500438,
            "auditor_fp_violation": 0.010398698447545868,
            "ave_precision_score": 0.8376060656461426,
            "fpr": 0.2678375411635565,
            "logloss": 0.6361874261223243,
            "mae": 0.3345862403702326,
            "precision": 0.6390532544378699,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7471559429082826,
            "auditor_fn_violation": 0.0074387215492907445,
            "auditor_fp_violation": 0.016254635996166195,
            "ave_precision_score": 0.747746377837234,
            "fpr": 0.26864035087719296,
            "logloss": 0.8543215205865023,
            "mae": 0.34097714625395864,
            "precision": 0.6524822695035462,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7718107572851964,
            "auditor_fn_violation": 0.010042840919598003,
            "auditor_fp_violation": 0.005179747530186619,
            "ave_precision_score": 0.7722254254725885,
            "fpr": 0.29198682766191,
            "logloss": 0.8403398400015925,
            "mae": 0.35472853537021415,
            "precision": 0.6189111747851003,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7817104649332033,
            "auditor_fn_violation": 0.009957748240254404,
            "auditor_fp_violation": 0.009469933741717717,
            "ave_precision_score": 0.6697156973568132,
            "fpr": 0.03179824561403509,
            "logloss": 0.6091193762597276,
            "mae": 0.4352499485800141,
            "precision": 0.8449197860962567,
            "recall": 0.32179226069246436
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7262136044384387,
            "auditor_fn_violation": 0.0026434767765230933,
            "auditor_fp_violation": 0.007683863885839737,
            "ave_precision_score": 0.6237580478643039,
            "fpr": 0.04610318331503842,
            "logloss": 0.6296092822716117,
            "mae": 0.4461928178136095,
            "precision": 0.7613636363636364,
            "recall": 0.2894168466522678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7091727180368553,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018361670208776157,
            "ave_precision_score": 0.7039334859848867,
            "fpr": 0.4583333333333333,
            "logloss": 0.6915294345862341,
            "mae": 0.49907813930328476,
            "precision": 0.5401540154015402,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.656817253978874,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015656852752077854,
            "ave_precision_score": 0.6524960529601292,
            "fpr": 0.4884742041712404,
            "logloss": 0.6927542526640996,
            "mae": 0.49969143738600086,
            "precision": 0.5099118942731278,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 14724,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7889684276844346,
            "auditor_fn_violation": 0.008955050559188195,
            "auditor_fp_violation": 0.0026461641038463143,
            "ave_precision_score": 0.7891738833024108,
            "fpr": 0.01644736842105263,
            "logloss": 0.6361915686610811,
            "mae": 0.42650867731550024,
            "precision": 0.9162011173184358,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745131176063481,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750196746493688,
            "fpr": 0.018660812294182216,
            "logloss": 0.642038577501771,
            "mae": 0.42562653490079083,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5715258730400092,
            "auditor_fn_violation": 0.01290777861149819,
            "auditor_fp_violation": 0.012282785348168521,
            "ave_precision_score": 0.5626433033201534,
            "fpr": 0.18640350877192982,
            "logloss": 0.6998942062967035,
            "mae": 0.4891791959342204,
            "precision": 0.5707070707070707,
            "recall": 0.46028513238289204
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5650942775993228,
            "auditor_fn_violation": 0.011655006128598632,
            "auditor_fp_violation": 0.011785518268778428,
            "ave_precision_score": 0.5522217059127899,
            "fpr": 0.1877058177826564,
            "logloss": 0.698314977974475,
            "mae": 0.48771941130234564,
            "precision": 0.5725,
            "recall": 0.4946004319654428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7453356679510783,
            "auditor_fn_violation": 0.044799817772537255,
            "auditor_fp_violation": 0.02655019377422178,
            "ave_precision_score": 0.7459637121955628,
            "fpr": 0.10855263157894737,
            "logloss": 0.6529515885137979,
            "mae": 0.40984481215765983,
            "precision": 0.7394736842105263,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7319420281539493,
            "auditor_fn_violation": 0.04795480247419943,
            "auditor_fp_violation": 0.023747451779833773,
            "ave_precision_score": 0.7327110534908636,
            "fpr": 0.11964873765093303,
            "logloss": 0.6285835758847079,
            "mae": 0.40001881542591566,
            "precision": 0.7161458333333334,
            "recall": 0.593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6134852413258776,
            "auditor_fn_violation": 0.0002880801800836106,
            "auditor_fp_violation": 0.000283889652873296,
            "ave_precision_score": 0.5366261505934975,
            "fpr": 0.45394736842105265,
            "logloss": 0.6927778124744544,
            "mae": 0.49972478516007723,
            "precision": 0.5389755011135857,
            "recall": 0.9857433808553971
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6053736711067542,
            "auditor_fn_violation": 0.0019251149260419214,
            "auditor_fp_violation": 0.0018058060216402875,
            "ave_precision_score": 0.5106964885451086,
            "fpr": 0.4862788144895719,
            "logloss": 0.6930615803289215,
            "mae": 0.4998725702746901,
            "precision": 0.5083240843507214,
            "recall": 0.9892008639308856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7889790876761125,
            "auditor_fn_violation": 0.007291331689713099,
            "auditor_fp_violation": 0.0034952285702379462,
            "ave_precision_score": 0.7891985069693158,
            "fpr": 0.01425438596491228,
            "logloss": 0.6372729489046927,
            "mae": 0.42634093560720204,
            "precision": 0.9261363636363636,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745367827351637,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750450099564357,
            "fpr": 0.018660812294182216,
            "logloss": 0.6432572879678405,
            "mae": 0.42536468123402454,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8394351022933022,
            "auditor_fn_violation": 0.011389216421910176,
            "auditor_fp_violation": 0.0068966954202608665,
            "ave_precision_score": 0.8397472649899842,
            "fpr": 0.12280701754385964,
            "logloss": 0.5111794379119425,
            "mae": 0.32663442662356956,
            "precision": 0.7751004016064257,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8247405085018014,
            "auditor_fn_violation": 0.010438769728279042,
            "auditor_fp_violation": 0.01526971930374785,
            "ave_precision_score": 0.8250614564314763,
            "fpr": 0.1251372118551043,
            "logloss": 0.5038929878942678,
            "mae": 0.3249690054823071,
            "precision": 0.758985200845666,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7335494131358783,
            "auditor_fn_violation": 0.0073404616429056345,
            "auditor_fp_violation": 0.004945930741342668,
            "ave_precision_score": 0.7338558261106084,
            "fpr": 0.010964912280701754,
            "logloss": 0.6291195406032513,
            "mae": 0.44996933122737365,
            "precision": 0.9186991869918699,
            "recall": 0.23014256619144602
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6775327315149922,
            "auditor_fn_violation": 0.007968363628604558,
            "auditor_fp_violation": 0.000955582562333386,
            "ave_precision_score": 0.6784072954922271,
            "fpr": 0.010976948408342482,
            "logloss": 0.6399977533263522,
            "mae": 0.4557642261492565,
            "precision": 0.9074074074074074,
            "recall": 0.21166306695464362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7889975768954651,
            "auditor_fn_violation": 0.008955050559188195,
            "auditor_fp_violation": 0.0020679668291869817,
            "ave_precision_score": 0.789214181219273,
            "fpr": 0.015350877192982455,
            "logloss": 0.6371876696959161,
            "mae": 0.4262275255061244,
            "precision": 0.9213483146067416,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745591389531925,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750659456406404,
            "fpr": 0.018660812294182216,
            "logloss": 0.6430168983589788,
            "mae": 0.42523090699654376,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6914545135994823,
            "mae": 0.4989757811029752,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930639007772993,
            "mae": 0.4997802836049663,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.811856690609351,
            "auditor_fn_violation": 0.011127934398113411,
            "auditor_fp_violation": 0.0017632412384881444,
            "ave_precision_score": 0.6724741628660581,
            "fpr": 0.007675438596491228,
            "logloss": 0.6060262960650735,
            "mae": 0.43027891052004535,
            "precision": 0.954248366013072,
            "recall": 0.2973523421588595
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7793700325228847,
            "auditor_fn_violation": 0.003302567847261566,
            "auditor_fp_violation": 0.00371452093460875,
            "ave_precision_score": 0.6330538132917503,
            "fpr": 0.012074643249176729,
            "logloss": 0.6193510088898408,
            "mae": 0.4374257308460617,
            "precision": 0.9185185185185185,
            "recall": 0.2678185745140389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7443545963101568,
            "auditor_fn_violation": 0.04808929145674777,
            "auditor_fp_violation": 0.029459411593115804,
            "ave_precision_score": 0.7450492420258243,
            "fpr": 0.10964912280701754,
            "logloss": 0.6553851375822871,
            "mae": 0.40639000066317077,
            "precision": 0.7375328083989501,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7455392764351148,
            "auditor_fn_violation": 0.052793668932391014,
            "auditor_fp_violation": 0.021405049396267837,
            "ave_precision_score": 0.7462833332784359,
            "fpr": 0.10537870472008781,
            "logloss": 0.6196678164142183,
            "mae": 0.3904404267491098,
            "precision": 0.7405405405405405,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8120370839924348,
            "auditor_fn_violation": 0.014198556472648016,
            "auditor_fp_violation": 0.029123432095678626,
            "ave_precision_score": 0.8080667577352503,
            "fpr": 0.2543859649122807,
            "logloss": 4.477824504264761,
            "mae": 0.3339271504380138,
            "precision": 0.6484848484848484,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7832974665716046,
            "auditor_fn_violation": 0.004153696244366312,
            "auditor_fp_violation": 0.03347969264544457,
            "ave_precision_score": 0.7800719125386761,
            "fpr": 0.27332601536772777,
            "logloss": 4.39375063721345,
            "mae": 0.343538690025703,
            "precision": 0.6232980332829047,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8240446055171686,
            "auditor_fn_violation": 0.017890002501161253,
            "auditor_fp_violation": 0.029811018043922166,
            "ave_precision_score": 0.8209692880633362,
            "fpr": 0.2324561403508772,
            "logloss": 3.566844105613408,
            "mae": 0.3216877964784348,
            "precision": 0.6618819776714514,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7938866892831752,
            "auditor_fn_violation": 0.0024253603070700583,
            "auditor_fp_violation": 0.03126960169358633,
            "ave_precision_score": 0.7915122339615357,
            "fpr": 0.24259055982436883,
            "logloss": 3.4080926930383377,
            "mae": 0.3153342951324257,
            "precision": 0.6446945337620579,
            "recall": 0.8660907127429806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7805689747857809,
            "auditor_fn_violation": 0.01597170114696109,
            "auditor_fp_violation": 0.01436377463849649,
            "ave_precision_score": 0.6647938996172227,
            "fpr": 0.10197368421052631,
            "logloss": 0.7250393009051643,
            "mae": 0.41332760896048376,
            "precision": 0.753968253968254,
            "recall": 0.5804480651731161
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7506819874873525,
            "auditor_fn_violation": 0.012408930446925395,
            "auditor_fp_violation": 0.013814293554963155,
            "ave_precision_score": 0.6241543595361478,
            "fpr": 0.1251372118551043,
            "logloss": 0.7114015052950537,
            "mae": 0.4126885859690752,
            "precision": 0.7038961038961039,
            "recall": 0.5853131749460043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6022660859203458,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5398481949853287,
            "fpr": 0.4616228070175439,
            "logloss": 0.6925453082072636,
            "mae": 0.499678905269033,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5846422013826895,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5121031924016505,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929852982995942,
            "mae": 0.4998982600401576,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5820538220265181,
            "auditor_fn_violation": 0.013738521456390476,
            "auditor_fp_violation": 0.011701983581280996,
            "ave_precision_score": 0.5319132109178126,
            "fpr": 0.1875,
            "logloss": 0.698531118122641,
            "mae": 0.48833048873041807,
            "precision": 0.5703517587939698,
            "recall": 0.4623217922606925
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5849128718045671,
            "auditor_fn_violation": 0.011835189299016348,
            "auditor_fp_violation": 0.012074643249176741,
            "ave_precision_score": 0.5306808875850019,
            "fpr": 0.18880351262349068,
            "logloss": 0.6945282243913669,
            "mae": 0.48614881839500956,
            "precision": 0.5742574257425742,
            "recall": 0.5010799136069114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7889892941009103,
            "auditor_fn_violation": 0.007291331689713099,
            "auditor_fp_violation": 0.0034952285702379462,
            "ave_precision_score": 0.7892068992150004,
            "fpr": 0.01425438596491228,
            "logloss": 0.6372780432811865,
            "mae": 0.4263482476031449,
            "precision": 0.9261363636363636,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745350137243906,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750446289032389,
            "fpr": 0.018660812294182216,
            "logloss": 0.6432660514870194,
            "mae": 0.4253732824761857,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8122027055732837,
            "auditor_fn_violation": 0.011127934398113411,
            "auditor_fp_violation": 0.0017632412384881444,
            "ave_precision_score": 0.6667298761378315,
            "fpr": 0.007675438596491228,
            "logloss": 0.6078577650330269,
            "mae": 0.43293898964398786,
            "precision": 0.954248366013072,
            "recall": 0.2973523421588595
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7791880419546544,
            "auditor_fn_violation": 0.003302567847261566,
            "auditor_fp_violation": 0.00371452093460875,
            "ave_precision_score": 0.6268050264750153,
            "fpr": 0.012074643249176729,
            "logloss": 0.6220358910838109,
            "mae": 0.44044867710800256,
            "precision": 0.9185185185185185,
            "recall": 0.2678185745140389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7500717993377894,
            "auditor_fn_violation": 0.047725283167184766,
            "auditor_fp_violation": 0.028790057090469647,
            "ave_precision_score": 0.7507240860647368,
            "fpr": 0.15460526315789475,
            "logloss": 0.6254158166277941,
            "mae": 0.4016161750399062,
            "precision": 0.6974248927038627,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7238997737474231,
            "auditor_fn_violation": 0.04478737200475116,
            "auditor_fp_violation": 0.0353222518425592,
            "ave_precision_score": 0.7246749584876759,
            "fpr": 0.1668496158068057,
            "logloss": 0.627174029544428,
            "mae": 0.40497158531143135,
            "precision": 0.6695652173913044,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8122027055732837,
            "auditor_fn_violation": 0.011127934398113411,
            "auditor_fp_violation": 0.0017632412384881444,
            "ave_precision_score": 0.6667298761378315,
            "fpr": 0.007675438596491228,
            "logloss": 0.6078577650330269,
            "mae": 0.43293898964398786,
            "precision": 0.954248366013072,
            "recall": 0.2973523421588595
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7791880419546544,
            "auditor_fn_violation": 0.003302567847261566,
            "auditor_fp_violation": 0.00371452093460875,
            "ave_precision_score": 0.6268050264750153,
            "fpr": 0.012074643249176729,
            "logloss": 0.6220358910838109,
            "mae": 0.44044867710800256,
            "precision": 0.9185185185185185,
            "recall": 0.2678185745140389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8379875403135624,
            "auditor_fn_violation": 0.012633097509558008,
            "auditor_fp_violation": 0.028633787556777944,
            "ave_precision_score": 0.8337337597806749,
            "fpr": 0.25877192982456143,
            "logloss": 4.344770698803202,
            "mae": 0.3345400248401443,
            "precision": 0.6467065868263473,
            "recall": 0.879837067209776
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.814491746413618,
            "auditor_fn_violation": 0.0007444409935679356,
            "auditor_fp_violation": 0.031357809314724795,
            "ave_precision_score": 0.8100983196946341,
            "fpr": 0.278814489571899,
            "logloss": 4.231137262119216,
            "mae": 0.34424825641176454,
            "precision": 0.6191904047976012,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7361155047188381,
            "auditor_fn_violation": 0.011127934398113411,
            "auditor_fp_violation": 0.0017632412384881444,
            "ave_precision_score": 0.71437625734285,
            "fpr": 0.007675438596491228,
            "logloss": 0.643622035639955,
            "mae": 0.4374117171065065,
            "precision": 0.954248366013072,
            "recall": 0.2973523421588595
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7006559631047524,
            "auditor_fn_violation": 0.003302567847261566,
            "auditor_fp_violation": 0.00371452093460875,
            "ave_precision_score": 0.6750754733419113,
            "fpr": 0.012074643249176729,
            "logloss": 0.650894410759418,
            "mae": 0.44069220622925803,
            "precision": 0.9185185185185185,
            "recall": 0.2678185745140389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7703744493392071,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0014246572488227816,
            "ave_precision_score": 0.5407488986784141,
            "fpr": 0.45723684210526316,
            "logloss": 0.6879385199724205,
            "mae": 0.49644431892349467,
            "precision": 0.5407488986784141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7552828873018779,
            "auditor_fn_violation": 0.0004955037186487212,
            "auditor_fp_violation": 0.0014407244785949647,
            "ave_precision_score": 0.5116205739407388,
            "fpr": 0.4840834248079034,
            "logloss": 0.6925961473756589,
            "mae": 0.4963494026644971,
            "precision": 0.5116279069767442,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8531645581618398,
            "auditor_fn_violation": 0.008367724300568122,
            "auditor_fp_violation": 0.007821290161270157,
            "ave_precision_score": 0.8534261636290219,
            "fpr": 0.12280701754385964,
            "logloss": 0.5078734380859177,
            "mae": 0.2990257467237442,
            "precision": 0.78125,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8430403679402768,
            "auditor_fn_violation": 0.008708062959793072,
            "auditor_fp_violation": 0.01880292457268308,
            "ave_precision_score": 0.8433178540670128,
            "fpr": 0.1251372118551043,
            "logloss": 0.49198068149745555,
            "mae": 0.29653496508339355,
            "precision": 0.7649484536082474,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.8122027055732837,
            "auditor_fn_violation": 0.011127934398113411,
            "auditor_fp_violation": 0.0017632412384881444,
            "ave_precision_score": 0.6667298761378315,
            "fpr": 0.007675438596491228,
            "logloss": 0.6078577650330269,
            "mae": 0.43293898964398786,
            "precision": 0.954248366013072,
            "recall": 0.2973523421588595
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7791880419546544,
            "auditor_fn_violation": 0.003302567847261566,
            "auditor_fp_violation": 0.00371452093460875,
            "ave_precision_score": 0.6268050264750153,
            "fpr": 0.012074643249176729,
            "logloss": 0.6220358910838109,
            "mae": 0.44044867710800256,
            "precision": 0.9185185185185185,
            "recall": 0.2678185745140389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 14724,
        "test": {
            "accuracy": 0.42653508771929827,
            "auc_prc": 0.5525430119805748,
            "auditor_fn_violation": 0.0014002036659877847,
            "auditor_fp_violation": 0.006209109472017335,
            "ave_precision_score": 0.5522745589905196,
            "fpr": 0.09978070175438597,
            "logloss": 0.7151813013511689,
            "mae": 0.5033704449724928,
            "precision": 0.3933333333333333,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.43468715697036225,
            "auc_prc": 0.5059452700617296,
            "auditor_fn_violation": 0.006778206371371742,
            "auditor_fp_violation": 0.014897287125607658,
            "ave_precision_score": 0.5056281678048209,
            "fpr": 0.10867178924259056,
            "logloss": 0.7130517101573995,
            "mae": 0.5023819103787942,
            "precision": 0.3219178082191781,
            "recall": 0.10151187904967603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.811977869119495,
            "auditor_fn_violation": 0.01701012970307643,
            "auditor_fp_violation": 0.026177751385589875,
            "ave_precision_score": 0.8082161498844509,
            "fpr": 0.2412280701754386,
            "logloss": 4.412085914057344,
            "mae": 0.33110986581391844,
            "precision": 0.6557120500782473,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7834869777761195,
            "auditor_fn_violation": 0.007434926610920524,
            "auditor_fp_violation": 0.03367815979300611,
            "ave_precision_score": 0.7803617263561212,
            "fpr": 0.2601536772777168,
            "logloss": 4.319581872985873,
            "mae": 0.3384042236455343,
            "precision": 0.6261829652996845,
            "recall": 0.857451403887689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7771879818609548,
            "auditor_fn_violation": 0.016576892843105737,
            "auditor_fp_violation": 0.014207505104804764,
            "ave_precision_score": 0.6612162153225442,
            "fpr": 0.10307017543859649,
            "logloss": 0.6908913479338884,
            "mae": 0.4393014617800649,
            "precision": 0.75,
            "recall": 0.5743380855397149
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7452243003394111,
            "auditor_fn_violation": 0.016401410170391647,
            "auditor_fp_violation": 0.012123647483142545,
            "ave_precision_score": 0.6182076822778757,
            "fpr": 0.12952799121844127,
            "logloss": 0.6795117367630522,
            "mae": 0.43796094937754015,
            "precision": 0.6950904392764858,
            "recall": 0.5809935205183585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8492018944255924,
            "auditor_fn_violation": 0.013468306713831429,
            "auditor_fp_violation": 0.008110388798599828,
            "ave_precision_score": 0.8494866087388235,
            "fpr": 0.11951754385964912,
            "logloss": 0.49837778550500844,
            "mae": 0.31745449946666077,
            "precision": 0.7806841046277666,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8299347432670927,
            "auditor_fn_violation": 0.013620425184865568,
            "auditor_fp_violation": 0.014818880351262349,
            "ave_precision_score": 0.8302494228957072,
            "fpr": 0.12294182217343579,
            "logloss": 0.49595229876816505,
            "mae": 0.3170273844829968,
            "precision": 0.7627118644067796,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7889873798690901,
            "auditor_fn_violation": 0.007291331689713099,
            "auditor_fp_violation": 0.0034952285702379462,
            "ave_precision_score": 0.7892045081683736,
            "fpr": 0.01425438596491228,
            "logloss": 0.6372853030917046,
            "mae": 0.4263578628883886,
            "precision": 0.9261363636363636,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7745323991677007,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.0004091853536145528,
            "ave_precision_score": 0.7750428179997318,
            "fpr": 0.018660812294182216,
            "logloss": 0.6432779371190823,
            "mae": 0.425384634485891,
            "precision": 0.8888888888888888,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6914545135994823,
            "mae": 0.4989757811029752,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930639007772993,
            "mae": 0.4997802836049663,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7890389906635011,
            "auditor_fn_violation": 0.007291331689713099,
            "auditor_fp_violation": 0.0023935283577113816,
            "ave_precision_score": 0.7892522955949741,
            "fpr": 0.013157894736842105,
            "logloss": 0.6421880663528475,
            "mae": 0.42652642600826274,
            "precision": 0.9314285714285714,
            "recall": 0.3319755600814664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7746767150735929,
            "auditor_fn_violation": 0.0020341731607684366,
            "auditor_fp_violation": 0.0035283048455386555,
            "ave_precision_score": 0.7751858730201978,
            "fpr": 0.01756311745334797,
            "logloss": 0.6476591984530156,
            "mae": 0.4251777780482251,
            "precision": 0.8940397350993378,
            "recall": 0.2915766738660907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7703744493392071,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0014246572488227816,
            "ave_precision_score": 0.5407488986784141,
            "fpr": 0.45723684210526316,
            "logloss": 0.6879385199785818,
            "mae": 0.49644431892962176,
            "precision": 0.5407488986784141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7552828873018779,
            "auditor_fn_violation": 0.0004955037186487212,
            "auditor_fp_violation": 0.0014407244785949647,
            "ave_precision_score": 0.5116205739407388,
            "fpr": 0.4840834248079034,
            "logloss": 0.69259614711002,
            "mae": 0.49634940267369787,
            "precision": 0.5116279069767442,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8549204254498849,
            "auditor_fn_violation": 0.014998034801872298,
            "auditor_fp_violation": 0.017166208276034507,
            "ave_precision_score": 0.8551181172573945,
            "fpr": 0.10964912280701754,
            "logloss": 0.5234391673348446,
            "mae": 0.3408484014593054,
            "precision": 0.7894736842105263,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8159122991829248,
            "auditor_fn_violation": 0.019284340897075106,
            "auditor_fp_violation": 0.014167124039517016,
            "ave_precision_score": 0.8163575304639711,
            "fpr": 0.13830954994511527,
            "logloss": 0.5268973238754684,
            "mae": 0.3418317247056754,
            "precision": 0.7330508474576272,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8280260546250748,
            "auditor_fn_violation": 0.017309375781612894,
            "auditor_fp_violation": 0.01836948368546069,
            "ave_precision_score": 0.8283377858142198,
            "fpr": 0.1513157894736842,
            "logloss": 0.8838155427875601,
            "mae": 0.28369447093889716,
            "precision": 0.7434944237918215,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8027964546726707,
            "auditor_fn_violation": 0.008283684176835556,
            "auditor_fp_violation": 0.013417359259840058,
            "ave_precision_score": 0.804154326244691,
            "fpr": 0.19099890230515917,
            "logloss": 0.8543914853447981,
            "mae": 0.3015288297637398,
            "precision": 0.6853526220614828,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7708694803511918,
            "auditor_fn_violation": 0.005944724336299005,
            "auditor_fp_violation": 0.0019689961245155647,
            "ave_precision_score": 0.7595187561374708,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6615806337163119,
            "mae": 0.4734731717852124,
            "precision": 0.9393939393939394,
            "recall": 0.12627291242362526
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7255540555548534,
            "auditor_fn_violation": 0.005761119790987525,
            "auditor_fp_violation": 0.0012251058491453662,
            "ave_precision_score": 0.7147481769710292,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6565747625046582,
            "mae": 0.47072014919227617,
            "precision": 0.9411764705882353,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 14724,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.519468479707266,
            "auditor_fn_violation": 0.002702147425590461,
            "auditor_fp_violation": 0.01097533024961455,
            "ave_precision_score": 0.5207549993121249,
            "fpr": 0.3969298245614035,
            "logloss": 0.6976430075270865,
            "mae": 0.4992629551589632,
            "precision": 0.5027472527472527,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5469258759772956,
            "auditor_fn_violation": 0.007721797184875047,
            "auditor_fp_violation": 0.0168452054257488,
            "ave_precision_score": 0.5470508492676175,
            "fpr": 0.39846322722283206,
            "logloss": 0.6887271604492952,
            "mae": 0.49678019857295797,
            "precision": 0.49372384937238495,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7511985942773766,
            "auditor_fn_violation": 0.046644424196948586,
            "auditor_fp_violation": 0.03198576905446514,
            "ave_precision_score": 0.7517967130600931,
            "fpr": 0.12280701754385964,
            "logloss": 0.6457239067376248,
            "mae": 0.4064006078683872,
            "precision": 0.7307692307692307,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7226347708545192,
            "auditor_fn_violation": 0.049955783998311964,
            "auditor_fp_violation": 0.026952328681198054,
            "ave_precision_score": 0.7234574563253782,
            "fpr": 0.13172338090010977,
            "logloss": 0.6246211229826664,
            "mae": 0.39814853607193884,
            "precision": 0.7163120567375887,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.757126435725347,
            "auditor_fn_violation": 0.05102815592953872,
            "auditor_fp_violation": 0.03456161186815019,
            "ave_precision_score": 0.7577369256596284,
            "fpr": 0.12828947368421054,
            "logloss": 0.6215150185268166,
            "mae": 0.4057817325148407,
            "precision": 0.7253521126760564,
            "recall": 0.6293279022403259
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.734854761398559,
            "auditor_fn_violation": 0.049794567477411913,
            "auditor_fp_violation": 0.031213246824525642,
            "ave_precision_score": 0.7355973859316116,
            "fpr": 0.1437980241492865,
            "logloss": 0.6177355226929966,
            "mae": 0.40537548855697975,
            "precision": 0.6895734597156398,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7524334341262762,
            "auditor_fn_violation": 0.0074387215492907445,
            "auditor_fp_violation": 0.01768189773721715,
            "ave_precision_score": 0.753006831047892,
            "fpr": 0.2708333333333333,
            "logloss": 0.8425998103186568,
            "mae": 0.34143760534457296,
            "precision": 0.6506364922206507,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7761532903836847,
            "auditor_fn_violation": 0.010002536789372988,
            "auditor_fp_violation": 0.007683863885839744,
            "ave_precision_score": 0.7765567903295868,
            "fpr": 0.29198682766191,
            "logloss": 0.830938513673952,
            "mae": 0.35522918917731566,
            "precision": 0.6183644189383071,
            "recall": 0.9308855291576674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7847387487050137,
            "auditor_fn_violation": 0.013162361096223246,
            "auditor_fp_violation": 0.0305480893445014,
            "ave_precision_score": 0.6376471985255727,
            "fpr": 0.2708333333333333,
            "logloss": 10.226386880346398,
            "mae": 0.3402675842639598,
            "precision": 0.6367647058823529,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7741048335083396,
            "auditor_fn_violation": 0.004675279106101808,
            "auditor_fp_violation": 0.03138721185510428,
            "ave_precision_score": 0.6136999512306744,
            "fpr": 0.29198682766191,
            "logloss": 10.50678216666076,
            "mae": 0.3509437210043089,
            "precision": 0.6093979441997063,
            "recall": 0.896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7614747702220473,
            "auditor_fn_violation": 0.0516914102976382,
            "auditor_fp_violation": 0.027787327582614506,
            "ave_precision_score": 0.7621164789834223,
            "fpr": 0.10964912280701754,
            "logloss": 0.6323990694900882,
            "mae": 0.40235284594675985,
            "precision": 0.7468354430379747,
            "recall": 0.6008146639511202
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7457405712437594,
            "auditor_fn_violation": 0.05217725282306725,
            "auditor_fp_violation": 0.024458013172338096,
            "ave_precision_score": 0.7464902552847338,
            "fpr": 0.11525795828759605,
            "logloss": 0.6098446402806291,
            "mae": 0.39280464125947434,
            "precision": 0.7348484848484849,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7849552266546919,
            "auditor_fn_violation": 0.012679994283059994,
            "auditor_fp_violation": 0.03230091261407677,
            "ave_precision_score": 0.6382939445611613,
            "fpr": 0.27850877192982454,
            "logloss": 10.223583841858014,
            "mae": 0.34352235373093243,
            "precision": 0.6318840579710145,
            "recall": 0.8879837067209776
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7739676320600917,
            "auditor_fn_violation": 0.007214439310277791,
            "auditor_fp_violation": 0.033354731848831747,
            "ave_precision_score": 0.6135627860266524,
            "fpr": 0.3062568605927552,
            "logloss": 10.531794772842861,
            "mae": 0.35691987593905156,
            "precision": 0.6002865329512894,
            "recall": 0.9049676025917927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8719848140189199,
            "auditor_fn_violation": 0.015971701146961094,
            "auditor_fp_violation": 0.012558861524357211,
            "ave_precision_score": 0.8721717968580616,
            "fpr": 0.10087719298245613,
            "logloss": 0.49491800397853575,
            "mae": 0.314211965547401,
            "precision": 0.8004338394793926,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.844746552740637,
            "auditor_fn_violation": 0.009715666215418462,
            "auditor_fp_violation": 0.012312313783910928,
            "ave_precision_score": 0.845064907461854,
            "fpr": 0.11086717892425905,
            "logloss": 0.4982286118118406,
            "mae": 0.3149366231963741,
            "precision": 0.7809110629067245,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 14724,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.519468479707266,
            "auditor_fn_violation": 0.005484689320041452,
            "auditor_fp_violation": 0.00968871108888612,
            "ave_precision_score": 0.5207549993121249,
            "fpr": 0.4144736842105263,
            "logloss": 0.6974834544405534,
            "mae": 0.4992268181514718,
            "precision": 0.5071707953063885,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5469258759772956,
            "auditor_fn_violation": 0.0016287610273285741,
            "auditor_fp_violation": 0.015340775442998292,
            "ave_precision_score": 0.5470508492676175,
            "fpr": 0.4138309549945115,
            "logloss": 0.6888489091974478,
            "mae": 0.49687108399835134,
            "precision": 0.4959893048128342,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8271602496899909,
            "auditor_fn_violation": 0.01827634258762997,
            "auditor_fp_violation": 0.027750864691419762,
            "ave_precision_score": 0.8240385082692322,
            "fpr": 0.22916666666666666,
            "logloss": 3.595061136029671,
            "mae": 0.3204874740880854,
            "precision": 0.6639871382636656,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.797029279548233,
            "auditor_fn_violation": 0.0052300536044931996,
            "auditor_fp_violation": 0.03125,
            "ave_precision_score": 0.7947177230287453,
            "fpr": 0.23819978046103182,
            "logloss": 3.448446943022282,
            "mae": 0.3131987781324922,
            "precision": 0.6471544715447154,
            "recall": 0.8596112311015118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 14724,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.519468479707266,
            "auditor_fn_violation": 0.005609747382713403,
            "auditor_fp_violation": 0.010204400550068764,
            "ave_precision_score": 0.5207549993121249,
            "fpr": 0.41118421052631576,
            "logloss": 0.697496409059945,
            "mae": 0.4992347908445752,
            "precision": 0.508519003931848,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5469258759772956,
            "auditor_fn_violation": 0.004521175078770867,
            "auditor_fp_violation": 0.014647365532382,
            "ave_precision_score": 0.5470508492676175,
            "fpr": 0.411635565312843,
            "logloss": 0.6888474905088046,
            "mae": 0.49687185635203424,
            "precision": 0.4952893674293405,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7852594918843004,
            "auditor_fn_violation": 0.017150820023582387,
            "auditor_fp_violation": 0.02430251698128933,
            "ave_precision_score": 0.6385981062013127,
            "fpr": 0.24671052631578946,
            "logloss": 10.18529843711774,
            "mae": 0.3313140068789117,
            "precision": 0.651702786377709,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7743071618840509,
            "auditor_fn_violation": 0.001512590299032939,
            "auditor_fp_violation": 0.030647247922220497,
            "ave_precision_score": 0.6139022245180513,
            "fpr": 0.265642151481888,
            "logloss": 10.483487525768375,
            "mae": 0.33988271295691846,
            "precision": 0.6253869969040248,
            "recall": 0.8725701943844493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7817104649332033,
            "auditor_fn_violation": 0.009957748240254404,
            "auditor_fp_violation": 0.009469933741717717,
            "ave_precision_score": 0.6697156973568132,
            "fpr": 0.03179824561403509,
            "logloss": 0.6090098926463556,
            "mae": 0.43512177960783766,
            "precision": 0.8449197860962567,
            "recall": 0.32179226069246436
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7262136044384387,
            "auditor_fn_violation": 0.0026434767765230933,
            "auditor_fp_violation": 0.007683863885839737,
            "ave_precision_score": 0.6237580478643039,
            "fpr": 0.04610318331503842,
            "logloss": 0.6288152776801877,
            "mae": 0.4457386264620445,
            "precision": 0.7613636363636364,
            "recall": 0.2894168466522678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7851207351870724,
            "auditor_fn_violation": 0.0167466144995891,
            "auditor_fp_violation": 0.024924990623827987,
            "ave_precision_score": 0.6384593953365734,
            "fpr": 0.24780701754385964,
            "logloss": 10.189452603625629,
            "mae": 0.33513242622818024,
            "precision": 0.6512345679012346,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7742955751849196,
            "auditor_fn_violation": 0.005343853501599128,
            "auditor_fp_violation": 0.033516445820918936,
            "ave_precision_score": 0.6138906398852695,
            "fpr": 0.2667398463227223,
            "logloss": 10.483948539084547,
            "mae": 0.34175712526438534,
            "precision": 0.624420401854714,
            "recall": 0.8725701943844493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.837946704815129,
            "auditor_fn_violation": 0.01671758316361168,
            "auditor_fp_violation": 0.025448493561695224,
            "ave_precision_score": 0.8335581779993212,
            "fpr": 0.24342105263157895,
            "logloss": 4.407730286643155,
            "mae": 0.33003010737771993,
            "precision": 0.6536661466458659,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.8136772981252249,
            "auditor_fn_violation": 0.007010547827963007,
            "auditor_fp_violation": 0.0318601027128744,
            "ave_precision_score": 0.8098265406964155,
            "fpr": 0.2579582875960483,
            "logloss": 4.298610847615237,
            "mae": 0.33754990547779146,
            "precision": 0.631083202511774,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8396363210875831,
            "auditor_fn_violation": 0.012633097509558008,
            "auditor_fp_violation": 0.02861034712672418,
            "ave_precision_score": 0.8358411494120721,
            "fpr": 0.2532894736842105,
            "logloss": 4.0276647364303075,
            "mae": 0.3330716773082059,
            "precision": 0.6515837104072398,
            "recall": 0.879837067209776
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8146874591917831,
            "auditor_fn_violation": 0.0007444409935679356,
            "auditor_fp_violation": 0.031899306100047056,
            "ave_precision_score": 0.8113604230869036,
            "fpr": 0.27552140504939626,
            "logloss": 3.89227851788739,
            "mae": 0.3429235460643004,
            "precision": 0.6219879518072289,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8361507781827288,
            "auditor_fn_violation": 0.012065869868153068,
            "auditor_fp_violation": 0.02822748676917949,
            "ave_precision_score": 0.8325528789669576,
            "fpr": 0.2631578947368421,
            "logloss": 3.9364825416988625,
            "mae": 0.335463705101702,
            "precision": 0.6433878157503715,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8117133715128965,
            "auditor_fn_violation": 0.006275590159153898,
            "auditor_fp_violation": 0.03081141210600597,
            "ave_precision_score": 0.8084344313805807,
            "fpr": 0.27991218441273324,
            "logloss": 3.7918439755089506,
            "mae": 0.3447191490450607,
            "precision": 0.6188340807174888,
            "recall": 0.8941684665226782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8406132650411845,
            "auditor_fn_violation": 0.010746060671025837,
            "auditor_fp_violation": 0.00789682043588783,
            "ave_precision_score": 0.8409232904993785,
            "fpr": 0.1206140350877193,
            "logloss": 0.5109981359175461,
            "mae": 0.325437080359008,
            "precision": 0.778672032193159,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8315224854332827,
            "auditor_fn_violation": 0.010438769728279042,
            "auditor_fp_violation": 0.01207464324917673,
            "ave_precision_score": 0.8318274247573867,
            "fpr": 0.12294182217343579,
            "logloss": 0.4965805606291928,
            "mae": 0.3216161253367797,
            "precision": 0.7622080679405521,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 14724,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.775846540659394,
            "auditor_fn_violation": 0.008955050559188195,
            "auditor_fp_violation": 0.0030706963370421302,
            "ave_precision_score": 0.7761633870248688,
            "fpr": 0.01644736842105263,
            "logloss": 0.6389242270578578,
            "mae": 0.4257345548464895,
            "precision": 0.9162011173184358,
            "recall": 0.3340122199592668
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7624156473647907,
            "auditor_fn_violation": 0.0011901572572328369,
            "auditor_fp_violation": 0.000392033871726517,
            "ave_precision_score": 0.7630004809282622,
            "fpr": 0.01756311745334797,
            "logloss": 0.6403356517374511,
            "mae": 0.42346501293792527,
            "precision": 0.8947368421052632,
            "recall": 0.2937365010799136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7847387487050137,
            "auditor_fn_violation": 0.013162361096223246,
            "auditor_fp_violation": 0.0305480893445014,
            "ave_precision_score": 0.6376471985255727,
            "fpr": 0.2708333333333333,
            "logloss": 10.226387355461664,
            "mae": 0.34026797928693175,
            "precision": 0.6367647058823529,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7741048335083396,
            "auditor_fn_violation": 0.004675279106101808,
            "auditor_fp_violation": 0.03138721185510428,
            "ave_precision_score": 0.6136999512306744,
            "fpr": 0.29198682766191,
            "logloss": 10.506782835883625,
            "mae": 0.3509441142987141,
            "precision": 0.6093979441997063,
            "recall": 0.896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7897412874667051,
            "auditor_fn_violation": 0.0033497695358559497,
            "auditor_fp_violation": 0.0022971621452681583,
            "ave_precision_score": 0.7899266615948108,
            "fpr": 0.01206140350877193,
            "logloss": 0.6513908474677027,
            "mae": 0.426069362757341,
            "precision": 0.9345238095238095,
            "recall": 0.319755600814664
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7770414948321104,
            "auditor_fn_violation": 0.0030180681044967624,
            "auditor_fp_violation": 0.0035283048455386555,
            "ave_precision_score": 0.7775362718420096,
            "fpr": 0.01756311745334797,
            "logloss": 0.6575685904668263,
            "mae": 0.42515200902133465,
            "precision": 0.8933333333333333,
            "recall": 0.2894168466522678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8295547489749188,
            "auditor_fn_violation": 0.017503662414692537,
            "auditor_fp_violation": 0.026341834395966168,
            "ave_precision_score": 0.8278107339489965,
            "fpr": 0.20065789473684212,
            "logloss": 2.965679028103432,
            "mae": 0.3041599516361303,
            "precision": 0.6887755102040817,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7981960016435066,
            "auditor_fn_violation": 0.004495095935684092,
            "auditor_fp_violation": 0.026001646542261253,
            "ave_precision_score": 0.7970304869223388,
            "fpr": 0.22283205268935236,
            "logloss": 2.7017709412789146,
            "mae": 0.3070433387887178,
            "precision": 0.6559322033898305,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8311665656581058,
            "auditor_fn_violation": 0.011190463429449389,
            "auditor_fp_violation": 0.011035233570863029,
            "ave_precision_score": 0.8314177003625085,
            "fpr": 0.13925438596491227,
            "logloss": 0.9668312740577129,
            "mae": 0.2937523849570767,
            "precision": 0.7470119521912351,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8108590176983916,
            "auditor_fn_violation": 0.014706265869751278,
            "auditor_fp_violation": 0.007132566253724322,
            "ave_precision_score": 0.8116923074861448,
            "fpr": 0.16794731064763996,
            "logloss": 0.8269895303667054,
            "mae": 0.30168056236072055,
            "precision": 0.6994106090373281,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8568507431331357,
            "auditor_fn_violation": 0.009352556544109769,
            "auditor_fp_violation": 0.006769075301079306,
            "ave_precision_score": 0.8571065292092532,
            "fpr": 0.12609649122807018,
            "logloss": 0.5103637423413292,
            "mae": 0.29633113795417654,
            "precision": 0.7762645914396887,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8450831707045612,
            "auditor_fn_violation": 0.010012020114131815,
            "auditor_fp_violation": 0.018530951074172814,
            "ave_precision_score": 0.8455133920150875,
            "fpr": 0.12843029637760703,
            "logloss": 0.4982234384099706,
            "mae": 0.2924777117585767,
            "precision": 0.7631578947368421,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7568473870164885,
            "auditor_fn_violation": 0.006436023868224531,
            "auditor_fp_violation": 0.013684002166937534,
            "ave_precision_score": 0.757402144397452,
            "fpr": 0.2817982456140351,
            "logloss": 0.855455291950109,
            "mae": 0.34343448297846135,
            "precision": 0.6405594405594406,
            "recall": 0.9327902240325866
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7854801492106649,
            "auditor_fn_violation": 0.008063196876192825,
            "auditor_fp_violation": 0.01418182530970678,
            "ave_precision_score": 0.7858608073804818,
            "fpr": 0.3062568605927552,
            "logloss": 0.8349596473289763,
            "mae": 0.355599435124959,
            "precision": 0.6097902097902098,
            "recall": 0.9416846652267818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8501685990042473,
            "auditor_fn_violation": 0.011299889234287345,
            "auditor_fp_violation": 0.007284764762261953,
            "ave_precision_score": 0.8504480600273212,
            "fpr": 0.1162280701754386,
            "logloss": 0.5126264938203652,
            "mae": 0.2993881561056345,
            "precision": 0.7888446215139442,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8421897125951374,
            "auditor_fn_violation": 0.010626065392265875,
            "auditor_fp_violation": 0.018873980711933514,
            "ave_precision_score": 0.8424661443305806,
            "fpr": 0.12403951701427003,
            "logloss": 0.49452329612776497,
            "mae": 0.296449454478461,
            "precision": 0.7640918580375783,
            "recall": 0.7904967602591793
        }
    }
]