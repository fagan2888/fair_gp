[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8315742492117595,
            "auditor_fn_violation": 0.00817384370015949,
            "auditor_fp_violation": 0.023382419249057224,
            "ave_precision_score": 0.8319317099066442,
            "fpr": 0.14583333333333334,
            "logloss": 0.8036029828569748,
            "mae": 0.2702064392161857,
            "precision": 0.7432432432432432,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8240883291832338,
            "auditor_fn_violation": 0.01287806245182988,
            "auditor_fp_violation": 0.012261326045236973,
            "ave_precision_score": 0.8243532819769005,
            "fpr": 0.14489571899012074,
            "logloss": 0.793122353197082,
            "mae": 0.2798603921097508,
            "precision": 0.7327935222672065,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8412886003397148,
            "auditor_fn_violation": 0.019424206176598523,
            "auditor_fp_violation": 0.023395228726020664,
            "ave_precision_score": 0.8416620612236828,
            "fpr": 0.12280701754385964,
            "logloss": 0.7427198361104618,
            "mae": 0.2649434864793055,
            "precision": 0.7700205338809035,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8350337168394862,
            "auditor_fn_violation": 0.019254034612420305,
            "auditor_fp_violation": 0.013276880455804715,
            "ave_precision_score": 0.8352733306747634,
            "fpr": 0.132821075740944,
            "logloss": 0.7436853302083973,
            "mae": 0.2733275599869127,
            "precision": 0.7473903966597077,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8297672285007293,
            "auditor_fn_violation": 0.010425728577642453,
            "auditor_fp_violation": 0.021094646663387444,
            "ave_precision_score": 0.8302260189246163,
            "fpr": 0.13267543859649122,
            "logloss": 0.7472544853447041,
            "mae": 0.2823207248975759,
            "precision": 0.7515400410677618,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8175120424053597,
            "auditor_fn_violation": 0.014559637527150433,
            "auditor_fp_violation": 0.011447389054414303,
            "ave_precision_score": 0.8177659031041964,
            "fpr": 0.13830954994511527,
            "logloss": 0.7574851632188212,
            "mae": 0.2944741207038243,
            "precision": 0.7301927194860813,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8352414217790152,
            "auditor_fn_violation": 0.006877990430622013,
            "auditor_fp_violation": 0.0172415559927857,
            "ave_precision_score": 0.8355951761924485,
            "fpr": 0.1074561403508772,
            "logloss": 0.7626282106549784,
            "mae": 0.27348811293331277,
            "precision": 0.7822222222222223,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8280332145131687,
            "auditor_fn_violation": 0.012784641614312076,
            "auditor_fp_violation": 0.012948318734738685,
            "ave_precision_score": 0.8282892339644762,
            "fpr": 0.1119648737650933,
            "logloss": 0.752308957416632,
            "mae": 0.2823971810013533,
            "precision": 0.7627906976744186,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8114199096692538,
            "auditor_fn_violation": 0.013864723792953459,
            "auditor_fp_violation": 0.02893917035579603,
            "ave_precision_score": 0.8122587284977445,
            "fpr": 0.17543859649122806,
            "logloss": 0.9410390500915551,
            "mae": 0.27572123156763007,
            "precision": 0.7192982456140351,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8285403377927234,
            "auditor_fn_violation": 0.015243945161968376,
            "auditor_fp_violation": 0.028764085216962745,
            "ave_precision_score": 0.8288380420879613,
            "fpr": 0.19099890230515917,
            "logloss": 0.9086347755353475,
            "mae": 0.285403765552018,
            "precision": 0.6952714535901926,
            "recall": 0.8446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8316600009666979,
            "auditor_fn_violation": 0.015106205596636215,
            "auditor_fp_violation": 0.024542957861944586,
            "ave_precision_score": 0.832208640971829,
            "fpr": 0.12280701754385964,
            "logloss": 0.8112168257246075,
            "mae": 0.2664784500130221,
            "precision": 0.7681159420289855,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8213398433968856,
            "auditor_fn_violation": 0.01825209613004181,
            "auditor_fp_violation": 0.019780909070543702,
            "ave_precision_score": 0.821614908623934,
            "fpr": 0.141602634467618,
            "logloss": 0.8218440458714655,
            "mae": 0.28041445149297867,
            "precision": 0.7334710743801653,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 2917,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7795237988639783,
            "auditor_fn_violation": 0.06614288821226622,
            "auditor_fp_violation": 0.028872561075586164,
            "ave_precision_score": 0.7798873498832111,
            "fpr": 0.1118421052631579,
            "logloss": 1.4972524546730475,
            "mae": 0.3395267818721146,
            "precision": 0.7315789473684211,
            "recall": 0.5743801652892562
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7576104032188957,
            "auditor_fn_violation": 0.0670247798771516,
            "auditor_fp_violation": 0.02829613367483839,
            "ave_precision_score": 0.7579903249264657,
            "fpr": 0.10757409440175632,
            "logloss": 1.5354838660162589,
            "mae": 0.33923841153503914,
            "precision": 0.7307692307692307,
            "recall": 0.5659574468085107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8465415053871324,
            "auditor_fn_violation": 0.01284072785268959,
            "auditor_fp_violation": 0.019583128381701922,
            "ave_precision_score": 0.8468545629443109,
            "fpr": 0.1118421052631579,
            "logloss": 0.7239408613153037,
            "mae": 0.2846907554076174,
            "precision": 0.7702702702702703,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8327505906312144,
            "auditor_fn_violation": 0.016250554686222763,
            "auditor_fp_violation": 0.014700647913757527,
            "ave_precision_score": 0.8329774388309648,
            "fpr": 0.1141602634467618,
            "logloss": 0.7875124417432321,
            "mae": 0.2951526118852289,
            "precision": 0.7592592592592593,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8536345106525993,
            "auditor_fn_violation": 0.031123133246338985,
            "auditor_fp_violation": 0.019393548122643055,
            "ave_precision_score": 0.854042425022731,
            "fpr": 0.11293859649122807,
            "logloss": 0.501049766516378,
            "mae": 0.3095695105773956,
            "precision": 0.7863070539419087,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8523906168153375,
            "auditor_fn_violation": 0.02393675409300045,
            "auditor_fp_violation": 0.020878603911377948,
            "ave_precision_score": 0.8526391482279049,
            "fpr": 0.12184412733260154,
            "logloss": 0.4928415695247585,
            "mae": 0.30818091227946975,
            "precision": 0.7771084337349398,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8427376415331589,
            "auditor_fn_violation": 0.014086740611860231,
            "auditor_fp_violation": 0.018712083948188227,
            "ave_precision_score": 0.843145441888648,
            "fpr": 0.11403508771929824,
            "logloss": 0.7026237589106742,
            "mae": 0.27269159877504145,
            "precision": 0.7744034707158352,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8345673269272967,
            "auditor_fn_violation": 0.01422332251208632,
            "auditor_fp_violation": 0.015325413004572484,
            "ave_precision_score": 0.8347930809585384,
            "fpr": 0.11964873765093303,
            "logloss": 0.7084793344437214,
            "mae": 0.28579501250422595,
            "precision": 0.7517084282460137,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8102603752874161,
            "auditor_fn_violation": 0.011875634333768313,
            "auditor_fp_violation": 0.024430234464666342,
            "ave_precision_score": 0.810856864412548,
            "fpr": 0.14144736842105263,
            "logloss": 0.9059887674538816,
            "mae": 0.2797567132707845,
            "precision": 0.7414829659318637,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8050314437077484,
            "auditor_fn_violation": 0.01575308872644043,
            "auditor_fp_violation": 0.012893558447894353,
            "ave_precision_score": 0.8053477331600013,
            "fpr": 0.145993413830955,
            "logloss": 0.8944887732107403,
            "mae": 0.29116905712885494,
            "precision": 0.7217573221757322,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8529635865040989,
            "auditor_fn_violation": 0.041195447295925766,
            "auditor_fp_violation": 0.020146745368093136,
            "ave_precision_score": 0.853314463391833,
            "fpr": 0.09868421052631579,
            "logloss": 0.5227380431731032,
            "mae": 0.3207079330714773,
            "precision": 0.801762114537445,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8376753151042802,
            "auditor_fn_violation": 0.03025667375108018,
            "auditor_fp_violation": 0.03134030780259415,
            "ave_precision_score": 0.8380265759225003,
            "fpr": 0.1251372118551043,
            "logloss": 0.5360381066169809,
            "mae": 0.32662328461247364,
            "precision": 0.7569296375266524,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.842380644172892,
            "auditor_fn_violation": 0.015998803827751196,
            "auditor_fp_violation": 0.024542957861944586,
            "ave_precision_score": 0.8427540857082186,
            "fpr": 0.12280701754385964,
            "logloss": 0.733967049385041,
            "mae": 0.26420161671175546,
            "precision": 0.7695473251028807,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8359599388953987,
            "auditor_fn_violation": 0.01909521918864003,
            "auditor_fp_violation": 0.013685093503189787,
            "ave_precision_score": 0.8361975277753619,
            "fpr": 0.132821075740944,
            "logloss": 0.7346140830434768,
            "mae": 0.27321205307512525,
            "precision": 0.7494824016563147,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.83899928779898,
            "auditor_fn_violation": 0.014619127881687698,
            "auditor_fp_violation": 0.022836735530414824,
            "ave_precision_score": 0.839420954544666,
            "fpr": 0.12938596491228072,
            "logloss": 0.7638984238285196,
            "mae": 0.2633475214514586,
            "precision": 0.7635270541082164,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8317585853726523,
            "auditor_fn_violation": 0.01602167363430413,
            "auditor_fp_violation": 0.015554410567739726,
            "ave_precision_score": 0.8320064989870927,
            "fpr": 0.13172338090010977,
            "logloss": 0.7655508242156888,
            "mae": 0.27056867976635957,
            "precision": 0.7540983606557377,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8466349753708188,
            "auditor_fn_violation": 0.029313016528925616,
            "auditor_fp_violation": 0.02844728644040007,
            "ave_precision_score": 0.8469675817245472,
            "fpr": 0.11842105263157894,
            "logloss": 0.6776581467776454,
            "mae": 0.26280396931151206,
            "precision": 0.780040733197556,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8462335934497394,
            "auditor_fn_violation": 0.02745404862554593,
            "auditor_fp_violation": 0.02901050650776227,
            "ave_precision_score": 0.8465112352474613,
            "fpr": 0.14818880351262348,
            "logloss": 0.677521157718504,
            "mae": 0.2732252808050954,
            "precision": 0.734251968503937,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8743718631691467,
            "auditor_fn_violation": 0.012041014209076413,
            "auditor_fp_violation": 0.010583189867191348,
            "ave_precision_score": 0.8745441335380137,
            "fpr": 0.07785087719298246,
            "logloss": 0.7958490376202496,
            "mae": 0.234466417432067,
            "precision": 0.8341121495327103,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8556466425297583,
            "auditor_fn_violation": 0.011906485741644681,
            "auditor_fp_violation": 0.011357781312305382,
            "ave_precision_score": 0.855829650775056,
            "fpr": 0.0889132821075741,
            "logloss": 0.9232634975599355,
            "mae": 0.26046661858291253,
            "precision": 0.8014705882352942,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8524523753689552,
            "auditor_fn_violation": 0.010969443236189654,
            "auditor_fp_violation": 0.021732558616166586,
            "ave_precision_score": 0.8527517756934817,
            "fpr": 0.12390350877192982,
            "logloss": 0.6105120403137999,
            "mae": 0.2657383955133883,
            "precision": 0.7717171717171717,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8508345482907544,
            "auditor_fn_violation": 0.014830557955952079,
            "auditor_fp_violation": 0.016622236161204333,
            "ave_precision_score": 0.8510453749191492,
            "fpr": 0.13172338090010977,
            "logloss": 0.6055834025016811,
            "mae": 0.2745511134608058,
            "precision": 0.75,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8375922534955522,
            "auditor_fn_violation": 0.013921360736552129,
            "auditor_fp_violation": 0.021837596327266763,
            "ave_precision_score": 0.8380887954443896,
            "fpr": 0.13706140350877194,
            "logloss": 0.6609781128269258,
            "mae": 0.274220392013057,
            "precision": 0.751984126984127,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8304052958904268,
            "auditor_fn_violation": 0.011023658827101386,
            "auditor_fp_violation": 0.019253219033680078,
            "ave_precision_score": 0.8306569500961627,
            "fpr": 0.150384193194292,
            "logloss": 0.6702205435868862,
            "mae": 0.28776556326723124,
            "precision": 0.7237903225806451,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8396849757876643,
            "auditor_fn_violation": 0.009157061041032335,
            "auditor_fp_violation": 0.02574704869650763,
            "ave_precision_score": 0.8403835915112492,
            "fpr": 0.16885964912280702,
            "logloss": 0.6492040275169004,
            "mae": 0.28976460661036535,
            "precision": 0.7148148148148148,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8324573466586909,
            "auditor_fn_violation": 0.010026391386598783,
            "auditor_fp_violation": 0.01918103501920344,
            "ave_precision_score": 0.8326787083410492,
            "fpr": 0.17233809001097694,
            "logloss": 0.662287824969802,
            "mae": 0.3007755625344359,
            "precision": 0.7026515151515151,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8286268274050629,
            "auditor_fn_violation": 0.012292482238654494,
            "auditor_fp_violation": 0.01750286932283981,
            "ave_precision_score": 0.8290459952476271,
            "fpr": 0.11403508771929824,
            "logloss": 0.8922139288747638,
            "mae": 0.2794579262347971,
            "precision": 0.7709251101321586,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8113170352392406,
            "auditor_fn_violation": 0.01746502557395428,
            "auditor_fp_violation": 0.015166110351934407,
            "ave_precision_score": 0.8115978843373626,
            "fpr": 0.11855104281009879,
            "logloss": 0.9447537435788741,
            "mae": 0.29257206322690604,
            "precision": 0.75,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8195807826729389,
            "auditor_fn_violation": 0.012709330143540674,
            "auditor_fp_violation": 0.02467105263157895,
            "ave_precision_score": 0.820063874929158,
            "fpr": 0.13925438596491227,
            "logloss": 0.8146832563896061,
            "mae": 0.27782034471703015,
            "precision": 0.7465069860279441,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8175549360203823,
            "auditor_fn_violation": 0.014667071490295917,
            "auditor_fp_violation": 0.01721464290070218,
            "ave_precision_score": 0.8178351869395928,
            "fpr": 0.14709110867178923,
            "logloss": 0.796375007097655,
            "mae": 0.28599054343144253,
            "precision": 0.7237113402061855,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8302538554875263,
            "auditor_fn_violation": 0.010434790488618242,
            "auditor_fp_violation": 0.02427652074110511,
            "ave_precision_score": 0.8306244246013521,
            "fpr": 0.1425438596491228,
            "logloss": 0.7946844806109753,
            "mae": 0.2722395328383184,
            "precision": 0.746588693957115,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8247000527271402,
            "auditor_fn_violation": 0.013233061634397554,
            "auditor_fp_violation": 0.014322304113742093,
            "ave_precision_score": 0.8249591058054234,
            "fpr": 0.14489571899012074,
            "logloss": 0.7800098588399487,
            "mae": 0.28079052105747365,
            "precision": 0.7306122448979592,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8474137584571984,
            "auditor_fn_violation": 0.009161591996520228,
            "auditor_fp_violation": 0.02707411050991966,
            "ave_precision_score": 0.8477280148039115,
            "fpr": 0.14035087719298245,
            "logloss": 0.6349819084678683,
            "mae": 0.26682305194811673,
            "precision": 0.751937984496124,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8470587106331322,
            "auditor_fn_violation": 0.01335917976504659,
            "auditor_fp_violation": 0.015897906912490573,
            "ave_precision_score": 0.8472800507379799,
            "fpr": 0.14270032930845225,
            "logloss": 0.6235226231670343,
            "mae": 0.2723036853137406,
            "precision": 0.7410358565737052,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8302831641670763,
            "auditor_fn_violation": 0.019437799043062205,
            "auditor_fp_violation": 0.020864076078045583,
            "ave_precision_score": 0.8308302624736071,
            "fpr": 0.11074561403508772,
            "logloss": 0.8641407062782099,
            "mae": 0.2678196466484084,
            "precision": 0.7770419426048565,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8214528480728425,
            "auditor_fn_violation": 0.01883597636452812,
            "auditor_fp_violation": 0.017667659819141708,
            "ave_precision_score": 0.8217283833037543,
            "fpr": 0.11525795828759605,
            "logloss": 0.8605879434910005,
            "mae": 0.27894647627052743,
            "precision": 0.7613636363636364,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8428829635872336,
            "auditor_fn_violation": 0.0109331955922865,
            "auditor_fp_violation": 0.02609034267912773,
            "ave_precision_score": 0.8435792713469117,
            "fpr": 0.16557017543859648,
            "logloss": 0.6401519057416812,
            "mae": 0.28809023840560194,
            "precision": 0.7188081936685289,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8347053423890805,
            "auditor_fn_violation": 0.012948128079968237,
            "auditor_fp_violation": 0.020871136599535534,
            "ave_precision_score": 0.8349244753691694,
            "fpr": 0.1734357848518112,
            "logloss": 0.6565352801914359,
            "mae": 0.30015754240614073,
            "precision": 0.7018867924528301,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8483052685765214,
            "auditor_fn_violation": 0.036829871683340586,
            "auditor_fp_violation": 0.02471716674864733,
            "ave_precision_score": 0.8487037124239705,
            "fpr": 0.125,
            "logloss": 0.5188676378943671,
            "mae": 0.31408639281385387,
            "precision": 0.7668711656441718,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8476710010022399,
            "auditor_fn_violation": 0.02456267370436976,
            "auditor_fp_violation": 0.017894168278361475,
            "ave_precision_score": 0.8478975489393052,
            "fpr": 0.13611416026344675,
            "logloss": 0.5080386118295763,
            "mae": 0.30930189553833654,
            "precision": 0.7534791252485089,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8289790079536759,
            "auditor_fn_violation": 0.017924459910105845,
            "auditor_fp_violation": 0.02253186997868503,
            "ave_precision_score": 0.8294588557045872,
            "fpr": 0.18311403508771928,
            "logloss": 0.5528132688037265,
            "mae": 0.33179207766538876,
            "precision": 0.7130584192439863,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8076837563144378,
            "auditor_fn_violation": 0.01142536842842796,
            "auditor_fp_violation": 0.015897906912490573,
            "ave_precision_score": 0.808030126352739,
            "fpr": 0.21075740944017562,
            "logloss": 0.5972910945885687,
            "mae": 0.3483631213064767,
            "precision": 0.679465776293823,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8323893992432754,
            "auditor_fn_violation": 0.010683993040452375,
            "auditor_fp_violation": 0.02341828578455485,
            "ave_precision_score": 0.8327492596734429,
            "fpr": 0.14364035087719298,
            "logloss": 0.8007339533440561,
            "mae": 0.26999364002477616,
            "precision": 0.7456310679611651,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8248394480607012,
            "auditor_fn_violation": 0.008849288833874399,
            "auditor_fp_violation": 0.013782168557141117,
            "ave_precision_score": 0.8250992209157729,
            "fpr": 0.145993413830955,
            "logloss": 0.7895155121807823,
            "mae": 0.2798232005166001,
            "precision": 0.7318548387096774,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8323613900970266,
            "auditor_fn_violation": 0.0045173626214296105,
            "auditor_fp_violation": 0.024138178389899987,
            "ave_precision_score": 0.8327301560325782,
            "fpr": 0.14583333333333334,
            "logloss": 0.7876481269674025,
            "mae": 0.2717483009036221,
            "precision": 0.7417475728155339,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8264001827628553,
            "auditor_fn_violation": 0.011490763014690434,
            "auditor_fp_violation": 0.012358401099188307,
            "ave_precision_score": 0.8266555223192409,
            "fpr": 0.14489571899012074,
            "logloss": 0.773397360350954,
            "mae": 0.280045624073429,
            "precision": 0.7333333333333333,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.852013131678553,
            "auditor_fn_violation": 0.009927323473974197,
            "auditor_fp_violation": 0.02250368912936547,
            "ave_precision_score": 0.8523137984317617,
            "fpr": 0.12280701754385964,
            "logloss": 0.618422737941724,
            "mae": 0.2641090864257189,
            "precision": 0.7728194726166329,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.848010433657318,
            "auditor_fn_violation": 0.012807996823691528,
            "auditor_fp_violation": 0.015870526769068402,
            "ave_precision_score": 0.8482280996439492,
            "fpr": 0.13391877058177826,
            "logloss": 0.6182024159484774,
            "mae": 0.2752221710475658,
            "precision": 0.7447698744769874,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8335252529390935,
            "auditor_fn_violation": 0.014902312599681024,
            "auditor_fp_violation": 0.02737129037547139,
            "ave_precision_score": 0.8339928643953373,
            "fpr": 0.12609649122807018,
            "logloss": 0.8067598681113102,
            "mae": 0.2657894363971302,
            "precision": 0.7648261758691206,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8226626742343813,
            "auditor_fn_violation": 0.013966415208912349,
            "auditor_fp_violation": 0.01787674455072918,
            "ave_precision_score": 0.8229320699086111,
            "fpr": 0.13830954994511527,
            "logloss": 0.8153105519613114,
            "mae": 0.2790377698255268,
            "precision": 0.7396694214876033,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8389425124198305,
            "auditor_fn_violation": 0.009761943598666093,
            "auditor_fp_violation": 0.02667189293326775,
            "ave_precision_score": 0.8396538198743065,
            "fpr": 0.16557017543859648,
            "logloss": 0.646272971988699,
            "mae": 0.28428999019780077,
            "precision": 0.7203703703703703,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8302773411342755,
            "auditor_fn_violation": 0.011112408622743309,
            "auditor_fp_violation": 0.020141829142926837,
            "ave_precision_score": 0.8305251219855603,
            "fpr": 0.17014270032930845,
            "logloss": 0.6540812558582005,
            "mae": 0.2963454600079632,
            "precision": 0.7036328871892925,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8392044928429614,
            "auditor_fn_violation": 0.007956357836740613,
            "auditor_fp_violation": 0.02470691916707657,
            "ave_precision_score": 0.8395489007210857,
            "fpr": 0.13925438596491227,
            "logloss": 0.7853538995588533,
            "mae": 0.27269605803364266,
            "precision": 0.7475149105367793,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8351134969613206,
            "auditor_fn_violation": 0.011670598126912209,
            "auditor_fp_violation": 0.012440541529454816,
            "ave_precision_score": 0.8353444873359639,
            "fpr": 0.145993413830955,
            "logloss": 0.771337080132713,
            "mae": 0.2794784143254574,
            "precision": 0.7307692307692307,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8414924812150526,
            "auditor_fn_violation": 0.01456249093808903,
            "auditor_fp_violation": 0.02689990162321692,
            "ave_precision_score": 0.8418452720223819,
            "fpr": 0.13925438596491227,
            "logloss": 0.7511452315016452,
            "mae": 0.26361213255806626,
            "precision": 0.7533980582524272,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8339270887088764,
            "auditor_fn_violation": 0.017936800803419205,
            "auditor_fp_violation": 0.01879024569945066,
            "ave_precision_score": 0.8341607230285103,
            "fpr": 0.14928649835345773,
            "logloss": 0.7562287866085311,
            "mae": 0.2731185276120581,
            "precision": 0.7333333333333333,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8423304603268005,
            "auditor_fn_violation": 0.02670998260113093,
            "auditor_fp_violation": 0.018235571405148397,
            "ave_precision_score": 0.8425328700721282,
            "fpr": 0.1206140350877193,
            "logloss": 0.7127889605756724,
            "mae": 0.3284292836146816,
            "precision": 0.7649572649572649,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.835361163179609,
            "auditor_fn_violation": 0.019296073989303324,
            "auditor_fp_violation": 0.018994352223143194,
            "ave_precision_score": 0.8355694792917511,
            "fpr": 0.12403951701427003,
            "logloss": 0.7285094804830854,
            "mae": 0.32602243615383286,
            "precision": 0.7569892473118279,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8258551389994684,
            "auditor_fn_violation": 0.007951826881252722,
            "auditor_fp_violation": 0.02436874897524185,
            "ave_precision_score": 0.8263344793241503,
            "fpr": 0.14473684210526316,
            "logloss": 0.8410987609806937,
            "mae": 0.27299176983600015,
            "precision": 0.7416829745596869,
            "recall": 0.7830578512396694
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8179771230243797,
            "auditor_fn_violation": 0.010649975477030154,
            "auditor_fp_violation": 0.013540725474236534,
            "ave_precision_score": 0.8182525000282098,
            "fpr": 0.150384193194292,
            "logloss": 0.8337647941043327,
            "mae": 0.2842338832698323,
            "precision": 0.7243460764587525,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8310137561189519,
            "auditor_fn_violation": 0.01344787588806728,
            "auditor_fp_violation": 0.019024635186096085,
            "ave_precision_score": 0.8313916883931058,
            "fpr": 0.12609649122807018,
            "logloss": 0.8066727378474869,
            "mae": 0.271547720481446,
            "precision": 0.7619047619047619,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.822560253635662,
            "auditor_fn_violation": 0.012144708877315087,
            "auditor_fp_violation": 0.01516859945588188,
            "ave_precision_score": 0.8228306432731877,
            "fpr": 0.13391877058177826,
            "logloss": 0.8016336331020684,
            "mae": 0.28201606235438886,
            "precision": 0.7387580299785867,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8387543291156172,
            "auditor_fn_violation": 0.015051834130781502,
            "auditor_fp_violation": 0.02045417281521561,
            "ave_precision_score": 0.8390950427617482,
            "fpr": 0.12280701754385964,
            "logloss": 0.7475928037301656,
            "mae": 0.26620712228025006,
            "precision": 0.7695473251028807,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8335053134534285,
            "auditor_fn_violation": 0.014157927925823858,
            "auditor_fp_violation": 0.014680735082177768,
            "ave_precision_score": 0.8337479309154415,
            "fpr": 0.12952799121844127,
            "logloss": 0.7384318748627238,
            "mae": 0.27374360438146317,
            "precision": 0.75,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8187901545117312,
            "auditor_fn_violation": 0.010683993040452377,
            "auditor_fp_violation": 0.02438668224299065,
            "ave_precision_score": 0.8193103274255749,
            "fpr": 0.15460526315789475,
            "logloss": 0.8512108482946867,
            "mae": 0.2762229366528903,
            "precision": 0.7324478178368121,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.815289507797061,
            "auditor_fn_violation": 0.016717658873811804,
            "auditor_fp_violation": 0.02119223100875916,
            "ave_precision_score": 0.8155698648654031,
            "fpr": 0.15806805708013172,
            "logloss": 0.833772310851599,
            "mae": 0.28684029850416576,
            "precision": 0.710261569416499,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.84399726496071,
            "auditor_fn_violation": 0.014390314629549079,
            "auditor_fp_violation": 0.022314108870306607,
            "ave_precision_score": 0.8452564046481825,
            "fpr": 0.12171052631578948,
            "logloss": 0.6794381409161888,
            "mae": 0.2660990131944146,
            "precision": 0.7701863354037267,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8378704915196977,
            "auditor_fn_violation": 0.016428054277506605,
            "auditor_fp_violation": 0.017981286916522923,
            "ave_precision_score": 0.8381034033924053,
            "fpr": 0.14489571899012074,
            "logloss": 0.6979787828289006,
            "mae": 0.28054781464601064,
            "precision": 0.7306122448979592,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8435732125466722,
            "auditor_fn_violation": 0.02769319994200377,
            "auditor_fp_violation": 0.0347674823741597,
            "ave_precision_score": 0.8439481393983824,
            "fpr": 0.13925438596491227,
            "logloss": 0.6867553226946056,
            "mae": 0.26946595983025207,
            "precision": 0.7533980582524272,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8277632411768481,
            "auditor_fn_violation": 0.02444356213653456,
            "auditor_fp_violation": 0.030167939843335795,
            "ave_precision_score": 0.8284908788318387,
            "fpr": 0.16465422612513722,
            "logloss": 0.7249306158992466,
            "mae": 0.28829503395999156,
            "precision": 0.7159090909090909,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8323307461018052,
            "auditor_fn_violation": 0.006273107872988257,
            "auditor_fp_violation": 0.01641662567634038,
            "ave_precision_score": 0.8326907709623911,
            "fpr": 0.10964912280701754,
            "logloss": 0.7770362834363161,
            "mae": 0.2743363398995438,
            "precision": 0.7782705099778271,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8255312834032651,
            "auditor_fn_violation": 0.012681878693042482,
            "auditor_fp_violation": 0.01285871099262977,
            "ave_precision_score": 0.8257963266368785,
            "fpr": 0.11525795828759605,
            "logloss": 0.7652566854230994,
            "mae": 0.28312968123329807,
            "precision": 0.7586206896551724,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.826414929040713,
            "auditor_fn_violation": 0.00681682253153545,
            "auditor_fp_violation": 0.02695626332185605,
            "ave_precision_score": 0.8268953036881862,
            "fpr": 0.1425438596491228,
            "logloss": 0.8603334296206518,
            "mae": 0.2723297779064872,
            "precision": 0.7435897435897436,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8173223818229894,
            "auditor_fn_violation": 0.01084148819394166,
            "auditor_fp_violation": 0.01456872540454162,
            "ave_precision_score": 0.8176019034692273,
            "fpr": 0.15148188803512624,
            "logloss": 0.8524395824977323,
            "mae": 0.28341497633667617,
            "precision": 0.7212121212121212,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8348532738948284,
            "auditor_fn_violation": 0.006778309409888357,
            "auditor_fp_violation": 0.021076713395638633,
            "ave_precision_score": 0.8352209213337758,
            "fpr": 0.13048245614035087,
            "logloss": 0.7491260115877,
            "mae": 0.26910391658736943,
            "precision": 0.7586206896551724,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.829851300004786,
            "auditor_fn_violation": 0.014227993553962216,
            "auditor_fp_violation": 0.01639821680593203,
            "ave_precision_score": 0.8301004068705282,
            "fpr": 0.141602634467618,
            "logloss": 0.7350570797971319,
            "mae": 0.28014044310178626,
            "precision": 0.7351129363449692,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 2917,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8396034287836129,
            "auditor_fn_violation": 0.008201029433086853,
            "auditor_fp_violation": 0.022821364158058702,
            "ave_precision_score": 0.8399545410325324,
            "fpr": 0.12719298245614036,
            "logloss": 0.7001919232037147,
            "mae": 0.2700690243063769,
            "precision": 0.7622950819672131,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8371364316541431,
            "auditor_fn_violation": 0.012845365158698647,
            "auditor_fp_violation": 0.018593606487600535,
            "ave_precision_score": 0.8373684340325389,
            "fpr": 0.1350164654226125,
            "logloss": 0.6879204056803494,
            "mae": 0.27961963818695174,
            "precision": 0.7421383647798742,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8281078822570367,
            "auditor_fn_violation": 0.007235935914165582,
            "auditor_fp_violation": 0.023979340875553375,
            "ave_precision_score": 0.8284431802506731,
            "fpr": 0.14912280701754385,
            "logloss": 0.8455633488487516,
            "mae": 0.275460291318448,
            "precision": 0.7354085603112841,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8260135162068548,
            "auditor_fn_violation": 0.014865590770021253,
            "auditor_fp_violation": 0.011663941097844192,
            "ave_precision_score": 0.8262708676366245,
            "fpr": 0.14489571899012074,
            "logloss": 0.8173007242679752,
            "mae": 0.27917654157589505,
            "precision": 0.7344064386317908,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8323673540277718,
            "auditor_fn_violation": 0.0045173626214296105,
            "auditor_fp_violation": 0.024138178389899987,
            "ave_precision_score": 0.832736111629553,
            "fpr": 0.14583333333333334,
            "logloss": 0.7876567486774299,
            "mae": 0.27174699145533415,
            "precision": 0.7417475728155339,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8263984990700097,
            "auditor_fn_violation": 0.011490763014690434,
            "auditor_fp_violation": 0.012358401099188307,
            "ave_precision_score": 0.8266538417541505,
            "fpr": 0.14489571899012074,
            "logloss": 0.773407153845293,
            "mae": 0.28004475018203356,
            "precision": 0.7333333333333333,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8453629142059464,
            "auditor_fn_violation": 0.016476819631723937,
            "auditor_fp_violation": 0.02154554025250041,
            "ave_precision_score": 0.8456410022014982,
            "fpr": 0.1162280701754386,
            "logloss": 0.7646045969514292,
            "mae": 0.2773059178036977,
            "precision": 0.7700650759219089,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8286694131155192,
            "auditor_fn_violation": 0.012354905761730166,
            "auditor_fp_violation": 0.014337238737426915,
            "ave_precision_score": 0.8288970377082971,
            "fpr": 0.11855104281009879,
            "logloss": 0.8175508598490231,
            "mae": 0.28870202547992047,
            "precision": 0.7567567567567568,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8264303173833027,
            "auditor_fn_violation": 0.006696752211106281,
            "auditor_fp_violation": 0.022595917363502218,
            "ave_precision_score": 0.8268114925964566,
            "fpr": 0.14802631578947367,
            "logloss": 0.8090040452541011,
            "mae": 0.27476598380210826,
            "precision": 0.7378640776699029,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8216503586057654,
            "auditor_fn_violation": 0.014608683466847282,
            "auditor_fp_violation": 0.01415802325320908,
            "ave_precision_score": 0.8219141933818346,
            "fpr": 0.15148188803512624,
            "logloss": 0.7905313769645341,
            "mae": 0.2826673977553526,
            "precision": 0.7223340040241448,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8376603819313314,
            "auditor_fn_violation": 0.012258500072495291,
            "auditor_fp_violation": 0.017820544351533043,
            "ave_precision_score": 0.8379696744375629,
            "fpr": 0.13157894736842105,
            "logloss": 0.822418653778028,
            "mae": 0.2757345709268693,
            "precision": 0.7535934291581109,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.822090130919764,
            "auditor_fn_violation": 0.012366583366419886,
            "auditor_fp_violation": 0.018750420036291137,
            "ave_precision_score": 0.8223377488221582,
            "fpr": 0.12843029637760703,
            "logloss": 0.8662669881643157,
            "mae": 0.2865254305717545,
            "precision": 0.7467532467532467,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8386906766430908,
            "auditor_fn_violation": 0.011812200956937798,
            "auditor_fp_violation": 0.02384612231513364,
            "ave_precision_score": 0.8390446293139949,
            "fpr": 0.1425438596491228,
            "logloss": 0.7347889827276237,
            "mae": 0.2679344665193028,
            "precision": 0.7475728155339806,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8329535211386977,
            "auditor_fn_violation": 0.012502043580820708,
            "auditor_fp_violation": 0.01500929680324381,
            "ave_precision_score": 0.8331963537593468,
            "fpr": 0.14270032930845225,
            "logloss": 0.7241272770451297,
            "mae": 0.2764927881191193,
            "precision": 0.738430583501006,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8338983644717011,
            "auditor_fn_violation": 0.008862548934319273,
            "auditor_fp_violation": 0.020318392359403182,
            "ave_precision_score": 0.8342869710022307,
            "fpr": 0.11951754385964912,
            "logloss": 0.7625922017688856,
            "mae": 0.2762492529655326,
            "precision": 0.7665952890792291,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8233215735279993,
            "auditor_fn_violation": 0.01659621178503866,
            "auditor_fp_violation": 0.011412541599149733,
            "ave_precision_score": 0.8235735141597084,
            "fpr": 0.12733260153677278,
            "logloss": 0.7677208408098267,
            "mae": 0.289283629174171,
            "precision": 0.7404921700223713,
            "recall": 0.7042553191489361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8346261573155359,
            "auditor_fn_violation": 0.01984105408148471,
            "auditor_fp_violation": 0.025731677324151506,
            "ave_precision_score": 0.8350194488765623,
            "fpr": 0.125,
            "logloss": 0.8042572133883681,
            "mae": 0.2661556600384415,
            "precision": 0.7659137577002053,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8290262593513196,
            "auditor_fn_violation": 0.01959969171123619,
            "auditor_fp_violation": 0.021550661977194834,
            "ave_precision_score": 0.8292763269540131,
            "fpr": 0.14050493962678376,
            "logloss": 0.804345270421318,
            "mae": 0.27452551365759215,
            "precision": 0.7387755102040816,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8519179592158923,
            "auditor_fn_violation": 0.010697585906916059,
            "auditor_fp_violation": 0.021176627315953437,
            "ave_precision_score": 0.8522325861220568,
            "fpr": 0.1206140350877193,
            "logloss": 0.6131593562242137,
            "mae": 0.26567113249916235,
            "precision": 0.7759674134419552,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8501007770460299,
            "auditor_fn_violation": 0.013289114136908245,
            "auditor_fp_violation": 0.016953286986217838,
            "ave_precision_score": 0.8503119655560989,
            "fpr": 0.13062568605927552,
            "logloss": 0.6096915636859717,
            "mae": 0.2753562711372068,
            "precision": 0.75,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8325991463634934,
            "auditor_fn_violation": 0.01649267797593157,
            "auditor_fp_violation": 0.01939867191342843,
            "ave_precision_score": 0.8329542992160326,
            "fpr": 0.11403508771929824,
            "logloss": 0.8728373322500089,
            "mae": 0.27531697726547155,
            "precision": 0.7709251101321586,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8140377387154564,
            "auditor_fn_violation": 0.018441273326015372,
            "auditor_fp_violation": 0.018864918817874755,
            "ave_precision_score": 0.8143152988903862,
            "fpr": 0.11964873765093303,
            "logloss": 0.9311185180717481,
            "mae": 0.28994584193471035,
            "precision": 0.75,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8419204499203548,
            "auditor_fn_violation": 0.011481441206321592,
            "auditor_fp_violation": 0.022557488932611905,
            "ave_precision_score": 0.842259050404266,
            "fpr": 0.12390350877192982,
            "logloss": 0.7900930404927565,
            "mae": 0.2597615630741718,
            "precision": 0.7689161554192229,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8411475600161886,
            "auditor_fn_violation": 0.013148982880631526,
            "auditor_fp_violation": 0.01713748067833061,
            "ave_precision_score": 0.8413774314225568,
            "fpr": 0.1350164654226125,
            "logloss": 0.7562434031876722,
            "mae": 0.265393550146514,
            "precision": 0.7453416149068323,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8435530302406912,
            "auditor_fn_violation": 0.013712936784109035,
            "auditor_fp_violation": 0.012015289391703564,
            "ave_precision_score": 0.8438815000355113,
            "fpr": 0.22587719298245615,
            "logloss": 1.004412531024343,
            "mae": 0.2919167839581051,
            "precision": 0.6776212832550861,
            "recall": 0.8946280991735537
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8309656987078317,
            "auditor_fn_violation": 0.01445687460588084,
            "auditor_fp_violation": 0.03533531963828344,
            "ave_precision_score": 0.8311938096721458,
            "fpr": 0.2305159165751921,
            "logloss": 1.049842695017166,
            "mae": 0.30378123748711316,
            "precision": 0.6634615384615384,
            "recall": 0.8808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.836300087551285,
            "auditor_fn_violation": 0.012840727852689575,
            "auditor_fp_violation": 0.0195472618462043,
            "ave_precision_score": 0.8367682751239389,
            "fpr": 0.13048245614035087,
            "logloss": 0.6980291418571709,
            "mae": 0.2767296545633607,
            "precision": 0.75564681724846,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8241622819396077,
            "auditor_fn_violation": 0.014877268374710984,
            "auditor_fp_violation": 0.018050981827052084,
            "ave_precision_score": 0.8244095949635442,
            "fpr": 0.1394072447859495,
            "logloss": 0.7135279220568091,
            "mae": 0.29044179630762884,
            "precision": 0.7309322033898306,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8247392090539137,
            "auditor_fn_violation": 0.00879685007974482,
            "auditor_fp_violation": 0.022403775209050663,
            "ave_precision_score": 0.8251601251273384,
            "fpr": 0.13048245614035087,
            "logloss": 0.855081547116101,
            "mae": 0.273157315879772,
            "precision": 0.7541322314049587,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8141528735752596,
            "auditor_fn_violation": 0.012541747436765768,
            "auditor_fp_violation": 0.019863049500810206,
            "ave_precision_score": 0.8144474279680197,
            "fpr": 0.132821075740944,
            "logloss": 0.8569056965480869,
            "mae": 0.28447791178760495,
            "precision": 0.740343347639485,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8462983325326087,
            "auditor_fn_violation": 0.025049387414818044,
            "auditor_fp_violation": 0.022478070175438597,
            "ave_precision_score": 0.8466614062837671,
            "fpr": 0.10197368421052631,
            "logloss": 0.793338082766563,
            "mae": 0.33322754754654516,
            "precision": 0.786697247706422,
            "recall": 0.7086776859504132
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8244362148503979,
            "auditor_fn_violation": 0.020477847583903603,
            "auditor_fp_violation": 0.024958245281281197,
            "ave_precision_score": 0.8246697900862124,
            "fpr": 0.1163556531284303,
            "logloss": 0.8442384640486993,
            "mae": 0.3391005788163409,
            "precision": 0.7601809954751131,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.829853143982884,
            "auditor_fn_violation": 0.010434790488618242,
            "auditor_fp_violation": 0.02427652074110511,
            "ave_precision_score": 0.8302100539285151,
            "fpr": 0.1425438596491228,
            "logloss": 0.8151896176756076,
            "mae": 0.2716699349559752,
            "precision": 0.746588693957115,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8234370705044056,
            "auditor_fn_violation": 0.012380596492047554,
            "auditor_fp_violation": 0.01454632346901439,
            "ave_precision_score": 0.8236998129030848,
            "fpr": 0.14270032930845225,
            "logloss": 0.7996019020557774,
            "mae": 0.28043757615575376,
            "precision": 0.7341513292433538,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8427573426825079,
            "auditor_fn_violation": 0.027391891402058867,
            "auditor_fp_violation": 0.019836756025577964,
            "ave_precision_score": 0.8429584391687639,
            "fpr": 0.12171052631578948,
            "logloss": 0.7066167193345162,
            "mae": 0.32782670170360406,
            "precision": 0.7628205128205128,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8357084786903825,
            "auditor_fn_violation": 0.020048111731321677,
            "auditor_fp_violation": 0.018153035088898345,
            "ave_precision_score": 0.8359159055229508,
            "fpr": 0.12184412733260154,
            "logloss": 0.7220340983760348,
            "mae": 0.3254076369945048,
            "precision": 0.7612903225806451,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8385493097137021,
            "auditor_fn_violation": 0.017498550094243875,
            "auditor_fp_violation": 0.021786358419413027,
            "ave_precision_score": 0.8389744101973224,
            "fpr": 0.13596491228070176,
            "logloss": 0.7744547865902442,
            "mae": 0.26337854060399485,
            "precision": 0.7568627450980392,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.83186238060162,
            "auditor_fn_violation": 0.01805824789219236,
            "auditor_fp_violation": 0.013169848986063508,
            "ave_precision_score": 0.8321149572111506,
            "fpr": 0.14270032930845225,
            "logloss": 0.775389186064699,
            "mae": 0.2706010546958834,
            "precision": 0.7420634920634921,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8464576703666863,
            "auditor_fn_violation": 0.018764952153110043,
            "auditor_fp_violation": 0.0169392523364486,
            "ave_precision_score": 0.8467701408203723,
            "fpr": 0.08771929824561403,
            "logloss": 0.7585978927092358,
            "mae": 0.2898394294862845,
            "precision": 0.8014888337468983,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8332266221861818,
            "auditor_fn_violation": 0.01860242427073359,
            "auditor_fp_violation": 0.015263185405885735,
            "ave_precision_score": 0.8334507453624909,
            "fpr": 0.09549945115257959,
            "logloss": 0.8254728093229272,
            "mae": 0.29854238085371804,
            "precision": 0.7780612244897959,
            "recall": 0.648936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8310330125187075,
            "auditor_fn_violation": 0.008327896186747865,
            "auditor_fp_violation": 0.025119384325299234,
            "ave_precision_score": 0.8314079695170933,
            "fpr": 0.14364035087719298,
            "logloss": 0.7372867667878865,
            "mae": 0.2740358215832387,
            "precision": 0.7436399217221135,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8288267313575677,
            "auditor_fn_violation": 0.014034145316112759,
            "auditor_fp_violation": 0.015950178095387447,
            "ave_precision_score": 0.8290771905796044,
            "fpr": 0.14818880351262348,
            "logloss": 0.7202481722313212,
            "mae": 0.2813012705797872,
            "precision": 0.7289156626506024,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8538045227731705,
            "auditor_fn_violation": 0.048404197477163985,
            "auditor_fp_violation": 0.028698352188883423,
            "ave_precision_score": 0.8541178130935997,
            "fpr": 0.08552631578947369,
            "logloss": 0.5386374762790458,
            "mae": 0.31891713549519235,
            "precision": 0.8147268408551069,
            "recall": 0.7086776859504132
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8305570909036394,
            "auditor_fn_violation": 0.04014994044421609,
            "auditor_fp_violation": 0.031190961565745946,
            "ave_precision_score": 0.8308424144078321,
            "fpr": 0.11086717892425905,
            "logloss": 0.5526370217262935,
            "mae": 0.3258585258590836,
            "precision": 0.7725225225225225,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8275994922435239,
            "auditor_fn_violation": 0.013660830795998268,
            "auditor_fp_violation": 0.025913571897032302,
            "ave_precision_score": 0.828054517481626,
            "fpr": 0.13706140350877194,
            "logloss": 0.6937894949776283,
            "mae": 0.27569486988458297,
            "precision": 0.750996015936255,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8321008849789282,
            "auditor_fn_violation": 0.019569329939042902,
            "auditor_fp_violation": 0.019315446632366815,
            "ave_precision_score": 0.8323426636485365,
            "fpr": 0.14050493962678376,
            "logloss": 0.6763521643779723,
            "mae": 0.28319267342927706,
            "precision": 0.7360824742268042,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8191133827214703,
            "auditor_fn_violation": 0.009850297230680009,
            "auditor_fp_violation": 0.020336325627151996,
            "ave_precision_score": 0.819629912958981,
            "fpr": 0.15460526315789475,
            "logloss": 0.8524850911113891,
            "mae": 0.2776820582876102,
            "precision": 0.7314285714285714,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8122809668892794,
            "auditor_fn_violation": 0.01118247425088166,
            "auditor_fp_violation": 0.01665459451252144,
            "ave_precision_score": 0.8125768092789262,
            "fpr": 0.1602634467618002,
            "logloss": 0.8369219191420723,
            "mae": 0.28830570431223956,
            "precision": 0.7091633466135459,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8189364664205718,
            "auditor_fn_violation": 0.009612422067565612,
            "auditor_fp_violation": 0.022713764551565842,
            "ave_precision_score": 0.8193688783957583,
            "fpr": 0.1337719298245614,
            "logloss": 0.9201958640939419,
            "mae": 0.2758495248239232,
            "precision": 0.7515274949083504,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.810502513521574,
            "auditor_fn_violation": 0.011957867202279475,
            "auditor_fp_violation": 0.013864308987407625,
            "ave_precision_score": 0.8108052375689684,
            "fpr": 0.14050493962678376,
            "logloss": 0.9160819060138456,
            "mae": 0.28560587979900154,
            "precision": 0.7305263157894737,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8475028409902166,
            "auditor_fn_violation": 0.01550946063505873,
            "auditor_fp_violation": 0.01991617478275127,
            "ave_precision_score": 0.8477765375827462,
            "fpr": 0.1162280701754386,
            "logloss": 0.7404516767906648,
            "mae": 0.27731324882739916,
            "precision": 0.7710583153347732,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8308155826448105,
            "auditor_fn_violation": 0.013368521848798384,
            "auditor_fp_violation": 0.014337238737426915,
            "ave_precision_score": 0.8310376742477631,
            "fpr": 0.11855104281009879,
            "logloss": 0.7920614829784295,
            "mae": 0.28897424487612444,
            "precision": 0.755656108597285,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 2917,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8396553692031339,
            "auditor_fn_violation": 0.014449217050891694,
            "auditor_fp_violation": 0.024914432693884242,
            "ave_precision_score": 0.83997167089852,
            "fpr": 0.12171052631578948,
            "logloss": 0.7961015604925248,
            "mae": 0.2644164070371211,
            "precision": 0.7706611570247934,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8294824738025567,
            "auditor_fn_violation": 0.014632038676226736,
            "auditor_fp_violation": 0.01826006655863956,
            "ave_precision_score": 0.8297327936810279,
            "fpr": 0.12403951701427003,
            "logloss": 0.7781183778992385,
            "mae": 0.2729317171956388,
            "precision": 0.7585470085470085,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8391584264750251,
            "auditor_fn_violation": 0.007360537190082647,
            "auditor_fp_violation": 0.022982763567798003,
            "ave_precision_score": 0.8395267525720236,
            "fpr": 0.13267543859649122,
            "logloss": 0.7669277589367227,
            "mae": 0.2652447172358916,
            "precision": 0.7618110236220472,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8334641847677036,
            "auditor_fn_violation": 0.013613751547282628,
            "auditor_fp_violation": 0.01568882218090311,
            "ave_precision_score": 0.8337088041898555,
            "fpr": 0.14270032930845225,
            "logloss": 0.7592257327808538,
            "mae": 0.2731028456915816,
            "precision": 0.738430583501006,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8309016107599482,
            "auditor_fn_violation": 0.009342830216035958,
            "auditor_fp_violation": 0.023210772257747172,
            "ave_precision_score": 0.831271148922198,
            "fpr": 0.13048245614035087,
            "logloss": 0.7802354105818399,
            "mae": 0.2740731936890766,
            "precision": 0.7551440329218106,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.827041058717223,
            "auditor_fn_violation": 0.013004180582478925,
            "auditor_fp_violation": 0.014648376730860663,
            "ave_precision_score": 0.8272984265548105,
            "fpr": 0.132821075740944,
            "logloss": 0.7561245579595782,
            "mae": 0.2802286591667432,
            "precision": 0.7414529914529915,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.832615270067525,
            "auditor_fn_violation": 0.017421523850949697,
            "auditor_fp_violation": 0.020146745368093136,
            "ave_precision_score": 0.8330271906790796,
            "fpr": 0.10964912280701754,
            "logloss": 0.856927226287712,
            "mae": 0.27628648113938564,
            "precision": 0.7777777777777778,
            "recall": 0.7231404958677686
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8155500039367292,
            "auditor_fn_violation": 0.01899946283018427,
            "auditor_fp_violation": 0.014807679383498742,
            "ave_precision_score": 0.8158197378186203,
            "fpr": 0.11855104281009879,
            "logloss": 0.9129174937981581,
            "mae": 0.2905885591235894,
            "precision": 0.7505773672055427,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8450585377656429,
            "auditor_fn_violation": 0.010548064375815574,
            "auditor_fp_violation": 0.02270351696999508,
            "ave_precision_score": 0.8453173605997075,
            "fpr": 0.11951754385964912,
            "logloss": 0.7089326532989016,
            "mae": 0.27215865249194393,
            "precision": 0.7695560253699789,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.827147279704395,
            "auditor_fn_violation": 0.013321811430039474,
            "auditor_fp_violation": 0.015803320962486715,
            "ave_precision_score": 0.8273862608910498,
            "fpr": 0.1207464324917673,
            "logloss": 0.747832661915636,
            "mae": 0.286302866472487,
            "precision": 0.7533632286995515,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8422681702488986,
            "auditor_fn_violation": 0.01794258373205742,
            "auditor_fp_violation": 0.02737129037547139,
            "ave_precision_score": 0.8426183104111344,
            "fpr": 0.12609649122807018,
            "logloss": 0.7551292514746506,
            "mae": 0.2634310165608944,
            "precision": 0.7648261758691206,
            "recall": 0.7727272727272727
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8352032447782335,
            "auditor_fn_violation": 0.02089824135273373,
            "auditor_fp_violation": 0.017968841396785572,
            "ave_precision_score": 0.835459899082716,
            "fpr": 0.132821075740944,
            "logloss": 0.746655405579497,
            "mae": 0.27091998771480635,
            "precision": 0.7489626556016598,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8440993999138537,
            "auditor_fn_violation": 0.021068943018703788,
            "auditor_fp_violation": 0.018281685522216765,
            "ave_precision_score": 0.8442956541213613,
            "fpr": 0.12280701754385964,
            "logloss": 0.7026161857041351,
            "mae": 0.3273493267507076,
            "precision": 0.7622080679405521,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.836174514964303,
            "auditor_fn_violation": 0.020048111731321677,
            "auditor_fp_violation": 0.018573693656020768,
            "ave_precision_score": 0.8363753976354404,
            "fpr": 0.12294182217343579,
            "logloss": 0.7173807280917639,
            "mae": 0.32469361439902733,
            "precision": 0.759656652360515,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8507720957513102,
            "auditor_fn_violation": 0.00902566333188343,
            "auditor_fp_violation": 0.02208353828496475,
            "ave_precision_score": 0.8510852166169078,
            "fpr": 0.12280701754385964,
            "logloss": 0.612018665250474,
            "mae": 0.2657265727126043,
            "precision": 0.7723577235772358,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8494549487680363,
            "auditor_fn_violation": 0.01219141929607399,
            "auditor_fp_violation": 0.012798972497890491,
            "ave_precision_score": 0.8496697092010319,
            "fpr": 0.13172338090010977,
            "logloss": 0.6067053629742367,
            "mae": 0.274824518951619,
            "precision": 0.7484276729559748,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8444683230175523,
            "auditor_fn_violation": 0.015421107003044807,
            "auditor_fp_violation": 0.016001598622725037,
            "ave_precision_score": 0.844740058108437,
            "fpr": 0.08662280701754387,
            "logloss": 0.7712228041031698,
            "mae": 0.29309967120309366,
            "precision": 0.8025,
            "recall": 0.6632231404958677
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8303980826167131,
            "auditor_fn_violation": 0.017147394726393733,
            "auditor_fp_violation": 0.012754168626836027,
            "ave_precision_score": 0.8306264666204367,
            "fpr": 0.09220636663007684,
            "logloss": 0.8336919270150445,
            "mae": 0.30048287103157106,
            "precision": 0.7829457364341085,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8101722911768254,
            "auditor_fn_violation": 0.018601837755545896,
            "auditor_fp_violation": 0.026072409411378915,
            "ave_precision_score": 0.8108065606659286,
            "fpr": 0.15021929824561403,
            "logloss": 0.9185643476882783,
            "mae": 0.27862169885287247,
            "precision": 0.7334630350194552,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8023679659348726,
            "auditor_fn_violation": 0.021120115841838524,
            "auditor_fp_violation": 0.019975059178446355,
            "ave_precision_score": 0.8026872289097138,
            "fpr": 0.15916575192096596,
            "logloss": 0.9211366354004719,
            "mae": 0.2878467542796303,
            "precision": 0.7189922480620154,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8256386747918356,
            "auditor_fn_violation": 0.011236769609975357,
            "auditor_fp_violation": 0.020869199868830964,
            "ave_precision_score": 0.8268815719583618,
            "fpr": 0.1337719298245614,
            "logloss": 0.6801314594481119,
            "mae": 0.29254528958201836,
            "precision": 0.7447698744769874,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8233803049282207,
            "auditor_fn_violation": 0.015909568629282767,
            "auditor_fp_violation": 0.02033349014688202,
            "ave_precision_score": 0.8236097731743055,
            "fpr": 0.141602634467618,
            "logloss": 0.6939856035110346,
            "mae": 0.30428858092167177,
            "precision": 0.7237687366167024,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8371132146594938,
            "auditor_fn_violation": 0.007177033492822967,
            "auditor_fp_violation": 0.021837596327266763,
            "ave_precision_score": 0.8374640552097541,
            "fpr": 0.13706140350877194,
            "logloss": 0.7372567724164572,
            "mae": 0.26768542480307006,
            "precision": 0.7544204322200393,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8307013312726068,
            "auditor_fn_violation": 0.00940514281710536,
            "auditor_fp_violation": 0.017503378958608692,
            "ave_precision_score": 0.8309511714949687,
            "fpr": 0.1437980241492865,
            "logloss": 0.729387218493249,
            "mae": 0.27738066109776266,
            "precision": 0.7369477911646586,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.835742441663953,
            "auditor_fn_violation": 0.013941750036247648,
            "auditor_fp_violation": 0.021361083784226926,
            "ave_precision_score": 0.836198019288716,
            "fpr": 0.13815789473684212,
            "logloss": 0.8519912334120493,
            "mae": 0.2725103472468734,
            "precision": 0.7485029940119761,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8207905203141195,
            "auditor_fn_violation": 0.014113553028002905,
            "auditor_fp_violation": 0.021159872657442052,
            "ave_precision_score": 0.8210433044504118,
            "fpr": 0.14050493962678376,
            "logloss": 0.9053929443344696,
            "mae": 0.28492525369161376,
            "precision": 0.7316561844863732,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 2917,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6197633039313788,
            "auditor_fn_violation": 0.05565372625779325,
            "auditor_fp_violation": 0.06782874241678964,
            "ave_precision_score": 0.5789602649328964,
            "fpr": 0.2982456140350877,
            "logloss": 5.191906476760243,
            "mae": 0.3907848678587366,
            "precision": 0.593423019431988,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6113329162311316,
            "auditor_fn_violation": 0.05481467641357404,
            "auditor_fp_violation": 0.060848635099850404,
            "ave_precision_score": 0.5669203758269253,
            "fpr": 0.31833150384193193,
            "logloss": 5.267064405939645,
            "mae": 0.4058424865723757,
            "precision": 0.5747800586510264,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8322817567543876,
            "auditor_fn_violation": 0.01783157532260404,
            "auditor_fp_violation": 0.020269716346942124,
            "ave_precision_score": 0.832693731659049,
            "fpr": 0.1118421052631579,
            "logloss": 0.8518891180185729,
            "mae": 0.2767066625180974,
            "precision": 0.7748344370860927,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8154279320615352,
            "auditor_fn_violation": 0.01890370647172852,
            "auditor_fp_violation": 0.016331010999350342,
            "ave_precision_score": 0.8156974553853689,
            "fpr": 0.1207464324917673,
            "logloss": 0.9082582406521073,
            "mae": 0.2910681716381174,
            "precision": 0.7465437788018433,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8771865598356836,
            "auditor_fn_violation": 0.03240992460490068,
            "auditor_fp_violation": 0.010862436464994261,
            "ave_precision_score": 0.8774560508660683,
            "fpr": 0.07017543859649122,
            "logloss": 0.4830721169796404,
            "mae": 0.30399336363546337,
            "precision": 0.847255369928401,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8703164515033177,
            "auditor_fn_violation": 0.016773711376322487,
            "auditor_fp_violation": 0.013458585043970022,
            "ave_precision_score": 0.8705056203743764,
            "fpr": 0.08342480790340286,
            "logloss": 0.4807245858376636,
            "mae": 0.30480831037189876,
            "precision": 0.8240740740740741,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8249378839519402,
            "auditor_fn_violation": 0.014995197187182837,
            "auditor_fp_violation": 0.02325176258403018,
            "ave_precision_score": 0.8254816393279027,
            "fpr": 0.12719298245614036,
            "logloss": 0.8258497311943553,
            "mae": 0.27299959268515056,
            "precision": 0.7618069815195072,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8203232041855653,
            "auditor_fn_violation": 0.01653315271971413,
            "auditor_fp_violation": 0.015464802825630803,
            "ave_precision_score": 0.8205965248161081,
            "fpr": 0.1350164654226125,
            "logloss": 0.8156166846596058,
            "mae": 0.28259260903079036,
            "precision": 0.7382978723404255,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8298509284584877,
            "auditor_fn_violation": 0.010434790488618242,
            "auditor_fp_violation": 0.02427652074110511,
            "ave_precision_score": 0.8302107881937677,
            "fpr": 0.1425438596491228,
            "logloss": 0.8184835690225908,
            "mae": 0.27159638858775353,
            "precision": 0.746588693957115,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8230155183639156,
            "auditor_fn_violation": 0.013693159259172765,
            "auditor_fp_violation": 0.013782168557141117,
            "ave_precision_score": 0.8232792403779183,
            "fpr": 0.145993413830955,
            "logloss": 0.8031871204021924,
            "mae": 0.28041163117639706,
            "precision": 0.7296747967479674,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8305084931834451,
            "auditor_fn_violation": 0.018191786283891554,
            "auditor_fp_violation": 0.027899040826364987,
            "ave_precision_score": 0.8309851343139261,
            "fpr": 0.1425438596491228,
            "logloss": 0.8603723922065113,
            "mae": 0.2648021210173104,
            "precision": 0.7475728155339806,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8212579299600472,
            "auditor_fn_violation": 0.014923978793469884,
            "auditor_fp_violation": 0.020594846061366374,
            "ave_precision_score": 0.8215361429900501,
            "fpr": 0.15148188803512624,
            "logloss": 0.8693898706721592,
            "mae": 0.27649204139608824,
            "precision": 0.7294117647058823,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8345911212682391,
            "auditor_fn_violation": 0.013928157169783972,
            "auditor_fp_violation": 0.02449684374487622,
            "ave_precision_score": 0.8348948258212353,
            "fpr": 0.12938596491228072,
            "logloss": 0.7914675033242564,
            "mae": 0.2795745722183758,
            "precision": 0.7531380753138075,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8216316033994766,
            "auditor_fn_violation": 0.01783870892402551,
            "auditor_fp_violation": 0.018750420036291137,
            "ave_precision_score": 0.8218810171804793,
            "fpr": 0.12733260153677278,
            "logloss": 0.8299154206436437,
            "mae": 0.289400045600199,
            "precision": 0.7433628318584071,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8339706485508391,
            "auditor_fn_violation": 0.021238853849499785,
            "auditor_fp_violation": 0.0242560255779636,
            "ave_precision_score": 0.8343742621658005,
            "fpr": 0.12280701754385964,
            "logloss": 0.8016224495688606,
            "mae": 0.26667845231806486,
            "precision": 0.7671517671517671,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8286603198204655,
            "auditor_fn_violation": 0.022012284840133588,
            "auditor_fp_violation": 0.021259436815340857,
            "ave_precision_score": 0.8289118280586647,
            "fpr": 0.1350164654226125,
            "logloss": 0.800774128102945,
            "mae": 0.274718103266932,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8519243208470381,
            "auditor_fn_violation": 0.010697585906916059,
            "auditor_fp_violation": 0.021176627315953437,
            "ave_precision_score": 0.8522387062188773,
            "fpr": 0.1206140350877193,
            "logloss": 0.6130266161345213,
            "mae": 0.26571995197366055,
            "precision": 0.7759674134419552,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8498753137324753,
            "auditor_fn_violation": 0.012775299530560297,
            "auditor_fp_violation": 0.01789914648625642,
            "ave_precision_score": 0.850086081733286,
            "fpr": 0.13172338090010977,
            "logloss": 0.610660166138522,
            "mae": 0.2759353485384142,
            "precision": 0.7478991596638656,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8300777838359916,
            "auditor_fn_violation": 0.014206810932289399,
            "auditor_fp_violation": 0.020285087719298246,
            "ave_precision_score": 0.8304366298607802,
            "fpr": 0.11732456140350878,
            "logloss": 0.8871928013127489,
            "mae": 0.27702164653184996,
            "precision": 0.7683982683982684,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8117703272836552,
            "auditor_fn_violation": 0.01899946283018427,
            "auditor_fp_violation": 0.014827592215078497,
            "ave_precision_score": 0.8120521401506258,
            "fpr": 0.12294182217343579,
            "logloss": 0.9470174983642804,
            "mae": 0.2917643031040196,
            "precision": 0.7437070938215103,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8516463526447192,
            "auditor_fn_violation": 0.010548064375815581,
            "auditor_fp_violation": 0.0169392523364486,
            "ave_precision_score": 0.8521986024415548,
            "fpr": 0.08552631578947369,
            "logloss": 0.6377595572162535,
            "mae": 0.2800275293379137,
            "precision": 0.8115942028985508,
            "recall": 0.6942148760330579
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.847898500522472,
            "auditor_fn_violation": 0.01604736436462153,
            "auditor_fp_violation": 0.012915960383421573,
            "ave_precision_score": 0.8481218386367835,
            "fpr": 0.09769484083424808,
            "logloss": 0.6448374811336555,
            "mae": 0.28926069136991006,
            "precision": 0.7775,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8386079567195387,
            "auditor_fn_violation": 0.014807162534435266,
            "auditor_fp_violation": 0.022216756845384496,
            "ave_precision_score": 0.8390661057225091,
            "fpr": 0.12719298245614036,
            "logloss": 0.7859331134028654,
            "mae": 0.2639543651708881,
            "precision": 0.7642276422764228,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8304900634196645,
            "auditor_fn_violation": 0.01553588527921153,
            "auditor_fp_violation": 0.013777190349246177,
            "ave_precision_score": 0.8307451485386205,
            "fpr": 0.1350164654226125,
            "logloss": 0.7879004363639595,
            "mae": 0.27141257859683954,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8314046793760804,
            "auditor_fn_violation": 0.011970784399014068,
            "auditor_fp_violation": 0.023000696835546813,
            "ave_precision_score": 0.8318547635377248,
            "fpr": 0.13267543859649122,
            "logloss": 0.7384875246213759,
            "mae": 0.2790531067539084,
            "precision": 0.7505154639175258,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8191415015460388,
            "auditor_fn_violation": 0.01535605016698975,
            "auditor_fp_violation": 0.015524541320370084,
            "ave_precision_score": 0.8193987941151352,
            "fpr": 0.13830954994511527,
            "logloss": 0.7508492749376225,
            "mae": 0.29221247046754956,
            "precision": 0.7301927194860813,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.813053585296349,
            "auditor_fn_violation": 0.010665869218500797,
            "auditor_fp_violation": 0.02175561567470077,
            "ave_precision_score": 0.8136290725793847,
            "fpr": 0.14473684210526316,
            "logloss": 0.8018836702539137,
            "mae": 0.2825879692756849,
            "precision": 0.7401574803149606,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8101849471495794,
            "auditor_fn_violation": 0.01373753415699372,
            "auditor_fp_violation": 0.017067785767801453,
            "ave_precision_score": 0.810483339016989,
            "fpr": 0.150384193194292,
            "logloss": 0.7901895625177077,
            "mae": 0.2896092662256627,
            "precision": 0.7237903225806451,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8528797823492853,
            "auditor_fn_violation": 0.01034190590111643,
            "auditor_fp_violation": 0.02491699458927693,
            "ave_precision_score": 0.8531700677969167,
            "fpr": 0.12609649122807018,
            "logloss": 0.5970437994909268,
            "mae": 0.2667296311112441,
            "precision": 0.77,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8517091780081429,
            "auditor_fn_violation": 0.014755821285937831,
            "auditor_fp_violation": 0.013471030563707383,
            "ave_precision_score": 0.8519243383445984,
            "fpr": 0.1350164654226125,
            "logloss": 0.590154074819002,
            "mae": 0.27378637792361527,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 2917,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8283289503195543,
            "auditor_fn_violation": 0.009424387414818037,
            "auditor_fp_violation": 0.024138178389899987,
            "ave_precision_score": 0.8287236356016707,
            "fpr": 0.14583333333333334,
            "logloss": 0.8077492592129664,
            "mae": 0.271909249231835,
            "precision": 0.7422480620155039,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8220319468083253,
            "auditor_fn_violation": 0.011238526753392349,
            "auditor_fp_violation": 0.014919689061134885,
            "ave_precision_score": 0.822299035560342,
            "fpr": 0.14818880351262348,
            "logloss": 0.7937714966223405,
            "mae": 0.2811859716286027,
            "precision": 0.7267206477732794,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 2917,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8709296549841249,
            "auditor_fn_violation": 0.028381905176163548,
            "auditor_fp_violation": 0.026646273979340874,
            "ave_precision_score": 0.8712286890475367,
            "fpr": 0.13267543859649122,
            "logloss": 0.48901028246391265,
            "mae": 0.29653219645913115,
            "precision": 0.766859344894027,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8634814902886037,
            "auditor_fn_violation": 0.024896653198495922,
            "auditor_fp_violation": 0.025597944995780976,
            "ave_precision_score": 0.8636872685371388,
            "fpr": 0.13721185510428102,
            "logloss": 0.5005823668942608,
            "mae": 0.29934010509120806,
            "precision": 0.7572815533980582,
            "recall": 0.8297872340425532
        }
    }
]