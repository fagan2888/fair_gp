[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8302923943303371,
            "auditor_fn_violation": 0.01697395776343145,
            "auditor_fp_violation": 0.010949647901656699,
            "ave_precision_score": 0.8305350333348138,
            "fpr": 0.11403508771929824,
            "logloss": 0.8919786038729313,
            "mae": 0.2824396300933337,
            "precision": 0.7688888888888888,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.843322888247886,
            "auditor_fn_violation": 0.010257528956632928,
            "auditor_fp_violation": 0.013387867214010396,
            "ave_precision_score": 0.8437805070856118,
            "fpr": 0.10757409440175632,
            "logloss": 0.7649025027589952,
            "mae": 0.257825908778471,
            "precision": 0.7841409691629956,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 1318,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8164861418551997,
            "auditor_fn_violation": 0.010841813473392421,
            "auditor_fp_violation": 0.027058655920543826,
            "ave_precision_score": 0.8167641348213881,
            "fpr": 0.23903508771929824,
            "logloss": 1.2856119033742803,
            "mae": 0.30072441866307037,
            "precision": 0.6640986132511556,
            "recall": 0.896049896049896
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8252548297089614,
            "auditor_fn_violation": 0.01400083081343133,
            "auditor_fp_violation": 0.0282042414126681,
            "ave_precision_score": 0.8254640158192676,
            "fpr": 0.2349066959385291,
            "logloss": 1.1853898434249313,
            "mae": 0.29061534071602935,
            "precision": 0.6682170542635659,
            "recall": 0.9112050739957717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8489993230560677,
            "auditor_fn_violation": 0.03827689025057447,
            "auditor_fp_violation": 0.04524361948955916,
            "ave_precision_score": 0.8492765507734721,
            "fpr": 0.17653508771929824,
            "logloss": 0.6453850104937405,
            "mae": 0.3014500469295447,
            "precision": 0.7130124777183601,
            "recall": 0.8316008316008316
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.852564493366459,
            "auditor_fn_violation": 0.035701770468063575,
            "auditor_fp_violation": 0.043110837105093,
            "ave_precision_score": 0.8529694390832019,
            "fpr": 0.1756311745334797,
            "logloss": 0.5955128153518617,
            "mae": 0.295480731619276,
            "precision": 0.7127468581687613,
            "recall": 0.8393234672304439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8301054153813098,
            "auditor_fn_violation": 0.051956815114709856,
            "auditor_fp_violation": 0.04454145805348638,
            "ave_precision_score": 0.8304826784382764,
            "fpr": 0.15350877192982457,
            "logloss": 0.6688810627170036,
            "mae": 0.31179688709737813,
            "precision": 0.7281553398058253,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8360326294835749,
            "auditor_fn_violation": 0.048702376172827765,
            "auditor_fp_violation": 0.04459949175225177,
            "ave_precision_score": 0.8364686533450267,
            "fpr": 0.14489571899012074,
            "logloss": 0.6199264944213698,
            "mae": 0.307716008758418,
            "precision": 0.7401574803149606,
            "recall": 0.7949260042283298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8240693854114423,
            "auditor_fn_violation": 0.019885016595542915,
            "auditor_fp_violation": 0.01707575202507429,
            "ave_precision_score": 0.8243176301204149,
            "fpr": 0.14364035087719298,
            "logloss": 0.7430661634405458,
            "mae": 0.2996383567423388,
            "precision": 0.7421259842519685,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8308594389770144,
            "auditor_fn_violation": 0.015216881757611343,
            "auditor_fp_violation": 0.013738728578660613,
            "ave_precision_score": 0.8312045443062154,
            "fpr": 0.15587266739846323,
            "logloss": 0.6997924822819439,
            "mae": 0.2865018356810237,
            "precision": 0.727447216890595,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 1318,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7829545652205403,
            "auditor_fn_violation": 0.016420013130539455,
            "auditor_fp_violation": 0.013735397077380229,
            "ave_precision_score": 0.7833894807372886,
            "fpr": 0.13048245614035087,
            "logloss": 1.0791506753422588,
            "mae": 0.3081848135547154,
            "precision": 0.7361419068736141,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7915452064201544,
            "auditor_fn_violation": 0.015864359264149943,
            "auditor_fp_violation": 0.019908876291295133,
            "ave_precision_score": 0.7924253392307332,
            "fpr": 0.13172338090010977,
            "logloss": 0.9724467361251865,
            "mae": 0.28952292936243956,
            "precision": 0.7391304347826086,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 1318,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8169173067311306,
            "auditor_fn_violation": 0.01504996899733742,
            "auditor_fp_violation": 0.017536227459600276,
            "ave_precision_score": 0.8172199982123527,
            "fpr": 0.13596491228070176,
            "logloss": 0.9170538918560883,
            "mae": 0.2863930257565897,
            "precision": 0.743801652892562,
            "recall": 0.7484407484407485
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.824491646828752,
            "auditor_fn_violation": 0.013137527471379876,
            "auditor_fp_violation": 0.022988937842403103,
            "ave_precision_score": 0.8250090530298418,
            "fpr": 0.13721185510428102,
            "logloss": 0.8174850939500399,
            "mae": 0.26350800300361443,
            "precision": 0.7469635627530364,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7649972741133709,
            "auditor_fn_violation": 0.0006154940365466682,
            "auditor_fp_violation": 0.0030172589245736343,
            "ave_precision_score": 0.5309720922506436,
            "fpr": 0.4649122807017544,
            "logloss": 16.06620802133745,
            "mae": 0.46616553753791795,
            "precision": 0.5309734513274337,
            "recall": 0.997920997920998
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.761037527593819,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002706644813015959,
            "ave_precision_score": 0.522075055187638,
            "fpr": 0.47530186608122943,
            "logloss": 16.4167948702602,
            "mae": 0.47536963589667114,
            "precision": 0.522075055187638,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.803518035249281,
            "auditor_fn_violation": 0.01303935514461831,
            "auditor_fp_violation": 0.017052855456506696,
            "ave_precision_score": 0.8037928940991065,
            "fpr": 0.08442982456140351,
            "logloss": 1.687140331227376,
            "mae": 0.3134941148789259,
            "precision": 0.7878787878787878,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8095034142426574,
            "auditor_fn_violation": 0.0078648791027215,
            "auditor_fp_violation": 0.013663544000521279,
            "ave_precision_score": 0.8102936892798717,
            "fpr": 0.07464324917672886,
            "logloss": 1.5443992905279083,
            "mae": 0.29210518099280086,
            "precision": 0.8126721763085399,
            "recall": 0.6236786469344608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.8065627319219416,
            "auditor_fn_violation": 0.011240744793376369,
            "auditor_fp_violation": 0.0023532584361134865,
            "ave_precision_score": 0.8081772929349744,
            "fpr": 0.019736842105263157,
            "logloss": 1.0728858550972318,
            "mae": 0.3862005753754293,
            "precision": 0.8947368421052632,
            "recall": 0.3180873180873181
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.855098355622594,
            "auditor_fn_violation": 0.01018094559564451,
            "auditor_fp_violation": 0.0032379491652005676,
            "ave_precision_score": 0.8554628492644039,
            "fpr": 0.010976948408342482,
            "logloss": 0.978866613459533,
            "mae": 0.36858447002265926,
            "precision": 0.937888198757764,
            "recall": 0.3192389006342495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8617723049732394,
            "auditor_fn_violation": 0.011302294197031043,
            "auditor_fp_violation": 0.00474213375666545,
            "ave_precision_score": 0.8620052456656262,
            "fpr": 0.09539473684210527,
            "logloss": 0.7457038279663518,
            "mae": 0.2441813356464649,
            "precision": 0.8036117381489842,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8581627239961407,
            "auditor_fn_violation": 0.007505169376866724,
            "auditor_fp_violation": 0.008766521811046117,
            "ave_precision_score": 0.8586085950691844,
            "fpr": 0.09001097694840834,
            "logloss": 0.7401261619620954,
            "mae": 0.24527874563702884,
            "precision": 0.8084112149532711,
            "recall": 0.7315010570824524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8238544701967221,
            "auditor_fn_violation": 0.019326512747565385,
            "auditor_fp_violation": 0.018569117108316033,
            "ave_precision_score": 0.8241025871659103,
            "fpr": 0.13706140350877194,
            "logloss": 0.7442845621599444,
            "mae": 0.29940032538408495,
            "precision": 0.748995983935743,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8308923626778426,
            "auditor_fn_violation": 0.014381426910464772,
            "auditor_fp_violation": 0.01680124706153608,
            "ave_precision_score": 0.8312879958063079,
            "fpr": 0.14928649835345773,
            "logloss": 0.6982261241731845,
            "mae": 0.2850286285239594,
            "precision": 0.7322834645669292,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8419051043180634,
            "auditor_fn_violation": 0.03967656928183245,
            "auditor_fp_violation": 0.017905116619855905,
            "ave_precision_score": 0.8421597228021387,
            "fpr": 0.08333333333333333,
            "logloss": 1.3445965042759374,
            "mae": 0.3158412566131479,
            "precision": 0.8181818181818182,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8532528566551978,
            "auditor_fn_violation": 0.037978384926538,
            "auditor_fp_violation": 0.015668466084236804,
            "ave_precision_score": 0.8536908939334773,
            "fpr": 0.07464324917672886,
            "logloss": 1.24448524443293,
            "mae": 0.31077727681811723,
            "precision": 0.826530612244898,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8413526355221659,
            "auditor_fn_violation": 0.04041516212568845,
            "auditor_fp_violation": 0.020606911710831604,
            "ave_precision_score": 0.8416164313569836,
            "fpr": 0.08662280701754387,
            "logloss": 1.3420448084961245,
            "mae": 0.3162958924795407,
            "precision": 0.8132387706855791,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8533649389228776,
            "auditor_fn_violation": 0.038721011457334954,
            "auditor_fp_violation": 0.015871464445213,
            "ave_precision_score": 0.8537169059249251,
            "fpr": 0.07574094401756312,
            "logloss": 1.2443687813037672,
            "mae": 0.31125228561011214,
            "precision": 0.8253164556962025,
            "recall": 0.6892177589852009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8367034220007828,
            "auditor_fn_violation": 0.014808330597804287,
            "auditor_fp_violation": 0.019490067977368013,
            "ave_precision_score": 0.8369187915482019,
            "fpr": 0.13706140350877194,
            "logloss": 0.7711298178114533,
            "mae": 0.2895728321454769,
            "precision": 0.7401247401247402,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8343470562971258,
            "auditor_fn_violation": 0.013836060551910763,
            "auditor_fp_violation": 0.023026530131472763,
            "ave_precision_score": 0.8350962139197357,
            "fpr": 0.13611416026344675,
            "logloss": 0.6953165808850116,
            "mae": 0.2721741102123905,
            "precision": 0.7453798767967146,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 1318,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8407483540679639,
            "auditor_fn_violation": 0.0411309588941168,
            "auditor_fp_violation": 0.021395571294826398,
            "ave_precision_score": 0.841020416974395,
            "fpr": 0.08881578947368421,
            "logloss": 1.3458352767505328,
            "mae": 0.31520510153277975,
            "precision": 0.8076009501187649,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8525924256694231,
            "auditor_fn_violation": 0.04250376534858194,
            "auditor_fp_violation": 0.014856472640332019,
            "ave_precision_score": 0.8530302793981277,
            "fpr": 0.07354555433589462,
            "logloss": 1.2438310151478393,
            "mae": 0.308960734352092,
            "precision": 0.8295165394402035,
            "recall": 0.6892177589852009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7759165923133899,
            "auditor_fn_violation": 0.023484516905569547,
            "auditor_fp_violation": 0.027503866976024745,
            "ave_precision_score": 0.7492983470863916,
            "fpr": 0.1524122807017544,
            "logloss": 3.2869505293315076,
            "mae": 0.3005360028814996,
            "precision": 0.7208835341365462,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7826322928201809,
            "auditor_fn_violation": 0.024792122589074577,
            "auditor_fp_violation": 0.024184372634818475,
            "ave_precision_score": 0.757837258940094,
            "fpr": 0.14928649835345773,
            "logloss": 3.012468636871431,
            "mae": 0.2844319628903594,
            "precision": 0.7269076305220884,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8723005998785193,
            "auditor_fn_violation": 0.007675438596491237,
            "auditor_fp_violation": 0.005403590181951399,
            "ave_precision_score": 0.872481101304803,
            "fpr": 0.09978070175438597,
            "logloss": 0.8855582585386319,
            "mae": 0.23156849316156342,
            "precision": 0.8026030368763557,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8745660514131024,
            "auditor_fn_violation": 0.008394000505914323,
            "auditor_fp_violation": 0.0060247908615651425,
            "ave_precision_score": 0.8746083704915972,
            "fpr": 0.09001097694840834,
            "logloss": 0.8004624025922655,
            "mae": 0.22341466347635772,
            "precision": 0.8153153153153153,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8742176932853607,
            "auditor_fn_violation": 0.013394973921289717,
            "auditor_fp_violation": 0.010178796759881141,
            "ave_precision_score": 0.874441992433798,
            "fpr": 0.09978070175438597,
            "logloss": 0.4704074216567158,
            "mae": 0.29329605499821665,
            "precision": 0.8076109936575053,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.874938500607643,
            "auditor_fn_violation": 0.013843022675636982,
            "auditor_fp_violation": 0.018352555523810963,
            "ave_precision_score": 0.8761446820810495,
            "fpr": 0.10208562019758508,
            "logloss": 0.45143336491819225,
            "mae": 0.2878060742842624,
            "precision": 0.7978260869565217,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8333110414795166,
            "auditor_fn_violation": 0.028260294707663138,
            "auditor_fp_violation": 0.030139516424471855,
            "ave_precision_score": 0.8335546139240786,
            "fpr": 0.14035087719298245,
            "logloss": 0.8904355414257692,
            "mae": 0.28286869736303794,
            "precision": 0.7371663244353183,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8346660152340939,
            "auditor_fn_violation": 0.02100240657410137,
            "auditor_fp_violation": 0.025788310301790907,
            "ave_precision_score": 0.835287425203096,
            "fpr": 0.12294182217343579,
            "logloss": 0.7723590099014755,
            "mae": 0.26724927146094324,
            "precision": 0.7575757575757576,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7837159441140022,
            "auditor_fn_violation": 0.01381214210161579,
            "auditor_fp_violation": 0.02016678878169903,
            "ave_precision_score": 0.7289426274278333,
            "fpr": 0.13815789473684212,
            "logloss": 5.150299421900275,
            "mae": 0.29341578123357254,
            "precision": 0.7423312883435583,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7950572161676597,
            "auditor_fn_violation": 0.0137525150671961,
            "auditor_fp_violation": 0.01701677618553549,
            "ave_precision_score": 0.740867770346891,
            "fpr": 0.12403951701427003,
            "logloss": 4.763023760529959,
            "mae": 0.2700838834705136,
            "precision": 0.7655601659751037,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7815983204271763,
            "auditor_fn_violation": 0.01611682532735165,
            "auditor_fp_violation": 0.02448915211462531,
            "ave_precision_score": 0.7480712916047029,
            "fpr": 0.14583333333333334,
            "logloss": 3.7771655889610973,
            "mae": 0.29812711109085016,
            "precision": 0.7285714285714285,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7903145396454292,
            "auditor_fn_violation": 0.0137525150671961,
            "auditor_fp_violation": 0.021021608047757247,
            "ave_precision_score": 0.7540201396579114,
            "fpr": 0.14489571899012074,
            "logloss": 3.604219617909034,
            "mae": 0.2752501155304409,
            "precision": 0.7365269461077845,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8444224335076713,
            "auditor_fn_violation": 0.04076850129481709,
            "auditor_fp_violation": 0.03931849635690154,
            "ave_precision_score": 0.8446513624747829,
            "fpr": 0.16557017543859648,
            "logloss": 1.3503337681770453,
            "mae": 0.31914711999776796,
            "precision": 0.7234432234432234,
            "recall": 0.8212058212058212
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8526633706011626,
            "auditor_fn_violation": 0.03399140873932185,
            "auditor_fp_violation": 0.03314136204381757,
            "ave_precision_score": 0.85310171271899,
            "fpr": 0.16794731064763996,
            "logloss": 1.2486387422416938,
            "mae": 0.3163339297243262,
            "precision": 0.7171903881700554,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 1318,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8196419015027336,
            "auditor_fn_violation": 0.011258981653718496,
            "auditor_fp_violation": 0.02281515854601701,
            "ave_precision_score": 0.8198546305041218,
            "fpr": 0.2543859649122807,
            "logloss": 1.3481905712628635,
            "mae": 0.3060971544843965,
            "precision": 0.6516516516516516,
            "recall": 0.9022869022869023
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8293149197330298,
            "auditor_fn_violation": 0.014098300545598429,
            "auditor_fp_violation": 0.026753179054578986,
            "ave_precision_score": 0.82976539281988,
            "fpr": 0.24478594950603733,
            "logloss": 1.2552525500615788,
            "mae": 0.29840601002377765,
            "precision": 0.6610942249240122,
            "recall": 0.919661733615222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7842841354548225,
            "auditor_fn_violation": 0.016005124557756146,
            "auditor_fp_violation": 0.019327247934220707,
            "ave_precision_score": 0.7507521603215415,
            "fpr": 0.14692982456140352,
            "logloss": 3.7202992303696427,
            "mae": 0.2912175614016726,
            "precision": 0.7303822937625755,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7907183856735759,
            "auditor_fn_violation": 0.014560121419437785,
            "auditor_fp_violation": 0.023427514548215875,
            "ave_precision_score": 0.7545367762067532,
            "fpr": 0.15148188803512624,
            "logloss": 3.575191386558876,
            "mae": 0.2726680970363432,
            "precision": 0.7288801571709234,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8665831791962081,
            "auditor_fn_violation": 0.01720419812525076,
            "auditor_fp_violation": 0.011735763422477303,
            "ave_precision_score": 0.8668038275106822,
            "fpr": 0.1074561403508772,
            "logloss": 0.48139521878431263,
            "mae": 0.2998544475387398,
            "precision": 0.7901498929336188,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8735042270619143,
            "auditor_fn_violation": 0.01262233031563949,
            "auditor_fp_violation": 0.01363347016926555,
            "ave_precision_score": 0.8738671889919363,
            "fpr": 0.09769484083424808,
            "logloss": 0.4611477193505821,
            "mae": 0.29216626018150804,
            "precision": 0.8052516411378556,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8290803164550119,
            "auditor_fn_violation": 0.01880220301272934,
            "auditor_fp_violation": 0.020840965522855862,
            "ave_precision_score": 0.8292966093464463,
            "fpr": 0.15679824561403508,
            "logloss": 0.7297352020404138,
            "mae": 0.29665771396040536,
            "precision": 0.7239382239382239,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8301800230247565,
            "auditor_fn_violation": 0.016472384736239944,
            "auditor_fp_violation": 0.015397801602935208,
            "ave_precision_score": 0.8309346970195223,
            "fpr": 0.15477497255762898,
            "logloss": 0.6714412192074939,
            "mae": 0.2819467517680209,
            "precision": 0.7283236994219653,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8641285112297445,
            "auditor_fn_violation": 0.0004559215085530925,
            "auditor_fp_violation": 0.011076851060365532,
            "ave_precision_score": 0.8643822190533272,
            "fpr": 0.09429824561403509,
            "logloss": 0.5470340283175832,
            "mae": 0.26041059650846,
            "precision": 0.8080357142857143,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8703931783760597,
            "auditor_fn_violation": 0.004079804503565768,
            "auditor_fp_violation": 0.008736447979790389,
            "ave_precision_score": 0.8708203147964009,
            "fpr": 0.07354555433589462,
            "logloss": 0.5240880742771422,
            "mae": 0.25397837075274987,
            "precision": 0.8361858190709046,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8294149243853974,
            "auditor_fn_violation": 0.018968614363351205,
            "auditor_fp_violation": 0.020260919119143572,
            "ave_precision_score": 0.8296485554915369,
            "fpr": 0.14473684210526316,
            "logloss": 0.7500565922234708,
            "mae": 0.2876649243688131,
            "precision": 0.7391304347826086,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8331568785024344,
            "auditor_fn_violation": 0.017003826847341516,
            "auditor_fp_violation": 0.022089229057335763,
            "ave_precision_score": 0.8339002306888132,
            "fpr": 0.1525795828759605,
            "logloss": 0.6908800054307453,
            "mae": 0.27263319762471794,
            "precision": 0.7295719844357976,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.800077920058104,
            "auditor_fn_violation": 0.006234726629463474,
            "auditor_fp_violation": 0.02869448854153947,
            "ave_precision_score": 0.7986291898049847,
            "fpr": 0.29605263157894735,
            "logloss": 2.033215693886421,
            "mae": 0.33315964397944703,
            "precision": 0.6265560165975104,
            "recall": 0.9417879417879418
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.8207799407877707,
            "auditor_fn_violation": 0.011731178478683138,
            "auditor_fp_violation": 0.030068818950523542,
            "ave_precision_score": 0.8202688966998176,
            "fpr": 0.31833150384193193,
            "logloss": 1.9096954191172284,
            "mae": 0.33835807567485743,
            "precision": 0.6065128900949797,
            "recall": 0.945031712473573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7828968964483998,
            "auditor_fn_violation": 0.01838503483240326,
            "auditor_fp_violation": 0.024601090894289093,
            "ave_precision_score": 0.7496366250756687,
            "fpr": 0.15350877192982457,
            "logloss": 3.6562128166692536,
            "mae": 0.2963150998758692,
            "precision": 0.7216699801192843,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7896667367159164,
            "auditor_fn_violation": 0.014086697006054732,
            "auditor_fp_violation": 0.019979048564225176,
            "ave_precision_score": 0.7537613371760923,
            "fpr": 0.1525795828759605,
            "logloss": 3.5170628156282513,
            "mae": 0.27478381157262766,
            "precision": 0.7274509803921568,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8423209109541235,
            "auditor_fn_violation": 0.043645366013787074,
            "auditor_fp_violation": 0.04451601742174462,
            "ave_precision_score": 0.8426325230269156,
            "fpr": 0.16885964912280702,
            "logloss": 0.6734261723791943,
            "mae": 0.304233571374553,
            "precision": 0.7158671586715867,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8468932039016963,
            "auditor_fn_violation": 0.041213451751322225,
            "auditor_fp_violation": 0.04211840067365382,
            "ave_precision_score": 0.8473019029287507,
            "fpr": 0.17233809001097694,
            "logloss": 0.6191772581869723,
            "mae": 0.29750890876606434,
            "precision": 0.7113970588235294,
            "recall": 0.8181818181818182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8336209421141754,
            "auditor_fn_violation": 0.015587956377430063,
            "auditor_fp_violation": 0.01705031139333253,
            "ave_precision_score": 0.8338529728234457,
            "fpr": 0.14692982456140352,
            "logloss": 0.7426606203667083,
            "mae": 0.2816010470951788,
            "precision": 0.7377690802348337,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8346766485083771,
            "auditor_fn_violation": 0.015049790788182034,
            "auditor_fp_violation": 0.02034244069189861,
            "ave_precision_score": 0.8354430499983514,
            "fpr": 0.145993413830955,
            "logloss": 0.6861475742296955,
            "mae": 0.2651811922911976,
            "precision": 0.7407407407407407,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8290270615184434,
            "auditor_fn_violation": 0.01728854360433308,
            "auditor_fp_violation": 0.019970895917287422,
            "ave_precision_score": 0.8292446392615449,
            "fpr": 0.15350877192982457,
            "logloss": 0.7384492222048546,
            "mae": 0.2953165297990461,
            "precision": 0.7265625,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.830054015263831,
            "auditor_fn_violation": 0.011450372821725544,
            "auditor_fp_violation": 0.01532261702479588,
            "ave_precision_score": 0.830804120349976,
            "fpr": 0.15477497255762898,
            "logloss": 0.6769294384109765,
            "mae": 0.27997528809606675,
            "precision": 0.72568093385214,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 1318,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.861380080886014,
            "auditor_fn_violation": 0.008056133056133062,
            "auditor_fp_violation": 0.00622277852403631,
            "ave_precision_score": 0.8616150896851151,
            "fpr": 0.09539473684210527,
            "logloss": 0.734361340573355,
            "mae": 0.24559976016112633,
            "precision": 0.8040540540540541,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8568775293465668,
            "auditor_fn_violation": 0.009925667725683042,
            "auditor_fp_violation": 0.008984557087650181,
            "ave_precision_score": 0.8573670417277618,
            "fpr": 0.09110867178924259,
            "logloss": 0.733322437272959,
            "mae": 0.2476675113920675,
            "precision": 0.8060747663551402,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 1318,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8666957599320444,
            "auditor_fn_violation": 0.011753656490498596,
            "auditor_fp_violation": 0.014783551105141046,
            "ave_precision_score": 0.8669330899320402,
            "fpr": 0.1425438596491228,
            "logloss": 0.7794903787464705,
            "mae": 0.25257398261087577,
            "precision": 0.7547169811320755,
            "recall": 0.8316008316008316
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8646010632541778,
            "auditor_fn_violation": 0.02005555774733525,
            "auditor_fp_violation": 0.022254635129242296,
            "ave_precision_score": 0.8651287054769741,
            "fpr": 0.1251372118551043,
            "logloss": 0.7515705057029619,
            "mae": 0.24841693086370398,
            "precision": 0.7729083665338645,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8329674517046125,
            "auditor_fn_violation": 0.019246726483568597,
            "auditor_fp_violation": 0.021405747547523103,
            "ave_precision_score": 0.8331928790704302,
            "fpr": 0.13925438596491227,
            "logloss": 0.7457749675245975,
            "mae": 0.28756754712364613,
            "precision": 0.7449799196787149,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.839156955956621,
            "auditor_fn_violation": 0.013968340902708971,
            "auditor_fp_violation": 0.02038253913357292,
            "ave_precision_score": 0.8397140753769343,
            "fpr": 0.145993413830955,
            "logloss": 0.6782571399246847,
            "mae": 0.2714932689963504,
            "precision": 0.7392156862745098,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8663983632795087,
            "auditor_fn_violation": 0.014607725134040931,
            "auditor_fp_violation": 0.013768469898644522,
            "ave_precision_score": 0.8666360740111498,
            "fpr": 0.08552631578947369,
            "logloss": 0.8119920973357225,
            "mae": 0.23946766324162452,
            "precision": 0.8194444444444444,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8685211764028228,
            "auditor_fn_violation": 0.015534818741108793,
            "auditor_fp_violation": 0.009553453728904463,
            "ave_precision_score": 0.8690315552604702,
            "fpr": 0.08342480790340286,
            "logloss": 0.7705511903881289,
            "mae": 0.2342894324581649,
            "precision": 0.8215962441314554,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.860780769468479,
            "auditor_fn_violation": 0.027145566619250834,
            "auditor_fp_violation": 0.02233433060609761,
            "ave_precision_score": 0.8610551298328315,
            "fpr": 0.11074561403508772,
            "logloss": 0.5023542398480716,
            "mae": 0.30360554415620344,
            "precision": 0.7887029288702929,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8725258835053206,
            "auditor_fn_violation": 0.02422122844352441,
            "auditor_fp_violation": 0.020811091228967123,
            "ave_precision_score": 0.8729396186596345,
            "fpr": 0.10098792535675083,
            "logloss": 0.4661114080495645,
            "mae": 0.2954132949187556,
            "precision": 0.7973568281938326,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.839984207474226,
            "auditor_fn_violation": 0.042327752854068645,
            "auditor_fp_violation": 0.017218219562828183,
            "ave_precision_score": 0.8402528215399605,
            "fpr": 0.08114035087719298,
            "logloss": 1.3740920410085184,
            "mae": 0.3183034872720937,
            "precision": 0.8208232445520581,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8519196911990846,
            "auditor_fn_violation": 0.03794589501581563,
            "auditor_fp_violation": 0.013901628497962502,
            "ave_precision_score": 0.8522776953883491,
            "fpr": 0.07574094401756312,
            "logloss": 1.2759533666834115,
            "mae": 0.31323790171933147,
            "precision": 0.8217054263565892,
            "recall": 0.6723044397463002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8413526355221659,
            "auditor_fn_violation": 0.04041516212568845,
            "auditor_fp_violation": 0.020606911710831604,
            "ave_precision_score": 0.8416164313569836,
            "fpr": 0.08662280701754387,
            "logloss": 1.3420442819842726,
            "mae": 0.3162958740202215,
            "precision": 0.8132387706855791,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8533649389228776,
            "auditor_fn_violation": 0.038721011457334954,
            "auditor_fp_violation": 0.015871464445213,
            "ave_precision_score": 0.8537169059249251,
            "fpr": 0.07574094401756312,
            "logloss": 1.244368245355771,
            "mae": 0.31125226032473435,
            "precision": 0.8253164556962025,
            "recall": 0.6892177589852009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 1318,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8215280941406498,
            "auditor_fn_violation": 0.030453277163803485,
            "auditor_fp_violation": 0.02809408963243376,
            "ave_precision_score": 0.8218098588946705,
            "fpr": 0.14802631578947367,
            "logloss": 0.8428740613244273,
            "mae": 0.2892934424601826,
            "precision": 0.7388781431334622,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8293174910211285,
            "auditor_fn_violation": 0.023478601912727458,
            "auditor_fp_violation": 0.02224962282403301,
            "ave_precision_score": 0.8298057187480835,
            "fpr": 0.14928649835345773,
            "logloss": 0.7310815134054126,
            "mae": 0.27283952107531667,
            "precision": 0.7384615384615385,
            "recall": 0.8118393234672304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7429048141163905,
            "auditor_fn_violation": 0.013210325710325727,
            "auditor_fp_violation": 0.011008161354662762,
            "ave_precision_score": 0.7430353313405906,
            "fpr": 0.10087719298245613,
            "logloss": 3.4127849010163223,
            "mae": 0.3579033709407371,
            "precision": 0.742296918767507,
            "recall": 0.5509355509355509
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7607288429645735,
            "auditor_fn_violation": 0.005699658623866632,
            "auditor_fp_violation": 0.011879163346014465,
            "ave_precision_score": 0.7610245898468063,
            "fpr": 0.09220636663007684,
            "logloss": 3.1436561365284867,
            "mae": 0.3324462577282792,
            "precision": 0.7698630136986301,
            "recall": 0.5940803382663847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.826684399340284,
            "auditor_fn_violation": 0.018391873655031553,
            "auditor_fp_violation": 0.02039575446737494,
            "ave_precision_score": 0.8269296239676407,
            "fpr": 0.14692982456140352,
            "logloss": 0.7466370733464647,
            "mae": 0.29254322066845306,
            "precision": 0.7403100775193798,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8330416597161546,
            "auditor_fn_violation": 0.015750644576621654,
            "auditor_fp_violation": 0.016142128926514593,
            "ave_precision_score": 0.8334737320047538,
            "fpr": 0.15477497255762898,
            "logloss": 0.6945928674013471,
            "mae": 0.2795788845333825,
            "precision": 0.7319391634980988,
            "recall": 0.813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.826438723314949,
            "auditor_fn_violation": 0.01665481270744429,
            "auditor_fp_violation": 0.019085561932673925,
            "ave_precision_score": 0.826677486798356,
            "fpr": 0.13925438596491227,
            "logloss": 0.828095912685063,
            "mae": 0.2889180448273981,
            "precision": 0.7413441955193483,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8317056397517267,
            "auditor_fn_violation": 0.014167921782860651,
            "auditor_fp_violation": 0.02133237097073315,
            "ave_precision_score": 0.832500422869927,
            "fpr": 0.1437980241492865,
            "logloss": 0.7333953616674723,
            "mae": 0.2695395062893029,
            "precision": 0.7348178137651822,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7987942867009685,
            "auditor_fn_violation": 0.01498158077105446,
            "auditor_fp_violation": 0.019347600439614115,
            "ave_precision_score": 0.793532723197107,
            "fpr": 0.13706140350877194,
            "logloss": 1.1222892536152598,
            "mae": 0.28360431837457295,
            "precision": 0.7433264887063655,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.803429248794181,
            "auditor_fn_violation": 0.012260299881875969,
            "auditor_fp_violation": 0.02103413881078047,
            "ave_precision_score": 0.799161779271951,
            "fpr": 0.1394072447859495,
            "logloss": 1.0216091349549845,
            "mae": 0.26576389330878475,
            "precision": 0.741869918699187,
            "recall": 0.7716701902748414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7840840077818522,
            "auditor_fn_violation": 0.00978407557354926,
            "auditor_fp_violation": 0.022652338502869705,
            "ave_precision_score": 0.7841205173477073,
            "fpr": 0.24451754385964913,
            "logloss": 1.3350910624312113,
            "mae": 0.3049114732929548,
            "precision": 0.6595419847328244,
            "recall": 0.8981288981288982
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8093966299968081,
            "auditor_fn_violation": 0.014040282847879918,
            "auditor_fp_violation": 0.029748031417129065,
            "ave_precision_score": 0.8097768347384929,
            "fpr": 0.24588364434687157,
            "logloss": 1.2201493721758059,
            "mae": 0.2952435026924938,
            "precision": 0.6569678407350689,
            "recall": 0.9069767441860465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.844340674306659,
            "auditor_fn_violation": 0.03891518036254879,
            "auditor_fp_violation": 0.020225302234705093,
            "ave_precision_score": 0.8446224906531652,
            "fpr": 0.08881578947368421,
            "logloss": 0.668781038924249,
            "mae": 0.31552208351781447,
            "precision": 0.8107476635514018,
            "recall": 0.7214137214137214
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8564100891606313,
            "auditor_fn_violation": 0.035105348535517285,
            "auditor_fp_violation": 0.017485426722603996,
            "ave_precision_score": 0.8568398965443191,
            "fpr": 0.0845225027442371,
            "logloss": 0.6174530290729879,
            "mae": 0.3105204814451234,
            "precision": 0.8098765432098766,
            "recall": 0.693446088794926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8268965238490458,
            "auditor_fn_violation": 0.018373636794689428,
            "auditor_fp_violation": 0.01976991492652746,
            "ave_precision_score": 0.8271401365642316,
            "fpr": 0.15679824561403508,
            "logloss": 0.7206188587268862,
            "mae": 0.30011865718439656,
            "precision": 0.7296786389413988,
            "recall": 0.8024948024948025
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.833627153427767,
            "auditor_fn_violation": 0.010717029122563547,
            "auditor_fp_violation": 0.01564841686339965,
            "ave_precision_score": 0.8339790227488887,
            "fpr": 0.16245883644346873,
            "logloss": 0.676335142718259,
            "mae": 0.28805488658394285,
            "precision": 0.7269372693726938,
            "recall": 0.8329809725158562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8291234981513749,
            "auditor_fn_violation": 0.018679104205419995,
            "auditor_fp_violation": 0.02007520250742867,
            "ave_precision_score": 0.8293580559837478,
            "fpr": 0.14364035087719298,
            "logloss": 0.7517747945706977,
            "mae": 0.2877455429009895,
            "precision": 0.7400793650793651,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8327956342127404,
            "auditor_fn_violation": 0.016516478186506017,
            "auditor_fp_violation": 0.02123212486654738,
            "ave_precision_score": 0.8335406237070633,
            "fpr": 0.15148188803512624,
            "logloss": 0.690824078311327,
            "mae": 0.2725921703142938,
            "precision": 0.73046875,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5711139271172156,
            "auditor_fn_violation": 0.011949702739176426,
            "auditor_fp_violation": 0.01335124353807954,
            "ave_precision_score": 0.5711964934916439,
            "fpr": 0.0756578947368421,
            "logloss": 8.812240232949978,
            "mae": 0.4940243917367332,
            "precision": 0.603448275862069,
            "recall": 0.2182952182952183
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5567499494604147,
            "auditor_fn_violation": 0.008226909536485005,
            "auditor_fp_violation": 0.01721726839390704,
            "ave_precision_score": 0.5555662429914429,
            "fpr": 0.07683863885839737,
            "logloss": 8.674541768426966,
            "mae": 0.4866204347909286,
            "precision": 0.6045197740112994,
            "recall": 0.226215644820296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.837931242895554,
            "auditor_fn_violation": 0.033617372433161916,
            "auditor_fp_violation": 0.03548459315341719,
            "ave_precision_score": 0.8381996944778047,
            "fpr": 0.15570175438596492,
            "logloss": 0.5783202147796261,
            "mae": 0.3112055132801049,
            "precision": 0.7305502846299811,
            "recall": 0.8004158004158004
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8452518675441762,
            "auditor_fn_violation": 0.031271539070278,
            "auditor_fp_violation": 0.028164142970993792,
            "ave_precision_score": 0.8454894498962249,
            "fpr": 0.1437980241492865,
            "logloss": 0.542717411242489,
            "mae": 0.30885600033775096,
            "precision": 0.7405940594059406,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8363924958295548,
            "auditor_fn_violation": 0.0469348396979976,
            "auditor_fp_violation": 0.04922253429397159,
            "ave_precision_score": 0.8367341902743919,
            "fpr": 0.17763157894736842,
            "logloss": 0.6782581532898215,
            "mae": 0.30956134638827076,
            "precision": 0.7054545454545454,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8388598380798628,
            "auditor_fn_violation": 0.043497028333522855,
            "auditor_fp_violation": 0.04422356886155512,
            "ave_precision_score": 0.8393083118179554,
            "fpr": 0.18111964873765093,
            "logloss": 0.6306791980134024,
            "mae": 0.30452632733016866,
            "precision": 0.7027027027027027,
            "recall": 0.8245243128964059
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8291649953700414,
            "auditor_fn_violation": 0.020400207900207905,
            "auditor_fp_violation": 0.020418651035942533,
            "ave_precision_score": 0.8293952692587735,
            "fpr": 0.14473684210526316,
            "logloss": 0.7252916988694411,
            "mae": 0.28994694099623175,
            "precision": 0.7396449704142012,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8339056375670042,
            "auditor_fn_violation": 0.01659770296331193,
            "auditor_fp_violation": 0.020851189670641423,
            "ave_precision_score": 0.8344757954559507,
            "fpr": 0.14928649835345773,
            "logloss": 0.6738264359916649,
            "mae": 0.2752445649182369,
            "precision": 0.7364341085271318,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8322105476747903,
            "auditor_fn_violation": 0.016716362111098955,
            "auditor_fp_violation": 0.020258375055969384,
            "ave_precision_score": 0.8324467023271951,
            "fpr": 0.15789473684210525,
            "logloss": 0.6929589368917728,
            "mae": 0.30002691660055253,
            "precision": 0.7313432835820896,
            "recall": 0.814968814968815
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8373378668124257,
            "auditor_fn_violation": 0.009730728261348841,
            "auditor_fp_violation": 0.015728613746748266,
            "ave_precision_score": 0.8377185407722821,
            "fpr": 0.16575192096597147,
            "logloss": 0.6533594757459134,
            "mae": 0.289624188198744,
            "precision": 0.7244525547445255,
            "recall": 0.8393234672304439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7358287685410327,
            "auditor_fn_violation": 0.0033077105445526566,
            "auditor_fp_violation": 0.014025420279236374,
            "ave_precision_score": 0.7360126897015467,
            "fpr": 0.12280701754385964,
            "logloss": 3.3833627745887696,
            "mae": 0.3583553665454169,
            "precision": 0.7157360406091371,
            "recall": 0.5862785862785863
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7457122866383026,
            "auditor_fn_violation": 0.008957932527738268,
            "auditor_fp_violation": 0.01940263346515697,
            "ave_precision_score": 0.7460638842660544,
            "fpr": 0.12294182217343579,
            "logloss": 3.1510720952740225,
            "mae": 0.33679892498321773,
            "precision": 0.7227722772277227,
            "recall": 0.6173361522198731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8216819814521106,
            "auditor_fn_violation": 0.02667824707298392,
            "auditor_fp_violation": 0.013954186510359429,
            "ave_precision_score": 0.8213881330200218,
            "fpr": 0.1206140350877193,
            "logloss": 0.622140135009914,
            "mae": 0.30276554084822127,
            "precision": 0.7759674134419552,
            "recall": 0.7920997920997921
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8456093004094887,
            "auditor_fn_violation": 0.017771981165134617,
            "auditor_fp_violation": 0.016510533359397325,
            "ave_precision_score": 0.844533763955169,
            "fpr": 0.11086717892425905,
            "logloss": 0.5787986369735181,
            "mae": 0.29195945396378353,
            "precision": 0.7887029288702929,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8479360083208893,
            "auditor_fn_violation": 0.04487179487179488,
            "auditor_fp_violation": 0.02846043472951521,
            "ave_precision_score": 0.8482718860766725,
            "fpr": 0.11732456140350878,
            "logloss": 0.9663557697303551,
            "mae": 0.29905637674792573,
            "precision": 0.7742616033755274,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8524325112242356,
            "auditor_fn_violation": 0.04020626451892886,
            "auditor_fp_violation": 0.02935205930559524,
            "ave_precision_score": 0.8529549707805124,
            "fpr": 0.1141602634467618,
            "logloss": 0.9506069428216728,
            "mae": 0.2951104221032282,
            "precision": 0.7773019271948608,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8544420365989713,
            "auditor_fn_violation": 0.010832695043221367,
            "auditor_fp_violation": 0.0034039565270484844,
            "ave_precision_score": 0.8547207516000306,
            "fpr": 0.07236842105263158,
            "logloss": 0.5100642962473823,
            "mae": 0.3114631421472918,
            "precision": 0.8267716535433071,
            "recall": 0.6548856548856549
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8732845770908424,
            "auditor_fn_violation": 0.006166120913523464,
            "auditor_fp_violation": 0.012520738412803432,
            "ave_precision_score": 0.8734960004186612,
            "fpr": 0.06147091108671789,
            "logloss": 0.4801965658452431,
            "mae": 0.29930589164164567,
            "precision": 0.8526315789473684,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.834064812831389,
            "auditor_fn_violation": 0.016217128059233327,
            "auditor_fp_violation": 0.017220763626002358,
            "ave_precision_score": 0.8342963403672423,
            "fpr": 0.13596491228070176,
            "logloss": 0.805088596119488,
            "mae": 0.2822330169147906,
            "precision": 0.746938775510204,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8376835480574294,
            "auditor_fn_violation": 0.012462201469936396,
            "auditor_fp_violation": 0.02135242019157031,
            "ave_precision_score": 0.8384674972107109,
            "fpr": 0.1394072447859495,
            "logloss": 0.7211603337231973,
            "mae": 0.26293842295380054,
            "precision": 0.742914979757085,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8451722200074965,
            "auditor_fn_violation": 0.044281376518218625,
            "auditor_fp_violation": 0.030215838319697166,
            "ave_precision_score": 0.8454788219975857,
            "fpr": 0.13048245614035087,
            "logloss": 0.7320266973991125,
            "mae": 0.29877739301696543,
            "precision": 0.7591093117408907,
            "recall": 0.7796257796257796
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8532442417331219,
            "auditor_fn_violation": 0.04247591685367705,
            "auditor_fp_violation": 0.028630287355457654,
            "ave_precision_score": 0.8535628892098195,
            "fpr": 0.12733260153677278,
            "logloss": 0.6787216019399088,
            "mae": 0.29372885266471277,
            "precision": 0.7598343685300207,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8473692857897202,
            "auditor_fn_violation": 0.011539373381478648,
            "auditor_fp_violation": 0.018831155615256247,
            "ave_precision_score": 0.847572494493591,
            "fpr": 0.13925438596491227,
            "logloss": 0.6558156427727663,
            "mae": 0.27919495671583144,
            "precision": 0.7514677103718199,
            "recall": 0.7983367983367984
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8533105399521427,
            "auditor_fn_violation": 0.013849984799363198,
            "auditor_fp_violation": 0.019332461192226928,
            "ave_precision_score": 0.854014470970381,
            "fpr": 0.14270032930845225,
            "logloss": 0.6058515095188344,
            "mae": 0.264222298855878,
            "precision": 0.746588693957115,
            "recall": 0.8097251585623678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8017524476272697,
            "auditor_fn_violation": 0.016764233869497033,
            "auditor_fp_violation": 0.022812614482842834,
            "ave_precision_score": 0.8021433510636892,
            "fpr": 0.1118421052631579,
            "logloss": 1.1135858225442337,
            "mae": 0.294633203221079,
            "precision": 0.7605633802816901,
            "recall": 0.6735966735966736
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8217266155138196,
            "auditor_fn_violation": 0.01131113034720111,
            "auditor_fp_violation": 0.019121944373436787,
            "ave_precision_score": 0.8219047106048889,
            "fpr": 0.10757409440175632,
            "logloss": 0.9510155539325567,
            "mae": 0.2751636327234489,
            "precision": 0.772093023255814,
            "recall": 0.7019027484143763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 1318,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.8468312129246677,
            "auditor_fn_violation": 0.01632882882882883,
            "auditor_fp_violation": 0.04375788659583996,
            "ave_precision_score": 0.8470487311080223,
            "fpr": 0.34649122807017546,
            "logloss": 1.3470164525644424,
            "mae": 0.3627093166121383,
            "precision": 0.5901426718547341,
            "recall": 0.9459459459459459
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.8461628599826017,
            "auditor_fn_violation": 0.010336433025530108,
            "auditor_fp_violation": 0.0418176623610965,
            "ave_precision_score": 0.8468665229216856,
            "fpr": 0.3534577387486279,
            "logloss": 1.2740208408418285,
            "mae": 0.35749602196222596,
            "precision": 0.5855855855855856,
            "recall": 0.9619450317124736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7456322440181479,
            "auditor_fn_violation": 0.008062971878761356,
            "auditor_fp_violation": 0.01474539015752839,
            "ave_precision_score": 0.7458020488921597,
            "fpr": 0.09649122807017543,
            "logloss": 3.393866405451767,
            "mae": 0.3546813496540266,
            "precision": 0.7507082152974505,
            "recall": 0.5509355509355509
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7642271242503239,
            "auditor_fn_violation": 0.009301397298231854,
            "auditor_fp_violation": 0.010292768747274557,
            "ave_precision_score": 0.7644352226855813,
            "fpr": 0.0889132821075741,
            "logloss": 3.1358808078027156,
            "mae": 0.32852112960797664,
            "precision": 0.775623268698061,
            "recall": 0.5919661733615222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7825184858375563,
            "auditor_fn_violation": 0.023705638837217793,
            "auditor_fp_violation": 0.0265472992225343,
            "ave_precision_score": 0.7490088320077646,
            "fpr": 0.15899122807017543,
            "logloss": 3.8482754009872457,
            "mae": 0.2939139428359897,
            "precision": 0.7156862745098039,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7906329144993266,
            "auditor_fn_violation": 0.015031225124912107,
            "auditor_fp_violation": 0.02508408141988582,
            "ave_precision_score": 0.7558735511362039,
            "fpr": 0.15916575192096596,
            "logloss": 3.6070474962038785,
            "mae": 0.2738573614925758,
            "precision": 0.7189922480620154,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8042789429663302,
            "auditor_fn_violation": 0.00609567056935478,
            "auditor_fp_violation": 0.025555114584605364,
            "ave_precision_score": 0.8036586921928137,
            "fpr": 0.29714912280701755,
            "logloss": 1.8919929943719134,
            "mae": 0.32917649305944985,
            "precision": 0.6262068965517241,
            "recall": 0.9438669438669439
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.8169783012054821,
            "auditor_fn_violation": 0.009700559058535218,
            "auditor_fp_violation": 0.01890390909683274,
            "ave_precision_score": 0.8156928819563526,
            "fpr": 0.3172338090010977,
            "logloss": 1.8496186136021981,
            "mae": 0.34014571878113836,
            "precision": 0.6084010840108401,
            "recall": 0.9492600422832981
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8352265263908509,
            "auditor_fn_violation": 0.015008936061567647,
            "auditor_fp_violation": 0.017220763626002358,
            "ave_precision_score": 0.8354636111364916,
            "fpr": 0.13596491228070176,
            "logloss": 0.7081844003322701,
            "mae": 0.289848853385417,
            "precision": 0.75,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.845588200662877,
            "auditor_fn_violation": 0.016179975539738645,
            "auditor_fp_violation": 0.019465287280273073,
            "ave_precision_score": 0.8458126428831823,
            "fpr": 0.1437980241492865,
            "logloss": 0.6617601705322445,
            "mae": 0.27375705237091447,
            "precision": 0.7421259842519685,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8358953516250909,
            "auditor_fn_violation": 0.030564977933398987,
            "auditor_fp_violation": 0.030480420889811545,
            "ave_precision_score": 0.8361265234458097,
            "fpr": 0.13925438596491227,
            "logloss": 0.8679047335907027,
            "mae": 0.28246248039830746,
            "precision": 0.7381443298969073,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8392337694060491,
            "auditor_fn_violation": 0.02158954567501271,
            "auditor_fp_violation": 0.025502608904861435,
            "ave_precision_score": 0.8398511497569394,
            "fpr": 0.1251372118551043,
            "logloss": 0.7497521189908977,
            "mae": 0.2657734277301888,
            "precision": 0.7548387096774194,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8725499323392423,
            "auditor_fn_violation": 0.015391910128752235,
            "auditor_fp_violation": 0.008919485488663653,
            "ave_precision_score": 0.8727321728866078,
            "fpr": 0.10197368421052631,
            "logloss": 0.47435503488591946,
            "mae": 0.30179680421695176,
            "precision": 0.7995689655172413,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8747830263697862,
            "auditor_fn_violation": 0.01621246545046101,
            "auditor_fp_violation": 0.012405455392989793,
            "ave_precision_score": 0.8751895902761768,
            "fpr": 0.08562019758507135,
            "logloss": 0.4594668954125721,
            "mae": 0.2966941836894246,
            "precision": 0.821917808219178,
            "recall": 0.7610993657505285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7749753227223687,
            "auditor_fn_violation": 0.017735346682715102,
            "auditor_fp_violation": 0.023153518948182527,
            "ave_precision_score": 0.7754125230152612,
            "fpr": 0.13157894736842105,
            "logloss": 1.024446843956524,
            "mae": 0.31836869059364054,
            "precision": 0.732739420935412,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7884227653661793,
            "auditor_fn_violation": 0.01770003921996366,
            "auditor_fp_violation": 0.025231944423559846,
            "ave_precision_score": 0.7890882546141416,
            "fpr": 0.14270032930845225,
            "logloss": 0.9326275550237753,
            "mae": 0.30249002216206405,
            "precision": 0.7228144989339019,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8194562822244705,
            "auditor_fn_violation": 0.01398083305978043,
            "auditor_fp_violation": 0.014933650832417473,
            "ave_precision_score": 0.8197462675484575,
            "fpr": 0.12828947368421054,
            "logloss": 0.8266130948492635,
            "mae": 0.2958843652040432,
            "precision": 0.7445414847161572,
            "recall": 0.7089397089397089
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8272300208469265,
            "auditor_fn_violation": 0.01388711612590305,
            "auditor_fp_violation": 0.0193424858026455,
            "ave_precision_score": 0.8276068072818161,
            "fpr": 0.13611416026344675,
            "logloss": 0.7383332131721391,
            "mae": 0.2735307499049639,
            "precision": 0.7405857740585774,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8408794475790052,
            "auditor_fn_violation": 0.04400326439800124,
            "auditor_fp_violation": 0.02183315016078479,
            "ave_precision_score": 0.8411454666536374,
            "fpr": 0.09210526315789473,
            "logloss": 1.3338075747160445,
            "mae": 0.31649109182319374,
            "precision": 0.8037383177570093,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8530594227419048,
            "auditor_fn_violation": 0.04250376534858194,
            "auditor_fp_violation": 0.016660902515675986,
            "ave_precision_score": 0.8535004687445782,
            "fpr": 0.07025246981339188,
            "logloss": 1.2334231397643483,
            "mae": 0.3097614968763712,
            "precision": 0.8358974358974359,
            "recall": 0.6892177589852009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7820749597089705,
            "auditor_fn_violation": 0.016415453915453924,
            "auditor_fp_violation": 0.01885405218382383,
            "ave_precision_score": 0.7484662663609382,
            "fpr": 0.13706140350877194,
            "logloss": 3.8279433701942533,
            "mae": 0.2959213023344224,
            "precision": 0.7412008281573499,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7912743589005351,
            "auditor_fn_violation": 0.012376335277312989,
            "auditor_fp_violation": 0.022094241362545043,
            "ave_precision_score": 0.7549212029429221,
            "fpr": 0.14270032930845225,
            "logloss": 3.642778532142312,
            "mae": 0.2726065036929593,
            "precision": 0.7389558232931727,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8705996936863956,
            "auditor_fn_violation": 0.017495987890724735,
            "auditor_fp_violation": 0.009830260105018928,
            "ave_precision_score": 0.8707846959355676,
            "fpr": 0.10307017543859649,
            "logloss": 0.4778149719087972,
            "mae": 0.3010057851487338,
            "precision": 0.8008474576271186,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8749798906957336,
            "auditor_fn_violation": 0.014116866208868355,
            "auditor_fp_violation": 0.016315053456235056,
            "ave_precision_score": 0.875389309378664,
            "fpr": 0.09879253567508232,
            "logloss": 0.4588346600487176,
            "mae": 0.2932991577101755,
            "precision": 0.8013245033112583,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7839293928900402,
            "auditor_fn_violation": 0.023386493781230627,
            "auditor_fp_violation": 0.0263285097895551,
            "ave_precision_score": 0.75037923938296,
            "fpr": 0.16557017543859648,
            "logloss": 3.757210509303697,
            "mae": 0.29131917364454873,
            "precision": 0.7112810707456979,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7909742624272341,
            "auditor_fn_violation": 0.015836510769245058,
            "auditor_fp_violation": 0.02526201825481557,
            "ave_precision_score": 0.7548592159224868,
            "fpr": 0.16245883644346873,
            "logloss": 3.590881871676515,
            "mae": 0.27174265627232447,
            "precision": 0.7170172084130019,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8733842272120536,
            "auditor_fn_violation": 0.007860086807455235,
            "auditor_fp_violation": 0.008970366752147187,
            "ave_precision_score": 0.873556327042925,
            "fpr": 0.09868421052631579,
            "logloss": 0.9122270724505375,
            "mae": 0.23245911797480193,
            "precision": 0.803921568627451,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8757628234631554,
            "auditor_fn_violation": 0.011631388038607299,
            "auditor_fp_violation": 0.012272629304943638,
            "ave_precision_score": 0.8777328117510135,
            "fpr": 0.0845225027442371,
            "logloss": 0.7779685142256377,
            "mae": 0.21819153744380387,
            "precision": 0.8246013667425968,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7536164052359524,
            "auditor_fn_violation": 0.013695882116934753,
            "auditor_fp_violation": 0.010395042129686166,
            "ave_precision_score": 0.7536991456818916,
            "fpr": 0.125,
            "logloss": 3.3166682041631135,
            "mae": 0.34856352143293645,
            "precision": 0.7266187050359713,
            "recall": 0.6299376299376299
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7650357190274459,
            "auditor_fn_violation": 0.010747198325377173,
            "auditor_fp_violation": 0.020237182282503548,
            "ave_precision_score": 0.7654901207833906,
            "fpr": 0.12403951701427003,
            "logloss": 3.078015896628505,
            "mae": 0.32524895749687005,
            "precision": 0.7315914489311164,
            "recall": 0.6511627906976745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8488194040355951,
            "auditor_fn_violation": 0.0076458036984352815,
            "auditor_fp_violation": 0.018047584157609802,
            "ave_precision_score": 0.8490304379577451,
            "fpr": 0.15789473684210525,
            "logloss": 0.5760954577454793,
            "mae": 0.29473192738307835,
            "precision": 0.7236084452975048,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8466143900384465,
            "auditor_fn_violation": 0.017669870017150036,
            "auditor_fp_violation": 0.02028730533459644,
            "ave_precision_score": 0.8469819558871929,
            "fpr": 0.15697036223929747,
            "logloss": 0.5479157983650984,
            "mae": 0.2821707560831086,
            "precision": 0.7276190476190476,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 1318,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8508735051459666,
            "auditor_fn_violation": 0.018061330561330566,
            "auditor_fp_violation": 0.022296169658484962,
            "ave_precision_score": 0.8510758038282191,
            "fpr": 0.14473684210526316,
            "logloss": 0.5805860152482919,
            "mae": 0.29398946431185896,
            "precision": 0.736,
            "recall": 0.7650727650727651
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8616743363997873,
            "auditor_fn_violation": 0.015332917153048364,
            "auditor_fp_violation": 0.016808765519350004,
            "ave_precision_score": 0.8621862648740214,
            "fpr": 0.1437980241492865,
            "logloss": 0.5205154717058836,
            "mae": 0.2788636247116858,
            "precision": 0.738,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8337668316866846,
            "auditor_fn_violation": 0.024519458729985046,
            "auditor_fp_violation": 0.03624781210567021,
            "ave_precision_score": 0.8339888983510604,
            "fpr": 0.15679824561403508,
            "logloss": 0.8892342258148245,
            "mae": 0.28091662651562527,
            "precision": 0.7276190476190476,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8390410344101563,
            "auditor_fn_violation": 0.023123533602690167,
            "auditor_fp_violation": 0.02968788375461759,
            "ave_precision_score": 0.8395866635922412,
            "fpr": 0.14709110867178923,
            "logloss": 0.7723281668881822,
            "mae": 0.26443922050341306,
            "precision": 0.7346534653465346,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7842146286089202,
            "auditor_fn_violation": 0.011119925593609806,
            "auditor_fp_violation": 0.02257856067081859,
            "ave_precision_score": 0.785372402617305,
            "fpr": 0.2532894736842105,
            "logloss": 1.4562783406500863,
            "mae": 0.3162805755900773,
            "precision": 0.6494688922610015,
            "recall": 0.8898128898128899
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8277568715954244,
            "auditor_fn_violation": 0.013244280035181933,
            "auditor_fp_violation": 0.03025928654847652,
            "ave_precision_score": 0.828013562662611,
            "fpr": 0.2513721185510428,
            "logloss": 1.3485960620545172,
            "mae": 0.3144308429357594,
            "precision": 0.6498470948012233,
            "recall": 0.8985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8765702735899631,
            "auditor_fn_violation": 0.01140487653645549,
            "auditor_fp_violation": 0.008326718769080477,
            "ave_precision_score": 0.8767594721493104,
            "fpr": 0.09978070175438597,
            "logloss": 0.46766273566071115,
            "mae": 0.2922874017590003,
            "precision": 0.8080168776371308,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8752611764360356,
            "auditor_fn_violation": 0.01067061496438874,
            "auditor_fp_violation": 0.011548351202201405,
            "ave_precision_score": 0.8764628013101388,
            "fpr": 0.09879253567508232,
            "logloss": 0.4517574697751946,
            "mae": 0.2873242185865125,
            "precision": 0.8034934497816594,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8268593066667149,
            "auditor_fn_violation": 0.015145712514133575,
            "auditor_fp_violation": 0.021677962307160018,
            "ave_precision_score": 0.827108855143376,
            "fpr": 0.16666666666666666,
            "logloss": 0.7109987460301128,
            "mae": 0.2996434874777119,
            "precision": 0.7211009174311926,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8369883316505351,
            "auditor_fn_violation": 0.011573370340888785,
            "auditor_fp_violation": 0.015523109233167435,
            "ave_precision_score": 0.8372957107848273,
            "fpr": 0.1668496158068057,
            "logloss": 0.6643512792405976,
            "mae": 0.288529929460377,
            "precision": 0.7231329690346083,
            "recall": 0.8393234672304439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8344922655642666,
            "auditor_fn_violation": 0.048254732465258784,
            "auditor_fp_violation": 0.03369102861562258,
            "ave_precision_score": 0.8346091312171688,
            "fpr": 0.13267543859649122,
            "logloss": 1.8640176590776805,
            "mae": 0.32131395756506936,
            "precision": 0.7545638945233266,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8415528553800871,
            "auditor_fn_violation": 0.04599178933541888,
            "auditor_fp_violation": 0.03232435629470349,
            "ave_precision_score": 0.8418931912541687,
            "fpr": 0.13611416026344675,
            "logloss": 1.6320422249224664,
            "mae": 0.3144367108300216,
            "precision": 0.7459016393442623,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.8180277830483211,
            "auditor_fn_violation": 0.03154976839187366,
            "auditor_fp_violation": 0.04630449383319086,
            "ave_precision_score": 0.8183882344973862,
            "fpr": 0.3848684210526316,
            "logloss": 1.8933313781002237,
            "mae": 0.4175396710746477,
            "precision": 0.5568181818181818,
            "recall": 0.9168399168399168
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.8326302888007115,
            "auditor_fn_violation": 0.025667029470669733,
            "auditor_fp_violation": 0.048088056177916796,
            "ave_precision_score": 0.8328592263149693,
            "fpr": 0.3885839736553238,
            "logloss": 1.8712660523389102,
            "mae": 0.4164529749777947,
            "precision": 0.553030303030303,
            "recall": 0.9260042283298098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8047870144430573,
            "auditor_fn_violation": 0.015070485465222312,
            "auditor_fp_violation": 0.01897871127935849,
            "ave_precision_score": 0.8050602219707352,
            "fpr": 0.08771929824561403,
            "logloss": 1.6259571255616982,
            "mae": 0.31164241159694006,
            "precision": 0.782608695652174,
            "recall": 0.5987525987525988
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8100241735229623,
            "auditor_fn_violation": 0.007953066003253635,
            "auditor_fp_violation": 0.017014270032930844,
            "ave_precision_score": 0.8108241425073655,
            "fpr": 0.0801317233809001,
            "logloss": 1.4880471192901001,
            "mae": 0.2904302168382095,
            "precision": 0.803763440860215,
            "recall": 0.6321353065539113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7762338649700508,
            "auditor_fn_violation": 0.015542364226574755,
            "auditor_fp_violation": 0.016989253877152277,
            "ave_precision_score": 0.7443922441778158,
            "fpr": 0.12938596491228072,
            "logloss": 3.6734622981610614,
            "mae": 0.3118226618382157,
            "precision": 0.7445887445887446,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.783352359338459,
            "auditor_fn_violation": 0.015732078913351738,
            "auditor_fp_violation": 0.019299881208366544,
            "ave_precision_score": 0.7509075525459111,
            "fpr": 0.1350164654226125,
            "logloss": 3.491462356872523,
            "mae": 0.29202857872857957,
            "precision": 0.7388535031847133,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.808174546520067,
            "auditor_fn_violation": 0.015248294853558015,
            "auditor_fp_violation": 0.014328163796963406,
            "ave_precision_score": 0.8084914865132183,
            "fpr": 0.10964912280701754,
            "logloss": 1.0656037379368373,
            "mae": 0.29177850269376765,
            "precision": 0.7742663656884876,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8170531055122139,
            "auditor_fn_violation": 0.01389407824962927,
            "auditor_fp_violation": 0.0149567187445178,
            "ave_precision_score": 0.8175350918299793,
            "fpr": 0.1141602634467618,
            "logloss": 0.9368408476548171,
            "mae": 0.2726491065094863,
            "precision": 0.7694013303769401,
            "recall": 0.733615221987315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.78633592220781,
            "auditor_fn_violation": 0.019107670423459903,
            "auditor_fp_violation": 0.021606728538283066,
            "ave_precision_score": 0.7574090222213417,
            "fpr": 0.14802631578947367,
            "logloss": 3.3857460753601303,
            "mae": 0.2940282267568824,
            "precision": 0.7283702213279678,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7924279310689004,
            "auditor_fn_violation": 0.014894303358296413,
            "auditor_fp_violation": 0.024171841871795257,
            "ave_precision_score": 0.7661766673708076,
            "fpr": 0.14818880351262348,
            "logloss": 3.1160739369989887,
            "mae": 0.2729712478775746,
            "precision": 0.7326732673267327,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7782993033881467,
            "auditor_fn_violation": 0.019830306014516547,
            "auditor_fp_violation": 0.023583465624618397,
            "ave_precision_score": 0.7517868802773346,
            "fpr": 0.1600877192982456,
            "logloss": 1.9789744028705076,
            "mae": 0.3086075008215088,
            "precision": 0.7120315581854043,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7860393187287636,
            "auditor_fn_violation": 0.014850209908030354,
            "auditor_fp_violation": 0.023622994451378138,
            "ave_precision_score": 0.7606939473563994,
            "fpr": 0.15477497255762898,
            "logloss": 1.886136320162511,
            "mae": 0.29202517304227904,
            "precision": 0.7235294117647059,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.840550676319439,
            "auditor_fn_violation": 0.042327752854068645,
            "auditor_fp_violation": 0.017905116619855905,
            "ave_precision_score": 0.840815536466168,
            "fpr": 0.08333333333333333,
            "logloss": 1.3680533070327676,
            "mae": 0.3179638187849131,
            "precision": 0.8168674698795181,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8521299222942398,
            "auditor_fn_violation": 0.03872565287315244,
            "auditor_fp_violation": 0.013901628497962502,
            "ave_precision_score": 0.852486277701906,
            "fpr": 0.07574094401756312,
            "logloss": 1.2700923694004531,
            "mae": 0.312989519955762,
            "precision": 0.8221649484536082,
            "recall": 0.6744186046511628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8496171180949478,
            "auditor_fn_violation": 0.04312789510157932,
            "auditor_fp_violation": 0.03449495257866243,
            "ave_precision_score": 0.8498752275014229,
            "fpr": 0.14583333333333334,
            "logloss": 0.7374746339524312,
            "mae": 0.30500823192637877,
            "precision": 0.7417475728155339,
            "recall": 0.7941787941787942
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8546013044351557,
            "auditor_fn_violation": 0.03750263980524619,
            "auditor_fp_violation": 0.03414883539088463,
            "ave_precision_score": 0.8552860649471876,
            "fpr": 0.13611416026344675,
            "logloss": 0.6862458717837951,
            "mae": 0.30038150271802017,
            "precision": 0.753968253968254,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8183005782198396,
            "auditor_fn_violation": 0.017707991392201927,
            "auditor_fp_violation": 0.02023293442422762,
            "ave_precision_score": 0.8185589772660378,
            "fpr": 0.14144736842105263,
            "logloss": 0.9602794399710273,
            "mae": 0.28986924633843464,
            "precision": 0.735655737704918,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.82396853746686,
            "auditor_fn_violation": 0.015077639283086915,
            "auditor_fp_violation": 0.022307264333939827,
            "ave_precision_score": 0.824601793092364,
            "fpr": 0.14818880351262348,
            "logloss": 0.8568118258787275,
            "mae": 0.27050442139576525,
            "precision": 0.7267206477732794,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8189384742734176,
            "auditor_fn_violation": 0.00842998869314659,
            "auditor_fp_violation": 0.024741014368868827,
            "ave_precision_score": 0.8190951124772814,
            "fpr": 0.27850877192982454,
            "logloss": 1.521875468281828,
            "mae": 0.31875204523789863,
            "precision": 0.6392045454545454,
            "recall": 0.9355509355509356
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8258215845928927,
            "auditor_fn_violation": 0.012049115462180583,
            "auditor_fp_violation": 0.02149276473743039,
            "ave_precision_score": 0.8259794949548873,
            "fpr": 0.287596048298573,
            "logloss": 1.469955701511082,
            "mae": 0.3228419220173309,
            "precision": 0.6294200848656294,
            "recall": 0.9408033826638478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8414213807845983,
            "auditor_fn_violation": 0.04372743188532663,
            "auditor_fp_violation": 0.022316522163878375,
            "ave_precision_score": 0.8416898830117755,
            "fpr": 0.09100877192982457,
            "logloss": 1.34370379583362,
            "mae": 0.3151523499621695,
            "precision": 0.8083140877598153,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8524754811149027,
            "auditor_fn_violation": 0.042236883939076784,
            "auditor_fp_violation": 0.018608183089484684,
            "ave_precision_score": 0.8529151891645184,
            "fpr": 0.09110867178924259,
            "logloss": 1.245983835117509,
            "mae": 0.3107737388500107,
            "precision": 0.8028503562945368,
            "recall": 0.7145877378435518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7251839225273206,
            "auditor_fn_violation": 0.012856986541197081,
            "auditor_fp_violation": 0.01198508161354663,
            "ave_precision_score": 0.7255311226926913,
            "fpr": 0.08223684210526316,
            "logloss": 1.5214836381806587,
            "mae": 0.3641665863237798,
            "precision": 0.7564935064935064,
            "recall": 0.48440748440748443
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.774369372345548,
            "auditor_fn_violation": 0.017361215865287546,
            "auditor_fp_violation": 0.012149827827316068,
            "ave_precision_score": 0.774414676937832,
            "fpr": 0.07244785949506037,
            "logloss": 1.1877905895730738,
            "mae": 0.33598946034475424,
            "precision": 0.7924528301886793,
            "recall": 0.53276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7838703191496101,
            "auditor_fn_violation": 0.014140405587774017,
            "auditor_fp_violation": 0.014577481988032735,
            "ave_precision_score": 0.760191853510742,
            "fpr": 0.1425438596491228,
            "logloss": 2.8233627345071057,
            "mae": 0.2878035488889663,
            "precision": 0.7373737373737373,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7930599277987993,
            "auditor_fn_violation": 0.01262233031563949,
            "auditor_fp_violation": 0.019678310251667844,
            "ave_precision_score": 0.7720363112303644,
            "fpr": 0.14709110867178923,
            "logloss": 2.560737517549381,
            "mae": 0.2693725388825118,
            "precision": 0.7330677290836654,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8772324395040225,
            "auditor_fn_violation": 0.013807582886530261,
            "auditor_fp_violation": 0.013129910041926162,
            "ave_precision_score": 0.8773757045200341,
            "fpr": 0.10526315789473684,
            "logloss": 0.9257549467434557,
            "mae": 0.22818656391988507,
            "precision": 0.7974683544303798,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8824565752269526,
            "auditor_fn_violation": 0.01451138655335424,
            "auditor_fp_violation": 0.013651013237498063,
            "ave_precision_score": 0.8820677108358217,
            "fpr": 0.09110867178924259,
            "logloss": 0.8054914647121474,
            "mae": 0.21667616571235548,
            "precision": 0.814317673378076,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.794533104117754,
            "auditor_fn_violation": 0.015654064996170263,
            "auditor_fp_violation": 0.03706700044775513,
            "ave_precision_score": 0.7950459327377938,
            "fpr": 0.26206140350877194,
            "logloss": 1.5193749695347285,
            "mae": 0.3191523639733471,
            "precision": 0.6459259259259259,
            "recall": 0.9064449064449065
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7970796678696328,
            "auditor_fn_violation": 0.015720475373808027,
            "auditor_fp_violation": 0.032239147106145595,
            "ave_precision_score": 0.7978311726526696,
            "fpr": 0.265642151481888,
            "logloss": 1.4207237764242249,
            "mae": 0.31087410375790325,
            "precision": 0.6435935198821797,
            "recall": 0.9238900634249472
        }
    }
]