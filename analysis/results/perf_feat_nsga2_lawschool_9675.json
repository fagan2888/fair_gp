[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 9675,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5313893005101243,
            "auditor_fn_violation": 0.007673149470754148,
            "auditor_fp_violation": 0.005029172237753738,
            "ave_precision_score": 0.5335976227257764,
            "fpr": 0.02850877192982456,
            "logloss": 0.6977865148107394,
            "mae": 0.5014557280953515,
            "precision": 0.5737704918032787,
            "recall": 0.07306889352818371
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5345119595463015,
            "auditor_fn_violation": 0.00639436131492289,
            "auditor_fp_violation": 0.0013494597125852227,
            "ave_precision_score": 0.536489632440224,
            "fpr": 0.03402854006586169,
            "logloss": 0.6982371680084942,
            "mae": 0.5015231341483434,
            "precision": 0.6025641025641025,
            "recall": 0.09894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7792608280022973,
            "auditor_fn_violation": 0.014886184668351465,
            "auditor_fp_violation": 0.013821360560755242,
            "ave_precision_score": 0.7708209230439034,
            "fpr": 0.11842105263157894,
            "logloss": 1.2243758716920488,
            "mae": 0.28875394980980157,
            "precision": 0.755656108597285,
            "recall": 0.697286012526096
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7894179233326826,
            "auditor_fn_violation": 0.013354902074065521,
            "auditor_fp_violation": 0.014491586017986084,
            "ave_precision_score": 0.7816039596376312,
            "fpr": 0.11525795828759605,
            "logloss": 1.2074096151699198,
            "mae": 0.29787126113920215,
            "precision": 0.7563805104408353,
            "recall": 0.6863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.515364361468903,
            "auditor_fn_violation": 0.0038960920045416256,
            "auditor_fp_violation": 0.0017321016166281756,
            "ave_precision_score": 0.5167712015794267,
            "fpr": 0.003289473684210526,
            "logloss": 0.6907323777788347,
            "mae": 0.4970343860617855,
            "precision": 0.7692307692307693,
            "recall": 0.020876826722338204
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5210054642135021,
            "auditor_fn_violation": 0.00882777745681439,
            "auditor_fp_violation": 0.00215510730218834,
            "ave_precision_score": 0.5222946898476263,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6858243637999653,
            "mae": 0.4936460800280817,
            "precision": 0.8181818181818182,
            "recall": 0.037894736842105266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7781842463382491,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.003952939508123658,
            "ave_precision_score": 0.7283027159721329,
            "fpr": 0.46710526315789475,
            "logloss": 4.82718877599337,
            "mae": 0.4667564178861826,
            "precision": 0.5287610619469026,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7807926731054884,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7313586236376697,
            "fpr": 0.47200878155872666,
            "logloss": 4.751873930490434,
            "mae": 0.46961048840240116,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7944334732344197,
            "auditor_fn_violation": 0.03994295498663151,
            "auditor_fp_violation": 0.0809960090758073,
            "ave_precision_score": 0.7262172775302064,
            "fpr": 0.2894736842105263,
            "logloss": 0.6183748237586882,
            "mae": 0.41784972475286114,
            "precision": 0.6088888888888889,
            "recall": 0.8580375782881002
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7992921664106085,
            "auditor_fn_violation": 0.04103067768213069,
            "auditor_fp_violation": 0.07448211965880824,
            "ave_precision_score": 0.7342419276318765,
            "fpr": 0.2722283205268935,
            "logloss": 0.6171705720497239,
            "mae": 0.4170894957138338,
            "precision": 0.6213740458015267,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7439518361852128,
            "auditor_fn_violation": 0.004685840383840611,
            "auditor_fp_violation": 0.011281451318828248,
            "ave_precision_score": 0.7448158579705295,
            "fpr": 0.0756578947368421,
            "logloss": 0.5907171916635172,
            "mae": 0.3807289011943922,
            "precision": 0.8056338028169014,
            "recall": 0.5970772442588727
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7333014153851853,
            "auditor_fn_violation": 0.0065075972037668284,
            "auditor_fp_violation": 0.007389298985891099,
            "ave_precision_score": 0.7347007872169365,
            "fpr": 0.07354555433589462,
            "logloss": 0.5926952310389856,
            "mae": 0.38306588884013676,
            "precision": 0.8057971014492754,
            "recall": 0.5852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.790436562783731,
            "auditor_fn_violation": 0.005851005384023739,
            "auditor_fp_violation": 0.0086225233985657,
            "ave_precision_score": 0.692595955331687,
            "fpr": 0.08114035087719298,
            "logloss": 0.6154732768792837,
            "mae": 0.40820740450892534,
            "precision": 0.7950138504155124,
            "recall": 0.5991649269311065
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7981347677035007,
            "auditor_fn_violation": 0.00240337396730025,
            "auditor_fp_violation": 0.006211039386096539,
            "ave_precision_score": 0.6966698695757566,
            "fpr": 0.07574094401756312,
            "logloss": 0.6104798652721088,
            "mae": 0.40729298248772566,
            "precision": 0.8028571428571428,
            "recall": 0.5915789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.777823037988157,
            "auditor_fn_violation": 0.014689319854960994,
            "auditor_fp_violation": 0.010058344475507481,
            "ave_precision_score": 0.7183575535789476,
            "fpr": 0.14035087719298245,
            "logloss": 3.3651439532176095,
            "mae": 0.34347927779890597,
            "precision": 0.7241379310344828,
            "recall": 0.7014613778705637
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.775633710192442,
            "auditor_fn_violation": 0.0036420359350626827,
            "auditor_fp_violation": 0.01932547155560479,
            "ave_precision_score": 0.7176574822989221,
            "fpr": 0.13611416026344675,
            "logloss": 3.256065749024647,
            "mae": 0.3461604385051987,
            "precision": 0.7292576419213974,
            "recall": 0.7031578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5426062048041146,
            "auditor_fn_violation": 0.006489671464674219,
            "auditor_fp_violation": 0.004864571937927962,
            "ave_precision_score": 0.5444703201168076,
            "fpr": 0.019736842105263157,
            "logloss": 0.6976760532498979,
            "mae": 0.48877383258781937,
            "precision": 0.71875,
            "recall": 0.09603340292275574
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5415155980192674,
            "auditor_fn_violation": 0.0075544514414466616,
            "auditor_fp_violation": 0.0016515775586863923,
            "ave_precision_score": 0.5430168384336168,
            "fpr": 0.019758507135016465,
            "logloss": 0.69271113908212,
            "mae": 0.48604664208140513,
            "precision": 0.7391304347826086,
            "recall": 0.10736842105263159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7818545944670494,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.01241339491916859,
            "ave_precision_score": 0.7186337045019648,
            "fpr": 0.14692982456140352,
            "logloss": 3.4228417438205567,
            "mae": 0.36736575004301575,
            "precision": 0.7196652719665272,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7812711867028901,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.019567165832485727,
            "ave_precision_score": 0.718594521935614,
            "fpr": 0.14489571899012074,
            "logloss": 3.338889820196853,
            "mae": 0.3656767275343873,
            "precision": 0.7191489361702128,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6177594424807188,
            "auditor_fn_violation": 0.010795516976156477,
            "auditor_fp_violation": 0.0006102872655078806,
            "ave_precision_score": 0.6184915096888702,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6847423520115453,
            "mae": 0.49186634831130505,
            "precision": 0.9473684210526315,
            "recall": 0.037578288100208766
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6305337612020611,
            "auditor_fn_violation": 0.015621930787451626,
            "auditor_fp_violation": 0.0005564003665696533,
            "ave_precision_score": 0.6311937093242083,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6783621417388921,
            "mae": 0.48747673339561104,
            "precision": 0.9629629629629629,
            "recall": 0.05473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7890489205015723,
            "auditor_fn_violation": 0.015801834963190858,
            "auditor_fp_violation": 0.01542431424982781,
            "ave_precision_score": 0.7637293872895198,
            "fpr": 0.12828947368421054,
            "logloss": 1.9193754068763789,
            "mae": 0.2721909305689667,
            "precision": 0.7597535934291582,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7937142006130803,
            "auditor_fn_violation": 0.0069512970131145645,
            "auditor_fp_violation": 0.015679916212650687,
            "ave_precision_score": 0.7672274024081229,
            "fpr": 0.12733260153677278,
            "logloss": 1.9979114571675056,
            "mae": 0.28235870235845706,
            "precision": 0.7552742616033755,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7115958330081874,
            "auditor_fn_violation": 0.09303235908141963,
            "auditor_fp_violation": 0.09671153924071148,
            "ave_precision_score": 0.5606874178248906,
            "fpr": 0.25877192982456143,
            "logloss": 0.6852393611696423,
            "mae": 0.4940643404005912,
            "precision": 0.5778175313059034,
            "recall": 0.6743215031315241
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.714461128927631,
            "auditor_fn_violation": 0.10030619908718008,
            "auditor_fp_violation": 0.0867430689130807,
            "ave_precision_score": 0.5685340249154981,
            "fpr": 0.2349066959385291,
            "logloss": 0.6831369712711451,
            "mae": 0.49312241076114544,
            "precision": 0.5931558935361216,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6518034135196059,
            "auditor_fn_violation": 0.09303235908141963,
            "auditor_fp_violation": 0.09671153924071148,
            "ave_precision_score": 0.5560458011195607,
            "fpr": 0.25877192982456143,
            "logloss": 0.6877668351569295,
            "mae": 0.49580118066647594,
            "precision": 0.5778175313059034,
            "recall": 0.6743215031315241
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6607206458318033,
            "auditor_fn_violation": 0.10030619908718008,
            "auditor_fp_violation": 0.0867430689130807,
            "ave_precision_score": 0.5639910005934422,
            "fpr": 0.2349066959385291,
            "logloss": 0.6857360181881422,
            "mae": 0.4948202225039217,
            "precision": 0.5931558935361216,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6914786205551443,
            "auditor_fn_violation": 0.0021792477017177738,
            "auditor_fp_violation": 0.011671427413800093,
            "ave_precision_score": 0.7166543041782515,
            "fpr": 0.1074561403508772,
            "logloss": 0.6306749219337687,
            "mae": 0.3913170286176497,
            "precision": 0.7480719794344473,
            "recall": 0.6075156576200418
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6678614469819046,
            "auditor_fn_violation": 0.005340574267721992,
            "auditor_fp_violation": 0.012973443841327708,
            "ave_precision_score": 0.7048857475113431,
            "fpr": 0.10867178924259056,
            "logloss": 0.6303760379444459,
            "mae": 0.39298704338518636,
            "precision": 0.7435233160621761,
            "recall": 0.6042105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.781888013348357,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.01241339491916859,
            "ave_precision_score": 0.7189530785294098,
            "fpr": 0.14692982456140352,
            "logloss": 3.420084142502678,
            "mae": 0.36682100647962407,
            "precision": 0.7196652719665272,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7813521236574532,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.019567165832485727,
            "ave_precision_score": 0.719115256633075,
            "fpr": 0.14489571899012074,
            "logloss": 3.33493817985743,
            "mae": 0.36522193964566674,
            "precision": 0.7191489361702128,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8094003502728744,
            "auditor_fn_violation": 0.007203878694648941,
            "auditor_fp_violation": 0.014312629147927561,
            "ave_precision_score": 0.8098894369647137,
            "fpr": 0.1787280701754386,
            "logloss": 0.7532166180067393,
            "mae": 0.3018255762259574,
            "precision": 0.7199312714776632,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8152687980728217,
            "auditor_fn_violation": 0.010662661043387834,
            "auditor_fp_violation": 0.01222570217222732,
            "ave_precision_score": 0.8156613708256986,
            "fpr": 0.1778265642151482,
            "logloss": 0.7742633595888988,
            "mae": 0.30786285927656193,
            "precision": 0.7137809187279152,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5486562732000899,
            "auditor_fn_violation": 0.012629106691572368,
            "auditor_fp_violation": 0.0012205745310157612,
            "ave_precision_score": 0.5495954310914009,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6805804837123901,
            "mae": 0.4897825209129798,
            "precision": 0.9259259259259259,
            "recall": 0.05219206680584551
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5446407067712596,
            "auditor_fn_violation": 0.011607834074758794,
            "auditor_fp_violation": 0.0010523771639190727,
            "ave_precision_score": 0.5454690743577418,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6783267545569531,
            "mae": 0.48824318438670244,
            "precision": 0.9310344827586207,
            "recall": 0.056842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7776193796671713,
            "auditor_fn_violation": 0.017140973519393476,
            "auditor_fp_violation": 0.03538399983793203,
            "ave_precision_score": 0.71815345740681,
            "fpr": 0.23793859649122806,
            "logloss": 3.403543981318587,
            "mae": 0.3749521510821094,
            "precision": 0.6561014263074485,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7755488390801051,
            "auditor_fn_violation": 0.022820498006817264,
            "auditor_fp_violation": 0.030594467215178407,
            "ave_precision_score": 0.7175745525661669,
            "fpr": 0.2689352360043908,
            "logloss": 3.2768453692618813,
            "mae": 0.3817660652309818,
            "precision": 0.6201550387596899,
            "recall": 0.8421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8093982513561793,
            "auditor_fn_violation": 0.007203878694648941,
            "auditor_fp_violation": 0.014312629147927561,
            "ave_precision_score": 0.8098873386624919,
            "fpr": 0.1787280701754386,
            "logloss": 0.7532602559428755,
            "mae": 0.3018216348555462,
            "precision": 0.7199312714776632,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8152672203473827,
            "auditor_fn_violation": 0.010662661043387834,
            "auditor_fp_violation": 0.01222570217222732,
            "ave_precision_score": 0.8156573120528822,
            "fpr": 0.1778265642151482,
            "logloss": 0.7742893235683633,
            "mae": 0.3078527858176163,
            "precision": 0.7137809187279152,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.777851965433429,
            "auditor_fn_violation": 0.014689319854960994,
            "auditor_fp_violation": 0.010058344475507481,
            "ave_precision_score": 0.7183864717572848,
            "fpr": 0.14035087719298245,
            "logloss": 3.364978369083662,
            "mae": 0.34344727885470266,
            "precision": 0.7241379310344828,
            "recall": 0.7014613778705637
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7756492325238232,
            "auditor_fn_violation": 0.0036420359350626827,
            "auditor_fp_violation": 0.01932547155560479,
            "ave_precision_score": 0.7176729988449507,
            "fpr": 0.13611416026344675,
            "logloss": 3.2558181971874545,
            "mae": 0.3461307811235925,
            "precision": 0.7292576419213974,
            "recall": 0.7031578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7775860855648402,
            "auditor_fn_violation": 0.020702853166318723,
            "auditor_fp_violation": 0.03391019407641506,
            "ave_precision_score": 0.7181202341472817,
            "fpr": 0.22807017543859648,
            "logloss": 3.3921839282850366,
            "mae": 0.3734060807901579,
            "precision": 0.6601307189542484,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7748364677488802,
            "auditor_fn_violation": 0.023793402276272455,
            "auditor_fp_violation": 0.03375159870693562,
            "ave_precision_score": 0.7168625231969052,
            "fpr": 0.2524698133918771,
            "logloss": 3.2723044012114575,
            "mae": 0.3810928688549514,
            "precision": 0.627831715210356,
            "recall": 0.8168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7775682780367879,
            "auditor_fn_violation": 0.010317089697102887,
            "auditor_fp_violation": 0.010790182731655938,
            "ave_precision_score": 0.7166792548485972,
            "fpr": 0.13706140350877194,
            "logloss": 3.3704878438391592,
            "mae": 0.34597715076769847,
            "precision": 0.7252747252747253,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7759325323118015,
            "auditor_fn_violation": 0.006003813045236583,
            "auditor_fp_violation": 0.017311352581597002,
            "ave_precision_score": 0.7165200707640262,
            "fpr": 0.13172338090010977,
            "logloss": 3.2583496786686372,
            "mae": 0.3472558924295499,
            "precision": 0.732739420935412,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8346288800238918,
            "auditor_fn_violation": 0.017926143647218257,
            "auditor_fp_violation": 0.014988756533365757,
            "ave_precision_score": 0.8349339331962727,
            "fpr": 0.17324561403508773,
            "logloss": 0.7950795905776362,
            "mae": 0.2657581850715869,
            "precision": 0.720353982300885,
            "recall": 0.8496868475991649
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8461361849603081,
            "auditor_fn_violation": 0.013456583280374376,
            "auditor_fp_violation": 0.024252510095771364,
            "ave_precision_score": 0.8463883033355739,
            "fpr": 0.18111964873765093,
            "logloss": 0.7705160080623117,
            "mae": 0.27559977834254523,
            "precision": 0.7084805653710248,
            "recall": 0.8442105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 9675,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5579212815050714,
            "auditor_fn_violation": 0.009866131926894487,
            "auditor_fp_violation": 0.0032996029334305746,
            "ave_precision_score": 0.5589353290678526,
            "fpr": 0.009868421052631578,
            "logloss": 0.6996857884971529,
            "mae": 0.49507532477901695,
            "precision": 0.7096774193548387,
            "recall": 0.04592901878914405
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5964395925097719,
            "auditor_fn_violation": 0.011184932693974236,
            "auditor_fp_violation": 0.0017472482099517624,
            "ave_precision_score": 0.5971739460873664,
            "fpr": 0.006586169045005488,
            "logloss": 0.6906033513130608,
            "mae": 0.48969266230790465,
            "precision": 0.8421052631578947,
            "recall": 0.06736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 9675,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.532729850368062,
            "auditor_fn_violation": 0.010056129363073653,
            "auditor_fp_violation": 0.0032996029334305746,
            "ave_precision_score": 0.5336835978226822,
            "fpr": 0.009868421052631578,
            "logloss": 0.7036340080578275,
            "mae": 0.49500167552839247,
            "precision": 0.7096774193548387,
            "recall": 0.04592901878914405
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5530211712642367,
            "auditor_fn_violation": 0.013317927089953224,
            "auditor_fp_violation": 0.0008509652665182933,
            "ave_precision_score": 0.5538348812256723,
            "fpr": 0.005488474204171241,
            "logloss": 0.6923373143906352,
            "mae": 0.4885197338105295,
            "precision": 0.868421052631579,
            "recall": 0.06947368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6988198226072971,
            "auditor_fn_violation": 0.006672801523642102,
            "auditor_fp_violation": 0.005495117701875941,
            "ave_precision_score": 0.7027199683086027,
            "fpr": 0.09649122807017543,
            "logloss": 0.631279822806891,
            "mae": 0.3946364283430995,
            "precision": 0.76657824933687,
            "recall": 0.6033402922755741
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6349344059377297,
            "auditor_fn_violation": 0.0051279681090762065,
            "auditor_fp_violation": 0.010951771921167384,
            "ave_precision_score": 0.6958420559615989,
            "fpr": 0.09110867178924259,
            "logloss": 0.6288784732457539,
            "mae": 0.39448245600863685,
            "precision": 0.773224043715847,
            "recall": 0.5957894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7115958330081874,
            "auditor_fn_violation": 0.09303235908141963,
            "auditor_fp_violation": 0.09671153924071148,
            "ave_precision_score": 0.5606874178248906,
            "fpr": 0.25877192982456143,
            "logloss": 0.6855324111509322,
            "mae": 0.4947213308983727,
            "precision": 0.5778175313059034,
            "recall": 0.6743215031315241
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.714461128927631,
            "auditor_fn_violation": 0.10030619908718008,
            "auditor_fp_violation": 0.0867430689130807,
            "ave_precision_score": 0.5685340249154981,
            "fpr": 0.2349066959385291,
            "logloss": 0.6835539119050338,
            "mae": 0.493802471362406,
            "precision": 0.5931558935361216,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7775916952617027,
            "auditor_fn_violation": 0.020702853166318723,
            "auditor_fp_violation": 0.034416656537417455,
            "ave_precision_score": 0.7181258408325357,
            "fpr": 0.22697368421052633,
            "logloss": 3.3962711369376333,
            "mae": 0.3730431684458749,
            "precision": 0.6612111292962357,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7739637453022962,
            "auditor_fn_violation": 0.023793402276272455,
            "auditor_fp_violation": 0.03375159870693562,
            "ave_precision_score": 0.7161080567965235,
            "fpr": 0.2524698133918771,
            "logloss": 3.271372504902214,
            "mae": 0.3807748025130958,
            "precision": 0.627831715210356,
            "recall": 0.8168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7957485788048411,
            "auditor_fn_violation": 0.010797806101893567,
            "auditor_fp_violation": 0.022649001256026903,
            "ave_precision_score": 0.7683438124168169,
            "fpr": 0.21052631578947367,
            "logloss": 2.094078917854055,
            "mae": 0.2753354408566763,
            "precision": 0.6923076923076923,
            "recall": 0.9018789144050104
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8025900709638979,
            "auditor_fn_violation": 0.012864983534577393,
            "auditor_fp_violation": 0.022417144180706765,
            "ave_precision_score": 0.7737648297822624,
            "fpr": 0.21295279912184412,
            "logloss": 2.157379222076449,
            "mae": 0.2933053665121314,
            "precision": 0.680921052631579,
            "recall": 0.871578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8092842907872377,
            "auditor_fn_violation": 0.00731375673002967,
            "auditor_fp_violation": 0.013747923503909893,
            "ave_precision_score": 0.8097861283008634,
            "fpr": 0.17982456140350878,
            "logloss": 0.7564675899732963,
            "mae": 0.30169608888396043,
            "precision": 0.7191780821917808,
            "recall": 0.8768267223382046
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8156928739425998,
            "auditor_fn_violation": 0.00962505055173609,
            "auditor_fp_violation": 0.01112800733139307,
            "ave_precision_score": 0.8160581261726164,
            "fpr": 0.1778265642151482,
            "logloss": 0.7765421824145238,
            "mae": 0.30738146319519216,
            "precision": 0.7147887323943662,
            "recall": 0.8547368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7867339345722779,
            "auditor_fn_violation": 0.010083598871918835,
            "auditor_fp_violation": 0.01566741623110895,
            "ave_precision_score": 0.726626695966611,
            "fpr": 0.18969298245614036,
            "logloss": 3.3994991211026444,
            "mae": 0.35567342767720683,
            "precision": 0.7012089810017271,
            "recall": 0.8475991649269311
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7904577458124737,
            "auditor_fn_violation": 0.00806516840949795,
            "auditor_fp_violation": 0.016626552130434354,
            "ave_precision_score": 0.7309531754292561,
            "fpr": 0.19758507135016465,
            "logloss": 3.3080571020842333,
            "mae": 0.3564724961763941,
            "precision": 0.6923076923076923,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7923550822528042,
            "auditor_fn_violation": 0.0044729516902904465,
            "auditor_fp_violation": 0.01848587982658726,
            "ave_precision_score": 0.7670179847845714,
            "fpr": 0.17543859649122806,
            "logloss": 1.9283952827271906,
            "mae": 0.2668233723350264,
            "precision": 0.7192982456140351,
            "recall": 0.8559498956158664
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7966011081695503,
            "auditor_fn_violation": 0.008682188456872153,
            "auditor_fp_violation": 0.01914923614537911,
            "ave_precision_score": 0.7701429845516227,
            "fpr": 0.18551042810098792,
            "logloss": 1.9929112563921727,
            "mae": 0.28344525391224273,
            "precision": 0.7008849557522124,
            "recall": 0.8336842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7817550692527088,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.015512945180503227,
            "ave_precision_score": 0.7195019550176316,
            "fpr": 0.1425438596491228,
            "logloss": 3.391896913502162,
            "mae": 0.36543252397524684,
            "precision": 0.7257383966244726,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7829353803492577,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.020292248663128537,
            "ave_precision_score": 0.721442600186563,
            "fpr": 0.1437980241492865,
            "logloss": 3.3075007641809973,
            "mae": 0.3645016638690894,
            "precision": 0.720682302771855,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7818945041624925,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.015512945180503227,
            "ave_precision_score": 0.7196145017275634,
            "fpr": 0.1425438596491228,
            "logloss": 3.3734424010784925,
            "mae": 0.36183097963466454,
            "precision": 0.7257383966244726,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7826903398445473,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.020292248663128537,
            "ave_precision_score": 0.7211806450366703,
            "fpr": 0.1437980241492865,
            "logloss": 3.2882682985553706,
            "mae": 0.3609145154152168,
            "precision": 0.720682302771855,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7078526009235433,
            "auditor_fn_violation": 0.004770538036113255,
            "auditor_fp_violation": 0.011661298164580041,
            "ave_precision_score": 0.6920193078889547,
            "fpr": 0.08771929824561403,
            "logloss": 0.6362460271830666,
            "mae": 0.43463624999123185,
            "precision": 0.778393351800554,
            "recall": 0.5866388308977035
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7143995452142717,
            "auditor_fn_violation": 0.006223352013403435,
            "auditor_fp_violation": 0.006354545362994595,
            "ave_precision_score": 0.7009026595410155,
            "fpr": 0.09440175631174534,
            "logloss": 0.6330983751209299,
            "mae": 0.43227594791534313,
            "precision": 0.7624309392265194,
            "recall": 0.5810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.817300703558017,
            "auditor_fn_violation": 0.01071997582683222,
            "auditor_fp_violation": 0.012165228313277422,
            "ave_precision_score": 0.8177797857477471,
            "fpr": 0.12280701754385964,
            "logloss": 0.7041054641023407,
            "mae": 0.2723872211303419,
            "precision": 0.7676348547717843,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8210230451674805,
            "auditor_fn_violation": 0.006475244092668563,
            "auditor_fp_violation": 0.013398926474586856,
            "ave_precision_score": 0.8213513791035958,
            "fpr": 0.12403951701427003,
            "logloss": 0.7583082627045599,
            "mae": 0.2822529337946254,
            "precision": 0.7590618336886994,
            "recall": 0.7494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 9675,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8110235877942535,
            "auditor_fn_violation": 0.006334010914551514,
            "auditor_fp_violation": 0.011939852518131363,
            "ave_precision_score": 0.8113350066838938,
            "fpr": 0.18969298245614036,
            "logloss": 0.8113887923499792,
            "mae": 0.319742486444547,
            "precision": 0.7102177554438861,
            "recall": 0.8851774530271399
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8151445397010448,
            "auditor_fn_violation": 0.012243341614189154,
            "auditor_fp_violation": 0.015846081028006328,
            "ave_precision_score": 0.815490428039408,
            "fpr": 0.1964873765093304,
            "logloss": 0.8307567911070056,
            "mae": 0.32684530032354964,
            "precision": 0.6955782312925171,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.809282564426458,
            "auditor_fn_violation": 0.00731375673002967,
            "auditor_fp_violation": 0.013747923503909893,
            "ave_precision_score": 0.8097844095963955,
            "fpr": 0.17982456140350878,
            "logloss": 0.7564327602022772,
            "mae": 0.30169622425149245,
            "precision": 0.7191780821917808,
            "recall": 0.8768267223382046
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8156943630047933,
            "auditor_fn_violation": 0.00962505055173609,
            "auditor_fp_violation": 0.01112800733139307,
            "ave_precision_score": 0.816049654913918,
            "fpr": 0.1778265642151482,
            "logloss": 0.7765155739893833,
            "mae": 0.30738400795694304,
            "precision": 0.7147887323943662,
            "recall": 0.8547368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7006298140975888,
            "auditor_fn_violation": 0.0021792477017177738,
            "auditor_fp_violation": 0.011696750536850212,
            "ave_precision_score": 0.7038392154109628,
            "fpr": 0.10635964912280702,
            "logloss": 0.6309916704121386,
            "mae": 0.3941810834630017,
            "precision": 0.75,
            "recall": 0.6075156576200418
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6685106330972571,
            "auditor_fn_violation": 0.005340574267721992,
            "auditor_fp_violation": 0.012973443841327708,
            "ave_precision_score": 0.6988459410106256,
            "fpr": 0.10867178924259056,
            "logloss": 0.6289442288279125,
            "mae": 0.3943118819421,
            "precision": 0.7435233160621761,
            "recall": 0.6042105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7514944798193893,
            "auditor_fn_violation": 0.011688276013624878,
            "auditor_fp_violation": 0.029020299015436988,
            "ave_precision_score": 0.7453488922750341,
            "fpr": 0.1337719298245614,
            "logloss": 0.6415646257876739,
            "mae": 0.37964023313530526,
            "precision": 0.7282850779510023,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7637938408447212,
            "auditor_fn_violation": 0.008649835345773878,
            "auditor_fp_violation": 0.020068177927270163,
            "ave_precision_score": 0.7573948305255329,
            "fpr": 0.12843029637760703,
            "logloss": 0.6239796841528604,
            "mae": 0.37894731377129154,
            "precision": 0.7220902612826603,
            "recall": 0.64
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.781842199941148,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.015512945180503227,
            "ave_precision_score": 0.7196693742124791,
            "fpr": 0.1425438596491228,
            "logloss": 3.3922156074497973,
            "mae": 0.3640522599187598,
            "precision": 0.7257383966244726,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7827928936894418,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.020292248663128537,
            "ave_precision_score": 0.7214571864181627,
            "fpr": 0.1437980241492865,
            "logloss": 3.308190281247432,
            "mae": 0.36319705111135114,
            "precision": 0.720682302771855,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7818068790716335,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.01241339491916859,
            "ave_precision_score": 0.7188724514435496,
            "fpr": 0.14692982456140352,
            "logloss": 3.4186748170396073,
            "mae": 0.36656464332420574,
            "precision": 0.7196652719665272,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7813165200671952,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.019567165832485727,
            "ave_precision_score": 0.7190798036703419,
            "fpr": 0.14489571899012074,
            "logloss": 3.3327928657284303,
            "mae": 0.36500697008014116,
            "precision": 0.7191489361702128,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7725153114837564,
            "auditor_fn_violation": 0.010008057722594587,
            "auditor_fp_violation": 0.014905190227300351,
            "ave_precision_score": 0.7213286868883858,
            "fpr": 0.22807017543859648,
            "logloss": 3.1533130665430984,
            "mae": 0.3665979592315604,
            "precision": 0.6623376623376623,
            "recall": 0.8517745302713987
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.769851189649353,
            "auditor_fn_violation": 0.009858455138945062,
            "auditor_fp_violation": 0.018308341473730866,
            "ave_precision_score": 0.7185344594703604,
            "fpr": 0.2283205268935236,
            "logloss": 3.089526454908228,
            "mae": 0.37211131784653667,
            "precision": 0.654485049833887,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.4849569106914513,
            "auditor_fn_violation": 0.00352754276086878,
            "auditor_fp_violation": 0.0036895790284024147,
            "ave_precision_score": 0.5233312671485376,
            "fpr": 0.01425438596491228,
            "logloss": 0.6970231825366003,
            "mae": 0.5012244373690664,
            "precision": 0.43478260869565216,
            "recall": 0.020876826722338204
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.4558993228557597,
            "auditor_fn_violation": 0.004342249696689608,
            "auditor_fp_violation": 0.006812757429581366,
            "ave_precision_score": 0.5181144351852036,
            "fpr": 0.019758507135016465,
            "logloss": 0.69843749212321,
            "mae": 0.5017853627874875,
            "precision": 0.3793103448275862,
            "recall": 0.023157894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7867332770164586,
            "auditor_fn_violation": 0.010083598871918835,
            "auditor_fp_violation": 0.01566741623110895,
            "ave_precision_score": 0.726626695966611,
            "fpr": 0.18969298245614036,
            "logloss": 3.3995109697164434,
            "mae": 0.35567693827314334,
            "precision": 0.7012089810017271,
            "recall": 0.8475991649269311
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.790460835990582,
            "auditor_fn_violation": 0.00806516840949795,
            "auditor_fp_violation": 0.016626552130434354,
            "ave_precision_score": 0.7309531754292561,
            "fpr": 0.19758507135016465,
            "logloss": 3.308168890540882,
            "mae": 0.3564756374262298,
            "precision": 0.6923076923076923,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7872831062022951,
            "auditor_fn_violation": 0.009248067977877888,
            "auditor_fp_violation": 0.015606640735788666,
            "ave_precision_score": 0.7248178498486941,
            "fpr": 0.18530701754385964,
            "logloss": 3.533743476240851,
            "mae": 0.3643824415049772,
            "precision": 0.7024647887323944,
            "recall": 0.8329853862212944
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7871515677550407,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.01476600972819464,
            "ave_precision_score": 0.7235086858474242,
            "fpr": 0.18990120746432493,
            "logloss": 3.460760138035878,
            "mae": 0.3665303354113658,
            "precision": 0.6943462897526502,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7724912997785292,
            "auditor_fn_violation": 0.010008057722594587,
            "auditor_fp_violation": 0.014905190227300351,
            "ave_precision_score": 0.7213046846517043,
            "fpr": 0.22807017543859648,
            "logloss": 3.1533086118558176,
            "mae": 0.3666196208936013,
            "precision": 0.6623376623376623,
            "recall": 0.8517745302713987
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7698283623182622,
            "auditor_fn_violation": 0.009858455138945062,
            "auditor_fp_violation": 0.018308341473730866,
            "ave_precision_score": 0.7185116410470406,
            "fpr": 0.2283205268935236,
            "logloss": 3.089457217162552,
            "mae": 0.37211667454567804,
            "precision": 0.654485049833887,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7817361697447898,
            "auditor_fn_violation": 0.007055085521737537,
            "auditor_fp_violation": 0.014682346744459299,
            "ave_precision_score": 0.7195631194620331,
            "fpr": 0.1513157894736842,
            "logloss": 4.118126402276842,
            "mae": 0.3531943374552355,
            "precision": 0.727810650887574,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7812117256228488,
            "auditor_fn_violation": 0.006008434918250625,
            "auditor_fp_violation": 0.01306156154644055,
            "ave_precision_score": 0.7179746940003354,
            "fpr": 0.15367727771679474,
            "logloss": 4.120014489302738,
            "mae": 0.35269213200968935,
            "precision": 0.7211155378486056,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7873137403921038,
            "auditor_fn_violation": 0.014217759953118704,
            "auditor_fp_violation": 0.038280965114865693,
            "ave_precision_score": 0.7285593558977165,
            "fpr": 0.22916666666666666,
            "logloss": 3.356619578832512,
            "mae": 0.3579864242955454,
            "precision": 0.6693037974683544,
            "recall": 0.8830897703549061
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7863689169369318,
            "auditor_fn_violation": 0.015381593390721591,
            "auditor_fp_violation": 0.03077825557155663,
            "ave_precision_score": 0.7285682690933964,
            "fpr": 0.2579582875960483,
            "logloss": 3.247295591990783,
            "mae": 0.36597804338221945,
            "precision": 0.6350931677018633,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8311553168879207,
            "auditor_fn_violation": 0.007778449254660662,
            "auditor_fp_violation": 0.01151695636319436,
            "ave_precision_score": 0.8314806172470661,
            "fpr": 0.12390350877192982,
            "logloss": 0.6965428712976702,
            "mae": 0.27147098522672064,
            "precision": 0.7650727650727651,
            "recall": 0.7682672233820459
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8283907000716405,
            "auditor_fn_violation": 0.006567681552949334,
            "auditor_fp_violation": 0.015246880633239009,
            "ave_precision_score": 0.8287313251200852,
            "fpr": 0.12733260153677278,
            "logloss": 0.7627246142262274,
            "mae": 0.2822182268803641,
            "precision": 0.7552742616033755,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.789001445330711,
            "auditor_fn_violation": 0.0057891989891220704,
            "auditor_fp_violation": 0.011051010899072166,
            "ave_precision_score": 0.6906595366995741,
            "fpr": 0.07894736842105263,
            "logloss": 0.6169313818822514,
            "mae": 0.4425882720633557,
            "precision": 0.7966101694915254,
            "recall": 0.5887265135699373
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7970448409343334,
            "auditor_fn_violation": 0.003293084522502749,
            "auditor_fp_violation": 0.0059164744861478985,
            "ave_precision_score": 0.6949989442719869,
            "fpr": 0.07244785949506037,
            "logloss": 0.612871809684281,
            "mae": 0.4402702169413101,
            "precision": 0.8064516129032258,
            "recall": 0.5789473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7771996679903014,
            "auditor_fn_violation": 0.021918378932718023,
            "auditor_fp_violation": 0.03391019407641506,
            "ave_precision_score": 0.7177339526910423,
            "fpr": 0.22807017543859648,
            "logloss": 3.3950111569411496,
            "mae": 0.374692076110229,
            "precision": 0.659016393442623,
            "recall": 0.8392484342379958
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7741886538716503,
            "auditor_fn_violation": 0.024870298688543534,
            "auditor_fp_violation": 0.03375159870693562,
            "ave_precision_score": 0.7162150755709458,
            "fpr": 0.2524698133918771,
            "logloss": 3.275230947283806,
            "mae": 0.3824733423121823,
            "precision": 0.6266233766233766,
            "recall": 0.8126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7873019706413248,
            "auditor_fn_violation": 0.014217759953118704,
            "auditor_fp_violation": 0.038280965114865693,
            "ave_precision_score": 0.7285475998312446,
            "fpr": 0.22916666666666666,
            "logloss": 3.3564337119875605,
            "mae": 0.35795776691247233,
            "precision": 0.6693037974683544,
            "recall": 0.8830897703549061
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7863639983483441,
            "auditor_fn_violation": 0.015381593390721591,
            "auditor_fp_violation": 0.03077825557155663,
            "ave_precision_score": 0.7285633649673529,
            "fpr": 0.2579582875960483,
            "logloss": 3.2470602269317004,
            "mae": 0.36593132645929843,
            "precision": 0.6350931677018633,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7818462573462742,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.01241339491916859,
            "ave_precision_score": 0.7186093961969114,
            "fpr": 0.14692982456140352,
            "logloss": 3.4241314153770066,
            "mae": 0.36771970260234776,
            "precision": 0.7196652719665272,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7812790397457418,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.019567165832485727,
            "ave_precision_score": 0.7186023749784657,
            "fpr": 0.14489571899012074,
            "logloss": 3.339969667386082,
            "mae": 0.36597356946094106,
            "precision": 0.7191489361702128,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7871405741205311,
            "auditor_fn_violation": 0.009680712742189504,
            "auditor_fp_violation": 0.015558526801993435,
            "ave_precision_score": 0.7248775972154857,
            "fpr": 0.18640350877192982,
            "logloss": 3.539796512031591,
            "mae": 0.36040622417562046,
            "precision": 0.7017543859649122,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7868501209385266,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.016218693038197767,
            "ave_precision_score": 0.7234485981194105,
            "fpr": 0.19099890230515917,
            "logloss": 3.4643654319451613,
            "mae": 0.3632737003960662,
            "precision": 0.6931216931216931,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7875744381904313,
            "auditor_fn_violation": 0.009248067977877888,
            "auditor_fp_violation": 0.015606640735788666,
            "ave_precision_score": 0.7255458576460583,
            "fpr": 0.18530701754385964,
            "logloss": 3.539672547769653,
            "mae": 0.36556337460628374,
            "precision": 0.7024647887323944,
            "recall": 0.8329853862212944
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7870692861900512,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.01476600972819464,
            "ave_precision_score": 0.7239387809545194,
            "fpr": 0.18990120746432493,
            "logloss": 3.4671746102065817,
            "mae": 0.36809667291527237,
            "precision": 0.6943462897526502,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7776233403830553,
            "auditor_fn_violation": 0.010317089697102887,
            "auditor_fp_violation": 0.010790182731655938,
            "ave_precision_score": 0.716735499633741,
            "fpr": 0.13706140350877194,
            "logloss": 3.3684245268426998,
            "mae": 0.3441874753451996,
            "precision": 0.7252747252747253,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7759376849648569,
            "auditor_fn_violation": 0.006003813045236583,
            "auditor_fp_violation": 0.017311352581597002,
            "ave_precision_score": 0.7165276841705455,
            "fpr": 0.13172338090010977,
            "logloss": 3.253985626130154,
            "mae": 0.3451575557264253,
            "precision": 0.732739420935412,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7860215697056722,
            "auditor_fn_violation": 0.010149983518294693,
            "auditor_fp_violation": 0.018328876463676518,
            "ave_precision_score": 0.72635781047163,
            "fpr": 0.19517543859649122,
            "logloss": 3.407337421030262,
            "mae": 0.35338784385015043,
            "precision": 0.696763202725724,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7913384710431153,
            "auditor_fn_violation": 0.006967473568663706,
            "auditor_fp_violation": 0.015851116325441353,
            "ave_precision_score": 0.7324164252403053,
            "fpr": 0.20197585071350166,
            "logloss": 3.316806048144169,
            "mae": 0.3538168209771555,
            "precision": 0.6876061120543294,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.56948824655326,
            "auditor_fn_violation": 0.008334706808775592,
            "auditor_fp_violation": 0.0007571613791985738,
            "ave_precision_score": 0.5704064432944751,
            "fpr": 0.005482456140350877,
            "logloss": 0.6839498005630652,
            "mae": 0.49220256079315094,
            "precision": 0.8571428571428571,
            "recall": 0.06263048016701461
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5934273172517778,
            "auditor_fn_violation": 0.01173493558264489,
            "auditor_fp_violation": 0.002084613138098068,
            "ave_precision_score": 0.5941704520075829,
            "fpr": 0.008781558726673985,
            "logloss": 0.6786622228559352,
            "mae": 0.48860904077143624,
            "precision": 0.8297872340425532,
            "recall": 0.08210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7944334732344197,
            "auditor_fn_violation": 0.03994295498663151,
            "auditor_fp_violation": 0.0809960090758073,
            "ave_precision_score": 0.7262172775302064,
            "fpr": 0.2894736842105263,
            "logloss": 0.6182942129107226,
            "mae": 0.4179477778247051,
            "precision": 0.6088888888888889,
            "recall": 0.8580375782881002
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7992921664106085,
            "auditor_fn_violation": 0.04103067768213069,
            "auditor_fp_violation": 0.07448211965880824,
            "ave_precision_score": 0.7342419276318765,
            "fpr": 0.2722283205268935,
            "logloss": 0.617207444195068,
            "mae": 0.4172255511341451,
            "precision": 0.6213740458015267,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7724130176824402,
            "auditor_fn_violation": 0.018544207596234846,
            "auditor_fp_violation": 0.017632490579798227,
            "ave_precision_score": 0.7122172194135468,
            "fpr": 0.1524122807017544,
            "logloss": 3.3963659836046887,
            "mae": 0.3720786789464846,
            "precision": 0.7169042769857433,
            "recall": 0.7348643006263048
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7768923206045402,
            "auditor_fn_violation": 0.014043561153157321,
            "auditor_fp_violation": 0.02325803885235501,
            "ave_precision_score": 0.7174066459917713,
            "fpr": 0.15148188803512624,
            "logloss": 3.309263486563075,
            "mae": 0.3698441618164075,
            "precision": 0.7154639175257732,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7818607252211716,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.015512945180503227,
            "ave_precision_score": 0.7196145017275634,
            "fpr": 0.1425438596491228,
            "logloss": 3.3724890941412573,
            "mae": 0.361596742693923,
            "precision": 0.7257383966244726,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7827108145169903,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.020292248663128537,
            "ave_precision_score": 0.7212670681694902,
            "fpr": 0.1437980241492865,
            "logloss": 3.2868510683892276,
            "mae": 0.3607117648836548,
            "precision": 0.720682302771855,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7875768533693477,
            "auditor_fn_violation": 0.009248067977877888,
            "auditor_fp_violation": 0.015606640735788666,
            "ave_precision_score": 0.7255506880038912,
            "fpr": 0.18530701754385964,
            "logloss": 3.5396219503576383,
            "mae": 0.36553272458423597,
            "precision": 0.7024647887323944,
            "recall": 0.8329853862212944
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7870756404795274,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.01476600972819464,
            "ave_precision_score": 0.7239517797022994,
            "fpr": 0.18990120746432493,
            "logloss": 3.467118892731697,
            "mae": 0.3680685317042448,
            "precision": 0.6943462897526502,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7872028164527165,
            "auditor_fn_violation": 0.009680712742189504,
            "auditor_fp_violation": 0.015558526801993435,
            "ave_precision_score": 0.7250246606333774,
            "fpr": 0.18640350877192982,
            "logloss": 3.539897825290229,
            "mae": 0.36045959804363836,
            "precision": 0.7017543859649122,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7869203866629462,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.016218693038197767,
            "ave_precision_score": 0.7235756363170651,
            "fpr": 0.19099890230515917,
            "logloss": 3.4644715701816833,
            "mae": 0.3633227696745448,
            "precision": 0.6931216931216931,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8153658977499597,
            "auditor_fn_violation": 0.023461249679522404,
            "auditor_fp_violation": 0.016282768121226854,
            "ave_precision_score": 0.8157997065536797,
            "fpr": 0.1699561403508772,
            "logloss": 0.7256254429106676,
            "mae": 0.2785296932383427,
            "precision": 0.716636197440585,
            "recall": 0.8183716075156576
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8318286165273905,
            "auditor_fn_violation": 0.012569183661678899,
            "auditor_fp_violation": 0.02362561556511144,
            "ave_precision_score": 0.8321423149572369,
            "fpr": 0.17014270032930845,
            "logloss": 0.7097479237034374,
            "mae": 0.2875172019575602,
            "precision": 0.7113594040968343,
            "recall": 0.8042105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 9675,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5321587787000679,
            "auditor_fn_violation": 0.010056129363073653,
            "auditor_fp_violation": 0.0032996029334305746,
            "ave_precision_score": 0.533109873484443,
            "fpr": 0.009868421052631578,
            "logloss": 0.7028890596446181,
            "mae": 0.4946901404478571,
            "precision": 0.7096774193548387,
            "recall": 0.04592901878914405
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5519914464805065,
            "auditor_fn_violation": 0.013317927089953224,
            "auditor_fp_violation": 0.0008509652665182933,
            "ave_precision_score": 0.5528573391004239,
            "fpr": 0.005488474204171241,
            "logloss": 0.6924285576890866,
            "mae": 0.48838497480759896,
            "precision": 0.868421052631579,
            "recall": 0.06947368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7482719869833955,
            "auditor_fn_violation": 0.004770538036113255,
            "auditor_fp_violation": 0.011661298164580041,
            "ave_precision_score": 0.6957090927235713,
            "fpr": 0.08771929824561403,
            "logloss": 0.6105831800858921,
            "mae": 0.42485630125003426,
            "precision": 0.778393351800554,
            "recall": 0.5866388308977035
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7579804891756909,
            "auditor_fn_violation": 0.006223352013403435,
            "auditor_fp_violation": 0.006354545362994595,
            "ave_precision_score": 0.6985129632783915,
            "fpr": 0.09440175631174534,
            "logloss": 0.6101331933509849,
            "mae": 0.42409643491589016,
            "precision": 0.7624309392265194,
            "recall": 0.5810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8079919285539422,
            "auditor_fn_violation": 0.007235926454968319,
            "auditor_fp_violation": 0.013514950771848791,
            "ave_precision_score": 0.8084166449804265,
            "fpr": 0.16557017543859648,
            "logloss": 0.7405930404988451,
            "mae": 0.30326067103422505,
            "precision": 0.7279279279279279,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8189809471480902,
            "auditor_fn_violation": 0.011797330868334397,
            "auditor_fp_violation": 0.018736341755707514,
            "ave_precision_score": 0.819324099260019,
            "fpr": 0.15697036223929747,
            "logloss": 0.7490297342890284,
            "mae": 0.3066741888986615,
            "precision": 0.7332089552238806,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7775551955904019,
            "auditor_fn_violation": 0.020702853166318723,
            "auditor_fp_violation": 0.03491045743689478,
            "ave_precision_score": 0.718089364256052,
            "fpr": 0.22478070175438597,
            "logloss": 3.391995906071527,
            "mae": 0.37346017758747924,
            "precision": 0.6633825944170771,
            "recall": 0.8434237995824635
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7747829864158721,
            "auditor_fn_violation": 0.024870298688543534,
            "auditor_fp_violation": 0.03375159870693562,
            "ave_precision_score": 0.7168090740988103,
            "fpr": 0.2524698133918771,
            "logloss": 3.2719535752289524,
            "mae": 0.3810843621133828,
            "precision": 0.6266233766233766,
            "recall": 0.8126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7772208361112961,
            "auditor_fn_violation": 0.01654808995348497,
            "auditor_fp_violation": 0.012562801345164302,
            "ave_precision_score": 0.7126631418348477,
            "fpr": 0.14144736842105263,
            "logloss": 3.46914110745687,
            "mae": 0.3829282708792833,
            "precision": 0.7133333333333334,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7753793017589692,
            "auditor_fn_violation": 0.011141024900340872,
            "auditor_fp_violation": 0.02012104855033787,
            "ave_precision_score": 0.7103380754479349,
            "fpr": 0.13830954994511527,
            "logloss": 3.422391013333868,
            "mae": 0.38136392882508846,
            "precision": 0.7155756207674944,
            "recall": 0.6673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7943112693924216,
            "auditor_fn_violation": 0.005851005384023739,
            "auditor_fp_violation": 0.0086225233985657,
            "ave_precision_score": 0.7022565999973949,
            "fpr": 0.08114035087719298,
            "logloss": 0.6087108050847682,
            "mae": 0.4042140676787025,
            "precision": 0.7950138504155124,
            "recall": 0.5991649269311065
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7976432648693234,
            "auditor_fn_violation": 0.00240337396730025,
            "auditor_fp_violation": 0.006211039386096539,
            "ave_precision_score": 0.6998405351866546,
            "fpr": 0.07574094401756312,
            "logloss": 0.608986496433287,
            "mae": 0.4056657887708997,
            "precision": 0.8028571428571428,
            "recall": 0.5915789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 9675,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5322054078040855,
            "auditor_fn_violation": 0.010056129363073653,
            "auditor_fp_violation": 0.0032996029334305746,
            "ave_precision_score": 0.5331532738562501,
            "fpr": 0.009868421052631578,
            "logloss": 0.702885949518024,
            "mae": 0.4946895058740649,
            "precision": 0.7096774193548387,
            "recall": 0.04592901878914405
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.5521014345490707,
            "auditor_fn_violation": 0.013317927089953224,
            "auditor_fp_violation": 0.0008509652665182933,
            "ave_precision_score": 0.5529674093183917,
            "fpr": 0.005488474204171241,
            "logloss": 0.6924385010354461,
            "mae": 0.488390733852868,
            "precision": 0.868421052631579,
            "recall": 0.06947368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7701458255489549,
            "auditor_fn_violation": 0.018303849393839507,
            "auditor_fp_violation": 0.021253697175965317,
            "ave_precision_score": 0.7196130532631667,
            "fpr": 0.20394736842105263,
            "logloss": 3.131091081692839,
            "mae": 0.37067078541416915,
            "precision": 0.667262969588551,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7684546447733582,
            "auditor_fn_violation": 0.01887804032584205,
            "auditor_fp_violation": 0.009559512180384495,
            "ave_precision_score": 0.718538138787804,
            "fpr": 0.2030735455543359,
            "logloss": 3.043019017494875,
            "mae": 0.3750687560366735,
            "precision": 0.6672661870503597,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7591637649929782,
            "auditor_fn_violation": 0.0836881478225836,
            "auditor_fp_violation": 0.045885498966816575,
            "ave_precision_score": 0.6489671373410845,
            "fpr": 0.13486842105263158,
            "logloss": 0.6492577050406194,
            "mae": 0.46683211640961336,
            "precision": 0.6992665036674817,
            "recall": 0.5970772442588727
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7330618117914016,
            "auditor_fn_violation": 0.0834895141255994,
            "auditor_fp_violation": 0.047301584104573066,
            "ave_precision_score": 0.623275451839771,
            "fpr": 0.13391877058177826,
            "logloss": 0.657208102098228,
            "mae": 0.4712362112773891,
            "precision": 0.6814621409921671,
            "recall": 0.5494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7875800925073879,
            "auditor_fn_violation": 0.009248067977877888,
            "auditor_fp_violation": 0.015606640735788666,
            "ave_precision_score": 0.7255846287789592,
            "fpr": 0.18530701754385964,
            "logloss": 3.539657414559993,
            "mae": 0.3655536827407089,
            "precision": 0.7024647887323944,
            "recall": 0.8329853862212944
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.787109535410041,
            "auditor_fn_violation": 0.00884395401236351,
            "auditor_fp_violation": 0.01476600972819464,
            "ave_precision_score": 0.7239893723542168,
            "fpr": 0.18990120746432493,
            "logloss": 3.4671572093783762,
            "mae": 0.36808776928332826,
            "precision": 0.6943462897526502,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.4849569106914513,
            "auditor_fn_violation": 0.00352754276086878,
            "auditor_fp_violation": 0.0036895790284024147,
            "ave_precision_score": 0.5233312671485376,
            "fpr": 0.01425438596491228,
            "logloss": 0.6970231825366003,
            "mae": 0.5012244373690664,
            "precision": 0.43478260869565216,
            "recall": 0.020876826722338204
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.4558993228557597,
            "auditor_fn_violation": 0.004342249696689608,
            "auditor_fp_violation": 0.006812757429581366,
            "ave_precision_score": 0.5181144351852036,
            "fpr": 0.019758507135016465,
            "logloss": 0.69843749212321,
            "mae": 0.5017853627874875,
            "precision": 0.3793103448275862,
            "recall": 0.023157894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7931432269279102,
            "auditor_fn_violation": 0.007712064608284805,
            "auditor_fp_violation": 0.021241035614440268,
            "ave_precision_score": 0.7927611857291268,
            "fpr": 0.16557017543859648,
            "logloss": 0.944587565184082,
            "mae": 0.30225836166197007,
            "precision": 0.7303571428571428,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8015583249350055,
            "auditor_fn_violation": 0.010621064186261487,
            "auditor_fp_violation": 0.021138178632211808,
            "ave_precision_score": 0.8010408682765604,
            "fpr": 0.1712403951701427,
            "logloss": 0.9662534860857764,
            "mae": 0.30955912315099615,
            "precision": 0.7158469945355191,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7482719869833955,
            "auditor_fn_violation": 0.004770538036113255,
            "auditor_fp_violation": 0.011661298164580041,
            "ave_precision_score": 0.6957090927235713,
            "fpr": 0.08771929824561403,
            "logloss": 0.6105831795410586,
            "mae": 0.42485630170752603,
            "precision": 0.778393351800554,
            "recall": 0.5866388308977035
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7579804891756909,
            "auditor_fn_violation": 0.006223352013403435,
            "auditor_fp_violation": 0.006354545362994595,
            "ave_precision_score": 0.6985129632783915,
            "fpr": 0.09440175631174534,
            "logloss": 0.6101331932437367,
            "mae": 0.42409643543931186,
            "precision": 0.7624309392265194,
            "recall": 0.5810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8175918583474884,
            "auditor_fn_violation": 0.019771178991319645,
            "auditor_fp_violation": 0.017052591061950492,
            "ave_precision_score": 0.8173883005703978,
            "fpr": 0.125,
            "logloss": 1.9744614437742718,
            "mae": 0.27974962542395,
            "precision": 0.7579617834394905,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8349850246514323,
            "auditor_fn_violation": 0.01452423594661737,
            "auditor_fp_violation": 0.021591355401363567,
            "ave_precision_score": 0.8347630913016472,
            "fpr": 0.12952799121844127,
            "logloss": 1.4583338450641403,
            "mae": 0.2800751865541611,
            "precision": 0.7505285412262156,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6181315337743134,
            "auditor_fn_violation": 0.010795516976156477,
            "auditor_fp_violation": 0.0006102872655078806,
            "ave_precision_score": 0.6188642322665748,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6847453199080662,
            "mae": 0.4918682847433446,
            "precision": 0.9473684210526315,
            "recall": 0.037578288100208766
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6307361206020315,
            "auditor_fn_violation": 0.015621930787451626,
            "auditor_fp_violation": 0.0005564003665696533,
            "ave_precision_score": 0.6313972193107517,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6783794099794919,
            "mae": 0.4874861330022927,
            "precision": 0.9629629629629629,
            "recall": 0.05473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8137788672061549,
            "auditor_fn_violation": 0.01611086693769916,
            "auditor_fp_violation": 0.015733256351039268,
            "ave_precision_score": 0.8142277112561689,
            "fpr": 0.17105263157894737,
            "logloss": 0.7310520487162256,
            "mae": 0.27787132575032103,
            "precision": 0.7132352941176471,
            "recall": 0.8100208768267223
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.829619529712872,
            "auditor_fn_violation": 0.011383673233577913,
            "auditor_fp_violation": 0.02228874409611376,
            "ave_precision_score": 0.8299338180879551,
            "fpr": 0.16575192096597147,
            "logloss": 0.7223399044518909,
            "mae": 0.2877887358549212,
            "precision": 0.7123809523809523,
            "recall": 0.7873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7734404422330905,
            "auditor_fn_violation": 0.02833022012233089,
            "auditor_fp_violation": 0.022023520116688955,
            "ave_precision_score": 0.7139764895631613,
            "fpr": 0.19846491228070176,
            "logloss": 3.388606170460368,
            "mae": 0.3782456698543666,
            "precision": 0.6813380281690141,
            "recall": 0.8079331941544885
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7694608244877029,
            "auditor_fn_violation": 0.029637760702524704,
            "auditor_fp_violation": 0.017862717650731625,
            "ave_precision_score": 0.7116068822079995,
            "fpr": 0.22063666300768386,
            "logloss": 3.267242781857803,
            "mae": 0.38419462467314414,
            "precision": 0.6510416666666666,
            "recall": 0.7894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8093674272993032,
            "auditor_fn_violation": 0.007203878694648941,
            "auditor_fp_violation": 0.014312629147927561,
            "ave_precision_score": 0.8098566070630033,
            "fpr": 0.1787280701754386,
            "logloss": 0.7533088440932497,
            "mae": 0.3018179839291087,
            "precision": 0.7199312714776632,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8152594723314499,
            "auditor_fn_violation": 0.010662661043387834,
            "auditor_fp_violation": 0.01222570217222732,
            "ave_precision_score": 0.8156454553527942,
            "fpr": 0.1778265642151482,
            "logloss": 0.7743303370711941,
            "mae": 0.30784353473183873,
            "precision": 0.7137809187279152,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7844925910682696,
            "auditor_fn_violation": 0.02362606673259349,
            "auditor_fp_violation": 0.06366739597261051,
            "ave_precision_score": 0.7229796115286742,
            "fpr": 0.25548245614035087,
            "logloss": 3.5221717185425687,
            "mae": 0.3609313124128322,
            "precision": 0.6464339908952959,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.78712833238722,
            "auditor_fn_violation": 0.023590039863654752,
            "auditor_fp_violation": 0.06654900854993506,
            "ave_precision_score": 0.7247164556432124,
            "fpr": 0.24698133918770582,
            "logloss": 3.44998091359797,
            "mae": 0.3617961465741414,
            "precision": 0.647887323943662,
            "recall": 0.871578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 9675,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7899022652926884,
            "auditor_fn_violation": 0.008675786543603268,
            "auditor_fp_violation": 0.016829747579109437,
            "ave_precision_score": 0.764586866038188,
            "fpr": 0.12719298245614036,
            "logloss": 1.9092332304884474,
            "mae": 0.2707108643002979,
            "precision": 0.7627811860940695,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7944586170680815,
            "auditor_fn_violation": 0.008464960425212316,
            "auditor_fp_violation": 0.018006223627629686,
            "ave_precision_score": 0.7679736659244569,
            "fpr": 0.13062568605927552,
            "logloss": 1.9882256325758365,
            "mae": 0.2811487308292622,
            "precision": 0.7525987525987526,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7942151986332575,
            "auditor_fn_violation": 0.007542669303739517,
            "auditor_fp_violation": 0.01800980511324501,
            "ave_precision_score": 0.7679650577119214,
            "fpr": 0.17763157894736842,
            "logloss": 1.987057635997488,
            "mae": 0.2635108062974629,
            "precision": 0.7177700348432056,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8016025335772892,
            "auditor_fn_violation": 0.010572534519614077,
            "auditor_fp_violation": 0.01804147070967482,
            "ave_precision_score": 0.7740361443878501,
            "fpr": 0.18221734357848518,
            "logloss": 2.0409865511054277,
            "mae": 0.278442820587455,
            "precision": 0.7067137809187279,
            "recall": 0.8421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.4933931975778566,
            "auditor_fn_violation": 0.003110921876716841,
            "auditor_fp_violation": 0.008257870426643978,
            "ave_precision_score": 0.49545753924426117,
            "fpr": 0.029605263157894735,
            "logloss": 0.690790441882434,
            "mae": 0.49703106627260385,
            "precision": 0.4375,
            "recall": 0.04384133611691023
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5024902052867521,
            "auditor_fn_violation": 0.00861979317118264,
            "auditor_fp_violation": 0.008237746603691882,
            "ave_precision_score": 0.5035555739838414,
            "fpr": 0.030735455543358946,
            "logloss": 0.6858946693326264,
            "mae": 0.49366332556230436,
            "precision": 0.5333333333333333,
            "recall": 0.06736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.4849569106914513,
            "auditor_fn_violation": 0.00352754276086878,
            "auditor_fp_violation": 0.0036895790284024147,
            "ave_precision_score": 0.5233312671485376,
            "fpr": 0.01425438596491228,
            "logloss": 0.6970231825366003,
            "mae": 0.5012244373690664,
            "precision": 0.43478260869565216,
            "recall": 0.020876826722338204
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.4558993228557597,
            "auditor_fn_violation": 0.004342249696689608,
            "auditor_fp_violation": 0.006812757429581366,
            "ave_precision_score": 0.5181144351852036,
            "fpr": 0.019758507135016465,
            "logloss": 0.69843749212321,
            "mae": 0.5017853627874875,
            "precision": 0.3793103448275862,
            "recall": 0.023157894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7789145550710745,
            "auditor_fn_violation": 0.019075284767241702,
            "auditor_fp_violation": 0.01326931647826263,
            "ave_precision_score": 0.7194446330513956,
            "fpr": 0.15350877192982457,
            "logloss": 3.369812744272672,
            "mae": 0.3638704778430493,
            "precision": 0.7131147540983607,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7796689194469055,
            "auditor_fn_violation": 0.01138598417008493,
            "auditor_fp_violation": 0.02040302520669897,
            "ave_precision_score": 0.7216928476613408,
            "fpr": 0.1525795828759605,
            "logloss": 3.2546890089990144,
            "mae": 0.36576291388790116,
            "precision": 0.7104166666666667,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8035926824991384,
            "auditor_fn_violation": 0.0044180126726000805,
            "auditor_fp_violation": 0.011357420687978608,
            "ave_precision_score": 0.6882618085021517,
            "fpr": 0.08223684210526316,
            "logloss": 0.6384370140157826,
            "mae": 0.39391139437232103,
            "precision": 0.7945205479452054,
            "recall": 0.605427974947808
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8025507735300328,
            "auditor_fn_violation": 0.00240337396730025,
            "auditor_fp_violation": 0.004133979194151,
            "ave_precision_score": 0.6865530390378736,
            "fpr": 0.07683863885839737,
            "logloss": 0.6340873056290854,
            "mae": 0.39552073676290417,
            "precision": 0.8005698005698005,
            "recall": 0.5915789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7818339343085831,
            "auditor_fn_violation": 0.015595813646852,
            "auditor_fp_violation": 0.015512945180503227,
            "ave_precision_score": 0.7196640171184382,
            "fpr": 0.1425438596491228,
            "logloss": 3.3725237082594473,
            "mae": 0.3616087805120307,
            "precision": 0.7257383966244726,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7827404138237324,
            "auditor_fn_violation": 0.011894390201629216,
            "auditor_fp_violation": 0.020292248663128537,
            "ave_precision_score": 0.7214030553682929,
            "fpr": 0.1437980241492865,
            "logloss": 3.286879868561855,
            "mae": 0.36072218198938505,
            "precision": 0.720682302771855,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7860239919889574,
            "auditor_fn_violation": 0.010149983518294693,
            "auditor_fp_violation": 0.018328876463676518,
            "ave_precision_score": 0.7263589611574558,
            "fpr": 0.19517543859649122,
            "logloss": 3.407227035465927,
            "mae": 0.35335694640678794,
            "precision": 0.696763202725724,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7913837295304202,
            "auditor_fn_violation": 0.006967473568663706,
            "auditor_fp_violation": 0.015851116325441353,
            "ave_precision_score": 0.7324508127886982,
            "fpr": 0.20197585071350166,
            "logloss": 3.3167032049493557,
            "mae": 0.3537903721030274,
            "precision": 0.6876061120543294,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8379212716803158,
            "auditor_fn_violation": 0.01918974105409662,
            "auditor_fp_violation": 0.018589704631092746,
            "ave_precision_score": 0.8382427852974775,
            "fpr": 0.14583333333333334,
            "logloss": 0.7504701068310107,
            "mae": 0.2607503499261243,
            "precision": 0.7442307692307693,
            "recall": 0.8079331941544885
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8478643076624734,
            "auditor_fn_violation": 0.0111803108209602,
            "auditor_fp_violation": 0.023162368201089637,
            "ave_precision_score": 0.8481377391040986,
            "fpr": 0.150384193194292,
            "logloss": 0.7389012225630064,
            "mae": 0.269046862951011,
            "precision": 0.7360308285163777,
            "recall": 0.8042105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    }
]