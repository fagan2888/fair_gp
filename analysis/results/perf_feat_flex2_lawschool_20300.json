[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8063850270355304,
            "auditor_fn_violation": 0.013046235752313578,
            "auditor_fp_violation": 0.017918906529982917,
            "ave_precision_score": 0.8067536717284456,
            "fpr": 0.14364035087719298,
            "logloss": 0.8766716226846919,
            "mae": 0.2943568186378943,
            "precision": 0.7374749498997996,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8062975332505653,
            "auditor_fn_violation": 0.015799219048206116,
            "auditor_fp_violation": 0.028123529872981026,
            "ave_precision_score": 0.806930114911315,
            "fpr": 0.141602634467618,
            "logloss": 0.870858657124295,
            "mae": 0.2870278013965133,
            "precision": 0.73125,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8395071734388282,
            "auditor_fn_violation": 0.006659341837281598,
            "auditor_fp_violation": 0.006597178814018422,
            "ave_precision_score": 0.8397449822832981,
            "fpr": 0.06030701754385965,
            "logloss": 0.5918111926187413,
            "mae": 0.3365223162379647,
            "precision": 0.844632768361582,
            "recall": 0.6089613034623218
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8368152393782038,
            "auditor_fn_violation": 0.011050444175223394,
            "auditor_fp_violation": 0.006037321624588364,
            "ave_precision_score": 0.8370716282654129,
            "fpr": 0.06256860592755215,
            "logloss": 0.5500132821453562,
            "mae": 0.32558738080933936,
            "precision": 0.8371428571428572,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8385770509910484,
            "auditor_fn_violation": 0.027950477007181906,
            "auditor_fp_violation": 0.01938523565445682,
            "ave_precision_score": 0.8398151974236202,
            "fpr": 0.1206140350877193,
            "logloss": 0.6565969048345425,
            "mae": 0.28427010186198076,
            "precision": 0.7731958762886598,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8364727468324582,
            "auditor_fn_violation": 0.020813527014435996,
            "auditor_fp_violation": 0.027084640112905754,
            "ave_precision_score": 0.8367765242788319,
            "fpr": 0.12952799121844127,
            "logloss": 0.6480857247323119,
            "mae": 0.27069202753497107,
            "precision": 0.7531380753138075,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.853178293214185,
            "auditor_fn_violation": 0.0009825990638510844,
            "auditor_fp_violation": 0.006334125098970706,
            "ave_precision_score": 0.7778411004219201,
            "fpr": 0.08771929824561403,
            "logloss": 7.541483146236942,
            "mae": 0.23883222995591388,
            "precision": 0.815668202764977,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8364006201978776,
            "auditor_fn_violation": 0.011017252538567498,
            "auditor_fp_violation": 0.008842814019131255,
            "ave_precision_score": 0.7569235493251256,
            "fpr": 0.09110867178924259,
            "logloss": 7.375357815436765,
            "mae": 0.23161596151330086,
            "precision": 0.801909307875895,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7750054664468152,
            "auditor_fn_violation": 0.008678136277557438,
            "auditor_fp_violation": 0.021210984706421646,
            "ave_precision_score": 0.7256179475606968,
            "fpr": 0.15021929824561403,
            "logloss": 5.327382391346651,
            "mae": 0.313539723022277,
            "precision": 0.7139874739039666,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7749496206607498,
            "auditor_fn_violation": 0.009831836943714098,
            "auditor_fp_violation": 0.027373765093304067,
            "ave_precision_score": 0.7239089689117275,
            "fpr": 0.15367727771679474,
            "logloss": 5.164294131025641,
            "mae": 0.31110392406672177,
            "precision": 0.6989247311827957,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8500511030989489,
            "auditor_fn_violation": 0.004048754779004543,
            "auditor_fp_violation": 0.008659936658749012,
            "ave_precision_score": 0.8503338902199704,
            "fpr": 0.07346491228070176,
            "logloss": 0.5590149392875834,
            "mae": 0.3331406240087521,
            "precision": 0.8308080808080808,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8375102049986621,
            "auditor_fn_violation": 0.005059353758834322,
            "auditor_fp_violation": 0.01183942292614082,
            "ave_precision_score": 0.8377991463638348,
            "fpr": 0.08781558726673985,
            "logloss": 0.5343415929459193,
            "mae": 0.32524443178567486,
            "precision": 0.8,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.83262563806651,
            "auditor_fn_violation": 0.007525815557222996,
            "auditor_fp_violation": 0.01677813893403342,
            "ave_precision_score": 0.832923972037555,
            "fpr": 0.16228070175438597,
            "logloss": 0.7903454391883336,
            "mae": 0.27466933976905844,
            "precision": 0.7299270072992701,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8281551844266981,
            "auditor_fn_violation": 0.009234387483907983,
            "auditor_fp_violation": 0.029490748000627256,
            "ave_precision_score": 0.8284983442862209,
            "fpr": 0.1602634467618002,
            "logloss": 0.8245374170678086,
            "mae": 0.2747611086156016,
            "precision": 0.7170542635658915,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8327372160245887,
            "auditor_fn_violation": 0.016027530639225355,
            "auditor_fp_violation": 0.017801704379714133,
            "ave_precision_score": 0.833065955580395,
            "fpr": 0.1337719298245614,
            "logloss": 0.7323542271413591,
            "mae": 0.2805927272790305,
            "precision": 0.7530364372469636,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8296497913729999,
            "auditor_fn_violation": 0.009106362599663815,
            "auditor_fp_violation": 0.023127548220166227,
            "ave_precision_score": 0.8300192545859458,
            "fpr": 0.132821075740944,
            "logloss": 0.7462454175066862,
            "mae": 0.2743290642975315,
            "precision": 0.7468619246861925,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8430464394140122,
            "auditor_fn_violation": 0.011036374030800015,
            "auditor_fp_violation": 0.016504667250072935,
            "ave_precision_score": 0.8434654832511359,
            "fpr": 0.1513157894736842,
            "logloss": 0.6717979355493717,
            "mae": 0.27608638126351154,
            "precision": 0.7401129943502824,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8369552409365878,
            "auditor_fn_violation": 0.010808619393873297,
            "auditor_fp_violation": 0.023088344832993577,
            "ave_precision_score": 0.8372276354165682,
            "fpr": 0.15697036223929747,
            "logloss": 0.6995012475891215,
            "mae": 0.2738316579526056,
            "precision": 0.7228682170542635,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8134778341650093,
            "auditor_fn_violation": 0.012704559259656268,
            "auditor_fp_violation": 0.015082614493478358,
            "ave_precision_score": 0.8139485807365074,
            "fpr": 0.11951754385964912,
            "logloss": 0.788161390497898,
            "mae": 0.29474274880144125,
            "precision": 0.7635574837310195,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8216137015360853,
            "auditor_fn_violation": 0.009153779223457954,
            "auditor_fp_violation": 0.019366473263289948,
            "ave_precision_score": 0.821985578920257,
            "fpr": 0.13172338090010977,
            "logloss": 0.7575446415705275,
            "mae": 0.2760202490437532,
            "precision": 0.744136460554371,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.842606856869747,
            "auditor_fn_violation": 0.014645192410762144,
            "auditor_fp_violation": 0.01942430303787974,
            "ave_precision_score": 0.8427772558952057,
            "fpr": 0.11842105263157894,
            "logloss": 0.5682961749462655,
            "mae": 0.33948415343822264,
            "precision": 0.7605321507760532,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8524928726818083,
            "auditor_fn_violation": 0.02022556087938871,
            "auditor_fp_violation": 0.022382683863885842,
            "ave_precision_score": 0.8526591918591937,
            "fpr": 0.11525795828759605,
            "logloss": 0.5140924212661866,
            "mae": 0.31552364183390463,
            "precision": 0.765625,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8139979931361188,
            "auditor_fn_violation": 0.013432575838782298,
            "auditor_fp_violation": 0.017129745384839783,
            "ave_precision_score": 0.8144026807279814,
            "fpr": 0.13486842105263158,
            "logloss": 0.7680965062480153,
            "mae": 0.29421279404124234,
            "precision": 0.7463917525773196,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8205230200749536,
            "auditor_fn_violation": 0.006462885823140733,
            "auditor_fp_violation": 0.025403794887878323,
            "ave_precision_score": 0.8209383798126453,
            "fpr": 0.14050493962678376,
            "logloss": 0.745192373690542,
            "mae": 0.2787642689723949,
            "precision": 0.7333333333333333,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8043588967422615,
            "auditor_fn_violation": 0.013213724229106378,
            "auditor_fp_violation": 0.015658207275909497,
            "ave_precision_score": 0.8047493682059303,
            "fpr": 0.125,
            "logloss": 0.8751089881710966,
            "mae": 0.30425712872634775,
            "precision": 0.7510917030567685,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8096667960367694,
            "auditor_fn_violation": 0.010765944432458579,
            "auditor_fp_violation": 0.02045436725733104,
            "ave_precision_score": 0.8104570114670337,
            "fpr": 0.11964873765093303,
            "logloss": 0.8356243362772424,
            "mae": 0.2819250922188619,
            "precision": 0.7528344671201814,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7804333381098453,
            "auditor_fn_violation": 0.013316450494872624,
            "auditor_fp_violation": 0.014376797099637456,
            "ave_precision_score": 0.7505061442248171,
            "fpr": 0.11951754385964912,
            "logloss": 3.46307418180263,
            "mae": 0.29513504423941894,
            "precision": 0.7620087336244541,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7946094880840159,
            "auditor_fn_violation": 0.005294066046615282,
            "auditor_fp_violation": 0.02031960561392505,
            "ave_precision_score": 0.7594595627833834,
            "fpr": 0.11306256860592755,
            "logloss": 3.5064625245723153,
            "mae": 0.2725228493187799,
            "precision": 0.7685393258426966,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8177659916342028,
            "auditor_fn_violation": 0.016496498374245192,
            "auditor_fp_violation": 0.00886829603700463,
            "ave_precision_score": 0.8180554385662218,
            "fpr": 0.10855263157894737,
            "logloss": 0.8555660302030023,
            "mae": 0.28996213543773847,
            "precision": 0.7765237020316027,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8265710808731254,
            "auditor_fn_violation": 0.007069818607705679,
            "auditor_fp_violation": 0.014338638858397368,
            "ave_precision_score": 0.8269053832389451,
            "fpr": 0.11525795828759605,
            "logloss": 0.8208663897272149,
            "mae": 0.2690534432637469,
            "precision": 0.7666666666666667,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.812522846991474,
            "auditor_fn_violation": 0.01567022188873406,
            "auditor_fp_violation": 0.020140538400633422,
            "ave_precision_score": 0.813002425282211,
            "fpr": 0.12938596491228072,
            "logloss": 0.8135052096327935,
            "mae": 0.29866555763797603,
            "precision": 0.7494692144373672,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8266292846664862,
            "auditor_fn_violation": 0.00891906693567698,
            "auditor_fp_violation": 0.02490885212482359,
            "ave_precision_score": 0.826989136577291,
            "fpr": 0.1251372118551043,
            "logloss": 0.7551473259178474,
            "mae": 0.2769793538231048,
            "precision": 0.7516339869281046,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7907522119187875,
            "auditor_fn_violation": 0.014828313145388933,
            "auditor_fp_violation": 0.015608721923573782,
            "ave_precision_score": 0.7911878647437938,
            "fpr": 0.10087719298245613,
            "logloss": 0.933205022385518,
            "mae": 0.3090366586156422,
            "precision": 0.7772397094430993,
            "recall": 0.6537678207739308
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7881997433029432,
            "auditor_fn_violation": 0.013696291782936186,
            "auditor_fp_violation": 0.014527305159165754,
            "ave_precision_score": 0.7886749675600286,
            "fpr": 0.11525795828759605,
            "logloss": 0.9104347285374559,
            "mae": 0.29944496237233426,
            "precision": 0.7463768115942029,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.851887967112267,
            "auditor_fn_violation": 0.003352002715546504,
            "auditor_fp_violation": 0.00824321790223778,
            "ave_precision_score": 0.8522302538124285,
            "fpr": 0.1118421052631579,
            "logloss": 0.5218809336515714,
            "mae": 0.30127548475279026,
            "precision": 0.7888198757763976,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8469006540533088,
            "auditor_fn_violation": 0.0052916952154255775,
            "auditor_fp_violation": 0.017352399247294967,
            "ave_precision_score": 0.847365412390616,
            "fpr": 0.1163556531284303,
            "logloss": 0.509419669750287,
            "mae": 0.290792847573338,
            "precision": 0.778705636743215,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6020225191785885,
            "auditor_fn_violation": 0.001000464501375638,
            "auditor_fp_violation": 0.015624348876942957,
            "ave_precision_score": 0.5658171097397855,
            "fpr": 0.24890350877192982,
            "logloss": 4.902193971212763,
            "mae": 0.3437215911052452,
            "precision": 0.6458658346333853,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.5550282196060313,
            "auditor_fn_violation": 0.0025936893215392407,
            "auditor_fp_violation": 0.012300062725419494,
            "ave_precision_score": 0.5147221655252849,
            "fpr": 0.27771679473106475,
            "logloss": 5.930262608605217,
            "mae": 0.3679226435209727,
            "precision": 0.6053042121684867,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8074343104050095,
            "auditor_fn_violation": 0.009450816450494871,
            "auditor_fp_violation": 0.013311559778305629,
            "ave_precision_score": 0.8077702857265938,
            "fpr": 0.16776315789473684,
            "logloss": 0.8107926140503185,
            "mae": 0.295516149599918,
            "precision": 0.7325174825174825,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8127907892734418,
            "auditor_fn_violation": 0.008331100800629695,
            "auditor_fp_violation": 0.02009908656107888,
            "ave_precision_score": 0.8130159079404149,
            "fpr": 0.17014270032930845,
            "logloss": 0.8240312400595547,
            "mae": 0.2902845711592083,
            "precision": 0.720216606498195,
            "recall": 0.8617710583153347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8192154160241147,
            "auditor_fn_violation": 0.015643423732447214,
            "auditor_fp_violation": 0.010514335125223994,
            "ave_precision_score": 0.8196670875609897,
            "fpr": 0.11842105263157894,
            "logloss": 0.8232013562389473,
            "mae": 0.28655444886850956,
            "precision": 0.7631578947368421,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8256997586635977,
            "auditor_fn_violation": 0.00453777089709882,
            "auditor_fp_violation": 0.01661733573780775,
            "ave_precision_score": 0.8260399507436933,
            "fpr": 0.1163556531284303,
            "logloss": 0.7995134675731485,
            "mae": 0.2677799064846257,
            "precision": 0.7685589519650655,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6281352744949387,
            "auditor_fn_violation": 0.022988351734733986,
            "auditor_fp_violation": 0.013759532441555209,
            "ave_precision_score": 0.5191298916715295,
            "fpr": 0.29605263157894735,
            "logloss": 9.04464722174148,
            "mae": 0.4347471712703976,
            "precision": 0.5964125560538116,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6551580381509187,
            "auditor_fn_violation": 0.005528778334396259,
            "auditor_fp_violation": 0.010898541633997194,
            "ave_precision_score": 0.5268255218182352,
            "fpr": 0.31613611416026344,
            "logloss": 9.301187977769088,
            "mae": 0.41624516897510766,
            "precision": 0.5807860262008734,
            "recall": 0.8617710583153347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8078443853362935,
            "auditor_fn_violation": 0.013061868010147581,
            "auditor_fp_violation": 0.007696274534316787,
            "ave_precision_score": 0.808295145094083,
            "fpr": 0.12938596491228072,
            "logloss": 0.8601885168329029,
            "mae": 0.2962907891840541,
            "precision": 0.7510548523206751,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8178457377023046,
            "auditor_fn_violation": 0.00882423368808871,
            "auditor_fp_violation": 0.019768307981809632,
            "ave_precision_score": 0.8181903648481365,
            "fpr": 0.12733260153677278,
            "logloss": 0.8263051188111874,
            "mae": 0.27786480597219,
            "precision": 0.7510729613733905,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8199083245849073,
            "auditor_fn_violation": 0.010417783256511954,
            "auditor_fp_violation": 0.013915801975246915,
            "ave_precision_score": 0.8202787635212131,
            "fpr": 0.13486842105263158,
            "logloss": 0.8872895184055005,
            "mae": 0.29096586097819116,
            "precision": 0.7453416149068323,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8335225971602462,
            "auditor_fn_violation": 0.01037238645496725,
            "auditor_fp_violation": 0.021473655323819982,
            "ave_precision_score": 0.8338905732145612,
            "fpr": 0.12733260153677278,
            "logloss": 0.7605045546420679,
            "mae": 0.2696468229089228,
            "precision": 0.7505376344086021,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8504326685623351,
            "auditor_fn_violation": 0.022771733304748635,
            "auditor_fp_violation": 0.008753698378964043,
            "ave_precision_score": 0.8506873401982726,
            "fpr": 0.09429824561403509,
            "logloss": 0.5494767813317838,
            "mae": 0.3238968037289931,
            "precision": 0.7995337995337995,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8555644747251702,
            "auditor_fn_violation": 0.01507611553534554,
            "auditor_fp_violation": 0.010957346714756155,
            "ave_precision_score": 0.8557723831533748,
            "fpr": 0.09659714599341383,
            "logloss": 0.5029631053263357,
            "mae": 0.3032867024477845,
            "precision": 0.7967667436489607,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8198881186903301,
            "auditor_fn_violation": 0.016286579483331547,
            "auditor_fp_violation": 0.01256927949326999,
            "ave_precision_score": 0.8202645028924891,
            "fpr": 0.10635964912280702,
            "logloss": 0.8523461827452722,
            "mae": 0.28558923622649857,
            "precision": 0.7815315315315315,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8276770212249701,
            "auditor_fn_violation": 0.012484797044996008,
            "auditor_fp_violation": 0.019047945742512163,
            "ave_precision_score": 0.8280160668582797,
            "fpr": 0.1163556531284303,
            "logloss": 0.8210969918776723,
            "mae": 0.2662694188437838,
            "precision": 0.7654867256637168,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7518829901467414,
            "auditor_fn_violation": 0.0198485010897917,
            "auditor_fp_violation": 0.009972600741759392,
            "ave_precision_score": 0.7532569836637815,
            "fpr": 0.08662280701754387,
            "logloss": 0.7949643894352961,
            "mae": 0.35805137536982856,
            "precision": 0.7817679558011049,
            "recall": 0.5763747454175153
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7373009242361517,
            "auditor_fn_violation": 0.01833600842119239,
            "auditor_fp_violation": 0.01046730437509801,
            "ave_precision_score": 0.7388108888210254,
            "fpr": 0.08781558726673985,
            "logloss": 0.7174575843313512,
            "mae": 0.3399664053984324,
            "precision": 0.7802197802197802,
            "recall": 0.6133909287257019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8322071723962744,
            "auditor_fn_violation": 0.006873727087576377,
            "auditor_fp_violation": 0.014655477768054342,
            "ave_precision_score": 0.8341641712711296,
            "fpr": 0.12390350877192982,
            "logloss": 0.6969996490434748,
            "mae": 0.26946397131591165,
            "precision": 0.7721774193548387,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8334970345319946,
            "auditor_fn_violation": 0.011491418776508859,
            "auditor_fp_violation": 0.02525188176258429,
            "ave_precision_score": 0.8338149350005931,
            "fpr": 0.1394072447859495,
            "logloss": 0.7183982252575215,
            "mae": 0.27059458834465866,
            "precision": 0.7381443298969073,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8242530261603576,
            "auditor_fn_violation": 0.004526655232786654,
            "auditor_fp_violation": 0.009329291161395173,
            "ave_precision_score": 0.8246143395800927,
            "fpr": 0.1513157894736842,
            "logloss": 0.7326553614001287,
            "mae": 0.2937308065932115,
            "precision": 0.7351247600767754,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8214012841417846,
            "auditor_fn_violation": 0.007854563731498633,
            "auditor_fp_violation": 0.01640906774345304,
            "ave_precision_score": 0.821898830494808,
            "fpr": 0.1525795828759605,
            "logloss": 0.7347406949493638,
            "mae": 0.2858318125198652,
            "precision": 0.7231075697211156,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.852595420399804,
            "auditor_fn_violation": 0.005589648765498275,
            "auditor_fp_violation": 0.00416197858065592,
            "ave_precision_score": 0.8528185319369713,
            "fpr": 0.08223684210526316,
            "logloss": 0.5489132478881844,
            "mae": 0.3279644654846993,
            "precision": 0.8218527315914489,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8431883340230412,
            "auditor_fn_violation": 0.013679695964608236,
            "auditor_fp_violation": 0.020814548376979776,
            "ave_precision_score": 0.8434612487274769,
            "fpr": 0.09330406147091108,
            "logloss": 0.5147651806911565,
            "mae": 0.3203485029113409,
            "precision": 0.7976190476190477,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8192075930038544,
            "auditor_fn_violation": 0.010714796155357849,
            "auditor_fp_violation": 0.010274721840230035,
            "ave_precision_score": 0.8199599024506214,
            "fpr": 0.11513157894736842,
            "logloss": 0.8368738305769924,
            "mae": 0.2855566954682104,
            "precision": 0.7717391304347826,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8269613844863468,
            "auditor_fn_violation": 0.007498939053042607,
            "auditor_fp_violation": 0.018974439391563434,
            "ave_precision_score": 0.8272954164565379,
            "fpr": 0.11855104281009879,
            "logloss": 0.8214323700306712,
            "mae": 0.2657775375008931,
            "precision": 0.7636761487964989,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8094040577986541,
            "auditor_fn_violation": 0.015417872583699584,
            "auditor_fp_violation": 0.019617035462766184,
            "ave_precision_score": 0.8098279908944923,
            "fpr": 0.12609649122807018,
            "logloss": 0.817831263880765,
            "mae": 0.3003473447060815,
            "precision": 0.7558386411889597,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8228709533334834,
            "auditor_fn_violation": 0.008430675710597382,
            "auditor_fp_violation": 0.0272855574721656,
            "ave_precision_score": 0.8232407245374859,
            "fpr": 0.12733260153677278,
            "logloss": 0.7600925852768611,
            "mae": 0.278781595710643,
            "precision": 0.7478260869565218,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8391967446523134,
            "auditor_fn_violation": 0.011047539929252871,
            "auditor_fp_violation": 0.013506896695420267,
            "ave_precision_score": 0.8396749029162016,
            "fpr": 0.1600877192982456,
            "logloss": 0.6803768121647993,
            "mae": 0.27870205752845867,
            "precision": 0.7291280148423006,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8369233036102532,
            "auditor_fn_violation": 0.009561562188087522,
            "auditor_fp_violation": 0.020973812137368673,
            "ave_precision_score": 0.8371935001329152,
            "fpr": 0.15806805708013172,
            "logloss": 0.7087404285434497,
            "mae": 0.27446638813508867,
            "precision": 0.722007722007722,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7575248085110253,
            "auditor_fn_violation": 0.0033899667702862045,
            "auditor_fp_violation": 0.006618014751843991,
            "ave_precision_score": 0.550669297703811,
            "fpr": 0.4232456140350877,
            "logloss": 14.170511547822674,
            "mae": 0.43768170165875675,
            "precision": 0.5547866205305652,
            "recall": 0.9796334012219959
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7572712439587526,
            "auditor_fn_violation": 0.000578482810288459,
            "auditor_fp_violation": 0.014544456641053787,
            "ave_precision_score": 0.5423211457267836,
            "fpr": 0.43029637760702527,
            "logloss": 14.018023831733245,
            "mae": 0.43526468478984237,
            "precision": 0.5388235294117647,
            "recall": 0.9892008639308856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8106456904161601,
            "auditor_fn_violation": 0.015717118662236042,
            "auditor_fp_violation": 0.01037890152935784,
            "ave_precision_score": 0.8112769704866671,
            "fpr": 0.09868421052631579,
            "logloss": 0.8505015648763106,
            "mae": 0.3007860830711648,
            "precision": 0.784688995215311,
            "recall": 0.6680244399185336
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8178518000466967,
            "auditor_fn_violation": 0.006517414940503992,
            "auditor_fp_violation": 0.013929453504782812,
            "ave_precision_score": 0.8183017532737324,
            "fpr": 0.09330406147091108,
            "logloss": 0.8099106832767298,
            "mae": 0.2749638222621308,
            "precision": 0.7926829268292683,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8636459480688836,
            "auditor_fn_violation": 0.011335620109336485,
            "auditor_fp_violation": 0.011360795099387425,
            "ave_precision_score": 0.8639493439729663,
            "fpr": 0.12390350877192982,
            "logloss": 0.5346832831893138,
            "mae": 0.2772627136066085,
            "precision": 0.772635814889336,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8579699609671692,
            "auditor_fn_violation": 0.011666860284547163,
            "auditor_fp_violation": 0.022370432805394393,
            "ave_precision_score": 0.8581775461494722,
            "fpr": 0.12843029637760703,
            "logloss": 0.5281134314074712,
            "mae": 0.2680484902612379,
            "precision": 0.7592592592592593,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 20300,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8489777642924751,
            "auditor_fn_violation": 0.010955979561939479,
            "auditor_fp_violation": 0.006784702254448476,
            "ave_precision_score": 0.8492752982868976,
            "fpr": 0.0756578947368421,
            "logloss": 0.5741908336323522,
            "mae": 0.32210876021149726,
            "precision": 0.8349282296650717,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8428736878930856,
            "auditor_fn_violation": 0.007214439310277791,
            "auditor_fp_violation": 0.018658362082483934,
            "ave_precision_score": 0.8431412418379959,
            "fpr": 0.09330406147091108,
            "logloss": 0.5391908814577823,
            "mae": 0.3108238082386259,
            "precision": 0.7985781990521327,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.841660675665115,
            "auditor_fn_violation": 0.010455747311251658,
            "auditor_fp_violation": 0.016319748301871072,
            "ave_precision_score": 0.8420171024752046,
            "fpr": 0.1074561403508772,
            "logloss": 0.7231613741607226,
            "mae": 0.27427172524611104,
            "precision": 0.7841409691629956,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8408790553701474,
            "auditor_fn_violation": 0.005900998831180223,
            "auditor_fp_violation": 0.017641524227693273,
            "ave_precision_score": 0.841141461857041,
            "fpr": 0.1119648737650933,
            "logloss": 0.7222707358851251,
            "mae": 0.26208366725810756,
            "precision": 0.7728285077951003,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8387956118265358,
            "auditor_fn_violation": 0.017387537070782864,
            "auditor_fp_violation": 0.00615962411968163,
            "ave_precision_score": 0.8390561123620293,
            "fpr": 0.1524122807017544,
            "logloss": 0.5724608011868406,
            "mae": 0.33717448115216064,
            "precision": 0.7290448343079922,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8557106087363979,
            "auditor_fn_violation": 0.013160483934062443,
            "auditor_fp_violation": 0.011251372118551047,
            "ave_precision_score": 0.8559172338768947,
            "fpr": 0.13830954994511527,
            "logloss": 0.5121802433974546,
            "mae": 0.31080742811724854,
            "precision": 0.7504950495049505,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 20300,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8343148791399578,
            "auditor_fn_violation": 0.008892521527852217,
            "auditor_fp_violation": 0.015103450431303917,
            "ave_precision_score": 0.8346202562421867,
            "fpr": 0.13925438596491227,
            "logloss": 0.7556569146743168,
            "mae": 0.27740037686299857,
            "precision": 0.7571701720841301,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8353980517139169,
            "auditor_fn_violation": 0.013845654147887706,
            "auditor_fp_violation": 0.021483456170613143,
            "ave_precision_score": 0.8357149081952739,
            "fpr": 0.14050493962678376,
            "logloss": 0.7524856053806481,
            "mae": 0.2745015794225365,
            "precision": 0.7429718875502008,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.805418511921212,
            "auditor_fn_violation": 0.020996355450744998,
            "auditor_fp_violation": 0.020763012043172067,
            "ave_precision_score": 0.8058531164669086,
            "fpr": 0.11403508771929824,
            "logloss": 0.8405995880400596,
            "mae": 0.30538746135207995,
            "precision": 0.7668161434977578,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8166108504612073,
            "auditor_fn_violation": 0.012852275879400566,
            "auditor_fp_violation": 0.027167947310647644,
            "ave_precision_score": 0.8169736649861998,
            "fpr": 0.1141602634467618,
            "logloss": 0.7771563275678577,
            "mae": 0.27957416705680455,
            "precision": 0.7603686635944701,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8400494086944879,
            "auditor_fn_violation": 0.010022510451280955,
            "auditor_fp_violation": 0.01579624536400384,
            "ave_precision_score": 0.8403988399448971,
            "fpr": 0.10964912280701754,
            "logloss": 0.7310151633943149,
            "mae": 0.27483000293979243,
            "precision": 0.7811816192560175,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8392579662624071,
            "auditor_fn_violation": 0.005900998831180223,
            "auditor_fp_violation": 0.01832758350321468,
            "ave_precision_score": 0.8395265840941698,
            "fpr": 0.1141602634467618,
            "logloss": 0.7322020736199529,
            "mae": 0.26269847164149207,
            "precision": 0.7694013303769401,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8118538388734132,
            "auditor_fn_violation": 0.011677296601993788,
            "auditor_fp_violation": 0.01319175313580865,
            "ave_precision_score": 0.8134930375645186,
            "fpr": 0.10964912280701754,
            "logloss": 0.8282589173150058,
            "mae": 0.2914124612876249,
            "precision": 0.7747747747747747,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8236334553416018,
            "auditor_fn_violation": 0.008824233688088705,
            "auditor_fp_violation": 0.017570468088442846,
            "ave_precision_score": 0.8239703987968549,
            "fpr": 0.11745334796926454,
            "logloss": 0.7915828108433485,
            "mae": 0.2699265058177028,
            "precision": 0.7616926503340757,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8302760447503297,
            "auditor_fn_violation": 0.013617929753099665,
            "auditor_fp_violation": 0.014144997291328086,
            "ave_precision_score": 0.8306632131653744,
            "fpr": 0.11074561403508772,
            "logloss": 0.8019416506018148,
            "mae": 0.28160142979178177,
            "precision": 0.7740492170022372,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8397088997406891,
            "auditor_fn_violation": 0.007543984845647036,
            "auditor_fp_violation": 0.016391916261564998,
            "ave_precision_score": 0.8399903963277365,
            "fpr": 0.1163556531284303,
            "logloss": 0.775497641275709,
            "mae": 0.2613037930707808,
            "precision": 0.7660044150110376,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8311590068025011,
            "auditor_fn_violation": 0.010880051452460068,
            "auditor_fp_violation": 0.017523023711297245,
            "ave_precision_score": 0.8314681568350459,
            "fpr": 0.12938596491228072,
            "logloss": 0.7559448568765013,
            "mae": 0.27798150065503163,
            "precision": 0.7611336032388664,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8271461587011029,
            "auditor_fn_violation": 0.01057390710609233,
            "auditor_fp_violation": 0.02108162145209346,
            "ave_precision_score": 0.8274698871800593,
            "fpr": 0.13611416026344675,
            "logloss": 0.7783924666237179,
            "mae": 0.2750935068909166,
            "precision": 0.740041928721174,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8333614792867425,
            "auditor_fn_violation": 0.01098054453853575,
            "auditor_fp_violation": 0.0124598908196858,
            "ave_precision_score": 0.8337322658121289,
            "fpr": 0.12609649122807018,
            "logloss": 0.697396025961464,
            "mae": 0.27767826508978005,
            "precision": 0.762396694214876,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8289863429403372,
            "auditor_fn_violation": 0.00787590121220599,
            "auditor_fp_violation": 0.022245472008781558,
            "ave_precision_score": 0.829304461050749,
            "fpr": 0.13062568605927552,
            "logloss": 0.7069232069613911,
            "mae": 0.27370684591848027,
            "precision": 0.75,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8078667935450887,
            "auditor_fn_violation": 0.009712098474291638,
            "auditor_fp_violation": 0.013329791223902992,
            "ave_precision_score": 0.8088177721140453,
            "fpr": 0.14473684210526316,
            "logloss": 0.8621976273876627,
            "mae": 0.2971336822772987,
            "precision": 0.7546468401486989,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8163030741930279,
            "auditor_fn_violation": 0.00775973048391036,
            "auditor_fp_violation": 0.014262682295750357,
            "ave_precision_score": 0.8164776682217139,
            "fpr": 0.14818880351262348,
            "logloss": 0.868347537336965,
            "mae": 0.2904328274836178,
            "precision": 0.7408829174664108,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8367412628419295,
            "auditor_fn_violation": 0.010292725193839999,
            "auditor_fp_violation": 0.015218048089344505,
            "ave_precision_score": 0.8371100866950019,
            "fpr": 0.1118421052631579,
            "logloss": 0.7536964427323971,
            "mae": 0.27642264086295076,
            "precision": 0.7768052516411379,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8362576422270744,
            "auditor_fn_violation": 0.00622343187298035,
            "auditor_fp_violation": 0.019023443625529247,
            "ave_precision_score": 0.836533459575217,
            "fpr": 0.1163556531284303,
            "logloss": 0.7539828462040841,
            "mae": 0.26374236555115177,
            "precision": 0.7654867256637168,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8313963188840883,
            "auditor_fn_violation": 0.007686604494944083,
            "auditor_fp_violation": 0.01660103346251615,
            "ave_precision_score": 0.8317063647537415,
            "fpr": 0.15899122807017543,
            "logloss": 0.7796818787069898,
            "mae": 0.2753459496605555,
            "precision": 0.7349177330895795,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8276464269503748,
            "auditor_fn_violation": 0.009234387483907983,
            "auditor_fp_violation": 0.02783930531597931,
            "ave_precision_score": 0.8279876346407649,
            "fpr": 0.16465422612513722,
            "logloss": 0.8120585656888694,
            "mae": 0.2763711203391186,
            "precision": 0.7115384615384616,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8458990544054474,
            "auditor_fn_violation": 0.0016659520491656844,
            "auditor_fp_violation": 0.007407175896987127,
            "ave_precision_score": 0.84619610200271,
            "fpr": 0.08223684210526316,
            "logloss": 0.5456106839404706,
            "mae": 0.3269482839496688,
            "precision": 0.8157248157248157,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8375671027903073,
            "auditor_fn_violation": 0.0060835528327876495,
            "auditor_fp_violation": 0.01271169829073232,
            "ave_precision_score": 0.8378414144450554,
            "fpr": 0.09001097694840834,
            "logloss": 0.5263544874334973,
            "mae": 0.3228245773782052,
            "precision": 0.7980295566502463,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7998238334984202,
            "auditor_fn_violation": 0.013010504877264448,
            "auditor_fp_violation": 0.01676772096512064,
            "ave_precision_score": 0.8002887929090594,
            "fpr": 0.14692982456140352,
            "logloss": 0.8204673661399212,
            "mae": 0.31221420367786445,
            "precision": 0.7281947261663286,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8032222856224236,
            "auditor_fn_violation": 0.0099005910482156,
            "auditor_fp_violation": 0.027677591343892114,
            "ave_precision_score": 0.803665942276546,
            "fpr": 0.14709110867178923,
            "logloss": 0.8003840666509722,
            "mae": 0.292687289057615,
            "precision": 0.7208333333333333,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8327566385960313,
            "auditor_fn_violation": 0.027588701897309473,
            "auditor_fp_violation": 0.006381005959078221,
            "ave_precision_score": 0.8331875510791481,
            "fpr": 0.07017543859649122,
            "logloss": 0.6112253865341674,
            "mae": 0.32779169183228524,
            "precision": 0.8297872340425532,
            "recall": 0.6354378818737271
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.840899285002749,
            "auditor_fn_violation": 0.014315078723449658,
            "auditor_fp_violation": 0.012454426062411794,
            "ave_precision_score": 0.8411631094277818,
            "fpr": 0.07574094401756312,
            "logloss": 0.5527472109816969,
            "mae": 0.30236767195257164,
            "precision": 0.8212435233160622,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8224919796542507,
            "auditor_fn_violation": 0.01131775467181192,
            "auditor_fp_violation": 0.016366629161978587,
            "ave_precision_score": 0.8228600401054749,
            "fpr": 0.14144736842105263,
            "logloss": 0.8079660397203348,
            "mae": 0.2844351413598201,
            "precision": 0.7490272373540856,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8272226399059838,
            "auditor_fn_violation": 0.007999184434070746,
            "auditor_fp_violation": 0.022238121373686692,
            "ave_precision_score": 0.8275315863436604,
            "fpr": 0.141602634467618,
            "logloss": 0.8038978612949722,
            "mae": 0.27798101206913584,
            "precision": 0.7361963190184049,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8147259257952878,
            "auditor_fn_violation": 0.016306678100546684,
            "auditor_fp_violation": 0.01282712422386132,
            "ave_precision_score": 0.8151153274751615,
            "fpr": 0.125,
            "logloss": 0.8847337293530836,
            "mae": 0.29210441195502773,
            "precision": 0.7564102564102564,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8225892828212766,
            "auditor_fn_violation": 0.005585678282949222,
            "auditor_fp_violation": 0.013189489571899018,
            "ave_precision_score": 0.8228997610514002,
            "fpr": 0.13062568605927552,
            "logloss": 0.8667794011701622,
            "mae": 0.27577891663830195,
            "precision": 0.7468085106382979,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7743742258387398,
            "auditor_fn_violation": 0.01613025690499161,
            "auditor_fp_violation": 0.02171365170646331,
            "ave_precision_score": 0.7764019761009695,
            "fpr": 0.17324561403508773,
            "logloss": 0.9652754002228615,
            "mae": 0.30093269046424065,
            "precision": 0.7137681159420289,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7856475629538366,
            "auditor_fn_violation": 0.015806331541775232,
            "auditor_fp_violation": 0.028745883644346874,
            "ave_precision_score": 0.7861201200632696,
            "fpr": 0.1690450054884742,
            "logloss": 0.9659271310592049,
            "mae": 0.29460771524874835,
            "precision": 0.7077798861480076,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8319937618646092,
            "auditor_fn_violation": 0.0420217422374674,
            "auditor_fp_violation": 0.038106325790723844,
            "ave_precision_score": 0.8324241814239857,
            "fpr": 0.1600877192982456,
            "logloss": 0.6463995399315118,
            "mae": 0.33234318840580873,
            "precision": 0.7170542635658915,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8261715384813844,
            "auditor_fn_violation": 0.03699207905299519,
            "auditor_fp_violation": 0.04366767288693744,
            "ave_precision_score": 0.8264162535738613,
            "fpr": 0.16136114160263446,
            "logloss": 0.6033374442624713,
            "mae": 0.3217844035993624,
            "precision": 0.7106299212598425,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8181543084407225,
            "auditor_fn_violation": 0.015038232036302578,
            "auditor_fp_violation": 0.008357815560278373,
            "ave_precision_score": 0.81855132615544,
            "fpr": 0.11293859649122807,
            "logloss": 0.8510203681704951,
            "mae": 0.28915358517267076,
            "precision": 0.7706013363028953,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8268976245927268,
            "auditor_fn_violation": 0.005609386594846291,
            "auditor_fp_violation": 0.016004782813235065,
            "ave_precision_score": 0.8272414764161455,
            "fpr": 0.12184412733260154,
            "logloss": 0.8170234205933988,
            "mae": 0.2687334338087287,
            "precision": 0.7592190889370932,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8475273015773005,
            "auditor_fn_violation": 0.023716368313860012,
            "auditor_fp_violation": 0.020085844063841316,
            "ave_precision_score": 0.8478843717841887,
            "fpr": 0.10964912280701754,
            "logloss": 0.7814470384650923,
            "mae": 0.26985760763046795,
            "precision": 0.7876857749469215,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8409345236596806,
            "auditor_fn_violation": 0.021818759438871675,
            "auditor_fp_violation": 0.026072702681511684,
            "ave_precision_score": 0.8412680916704232,
            "fpr": 0.11745334796926454,
            "logloss": 0.762285934226137,
            "mae": 0.25627329941785204,
            "precision": 0.7688984881209503,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8077369002049974,
            "auditor_fn_violation": 0.012159663415157044,
            "auditor_fp_violation": 0.014595574446805856,
            "ave_precision_score": 0.808136410550137,
            "fpr": 0.15679824561403508,
            "logloss": 0.8071851638296023,
            "mae": 0.2956613590123883,
            "precision": 0.7409420289855072,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8170498509748771,
            "auditor_fn_violation": 0.007643559755614721,
            "auditor_fp_violation": 0.019787909675395957,
            "ave_precision_score": 0.8169790798682622,
            "fpr": 0.15916575192096596,
            "logloss": 0.7978288779262513,
            "mae": 0.28030578691014485,
            "precision": 0.7309833024118738,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8239178618591637,
            "auditor_fn_violation": 0.009180601707935842,
            "auditor_fp_violation": 0.005563195399424931,
            "ave_precision_score": 0.8243445011896948,
            "fpr": 0.1074561403508772,
            "logloss": 0.8068423271308658,
            "mae": 0.2865917963802614,
            "precision": 0.7767653758542141,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8302908651672654,
            "auditor_fn_violation": 0.007174135180052779,
            "auditor_fp_violation": 0.01656098086874706,
            "ave_precision_score": 0.8306542643914621,
            "fpr": 0.11306256860592755,
            "logloss": 0.7773431506818288,
            "mae": 0.27021929206552053,
            "precision": 0.7690582959641256,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.82618054402693,
            "auditor_fn_violation": 0.01122619430449852,
            "auditor_fp_violation": 0.0073186231612284896,
            "ave_precision_score": 0.8265372530361788,
            "fpr": 0.10855263157894737,
            "logloss": 0.8259213657581618,
            "mae": 0.27781864158693753,
            "precision": 0.7780269058295964,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8241217714521623,
            "auditor_fn_violation": 0.007849822069119217,
            "auditor_fp_violation": 0.01710982828916419,
            "ave_precision_score": 0.8244710565831438,
            "fpr": 0.11086717892425905,
            "logloss": 0.8251517388249465,
            "mae": 0.2693805927004072,
            "precision": 0.7704545454545455,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.799923332449221,
            "auditor_fn_violation": 0.011159198913781409,
            "auditor_fp_violation": 0.014741426011584782,
            "ave_precision_score": 0.8012450160342,
            "fpr": 0.13048245614035087,
            "logloss": 0.831697480129339,
            "mae": 0.30256603295680845,
            "precision": 0.750524109014675,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8114223467523332,
            "auditor_fn_violation": 0.009454874784550728,
            "auditor_fp_violation": 0.022833522816371337,
            "ave_precision_score": 0.8117758509383971,
            "fpr": 0.13721185510428102,
            "logloss": 0.7964601168244276,
            "mae": 0.2857540956284583,
            "precision": 0.7351694915254238,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.826692889714562,
            "auditor_fn_violation": 0.018624718619358997,
            "auditor_fp_violation": 0.014517439679960005,
            "ave_precision_score": 0.827029651764655,
            "fpr": 0.12719298245614036,
            "logloss": 0.7702564988404539,
            "mae": 0.28770017098144657,
            "precision": 0.7568134171907757,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8298809626993517,
            "auditor_fn_violation": 0.011688197765254519,
            "auditor_fp_violation": 0.023061392504312377,
            "ave_precision_score": 0.8301953287296836,
            "fpr": 0.12733260153677278,
            "logloss": 0.7661962390712188,
            "mae": 0.27250977723119824,
            "precision": 0.7489177489177489,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8448342237927192,
            "auditor_fn_violation": 0.010973844999464038,
            "auditor_fp_violation": 0.012071821477684713,
            "ave_precision_score": 0.8452719028708959,
            "fpr": 0.13596491228070176,
            "logloss": 0.6511195272813964,
            "mae": 0.26937720990924907,
            "precision": 0.761996161228407,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8408226750186497,
            "auditor_fn_violation": 0.007053222789377728,
            "auditor_fp_violation": 0.021042418064920815,
            "ave_precision_score": 0.8410890675423678,
            "fpr": 0.14709110867178923,
            "logloss": 0.6721937462147088,
            "mae": 0.26874063908802576,
            "precision": 0.7335984095427436,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8111498832978148,
            "auditor_fn_violation": 0.011697395219208928,
            "auditor_fp_violation": 0.016530712172354876,
            "ave_precision_score": 0.8115454067894898,
            "fpr": 0.13925438596491227,
            "logloss": 0.7720066194302587,
            "mae": 0.2992626286616633,
            "precision": 0.741869918699187,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8181293518942048,
            "auditor_fn_violation": 0.008127209318314907,
            "auditor_fp_violation": 0.02836365061941352,
            "ave_precision_score": 0.8185648850352043,
            "fpr": 0.14928649835345773,
            "logloss": 0.7458896900877804,
            "mae": 0.2807509417245124,
            "precision": 0.7274549098196392,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7976375233652342,
            "auditor_fn_violation": 0.03253072855254226,
            "auditor_fp_violation": 0.023604513064133015,
            "ave_precision_score": 0.7980303902764394,
            "fpr": 0.09978070175438597,
            "logloss": 1.0351581520058046,
            "mae": 0.3083889706722653,
            "precision": 0.7764127764127764,
            "recall": 0.6435845213849287
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8062111023964194,
            "auditor_fn_violation": 0.018362087564279164,
            "auditor_fp_violation": 0.013708934451936649,
            "ave_precision_score": 0.8065867537953184,
            "fpr": 0.10867178924259056,
            "logloss": 0.9629175542484368,
            "mae": 0.2793458170301146,
            "precision": 0.762589928057554,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8323125544683931,
            "auditor_fn_violation": 0.014368278129131383,
            "auditor_fp_violation": 0.013809017793890908,
            "ave_precision_score": 0.8326832728752143,
            "fpr": 0.1337719298245614,
            "logloss": 0.7536014951730354,
            "mae": 0.2786672638638339,
            "precision": 0.7598425196850394,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8366089723184728,
            "auditor_fn_violation": 0.010614211236317339,
            "auditor_fp_violation": 0.020567076995452415,
            "ave_precision_score": 0.8368895270848367,
            "fpr": 0.13391877058177826,
            "logloss": 0.751729418192995,
            "mae": 0.2732091172162906,
            "precision": 0.7489711934156379,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8328300315020541,
            "auditor_fn_violation": 0.008253832136349027,
            "auditor_fp_violation": 0.01027472184023004,
            "ave_precision_score": 0.8332007840318845,
            "fpr": 0.11951754385964912,
            "logloss": 0.7004638879302195,
            "mae": 0.27741738214448974,
            "precision": 0.7733887733887734,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8284106662465753,
            "auditor_fn_violation": 0.010701931990336496,
            "auditor_fp_violation": 0.022737964560137998,
            "ave_precision_score": 0.828729663899142,
            "fpr": 0.12623490669593854,
            "logloss": 0.7105134782102498,
            "mae": 0.2737539481399031,
            "precision": 0.7532188841201717,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 20300,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8329881137785944,
            "auditor_fn_violation": 0.028669560867545647,
            "auditor_fp_violation": 0.012946930866358296,
            "ave_precision_score": 0.8332529438286601,
            "fpr": 0.0625,
            "logloss": 0.6144043537617552,
            "mae": 0.33526432021284436,
            "precision": 0.8416666666666667,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8367634441053753,
            "auditor_fn_violation": 0.019274857572316288,
            "auditor_fp_violation": 0.015470636663007686,
            "ave_precision_score": 0.8370419792824383,
            "fpr": 0.06366630076838639,
            "logloss": 0.5501006838626321,
            "mae": 0.31147130928008687,
            "precision": 0.8410958904109589,
            "recall": 0.6630669546436285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8310799428461938,
            "auditor_fn_violation": 0.027959409725944188,
            "auditor_fp_violation": 0.007170167104221361,
            "ave_precision_score": 0.8313885929209213,
            "fpr": 0.06798245614035088,
            "logloss": 0.636414534202429,
            "mae": 0.3312813258805698,
            "precision": 0.8355437665782494,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8354292454692503,
            "auditor_fn_violation": 0.014876965715410173,
            "auditor_fp_violation": 0.012839109299043435,
            "ave_precision_score": 0.8357107440589673,
            "fpr": 0.07354555433589462,
            "logloss": 0.5730788213395823,
            "mae": 0.3056851379082893,
            "precision": 0.824607329842932,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8074469539146351,
            "auditor_fn_violation": 0.010976078179154613,
            "auditor_fp_violation": 0.014986248281035144,
            "ave_precision_score": 0.8078360343318991,
            "fpr": 0.13486842105263158,
            "logloss": 0.9174070080695338,
            "mae": 0.30579482974423133,
            "precision": 0.7432150313152401,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8204529307118161,
            "auditor_fn_violation": 0.013829058329559761,
            "auditor_fp_violation": 0.023277011133761967,
            "ave_precision_score": 0.8208538025229095,
            "fpr": 0.1350164654226125,
            "logloss": 0.7901961211746875,
            "mae": 0.2834895751889835,
            "precision": 0.7399577167019028,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 20300,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8156600527370264,
            "auditor_fn_violation": 0.02770482724121914,
            "auditor_fp_violation": 0.04443263741300998,
            "ave_precision_score": 0.8132627279051792,
            "fpr": 0.20394736842105263,
            "logloss": 3.0263041091942626,
            "mae": 0.2972897453018504,
            "precision": 0.6873949579831933,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8079428675670912,
            "auditor_fn_violation": 0.03282178699030094,
            "auditor_fp_violation": 0.0572369452720715,
            "ave_precision_score": 0.8045570805933693,
            "fpr": 0.20197585071350166,
            "logloss": 3.0165655459789114,
            "mae": 0.2921344729241945,
            "precision": 0.6771929824561403,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7409483779504513,
            "auditor_fn_violation": 0.013959606245756961,
            "auditor_fp_violation": 0.01776784598074759,
            "ave_precision_score": 0.734881494842068,
            "fpr": 0.20614035087719298,
            "logloss": 1.3775687369654317,
            "mae": 0.3276711560869891,
            "precision": 0.6791808873720137,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7651687767669008,
            "auditor_fn_violation": 0.006946535385840922,
            "auditor_fp_violation": 0.017322996706915488,
            "ave_precision_score": 0.7609836099701747,
            "fpr": 0.19538968166849616,
            "logloss": 1.2608350814689617,
            "mae": 0.31197955336125677,
            "precision": 0.6838365896980462,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8061344312385775,
            "auditor_fn_violation": 0.01010067174045093,
            "auditor_fp_violation": 0.014780493395007716,
            "ave_precision_score": 0.8065769453718873,
            "fpr": 0.1600877192982456,
            "logloss": 0.8134133773548176,
            "mae": 0.29725074023672116,
            "precision": 0.737410071942446,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8180902465208808,
            "auditor_fn_violation": 0.005659174049830132,
            "auditor_fp_violation": 0.017974753018660816,
            "ave_precision_score": 0.8182711781675691,
            "fpr": 0.15367727771679474,
            "logloss": 0.7991556278915105,
            "mae": 0.2813678061233452,
            "precision": 0.7378277153558053,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 20300,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8200096160494666,
            "auditor_fn_violation": 0.0060630828598992395,
            "auditor_fp_violation": 0.012183814643497106,
            "ave_precision_score": 0.8203843392035218,
            "fpr": 0.11293859649122807,
            "logloss": 0.7878650964953877,
            "mae": 0.27136306236121055,
            "precision": 0.783157894736842,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.816159887325012,
            "auditor_fn_violation": 0.00673553140995702,
            "auditor_fp_violation": 0.020307354555433584,
            "ave_precision_score": 0.816570073590588,
            "fpr": 0.12403951701427003,
            "logloss": 0.811909315013896,
            "mae": 0.26635986945092893,
            "precision": 0.7590618336886994,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 20300,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6712801078719784,
            "auditor_fn_violation": 0.026047807910815735,
            "auditor_fp_violation": 0.0479877693044964,
            "ave_precision_score": 0.6619178160971845,
            "fpr": 0.17982456140350878,
            "logloss": 2.369830110367534,
            "mae": 0.31373394342787203,
            "precision": 0.7023593466424682,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.6713737338364077,
            "auditor_fn_violation": 0.019253520091608918,
            "auditor_fp_violation": 0.05860661361141603,
            "ave_precision_score": 0.661754481732187,
            "fpr": 0.19209659714599342,
            "logloss": 2.227108701221078,
            "mae": 0.30307918480197704,
            "precision": 0.6823956442831216,
            "recall": 0.8120950323974082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.837832951764053,
            "auditor_fn_violation": 0.013229356486940373,
            "auditor_fp_violation": 0.010329416177022127,
            "ave_precision_score": 0.8381676551480745,
            "fpr": 0.11074561403508772,
            "logloss": 0.7763006930812313,
            "mae": 0.2696669920017707,
            "precision": 0.7832618025751072,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8376765531751482,
            "auditor_fn_violation": 0.006360940081983341,
            "auditor_fp_violation": 0.01904549553081386,
            "ave_precision_score": 0.8379719171381246,
            "fpr": 0.12184412733260154,
            "logloss": 0.7772348536756319,
            "mae": 0.262179166194284,
            "precision": 0.7592190889370932,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 20300,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8176004934597199,
            "auditor_fn_violation": 0.01592927073284025,
            "auditor_fp_violation": 0.00886829603700463,
            "ave_precision_score": 0.8180465164877129,
            "fpr": 0.10855263157894737,
            "logloss": 0.8558484691156937,
            "mae": 0.2900234025073163,
            "precision": 0.777027027027027,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8269252071190937,
            "auditor_fn_violation": 0.007069818607705679,
            "auditor_fp_violation": 0.016097890857770115,
            "ave_precision_score": 0.8272489007881472,
            "fpr": 0.1163556531284303,
            "logloss": 0.8213487267275944,
            "mae": 0.26907207079805584,
            "precision": 0.7649667405764967,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8259590519319764,
            "auditor_fn_violation": 0.013401311323114314,
            "auditor_fp_violation": 0.006644059674125931,
            "ave_precision_score": 0.8263708447429872,
            "fpr": 0.11074561403508772,
            "logloss": 0.7917961483188393,
            "mae": 0.2802682699623394,
            "precision": 0.7799564270152506,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8260071914286619,
            "auditor_fn_violation": 0.006858814631821772,
            "auditor_fp_violation": 0.018915634310804456,
            "ave_precision_score": 0.8263302426728025,
            "fpr": 0.11855104281009879,
            "logloss": 0.7905188634638912,
            "mae": 0.2719711115896447,
            "precision": 0.7636761487964989,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8116319125698548,
            "auditor_fn_violation": 0.010625468967735025,
            "auditor_fp_violation": 0.020148351877318,
            "ave_precision_score": 0.8120109960311028,
            "fpr": 0.13486842105263158,
            "logloss": 0.8964268544714052,
            "mae": 0.30195396445163936,
            "precision": 0.74375,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8252242967605834,
            "auditor_fn_violation": 0.01298741325721385,
            "auditor_fp_violation": 0.02222832052689353,
            "ave_precision_score": 0.8255909444508174,
            "fpr": 0.13172338090010977,
            "logloss": 0.7694543834811212,
            "mae": 0.27842480182677415,
            "precision": 0.7463002114164905,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.818426404679611,
            "auditor_fn_violation": 0.0129077786114982,
            "auditor_fp_violation": 0.016705213151643958,
            "ave_precision_score": 0.8188701745120536,
            "fpr": 0.1337719298245614,
            "logloss": 0.7474249157209112,
            "mae": 0.2866102032858265,
            "precision": 0.7515274949083504,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8199220722811393,
            "auditor_fn_violation": 0.007503680715422023,
            "auditor_fp_violation": 0.02439920809157912,
            "ave_precision_score": 0.8202771105007185,
            "fpr": 0.14270032930845225,
            "logloss": 0.7475517553812768,
            "mae": 0.27874040126452265,
            "precision": 0.7346938775510204,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8313185992830054,
            "auditor_fn_violation": 0.018638117697502413,
            "auditor_fp_violation": 0.01439242405300663,
            "ave_precision_score": 0.8317301001333566,
            "fpr": 0.1162280701754386,
            "logloss": 0.7485859549596582,
            "mae": 0.2862770753618183,
            "precision": 0.7680525164113785,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8397933407282805,
            "auditor_fn_violation": 0.00861797137458422,
            "auditor_fp_violation": 0.02314469970205426,
            "ave_precision_score": 0.8400300223881045,
            "fpr": 0.1163556531284303,
            "logloss": 0.7201375649727466,
            "mae": 0.2701637140373097,
            "precision": 0.7649667405764967,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8357054678975739,
            "auditor_fn_violation": 0.01181575374280916,
            "auditor_fp_violation": 0.016033254156769594,
            "ave_precision_score": 0.8360126775558966,
            "fpr": 0.1162280701754386,
            "logloss": 0.7900804975611563,
            "mae": 0.2788851896204963,
            "precision": 0.7710583153347732,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8420829662099015,
            "auditor_fn_violation": 0.008497058983909171,
            "auditor_fp_violation": 0.017925748784694998,
            "ave_precision_score": 0.8423483387306853,
            "fpr": 0.1163556531284303,
            "logloss": 0.7536222904195831,
            "mae": 0.25864642850534525,
            "precision": 0.7695652173913043,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8254072356062712,
            "auditor_fn_violation": 0.014366044949440814,
            "auditor_fp_violation": 0.010597678876526233,
            "ave_precision_score": 0.8258143124885089,
            "fpr": 0.11951754385964912,
            "logloss": 0.8020650291247576,
            "mae": 0.28258848153894023,
            "precision": 0.7614879649890591,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8330340198016843,
            "auditor_fn_violation": 0.011394214697730883,
            "auditor_fp_violation": 0.01800415555904031,
            "ave_precision_score": 0.8333891800449468,
            "fpr": 0.1251372118551043,
            "logloss": 0.7785427939079074,
            "mae": 0.26470961545147503,
            "precision": 0.7553648068669528,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8482427617123556,
            "auditor_fn_violation": 0.0033363704577125163,
            "auditor_fp_violation": 0.006157019627453433,
            "ave_precision_score": 0.8485987234498704,
            "fpr": 0.08771929824561403,
            "logloss": 0.5362494274038061,
            "mae": 0.3039484590661136,
            "precision": 0.816933638443936,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8403022863264115,
            "auditor_fn_violation": 0.007411218299023455,
            "auditor_fp_violation": 0.009653834091265487,
            "ave_precision_score": 0.8407765163226166,
            "fpr": 0.09879253567508232,
            "logloss": 0.5184777582897839,
            "mae": 0.2927184589748177,
            "precision": 0.7949886104783599,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8346732216652701,
            "auditor_fn_violation": 0.027794154428841963,
            "auditor_fp_violation": 0.005865316497895577,
            "ave_precision_score": 0.8349196166354698,
            "fpr": 0.06359649122807018,
            "logloss": 0.6379878352872823,
            "mae": 0.3284451166861497,
            "precision": 0.8428184281842819,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8341934108346838,
            "auditor_fn_violation": 0.012717138501587278,
            "auditor_fp_violation": 0.012128547906539128,
            "ave_precision_score": 0.8345041265178585,
            "fpr": 0.07135016465422613,
            "logloss": 0.5714915214207968,
            "mae": 0.30400681981770755,
            "precision": 0.828042328042328,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8311659955876696,
            "auditor_fn_violation": 0.010880051452460068,
            "auditor_fp_violation": 0.017523023711297245,
            "ave_precision_score": 0.8314751113777595,
            "fpr": 0.12938596491228072,
            "logloss": 0.7559934803536309,
            "mae": 0.27799471696145994,
            "precision": 0.7611336032388664,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8271662941715237,
            "auditor_fn_violation": 0.01057390710609233,
            "auditor_fp_violation": 0.02108162145209346,
            "ave_precision_score": 0.8274900013284234,
            "fpr": 0.13611416026344675,
            "logloss": 0.7784239550597251,
            "mae": 0.27509695979826326,
            "precision": 0.740041928721174,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7927337915831533,
            "auditor_fn_violation": 0.019940061457105085,
            "auditor_fp_violation": 0.024075926157436346,
            "ave_precision_score": 0.7931104762623713,
            "fpr": 0.17214912280701755,
            "logloss": 0.9628737896552497,
            "mae": 0.29821094772775936,
            "precision": 0.7103321033210332,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7794279282590698,
            "auditor_fn_violation": 0.015784994061067877,
            "auditor_fp_violation": 0.03538350713501647,
            "ave_precision_score": 0.7810989889464848,
            "fpr": 0.17014270032930845,
            "logloss": 0.9801331998811094,
            "mae": 0.2878569544011803,
            "precision": 0.7053231939163498,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8693387563845267,
            "auditor_fn_violation": 0.009971147318397823,
            "auditor_fp_violation": 0.006696149518689838,
            "ave_precision_score": 0.8696648246642088,
            "fpr": 0.09868421052631579,
            "logloss": 0.6851948691719445,
            "mae": 0.2482285481002446,
            "precision": 0.8068669527896996,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8666345046633954,
            "auditor_fn_violation": 0.01239470545978715,
            "auditor_fp_violation": 0.013652579582875963,
            "ave_precision_score": 0.8668298839512789,
            "fpr": 0.10976948408342481,
            "logloss": 0.6934217770018997,
            "mae": 0.24359929443258002,
            "precision": 0.7787610619469026,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.851703436186554,
            "auditor_fn_violation": 0.004254207310537035,
            "auditor_fp_violation": 0.0031931074717673064,
            "ave_precision_score": 0.8519633966206115,
            "fpr": 0.07675438596491228,
            "logloss": 0.5481988247130253,
            "mae": 0.3306975201042429,
            "precision": 0.828009828009828,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8455192365089765,
            "auditor_fn_violation": 0.007536872352077917,
            "auditor_fp_violation": 0.015642151481888036,
            "ave_precision_score": 0.8457668604976455,
            "fpr": 0.07903402854006586,
            "logloss": 0.5168697285833442,
            "mae": 0.32378836802902616,
            "precision": 0.8195488721804511,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 20300,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8462462817939365,
            "auditor_fn_violation": 0.031177421660056454,
            "auditor_fp_violation": 0.007628557736383715,
            "ave_precision_score": 0.8464897379516315,
            "fpr": 0.08223684210526316,
            "logloss": 0.554851488506035,
            "mae": 0.31935192529865736,
            "precision": 0.8210023866348448,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8445622408101977,
            "auditor_fn_violation": 0.016252047805440113,
            "auditor_fp_violation": 0.016671240395170144,
            "ave_precision_score": 0.8448594445364825,
            "fpr": 0.09220636663007684,
            "logloss": 0.5125592250384663,
            "mae": 0.30052983340358463,
            "precision": 0.8018867924528302,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.779002687325269,
            "auditor_fn_violation": 0.011380283703147896,
            "auditor_fp_violation": 0.014676313705879903,
            "ave_precision_score": 0.7480424841135629,
            "fpr": 0.14692982456140352,
            "logloss": 3.563100635442079,
            "mae": 0.2961199025548316,
            "precision": 0.7325349301397206,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7921585587038497,
            "auditor_fn_violation": 0.004101537958192768,
            "auditor_fp_violation": 0.02232632899482516,
            "ave_precision_score": 0.7546167235800533,
            "fpr": 0.14489571899012074,
            "logloss": 3.642455376607592,
            "mae": 0.27508824774145524,
            "precision": 0.7327935222672065,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8188296591704548,
            "auditor_fn_violation": 0.013544234823310821,
            "auditor_fp_violation": 0.008224986456640413,
            "ave_precision_score": 0.8192980039413331,
            "fpr": 0.10855263157894737,
            "logloss": 0.8471043524094121,
            "mae": 0.2932998693285447,
            "precision": 0.7729357798165137,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8263166028418448,
            "auditor_fn_violation": 0.004895766406744546,
            "auditor_fp_violation": 0.015556394072447865,
            "ave_precision_score": 0.8266597833384839,
            "fpr": 0.11525795828759605,
            "logloss": 0.8128776051444115,
            "mae": 0.2713275845817956,
            "precision": 0.7619047619047619,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.861413077156413,
            "auditor_fn_violation": 0.012981473541287031,
            "auditor_fp_violation": 0.012566675001041796,
            "ave_precision_score": 0.8617176185805444,
            "fpr": 0.13157894736842105,
            "logloss": 0.5467360877557147,
            "mae": 0.2782575728755897,
            "precision": 0.7633136094674556,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8539984343174818,
            "auditor_fn_violation": 0.013224496376184525,
            "auditor_fp_violation": 0.01672024462913596,
            "ave_precision_score": 0.8542387707515273,
            "fpr": 0.12733260153677278,
            "logloss": 0.5397830548136336,
            "mae": 0.2676385085713675,
            "precision": 0.7618069815195072,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.835923151743956,
            "auditor_fn_violation": 0.013434809018472865,
            "auditor_fp_violation": 0.01656977955577781,
            "ave_precision_score": 0.8362786260516388,
            "fpr": 0.11951754385964912,
            "logloss": 0.7296766914875129,
            "mae": 0.2795403064077991,
            "precision": 0.7680851063829788,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.833189144329985,
            "auditor_fn_violation": 0.009360041536962441,
            "auditor_fp_violation": 0.0200133291516387,
            "ave_precision_score": 0.8334616581145902,
            "fpr": 0.11855104281009879,
            "logloss": 0.7456236033744914,
            "mae": 0.2703482572705588,
            "precision": 0.7641921397379913,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8177051312750117,
            "auditor_fn_violation": 0.012637563868939154,
            "auditor_fp_violation": 0.007847335083552108,
            "ave_precision_score": 0.8181929112248574,
            "fpr": 0.10964912280701754,
            "logloss": 0.8546677742433892,
            "mae": 0.29069135548697156,
            "precision": 0.771689497716895,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8241550300590439,
            "auditor_fn_violation": 0.0040138172041736175,
            "auditor_fp_violation": 0.013976007527050341,
            "ave_precision_score": 0.8245061062340361,
            "fpr": 0.1141602634467618,
            "logloss": 0.8295731256958184,
            "mae": 0.27031905363021785,
            "precision": 0.7683741648106904,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8277782267130516,
            "auditor_fn_violation": 0.016996730624933006,
            "auditor_fp_violation": 0.015551423094553488,
            "ave_precision_score": 0.8281132492434167,
            "fpr": 0.12609649122807018,
            "logloss": 0.7668625380080524,
            "mae": 0.28683651372951746,
            "precision": 0.7578947368421053,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8314812247406504,
            "auditor_fn_violation": 0.010019132607700936,
            "auditor_fp_violation": 0.022733064136741418,
            "ave_precision_score": 0.8317857398195978,
            "fpr": 0.12843029637760703,
            "logloss": 0.7625140281530434,
            "mae": 0.27163255545863235,
            "precision": 0.7478448275862069,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8415652493709171,
            "auditor_fn_violation": 0.012048004430628513,
            "auditor_fp_violation": 0.014673709213651707,
            "ave_precision_score": 0.8419219510302915,
            "fpr": 0.10855263157894737,
            "logloss": 0.7236781804652112,
            "mae": 0.2743257480163953,
            "precision": 0.7819383259911894,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8405705551203564,
            "auditor_fn_violation": 0.004535400065909115,
            "auditor_fp_violation": 0.01756801787674455,
            "ave_precision_score": 0.8408362784197161,
            "fpr": 0.11306256860592755,
            "logloss": 0.7229328356735172,
            "mae": 0.2621862927693173,
            "precision": 0.7706013363028953,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8287013356771802,
            "auditor_fn_violation": 0.011331153749955344,
            "auditor_fp_violation": 0.014241363503771304,
            "ave_precision_score": 0.8290830453852449,
            "fpr": 0.14473684210526316,
            "logloss": 0.758437549999964,
            "mae": 0.27407824909040274,
            "precision": 0.7446808510638298,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8325946664616635,
            "auditor_fn_violation": 0.010303632350465754,
            "auditor_fp_violation": 0.024999509957660343,
            "ave_precision_score": 0.8328761847600727,
            "fpr": 0.14818880351262348,
            "logloss": 0.7668384430993754,
            "mae": 0.2717425061686747,
            "precision": 0.7294589178356713,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7962772939862246,
            "auditor_fn_violation": 0.016923035695144178,
            "auditor_fp_violation": 0.015624348876942954,
            "ave_precision_score": 0.7967763843007939,
            "fpr": 0.12719298245614036,
            "logloss": 0.8999480752436706,
            "mae": 0.3013114232704267,
            "precision": 0.7505376344086021,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8012614982799455,
            "auditor_fn_violation": 0.013452096170396388,
            "auditor_fp_violation": 0.02227242433746276,
            "ave_precision_score": 0.802089837114426,
            "fpr": 0.11745334796926454,
            "logloss": 0.858391875231971,
            "mae": 0.28100683934055026,
            "precision": 0.7579185520361991,
            "recall": 0.7235421166306696
        }
    }
]