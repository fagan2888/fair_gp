[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7517160384770785,
            "auditor_fn_violation": 0.008053299209969956,
            "auditor_fp_violation": 0.01905746713024019,
            "ave_precision_score": 0.7483114961284654,
            "fpr": 0.2730263157894737,
            "logloss": 1.9789719988143544,
            "mae": 0.3345239678069314,
            "precision": 0.6300148588410104,
            "recall": 0.8964059196617337
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7945074494378397,
            "auditor_fn_violation": 0.007266237782154359,
            "auditor_fp_violation": 0.014959283179741155,
            "ave_precision_score": 0.7901840615826382,
            "fpr": 0.27661909989023054,
            "logloss": 1.834916356875658,
            "mae": 0.3261108768415729,
            "precision": 0.637410071942446,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.653154270867686,
            "auditor_fn_violation": 0.012531990653165695,
            "auditor_fp_violation": 0.04105223194660912,
            "ave_precision_score": 0.643628661408201,
            "fpr": 0.1600877192982456,
            "logloss": 1.6875404074495806,
            "mae": 0.36451824985123304,
            "precision": 0.6977225672877847,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6684025401207455,
            "auditor_fn_violation": 0.018927819147358117,
            "auditor_fp_violation": 0.045909172133867714,
            "ave_precision_score": 0.6577952820456843,
            "fpr": 0.15148188803512624,
            "logloss": 1.821255803210543,
            "mae": 0.3385393102241903,
            "precision": 0.7250996015936255,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8142630041233341,
            "auditor_fn_violation": 0.017877675160416905,
            "auditor_fp_violation": 0.019187347640171045,
            "ave_precision_score": 0.8145528626748836,
            "fpr": 0.1162280701754386,
            "logloss": 1.223218923084981,
            "mae": 0.3065439920943977,
            "precision": 0.7511737089201878,
            "recall": 0.6765327695560254
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8347243053924609,
            "auditor_fn_violation": 0.011125285548995766,
            "auditor_fp_violation": 0.020274168432338598,
            "ave_precision_score": 0.8351511514236799,
            "fpr": 0.1141602634467618,
            "logloss": 1.0506058490297288,
            "mae": 0.2997418094725873,
            "precision": 0.7575757575757576,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7694803824223116,
            "auditor_fn_violation": 0.006720355328066469,
            "auditor_fp_violation": 0.016834512248731174,
            "ave_precision_score": 0.7322548299111098,
            "fpr": 0.14144736842105263,
            "logloss": 4.086435069522714,
            "mae": 0.2905117910787911,
            "precision": 0.734020618556701,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8010773642814538,
            "auditor_fn_violation": 0.006225595687725218,
            "auditor_fp_violation": 0.014231741250351006,
            "ave_precision_score": 0.7685641048157115,
            "fpr": 0.13062568605927552,
            "logloss": 3.5207066241112366,
            "mae": 0.27277413080379653,
            "precision": 0.7531120331950207,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6913039567988768,
            "auditor_fn_violation": 0.009418697377693705,
            "auditor_fp_violation": 0.02902080086320586,
            "ave_precision_score": 0.6802730914325832,
            "fpr": 0.2774122807017544,
            "logloss": 2.3088469873280886,
            "mae": 0.3276273591767725,
            "precision": 0.6306569343065693,
            "recall": 0.9133192389006343
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7008780308613574,
            "auditor_fn_violation": 0.0048700224331398876,
            "auditor_fp_violation": 0.03683659663543768,
            "ave_precision_score": 0.6864240447544173,
            "fpr": 0.27442371020856204,
            "logloss": 2.5827253551383738,
            "mae": 0.31480508612218144,
            "precision": 0.6428571428571429,
            "recall": 0.9355509355509356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7514490040262415,
            "auditor_fn_violation": 0.011022866362523646,
            "auditor_fp_violation": 0.020006593933581118,
            "ave_precision_score": 0.7479925971191124,
            "fpr": 0.2730263157894737,
            "logloss": 1.981978658935839,
            "mae": 0.3344128765074348,
            "precision": 0.6294642857142857,
            "recall": 0.8942917547568711
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7945584388971618,
            "auditor_fn_violation": 0.005518141632301898,
            "auditor_fp_violation": 0.014959283179741155,
            "ave_precision_score": 0.7902576671169619,
            "fpr": 0.27661909989023054,
            "logloss": 1.8337350697394605,
            "mae": 0.3257949061013374,
            "precision": 0.6368876080691642,
            "recall": 0.918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8505168078677161,
            "auditor_fn_violation": 0.0160509625013909,
            "auditor_fp_violation": 0.01411951005075331,
            "ave_precision_score": 0.8513393926462374,
            "fpr": 0.10855263157894737,
            "logloss": 0.5002442976777316,
            "mae": 0.3036634109241213,
            "precision": 0.7824175824175824,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.886454204758574,
            "auditor_fn_violation": 0.02153855282285579,
            "auditor_fp_violation": 0.010798253899369465,
            "ave_precision_score": 0.886672432764908,
            "fpr": 0.09879253567508232,
            "logloss": 0.46667053470020525,
            "mae": 0.28615540677963214,
            "precision": 0.8097251585623678,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8037759792041403,
            "auditor_fn_violation": 0.00863747635473462,
            "auditor_fp_violation": 0.016802042121248455,
            "ave_precision_score": 0.8042159293006691,
            "fpr": 0.13706140350877194,
            "logloss": 0.9721943130649021,
            "mae": 0.27963122282111985,
            "precision": 0.7390396659707724,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8426591904165222,
            "auditor_fn_violation": 0.009507269660946942,
            "auditor_fp_violation": 0.018119623209863944,
            "ave_precision_score": 0.8428917914485973,
            "fpr": 0.12843029637760703,
            "logloss": 0.8349433199474043,
            "mae": 0.2659567716105932,
            "precision": 0.7572614107883817,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7884575522749674,
            "auditor_fn_violation": 0.012937669225918923,
            "auditor_fp_violation": 0.02119300243775727,
            "ave_precision_score": 0.7888301107245678,
            "fpr": 0.20942982456140352,
            "logloss": 1.1493243152846535,
            "mae": 0.2937791988324118,
            "precision": 0.676271186440678,
            "recall": 0.8435517970401691
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8254874403371084,
            "auditor_fn_violation": 0.009450216914541835,
            "auditor_fp_violation": 0.024976386797028585,
            "ave_precision_score": 0.8257590548721163,
            "fpr": 0.1964873765093304,
            "logloss": 1.021724293757634,
            "mae": 0.2776653504951901,
            "precision": 0.7021630615640599,
            "recall": 0.8773388773388774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8444723765622164,
            "auditor_fn_violation": 0.01717758985200846,
            "auditor_fp_violation": 0.017224153778523762,
            "ave_precision_score": 0.845740690253945,
            "fpr": 0.12390350877192982,
            "logloss": 0.5876786759706975,
            "mae": 0.274073224926808,
            "precision": 0.7660455486542443,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.88237203654977,
            "auditor_fn_violation": 0.014959230107418913,
            "auditor_fp_violation": 0.012615832333495012,
            "ave_precision_score": 0.8825204046088049,
            "fpr": 0.1119648737650933,
            "logloss": 0.519396535901831,
            "mae": 0.26091808336420236,
            "precision": 0.7888198757763976,
            "recall": 0.7920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6873027585408712,
            "auditor_fn_violation": 0.009557787174066246,
            "auditor_fp_violation": 0.025274247692123254,
            "ave_precision_score": 0.6798425111691494,
            "fpr": 0.17543859649122806,
            "logloss": 1.567288499982326,
            "mae": 0.3161839966064587,
            "precision": 0.6992481203007519,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.708981710835509,
            "auditor_fn_violation": 0.018033232083726047,
            "auditor_fp_violation": 0.044351977127102864,
            "ave_precision_score": 0.700108402235128,
            "fpr": 0.16136114160263446,
            "logloss": 1.5985521812476895,
            "mae": 0.2890385785622219,
            "precision": 0.7317518248175182,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 9296,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.4266905589455756,
            "auditor_fn_violation": 0.019620933941619373,
            "auditor_fp_violation": 0.021297905926547574,
            "ave_precision_score": 0.4217527943638739,
            "fpr": 0.41118421052631576,
            "logloss": 4.721846957917606,
            "mae": 0.5149775689594501,
            "precision": 0.5059288537549407,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.42953544749080835,
            "auditor_fn_violation": 0.021675479414228052,
            "auditor_fp_violation": 0.018928854057641747,
            "ave_precision_score": 0.42628514065300355,
            "fpr": 0.4226125137211855,
            "logloss": 4.467521982556444,
            "mae": 0.5280417696542926,
            "precision": 0.5038659793814433,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8320008064818698,
            "auditor_fn_violation": 0.015856236786469337,
            "auditor_fp_violation": 0.0062142828597690145,
            "ave_precision_score": 0.8328261248990406,
            "fpr": 0.044956140350877194,
            "logloss": 0.6225119926432306,
            "mae": 0.3525604558797153,
            "precision": 0.8503649635036497,
            "recall": 0.492600422832981
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8738814800145205,
            "auditor_fn_violation": 0.010445216811846894,
            "auditor_fp_violation": 0.007071196997932251,
            "ave_precision_score": 0.8740813543854815,
            "fpr": 0.029637760702524697,
            "logloss": 0.5786404721184216,
            "mae": 0.3365218149059535,
            "precision": 0.90625,
            "recall": 0.5426195426195426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7547897700096066,
            "auditor_fn_violation": 0.08101053373391197,
            "auditor_fp_violation": 0.039241397913919195,
            "ave_precision_score": 0.7551843634323172,
            "fpr": 0.09429824561403509,
            "logloss": 1.4737175257062889,
            "mae": 0.35036465907410763,
            "precision": 0.7401812688821753,
            "recall": 0.5179704016913319
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7897323593251897,
            "auditor_fn_violation": 0.06658968349418405,
            "auditor_fp_violation": 0.03978760881219207,
            "ave_precision_score": 0.7901127161445994,
            "fpr": 0.0845225027442371,
            "logloss": 1.26544963822278,
            "mae": 0.3256818292788961,
            "precision": 0.7793696275071633,
            "recall": 0.5654885654885655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.6728178588861575,
            "auditor_fn_violation": 0.0015114424539149148,
            "auditor_fp_violation": 0.03497532270311314,
            "ave_precision_score": 0.653235997531668,
            "fpr": 0.14473684210526316,
            "logloss": 2.389960597390362,
            "mae": 0.33189729259111955,
            "precision": 0.7322515212981744,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.6848856949868536,
            "auditor_fn_violation": 0.011615939168079677,
            "auditor_fp_violation": 0.04157455390192224,
            "ave_precision_score": 0.6590474193265002,
            "fpr": 0.14928649835345773,
            "logloss": 2.7783753877821593,
            "mae": 0.31837913956132924,
            "precision": 0.7379576107899807,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7816699756013674,
            "auditor_fn_violation": 0.01160472534401543,
            "auditor_fp_violation": 0.030626823322543264,
            "ave_precision_score": 0.7817774642222661,
            "fpr": 0.22697368421052633,
            "logloss": 1.307847266965554,
            "mae": 0.31054715131785715,
            "precision": 0.6555740432612313,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8112897906374632,
            "auditor_fn_violation": 0.01391858801298977,
            "auditor_fp_violation": 0.03152681694023946,
            "ave_precision_score": 0.8115778736163946,
            "fpr": 0.20856201975850713,
            "logloss": 1.1834540235346667,
            "mae": 0.28695783787357076,
            "precision": 0.6890343698854338,
            "recall": 0.8752598752598753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8372052709849273,
            "auditor_fn_violation": 0.016530822298876157,
            "auditor_fp_violation": 0.01918484993805699,
            "ave_precision_score": 0.8380173544384444,
            "fpr": 0.11842105263157894,
            "logloss": 0.6080608262602205,
            "mae": 0.2708789281102412,
            "precision": 0.7726315789473684,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8751936114977027,
            "auditor_fn_violation": 0.015285571816856127,
            "auditor_fp_violation": 0.02255635258979399,
            "ave_precision_score": 0.8753517198620179,
            "fpr": 0.1163556531284303,
            "logloss": 0.5676403564683606,
            "mae": 0.2628087753554331,
            "precision": 0.7777777777777778,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7829342690397285,
            "auditor_fn_violation": 0.008600385742368606,
            "auditor_fp_violation": 0.03074171761978979,
            "ave_precision_score": 0.7796703125262683,
            "fpr": 0.32346491228070173,
            "logloss": 2.2794165779651747,
            "mae": 0.3538473355321125,
            "precision": 0.6029609690444145,
            "recall": 0.9471458773784355
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8144001426455507,
            "auditor_fn_violation": 0.004071283983468397,
            "auditor_fp_violation": 0.02334516120797489,
            "ave_precision_score": 0.8111786608073599,
            "fpr": 0.3238199780461032,
            "logloss": 2.1168067473329533,
            "mae": 0.34256728784674256,
            "precision": 0.6087533156498673,
            "recall": 0.9542619542619543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.834196115697357,
            "auditor_fn_violation": 0.018628760060828604,
            "auditor_fp_violation": 0.023288574511449472,
            "ave_precision_score": 0.834726298048805,
            "fpr": 0.12280701754385964,
            "logloss": 0.6308135835797891,
            "mae": 0.27397288213206633,
            "precision": 0.7647058823529411,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.874255530162756,
            "auditor_fn_violation": 0.01904192464016833,
            "auditor_fp_violation": 0.021080846501416794,
            "ave_precision_score": 0.8744231529389495,
            "fpr": 0.11964873765093303,
            "logloss": 0.5665883565915419,
            "mae": 0.26073423413313407,
            "precision": 0.7719665271966527,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.671630130475612,
            "auditor_fn_violation": 0.008630521864915995,
            "auditor_fp_violation": 0.03950615433800904,
            "ave_precision_score": 0.6520476586418603,
            "fpr": 0.14364035087719298,
            "logloss": 2.3893580054500947,
            "mae": 0.340299983815241,
            "precision": 0.7282157676348547,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.6831958531759124,
            "auditor_fn_violation": 0.01812908069768663,
            "auditor_fp_violation": 0.046544814030071734,
            "ave_precision_score": 0.6573590781310412,
            "fpr": 0.1394072447859495,
            "logloss": 2.7812776980508427,
            "mae": 0.3254771130527528,
            "precision": 0.7495069033530573,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7802795126923764,
            "auditor_fn_violation": 0.012610808204443455,
            "auditor_fp_violation": 0.01668215241977381,
            "ave_precision_score": 0.7772573982177082,
            "fpr": 0.1513157894736842,
            "logloss": 1.1854236236918572,
            "mae": 0.28419336592508193,
            "precision": 0.7272727272727273,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8128637174492654,
            "auditor_fn_violation": 0.007720377643539011,
            "auditor_fp_violation": 0.019247951395093565,
            "ave_precision_score": 0.8112246396178088,
            "fpr": 0.14050493962678376,
            "logloss": 1.042777562712815,
            "mae": 0.2688396908675396,
            "precision": 0.7445109780439122,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8002908511364759,
            "auditor_fn_violation": 0.018269444753532885,
            "auditor_fp_violation": 0.013205351077009153,
            "ave_precision_score": 0.8006992024951457,
            "fpr": 0.13157894736842105,
            "logloss": 0.924265019126319,
            "mae": 0.289359913963122,
            "precision": 0.7424892703862661,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8365503163998081,
            "auditor_fn_violation": 0.016082028156671407,
            "auditor_fp_violation": 0.018637837285885687,
            "ave_precision_score": 0.8368848860387852,
            "fpr": 0.11745334796926454,
            "logloss": 0.80523021963067,
            "mae": 0.2662097733869639,
            "precision": 0.7708779443254818,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7929344208715986,
            "auditor_fn_violation": 0.011356681873817743,
            "auditor_fp_violation": 0.014881309195540109,
            "ave_precision_score": 0.7934937103019275,
            "fpr": 0.125,
            "logloss": 0.9512258332384699,
            "mae": 0.29225015942524835,
            "precision": 0.7477876106194691,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8286168623332388,
            "auditor_fn_violation": 0.013384574306637973,
            "auditor_fp_violation": 0.016812600515661302,
            "ave_precision_score": 0.8289052983645543,
            "fpr": 0.1163556531284303,
            "logloss": 0.8587459833291644,
            "mae": 0.27620294855157707,
            "precision": 0.7644444444444445,
            "recall": 0.7151767151767152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7470903209620778,
            "auditor_fn_violation": 0.013593709432142725,
            "auditor_fp_violation": 0.02409033689006115,
            "ave_precision_score": 0.7445683342442277,
            "fpr": 0.23903508771929824,
            "logloss": 1.7653225079358812,
            "mae": 0.32503987586707206,
            "precision": 0.646677471636953,
            "recall": 0.8435517970401691
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7908959406722972,
            "auditor_fn_violation": 0.007168107058337577,
            "auditor_fp_violation": 0.013810532764914622,
            "ave_precision_score": 0.7896056994906129,
            "fpr": 0.24039517014270034,
            "logloss": 1.541212974663517,
            "mae": 0.31549645219531186,
            "precision": 0.6562009419152276,
            "recall": 0.8690228690228691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6716379805219725,
            "auditor_fn_violation": 0.09864248358740403,
            "auditor_fp_violation": 0.03628411861087799,
            "ave_precision_score": 0.6728127862160734,
            "fpr": 0.0800438596491228,
            "logloss": 8.78192673323742,
            "mae": 0.3884035755969399,
            "precision": 0.7296296296296296,
            "recall": 0.4164904862579281
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6955461418830193,
            "auditor_fn_violation": 0.09770396927367289,
            "auditor_fp_violation": 0.038230413805427216,
            "ave_precision_score": 0.6901887966899505,
            "fpr": 0.07903402854006586,
            "logloss": 8.248076049753465,
            "mae": 0.3826636425643848,
            "precision": 0.7473684210526316,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7914116900148295,
            "auditor_fn_violation": 0.011071547791254036,
            "auditor_fp_violation": 0.02527424769212325,
            "ave_precision_score": 0.791902014685107,
            "fpr": 0.17214912280701755,
            "logloss": 1.1720678460739575,
            "mae": 0.2857370521229434,
            "precision": 0.70817843866171,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8280969092968277,
            "auditor_fn_violation": 0.008959563295457917,
            "auditor_fp_violation": 0.024491358844101807,
            "ave_precision_score": 0.8283816219229797,
            "fpr": 0.15806805708013172,
            "logloss": 1.0242400698403715,
            "mae": 0.26636112369354575,
            "precision": 0.7303370786516854,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7873366984531793,
            "auditor_fn_violation": 0.011678906568747448,
            "auditor_fp_violation": 0.03292970467170203,
            "ave_precision_score": 0.7865062088134629,
            "fpr": 0.2576754385964912,
            "logloss": 1.5876189179270144,
            "mae": 0.31724942746907564,
            "precision": 0.6406727828746177,
            "recall": 0.8858350951374208
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8239290217691855,
            "auditor_fn_violation": 0.011113874999714737,
            "auditor_fp_violation": 0.02371531411941899,
            "ave_precision_score": 0.8231823918525656,
            "fpr": 0.2414928649835346,
            "logloss": 1.4040757219925364,
            "mae": 0.29269940472572215,
            "precision": 0.6671709531013615,
            "recall": 0.9168399168399168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7696400043648417,
            "auditor_fn_violation": 0.010556915544675643,
            "auditor_fp_violation": 0.013150401630499946,
            "ave_precision_score": 0.7190873112020347,
            "fpr": 0.14144736842105263,
            "logloss": 4.8571698001007695,
            "mae": 0.2895222359834922,
            "precision": 0.7318087318087318,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7977876762757186,
            "auditor_fn_violation": 0.015753404337378,
            "auditor_fp_violation": 0.020299696219334754,
            "ave_precision_score": 0.746481433400296,
            "fpr": 0.12733260153677278,
            "logloss": 4.48963743602495,
            "mae": 0.2747118334161794,
            "precision": 0.7568134171907757,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6728121639157274,
            "auditor_fn_violation": 0.11065984199399134,
            "auditor_fp_violation": 0.04970427206969588,
            "ave_precision_score": 0.6739177868221905,
            "fpr": 0.10964912280701754,
            "logloss": 8.848576278597957,
            "mae": 0.3909163881148115,
            "precision": 0.6884735202492211,
            "recall": 0.46723044397463004
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6999841343462241,
            "auditor_fn_violation": 0.1091715713010993,
            "auditor_fp_violation": 0.05734562070814082,
            "ave_precision_score": 0.6945761723864139,
            "fpr": 0.11855104281009879,
            "logloss": 8.293561179742799,
            "mae": 0.3831878599039292,
            "precision": 0.6878612716763006,
            "recall": 0.49480249480249483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7865595300315598,
            "auditor_fn_violation": 0.020986332109343125,
            "auditor_fp_violation": 0.020074031890660596,
            "ave_precision_score": 0.786968770747016,
            "fpr": 0.10964912280701754,
            "logloss": 1.2205226199394645,
            "mae": 0.29948750289126796,
            "precision": 0.7578692493946732,
            "recall": 0.6617336152219874
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8200971529693389,
            "auditor_fn_violation": 0.018281982058052315,
            "auditor_fp_violation": 0.013703316059530802,
            "ave_precision_score": 0.8203912258417123,
            "fpr": 0.1141602634467618,
            "logloss": 1.0660960405220863,
            "mae": 0.2842282145050684,
            "precision": 0.7614678899082569,
            "recall": 0.6902286902286903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7909129034795964,
            "auditor_fn_violation": 0.009256425948592415,
            "auditor_fp_violation": 0.024090336890061154,
            "ave_precision_score": 0.7926249755320682,
            "fpr": 0.17763157894736842,
            "logloss": 1.0846711990974847,
            "mae": 0.28456829033756886,
            "precision": 0.7022058823529411,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8324967581471618,
            "auditor_fn_violation": 0.011768840528445363,
            "auditor_fp_violation": 0.021085952058816016,
            "ave_precision_score": 0.8327624156473585,
            "fpr": 0.16465422612513722,
            "logloss": 0.9571334705537181,
            "mae": 0.27085321091665976,
            "precision": 0.7201492537313433,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7899473977990753,
            "auditor_fn_violation": 0.016693093727977452,
            "auditor_fp_violation": 0.015660592255125293,
            "ave_precision_score": 0.7903481683220882,
            "fpr": 0.13815789473684212,
            "logloss": 1.2750688552006681,
            "mae": 0.3066736630642952,
            "precision": 0.7272727272727273,
            "recall": 0.7103594080338267
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8150198231874906,
            "auditor_fn_violation": 0.01613451668336411,
            "auditor_fp_violation": 0.02690628749393715,
            "ave_precision_score": 0.8153217333254638,
            "fpr": 0.13172338090010977,
            "logloss": 1.0776694250062555,
            "mae": 0.2913856300014221,
            "precision": 0.7391304347826086,
            "recall": 0.7068607068607069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8155499321759003,
            "auditor_fn_violation": 0.010577779014131521,
            "auditor_fp_violation": 0.01897254525836231,
            "ave_precision_score": 0.8168647605596362,
            "fpr": 0.14364035087719298,
            "logloss": 1.0649097307714037,
            "mae": 0.2793468809801471,
            "precision": 0.7342799188640974,
            "recall": 0.7653276955602537
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8588449954393171,
            "auditor_fn_violation": 0.011273622689649043,
            "auditor_fp_violation": 0.019253056952492794,
            "ave_precision_score": 0.8590218538324128,
            "fpr": 0.13611416026344675,
            "logloss": 0.9056129689651012,
            "mae": 0.2684984039953966,
            "precision": 0.7459016393442623,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7753037742094491,
            "auditor_fn_violation": 0.008908701457661074,
            "auditor_fp_violation": 0.014119510050753311,
            "ave_precision_score": 0.7339358943685238,
            "fpr": 0.13925438596491227,
            "logloss": 4.402765133493005,
            "mae": 0.2884163309836389,
            "precision": 0.7365145228215768,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8090044441393999,
            "auditor_fn_violation": 0.007448806570650706,
            "auditor_fp_violation": 0.021471421642457824,
            "ave_precision_score": 0.7727285040359421,
            "fpr": 0.132821075740944,
            "logloss": 3.8646903938349566,
            "mae": 0.27406102866719895,
            "precision": 0.75,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7904355488361864,
            "auditor_fn_violation": 0.009434924520603839,
            "auditor_fp_violation": 0.024672301482635977,
            "ave_precision_score": 0.7910396356960975,
            "fpr": 0.1600877192982456,
            "logloss": 0.9523974748889483,
            "mae": 0.2887527723209656,
            "precision": 0.7192307692307692,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8271600596982898,
            "auditor_fn_violation": 0.006467499332482872,
            "auditor_fp_violation": 0.018431062211216907,
            "ave_precision_score": 0.8274445714914798,
            "fpr": 0.14818880351262348,
            "logloss": 0.8568052380059172,
            "mae": 0.2764246807190978,
            "precision": 0.736328125,
            "recall": 0.7837837837837838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6859292413379952,
            "auditor_fn_violation": 0.007420440636474908,
            "auditor_fp_violation": 0.01791851496623107,
            "ave_precision_score": 0.6750613506273856,
            "fpr": 0.16557017543859648,
            "logloss": 2.152961607052016,
            "mae": 0.3136312349698393,
            "precision": 0.6998011928429424,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6899329874979989,
            "auditor_fn_violation": 0.0040895408623180364,
            "auditor_fp_violation": 0.03847803333928982,
            "ave_precision_score": 0.6774384136173837,
            "fpr": 0.16355653128430298,
            "logloss": 2.3601601900576816,
            "mae": 0.30432869998439455,
            "precision": 0.708984375,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7101871648736601,
            "auditor_fn_violation": 0.006706446348429217,
            "auditor_fp_violation": 0.015540702553650643,
            "ave_precision_score": 0.7065859742822114,
            "fpr": 0.1524122807017544,
            "logloss": 1.6389921080627672,
            "mae": 0.3145780521891668,
            "precision": 0.7104166666666667,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.723365167950579,
            "auditor_fn_violation": 0.006102361755490186,
            "auditor_fp_violation": 0.03200673933576699,
            "ave_precision_score": 0.7193242963022397,
            "fpr": 0.15148188803512624,
            "logloss": 1.5572892079478164,
            "mae": 0.29826213969358945,
            "precision": 0.7195121951219512,
            "recall": 0.735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6872333528022194,
            "auditor_fn_violation": 0.010605596973406033,
            "auditor_fp_violation": 0.028506274227710512,
            "ave_precision_score": 0.6787999576277355,
            "fpr": 0.16557017543859648,
            "logloss": 1.6058834849372734,
            "mae": 0.3189047982997896,
            "precision": 0.702755905511811,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7065274838982062,
            "auditor_fn_violation": 0.017551706904066953,
            "auditor_fp_violation": 0.04336149899165242,
            "ave_precision_score": 0.6954873658108875,
            "fpr": 0.15148188803512624,
            "logloss": 1.7488835789838206,
            "mae": 0.29222017490537494,
            "precision": 0.7351247600767754,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6800658351602153,
            "auditor_fn_violation": 0.010332053707206709,
            "auditor_fp_violation": 0.018950065939335816,
            "ave_precision_score": 0.6680750071608907,
            "fpr": 0.16776315789473684,
            "logloss": 2.2944418901909316,
            "mae": 0.3156729970376998,
            "precision": 0.6964285714285714,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6890733625720845,
            "auditor_fn_violation": 0.005381215040929645,
            "auditor_fp_violation": 0.039159625252086896,
            "ave_precision_score": 0.6733755115299332,
            "fpr": 0.1668496158068057,
            "logloss": 2.5324440754877475,
            "mae": 0.3075380145834794,
            "precision": 0.7037037037037037,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6807283545878302,
            "auditor_fn_violation": 0.01682754719780424,
            "auditor_fp_violation": 0.02954781600927147,
            "ave_precision_score": 0.670073326676366,
            "fpr": 0.16666666666666666,
            "logloss": 1.784610391218437,
            "mae": 0.3186560878480514,
            "precision": 0.703125,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.6930314446956665,
            "auditor_fn_violation": 0.019767635574441285,
            "auditor_fp_violation": 0.04439792714369592,
            "ave_precision_score": 0.6797000495475085,
            "fpr": 0.15587266739846323,
            "logloss": 2.0240923845225947,
            "mae": 0.29970580204039177,
            "precision": 0.7295238095238096,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6039657018329816,
            "auditor_fn_violation": 0.010719186973776936,
            "auditor_fp_violation": 0.030734224513447626,
            "ave_precision_score": 0.5865162655160265,
            "fpr": 0.2149122807017544,
            "logloss": 3.135407747084186,
            "mae": 0.35085472259881084,
            "precision": 0.6506238859180036,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6246118829462372,
            "auditor_fn_violation": 0.0015906305697743742,
            "auditor_fp_violation": 0.03027595537742833,
            "ave_precision_score": 0.6036731452118256,
            "fpr": 0.21295279912184412,
            "logloss": 3.3061103588322056,
            "mae": 0.34561124078287075,
            "precision": 0.6548042704626335,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7935987198966744,
            "auditor_fn_violation": 0.01981334149326806,
            "auditor_fp_violation": 0.013477600607441152,
            "ave_precision_score": 0.7940514068189111,
            "fpr": 0.13267543859649122,
            "logloss": 0.9271291385181688,
            "mae": 0.2989920516881528,
            "precision": 0.7386609071274298,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8327443916999056,
            "auditor_fn_violation": 0.01913549114427271,
            "auditor_fp_violation": 0.018913537385444056,
            "ave_precision_score": 0.8330024524504168,
            "fpr": 0.12403951701427003,
            "logloss": 0.8122597763986164,
            "mae": 0.278569972294184,
            "precision": 0.7543478260869565,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8004102236262134,
            "auditor_fn_violation": 0.008681521456919254,
            "auditor_fp_violation": 0.02535916956400112,
            "ave_precision_score": 0.8008641856991241,
            "fpr": 0.20394736842105263,
            "logloss": 1.050181257928174,
            "mae": 0.2921105168745073,
            "precision": 0.6798623063683304,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8368742541939864,
            "auditor_fn_violation": 0.00785274001519886,
            "auditor_fp_violation": 0.02239297475301866,
            "ave_precision_score": 0.8371648830931884,
            "fpr": 0.18880351262349068,
            "logloss": 0.9074788054877668,
            "mae": 0.27515336488097036,
            "precision": 0.7024221453287197,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7496878074490174,
            "auditor_fn_violation": 0.040505266866955984,
            "auditor_fp_violation": 0.04801582544059466,
            "ave_precision_score": 0.7487348215632517,
            "fpr": 0.19298245614035087,
            "logloss": 1.5870638338622127,
            "mae": 0.3273713515642677,
            "precision": 0.6710280373831776,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7827563972608236,
            "auditor_fn_violation": 0.03647267972185646,
            "auditor_fp_violation": 0.0495443290021188,
            "ave_precision_score": 0.7828261619636876,
            "fpr": 0.19319429198682767,
            "logloss": 1.4304129500160205,
            "mae": 0.3004939160266975,
            "precision": 0.6906854130052724,
            "recall": 0.817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8359489371294963,
            "auditor_fn_violation": 0.018369125774266536,
            "auditor_fp_violation": 0.017111757183391287,
            "ave_precision_score": 0.8368187624564778,
            "fpr": 0.1206140350877193,
            "logloss": 0.6105784233274891,
            "mae": 0.27179667433516114,
            "precision": 0.7713097713097713,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8782337491284136,
            "auditor_fn_violation": 0.020032360317760976,
            "auditor_fp_violation": 0.021678196717126598,
            "ave_precision_score": 0.8783892121707217,
            "fpr": 0.12294182217343579,
            "logloss": 0.5539122433448116,
            "mae": 0.25960472898208153,
            "precision": 0.768595041322314,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6983875893927401,
            "auditor_fn_violation": 0.00899215533548459,
            "auditor_fp_violation": 0.038392179195140486,
            "ave_precision_score": 0.6793600809192095,
            "fpr": 0.17324561403508773,
            "logloss": 1.9225498011367528,
            "mae": 0.3419601678957797,
            "precision": 0.6932038834951456,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.716877098721332,
            "auditor_fn_violation": 0.02017156901898944,
            "auditor_fp_violation": 0.047711433895795574,
            "ave_precision_score": 0.6953601057129751,
            "fpr": 0.15148188803512624,
            "logloss": 2.021865012945111,
            "mae": 0.3134702586615397,
            "precision": 0.7396226415094339,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8543123862751104,
            "auditor_fn_violation": 0.010225418196654429,
            "auditor_fp_violation": 0.029677696519202334,
            "ave_precision_score": 0.8545268590310657,
            "fpr": 0.25877192982456143,
            "logloss": 0.721020974904858,
            "mae": 0.31761841019518516,
            "precision": 0.6482861400894188,
            "recall": 0.919661733615222
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8842510702350043,
            "auditor_fn_violation": 0.008690274332425816,
            "auditor_fp_violation": 0.03238199780461033,
            "ave_precision_score": 0.8844742878097023,
            "fpr": 0.23600439077936333,
            "logloss": 0.6413056821012676,
            "mae": 0.2939103404458706,
            "precision": 0.6766917293233082,
            "recall": 0.9355509355509356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7837465806332985,
            "auditor_fn_violation": 0.008373205741626795,
            "auditor_fp_violation": 0.03632158414258883,
            "ave_precision_score": 0.7813231352825041,
            "fpr": 0.3059210526315789,
            "logloss": 2.066917693754617,
            "mae": 0.34179430119464027,
            "precision": 0.6135734072022161,
            "recall": 0.9365750528541226
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8162859826569839,
            "auditor_fn_violation": 0.004840355005009232,
            "auditor_fp_violation": 0.025583948127536837,
            "ave_precision_score": 0.8142086507901165,
            "fpr": 0.29857299670691545,
            "logloss": 1.88849378267156,
            "mae": 0.32785127719168733,
            "precision": 0.6263736263736264,
            "recall": 0.9480249480249481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6922709976783965,
            "auditor_fn_violation": 0.012033585549497424,
            "auditor_fp_violation": 0.018492986452463736,
            "ave_precision_score": 0.6861049732045754,
            "fpr": 0.17982456140350878,
            "logloss": 1.671013795263283,
            "mae": 0.3143629928422899,
            "precision": 0.6911487758945386,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7066702678188299,
            "auditor_fn_violation": 0.008519116093210497,
            "auditor_fp_violation": 0.038654175069563215,
            "ave_precision_score": 0.6991124398308874,
            "fpr": 0.1778265642151482,
            "logloss": 1.705803756224788,
            "mae": 0.29453317086753783,
            "precision": 0.7032967032967034,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8239603825841768,
            "auditor_fn_violation": 0.01812340046734172,
            "auditor_fp_violation": 0.022529273068776726,
            "ave_precision_score": 0.8246924336718924,
            "fpr": 0.12171052631578948,
            "logloss": 0.6886591390285272,
            "mae": 0.27430893827063213,
            "precision": 0.7663157894736842,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8661944250992297,
            "auditor_fn_violation": 0.01525362227886926,
            "auditor_fp_violation": 0.023077119444515366,
            "ave_precision_score": 0.8663745892239144,
            "fpr": 0.12623490669593854,
            "logloss": 0.6200183684872982,
            "mae": 0.2635584642873259,
            "precision": 0.7604166666666666,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7789020444370863,
            "auditor_fn_violation": 0.01328307555357739,
            "auditor_fp_violation": 0.021700035966910447,
            "ave_precision_score": 0.754307971072602,
            "fpr": 0.15021929824561403,
            "logloss": 3.0825909695540004,
            "mae": 0.29254834521200135,
            "precision": 0.7270916334661355,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8120946831210138,
            "auditor_fn_violation": 0.008201902823198106,
            "auditor_fp_violation": 0.02246445255660787,
            "ave_precision_score": 0.7907020491417939,
            "fpr": 0.13721185510428102,
            "logloss": 2.627095033400794,
            "mae": 0.26499793756507806,
            "precision": 0.7549019607843137,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7917170251473779,
            "auditor_fn_violation": 0.00702635288008605,
            "auditor_fp_violation": 0.029655217200175856,
            "ave_precision_score": 0.7921224196761694,
            "fpr": 0.19078947368421054,
            "logloss": 1.0977578279216667,
            "mae": 0.2892413447443786,
            "precision": 0.6931216931216931,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.827066580357686,
            "auditor_fn_violation": 0.008188210164060877,
            "auditor_fp_violation": 0.023077119444515355,
            "ave_precision_score": 0.8273380846447815,
            "fpr": 0.18331503841931943,
            "logloss": 0.9485255900906998,
            "mae": 0.2700298699035789,
            "precision": 0.7095652173913043,
            "recall": 0.8482328482328483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7401172685192301,
            "auditor_fn_violation": 0.02975362560735878,
            "auditor_fp_violation": 0.028713583503177084,
            "ave_precision_score": 0.7418626831757078,
            "fpr": 0.14035087719298245,
            "logloss": 0.8200032675728489,
            "mae": 0.326171471645181,
            "precision": 0.7161862527716186,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7818878066843564,
            "auditor_fn_violation": 0.022241442658566705,
            "auditor_fp_violation": 0.04546498864013479,
            "ave_precision_score": 0.7827906911576936,
            "fpr": 0.12294182217343579,
            "logloss": 0.6975387711671711,
            "mae": 0.2993246796588637,
            "precision": 0.7591397849462366,
            "recall": 0.7338877338877339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7524738369855741,
            "auditor_fn_violation": 0.02888895070657617,
            "auditor_fp_violation": 0.005547396395316308,
            "ave_precision_score": 0.7543172475025354,
            "fpr": 0.13706140350877194,
            "logloss": 0.9235841314704601,
            "mae": 0.30676559705036877,
            "precision": 0.7300215982721382,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.786244985278052,
            "auditor_fn_violation": 0.014893048921588999,
            "auditor_fp_violation": 0.012860899088658008,
            "ave_precision_score": 0.7873164398201603,
            "fpr": 0.13391877058177826,
            "logloss": 0.8248268419360321,
            "mae": 0.29724478464198245,
            "precision": 0.7420718816067653,
            "recall": 0.7297297297297297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8591424865405233,
            "auditor_fn_violation": 0.02386780905752755,
            "auditor_fp_violation": 0.016307497102665547,
            "ave_precision_score": 0.8598708462399234,
            "fpr": 0.11074561403508772,
            "logloss": 0.4968028124786333,
            "mae": 0.2813554315253944,
            "precision": 0.7873684210526316,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8933318017630741,
            "auditor_fn_violation": 0.026426832134845316,
            "auditor_fp_violation": 0.018372348301125777,
            "ave_precision_score": 0.8934872689793771,
            "fpr": 0.09769484083424808,
            "logloss": 0.46480426732253105,
            "mae": 0.2686057419230986,
            "precision": 0.8073593073593074,
            "recall": 0.7754677754677755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7895938022439002,
            "auditor_fn_violation": 0.009692240643893034,
            "auditor_fp_violation": 0.018058386284618148,
            "ave_precision_score": 0.7910337745433981,
            "fpr": 0.13706140350877194,
            "logloss": 1.0791372270216495,
            "mae": 0.28689921598465656,
            "precision": 0.7357293868921776,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8292337642171006,
            "auditor_fn_violation": 0.011661581365203767,
            "auditor_fp_violation": 0.01446404411201593,
            "ave_precision_score": 0.8295069338335457,
            "fpr": 0.12184412733260154,
            "logloss": 0.9623355922807094,
            "mae": 0.27210708416746376,
            "precision": 0.7633262260127932,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6653536836224092,
            "auditor_fn_violation": 0.02141055598827937,
            "auditor_fp_violation": 0.026483135515325898,
            "ave_precision_score": 0.6507904636364481,
            "fpr": 0.1699561403508772,
            "logloss": 2.2832520998460097,
            "mae": 0.3211054527045625,
            "precision": 0.6912350597609562,
            "recall": 0.733615221987315
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6826031074071901,
            "auditor_fn_violation": 0.012086053798457756,
            "auditor_fp_violation": 0.035687846220611136,
            "ave_precision_score": 0.6661426181293133,
            "fpr": 0.17014270032930845,
            "logloss": 2.4370006029779945,
            "mae": 0.30795101612479053,
            "precision": 0.7024952015355086,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.674115803963238,
            "auditor_fn_violation": 0.11065984199399134,
            "auditor_fp_violation": 0.052951284817967466,
            "ave_precision_score": 0.6743663354723366,
            "fpr": 0.1162280701754386,
            "logloss": 8.924406880659344,
            "mae": 0.3940427400613991,
            "precision": 0.6758409785932722,
            "recall": 0.46723044397463004
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7017537817364945,
            "auditor_fn_violation": 0.11421731619316693,
            "auditor_fp_violation": 0.06000051055573993,
            "ave_precision_score": 0.6957973417782262,
            "fpr": 0.12403951701427003,
            "logloss": 8.373566216279665,
            "mae": 0.38442024827603416,
            "precision": 0.6878453038674033,
            "recall": 0.5176715176715176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8543002427157458,
            "auditor_fn_violation": 0.011699770038203333,
            "auditor_fp_violation": 0.024924569396155543,
            "ave_precision_score": 0.8545173624029841,
            "fpr": 0.2412280701754386,
            "logloss": 0.6852055472147989,
            "mae": 0.3096602428643229,
            "precision": 0.6625766871165644,
            "recall": 0.9133192389006343
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8844004873574025,
            "auditor_fn_violation": 0.004224185343834083,
            "auditor_fp_violation": 0.026681642968371083,
            "ave_precision_score": 0.8846211263694723,
            "fpr": 0.22283205268935236,
            "logloss": 0.6079799710155602,
            "mae": 0.28604325862079,
            "precision": 0.687211093990755,
            "recall": 0.9272349272349273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7761108186729506,
            "auditor_fn_violation": 0.012019676569860171,
            "auditor_fp_violation": 0.032904727650561495,
            "ave_precision_score": 0.7760517079028231,
            "fpr": 0.23684210526315788,
            "logloss": 1.4030088631624198,
            "mae": 0.3135849381253209,
            "precision": 0.6527331189710611,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8052839613197562,
            "auditor_fn_violation": 0.00806041201211344,
            "auditor_fp_violation": 0.02521634799479234,
            "ave_precision_score": 0.8054787123297139,
            "fpr": 0.2239297475301866,
            "logloss": 1.2676161281565963,
            "mae": 0.2925030320705941,
            "precision": 0.6772151898734177,
            "recall": 0.8898128898128899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8075121275842476,
            "auditor_fn_violation": 0.01269889840881273,
            "auditor_fp_violation": 0.019082444151380735,
            "ave_precision_score": 0.8080889559335576,
            "fpr": 0.12938596491228072,
            "logloss": 0.9865405569045778,
            "mae": 0.2823013209739352,
            "precision": 0.7484008528784648,
            "recall": 0.7420718816067653
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8432061683183198,
            "auditor_fn_violation": 0.005903818198000418,
            "auditor_fp_violation": 0.019630868200035737,
            "ave_precision_score": 0.843458440323667,
            "fpr": 0.12623490669593854,
            "logloss": 0.8546998368118709,
            "mae": 0.2685961672252982,
            "precision": 0.7599164926931107,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7840419714882265,
            "auditor_fn_violation": 0.015037925151144249,
            "auditor_fp_violation": 0.024377572633177476,
            "ave_precision_score": 0.7842130714664306,
            "fpr": 0.19846491228070176,
            "logloss": 1.2777309415988596,
            "mae": 0.3021308890538519,
            "precision": 0.6790780141843972,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8175946973403292,
            "auditor_fn_violation": 0.016218954748043666,
            "auditor_fp_violation": 0.03423786791923008,
            "ave_precision_score": 0.817857659900581,
            "fpr": 0.19099890230515917,
            "logloss": 1.1459466631014228,
            "mae": 0.2823612320215675,
            "precision": 0.7015437392795884,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.8449693740790325,
            "auditor_fn_violation": 0.008975928192574461,
            "auditor_fp_violation": 0.027429764616552787,
            "ave_precision_score": 0.8451960066576654,
            "fpr": 0.3519736842105263,
            "logloss": 0.8979426479690971,
            "mae": 0.3611704004551141,
            "precision": 0.5841968911917098,
            "recall": 0.9534883720930233
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8828532607538844,
            "auditor_fn_violation": 0.009578015066489271,
            "auditor_fp_violation": 0.020218007300947093,
            "ave_precision_score": 0.8830732937858036,
            "fpr": 0.34906695938529086,
            "logloss": 0.8235179412032333,
            "mae": 0.3448893671932515,
            "precision": 0.5917843388960206,
            "recall": 0.9584199584199584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8370691602349738,
            "auditor_fn_violation": 0.006180223285486446,
            "auditor_fp_violation": 0.018857650961115784,
            "ave_precision_score": 0.8375355507392626,
            "fpr": 0.14583333333333334,
            "logloss": 0.516753580320846,
            "mae": 0.3057348856592667,
            "precision": 0.7442307692307693,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8781114494925566,
            "auditor_fn_violation": 0.0045482449434150925,
            "auditor_fp_violation": 0.012740918489776126,
            "ave_precision_score": 0.8782798712576619,
            "fpr": 0.13062568605927552,
            "logloss": 0.46397301984549594,
            "mae": 0.2894424739417185,
            "precision": 0.7724665391969407,
            "recall": 0.83991683991684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7750811020719703,
            "auditor_fn_violation": 0.00863747635473462,
            "auditor_fp_violation": 0.01476141949406546,
            "ave_precision_score": 0.7327423961059824,
            "fpr": 0.14144736842105263,
            "logloss": 4.45415910262407,
            "mae": 0.2894212675533813,
            "precision": 0.7329192546583851,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8073663179457785,
            "auditor_fn_violation": 0.007448806570650706,
            "auditor_fp_violation": 0.021471421642457824,
            "ave_precision_score": 0.7687765917721865,
            "fpr": 0.132821075740944,
            "logloss": 3.9566131022257096,
            "mae": 0.27485150085049737,
            "precision": 0.75,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6695807193604977,
            "auditor_fn_violation": 0.02213382292941657,
            "auditor_fp_violation": 0.025456579946449266,
            "ave_precision_score": 0.655237477879765,
            "fpr": 0.16666666666666666,
            "logloss": 2.289256185338176,
            "mae": 0.316340769291792,
            "precision": 0.7019607843137254,
            "recall": 0.7568710359408034
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6884598272514226,
            "auditor_fn_violation": 0.010098336113703844,
            "auditor_fp_violation": 0.0432338600566717,
            "ave_precision_score": 0.670402006382264,
            "fpr": 0.1690450054884742,
            "logloss": 2.4844940235394364,
            "mae": 0.3048504089232121,
            "precision": 0.7044145873320538,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7863069961693763,
            "auditor_fn_violation": 0.01242767330588628,
            "auditor_fp_violation": 0.021997262518482996,
            "ave_precision_score": 0.7863465061738859,
            "fpr": 0.19956140350877194,
            "logloss": 1.2919148789383437,
            "mae": 0.30022513222787695,
            "precision": 0.6778761061946903,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8190470185172516,
            "auditor_fn_violation": 0.010554758084944698,
            "auditor_fp_violation": 0.028029510121767548,
            "ave_precision_score": 0.819381318075832,
            "fpr": 0.19209659714599342,
            "logloss": 1.1169168046063869,
            "mae": 0.2827280963224798,
            "precision": 0.6956521739130435,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7553071196058245,
            "auditor_fn_violation": 0.08041476577278292,
            "auditor_fp_violation": 0.039241397913919195,
            "ave_precision_score": 0.7557005944428128,
            "fpr": 0.09429824561403509,
            "logloss": 1.4729097537235776,
            "mae": 0.34959738518169003,
            "precision": 0.7409638554216867,
            "recall": 0.5200845665961945
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7899203626039646,
            "auditor_fn_violation": 0.06658968349418405,
            "auditor_fp_violation": 0.03978760881219207,
            "ave_precision_score": 0.7903063775014847,
            "fpr": 0.0845225027442371,
            "logloss": 1.2670246802146734,
            "mae": 0.3249813257668451,
            "precision": 0.7793696275071633,
            "recall": 0.5654885654885655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7901517847425282,
            "auditor_fn_violation": 0.021208875783539194,
            "auditor_fp_violation": 0.01789104024297646,
            "ave_precision_score": 0.7909045571504153,
            "fpr": 0.13486842105263158,
            "logloss": 1.1195552951914503,
            "mae": 0.27715560654517807,
            "precision": 0.7453416149068323,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8306815922685492,
            "auditor_fn_violation": 0.014258622381564204,
            "auditor_fp_violation": 0.021780307865111172,
            "ave_precision_score": 0.8309382198110542,
            "fpr": 0.132821075740944,
            "logloss": 1.0126517354111149,
            "mae": 0.272267451018131,
            "precision": 0.7484407484407485,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8419606985962755,
            "auditor_fn_violation": 0.004450873483921224,
            "auditor_fp_violation": 0.016092694720856813,
            "ave_precision_score": 0.8423860158088223,
            "fpr": 0.13157894736842105,
            "logloss": 0.5523564506010507,
            "mae": 0.28311950557942683,
            "precision": 0.7614314115308151,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8766568187506003,
            "auditor_fn_violation": 0.0022980846251976893,
            "auditor_fp_violation": 0.009787353534322115,
            "ave_precision_score": 0.8768385366201835,
            "fpr": 0.1119648737650933,
            "logloss": 0.5106894172121527,
            "mae": 0.2601201543741646,
            "precision": 0.7931034482758621,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8469720030304093,
            "auditor_fn_violation": 0.026691331923890074,
            "auditor_fp_violation": 0.015255964512648365,
            "ave_precision_score": 0.8477480126212318,
            "fpr": 0.10964912280701754,
            "logloss": 0.5155912556333129,
            "mae": 0.3093718893500267,
            "precision": 0.782608695652174,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8880835760215974,
            "auditor_fn_violation": 0.02368145397783159,
            "auditor_fp_violation": 0.014091338421872213,
            "ave_precision_score": 0.8883029921189649,
            "fpr": 0.09879253567508232,
            "logloss": 0.4602518442068192,
            "mae": 0.2897522383041297,
            "precision": 0.8085106382978723,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7895988509247771,
            "auditor_fn_violation": 0.03665247950743668,
            "auditor_fp_violation": 0.030227190984294453,
            "ave_precision_score": 0.790100602482348,
            "fpr": 0.1162280701754386,
            "logloss": 0.9907332338266377,
            "mae": 0.29288960870030456,
            "precision": 0.752913752913753,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8280280202988277,
            "auditor_fn_violation": 0.040174261908619766,
            "auditor_fp_violation": 0.030745666658157412,
            "ave_precision_score": 0.8283200757539387,
            "fpr": 0.11855104281009879,
            "logloss": 0.8987937932766419,
            "mae": 0.2834719070688641,
            "precision": 0.7534246575342466,
            "recall": 0.6860706860706861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 9296,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7593201754385965,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.518640350877193,
            "fpr": 0.48135964912280704,
            "logloss": 16.625958180523735,
            "mae": 0.48135964912280704,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7639956092206366,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5279912184412733,
            "fpr": 0.47200878155872666,
            "logloss": 16.30298317969987,
            "mae": 0.47200878155872666,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.78854408953383,
            "auditor_fn_violation": 0.010174418604651164,
            "auditor_fp_violation": 0.025813751348759153,
            "ave_precision_score": 0.7899527297337073,
            "fpr": 0.20065789473684212,
            "logloss": 0.6925497936082894,
            "mae": 0.3161521310653131,
            "precision": 0.6778169014084507,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8222189071648333,
            "auditor_fn_violation": 0.00827721244845285,
            "auditor_fp_violation": 0.0223623414086233,
            "ave_precision_score": 0.8224766637565553,
            "fpr": 0.19538968166849616,
            "logloss": 0.6453483113131903,
            "mae": 0.3099675486406424,
            "precision": 0.6898954703832753,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7756205928881477,
            "auditor_fn_violation": 0.008924928600571199,
            "auditor_fp_violation": 0.02091825520521121,
            "ave_precision_score": 0.7770910126619827,
            "fpr": 0.1524122807017544,
            "logloss": 1.0833050560384454,
            "mae": 0.29866109042495464,
            "precision": 0.7169042769857433,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8214246668427111,
            "auditor_fn_violation": 0.01673014735583342,
            "auditor_fp_violation": 0.023965486431981212,
            "ave_precision_score": 0.8217290532229494,
            "fpr": 0.14050493962678376,
            "logloss": 0.927790134595518,
            "mae": 0.2792197848240338,
            "precision": 0.7387755102040816,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 9296,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6574682799200626,
            "auditor_fn_violation": 0.0027957049070880184,
            "auditor_fp_violation": 0.02879350997082684,
            "ave_precision_score": 0.6389242460274283,
            "fpr": 0.19517543859649122,
            "logloss": 2.8485279191059325,
            "mae": 0.3146085248329965,
            "precision": 0.6763636363636364,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6716226356862691,
            "auditor_fn_violation": 0.008676581673288594,
            "auditor_fp_violation": 0.038960508513516956,
            "ave_precision_score": 0.6495321171254436,
            "fpr": 0.1986827661909989,
            "logloss": 2.9631058637219305,
            "mae": 0.3116575369115497,
            "precision": 0.6802120141342756,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.787033246063271,
            "auditor_fn_violation": 0.009490560439152857,
            "auditor_fp_violation": 0.020868301162930113,
            "ave_precision_score": 0.7876077469987042,
            "fpr": 0.14473684210526316,
            "logloss": 1.0006372693903718,
            "mae": 0.2948629087616728,
            "precision": 0.7255717255717256,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8297171793845141,
            "auditor_fn_violation": 0.015655273613561217,
            "auditor_fp_violation": 0.018104306537666256,
            "ave_precision_score": 0.830000009726956,
            "fpr": 0.12733260153677278,
            "logloss": 0.8535390138009585,
            "mae": 0.2742064587042623,
            "precision": 0.7573221757322176,
            "recall": 0.7525987525987526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7729221845155614,
            "auditor_fn_violation": 0.011873632283669004,
            "auditor_fp_violation": 0.015485753107141433,
            "ave_precision_score": 0.7734190639104769,
            "fpr": 0.10635964912280702,
            "logloss": 2.197045167504213,
            "mae": 0.34435907086688156,
            "precision": 0.7364130434782609,
            "recall": 0.572938689217759
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.8003262690318732,
            "auditor_fn_violation": 0.00558204070827562,
            "auditor_fp_violation": 0.012848135195159935,
            "ave_precision_score": 0.8007728823956871,
            "fpr": 0.09769484083424808,
            "logloss": 1.9002848952561742,
            "mae": 0.32961468756376083,
            "precision": 0.7632978723404256,
            "recall": 0.5966735966735967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7884315703951248,
            "auditor_fn_violation": 0.009873057379177331,
            "auditor_fp_violation": 0.01889261879071255,
            "ave_precision_score": 0.788941171432437,
            "fpr": 0.23684210526315788,
            "logloss": 1.2263646555785455,
            "mae": 0.3086117939150901,
            "precision": 0.6527331189710611,
            "recall": 0.8583509513742071
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8299359523148768,
            "auditor_fn_violation": 0.01032198287961186,
            "auditor_fp_violation": 0.026921604166134833,
            "ave_precision_score": 0.8302763626762331,
            "fpr": 0.21734357848518113,
            "logloss": 1.0730789561148597,
            "mae": 0.2797508675590007,
            "precision": 0.685214626391097,
            "recall": 0.896049896049896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7058903959736561,
            "auditor_fn_violation": 0.009381606765327696,
            "auditor_fp_violation": 0.018915098109739042,
            "ave_precision_score": 0.7027299521517084,
            "fpr": 0.1787280701754386,
            "logloss": 1.2669160516571012,
            "mae": 0.31389219449735967,
            "precision": 0.7009174311926606,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7220578834317264,
            "auditor_fn_violation": 0.011866971252262142,
            "auditor_fp_violation": 0.03494243484032369,
            "ave_precision_score": 0.7184868922618652,
            "fpr": 0.17892425905598244,
            "logloss": 1.313799456834066,
            "mae": 0.2878344481485202,
            "precision": 0.7120141342756183,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6915090132575701,
            "auditor_fn_violation": 0.015948963317384372,
            "auditor_fp_violation": 0.029635235583263392,
            "ave_precision_score": 0.6809478689318211,
            "fpr": 0.2149122807017544,
            "logloss": 1.9942943710722896,
            "mae": 0.3118913160908032,
            "precision": 0.6683587140439933,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6988659339010653,
            "auditor_fn_violation": 0.008774712397105375,
            "auditor_fp_violation": 0.03459525693717612,
            "ave_precision_score": 0.6855709104383506,
            "fpr": 0.21844127332601537,
            "logloss": 2.242026797898722,
            "mae": 0.29956434911284135,
            "precision": 0.67430441898527,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7985907591851357,
            "auditor_fn_violation": 0.015754237602462813,
            "auditor_fp_violation": 0.020491148143707796,
            "ave_precision_score": 0.7992992222330275,
            "fpr": 0.1337719298245614,
            "logloss": 1.2004725803026708,
            "mae": 0.28329296024400175,
            "precision": 0.7404255319148936,
            "recall": 0.7357293868921776
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8376801868541688,
            "auditor_fn_violation": 0.015965640554004987,
            "auditor_fp_violation": 0.0257371148495137,
            "ave_precision_score": 0.8379156120287274,
            "fpr": 0.1251372118551043,
            "logloss": 1.0334068539628989,
            "mae": 0.2735470294427612,
            "precision": 0.7574468085106383,
            "recall": 0.7401247401247402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6137623814386497,
            "auditor_fn_violation": 0.009886966358814597,
            "auditor_fp_violation": 0.0049054869520041575,
            "ave_precision_score": 0.6145002629915937,
            "fpr": 0.025219298245614034,
            "logloss": 11.158735408131827,
            "mae": 0.466167446101328,
            "precision": 0.7788461538461539,
            "recall": 0.17124735729386892
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5772511291811231,
            "auditor_fn_violation": 0.006344265400247837,
            "auditor_fp_violation": 0.00092410588926046,
            "ave_precision_score": 0.578882318229732,
            "fpr": 0.024149286498353458,
            "logloss": 12.161320005110687,
            "mae": 0.4950703215286153,
            "precision": 0.7411764705882353,
            "recall": 0.13097713097713098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6784649452426734,
            "auditor_fn_violation": 0.01959311598234487,
            "auditor_fp_violation": 0.026702933301362756,
            "ave_precision_score": 0.6694571079996576,
            "fpr": 0.18092105263157895,
            "logloss": 1.7466544369215131,
            "mae": 0.3316862105803497,
            "precision": 0.6857142857142857,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6973418783329056,
            "auditor_fn_violation": 0.0218124060056003,
            "auditor_fp_violation": 0.04263140428356266,
            "ave_precision_score": 0.686306325387195,
            "fpr": 0.17672886937431395,
            "logloss": 1.83052109579278,
            "mae": 0.3047149874375959,
            "precision": 0.7034990791896869,
            "recall": 0.7941787941787942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6916923065294129,
            "auditor_fn_violation": 0.009418697377693705,
            "auditor_fp_violation": 0.02902080086320586,
            "ave_precision_score": 0.6802767978610621,
            "fpr": 0.2774122807017544,
            "logloss": 2.310378311366463,
            "mae": 0.3273847628239007,
            "precision": 0.6306569343065693,
            "recall": 0.9133192389006343
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7000817772907602,
            "auditor_fn_violation": 0.0048700224331398876,
            "auditor_fp_violation": 0.03683659663543768,
            "ave_precision_score": 0.6856719938981601,
            "fpr": 0.27442371020856204,
            "logloss": 2.583628530663978,
            "mae": 0.31417604582956543,
            "precision": 0.6428571428571429,
            "recall": 0.9355509355509356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7844457483898875,
            "auditor_fn_violation": 0.018997348021215832,
            "auditor_fp_violation": 0.011137253726571556,
            "ave_precision_score": 0.784835243647354,
            "fpr": 0.13267543859649122,
            "logloss": 1.2204948806389886,
            "mae": 0.29185975808023196,
            "precision": 0.7380952380952381,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.817302727520422,
            "auditor_fn_violation": 0.015274161267575104,
            "auditor_fp_violation": 0.022099405202562997,
            "ave_precision_score": 0.8176507089097129,
            "fpr": 0.12843029637760703,
            "logloss": 1.057404411460206,
            "mae": 0.2792454174597526,
            "precision": 0.7483870967741936,
            "recall": 0.7234927234927235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.688496760714666,
            "auditor_fn_violation": 0.011064593301435412,
            "auditor_fp_violation": 0.029150681373136714,
            "ave_precision_score": 0.6800417964288616,
            "fpr": 0.16776315789473684,
            "logloss": 1.6066250372294921,
            "mae": 0.3174318098919139,
            "precision": 0.7017543859649122,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7065285955367794,
            "auditor_fn_violation": 0.015760250666946606,
            "auditor_fp_violation": 0.0422331708064228,
            "ave_precision_score": 0.6956622329417868,
            "fpr": 0.15587266739846323,
            "logloss": 1.7305777367861042,
            "mae": 0.2922476213616835,
            "precision": 0.7300380228136882,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 9296,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8067728761962446,
            "auditor_fn_violation": 0.01803067393642669,
            "auditor_fp_violation": 0.01843553930384047,
            "ave_precision_score": 0.8078472272210976,
            "fpr": 0.15460526315789475,
            "logloss": 1.0649007919255709,
            "mae": 0.28139507516483064,
            "precision": 0.7235294117647059,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8474578769483931,
            "auditor_fn_violation": 0.013840996277878829,
            "auditor_fp_violation": 0.02427692543333419,
            "ave_precision_score": 0.8476584115650903,
            "fpr": 0.15367727771679474,
            "logloss": 0.9111946767825507,
            "mae": 0.2767439326316677,
            "precision": 0.7265625,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.824029873761997,
            "auditor_fn_violation": 0.024275805793553658,
            "auditor_fp_violation": 0.012471026655476966,
            "ave_precision_score": 0.8243827846542767,
            "fpr": 0.1206140350877193,
            "logloss": 0.6673305632927184,
            "mae": 0.29002416983672974,
            "precision": 0.7555555555555555,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8625514213328237,
            "auditor_fn_violation": 0.017668094506733373,
            "auditor_fp_violation": 0.0201158961529625,
            "ave_precision_score": 0.8628276423887412,
            "fpr": 0.09879253567508232,
            "logloss": 0.5601167531344255,
            "mae": 0.2608477379669112,
            "precision": 0.8030634573304157,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6765943945777099,
            "auditor_fn_violation": 0.00936537962241757,
            "auditor_fp_violation": 0.023818087359629144,
            "ave_precision_score": 0.6744132135853451,
            "fpr": 0.17982456140350878,
            "logloss": 1.8983254294780527,
            "mae": 0.31234645501219577,
            "precision": 0.690566037735849,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6929325446576282,
            "auditor_fn_violation": 0.009265366016189294,
            "auditor_fp_violation": 0.032583667321879874,
            "ave_precision_score": 0.6876625111997643,
            "fpr": 0.18551042810098792,
            "logloss": 1.863180527891245,
            "mae": 0.3027354471191003,
            "precision": 0.6916058394160584,
            "recall": 0.7879417879417879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7445806292796944,
            "auditor_fn_violation": 0.0079350728830533,
            "auditor_fp_violation": 0.02664548615273949,
            "ave_precision_score": 0.7423741333038538,
            "fpr": 0.2324561403508772,
            "logloss": 1.710764426792258,
            "mae": 0.3253076402972956,
            "precision": 0.6478405315614618,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7873106717620706,
            "auditor_fn_violation": 0.006273519994705511,
            "auditor_fp_violation": 0.013172338090010982,
            "ave_precision_score": 0.785983159518803,
            "fpr": 0.23600439077936333,
            "logloss": 1.4871108866286427,
            "mae": 0.31446474673597263,
            "precision": 0.655448717948718,
            "recall": 0.8503118503118503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7954422683828283,
            "auditor_fn_violation": 0.012773079633544753,
            "auditor_fp_violation": 0.01838808296367343,
            "ave_precision_score": 0.7961028358884568,
            "fpr": 0.15350877192982457,
            "logloss": 0.9325234437845991,
            "mae": 0.2846866495765034,
            "precision": 0.7227722772277227,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8349991708967421,
            "auditor_fn_violation": 0.011862407032549734,
            "auditor_fp_violation": 0.024039517014270033,
            "ave_precision_score": 0.8352440526934328,
            "fpr": 0.141602634467618,
            "logloss": 0.8445050382443986,
            "mae": 0.27161559580661343,
            "precision": 0.7440476190476191,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8124775240460586,
            "auditor_fn_violation": 0.017196135158191468,
            "auditor_fp_violation": 0.018390580665787488,
            "ave_precision_score": 0.8138341838475729,
            "fpr": 0.14583333333333334,
            "logloss": 0.6925412193486684,
            "mae": 0.2906529177390067,
            "precision": 0.7268993839835729,
            "recall": 0.7484143763213531
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8559590074473097,
            "auditor_fn_violation": 0.005739506288353715,
            "auditor_fp_violation": 0.01732315625558421,
            "ave_precision_score": 0.8561484274222136,
            "fpr": 0.1350164654226125,
            "logloss": 0.6401365255288972,
            "mae": 0.28024312077829194,
            "precision": 0.7453416149068323,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8205536847527019,
            "auditor_fn_violation": 0.017434905975297652,
            "auditor_fp_violation": 0.020728429844543022,
            "ave_precision_score": 0.8210196175039556,
            "fpr": 0.12828947368421054,
            "logloss": 0.7752585719688911,
            "mae": 0.2731430217896646,
            "precision": 0.7572614107883817,
            "recall": 0.7716701902748414
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8547524300602042,
            "auditor_fn_violation": 0.01633077813099767,
            "auditor_fp_violation": 0.023031169427922295,
            "ave_precision_score": 0.8549666032738658,
            "fpr": 0.12952799121844127,
            "logloss": 0.7022992731518537,
            "mae": 0.262632833742611,
            "precision": 0.756198347107438,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7914225455204896,
            "auditor_fn_violation": 0.011848132487667374,
            "auditor_fp_violation": 0.019064960236582353,
            "ave_precision_score": 0.7918250255678771,
            "fpr": 0.2138157894736842,
            "logloss": 1.0602194040750208,
            "mae": 0.29252491566612704,
            "precision": 0.6766169154228856,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8313304382493054,
            "auditor_fn_violation": 0.00895956329545792,
            "auditor_fp_violation": 0.026459551221504608,
            "ave_precision_score": 0.8315883020545931,
            "fpr": 0.2074643249176729,
            "logloss": 0.9500724432611785,
            "mae": 0.27748432882536256,
            "precision": 0.6941747572815534,
            "recall": 0.8918918918918919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.6725194158855994,
            "auditor_fn_violation": 0.0013259893920848686,
            "auditor_fp_violation": 0.03266494824761221,
            "ave_precision_score": 0.6529374778303103,
            "fpr": 0.1513157894736842,
            "logloss": 2.3948405620004474,
            "mae": 0.32933788898415317,
            "precision": 0.73046875,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.6839964682916859,
            "auditor_fn_violation": 0.014610067299419664,
            "auditor_fp_violation": 0.04001480611645777,
            "ave_precision_score": 0.6581583452341356,
            "fpr": 0.15916575192096596,
            "logloss": 2.7868820939998327,
            "mae": 0.3172040971888356,
            "precision": 0.7279549718574109,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.6740255728639313,
            "auditor_fn_violation": 0.0005099959200326388,
            "auditor_fp_violation": 0.0346331375134876,
            "ave_precision_score": 0.6544422084270969,
            "fpr": 0.14583333333333334,
            "logloss": 2.387959398299018,
            "mae": 0.3326875713538134,
            "precision": 0.7285714285714285,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.683295281025043,
            "auditor_fn_violation": 0.01651562902935022,
            "auditor_fp_violation": 0.04254460980777577,
            "ave_precision_score": 0.6574576847643828,
            "fpr": 0.150384193194292,
            "logloss": 2.7825589054800197,
            "mae": 0.3200829994432666,
            "precision": 0.7365384615384616,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 9296,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8003865330500695,
            "auditor_fn_violation": 0.006743536960795223,
            "auditor_fp_violation": 0.016205091315989295,
            "ave_precision_score": 0.8008804241861252,
            "fpr": 0.13267543859649122,
            "logloss": 0.9816182366023528,
            "mae": 0.2847672925577192,
            "precision": 0.7430997876857749,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8380473793039482,
            "auditor_fn_violation": 0.013350342658794917,
            "auditor_fp_violation": 0.016924922778444342,
            "ave_precision_score": 0.8383062075946579,
            "fpr": 0.1207464324917673,
            "logloss": 0.8540170145793937,
            "mae": 0.26735400705403695,
            "precision": 0.7674418604651163,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 9296,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7996715728421937,
            "auditor_fn_violation": 0.002345981232150143,
            "auditor_fp_violation": 0.018308156496023662,
            "ave_precision_score": 0.7739724368102072,
            "fpr": 0.4298245614035088,
            "logloss": 4.447678648506226,
            "mae": 0.42793556132710764,
            "precision": 0.5447154471544715,
            "recall": 0.9915433403805497
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.8251827127530008,
            "auditor_fn_violation": 0.0005089104979335495,
            "auditor_fp_violation": 0.012100171036172882,
            "ave_precision_score": 0.8038059486732987,
            "fpr": 0.4226125137211855,
            "logloss": 4.212830688363654,
            "mae": 0.42178509818571885,
            "precision": 0.5549132947976878,
            "recall": 0.997920997920998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 9296,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.754606452102965,
            "auditor_fn_violation": 0.07991404250584179,
            "auditor_fp_violation": 0.039241397913919195,
            "ave_precision_score": 0.7550024862134075,
            "fpr": 0.09429824561403509,
            "logloss": 1.467149226150074,
            "mae": 0.350064794844484,
            "precision": 0.7401812688821753,
            "recall": 0.5179704016913319
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7881194596697276,
            "auditor_fn_violation": 0.0654919886533498,
            "auditor_fp_violation": 0.03978760881219207,
            "ave_precision_score": 0.7885159529715988,
            "fpr": 0.0845225027442371,
            "logloss": 1.2639886137335854,
            "mae": 0.3239890937642751,
            "precision": 0.7793696275071633,
            "recall": 0.5654885654885655
        }
    }
]