[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8180866178637871,
            "auditor_fn_violation": 0.02684811094125355,
            "auditor_fp_violation": 0.024301305589555285,
            "ave_precision_score": 0.8184482945416807,
            "fpr": 0.15350877192982457,
            "logloss": 0.7912625166248859,
            "mae": 0.2918342409201771,
            "precision": 0.7216699801192843,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8403203423515555,
            "auditor_fn_violation": 0.0269353848443692,
            "auditor_fp_violation": 0.02847505432214219,
            "ave_precision_score": 0.840586553689561,
            "fpr": 0.14050493962678376,
            "logloss": 0.6906957406330088,
            "mae": 0.2718905339517691,
            "precision": 0.7485265225933202,
            "recall": 0.8072033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7888938625390125,
            "auditor_fn_violation": 0.029159387056853753,
            "auditor_fp_violation": 0.03062270501835986,
            "ave_precision_score": 0.790505053640757,
            "fpr": 0.21600877192982457,
            "logloss": 0.9618496218474458,
            "mae": 0.3059310905953838,
            "precision": 0.6754530477759473,
            "recall": 0.8506224066390041
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8162520374643171,
            "auditor_fn_violation": 0.023716720311075558,
            "auditor_fp_violation": 0.040012102148131286,
            "ave_precision_score": 0.8165866890416005,
            "fpr": 0.22502744237102085,
            "logloss": 0.9230692808209274,
            "mae": 0.29584978809057755,
            "precision": 0.6714743589743589,
            "recall": 0.8877118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8620477525538357,
            "auditor_fn_violation": 0.00720681371478489,
            "auditor_fp_violation": 0.019201346389228897,
            "ave_precision_score": 0.8622474819322946,
            "fpr": 0.13486842105263158,
            "logloss": 0.600649413850777,
            "mae": 0.26357161130112056,
            "precision": 0.7602339181286549,
            "recall": 0.8091286307053942
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8471170643897666,
            "auditor_fn_violation": 0.014228171686915108,
            "auditor_fp_violation": 0.020908711296255097,
            "ave_precision_score": 0.8474251738842534,
            "fpr": 0.14709110867178923,
            "logloss": 0.6089408849301209,
            "mae": 0.2659895879655413,
            "precision": 0.7437858508604207,
            "recall": 0.8241525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8286543802850465,
            "auditor_fn_violation": 0.0243548445803305,
            "auditor_fp_violation": 0.027820277437780497,
            "ave_precision_score": 0.8289819066508175,
            "fpr": 0.15350877192982457,
            "logloss": 0.8167566581471507,
            "mae": 0.2735156023471736,
            "precision": 0.7348484848484849,
            "recall": 0.8049792531120332
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.837857674278712,
            "auditor_fn_violation": 0.021223650672570656,
            "auditor_fp_violation": 0.03053041914939902,
            "ave_precision_score": 0.8382083739783546,
            "fpr": 0.15477497255762898,
            "logloss": 0.7375584103501363,
            "mae": 0.26309917455949744,
            "precision": 0.7344632768361582,
            "recall": 0.826271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8436816917215435,
            "auditor_fn_violation": 0.024750673363907693,
            "auditor_fp_violation": 0.022261321909424727,
            "ave_precision_score": 0.8439338340842253,
            "fpr": 0.10964912280701754,
            "logloss": 0.7629530830702158,
            "mae": 0.27083477345026846,
            "precision": 0.7797356828193832,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8334445879783705,
            "auditor_fn_violation": 0.02579582875960483,
            "auditor_fp_violation": 0.020473634070047438,
            "ave_precision_score": 0.8339201444368199,
            "fpr": 0.11086717892425905,
            "logloss": 0.761102517621751,
            "mae": 0.2630998477447827,
            "precision": 0.778021978021978,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 25349,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8601771950427437,
            "auditor_fn_violation": 0.007006624444929755,
            "auditor_fp_violation": 0.010194818441452468,
            "ave_precision_score": 0.8603804757433313,
            "fpr": 0.11732456140350878,
            "logloss": 0.6193642153621255,
            "mae": 0.26515004445436846,
            "precision": 0.7793814432989691,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8556498354764817,
            "auditor_fn_violation": 0.014479339150495827,
            "auditor_fp_violation": 0.01668046078178877,
            "ave_precision_score": 0.8559010711273222,
            "fpr": 0.13062568605927552,
            "logloss": 0.5890102247070578,
            "mae": 0.26153123843069054,
            "precision": 0.7605633802816901,
            "recall": 0.8008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7982559540284144,
            "auditor_fn_violation": 0.033754640751255734,
            "auditor_fp_violation": 0.03975418196654427,
            "ave_precision_score": 0.7986488893083651,
            "fpr": 0.20833333333333334,
            "logloss": 0.8388890842567298,
            "mae": 0.3212298744697012,
            "precision": 0.676320272572402,
            "recall": 0.8236514522821576
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7971057843286535,
            "auditor_fn_violation": 0.026853987981171747,
            "auditor_fp_violation": 0.042360018903355355,
            "ave_precision_score": 0.797773205361224,
            "fpr": 0.21295279912184412,
            "logloss": 0.8097677266821243,
            "mae": 0.3141510461944106,
            "precision": 0.6750418760469011,
            "recall": 0.8538135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8303187060707562,
            "auditor_fn_violation": 0.03853643444711363,
            "auditor_fp_violation": 0.03349398204814361,
            "ave_precision_score": 0.8310771072040091,
            "fpr": 0.13706140350877194,
            "logloss": 0.8046186237417897,
            "mae": 0.2807976576813539,
            "precision": 0.750996015936255,
            "recall": 0.7821576763485477
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8394070037371937,
            "auditor_fn_violation": 0.03427970752944241,
            "auditor_fp_violation": 0.035193746890072986,
            "ave_precision_score": 0.8398371938717484,
            "fpr": 0.132821075740944,
            "logloss": 0.7052028879271711,
            "mae": 0.26139649743465143,
            "precision": 0.7584830339321357,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8132875015132676,
            "auditor_fn_violation": 0.02819938851277572,
            "auditor_fp_violation": 0.029079967360261125,
            "ave_precision_score": 0.8137788125281221,
            "fpr": 0.16337719298245615,
            "logloss": 0.7667145918210385,
            "mae": 0.30573775833032524,
            "precision": 0.7151051625239006,
            "recall": 0.7759336099585062
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8333154766879962,
            "auditor_fn_violation": 0.03022381811754637,
            "auditor_fp_violation": 0.031125524780648568,
            "ave_precision_score": 0.8336573266574363,
            "fpr": 0.14818880351262348,
            "logloss": 0.6450028311570599,
            "mae": 0.28473960424943845,
            "precision": 0.7388781431334622,
            "recall": 0.809322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 25349,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.5977691948734924,
            "auditor_fn_violation": 0.004581604426002774,
            "auditor_fp_violation": 0.005329457364341089,
            "ave_precision_score": 0.5979019357267468,
            "fpr": 0.1699561403508772,
            "logloss": 1.731337761962071,
            "mae": 0.39651403076244146,
            "precision": 0.6680942184154176,
            "recall": 0.6473029045643154
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6172312841042162,
            "auditor_fn_violation": 0.011165324006028024,
            "auditor_fp_violation": 0.008296472623890746,
            "ave_precision_score": 0.6164627414533724,
            "fpr": 0.1525795828759605,
            "logloss": 1.7544458581984164,
            "mae": 0.37209712602178796,
            "precision": 0.6938325991189427,
            "recall": 0.6673728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8363157586843335,
            "auditor_fn_violation": 0.005236769309165028,
            "auditor_fp_violation": 0.013132394940840477,
            "ave_precision_score": 0.8365658855718161,
            "fpr": 0.12938596491228072,
            "logloss": 0.7461502638020712,
            "mae": 0.2756771184267945,
            "precision": 0.757201646090535,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.826441243269214,
            "auditor_fn_violation": 0.008023405086606265,
            "auditor_fp_violation": 0.01993103775920226,
            "ave_precision_score": 0.826711639247548,
            "fpr": 0.1437980241492865,
            "logloss": 0.7193167173786942,
            "mae": 0.2797404158597866,
            "precision": 0.7400793650793651,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.813214855217912,
            "auditor_fn_violation": 0.028909150469534836,
            "auditor_fp_violation": 0.02905956752345982,
            "ave_precision_score": 0.8137901699237757,
            "fpr": 0.14912280701754385,
            "logloss": 0.7404567287573374,
            "mae": 0.3057794857602636,
            "precision": 0.7306930693069307,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8351620404324659,
            "auditor_fn_violation": 0.030102885635081587,
            "auditor_fp_violation": 0.03076796131313308,
            "ave_precision_score": 0.8355378346393039,
            "fpr": 0.132821075740944,
            "logloss": 0.6212850046917229,
            "mae": 0.2847143909967066,
            "precision": 0.7565392354124748,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8568199949127651,
            "auditor_fn_violation": 0.004442836863944091,
            "auditor_fp_violation": 0.008754079967360263,
            "ave_precision_score": 0.8570187425198967,
            "fpr": 0.12828947368421054,
            "logloss": 0.6211045232739937,
            "mae": 0.2713315107599279,
            "precision": 0.7650602409638554,
            "recall": 0.7904564315352697
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.854805785319197,
            "auditor_fn_violation": 0.015125862806749896,
            "auditor_fp_violation": 0.017408089935963635,
            "ave_precision_score": 0.8550571215913394,
            "fpr": 0.1437980241492865,
            "logloss": 0.5844761655694877,
            "mae": 0.26844338083513647,
            "precision": 0.7456310679611651,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8505258954915983,
            "auditor_fn_violation": 0.02479617092523841,
            "auditor_fp_violation": 0.016681966544267655,
            "ave_precision_score": 0.8507493376701709,
            "fpr": 0.125,
            "logloss": 0.7143567708674369,
            "mae": 0.26924599111334613,
            "precision": 0.7639751552795031,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8524098712432981,
            "auditor_fn_violation": 0.021972501813987237,
            "auditor_fp_violation": 0.01995354175366128,
            "ave_precision_score": 0.8526671411358107,
            "fpr": 0.12294182217343579,
            "logloss": 0.6720113418734773,
            "mae": 0.25705742189174696,
            "precision": 0.768595041322314,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7187270232840584,
            "auditor_fn_violation": 0.01544642207177696,
            "auditor_fp_violation": 0.02191452468380254,
            "ave_precision_score": 0.7205090692422351,
            "fpr": 0.125,
            "logloss": 0.7097681749815482,
            "mae": 0.369601243987011,
            "precision": 0.7219512195121951,
            "recall": 0.6141078838174274
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6771860308308396,
            "auditor_fn_violation": 0.009037377439580278,
            "auditor_fp_violation": 0.015120183832630299,
            "ave_precision_score": 0.6784857478410371,
            "fpr": 0.14928649835345773,
            "logloss": 0.7063546598377037,
            "mae": 0.3802147419668708,
            "precision": 0.6837209302325581,
            "recall": 0.6228813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.799886717488243,
            "auditor_fn_violation": 0.008630887384436197,
            "auditor_fp_violation": 0.024173806609547124,
            "ave_precision_score": 0.8001745542212482,
            "fpr": 0.2850877192982456,
            "logloss": 0.8737910929477573,
            "mae": 0.3498781662672722,
            "precision": 0.6231884057971014,
            "recall": 0.8921161825726142
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8188232940374474,
            "auditor_fn_violation": 0.010042047293903145,
            "auditor_fp_violation": 0.00145775875217852,
            "ave_precision_score": 0.8191069323645355,
            "fpr": 0.2623490669593853,
            "logloss": 0.7818889258834374,
            "mae": 0.33860127823905795,
            "precision": 0.6448736998514116,
            "recall": 0.9194915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8524667949420478,
            "auditor_fn_violation": 0.03785397102715295,
            "auditor_fp_violation": 0.028725520195838437,
            "ave_precision_score": 0.8527439309262569,
            "fpr": 0.12609649122807018,
            "logloss": 0.604570881349628,
            "mae": 0.2920271138830919,
            "precision": 0.7619047619047619,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8669915541691826,
            "auditor_fn_violation": 0.029963348155314522,
            "auditor_fp_violation": 0.02666223254627697,
            "ave_precision_score": 0.8673302509990439,
            "fpr": 0.10757409440175632,
            "logloss": 0.5257202955317656,
            "mae": 0.2635154008128982,
            "precision": 0.7928118393234672,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8328818297072785,
            "auditor_fn_violation": 0.004608902962801196,
            "auditor_fp_violation": 0.015223378212974299,
            "ave_precision_score": 0.8331501291983148,
            "fpr": 0.13157894736842105,
            "logloss": 0.7535521706664016,
            "mae": 0.27661774503251957,
            "precision": 0.7565922920892495,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8229109764376799,
            "auditor_fn_violation": 0.008493181268488723,
            "auditor_fp_violation": 0.020576152267027397,
            "ave_precision_score": 0.8231805583422656,
            "fpr": 0.14489571899012074,
            "logloss": 0.7366273761665038,
            "mae": 0.28368990789659154,
            "precision": 0.7349397590361446,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8580330352069894,
            "auditor_fn_violation": 0.003453264905001092,
            "auditor_fp_violation": 0.009419624643002859,
            "ave_precision_score": 0.8582338192593354,
            "fpr": 0.12719298245614036,
            "logloss": 0.6141718994210155,
            "mae": 0.2708190289197751,
            "precision": 0.7670682730923695,
            "recall": 0.7925311203319502
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8568511696172579,
            "auditor_fn_violation": 0.014102587955124748,
            "auditor_fp_violation": 0.016682961225617552,
            "ave_precision_score": 0.857084367911068,
            "fpr": 0.1394072447859495,
            "logloss": 0.5765921301823006,
            "mae": 0.2671605063310043,
            "precision": 0.7514677103718199,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8055425264878822,
            "auditor_fn_violation": 0.006956577127465971,
            "auditor_fp_violation": 0.026234190126478995,
            "ave_precision_score": 0.7897198636405511,
            "fpr": 0.19078947368421054,
            "logloss": 1.2998041521930723,
            "mae": 0.31130000960010706,
            "precision": 0.7050847457627119,
            "recall": 0.8630705394190872
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8001678181246157,
            "auditor_fn_violation": 0.007962938845373869,
            "auditor_fp_violation": 0.014190018728324276,
            "ave_precision_score": 0.7774578037681737,
            "fpr": 0.16575192096597147,
            "logloss": 1.5362630798382333,
            "mae": 0.29593156874686843,
            "precision": 0.7249544626593807,
            "recall": 0.8432203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8528292503489345,
            "auditor_fn_violation": 0.003548809783795595,
            "auditor_fp_violation": 0.016294369645042845,
            "ave_precision_score": 0.853033013162527,
            "fpr": 0.1162280701754386,
            "logloss": 0.7035008264315266,
            "mae": 0.26128299499626606,
            "precision": 0.7758985200845666,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8214895535187483,
            "auditor_fn_violation": 0.007483860164840273,
            "auditor_fp_violation": 0.011427028297522812,
            "ave_precision_score": 0.8220262371531936,
            "fpr": 0.13172338090010977,
            "logloss": 0.7667659672671046,
            "mae": 0.2746625159451266,
            "precision": 0.7510373443983402,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8603812694365433,
            "auditor_fn_violation": 0.007343306398777025,
            "auditor_fp_violation": 0.010085169318645457,
            "ave_precision_score": 0.8605772903639182,
            "fpr": 0.12609649122807018,
            "logloss": 0.5946520650480411,
            "mae": 0.27292665994137405,
            "precision": 0.7695390781563126,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8612345603252822,
            "auditor_fn_violation": 0.010528102848425088,
            "auditor_fp_violation": 0.011937118838593861,
            "ave_precision_score": 0.8614779754500937,
            "fpr": 0.1207464324917673,
            "logloss": 0.538705760898666,
            "mae": 0.261825478004124,
            "precision": 0.7768762677484787,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8580825074012035,
            "auditor_fn_violation": 0.003453264905001092,
            "auditor_fp_violation": 0.009419624643002859,
            "ave_precision_score": 0.8582831236410037,
            "fpr": 0.12719298245614036,
            "logloss": 0.6139580086172982,
            "mae": 0.27077877099349296,
            "precision": 0.7670682730923695,
            "recall": 0.7925311203319502
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.85696085858192,
            "auditor_fn_violation": 0.01361420677594002,
            "auditor_fp_violation": 0.016682961225617552,
            "ave_precision_score": 0.8571948052910641,
            "fpr": 0.1394072447859495,
            "logloss": 0.5762196508174251,
            "mae": 0.26706182833094644,
            "precision": 0.7509803921568627,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8380438479448249,
            "auditor_fn_violation": 0.003789946858848369,
            "auditor_fp_violation": 0.006573847409220737,
            "ave_precision_score": 0.8382703513629157,
            "fpr": 0.1611842105263158,
            "logloss": 0.641739031073914,
            "mae": 0.3038752266309173,
            "precision": 0.7226415094339622,
            "recall": 0.7946058091286307
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8407016735647668,
            "auditor_fn_violation": 0.015181677798656723,
            "auditor_fp_violation": 0.02172635642826602,
            "ave_precision_score": 0.8410832000147996,
            "fpr": 0.1690450054884742,
            "logloss": 0.5694979599181894,
            "mae": 0.29124894157961606,
            "precision": 0.72,
            "recall": 0.8389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.858198841074894,
            "auditor_fn_violation": 0.00987524568683119,
            "auditor_fp_violation": 0.008282333741330075,
            "ave_precision_score": 0.8583981140216906,
            "fpr": 0.11293859649122807,
            "logloss": 0.6769960871878999,
            "mae": 0.26193745362522075,
            "precision": 0.7799145299145299,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.84849551809533,
            "auditor_fn_violation": 0.01551424212543489,
            "auditor_fp_violation": 0.011942119726251414,
            "ave_precision_score": 0.8489189251380148,
            "fpr": 0.11964873765093303,
            "logloss": 0.6801339792193094,
            "mae": 0.26016961731693783,
            "precision": 0.7738589211618258,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8144676029514051,
            "auditor_fn_violation": 0.031311421707796466,
            "auditor_fp_violation": 0.028233374133006944,
            "ave_precision_score": 0.8150441788909812,
            "fpr": 0.1611842105263158,
            "logloss": 0.7635992519861563,
            "mae": 0.3034344486855615,
            "precision": 0.72,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8335236122244797,
            "auditor_fn_violation": 0.030656384304824282,
            "auditor_fp_violation": 0.03264329418471779,
            "ave_precision_score": 0.8338444278029131,
            "fpr": 0.14818880351262348,
            "logloss": 0.6481869259976497,
            "mae": 0.283555169358382,
            "precision": 0.7403846153846154,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8407994152329255,
            "auditor_fn_violation": 0.014295333770109931,
            "auditor_fp_violation": 0.021554977560179524,
            "ave_precision_score": 0.8410213746914184,
            "fpr": 0.10855263157894737,
            "logloss": 0.9894375084783742,
            "mae": 0.2866515245753943,
            "precision": 0.7734553775743707,
            "recall": 0.7012448132780082
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8432333866597741,
            "auditor_fn_violation": 0.013372341811010439,
            "auditor_fp_violation": 0.01575029567748275,
            "ave_precision_score": 0.8435373195370393,
            "fpr": 0.09989023051591657,
            "logloss": 0.9198077553296087,
            "mae": 0.2696953379358628,
            "precision": 0.7912844036697247,
            "recall": 0.7309322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.763244903068448,
            "auditor_fn_violation": 0.01942290893208124,
            "auditor_fp_violation": 0.03263208894328846,
            "ave_precision_score": 0.7622925427680364,
            "fpr": 0.29276315789473684,
            "logloss": 1.4220259971533864,
            "mae": 0.3344705041633209,
            "precision": 0.6276150627615062,
            "recall": 0.9336099585062241
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7583320637029348,
            "auditor_fn_violation": 0.016502632607118272,
            "auditor_fp_violation": 0.0400371065864191,
            "ave_precision_score": 0.7559120897281775,
            "fpr": 0.29747530186608123,
            "logloss": 1.5351161705195782,
            "mae": 0.3366490525533922,
            "precision": 0.6188466947960619,
            "recall": 0.9322033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8553109559613827,
            "auditor_fn_violation": 0.03625928150251147,
            "auditor_fp_violation": 0.023220114239086084,
            "ave_precision_score": 0.8555735066112937,
            "fpr": 0.09649122807017543,
            "logloss": 0.6018848027071537,
            "mae": 0.2949841787131883,
            "precision": 0.7899761336515513,
            "recall": 0.6867219917012448
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8652518293750588,
            "auditor_fn_violation": 0.03134476920500847,
            "auditor_fp_violation": 0.018573296760174933,
            "ave_precision_score": 0.8655733004880464,
            "fpr": 0.07793633369923161,
            "logloss": 0.5419015295330629,
            "mae": 0.27068254980794954,
            "precision": 0.829736211031175,
            "recall": 0.7330508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8457127900075,
            "auditor_fn_violation": 0.00781648103661644,
            "auditor_fp_violation": 0.018604651162790704,
            "ave_precision_score": 0.8459068479947198,
            "fpr": 0.12390350877192982,
            "logloss": 0.6866773034890877,
            "mae": 0.27656000227723443,
            "precision": 0.7650727650727651,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8173710029194261,
            "auditor_fn_violation": 0.010269958510856016,
            "auditor_fp_violation": 0.01958597651083067,
            "ave_precision_score": 0.8177215193157936,
            "fpr": 0.15477497255762898,
            "logloss": 0.7336047336472522,
            "mae": 0.2891375949709455,
            "precision": 0.7207920792079208,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7977908698542453,
            "auditor_fn_violation": 0.03682572614107884,
            "auditor_fp_violation": 0.025071399428804573,
            "ave_precision_score": 0.7982619664301246,
            "fpr": 0.13815789473684212,
            "logloss": 0.747486118492476,
            "mae": 0.3293883757804344,
            "precision": 0.7248908296943232,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8418554174154087,
            "auditor_fn_violation": 0.03621927849820463,
            "auditor_fp_violation": 0.02532699554170866,
            "ave_precision_score": 0.8421799056675063,
            "fpr": 0.09769484083424808,
            "logloss": 0.5997110900564044,
            "mae": 0.2922522542875747,
            "precision": 0.7915690866510539,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7700584784792117,
            "auditor_fn_violation": 0.03397302904564315,
            "auditor_fp_violation": 0.02747603019175847,
            "ave_precision_score": 0.7707415785531873,
            "fpr": 0.13706140350877194,
            "logloss": 1.7701974069636137,
            "mae": 0.29086120969123347,
            "precision": 0.7474747474747475,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7764889397004313,
            "auditor_fn_violation": 0.038940259353662396,
            "auditor_fp_violation": 0.03889190331283803,
            "ave_precision_score": 0.777330702222794,
            "fpr": 0.13611416026344675,
            "logloss": 1.6154745714907524,
            "mae": 0.2784830453354398,
            "precision": 0.751503006012024,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7792384630377485,
            "auditor_fn_violation": 0.03111123243794133,
            "auditor_fp_violation": 0.02622399020807835,
            "ave_precision_score": 0.780394617089583,
            "fpr": 0.14364035087719298,
            "logloss": 1.683342198266979,
            "mae": 0.28614622678670554,
            "precision": 0.7431372549019608,
            "recall": 0.7863070539419087
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7867162650694881,
            "auditor_fn_violation": 0.035716943571043186,
            "auditor_fp_violation": 0.036381457708743306,
            "ave_precision_score": 0.7875602407307141,
            "fpr": 0.14928649835345773,
            "logloss": 1.587777494970793,
            "mae": 0.27522335851581936,
            "precision": 0.7369439071566731,
            "recall": 0.8072033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7627644217929818,
            "auditor_fn_violation": 0.011583679114799452,
            "auditor_fp_violation": 0.023735210118319056,
            "ave_precision_score": 0.7628024909341303,
            "fpr": 0.15789473684210525,
            "logloss": 0.9712336053154531,
            "mae": 0.31897134047346976,
            "precision": 0.7073170731707317,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7147185470209776,
            "auditor_fn_violation": 0.007397812052317256,
            "auditor_fp_violation": 0.02390424300313306,
            "ave_precision_score": 0.7149757266999823,
            "fpr": 0.1877058177826564,
            "logloss": 1.0694672951282265,
            "mae": 0.3406324862429497,
            "precision": 0.6749049429657795,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8306006600659636,
            "auditor_fn_violation": 0.02374517725849895,
            "auditor_fp_violation": 0.02813647490820074,
            "ave_precision_score": 0.8308631193290846,
            "fpr": 0.12171052631578948,
            "logloss": 0.8223143573059429,
            "mae": 0.2821427537653888,
            "precision": 0.7602591792656588,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8041871190797633,
            "auditor_fn_violation": 0.022025991181231278,
            "auditor_fp_violation": 0.027962463337242366,
            "ave_precision_score": 0.804887024627522,
            "fpr": 0.12294182217343579,
            "logloss": 0.8597826136745897,
            "mae": 0.2836446802483847,
            "precision": 0.7601713062098501,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 25349,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8050578438005499,
            "auditor_fn_violation": 0.03479880978379559,
            "auditor_fp_violation": 0.0325453896368829,
            "ave_precision_score": 0.8056562588009969,
            "fpr": 0.19407894736842105,
            "logloss": 0.8826735049956257,
            "mae": 0.31022967925771855,
            "precision": 0.6883802816901409,
            "recall": 0.8112033195020747
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.81715682577238,
            "auditor_fn_violation": 0.02834936463934213,
            "auditor_fp_violation": 0.04112980053959578,
            "ave_precision_score": 0.8175360638657279,
            "fpr": 0.19538968166849616,
            "logloss": 0.7808476308174777,
            "mae": 0.29680330050789383,
            "precision": 0.6931034482758621,
            "recall": 0.8516949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7505483895068925,
            "auditor_fn_violation": 0.0032940234403435985,
            "auditor_fp_violation": 0.011286209710322318,
            "ave_precision_score": 0.752076706223604,
            "fpr": 0.22039473684210525,
            "logloss": 0.8456908373800758,
            "mae": 0.35156128495115213,
            "precision": 0.6581632653061225,
            "recall": 0.8029045643153527
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7864537819156487,
            "auditor_fn_violation": 0.0009488548624160482,
            "auditor_fp_violation": 0.006183597588571967,
            "ave_precision_score": 0.7873852014515357,
            "fpr": 0.21185510428100987,
            "logloss": 0.7045826196303617,
            "mae": 0.32973827671349143,
            "precision": 0.67008547008547,
            "recall": 0.8305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8305385919699639,
            "auditor_fn_violation": 0.0007052122006260461,
            "auditor_fp_violation": 0.017679008567931465,
            "ave_precision_score": 0.830801882352791,
            "fpr": 0.1611842105263158,
            "logloss": 0.8048945991035102,
            "mae": 0.27650122741802685,
            "precision": 0.7302752293577982,
            "recall": 0.8257261410788381
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.822100060289113,
            "auditor_fn_violation": 0.012816517516604963,
            "auditor_fp_violation": 0.02592960250444454,
            "ave_precision_score": 0.8224235756059223,
            "fpr": 0.1734357848518112,
            "logloss": 0.794083185225889,
            "mae": 0.28310262960377736,
            "precision": 0.7163375224416517,
            "recall": 0.8453389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7918788517283458,
            "auditor_fn_violation": 0.005534778335881193,
            "auditor_fp_violation": 0.009689922480620157,
            "ave_precision_score": 0.7922013655842876,
            "fpr": 0.08771929824561403,
            "logloss": 0.7696019734702426,
            "mae": 0.3503501374814948,
            "precision": 0.7667638483965015,
            "recall": 0.5456431535269709
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8200766602172925,
            "auditor_fn_violation": 0.013344434315057026,
            "auditor_fp_violation": 0.007891400723628447,
            "ave_precision_score": 0.8204817514199618,
            "fpr": 0.06805708013172337,
            "logloss": 0.6504061781562582,
            "mae": 0.321884446954976,
            "precision": 0.8154761904761905,
            "recall": 0.5805084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8359535952585387,
            "auditor_fn_violation": 0.006246815170706853,
            "auditor_fp_violation": 0.009154426764585897,
            "ave_precision_score": 0.8362028426084632,
            "fpr": 0.13486842105263158,
            "logloss": 0.7490535713165454,
            "mae": 0.27530796214776737,
            "precision": 0.7515151515151515,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8262966221847373,
            "auditor_fn_violation": 0.0071257139667714785,
            "auditor_fp_violation": 0.01993103775920226,
            "ave_precision_score": 0.8265685801233094,
            "fpr": 0.1437980241492865,
            "logloss": 0.7253467789973465,
            "mae": 0.2795252202186773,
            "precision": 0.7416173570019724,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8377423837486766,
            "auditor_fn_violation": 0.03431881051175657,
            "auditor_fp_violation": 0.019629742962056305,
            "ave_precision_score": 0.8380339040332063,
            "fpr": 0.1118421052631579,
            "logloss": 0.7503304066344871,
            "mae": 0.2854368545362507,
            "precision": 0.7733333333333333,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.850946702674064,
            "auditor_fn_violation": 0.02692608234571806,
            "auditor_fp_violation": 0.020993726386433598,
            "ave_precision_score": 0.8512042651004862,
            "fpr": 0.1119648737650933,
            "logloss": 0.68174563462898,
            "mae": 0.26491094349913685,
            "precision": 0.7777777777777778,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8363635493140102,
            "auditor_fn_violation": 0.003539710271529449,
            "auditor_fp_violation": 0.013540391676866584,
            "ave_precision_score": 0.8366129156893989,
            "fpr": 0.1337719298245614,
            "logloss": 0.7408137946717739,
            "mae": 0.27573368596026904,
            "precision": 0.7535353535353535,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8261119902637675,
            "auditor_fn_violation": 0.010256004762879311,
            "auditor_fp_violation": 0.021151254347646715,
            "ave_precision_score": 0.8263820443424117,
            "fpr": 0.14709110867178923,
            "logloss": 0.7193918463633336,
            "mae": 0.28020672584165773,
            "precision": 0.7377690802348337,
            "recall": 0.798728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6786480407138996,
            "auditor_fn_violation": 0.012793914246196407,
            "auditor_fp_violation": 0.029681762545899642,
            "ave_precision_score": 0.6776082151860947,
            "fpr": 0.19846491228070176,
            "logloss": 1.8045516651692743,
            "mae": 0.33999290206170274,
            "precision": 0.6666666666666666,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7181705019553877,
            "auditor_fn_violation": 0.020307354555433595,
            "auditor_fp_violation": 0.013117328325777819,
            "ave_precision_score": 0.7142234508464085,
            "fpr": 0.18331503841931943,
            "logloss": 1.5830334460028828,
            "mae": 0.31298491027169884,
            "precision": 0.6854990583804144,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7690027317700744,
            "auditor_fn_violation": 0.016888694765960544,
            "auditor_fp_violation": 0.022898816809465528,
            "ave_precision_score": 0.769568961197042,
            "fpr": 0.14364035087719298,
            "logloss": 0.9412807115128384,
            "mae": 0.3130084572762337,
            "precision": 0.7170626349892009,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7224415732462538,
            "auditor_fn_violation": 0.011911849522781823,
            "auditor_fp_violation": 0.026159643336692275,
            "ave_precision_score": 0.7233695055633751,
            "fpr": 0.1712403951701427,
            "logloss": 1.046549463553401,
            "mae": 0.3341786683945972,
            "precision": 0.6796714579055442,
            "recall": 0.701271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6840345446328482,
            "auditor_fn_violation": 0.016938742083424344,
            "auditor_fp_violation": 0.005018359853121177,
            "ave_precision_score": 0.6885169775470928,
            "fpr": 0.08991228070175439,
            "logloss": 5.051396444213996,
            "mae": 0.42704710506178867,
            "precision": 0.725752508361204,
            "recall": 0.45020746887966806
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7176419426773595,
            "auditor_fn_violation": 0.0060373216245883776,
            "auditor_fp_violation": 0.0067712018883351825,
            "ave_precision_score": 0.7210736680326552,
            "fpr": 0.059275521405049394,
            "logloss": 4.847368167192008,
            "mae": 0.4027628621952027,
            "precision": 0.7931034482758621,
            "recall": 0.4385593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8267083406907745,
            "auditor_fn_violation": 0.03606591686685594,
            "auditor_fp_violation": 0.03836444308445532,
            "ave_precision_score": 0.8271738217579379,
            "fpr": 0.15899122807017543,
            "logloss": 0.6899577197276564,
            "mae": 0.3084696971548574,
            "precision": 0.725897920604915,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8473659227408084,
            "auditor_fn_violation": 0.036514632830378244,
            "auditor_fp_violation": 0.03931697876373057,
            "ave_precision_score": 0.8478243325778765,
            "fpr": 0.1437980241492865,
            "logloss": 0.5855645033651101,
            "mae": 0.2821468338595755,
            "precision": 0.745136186770428,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7733892543512693,
            "auditor_fn_violation": 0.03575198369367402,
            "auditor_fp_violation": 0.040789473684210535,
            "ave_precision_score": 0.7738688215452784,
            "fpr": 0.18859649122807018,
            "logloss": 0.7958966926441149,
            "mae": 0.3470403077062114,
            "precision": 0.6791044776119403,
            "recall": 0.7551867219917012
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8156033936086406,
            "auditor_fn_violation": 0.034184356918268245,
            "auditor_fp_violation": 0.037676687612051146,
            "ave_precision_score": 0.8160948978761425,
            "fpr": 0.16355653128430298,
            "logloss": 0.6481303964686566,
            "mae": 0.31937818574599386,
            "precision": 0.7101167315175098,
            "recall": 0.7733050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8092758947237623,
            "auditor_fn_violation": 0.0018335517216277243,
            "auditor_fp_violation": 0.005987352101183191,
            "ave_precision_score": 0.8095498728907464,
            "fpr": 0.1524122807017544,
            "logloss": 0.7399684376501461,
            "mae": 0.3125227582192994,
            "precision": 0.7225548902195609,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8093903280867816,
            "auditor_fn_violation": 0.007204785205306153,
            "auditor_fp_violation": 0.018373261253872567,
            "ave_precision_score": 0.8097802798509979,
            "fpr": 0.15367727771679474,
            "logloss": 0.6690315799602555,
            "mae": 0.3070225661635577,
            "precision": 0.7211155378486056,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8445899387478176,
            "auditor_fn_violation": 0.02905019290966004,
            "auditor_fp_violation": 0.028253773969808244,
            "ave_precision_score": 0.8449241314177474,
            "fpr": 0.13157894736842105,
            "logloss": 0.7247273697943336,
            "mae": 0.27258511359376875,
            "precision": 0.7614314115308151,
            "recall": 0.7946058091286307
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8549888345115466,
            "auditor_fn_violation": 0.030865690524474878,
            "auditor_fp_violation": 0.028687592047588452,
            "ave_precision_score": 0.8553169780916428,
            "fpr": 0.12403951701427003,
            "logloss": 0.6429488956090533,
            "mae": 0.25406092437589345,
            "precision": 0.7679671457905544,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8428533047478712,
            "auditor_fn_violation": 0.011381214966877778,
            "auditor_fp_violation": 0.01903814769481845,
            "ave_precision_score": 0.8430513036391687,
            "fpr": 0.13486842105263158,
            "logloss": 0.6963563959775142,
            "mae": 0.27876891567903445,
            "precision": 0.7520161290322581,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8136362472423743,
            "auditor_fn_violation": 0.010190887272321342,
            "auditor_fp_violation": 0.021783866636327944,
            "ave_precision_score": 0.8140382080168744,
            "fpr": 0.1690450054884742,
            "logloss": 0.7419246764087363,
            "mae": 0.29194713299196856,
            "precision": 0.7055449330783938,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8135536743008049,
            "auditor_fn_violation": 0.0025069156293222685,
            "auditor_fp_violation": 0.007843737250102002,
            "ave_precision_score": 0.8138231772224447,
            "fpr": 0.14692982456140352,
            "logloss": 0.7232291625058437,
            "mae": 0.3080506851560093,
            "precision": 0.7292929292929293,
            "recall": 0.7489626556016598
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8108927772775316,
            "auditor_fn_violation": 0.006172207855029861,
            "auditor_fp_violation": 0.01977350979798915,
            "ave_precision_score": 0.8113243357313689,
            "fpr": 0.15148188803512624,
            "logloss": 0.6651163270681483,
            "mae": 0.303706019365475,
            "precision": 0.7217741935483871,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8391109173760429,
            "auditor_fn_violation": 0.02571294678605227,
            "auditor_fp_violation": 0.027667278661770704,
            "ave_precision_score": 0.8394001245739051,
            "fpr": 0.1337719298245614,
            "logloss": 0.8586205491985757,
            "mae": 0.270080061655197,
            "precision": 0.7505112474437627,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8319520344058116,
            "auditor_fn_violation": 0.02504232636886268,
            "auditor_fp_violation": 0.028109989523140363,
            "ave_precision_score": 0.8323677779094393,
            "fpr": 0.1437980241492865,
            "logloss": 0.8322677218656237,
            "mae": 0.2638277484955329,
            "precision": 0.7436399217221135,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8411629189719471,
            "auditor_fn_violation": 0.0025478634345199196,
            "auditor_fp_violation": 0.016880864953080377,
            "ave_precision_score": 0.8413864516229058,
            "fpr": 0.1162280701754386,
            "logloss": 0.7188147487822008,
            "mae": 0.27867581750463966,
            "precision": 0.7675438596491229,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8052933902395222,
            "auditor_fn_violation": 0.010335076001413987,
            "auditor_fp_violation": 0.014062496093056525,
            "ave_precision_score": 0.8057497538357243,
            "fpr": 0.13830954994511527,
            "logloss": 0.788288662143797,
            "mae": 0.2946971681455821,
            "precision": 0.7341772151898734,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8098237361552234,
            "auditor_fn_violation": 0.03238516415520128,
            "auditor_fp_violation": 0.022817217462260304,
            "ave_precision_score": 0.8101547219707396,
            "fpr": 0.11732456140350878,
            "logloss": 0.85949235981776,
            "mae": 0.2970646311650715,
            "precision": 0.7584650112866818,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.80528738726686,
            "auditor_fn_violation": 0.025909784368081265,
            "auditor_fp_violation": 0.02740236391959573,
            "ave_precision_score": 0.8059397959427411,
            "fpr": 0.1251372118551043,
            "logloss": 0.8346716647840358,
            "mae": 0.28998125240191414,
            "precision": 0.7516339869281046,
            "recall": 0.7309322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8401044235413746,
            "auditor_fn_violation": 0.00605117565698479,
            "auditor_fp_violation": 0.011143410852713184,
            "ave_precision_score": 0.8403471147504982,
            "fpr": 0.1337719298245614,
            "logloss": 0.7309867974535889,
            "mae": 0.2726559080613798,
            "precision": 0.7525354969574036,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8289470141197793,
            "auditor_fn_violation": 0.0071257139667714785,
            "auditor_fp_violation": 0.019270920588404447,
            "ave_precision_score": 0.8292198091299767,
            "fpr": 0.14270032930845225,
            "logloss": 0.7119876318614262,
            "mae": 0.27715873030692145,
            "precision": 0.7430830039525692,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8498552988641088,
            "auditor_fn_violation": 0.009058564460944891,
            "auditor_fp_violation": 0.010368217054263565,
            "ave_precision_score": 0.850072509813195,
            "fpr": 0.12390350877192982,
            "logloss": 0.6703802678812273,
            "mae": 0.2712208805293427,
            "precision": 0.7660455486542443,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.84243007676118,
            "auditor_fn_violation": 0.00990716106346165,
            "auditor_fp_violation": 0.01357740999027328,
            "ave_precision_score": 0.8426969742174485,
            "fpr": 0.1207464324917673,
            "logloss": 0.6532373690800343,
            "mae": 0.2712019899804395,
            "precision": 0.7708333333333334,
            "recall": 0.7838983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.827918589305657,
            "auditor_fn_violation": 0.029209434374317535,
            "auditor_fp_violation": 0.0346797225622195,
            "ave_precision_score": 0.8284750653219669,
            "fpr": 0.18092105263157895,
            "logloss": 0.6720606346734187,
            "mae": 0.31443150107390305,
            "precision": 0.7069271758436945,
            "recall": 0.8257261410788381
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8249999325225781,
            "auditor_fn_violation": 0.029298219501758177,
            "auditor_fp_violation": 0.03848183052491817,
            "ave_precision_score": 0.8254978971984075,
            "fpr": 0.18660812294182216,
            "logloss": 0.6350280501171093,
            "mae": 0.29950249786981953,
            "precision": 0.7053726169844021,
            "recall": 0.8622881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7932273540554408,
            "auditor_fn_violation": 0.000932700007279605,
            "auditor_fp_violation": 0.004054467564259496,
            "ave_precision_score": 0.7935669745546509,
            "fpr": 0.12609649122807018,
            "logloss": 0.7260581991190388,
            "mae": 0.3361688276792438,
            "precision": 0.7294117647058823,
            "recall": 0.6431535269709544
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.80590350394587,
            "auditor_fn_violation": 0.005279167984520645,
            "auditor_fp_violation": 0.018805838036251438,
            "ave_precision_score": 0.8063200092126048,
            "fpr": 0.12184412733260154,
            "logloss": 0.628433721703795,
            "mae": 0.3217481989783524,
            "precision": 0.7357142857142858,
            "recall": 0.6546610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6781988373531532,
            "auditor_fn_violation": 0.013230690834971246,
            "auditor_fp_violation": 0.030038759689922492,
            "ave_precision_score": 0.6774368333698938,
            "fpr": 0.19736842105263158,
            "logloss": 1.7732282408907443,
            "mae": 0.3398271623150054,
            "precision": 0.6654275092936803,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7177826082313461,
            "auditor_fn_violation": 0.01908407598280898,
            "auditor_fp_violation": 0.01630539420747183,
            "ave_precision_score": 0.7142618291975986,
            "fpr": 0.1756311745334797,
            "logloss": 1.572998976109354,
            "mae": 0.3119045275945648,
            "precision": 0.6917148362235067,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8415728377720922,
            "auditor_fn_violation": 0.03347255587100532,
            "auditor_fp_violation": 0.020897082823337416,
            "ave_precision_score": 0.8418192324321123,
            "fpr": 0.11732456140350878,
            "logloss": 0.7770734371141449,
            "mae": 0.27860492612692067,
            "precision": 0.7688984881209503,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8457959262795485,
            "auditor_fn_violation": 0.025400472566931478,
            "auditor_fp_violation": 0.018240737730947247,
            "ave_precision_score": 0.846530299663818,
            "fpr": 0.11525795828759605,
            "logloss": 0.7235540747876242,
            "mae": 0.2572804191130986,
            "precision": 0.7784810126582279,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8493991746751727,
            "auditor_fn_violation": 0.023167358229598894,
            "auditor_fp_violation": 0.01897694818441453,
            "ave_precision_score": 0.849624882926097,
            "fpr": 0.11732456140350878,
            "logloss": 0.7182037418653808,
            "mae": 0.2710339298929325,
            "precision": 0.7688984881209503,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8511458522335557,
            "auditor_fn_violation": 0.021079461943478015,
            "auditor_fp_violation": 0.01979851423627694,
            "ave_precision_score": 0.8514058110766995,
            "fpr": 0.11855104281009879,
            "logloss": 0.6730304883650128,
            "mae": 0.25879076220397185,
            "precision": 0.773109243697479,
            "recall": 0.7796610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7732465321390789,
            "auditor_fn_violation": 0.03634345199097329,
            "auditor_fp_violation": 0.02798857609139127,
            "ave_precision_score": 0.7749064074329408,
            "fpr": 0.15570175438596492,
            "logloss": 1.7243178203111005,
            "mae": 0.29242348056587397,
            "precision": 0.7253384912959381,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7901708335486994,
            "auditor_fn_violation": 0.03462855122886008,
            "auditor_fp_violation": 0.039794563535027465,
            "ave_precision_score": 0.7908025073830269,
            "fpr": 0.15587266739846323,
            "logloss": 1.5871753335762562,
            "mae": 0.2767030273395661,
            "precision": 0.7315689981096408,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.800491702572935,
            "auditor_fn_violation": 0.02396811530901944,
            "auditor_fp_violation": 0.009399224806201555,
            "ave_precision_score": 0.8000120423416788,
            "fpr": 0.11293859649122807,
            "logloss": 0.7582067831062584,
            "mae": 0.3059991106633868,
            "precision": 0.7664399092970522,
            "recall": 0.7012448132780082
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.7814023477162274,
            "auditor_fn_violation": 0.027470278516809624,
            "auditor_fp_violation": 0.008801562277304222,
            "ave_precision_score": 0.7815919374208663,
            "fpr": 0.09330406147091108,
            "logloss": 0.8444850765943692,
            "mae": 0.2911045074052178,
            "precision": 0.8045977011494253,
            "recall": 0.7415254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8367411567363873,
            "auditor_fn_violation": 0.03046971682317829,
            "auditor_fp_violation": 0.02496940024479805,
            "ave_precision_score": 0.8369667365794379,
            "fpr": 0.13596491228070176,
            "logloss": 1.3697824265566165,
            "mae": 0.2862950803915273,
            "precision": 0.7416666666666667,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8404546623599987,
            "auditor_fn_violation": 0.02690282609909022,
            "auditor_fp_violation": 0.02557453948075784,
            "ave_precision_score": 0.8406849709305185,
            "fpr": 0.11855104281009879,
            "logloss": 1.236089379065037,
            "mae": 0.26837357449184535,
            "precision": 0.7692307692307693,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8071796235097992,
            "auditor_fn_violation": 0.02253039237096892,
            "auditor_fp_violation": 0.02548704610363117,
            "ave_precision_score": 0.8085201852510868,
            "fpr": 0.20285087719298245,
            "logloss": 0.9370766033897823,
            "mae": 0.29234656831860767,
            "precision": 0.6890756302521008,
            "recall": 0.8506224066390041
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8292892472223709,
            "auditor_fn_violation": 0.018921282256414075,
            "auditor_fp_violation": 0.03150809268645185,
            "ave_precision_score": 0.8295856021304487,
            "fpr": 0.20965971459934138,
            "logloss": 0.9100313129832194,
            "mae": 0.2883763481084234,
            "precision": 0.6894308943089431,
            "recall": 0.8983050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8481308530651759,
            "auditor_fn_violation": 0.006988425420397464,
            "auditor_fp_violation": 0.017559159526723784,
            "ave_precision_score": 0.8483489904493045,
            "fpr": 0.11403508771929824,
            "logloss": 0.7004455003890221,
            "mae": 0.26340769894317406,
            "precision": 0.7796610169491526,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8209621121210424,
            "auditor_fn_violation": 0.010551359095052932,
            "auditor_fp_violation": 0.010844424885417165,
            "ave_precision_score": 0.8214085238346422,
            "fpr": 0.12184412733260154,
            "logloss": 0.7458476766878677,
            "mae": 0.27770178163474474,
            "precision": 0.7618025751072961,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8359773993308512,
            "auditor_fn_violation": 0.006610795661352554,
            "auditor_fp_violation": 0.01407588739290086,
            "ave_precision_score": 0.8362280412836866,
            "fpr": 0.13925438596491227,
            "logloss": 0.7442488604844799,
            "mae": 0.27592629678500746,
            "precision": 0.744466800804829,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8265807876908313,
            "auditor_fn_violation": 0.008060615081210813,
            "auditor_fp_violation": 0.021321284528003727,
            "ave_precision_score": 0.826850232270985,
            "fpr": 0.14818880351262348,
            "logloss": 0.7193027326444731,
            "mae": 0.2799039097981827,
            "precision": 0.736328125,
            "recall": 0.798728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8504108231502041,
            "auditor_fn_violation": 0.004931935648249256,
            "auditor_fp_violation": 0.014764381884944925,
            "ave_precision_score": 0.8506346580295727,
            "fpr": 0.13815789473684212,
            "logloss": 0.6069036779458574,
            "mae": 0.27603269190872753,
            "precision": 0.7509881422924901,
            "recall": 0.7883817427385892
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8513098637415961,
            "auditor_fn_violation": 0.010139723529740088,
            "auditor_fp_violation": 0.019378439673041967,
            "ave_precision_score": 0.851573526887331,
            "fpr": 0.13062568605927552,
            "logloss": 0.5734432083408797,
            "mae": 0.27131154219682874,
            "precision": 0.7595959595959596,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.843574840259759,
            "auditor_fn_violation": 0.020988025041857754,
            "auditor_fp_violation": 0.021970624235006127,
            "ave_precision_score": 0.8438122126341584,
            "fpr": 0.14473684210526316,
            "logloss": 0.7740440567209286,
            "mae": 0.2736753648964784,
            "precision": 0.7421875,
            "recall": 0.7883817427385892
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8343104369692482,
            "auditor_fn_violation": 0.025744665017023573,
            "auditor_fp_violation": 0.02536200175531157,
            "ave_precision_score": 0.8345618578386654,
            "fpr": 0.15916575192096596,
            "logloss": 0.7567403320998352,
            "mae": 0.27193207426788757,
            "precision": 0.7264150943396226,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8434684723465611,
            "auditor_fn_violation": 0.006360559074033632,
            "auditor_fp_violation": 0.014570583435332523,
            "ave_precision_score": 0.8437074180503399,
            "fpr": 0.15021929824561403,
            "logloss": 0.7057237232878463,
            "mae": 0.27329490323418787,
            "precision": 0.7400379506641366,
            "recall": 0.8091286307053942
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8406522866102875,
            "auditor_fn_violation": 0.014039796089229572,
            "auditor_fp_violation": 0.021361291629264197,
            "ave_precision_score": 0.8409167354833043,
            "fpr": 0.16245883644346873,
            "logloss": 0.6677709481881576,
            "mae": 0.27002190598659637,
            "precision": 0.728440366972477,
            "recall": 0.8411016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8517914862042282,
            "auditor_fn_violation": 0.0069201790784013985,
            "auditor_fp_violation": 0.016569767441860464,
            "ave_precision_score": 0.8520070683649064,
            "fpr": 0.12828947368421054,
            "logloss": 0.6533928889887091,
            "mae": 0.2652038301763304,
            "precision": 0.7636363636363637,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8317820500138555,
            "auditor_fn_violation": 0.010967645909691343,
            "auditor_fp_violation": 0.01808320976973413,
            "ave_precision_score": 0.8322177182094368,
            "fpr": 0.15697036223929747,
            "logloss": 0.6705361002506417,
            "mae": 0.27374338031773343,
            "precision": 0.7265774378585086,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7946934682180968,
            "auditor_fn_violation": 0.005334589066026064,
            "auditor_fp_violation": 0.016110771113831097,
            "ave_precision_score": 0.7932412964668253,
            "fpr": 0.14473684210526316,
            "logloss": 1.0048260600757066,
            "mae": 0.26698818898140014,
            "precision": 0.7446808510638298,
            "recall": 0.7987551867219918
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7561289175828186,
            "auditor_fn_violation": 0.006214069098959983,
            "auditor_fp_violation": 0.009856749573049226,
            "ave_precision_score": 0.7530998857770916,
            "fpr": 0.1668496158068057,
            "logloss": 1.2365883590484041,
            "mae": 0.28114428281062775,
            "precision": 0.7174721189591078,
            "recall": 0.8177966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8135327266113399,
            "auditor_fn_violation": 0.0002525114653854544,
            "auditor_fp_violation": 0.005054059567523459,
            "ave_precision_score": 0.8138017124595249,
            "fpr": 0.14692982456140352,
            "logloss": 0.7296118658262065,
            "mae": 0.30774635890850066,
            "precision": 0.7281947261663286,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8105767270393622,
            "auditor_fn_violation": 0.002090736571843205,
            "auditor_fp_violation": 0.02152382047813487,
            "ave_precision_score": 0.8110094102042791,
            "fpr": 0.15367727771679474,
            "logloss": 0.6717212466316103,
            "mae": 0.3041710154470803,
            "precision": 0.720558882235529,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8485513449820761,
            "auditor_fn_violation": 0.02502820848802504,
            "auditor_fp_violation": 0.023128314973480214,
            "ave_precision_score": 0.8488155188217176,
            "fpr": 0.11951754385964912,
            "logloss": 0.7185216229283777,
            "mae": 0.26743724915772776,
            "precision": 0.7710084033613446,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8390452839936785,
            "auditor_fn_violation": 0.02357253158198292,
            "auditor_fp_violation": 0.022126427440870757,
            "ave_precision_score": 0.8394503182164136,
            "fpr": 0.12294182217343579,
            "logloss": 0.7164418631353443,
            "mae": 0.26266017796266483,
            "precision": 0.7647058823529411,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7828876209829625,
            "auditor_fn_violation": 0.006624444929751762,
            "auditor_fp_violation": 0.008465932272541821,
            "ave_precision_score": 0.7832204706781085,
            "fpr": 0.07675438596491228,
            "logloss": 0.781197400924743,
            "mae": 0.3621650057210373,
            "precision": 0.7784810126582279,
            "recall": 0.5103734439834025
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.814554578774985,
            "auditor_fn_violation": 0.011386258348992543,
            "auditor_fp_violation": 0.007261288878775983,
            "ave_precision_score": 0.8149756254369763,
            "fpr": 0.054884742041712405,
            "logloss": 0.669174052046801,
            "mae": 0.33368272192597026,
            "precision": 0.8281786941580757,
            "recall": 0.510593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8436108690710818,
            "auditor_fn_violation": 0.00017971536725631615,
            "auditor_fp_violation": 0.015006629946960427,
            "ave_precision_score": 0.8438498208349338,
            "fpr": 0.14364035087719298,
            "logloss": 0.6967699668989854,
            "mae": 0.27303450916839245,
            "precision": 0.747104247104247,
            "recall": 0.8029045643153527
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8377712336308076,
            "auditor_fn_violation": 0.012372323206013136,
            "auditor_fp_violation": 0.021231268550167662,
            "ave_precision_score": 0.8380297890638976,
            "fpr": 0.1525795828759605,
            "logloss": 0.663145301868941,
            "mae": 0.2730383271229544,
            "precision": 0.7362428842504743,
            "recall": 0.8220338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7741504196061275,
            "auditor_fn_violation": 0.03457359685520857,
            "auditor_fp_violation": 0.030064259485924116,
            "ave_precision_score": 0.7749097959702272,
            "fpr": 0.16447368421052633,
            "logloss": 1.7239849935847529,
            "mae": 0.2903224756690113,
            "precision": 0.7201492537313433,
            "recall": 0.8008298755186722
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7804622660395069,
            "auditor_fn_violation": 0.03225873969748275,
            "auditor_fp_violation": 0.04169740128872875,
            "ave_precision_score": 0.781126163923681,
            "fpr": 0.16245883644346873,
            "logloss": 1.6231450441364184,
            "mae": 0.2781825185432181,
            "precision": 0.7264325323475046,
            "recall": 0.8326271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7793362646576999,
            "auditor_fn_violation": 0.008403399577782642,
            "auditor_fp_violation": 0.004895960832313342,
            "ave_precision_score": 0.7796903582397459,
            "fpr": 0.06578947368421052,
            "logloss": 0.8519302850121775,
            "mae": 0.370339468648142,
            "precision": 0.781021897810219,
            "recall": 0.44398340248962653
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8057882874472295,
            "auditor_fn_violation": 0.007281530819178043,
            "auditor_fp_violation": 0.006613673927122064,
            "ave_precision_score": 0.8062444516412732,
            "fpr": 0.052689352360043906,
            "logloss": 0.7574938292654119,
            "mae": 0.345042506282248,
            "precision": 0.8228782287822878,
            "recall": 0.4724576271186441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.835819487171432,
            "auditor_fn_violation": 0.001697059037635587,
            "auditor_fp_violation": 0.01333639330885354,
            "ave_precision_score": 0.8360901510749027,
            "fpr": 0.1425438596491228,
            "logloss": 0.7757287509294233,
            "mae": 0.27014887950380545,
            "precision": 0.748062015503876,
            "recall": 0.8008298755186722
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.82033072976987,
            "auditor_fn_violation": 0.010790898435319727,
            "auditor_fp_violation": 0.025121959147748726,
            "ave_precision_score": 0.8206288320617043,
            "fpr": 0.16794731064763996,
            "logloss": 0.7772708198245366,
            "mae": 0.2801681510545489,
            "precision": 0.7150837988826816,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8398153159540043,
            "auditor_fn_violation": 0.024941763121496693,
            "auditor_fp_violation": 0.02214657282741738,
            "ave_precision_score": 0.8400344179608051,
            "fpr": 0.11513157894736842,
            "logloss": 0.832712473941322,
            "mae": 0.28132455360593306,
            "precision": 0.7676991150442478,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8351956844428097,
            "auditor_fn_violation": 0.020409682040596115,
            "auditor_fp_violation": 0.024581863280732332,
            "ave_precision_score": 0.8355201746664846,
            "fpr": 0.1163556531284303,
            "logloss": 0.8228232375567669,
            "mae": 0.2706255153629331,
            "precision": 0.7665198237885462,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8632183007692338,
            "auditor_fn_violation": 0.005593925165611125,
            "auditor_fp_violation": 0.006624847001223997,
            "ave_precision_score": 0.8634194391595715,
            "fpr": 0.13596491228070176,
            "logloss": 0.592677309878278,
            "mae": 0.26754275290719326,
            "precision": 0.7592233009708738,
            "recall": 0.8112033195020747
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8624627031456985,
            "auditor_fn_violation": 0.01187463952817727,
            "auditor_fp_violation": 0.017283067744524656,
            "ave_precision_score": 0.8627052763874993,
            "fpr": 0.14489571899012074,
            "logloss": 0.5578041957778047,
            "mae": 0.2606494585501982,
            "precision": 0.7490494296577946,
            "recall": 0.8347457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7106302090729639,
            "auditor_fn_violation": 0.030406020237315277,
            "auditor_fp_violation": 0.028327723378212977,
            "ave_precision_score": 0.7140432566368116,
            "fpr": 0.11293859649122807,
            "logloss": 4.494972157570758,
            "mae": 0.38918234620115144,
            "precision": 0.7146814404432132,
            "recall": 0.5352697095435685
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7380721035754936,
            "auditor_fn_violation": 0.03061219743623139,
            "auditor_fp_violation": 0.025772074543231424,
            "ave_precision_score": 0.7414099467019606,
            "fpr": 0.09001097694840834,
            "logloss": 4.202713011122591,
            "mae": 0.35659905392828833,
            "precision": 0.760932944606414,
            "recall": 0.5529661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7009900027014558,
            "auditor_fn_violation": 0.03519008881123973,
            "auditor_fp_violation": 0.02348531211750306,
            "ave_precision_score": 0.7039545717165931,
            "fpr": 0.08771929824561403,
            "logloss": 5.543668626885007,
            "mae": 0.4032864973605908,
            "precision": 0.7306397306397306,
            "recall": 0.45020746887966806
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7239713644345729,
            "auditor_fn_violation": 0.035089024912091406,
            "auditor_fp_violation": 0.020356113210094798,
            "ave_precision_score": 0.726335345669176,
            "fpr": 0.06915477497255763,
            "logloss": 5.14536249814861,
            "mae": 0.37418930502924336,
            "precision": 0.78125,
            "recall": 0.4766949152542373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8380322370957266,
            "auditor_fn_violation": 0.0029823651452282156,
            "auditor_fp_violation": 0.013094145246838025,
            "ave_precision_score": 0.8382938542646408,
            "fpr": 0.13486842105263158,
            "logloss": 0.7570886666762179,
            "mae": 0.2704760078583064,
            "precision": 0.7559523809523809,
            "recall": 0.7904564315352697
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8248972021854515,
            "auditor_fn_violation": 0.013283968073824629,
            "auditor_fp_violation": 0.02303908943837531,
            "ave_precision_score": 0.8251910845377135,
            "fpr": 0.16136114160263446,
            "logloss": 0.7479563697083236,
            "mae": 0.2772121937380571,
            "precision": 0.7247191011235955,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8093600556191947,
            "auditor_fn_violation": 0.005430133944820563,
            "auditor_fp_violation": 0.007649938800489605,
            "ave_precision_score": 0.8096606934307986,
            "fpr": 0.1787280701754386,
            "logloss": 0.8079266101224349,
            "mae": 0.306662182793444,
            "precision": 0.7036363636363636,
            "recall": 0.8029045643153527
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7967941066235406,
            "auditor_fn_violation": 0.004911719287800709,
            "auditor_fp_violation": 0.01742059215510754,
            "ave_precision_score": 0.7972521263013178,
            "fpr": 0.1800219538968167,
            "logloss": 0.7769102058048233,
            "mae": 0.30526281136436606,
            "precision": 0.6985294117647058,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8474297254008152,
            "auditor_fn_violation": 0.03090194365582006,
            "auditor_fp_violation": 0.021830375356997143,
            "ave_precision_score": 0.8476829663648817,
            "fpr": 0.10855263157894737,
            "logloss": 0.7404704661872412,
            "mae": 0.27106031779816114,
            "precision": 0.779510022271715,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8380032409357359,
            "auditor_fn_violation": 0.02552140504939627,
            "auditor_fp_violation": 0.020293602114375302,
            "ave_precision_score": 0.8384826725461542,
            "fpr": 0.10537870472008781,
            "logloss": 0.7350929684566644,
            "mae": 0.2621336131927174,
            "precision": 0.7866666666666666,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8083577054635712,
            "auditor_fn_violation": 0.0308154982892917,
            "auditor_fp_violation": 0.031992044063647494,
            "ave_precision_score": 0.8088393378206833,
            "fpr": 0.14912280701754385,
            "logloss": 0.8813359124109784,
            "mae": 0.29463348832289976,
            "precision": 0.7301587301587301,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8288399384366364,
            "auditor_fn_violation": 0.03271456213138849,
            "auditor_fp_violation": 0.034001035183745115,
            "ave_precision_score": 0.8291579470315513,
            "fpr": 0.14928649835345773,
            "logloss": 0.7785944201938313,
            "mae": 0.27633026087278145,
            "precision": 0.7369439071566731,
            "recall": 0.8072033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.826028902790169,
            "auditor_fn_violation": 0.022264231637184245,
            "auditor_fp_violation": 0.02988066095471236,
            "ave_precision_score": 0.8262978726912806,
            "fpr": 0.15021929824561403,
            "logloss": 0.8392824184090023,
            "mae": 0.2825860370770126,
            "precision": 0.7303149606299213,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8265960002982756,
            "auditor_fn_violation": 0.022658561089508644,
            "auditor_fp_violation": 0.03409105116158119,
            "ave_precision_score": 0.827196030939098,
            "fpr": 0.16355653128430298,
            "logloss": 0.8363866812896184,
            "mae": 0.2777126974368857,
            "precision": 0.7178030303030303,
            "recall": 0.8029661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8445525420757671,
            "auditor_fn_violation": 0.025264795806944754,
            "auditor_fp_violation": 0.023128314973480214,
            "ave_precision_score": 0.8447991810109994,
            "fpr": 0.11951754385964912,
            "logloss": 0.7854410722497484,
            "mae": 0.2708439107607202,
            "precision": 0.7645788336933045,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.837856040506157,
            "auditor_fn_violation": 0.02306554540549592,
            "auditor_fp_violation": 0.020551147828739603,
            "ave_precision_score": 0.8381693449182963,
            "fpr": 0.11086717892425905,
            "logloss": 0.7767136431795784,
            "mae": 0.26422060736450037,
            "precision": 0.7818574514038877,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7888332134031097,
            "auditor_fn_violation": 0.028426876319429285,
            "auditor_fp_violation": 0.0333919828641371,
            "ave_precision_score": 0.7904249072802082,
            "fpr": 0.2225877192982456,
            "logloss": 1.017500660124911,
            "mae": 0.3056157960275086,
            "precision": 0.6699186991869919,
            "recall": 0.8547717842323651
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8146105243419978,
            "auditor_fn_violation": 0.02329810787177436,
            "auditor_fp_violation": 0.04173490794616045,
            "ave_precision_score": 0.8149411826958461,
            "fpr": 0.2283205268935236,
            "logloss": 0.987058985697647,
            "mae": 0.29831854334016955,
            "precision": 0.6693163751987281,
            "recall": 0.8919491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8129209245099713,
            "auditor_fn_violation": 3.639804906457731e-05,
            "auditor_fp_violation": 0.005054059567523459,
            "ave_precision_score": 0.8131913606399487,
            "fpr": 0.14692982456140352,
            "logloss": 0.7329128064475996,
            "mae": 0.3081108903661615,
            "precision": 0.7276422764227642,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8104028178607797,
            "auditor_fn_violation": 0.002090736571843205,
            "auditor_fp_violation": 0.02134128807863396,
            "ave_precision_score": 0.8108106095291904,
            "fpr": 0.1525795828759605,
            "logloss": 0.6744410699518033,
            "mae": 0.30456949752069606,
            "precision": 0.722,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.845510174715524,
            "auditor_fn_violation": 0.03258990318118949,
            "auditor_fp_violation": 0.020236638106895143,
            "ave_precision_score": 0.8457408871172827,
            "fpr": 0.12280701754385964,
            "logloss": 0.800936162164432,
            "mae": 0.27581619240174865,
            "precision": 0.7622080679405521,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.848180744371972,
            "auditor_fn_violation": 0.022926007925728856,
            "auditor_fp_violation": 0.01911089218336255,
            "ave_precision_score": 0.84856244588293,
            "fpr": 0.11745334796926454,
            "logloss": 0.756913589517517,
            "mae": 0.25786459487512503,
            "precision": 0.773784355179704,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8644148523695823,
            "auditor_fn_violation": 0.010132306908349714,
            "auditor_fp_violation": 0.019772541819665448,
            "ave_precision_score": 0.8645986873376053,
            "fpr": 0.19517543859649122,
            "logloss": 0.831008928332539,
            "mae": 0.266644504700745,
            "precision": 0.7062706270627063,
            "recall": 0.8879668049792531
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8433995472777809,
            "auditor_fn_violation": 0.011260674617202182,
            "auditor_fp_violation": 0.022879061033333422,
            "ave_precision_score": 0.8437100240337949,
            "fpr": 0.21405049396267836,
            "logloss": 1.003619673736132,
            "mae": 0.28090991894044,
            "precision": 0.6818923327895595,
            "recall": 0.885593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.6970976369874686,
            "auditor_fn_violation": 0.0013103297663245267,
            "auditor_fp_violation": 0.02304161566707466,
            "ave_precision_score": 0.6971721249084712,
            "fpr": 0.15789473684210525,
            "logloss": 1.7740895382208453,
            "mae": 0.29734547070568107,
            "precision": 0.7230769230769231,
            "recall": 0.7800829875518672
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7100884325191028,
            "auditor_fn_violation": 0.010381588494669669,
            "auditor_fp_violation": 0.013259853624018271,
            "ave_precision_score": 0.7075475489660119,
            "fpr": 0.16575192096597147,
            "logloss": 1.5567290325188403,
            "mae": 0.2927749520707565,
            "precision": 0.713472485768501,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7525947686140733,
            "auditor_fn_violation": 0.036448096382033925,
            "auditor_fp_violation": 0.016442268461852306,
            "ave_precision_score": 0.7534576373738372,
            "fpr": 0.0756578947368421,
            "logloss": 2.5968644307435325,
            "mae": 0.32510425425830075,
            "precision": 0.8050847457627118,
            "recall": 0.5912863070539419
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7664568173221256,
            "auditor_fn_violation": 0.031554075424659066,
            "auditor_fp_violation": 0.025984612268677695,
            "ave_precision_score": 0.7671190814656171,
            "fpr": 0.07683863885839737,
            "logloss": 2.195699922117399,
            "mae": 0.30271529315342666,
            "precision": 0.8066298342541437,
            "recall": 0.6186440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7832348695891034,
            "auditor_fn_violation": 0.005154873698769746,
            "auditor_fp_violation": 0.00038249694002448487,
            "ave_precision_score": 0.7836794018013326,
            "fpr": 0.15899122807017543,
            "logloss": 0.618909648919921,
            "mae": 0.35169874985085536,
            "precision": 0.7094188376753507,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.79953518379764,
            "auditor_fn_violation": 0.007121062717445909,
            "auditor_fp_violation": 0.012354692958000048,
            "ave_precision_score": 0.7998439998429432,
            "fpr": 0.17233809001097694,
            "logloss": 0.5785782117757148,
            "mae": 0.34398803301257797,
            "precision": 0.697495183044316,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.68331435057601,
            "auditor_fn_violation": 0.01956395137220645,
            "auditor_fp_violation": 0.032114443084455324,
            "ave_precision_score": 0.6820204593695081,
            "fpr": 0.19298245614035087,
            "logloss": 1.7806300729675102,
            "mae": 0.3396716693598988,
            "precision": 0.6685499058380414,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7213997258288453,
            "auditor_fn_violation": 0.01866081229418222,
            "auditor_fp_violation": 0.012842279504612069,
            "ave_precision_score": 0.7180468444941599,
            "fpr": 0.17233809001097694,
            "logloss": 1.5820215710294747,
            "mae": 0.31084246966356976,
            "precision": 0.6963249516441006,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8132417555025079,
            "auditor_fn_violation": 0.0075298464002329455,
            "auditor_fp_violation": 0.014713382292941661,
            "ave_precision_score": 0.8135558454265722,
            "fpr": 0.13048245614035087,
            "logloss": 0.6489812313794447,
            "mae": 0.33156060742971943,
            "precision": 0.7373068432671082,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8477395774909118,
            "auditor_fn_violation": 0.013523507414091427,
            "auditor_fp_violation": 0.005495975535657579,
            "ave_precision_score": 0.8481590360387372,
            "fpr": 0.09989023051591657,
            "logloss": 0.5260367490124235,
            "mae": 0.2970450120744707,
            "precision": 0.7959641255605381,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.839373757891775,
            "auditor_fn_violation": 0.005641697605008372,
            "auditor_fp_violation": 0.013922888616891067,
            "ave_precision_score": 0.8396217138955047,
            "fpr": 0.15350877192982457,
            "logloss": 0.7306683224761844,
            "mae": 0.2748989898394277,
            "precision": 0.7368421052631579,
            "recall": 0.8132780082987552
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.831560353578672,
            "auditor_fn_violation": 0.011535098327410745,
            "auditor_fp_violation": 0.020813694430761455,
            "ave_precision_score": 0.831858821979834,
            "fpr": 0.16794731064763996,
            "logloss": 0.6951727601622452,
            "mae": 0.2745278989428835,
            "precision": 0.7213114754098361,
            "recall": 0.8389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6727503358972855,
            "auditor_fn_violation": 0.01525078255805489,
            "auditor_fp_violation": 0.03546511627906978,
            "ave_precision_score": 0.6718118654259093,
            "fpr": 0.20723684210526316,
            "logloss": 1.8773908841644693,
            "mae": 0.342296076530909,
            "precision": 0.6569872958257713,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7159828295235509,
            "auditor_fn_violation": 0.016911942547768337,
            "auditor_fp_violation": 0.01636290441553376,
            "ave_precision_score": 0.7122123017523192,
            "fpr": 0.18441273326015367,
            "logloss": 1.5963573781495384,
            "mae": 0.31311832715399945,
            "precision": 0.6894639556377079,
            "recall": 0.7902542372881356
        }
    }
]