[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.7617172469442,
            "mae": 0.5142543859649122,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.38782277884927,
            "mae": 0.5323819978046103,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5080572059434478,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5011623794596054,
            "fpr": 0.06907894736842106,
            "logloss": 0.6970082689548796,
            "mae": 0.5013383374337042,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5696835868671956,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5592186000983967,
            "fpr": 0.042810098792535674,
            "logloss": 0.6948484919731182,
            "mae": 0.5002615243098346,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5101220478961874,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5039982748026425,
            "fpr": 0.06907894736842106,
            "logloss": 0.6969612091654569,
            "mae": 0.5013235111704522,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.569909559364294,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5598053537409216,
            "fpr": 0.042810098792535674,
            "logloss": 0.6947372948233939,
            "mae": 0.5002163041436188,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5080572059434478,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5011623794596054,
            "fpr": 0.06907894736842106,
            "logloss": 0.6970505341433176,
            "mae": 0.5013489542169529,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5696835868671956,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5592186000983967,
            "fpr": 0.042810098792535674,
            "logloss": 0.6948880641224763,
            "mae": 0.5002705794069037,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 29198,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.5246290819202806,
            "auditor_fn_violation": 0.04314190326562679,
            "auditor_fp_violation": 0.05525523741633995,
            "ave_precision_score": 0.5316171125052174,
            "fpr": 0.18859649122807018,
            "logloss": 0.692195545230618,
            "mae": 0.49874733591027426,
            "precision": 0.5071633237822349,
            "recall": 0.3773987206823028
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5581935122377146,
            "auditor_fn_violation": 0.04477236977604762,
            "auditor_fp_violation": 0.05433847136974795,
            "ave_precision_score": 0.5519448282289368,
            "fpr": 0.16245883644346873,
            "logloss": 0.6921860692182386,
            "mae": 0.49876690660035966,
            "precision": 0.5432098765432098,
            "recall": 0.3628865979381443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7136084361575332,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517415180781213,
            "fpr": 0.2982456140350877,
            "logloss": 0.6858439317071058,
            "mae": 0.4923833824955581,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7243611112925153,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757487382013154,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826786255070572,
            "mae": 0.4909037955178911,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.713611642637677,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517434236827563,
            "fpr": 0.2982456140350877,
            "logloss": 0.6858433293221564,
            "mae": 0.492382154326167,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7243566707248313,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757410469250358,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826777915740985,
            "mae": 0.4909024770840855,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.4461056002825772,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.4453604686052385,
            "fpr": 0.06907894736842106,
            "logloss": 0.6971773286201067,
            "mae": 0.5014254536414355,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5091016628881047,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.51039670654679,
            "fpr": 0.042810098792535674,
            "logloss": 0.6949505548556514,
            "mae": 0.5003169786459005,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.4461043279355148,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.44535524501685425,
            "fpr": 0.06907894736842106,
            "logloss": 0.6971792877170898,
            "mae": 0.5014259473731121,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5090940843754848,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.510384405277326,
            "fpr": 0.042810098792535674,
            "logloss": 0.6949523998464867,
            "mae": 0.5003174055617151,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7136110472816249,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517428166122487,
            "fpr": 0.2982456140350877,
            "logloss": 0.6858453583761145,
            "mae": 0.49238639308564497,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7243517278488066,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757335989832114,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826806180061685,
            "mae": 0.4909070280393837,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5003098943196902,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.500720895860752,
            "fpr": 0.06907894736842106,
            "logloss": 0.697020673657708,
            "mae": 0.5013420103738705,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5541813538616014,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.556334230294891,
            "fpr": 0.042810098792535674,
            "logloss": 0.6948512037650835,
            "mae": 0.5002609090603536,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.8240227829492504,
            "auditor_fn_violation": 0.008367467175401199,
            "auditor_fp_violation": 0.006556671022929787,
            "ave_precision_score": 0.8242265694245889,
            "fpr": 0.019736842105263157,
            "logloss": 0.83760185566148,
            "mae": 0.4128696472490249,
            "precision": 0.9005524861878453,
            "recall": 0.34754797441364604
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8625210873087423,
            "auditor_fn_violation": 0.010327384657168403,
            "auditor_fp_violation": 0.003625485072896214,
            "ave_precision_score": 0.8625437702947709,
            "fpr": 0.01646542261251372,
            "logloss": 0.8732293158706603,
            "mae": 0.4078343374927023,
            "precision": 0.9206349206349206,
            "recall": 0.35876288659793815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7136070268668315,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517374355123402,
            "fpr": 0.2982456140350877,
            "logloss": 0.685845991552871,
            "mae": 0.49238772638011397,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7243576830541905,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757418817246658,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826815055890145,
            "mae": 0.49090846057911736,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7897367352108196,
            "auditor_fn_violation": 0.0006008491377698197,
            "auditor_fp_violation": 0.007395746703100868,
            "ave_precision_score": 0.7903063448862521,
            "fpr": 0.03399122807017544,
            "logloss": 0.6600782335181183,
            "mae": 0.40280020800453614,
            "precision": 0.8577981651376146,
            "recall": 0.39872068230277186
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8109818076614886,
            "auditor_fn_violation": 0.006959611619722299,
            "auditor_fp_violation": 0.0005771916533964123,
            "ave_precision_score": 0.8112277275225225,
            "fpr": 0.02854006586169045,
            "logloss": 0.6381124132021306,
            "mae": 0.39765817152502875,
            "precision": 0.8898305084745762,
            "recall": 0.4329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.776408533745065,
            "auditor_fn_violation": 0.0021999962593049847,
            "auditor_fp_violation": 0.0073982218525998995,
            "ave_precision_score": 0.7769867293399149,
            "fpr": 0.03508771929824561,
            "logloss": 0.6591518547081104,
            "mae": 0.40276931014286993,
            "precision": 0.8620689655172413,
            "recall": 0.42643923240938164
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.8025814075966461,
            "auditor_fn_violation": 0.006900766123100261,
            "auditor_fp_violation": 0.0009817411604644338,
            "ave_precision_score": 0.8028412986087375,
            "fpr": 0.029637760702524697,
            "logloss": 0.6361421921016059,
            "mae": 0.3972350647306897,
            "precision": 0.8875,
            "recall": 0.43917525773195876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7140416492297904,
            "auditor_fn_violation": 0.01798806718288258,
            "auditor_fp_violation": 0.025229198843610162,
            "ave_precision_score": 0.7152184440623991,
            "fpr": 0.2982456140350877,
            "logloss": 1.4039205487189612,
            "mae": 0.36067719972321255,
            "precision": 0.6103151862464183,
            "recall": 0.908315565031983
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7300003631810135,
            "auditor_fn_violation": 0.010259486007219891,
            "auditor_fp_violation": 0.02069129007488032,
            "ave_precision_score": 0.7294422238663175,
            "fpr": 0.287596048298573,
            "logloss": 1.4985866233229088,
            "mae": 0.3470039375887839,
            "precision": 0.6288951841359773,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.4535156207422518,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.009752089026177187,
            "ave_precision_score": 0.45304846308385205,
            "fpr": 0.07017543859649122,
            "logloss": 0.6976188804687669,
            "mae": 0.5015351667085237,
            "precision": 0.452991452991453,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.515873373503793,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.009673113691295232,
            "ave_precision_score": 0.5166555034095986,
            "fpr": 0.043907793633369926,
            "logloss": 0.6953396812401514,
            "mae": 0.5004007138810749,
            "precision": 0.6116504854368932,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6935626467936611,
            "mae": 0.500171523671924,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939989286000984,
            "mae": 0.5003896540462252,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7158440074944907,
            "auditor_fn_violation": 0.00212752029327049,
            "auditor_fp_violation": 0.01789038057898697,
            "ave_precision_score": 0.7162866183718857,
            "fpr": 0.09978070175438597,
            "logloss": 0.6617174402472227,
            "mae": 0.4554198957947001,
            "precision": 0.6486486486486487,
            "recall": 0.3582089552238806
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7554576197059109,
            "auditor_fn_violation": 0.006221779623615163,
            "auditor_fp_violation": 0.01827945352318816,
            "ave_precision_score": 0.7557104056288001,
            "fpr": 0.09659714599341383,
            "logloss": 0.6420113448809187,
            "mae": 0.45120935120776245,
            "precision": 0.6752767527675276,
            "recall": 0.37731958762886597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7600665946418117,
            "auditor_fn_violation": 0.013873302659634167,
            "auditor_fp_violation": 0.02819690309294682,
            "ave_precision_score": 0.7302321923747743,
            "fpr": 0.13706140350877194,
            "logloss": 2.464871555854404,
            "mae": 0.36347445511163,
            "precision": 0.7119815668202765,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7543772412188261,
            "auditor_fn_violation": 0.01696334604546947,
            "auditor_fp_violation": 0.015463067464427988,
            "ave_precision_score": 0.720575738822062,
            "fpr": 0.13721185510428102,
            "logloss": 2.793124529422245,
            "mae": 0.3669448021579824,
            "precision": 0.7159090909090909,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7413463528266218,
            "auditor_fn_violation": 0.013279467325028993,
            "auditor_fp_violation": 0.028313235119401217,
            "ave_precision_score": 0.7038897669281627,
            "fpr": 0.1425438596491228,
            "logloss": 2.4434789530118963,
            "mae": 0.3886172737958923,
            "precision": 0.7045454545454546,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7369697656574381,
            "auditor_fn_violation": 0.01299580160014485,
            "auditor_fp_violation": 0.012221517910978497,
            "ave_precision_score": 0.6972758414501219,
            "fpr": 0.1394072447859495,
            "logloss": 2.6237111856899644,
            "mae": 0.391457112638932,
            "precision": 0.713963963963964,
            "recall": 0.6536082474226804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6935626467936611,
            "mae": 0.500171523671924,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6939989286000984,
            "mae": 0.5003896540462252,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5597091743217318,
            "auditor_fn_violation": 0.00947564807541242,
            "auditor_fp_violation": 0.011462417330006735,
            "ave_precision_score": 0.5343843350380214,
            "fpr": 0.06140350877192982,
            "logloss": 0.6923631896977654,
            "mae": 0.49386508357629444,
            "precision": 0.6190476190476191,
            "recall": 0.19402985074626866
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6683930270825513,
            "auditor_fn_violation": 0.0010682720925232377,
            "auditor_fp_violation": 0.011456223620537716,
            "ave_precision_score": 0.5738075263563169,
            "fpr": 0.052689352360043906,
            "logloss": 0.6825530948838158,
            "mae": 0.48914054798373274,
            "precision": 0.6942675159235668,
            "recall": 0.22474226804123712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6420532861287069,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.6446340564096038,
            "fpr": 0.2982456140350877,
            "logloss": 0.6858606959152774,
            "mae": 0.4923130055856809,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.678216948560299,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.6804011639583549,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826504758109608,
            "mae": 0.4908132956462425,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7136084714946512,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517422411709663,
            "fpr": 0.2982456140350877,
            "logloss": 0.6857708755188745,
            "mae": 0.49234048819594217,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.724375427788356,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757758512973976,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826578708729857,
            "mae": 0.4908827268462281,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 29198,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.624970386164416,
            "auditor_fn_violation": 0.003579377548348486,
            "auditor_fp_violation": 0.0028711734188745,
            "ave_precision_score": 0.5200189528547737,
            "fpr": 0.005482456140350877,
            "logloss": 0.6940862311970356,
            "mae": 0.49832822663480775,
            "precision": 0.7222222222222222,
            "recall": 0.02771855010660981
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7396067913738537,
            "auditor_fn_violation": 0.006328154175201154,
            "auditor_fp_violation": 0.0005771916533964122,
            "ave_precision_score": 0.5439558507889445,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6922862451724678,
            "mae": 0.49782507695691125,
            "precision": 0.9333333333333333,
            "recall": 0.0288659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.758711425545161,
            "auditor_fn_violation": 0.013279467325028993,
            "auditor_fp_violation": 0.02851867252782068,
            "ave_precision_score": 0.7289009580520495,
            "fpr": 0.14035087719298245,
            "logloss": 2.2596272710943843,
            "mae": 0.39154756098593535,
            "precision": 0.7077625570776256,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7516301546599178,
            "auditor_fn_violation": 0.01251598447384205,
            "auditor_fp_violation": 0.012221517910978497,
            "ave_precision_score": 0.7177471495350283,
            "fpr": 0.1394072447859495,
            "logloss": 2.5340559332113712,
            "mae": 0.396407557632999,
            "precision": 0.7126696832579186,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7574333912912975,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.757536382697646,
            "fpr": 0.4780701754385965,
            "logloss": 3.7587338153619543,
            "mae": 0.4785660553126243,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7553834395687234,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7560522287714235,
            "fpr": 0.4621295279912184,
            "logloss": 3.670154112531841,
            "mae": 0.4616819103974086,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7403353856868318,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.741163895613434,
            "fpr": 0.4780701754385965,
            "logloss": 2.993861948117269,
            "mae": 0.4734058620747678,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7511632183992262,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7520494539023028,
            "fpr": 0.4621295279912184,
            "logloss": 2.935829591457664,
            "mae": 0.4589041556007875,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7235179218396566,
            "auditor_fn_violation": 0.017207197097220666,
            "auditor_fp_violation": 0.027041008276899925,
            "ave_precision_score": 0.6963072473829856,
            "fpr": 0.13706140350877194,
            "logloss": 2.140213045356943,
            "mae": 0.412228664873462,
            "precision": 0.7030878859857482,
            "recall": 0.6311300639658849
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7145296572711125,
            "auditor_fn_violation": 0.01603539782950649,
            "auditor_fp_violation": 0.011564447055549548,
            "ave_precision_score": 0.6841368788108461,
            "fpr": 0.13830954994511527,
            "logloss": 2.4214684152543944,
            "mae": 0.4209295101995395,
            "precision": 0.7007125890736342,
            "recall": 0.6082474226804123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 29198,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.624970386164416,
            "auditor_fn_violation": 0.003579377548348486,
            "auditor_fp_violation": 0.0028711734188745,
            "ave_precision_score": 0.5200189528547737,
            "fpr": 0.005482456140350877,
            "logloss": 0.6940862311970356,
            "mae": 0.49832822663480775,
            "precision": 0.7222222222222222,
            "recall": 0.02771855010660981
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7396067913738537,
            "auditor_fn_violation": 0.006328154175201154,
            "auditor_fp_violation": 0.0005771916533964122,
            "ave_precision_score": 0.5439558507889445,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6922862451724678,
            "mae": 0.49782507695691125,
            "precision": 0.9333333333333333,
            "recall": 0.0288659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7605820101616302,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7606800931924406,
            "fpr": 0.4780701754385965,
            "logloss": 3.7538251066471746,
            "mae": 0.478573894192704,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7589240847186113,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.75967065227955,
            "fpr": 0.4621295279912184,
            "logloss": 3.6615442111424086,
            "mae": 0.46168296856312957,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7983431021602634,
            "auditor_fn_violation": 0.007832080200501254,
            "auditor_fp_violation": 0.028038493525008906,
            "ave_precision_score": 0.7998085658429737,
            "fpr": 0.21710526315789475,
            "logloss": 0.6587068504331697,
            "mae": 0.3273461020243734,
            "precision": 0.67,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8159011642921712,
            "auditor_fn_violation": 0.0068622902214627675,
            "auditor_fp_violation": 0.034832485583092404,
            "ave_precision_score": 0.8167806332578031,
            "fpr": 0.19099890230515917,
            "logloss": 0.6205820751830711,
            "mae": 0.3089491768118299,
            "precision": 0.7085427135678392,
            "recall": 0.8721649484536083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7070484867487158,
            "auditor_fn_violation": 0.09889462462125465,
            "auditor_fp_violation": 0.09936240148904994,
            "ave_precision_score": 0.556964646763616,
            "fpr": 0.2730263157894737,
            "logloss": 0.6869128677710676,
            "mae": 0.49107242427897035,
            "precision": 0.5646853146853147,
            "recall": 0.6886993603411514
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.712961823349758,
            "auditor_fn_violation": 0.10928966695712201,
            "auditor_fp_violation": 0.09343547564199689,
            "ave_precision_score": 0.5718439571410099,
            "fpr": 0.2601536772777168,
            "logloss": 0.6852505901316669,
            "mae": 0.4903634449325984,
            "precision": 0.5767857142857142,
            "recall": 0.6659793814432989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7486525457195656,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.748811921192554,
            "fpr": 0.4780701754385965,
            "logloss": 3.2296750904376608,
            "mae": 0.47552634783184344,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7534234041921297,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7541413637766847,
            "fpr": 0.4621295279912184,
            "logloss": 3.170652951313837,
            "mae": 0.4602110452984383,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.44638857857541636,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.44563524985600544,
            "fpr": 0.06907894736842106,
            "logloss": 0.6972431869250368,
            "mae": 0.5014420182101036,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.509167680143929,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5104668569095905,
            "fpr": 0.042810098792535674,
            "logloss": 0.6950122144548824,
            "mae": 0.5003311248040225,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.4457780271175462,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.44504004204203035,
            "fpr": 0.06907894736842106,
            "logloss": 0.6970743677654981,
            "mae": 0.5013992071739937,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5088332191411504,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5101325958517966,
            "fpr": 0.042810098792535674,
            "logloss": 0.6948552383293596,
            "mae": 0.5002950186852435,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7196959545845741,
            "auditor_fn_violation": 0.017450342273594432,
            "auditor_fp_violation": 0.02108084828323632,
            "ave_precision_score": 0.7201295222915932,
            "fpr": 0.3092105263157895,
            "logloss": 1.4481582422635069,
            "mae": 0.36395619542661506,
            "precision": 0.6028169014084507,
            "recall": 0.9125799573560768
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7317947996828411,
            "auditor_fn_violation": 0.009068996344789347,
            "auditor_fp_violation": 0.020072870446241307,
            "ave_precision_score": 0.7311766793337796,
            "fpr": 0.30735455543358947,
            "logloss": 1.5210676281066648,
            "mae": 0.3534978589687612,
            "precision": 0.6132596685082873,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8439499485650938,
            "auditor_fn_violation": 0.009922193543560397,
            "auditor_fp_violation": 0.02250900954417648,
            "ave_precision_score": 0.8443135753719275,
            "fpr": 0.16228070175438597,
            "logloss": 0.5630689002258885,
            "mae": 0.3107790470488461,
            "precision": 0.7238805970149254,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8699589824205597,
            "auditor_fn_violation": 0.013025224348455874,
            "auditor_fp_violation": 0.021152528047906908,
            "ave_precision_score": 0.8701874692354854,
            "fpr": 0.1437980241492865,
            "logloss": 0.5067733706511858,
            "mae": 0.28650412118532576,
            "precision": 0.76007326007326,
            "recall": 0.8556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7100166347502241,
            "auditor_fn_violation": 0.017380204241948152,
            "auditor_fp_violation": 0.029211714387549013,
            "ave_precision_score": 0.7101961229938204,
            "fpr": 0.20833333333333334,
            "logloss": 1.2753381041201761,
            "mae": 0.3335613662794095,
            "precision": 0.6735395189003437,
            "recall": 0.835820895522388
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7254068809179403,
            "auditor_fn_violation": 0.01485622460873403,
            "auditor_fp_violation": 0.017998587941847943,
            "ave_precision_score": 0.7243801136831645,
            "fpr": 0.20965971459934138,
            "logloss": 1.3985704176330487,
            "mae": 0.32187101306936344,
            "precision": 0.685337726523888,
            "recall": 0.8577319587628865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7161847626863131,
            "auditor_fn_violation": 0.019091572214117388,
            "auditor_fp_violation": 0.02573412934141222,
            "ave_precision_score": 0.6890618133268571,
            "fpr": 0.1337719298245614,
            "logloss": 2.139141420285551,
            "mae": 0.4149915912891166,
            "precision": 0.6972704714640199,
            "recall": 0.5991471215351812
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7078045987777722,
            "auditor_fn_violation": 0.013806058822863744,
            "auditor_fp_violation": 0.011623712269960782,
            "ave_precision_score": 0.6776536899519204,
            "fpr": 0.13721185510428102,
            "logloss": 2.42009239262625,
            "mae": 0.4243506792478844,
            "precision": 0.691358024691358,
            "recall": 0.5773195876288659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 29198,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.4729664646691355,
            "auditor_fn_violation": 0.0022303894063517176,
            "auditor_fp_violation": 0.0024751494990297414,
            "ave_precision_score": 0.5137063073461906,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6969330593155798,
            "mae": 0.5008549893176869,
            "precision": 0.42857142857142855,
            "recall": 0.006396588486140725
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.7700476422193805,
            "auditor_fn_violation": 0.0052327226226985355,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5400952844387611,
            "fpr": 0.0,
            "logloss": 0.6922265469858482,
            "mae": 0.4987149361917661,
            "precision": 1.0,
            "recall": 0.016494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 29198,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7793076637309486,
            "auditor_fn_violation": 0.010345359667826284,
            "auditor_fp_violation": 0.021662508415508302,
            "ave_precision_score": 0.7770252255455832,
            "fpr": 0.23903508771929824,
            "logloss": 1.0602701640098715,
            "mae": 0.329538612309925,
            "precision": 0.6517571884984026,
            "recall": 0.8699360341151386
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7940132673113768,
            "auditor_fn_violation": 0.007127094956261954,
            "auditor_fp_violation": 0.02930278340367857,
            "ave_precision_score": 0.7933155350906966,
            "fpr": 0.23161361141602635,
            "logloss": 1.0065387008908782,
            "mae": 0.3116251725507195,
            "precision": 0.6773700305810397,
            "recall": 0.9134020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7149752729300967,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.5537571530584599,
            "fpr": 0.4780701754385965,
            "logloss": 0.7869849559001929,
            "mae": 0.483699205012894,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7257946473449675,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.5778543252764802,
            "fpr": 0.4621295279912184,
            "logloss": 0.7649664565637994,
            "mae": 0.47581800031675076,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.73364585973957,
            "auditor_fn_violation": 0.027861164104290577,
            "auditor_fp_violation": 0.04623084234287752,
            "ave_precision_score": 0.7273479548164397,
            "fpr": 0.15570175438596492,
            "logloss": 1.2491346669373837,
            "mae": 0.3291715742465502,
            "precision": 0.7035490605427975,
            "recall": 0.7185501066098081
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7235830662777137,
            "auditor_fn_violation": 0.017400160693471545,
            "auditor_fp_violation": 0.050151255134171284,
            "ave_precision_score": 0.7158475700647893,
            "fpr": 0.1525795828759605,
            "logloss": 1.3756062095506254,
            "mae": 0.32460130253558495,
            "precision": 0.719758064516129,
            "recall": 0.7360824742268042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7830291969652345,
            "auditor_fn_violation": 0.009499027419294506,
            "auditor_fp_violation": 0.02695437804443389,
            "ave_precision_score": 0.7693077757506396,
            "fpr": 0.2412280701754386,
            "logloss": 1.6218192733542869,
            "mae": 0.32826112825607295,
            "precision": 0.6529968454258676,
            "recall": 0.8827292110874201
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7871587230633341,
            "auditor_fn_violation": 0.00446999445494359,
            "auditor_fp_violation": 0.03187953185634112,
            "ave_precision_score": 0.7731463573246138,
            "fpr": 0.2305159165751921,
            "logloss": 1.6751618204071828,
            "mae": 0.30959659739848305,
            "precision": 0.6793893129770993,
            "recall": 0.9175257731958762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.8109833262019479,
            "auditor_fn_violation": 0.006464388583398812,
            "auditor_fp_violation": 0.0036706467070611068,
            "ave_precision_score": 0.8112622223678867,
            "fpr": 0.03070175438596491,
            "logloss": 0.6234825141614748,
            "mae": 0.42311661427415775,
            "precision": 0.8634146341463415,
            "recall": 0.3773987206823028
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.8391612389110437,
            "auditor_fn_violation": 0.004943021716251549,
            "auditor_fp_violation": 0.003360079982271971,
            "ave_precision_score": 0.8391834935410942,
            "fpr": 0.02854006586169045,
            "logloss": 0.6002132665617912,
            "mae": 0.41911768052894643,
            "precision": 0.8790697674418605,
            "recall": 0.38969072164948454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7832486231938803,
            "auditor_fn_violation": 0.012790839037893239,
            "auditor_fp_violation": 0.025479188943012165,
            "ave_precision_score": 0.7679415874989945,
            "fpr": 0.23793859649122806,
            "logloss": 1.6821933000151956,
            "mae": 0.32583235540164823,
            "precision": 0.6550079491255962,
            "recall": 0.8784648187633263
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7863171446442606,
            "auditor_fn_violation": 0.00566274740570575,
            "auditor_fp_violation": 0.03232530933865175,
            "ave_precision_score": 0.7707949249247938,
            "fpr": 0.22502744237102085,
            "logloss": 1.7433963512368253,
            "mae": 0.30798079199811934,
            "precision": 0.6816770186335404,
            "recall": 0.9051546391752577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.45295337834415106,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.44863663420262734,
            "fpr": 0.06907894736842106,
            "logloss": 0.6975777006997693,
            "mae": 0.5015133983014446,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5244805465973728,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5196703158115726,
            "fpr": 0.042810098792535674,
            "logloss": 0.6953409429808487,
            "mae": 0.500400171092784,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.8240248656711834,
            "auditor_fn_violation": 0.008367467175401199,
            "auditor_fp_violation": 0.006556671022929787,
            "ave_precision_score": 0.8242265694245889,
            "fpr": 0.019736842105263157,
            "logloss": 0.8376019027688022,
            "mae": 0.41286966285741467,
            "precision": 0.9005524861878453,
            "recall": 0.34754797441364604
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8625210873087423,
            "auditor_fn_violation": 0.010327384657168403,
            "auditor_fp_violation": 0.003625485072896214,
            "ave_precision_score": 0.8625437702947708,
            "fpr": 0.01646542261251372,
            "logloss": 0.8732293493619122,
            "mae": 0.40783435186661315,
            "precision": 0.9206349206349206,
            "recall": 0.35876288659793815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7599542275872981,
            "auditor_fn_violation": 0.013873302659634167,
            "auditor_fp_violation": 0.023664904360223355,
            "ave_precision_score": 0.7301525632126376,
            "fpr": 0.13815789473684212,
            "logloss": 2.4620104970400845,
            "mae": 0.3635169430290872,
            "precision": 0.7103448275862069,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7537645317105026,
            "auditor_fn_violation": 0.01696334604546947,
            "auditor_fp_violation": 0.015463067464427988,
            "ave_precision_score": 0.7199534771445886,
            "fpr": 0.13721185510428102,
            "logloss": 2.7927553705255055,
            "mae": 0.3671426024625065,
            "precision": 0.7159090909090909,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.754818459934281,
            "auditor_fn_violation": 0.014188923802042423,
            "auditor_fp_violation": 0.026768741832006664,
            "ave_precision_score": 0.7565185637182789,
            "fpr": 0.22039473684210525,
            "logloss": 0.7463666717526648,
            "mae": 0.34088271538974113,
            "precision": 0.6581632653061225,
            "recall": 0.8251599147121536
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7632066434759704,
            "auditor_fn_violation": 0.005751015650638816,
            "auditor_fp_violation": 0.029823286591116403,
            "ave_precision_score": 0.7647429848304936,
            "fpr": 0.21405049396267836,
            "logloss": 0.730338406970605,
            "mae": 0.3244774089068068,
            "precision": 0.6839546191247974,
            "recall": 0.8701030927835052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6032153782361392,
            "auditor_fn_violation": 0.012370010848015566,
            "auditor_fp_violation": 0.018568571541721125,
            "ave_precision_score": 0.60155251039547,
            "fpr": 0.2225877192982456,
            "logloss": 2.015447373611842,
            "mae": 0.37633880141011933,
            "precision": 0.643859649122807,
            "recall": 0.7825159914712153
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6508713976576779,
            "auditor_fn_violation": 0.014231557029207741,
            "auditor_fp_violation": 0.013040923918925194,
            "ave_precision_score": 0.6488513810331111,
            "fpr": 0.22722283205268934,
            "logloss": 1.650814262896309,
            "mae": 0.3574632936585686,
            "precision": 0.654424040066778,
            "recall": 0.8082474226804124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7935813854901468,
            "auditor_fn_violation": 0.01282824598810459,
            "auditor_fp_violation": 0.028360262959882792,
            "ave_precision_score": 0.7945653351587403,
            "fpr": 0.1962719298245614,
            "logloss": 0.6841900471442721,
            "mae": 0.3062641495343996,
            "precision": 0.68760907504363,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8072646906362941,
            "auditor_fn_violation": 0.007914719295664677,
            "auditor_fp_violation": 0.030890060450518703,
            "ave_precision_score": 0.8078759930071461,
            "fpr": 0.18660812294182216,
            "logloss": 0.6434528759424711,
            "mae": 0.29148504614011406,
            "precision": 0.7113752122241087,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6076479843356004,
            "auditor_fn_violation": 0.004657165301312998,
            "auditor_fp_violation": 0.019437349015880557,
            "ave_precision_score": 0.6084307781951888,
            "fpr": 0.1118421052631579,
            "logloss": 0.991833336944534,
            "mae": 0.48193317762853805,
            "precision": 0.6370106761565836,
            "recall": 0.3816631130063966
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.628311714706409,
            "auditor_fn_violation": 0.009274955582966494,
            "auditor_fp_violation": 0.013996897594862993,
            "ave_precision_score": 0.6288400818594632,
            "fpr": 0.10757409440175632,
            "logloss": 0.9717544900296722,
            "mae": 0.4779607386999936,
            "precision": 0.6608996539792388,
            "recall": 0.3938144329896907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7166948698655107,
            "auditor_fn_violation": 0.01579976059551865,
            "auditor_fp_violation": 0.024154983961031253,
            "ave_precision_score": 0.7178812078254178,
            "fpr": 0.18640350877192982,
            "logloss": 1.1890751639255992,
            "mae": 0.3231893019015537,
            "precision": 0.6925858951175407,
            "recall": 0.8166311300639659
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7281314608636357,
            "auditor_fn_violation": 0.011164801339866694,
            "auditor_fp_violation": 0.021482351849847713,
            "ave_precision_score": 0.7272281058019443,
            "fpr": 0.17892425905598244,
            "logloss": 1.3289507368876243,
            "mae": 0.3131809714580332,
            "precision": 0.7120141342756183,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7558758994475523,
            "auditor_fn_violation": 0.014941738675045821,
            "auditor_fp_violation": 0.021957051205892846,
            "ave_precision_score": 0.7561458907206475,
            "fpr": 0.1699561403508772,
            "logloss": 0.8235184146361589,
            "mae": 0.32670005854781364,
            "precision": 0.7047619047619048,
            "recall": 0.7889125799573561
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8010651179795782,
            "auditor_fn_violation": 0.01711951294035104,
            "auditor_fp_violation": 0.014996675994496072,
            "ave_precision_score": 0.8015441060953866,
            "fpr": 0.14270032930845225,
            "logloss": 0.6377281050876756,
            "mae": 0.29831369637749866,
            "precision": 0.7560975609756098,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8405279615533384,
            "auditor_fn_violation": 0.013141529196124645,
            "auditor_fp_violation": 0.023016415191477572,
            "ave_precision_score": 0.8407923915501591,
            "fpr": 0.1513157894736842,
            "logloss": 0.5502457325803534,
            "mae": 0.3104441179699247,
            "precision": 0.7288801571709234,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8676202553004225,
            "auditor_fn_violation": 0.013142915341699955,
            "auditor_fp_violation": 0.012924970238555374,
            "ave_precision_score": 0.8678565699107654,
            "fpr": 0.1251372118551043,
            "logloss": 0.49300763825029875,
            "mae": 0.28365772430318315,
            "precision": 0.776908023483366,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7598518746775509,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7600448957582477,
            "fpr": 0.4780701754385965,
            "logloss": 3.7558708114426405,
            "mae": 0.47858096026534813,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7582716893702457,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7592209750771529,
            "fpr": 0.4621295279912184,
            "logloss": 3.6639120870178745,
            "mae": 0.4616848391615715,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6059311905661996,
            "auditor_fn_violation": 0.01736383870123069,
            "auditor_fp_violation": 0.017840877589006376,
            "ave_precision_score": 0.6042665059189959,
            "fpr": 0.2225877192982456,
            "logloss": 2.027581705585244,
            "mae": 0.3734469672932247,
            "precision": 0.6506024096385542,
            "recall": 0.8059701492537313
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6499655356578732,
            "auditor_fn_violation": 0.0149444928536671,
            "auditor_fp_violation": 0.00803430167540185,
            "ave_precision_score": 0.6477762804900934,
            "fpr": 0.2283205268935236,
            "logloss": 1.6711708525948203,
            "mae": 0.3571001313681152,
            "precision": 0.656198347107438,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7544655964331634,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.753512630262022,
            "fpr": 0.4780701754385965,
            "logloss": 5.451810686027116,
            "mae": 0.47914365304664697,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7499735596038216,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7500942020424193,
            "fpr": 0.4621295279912184,
            "logloss": 5.445892469452187,
            "mae": 0.462111573855047,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7805791328507016,
            "auditor_fn_violation": 0.010345359667826284,
            "auditor_fp_violation": 0.02310057027444459,
            "ave_precision_score": 0.7797781119521772,
            "fpr": 0.23574561403508773,
            "logloss": 1.0004939839562956,
            "mae": 0.3265409710280405,
            "precision": 0.6548956661316212,
            "recall": 0.8699360341151386
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7928951464463205,
            "auditor_fn_violation": 0.0074009528443876125,
            "auditor_fp_violation": 0.03087459995980274,
            "ave_precision_score": 0.792546662440758,
            "fpr": 0.2239297475301866,
            "logloss": 0.9812839241824397,
            "mae": 0.3086960985983132,
            "precision": 0.6832298136645962,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5080572059434478,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5011623794596054,
            "fpr": 0.06907894736842106,
            "logloss": 0.6970082628395379,
            "mae": 0.5013383356690929,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5696835868671956,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5592186000983967,
            "fpr": 0.042810098792535674,
            "logloss": 0.6948484872456081,
            "mae": 0.5002615232629912,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7439289723626324,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7446511047433073,
            "fpr": 0.4780701754385965,
            "logloss": 2.968425649759966,
            "mae": 0.47410876286076736,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7519032864653636,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.753795500634936,
            "fpr": 0.4621295279912184,
            "logloss": 2.8929280554089187,
            "mae": 0.4591079878729167,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8423994275705677,
            "auditor_fn_violation": 0.010555773762765125,
            "auditor_fp_violation": 0.024367846817947805,
            "ave_precision_score": 0.8427226771928262,
            "fpr": 0.17653508771929824,
            "logloss": 0.5754923615960611,
            "mae": 0.315923539577629,
            "precision": 0.7088607594936709,
            "recall": 0.835820895522388
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8686897478150205,
            "auditor_fn_violation": 0.010585399526972739,
            "auditor_fp_violation": 0.017485814999768094,
            "ave_precision_score": 0.8689211988720081,
            "fpr": 0.15806805708013172,
            "logloss": 0.5190928666507467,
            "mae": 0.2908424353520933,
            "precision": 0.746031746031746,
            "recall": 0.8721649484536083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8399776559914995,
            "auditor_fn_violation": 0.016096678262821237,
            "auditor_fp_violation": 0.02428864203397885,
            "ave_precision_score": 0.8402665549483394,
            "fpr": 0.14144736842105263,
            "logloss": 0.5484710959155854,
            "mae": 0.3078232803169126,
            "precision": 0.7361963190184049,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8651808825430101,
            "auditor_fn_violation": 0.01741826700012448,
            "auditor_fp_violation": 0.012790979319016918,
            "ave_precision_score": 0.8654049584133667,
            "fpr": 0.1141602634467618,
            "logloss": 0.4965122180361643,
            "mae": 0.2835497076627742,
            "precision": 0.7903225806451613,
            "recall": 0.8082474226804124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 29198,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7795817007054311,
            "auditor_fn_violation": 0.013120487786630755,
            "auditor_fp_violation": 0.02307581877945428,
            "ave_precision_score": 0.7773036550094943,
            "fpr": 0.2412280701754386,
            "logloss": 1.065834359626601,
            "mae": 0.32929875215938265,
            "precision": 0.6507936507936508,
            "recall": 0.8742004264392325
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7939645401668582,
            "auditor_fn_violation": 0.0074009528443876125,
            "auditor_fp_violation": 0.030707111310379655,
            "ave_precision_score": 0.7932165512477765,
            "fpr": 0.22941822173435786,
            "logloss": 1.0124775414144713,
            "mae": 0.3112309095902117,
            "precision": 0.6779661016949152,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 29198,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7796094262306505,
            "auditor_fn_violation": 0.013120487786630755,
            "auditor_fp_violation": 0.02307581877945428,
            "ave_precision_score": 0.7773267406974016,
            "fpr": 0.2412280701754386,
            "logloss": 1.0664031767415822,
            "mae": 0.3292696947025609,
            "precision": 0.6507936507936508,
            "recall": 0.8742004264392325
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.794096620588981,
            "auditor_fn_violation": 0.0074009528443876125,
            "auditor_fp_violation": 0.030707111310379655,
            "ave_precision_score": 0.7933422749223031,
            "fpr": 0.22941822173435786,
            "logloss": 1.0130200665812508,
            "mae": 0.31116822874608,
            "precision": 0.6779661016949152,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7833684328492772,
            "auditor_fn_violation": 0.011750458235140088,
            "auditor_fp_violation": 0.02629351312819294,
            "ave_precision_score": 0.7680923186489157,
            "fpr": 0.23574561403508773,
            "logloss": 1.6809667627590676,
            "mae": 0.3254845519733958,
            "precision": 0.6576433121019108,
            "recall": 0.8805970149253731
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7862036488754864,
            "auditor_fn_violation": 0.006303258003553363,
            "auditor_fp_violation": 0.03198517854290029,
            "ave_precision_score": 0.7707001892375688,
            "fpr": 0.22283205268935236,
            "logloss": 1.7419259211777451,
            "mae": 0.30769162006220246,
            "precision": 0.6842923794712286,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7827630550109362,
            "auditor_fn_violation": 0.0008486701829200059,
            "auditor_fp_violation": 0.008269474476258367,
            "ave_precision_score": 0.783212310717621,
            "fpr": 0.03508771929824561,
            "logloss": 0.6573089867754249,
            "mae": 0.4006959508790858,
            "precision": 0.864406779661017,
            "recall": 0.4349680170575693
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8032042776116606,
            "auditor_fn_violation": 0.006190093586972525,
            "auditor_fp_violation": 0.00406610905830151,
            "ave_precision_score": 0.8033864426481411,
            "fpr": 0.03293084522502744,
            "logloss": 0.6337030217973691,
            "mae": 0.3949304750538942,
            "precision": 0.88,
            "recall": 0.4536082474226804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.824026741660768,
            "auditor_fn_violation": 0.008367467175401199,
            "auditor_fp_violation": 0.006556671022929787,
            "ave_precision_score": 0.824230321403758,
            "fpr": 0.019736842105263157,
            "logloss": 0.8376019294148435,
            "mae": 0.4128696733011545,
            "precision": 0.9005524861878453,
            "recall": 0.34754797441364604
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8625210873087423,
            "auditor_fn_violation": 0.010327384657168403,
            "auditor_fp_violation": 0.003625485072896214,
            "ave_precision_score": 0.8625437702947708,
            "fpr": 0.01646542261251372,
            "logloss": 0.873229370644329,
            "mae": 0.40783436192730715,
            "precision": 0.9206349206349206,
            "recall": 0.35876288659793815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7200966526654591,
            "auditor_fn_violation": 0.01579976059551865,
            "auditor_fp_violation": 0.02395202170211081,
            "ave_precision_score": 0.7213364251035466,
            "fpr": 0.18421052631578946,
            "logloss": 1.1660186934317815,
            "mae": 0.3216954592479922,
            "precision": 0.6950998185117967,
            "recall": 0.8166311300639659
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7318607459297934,
            "auditor_fn_violation": 0.010135005148980957,
            "auditor_fp_violation": 0.01951113928356086,
            "ave_precision_score": 0.7309585765430339,
            "fpr": 0.1756311745334797,
            "logloss": 1.3086205813682235,
            "mae": 0.311278065932263,
            "precision": 0.7153024911032029,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7622062139481107,
            "auditor_fn_violation": 0.013279467325028993,
            "auditor_fp_violation": 0.02851867252782068,
            "ave_precision_score": 0.7318866509163504,
            "fpr": 0.14035087719298245,
            "logloss": 2.2961874195957575,
            "mae": 0.39309467760878697,
            "precision": 0.7077625570776256,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7527451097530845,
            "auditor_fn_violation": 0.012563513528806003,
            "auditor_fp_violation": 0.012221517910978497,
            "ave_precision_score": 0.7174477054221913,
            "fpr": 0.1394072447859495,
            "logloss": 2.6006054337246165,
            "mae": 0.3970450771365286,
            "precision": 0.7133182844243793,
            "recall": 0.6515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7625847490355528,
            "auditor_fn_violation": 0.013873302659634167,
            "auditor_fp_violation": 0.02819690309294682,
            "ave_precision_score": 0.7325112107587812,
            "fpr": 0.13706140350877194,
            "logloss": 2.469258089972978,
            "mae": 0.36342658270385114,
            "precision": 0.7119815668202765,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7552988407992605,
            "auditor_fn_violation": 0.01696334604546947,
            "auditor_fp_violation": 0.015463067464427988,
            "ave_precision_score": 0.7208191512333079,
            "fpr": 0.13721185510428102,
            "logloss": 2.813390564551565,
            "mae": 0.36667396411119724,
            "precision": 0.7159090909090909,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7474641797015669,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7499589241145227,
            "fpr": 0.4780701754385965,
            "logloss": 2.9066011060624315,
            "mae": 0.4727126537193144,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7567917293078911,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7587629405799845,
            "fpr": 0.4621295279912184,
            "logloss": 2.8335588091377897,
            "mae": 0.4582567648787695,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7136097253421815,
            "auditor_fn_violation": 0.09261259492013617,
            "auditor_fp_violation": 0.10510227317729992,
            "ave_precision_score": 0.5517381522326563,
            "fpr": 0.2982456140350877,
            "logloss": 0.6857693300390018,
            "mae": 0.49233706609198924,
            "precision": 0.5577235772357724,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7243615977602713,
            "auditor_fn_violation": 0.1033530616632906,
            "auditor_fp_violation": 0.09585504243904704,
            "ave_precision_score": 0.5757424824159777,
            "fpr": 0.2722283205268935,
            "logloss": 0.6826557525546048,
            "mae": 0.49087907696136657,
            "precision": 0.5803722504230119,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7839401987686558,
            "auditor_fn_violation": 0.012283507275651816,
            "auditor_fp_violation": 0.025570769474476257,
            "ave_precision_score": 0.7701650883959261,
            "fpr": 0.24342105263157895,
            "logloss": 1.6385479488412893,
            "mae": 0.32854392418889083,
            "precision": 0.6514913657770801,
            "recall": 0.8848614072494669
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7868306072690785,
            "auditor_fn_violation": 0.002720472574603644,
            "auditor_fp_violation": 0.03111681431435302,
            "ave_precision_score": 0.7728141899271637,
            "fpr": 0.2327113062568606,
            "logloss": 1.695617794123659,
            "mae": 0.31079174062077664,
            "precision": 0.6787878787878788,
            "recall": 0.9237113402061856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.844546299869738,
            "auditor_fn_violation": 0.010394456289978678,
            "auditor_fp_violation": 0.024503980040394446,
            "ave_precision_score": 0.8448858151440796,
            "fpr": 0.1600877192982456,
            "logloss": 0.5650005367210585,
            "mae": 0.31032917988218206,
            "precision": 0.726078799249531,
            "recall": 0.8251599147121536
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.869543332032446,
            "auditor_fn_violation": 0.016782282978940105,
            "auditor_fp_violation": 0.01456378225444876,
            "ave_precision_score": 0.8697809225310074,
            "fpr": 0.14270032930845225,
            "logloss": 0.5085012186788239,
            "mae": 0.28554613880728974,
            "precision": 0.7614678899082569,
            "recall": 0.8556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5080572059434478,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5011623794596054,
            "fpr": 0.06907894736842106,
            "logloss": 0.6966355278404515,
            "mae": 0.5012399971223714,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5696835868671956,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5592186000983967,
            "fpr": 0.042810098792535674,
            "logloss": 0.694517219133367,
            "mae": 0.5001852494366998,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7952946286772354,
            "auditor_fn_violation": 0.028985710545019267,
            "auditor_fp_violation": 0.029229040434042217,
            "ave_precision_score": 0.795660459284101,
            "fpr": 0.12938596491228072,
            "logloss": 0.7017059900405308,
            "mae": 0.3313467011780915,
            "precision": 0.7348314606741573,
            "recall": 0.697228144989339
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.833835192525991,
            "auditor_fn_violation": 0.013559360394717493,
            "auditor_fp_violation": 0.015019866730570028,
            "ave_precision_score": 0.834110713708816,
            "fpr": 0.10867178924259056,
            "logloss": 0.5974443194164505,
            "mae": 0.30874916657596796,
            "precision": 0.7790178571428571,
            "recall": 0.7195876288659794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.700884253755604,
            "auditor_fn_violation": 0.019556821157371045,
            "auditor_fp_violation": 0.02091996356579938,
            "ave_precision_score": 0.7021300787363125,
            "fpr": 0.17763157894736842,
            "logloss": 1.2164437143354276,
            "mae": 0.33919146478171625,
            "precision": 0.6960600375234521,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.726981214286329,
            "auditor_fn_violation": 0.01484943474373918,
            "auditor_fp_violation": 0.01203341527393413,
            "ave_precision_score": 0.7261794139847482,
            "fpr": 0.18660812294182216,
            "logloss": 1.295212192440093,
            "mae": 0.3254855013270338,
            "precision": 0.6980461811722913,
            "recall": 0.8103092783505155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8432084002481284,
            "auditor_fn_violation": 0.015488815321886807,
            "auditor_fp_violation": 0.025763831135400588,
            "ave_precision_score": 0.8434671684040835,
            "fpr": 0.15679824561403508,
            "logloss": 0.5549567767104828,
            "mae": 0.31085669482063005,
            "precision": 0.7276190476190476,
            "recall": 0.814498933901919
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8683455488839693,
            "auditor_fn_violation": 0.014949019430330326,
            "auditor_fp_violation": 0.017516735981200047,
            "ave_precision_score": 0.8685759880401531,
            "fpr": 0.13062568605927552,
            "logloss": 0.500019223921439,
            "mae": 0.2844902256883361,
            "precision": 0.7729007633587787,
            "recall": 0.8350515463917526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6412888045154345,
            "auditor_fn_violation": 0.007724535218643631,
            "auditor_fp_violation": 0.014308839253890935,
            "ave_precision_score": 0.5452641761950481,
            "fpr": 0.04824561403508772,
            "logloss": 0.6872995279751434,
            "mae": 0.48592194290668295,
            "precision": 0.674074074074074,
            "recall": 0.19402985074626866
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6738502541654244,
            "auditor_fn_violation": 0.008706870211730628,
            "auditor_fp_violation": 0.0036718665450441407,
            "ave_precision_score": 0.5685556714202523,
            "fpr": 0.036223929747530186,
            "logloss": 0.6792235893798491,
            "mae": 0.4834193770827891,
            "precision": 0.7295081967213115,
            "recall": 0.18350515463917524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.45295532516817594,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.4486385819368702,
            "fpr": 0.06907894736842106,
            "logloss": 0.6976095044114214,
            "mae": 0.5015210074683031,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5245495261104643,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5197381097754736,
            "fpr": 0.042810098792535674,
            "logloss": 0.6953713439844538,
            "mae": 0.5004069132548394,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7149856202209003,
            "auditor_fn_violation": 0.02050836045337224,
            "auditor_fp_violation": 0.024937131202724647,
            "ave_precision_score": 0.7162281970081665,
            "fpr": 0.18530701754385964,
            "logloss": 1.1950621581375114,
            "mae": 0.3253761157140709,
            "precision": 0.692167577413479,
            "recall": 0.8102345415778252
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7267971923417273,
            "auditor_fn_violation": 0.012101802709156133,
            "auditor_fp_violation": 0.01711476322258469,
            "ave_precision_score": 0.7258568053507573,
            "fpr": 0.1778265642151482,
            "logloss": 1.339042790953346,
            "mae": 0.315764504368948,
            "precision": 0.7157894736842105,
            "recall": 0.8412371134020619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8401394815716132,
            "auditor_fn_violation": 0.011032712377959827,
            "auditor_fp_violation": 0.02346441725080195,
            "ave_precision_score": 0.8404042924539972,
            "fpr": 0.14912280701754385,
            "logloss": 0.5499425599529845,
            "mae": 0.31049673204803474,
            "precision": 0.7306930693069307,
            "recall": 0.7867803837953091
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8678974292459237,
            "auditor_fn_violation": 0.013142915341699955,
            "auditor_fp_violation": 0.012445695026360136,
            "ave_precision_score": 0.8681332767807055,
            "fpr": 0.12403951701427003,
            "logloss": 0.492149934441973,
            "mae": 0.28355155917345604,
            "precision": 0.7784313725490196,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7585923381476884,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7588002450928978,
            "fpr": 0.4780701754385965,
            "logloss": 3.749844672246308,
            "mae": 0.47849224022477865,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7512516519501267,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7536853963114842,
            "fpr": 0.4621295279912184,
            "logloss": 3.6838162934601075,
            "mae": 0.4616051439734872,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 29198,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7778318390858624,
            "auditor_fn_violation": 0.013120487786630755,
            "auditor_fp_violation": 0.02307581877945428,
            "ave_precision_score": 0.7744490894963689,
            "fpr": 0.2412280701754386,
            "logloss": 1.1123518063247488,
            "mae": 0.3291788353582664,
            "precision": 0.6507936507936508,
            "recall": 0.8742004264392325
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7926959731971275,
            "auditor_fn_violation": 0.0074009528443876125,
            "auditor_fp_violation": 0.03068649732275837,
            "ave_precision_score": 0.7910426919732854,
            "fpr": 0.22941822173435786,
            "logloss": 1.0409203527277913,
            "mae": 0.3110128502559804,
            "precision": 0.6779661016949152,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7551700071936912,
            "auditor_fn_violation": 0.005040586540979322,
            "auditor_fp_violation": 0.007747217931963091,
            "ave_precision_score": 0.7557513568351237,
            "fpr": 0.03399122807017544,
            "logloss": 0.7728138241332214,
            "mae": 0.40971698440011606,
            "precision": 0.8564814814814815,
            "recall": 0.39445628997867804
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7883137947496758,
            "auditor_fn_violation": 0.007559383027600803,
            "auditor_fp_violation": 0.0012548764964466646,
            "ave_precision_score": 0.78858479300722,
            "fpr": 0.027442371020856202,
            "logloss": 0.7304819795512717,
            "mae": 0.40238769782340134,
            "precision": 0.8913043478260869,
            "recall": 0.422680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.8109734500792778,
            "auditor_fn_violation": 0.006464388583398812,
            "auditor_fp_violation": 0.0036706467070611068,
            "ave_precision_score": 0.8112479436165545,
            "fpr": 0.03070175438596491,
            "logloss": 0.6234818520386135,
            "mae": 0.4231165273507175,
            "precision": 0.8634146341463415,
            "recall": 0.3773987206823028
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.8391391565548965,
            "auditor_fn_violation": 0.004943021716251549,
            "auditor_fp_violation": 0.003360079982271971,
            "ave_precision_score": 0.839195509524837,
            "fpr": 0.02854006586169045,
            "logloss": 0.6002130158538641,
            "mae": 0.4191174762759002,
            "precision": 0.8790697674418605,
            "recall": 0.38969072164948454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7826260024847238,
            "auditor_fn_violation": 0.011692009875434855,
            "auditor_fp_violation": 0.025741554789909308,
            "ave_precision_score": 0.7640298754171014,
            "fpr": 0.24013157894736842,
            "logloss": 1.8275692240868395,
            "mae": 0.32503980513495645,
            "precision": 0.6540284360189573,
            "recall": 0.8827292110874201
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7869323422951526,
            "auditor_fn_violation": 0.006303258003553363,
            "auditor_fp_violation": 0.031186386522574897,
            "ave_precision_score": 0.7689061460222291,
            "fpr": 0.22502744237102085,
            "logloss": 1.879288015351756,
            "mae": 0.3076438952027028,
            "precision": 0.6821705426356589,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7605711996409158,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7606915452626493,
            "fpr": 0.4780701754385965,
            "logloss": 3.753794844635414,
            "mae": 0.4785738456395922,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7589135674618817,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7596441842002789,
            "fpr": 0.4621295279912184,
            "logloss": 3.661511170046121,
            "mae": 0.4616829323854166,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7621917206968436,
            "auditor_fn_violation": 0.013873302659634167,
            "auditor_fp_violation": 0.02819690309294682,
            "ave_precision_score": 0.7321407345649932,
            "fpr": 0.13706140350877194,
            "logloss": 2.4694154846211847,
            "mae": 0.36338416068391455,
            "precision": 0.7119815668202765,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7564008772243824,
            "auditor_fn_violation": 0.01696334604546947,
            "auditor_fp_violation": 0.015463067464427988,
            "ave_precision_score": 0.7224442173400543,
            "fpr": 0.13721185510428102,
            "logloss": 2.794279047965912,
            "mae": 0.36664165770791407,
            "precision": 0.7159090909090909,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7840476562100162,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7835735075539539,
            "fpr": 0.4780701754385965,
            "logloss": 5.16965454718815,
            "mae": 0.4791337683842779,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7793543110335361,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7785188952770385,
            "fpr": 0.4621295279912184,
            "logloss": 5.052785851856244,
            "mae": 0.4621046102025817,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7609214406331374,
            "auditor_fn_violation": 0.013279467325028993,
            "auditor_fp_violation": 0.02851867252782068,
            "ave_precision_score": 0.7307997846093647,
            "fpr": 0.14035087719298245,
            "logloss": 2.2701096002104264,
            "mae": 0.3902690304737342,
            "precision": 0.7077625570776256,
            "recall": 0.6609808102345416
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7531127269034119,
            "auditor_fn_violation": 0.01251598447384205,
            "auditor_fp_violation": 0.012221517910978497,
            "ave_precision_score": 0.7184890857942755,
            "fpr": 0.1394072447859495,
            "logloss": 2.560338991314584,
            "mae": 0.39515057847345436,
            "precision": 0.7126696832579186,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8425324945353313,
            "auditor_fn_violation": 0.01036640107732017,
            "auditor_fp_violation": 0.021273909944160636,
            "ave_precision_score": 0.8428775937098791,
            "fpr": 0.1787280701754386,
            "logloss": 0.5766671620298214,
            "mae": 0.3151764585974505,
            "precision": 0.7089285714285715,
            "recall": 0.8464818763326226
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.869690054911345,
            "auditor_fn_violation": 0.008473751513574074,
            "auditor_fp_violation": 0.014919373540916195,
            "ave_precision_score": 0.8699139532946201,
            "fpr": 0.15477497255762898,
            "logloss": 0.5194891699939339,
            "mae": 0.2905689323830366,
            "precision": 0.7477638640429338,
            "recall": 0.8618556701030928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7537606696369861,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.75466164946053,
            "fpr": 0.4780701754385965,
            "logloss": 3.113660387732754,
            "mae": 0.4764760575878433,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7579970966025106,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7595936932684655,
            "fpr": 0.4621295279912184,
            "logloss": 3.026262399029609,
            "mae": 0.46008565040531313,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7935886501503258,
            "auditor_fn_violation": 0.016201885310290657,
            "auditor_fp_violation": 0.02637024276266286,
            "ave_precision_score": 0.7945659561486522,
            "fpr": 0.19956140350877194,
            "logloss": 0.6897733203928623,
            "mae": 0.3071190191270497,
            "precision": 0.6840277777777778,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8088651768248035,
            "auditor_fn_violation": 0.008863037106612197,
            "auditor_fp_violation": 0.03106785609375242,
            "ave_precision_score": 0.8094614461393516,
            "fpr": 0.18551042810098792,
            "logloss": 0.6487335776091511,
            "mae": 0.2931557727577208,
            "precision": 0.7125850340136054,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7536587280843214,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7524818731267958,
            "fpr": 0.4780701754385965,
            "logloss": 5.525711345577539,
            "mae": 0.4791470797774567,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7518806776711723,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7526713608836356,
            "fpr": 0.4621295279912184,
            "logloss": 5.5147483609485395,
            "mae": 0.46211434269021917,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8431727601614656,
            "auditor_fn_violation": 0.009613586204316765,
            "auditor_fp_violation": 0.022659993663617282,
            "ave_precision_score": 0.8435375834878457,
            "fpr": 0.16447368421052633,
            "logloss": 0.5676359862876162,
            "mae": 0.31139895443784715,
            "precision": 0.7211895910780669,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8686213314885367,
            "auditor_fn_violation": 0.011927529507621625,
            "auditor_fp_violation": 0.020054833207072666,
            "ave_precision_score": 0.868850774080638,
            "fpr": 0.1437980241492865,
            "logloss": 0.512381367289507,
            "mae": 0.28775223269579747,
            "precision": 0.7596330275229358,
            "recall": 0.8536082474226804
        }
    }
]