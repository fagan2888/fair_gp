[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 871,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8219858765772067,
            "auditor_fn_violation": 0.010266930767779662,
            "auditor_fp_violation": 0.02286932375681935,
            "ave_precision_score": 0.8222770037787924,
            "fpr": 0.12390350877192982,
            "logloss": 0.9288588112928411,
            "mae": 0.2685119902377032,
            "precision": 0.7554112554112554,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8171111987527087,
            "auditor_fn_violation": 0.010792876880840626,
            "auditor_fp_violation": 0.01080006867095687,
            "ave_precision_score": 0.8175109901487001,
            "fpr": 0.10757409440175632,
            "logloss": 1.0649493981888394,
            "mae": 0.2679211309717036,
            "precision": 0.7850877192982456,
            "recall": 0.7321063394683026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 871,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8510825896160705,
            "auditor_fn_violation": 0.007246274287870212,
            "auditor_fp_violation": 0.016241316378193812,
            "ave_precision_score": 0.8513138698193194,
            "fpr": 0.09758771929824561,
            "logloss": 0.878488813303376,
            "mae": 0.24214987888351275,
            "precision": 0.7954022988505747,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8440558390323782,
            "auditor_fn_violation": 0.009499886638876364,
            "auditor_fp_violation": 0.009062485368404075,
            "ave_precision_score": 0.8443289432136137,
            "fpr": 0.09330406147091108,
            "logloss": 1.0967836131068236,
            "mae": 0.2537741747892125,
            "precision": 0.8059360730593608,
            "recall": 0.721881390593047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 871,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6568378470635717,
            "auditor_fn_violation": 0.010745614035087718,
            "auditor_fp_violation": 0.022238902625691746,
            "ave_precision_score": 0.6518914086362319,
            "fpr": 0.08114035087719298,
            "logloss": 8.51885270433022,
            "mae": 0.41113438364182164,
            "precision": 0.7153846153846154,
            "recall": 0.4
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7163993187935285,
            "auditor_fn_violation": 0.005050743132672919,
            "auditor_fp_violation": 0.00831074648451522,
            "ave_precision_score": 0.7042831668104899,
            "fpr": 0.05378704720087816,
            "logloss": 8.777327115745836,
            "mae": 0.4090008562016449,
            "precision": 0.7966804979253111,
            "recall": 0.39263803680981596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 871,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7917827463310307,
            "auditor_fn_violation": 0.013205055649877393,
            "auditor_fp_violation": 0.020686153302719893,
            "ave_precision_score": 0.7856667488106893,
            "fpr": 0.11842105263157894,
            "logloss": 1.9985520618960568,
            "mae": 0.28499895850275375,
            "precision": 0.7539863325740319,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7906159846847175,
            "auditor_fn_violation": 0.01383903618352381,
            "auditor_fp_violation": 0.01325557561348656,
            "ave_precision_score": 0.7830676105014317,
            "fpr": 0.10976948408342481,
            "logloss": 2.2878696149932467,
            "mae": 0.29052989856526656,
            "precision": 0.7747747747747747,
            "recall": 0.7034764826175869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 871,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8298778450747177,
            "auditor_fn_violation": 0.008524335031126202,
            "auditor_fp_violation": 0.019214352996585426,
            "ave_precision_score": 0.8301482952754536,
            "fpr": 0.14802631578947367,
            "logloss": 0.8825436548808591,
            "mae": 0.2672394683226073,
            "precision": 0.7321428571428571,
            "recall": 0.7935483870967742
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8271398596780233,
            "auditor_fn_violation": 0.016108503431138173,
            "auditor_fp_violation": 0.015279287902986665,
            "ave_precision_score": 0.8274873980686127,
            "fpr": 0.1251372118551043,
            "logloss": 0.90685278006555,
            "mae": 0.26343567533383005,
            "precision": 0.7668711656441718,
            "recall": 0.7668711656441718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 871,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6572763061735911,
            "auditor_fn_violation": 0.013853518204112434,
            "auditor_fp_violation": 0.025835001373680284,
            "ave_precision_score": 0.6520993043109625,
            "fpr": 0.23574561403508773,
            "logloss": 1.9080477739866217,
            "mae": 0.34020720697555,
            "precision": 0.6486928104575164,
            "recall": 0.853763440860215
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7037367361512146,
            "auditor_fn_violation": 0.014718987875971711,
            "auditor_fp_violation": 0.03271234672590404,
            "ave_precision_score": 0.6964565091712344,
            "fpr": 0.20197585071350166,
            "logloss": 1.5597963215089905,
            "mae": 0.3171047455664385,
            "precision": 0.6933333333333334,
            "recall": 0.8507157464212679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 871,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8563032420995337,
            "auditor_fn_violation": 0.010736181852480665,
            "auditor_fp_violation": 0.019273225008830806,
            "ave_precision_score": 0.8522947325196688,
            "fpr": 0.14802631578947367,
            "logloss": 1.0292399410805755,
            "mae": 0.25273652628276677,
            "precision": 0.7393822393822393,
            "recall": 0.8236559139784946
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8566891720332446,
            "auditor_fn_violation": 0.008069965138648511,
            "auditor_fp_violation": 0.011335910228330937,
            "ave_precision_score": 0.8474359817234589,
            "fpr": 0.12623490669593854,
            "logloss": 1.1988405039503864,
            "mae": 0.24564959995791918,
            "precision": 0.7731755424063116,
            "recall": 0.8016359918200409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 871,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8323419380516104,
            "auditor_fn_violation": 0.01073382380682891,
            "auditor_fp_violation": 0.017970681737901797,
            "ave_precision_score": 0.8326165459039456,
            "fpr": 0.10526315789473684,
            "logloss": 0.8333121495645486,
            "mae": 0.27034714126645043,
            "precision": 0.775175644028103,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8326833041722165,
            "auditor_fn_violation": 0.012963574040527172,
            "auditor_fp_violation": 0.007912767075397589,
            "ave_precision_score": 0.833009392927728,
            "fpr": 0.09220636663007684,
            "logloss": 0.8910357691789804,
            "mae": 0.27147433869031673,
            "precision": 0.8041958041958042,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 871,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7940100396084095,
            "auditor_fn_violation": 0.009361441237502363,
            "auditor_fp_violation": 0.009814455041406652,
            "ave_precision_score": 0.7876555868315509,
            "fpr": 0.08662280701754387,
            "logloss": 1.9504776180712562,
            "mae": 0.30388533690394437,
            "precision": 0.7669616519174042,
            "recall": 0.5591397849462365
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7915829779771855,
            "auditor_fn_violation": 0.005138289346972598,
            "auditor_fp_violation": 0.008274330067994653,
            "ave_precision_score": 0.7821633990324152,
            "fpr": 0.07574094401756312,
            "logloss": 2.2806007858392117,
            "mae": 0.3097378528952328,
            "precision": 0.8017241379310345,
            "recall": 0.5705521472392638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 871,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.864716233427596,
            "auditor_fn_violation": 0.012966893039049241,
            "auditor_fp_violation": 0.019518525059853218,
            "ave_precision_score": 0.8617582072475538,
            "fpr": 0.13925438596491227,
            "logloss": 1.053642601367714,
            "mae": 0.24208233446095145,
            "precision": 0.748015873015873,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8668530941807993,
            "auditor_fn_violation": 0.006895947957142765,
            "auditor_fp_violation": 0.014041129741287382,
            "ave_precision_score": 0.8603819355917233,
            "fpr": 0.11525795828759605,
            "logloss": 1.1730849970538215,
            "mae": 0.23397068821738712,
            "precision": 0.7878787878787878,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 871,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6942187285126282,
            "auditor_fn_violation": 0.0024641577060931855,
            "auditor_fp_violation": 0.0197515601083245,
            "ave_precision_score": 0.694965634704119,
            "fpr": 0.15460526315789475,
            "logloss": 2.025806093455928,
            "mae": 0.36078876882913596,
            "precision": 0.6728538283062645,
            "recall": 0.6236559139784946
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7302793462072298,
            "auditor_fn_violation": 0.006934109127478513,
            "auditor_fp_violation": 0.020031630258920727,
            "ave_precision_score": 0.7308640888251356,
            "fpr": 0.1350164654226125,
            "logloss": 2.034633099020724,
            "mae": 0.35149973099747783,
            "precision": 0.7126168224299065,
            "recall": 0.623721881390593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 871,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8156549030376955,
            "auditor_fn_violation": 0.009882569326542166,
            "auditor_fp_violation": 0.02583745437419051,
            "ave_precision_score": 0.8159550236161447,
            "fpr": 0.11842105263157894,
            "logloss": 0.9803949758377123,
            "mae": 0.2755402286615102,
            "precision": 0.7583892617449665,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8128395719436651,
            "auditor_fn_violation": 0.012198105859086516,
            "auditor_fp_violation": 0.01023301304227946,
            "ave_precision_score": 0.813225173646293,
            "fpr": 0.10318331503841932,
            "logloss": 1.0537729412634655,
            "mae": 0.27301145301560625,
            "precision": 0.7906458797327395,
            "recall": 0.7259713701431493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8251166246940529,
            "auditor_fn_violation": 0.009759950952650448,
            "auditor_fp_violation": 0.02689715059460733,
            "ave_precision_score": 0.8254099774008374,
            "fpr": 0.13815789473684212,
            "logloss": 0.8995991749470098,
            "mae": 0.2713840996484326,
            "precision": 0.7402061855670103,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8243347667680455,
            "auditor_fn_violation": 0.007513261006691675,
            "auditor_fp_violation": 0.013146326363924862,
            "ave_precision_score": 0.8246931631089935,
            "fpr": 0.1251372118551043,
            "logloss": 0.9505858317369568,
            "mae": 0.2664686452568442,
            "precision": 0.7649484536082474,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 871,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.785198321070811,
            "auditor_fn_violation": 0.004963686096962838,
            "auditor_fp_violation": 0.023210290827740506,
            "ave_precision_score": 0.745734211739744,
            "fpr": 0.3519736842105263,
            "logloss": 2.956365228644936,
            "mae": 0.35941828687633426,
            "precision": 0.586340206185567,
            "recall": 0.978494623655914
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7897780687428382,
            "auditor_fn_violation": 0.004431185308398375,
            "auditor_fp_violation": 0.029804235749475876,
            "ave_precision_score": 0.7480501798190105,
            "fpr": 0.3205268935236004,
            "logloss": 3.010310520221995,
            "mae": 0.3416395152118527,
            "precision": 0.6132450331125828,
            "recall": 0.9468302658486708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7958999050615552,
            "auditor_fn_violation": 0.0037162799471797754,
            "auditor_fp_violation": 0.019025471957298177,
            "ave_precision_score": 0.793052746350592,
            "fpr": 0.12719298245614036,
            "logloss": 1.5727516539758675,
            "mae": 0.30380374909594504,
            "precision": 0.7314814814814815,
            "recall": 0.6795698924731183
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8182952617340915,
            "auditor_fn_violation": 0.0027543385883509706,
            "auditor_fp_violation": 0.008042825705828191,
            "ave_precision_score": 0.813853270184195,
            "fpr": 0.10867178924259056,
            "logloss": 1.6587753744596057,
            "mae": 0.29249917220289345,
            "precision": 0.7686915887850467,
            "recall": 0.6728016359918201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 871,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7835502552589317,
            "auditor_fn_violation": 0.01652990001886437,
            "auditor_fp_violation": 0.01861827387260097,
            "ave_precision_score": 0.7854106391774179,
            "fpr": 0.11842105263157894,
            "logloss": 1.1114093653696013,
            "mae": 0.2818115285811268,
            "precision": 0.7505773672055427,
            "recall": 0.6989247311827957
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7912066178283427,
            "auditor_fn_violation": 0.0070463478637601325,
            "auditor_fp_violation": 0.0023254483120990982,
            "ave_precision_score": 0.7916215232835384,
            "fpr": 0.09549945115257959,
            "logloss": 1.1438650682408313,
            "mae": 0.27600017040894465,
            "precision": 0.7990762124711316,
            "recall": 0.7075664621676891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 871,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6701629440955161,
            "auditor_fn_violation": 9.432182607055215e-05,
            "auditor_fp_violation": 0.0166068134542172,
            "ave_precision_score": 0.6717157746937923,
            "fpr": 0.19517543859649122,
            "logloss": 2.0883919421287116,
            "mae": 0.36736094628784915,
            "precision": 0.6396761133603239,
            "recall": 0.6795698924731183
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7224704646665799,
            "auditor_fn_violation": 0.011367539210602528,
            "auditor_fp_violation": 0.020934237154109085,
            "ave_precision_score": 0.7239180510348967,
            "fpr": 0.1778265642151482,
            "logloss": 2.028843498917765,
            "mae": 0.353508242644811,
            "precision": 0.6746987951807228,
            "recall": 0.6871165644171779
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 871,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8286911805418841,
            "auditor_fn_violation": 0.009495849839652898,
            "auditor_fp_violation": 0.028074590839514902,
            "ave_precision_score": 0.828968186818378,
            "fpr": 0.12719298245614036,
            "logloss": 0.902350499239613,
            "mae": 0.26655220733592094,
            "precision": 0.7526652452025586,
            "recall": 0.7591397849462366
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8276502197616797,
            "auditor_fn_violation": 0.014465328331975249,
            "auditor_fp_violation": 0.01386425000390176,
            "ave_precision_score": 0.8279094859552699,
            "fpr": 0.10976948408342481,
            "logloss": 0.9871275041334705,
            "mae": 0.2646376095298179,
            "precision": 0.7840172786177105,
            "recall": 0.7423312883435583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7773474590605752,
            "auditor_fn_violation": 0.01042491982644784,
            "auditor_fp_violation": 0.03926763216766749,
            "ave_precision_score": 0.7534237525781774,
            "fpr": 0.17105263157894737,
            "logloss": 2.064771213194326,
            "mae": 0.27102426581786376,
            "precision": 0.7121771217712177,
            "recall": 0.8301075268817204
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8157259289804699,
            "auditor_fn_violation": 0.010572888957728649,
            "auditor_fp_violation": 0.022643207557967136,
            "ave_precision_score": 0.7976791766588247,
            "fpr": 0.150384193194292,
            "logloss": 1.8007300433337134,
            "mae": 0.2602232698618091,
            "precision": 0.7458256029684601,
            "recall": 0.8220858895705522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 871,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.5277176629018046,
            "auditor_fn_violation": 0.009903791737408043,
            "auditor_fp_violation": 0.007503728560775541,
            "ave_precision_score": 0.5257957578314729,
            "fpr": 0.14692982456140352,
            "logloss": 3.359202925532903,
            "mae": 0.4321415638822712,
            "precision": 0.6318681318681318,
            "recall": 0.4946236559139785
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5366528636745584,
            "auditor_fn_violation": 0.008512185759598103,
            "auditor_fp_violation": 0.018327862200279887,
            "ave_precision_score": 0.5356439407127594,
            "fpr": 0.14709110867178923,
            "logloss": 3.947268785116247,
            "mae": 0.44812507262373164,
            "precision": 0.6358695652173914,
            "recall": 0.4785276073619632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 871,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7953493651637198,
            "auditor_fn_violation": 0.0029121863799283177,
            "auditor_fp_violation": 0.021978884571608,
            "ave_precision_score": 0.7958831700672537,
            "fpr": 0.18859649122807018,
            "logloss": 0.9429892651428866,
            "mae": 0.2906211565136226,
            "precision": 0.6912028725314183,
            "recall": 0.8279569892473119
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.781332801742497,
            "auditor_fn_violation": 0.01169078677109359,
            "auditor_fp_violation": 0.017984507415943107,
            "ave_precision_score": 0.7837383407944895,
            "fpr": 0.1734357848518112,
            "logloss": 0.9974870182582265,
            "mae": 0.2864994468430717,
            "precision": 0.7116788321167883,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 871,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8637402719576055,
            "auditor_fn_violation": 0.007168458781362011,
            "auditor_fp_violation": 0.02230758663997803,
            "ave_precision_score": 0.8587458659720693,
            "fpr": 0.16557017543859648,
            "logloss": 1.134686195276733,
            "mae": 0.256310872348785,
            "precision": 0.7198515769944341,
            "recall": 0.8344086021505376
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.871690393818996,
            "auditor_fn_violation": 0.006815136067019999,
            "auditor_fp_violation": 0.014361073972146645,
            "ave_precision_score": 0.8650633573114728,
            "fpr": 0.1394072447859495,
            "logloss": 1.1562783114874704,
            "mae": 0.24490834550463195,
            "precision": 0.759469696969697,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8327050791902657,
            "auditor_fn_violation": 0.011344557630635731,
            "auditor_fp_violation": 0.02741963970328506,
            "ave_precision_score": 0.8330082513306561,
            "fpr": 0.14144736842105263,
            "logloss": 0.8181331457215806,
            "mae": 0.2674115484106608,
            "precision": 0.742,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8336131345773712,
            "auditor_fn_violation": 0.008494227561793041,
            "auditor_fp_violation": 0.016168888935131957,
            "ave_precision_score": 0.8339299766322237,
            "fpr": 0.12733260153677278,
            "logloss": 0.8592086035308099,
            "mae": 0.2619869749498207,
            "precision": 0.7661290322580645,
            "recall": 0.7770961145194274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 871,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.824538916055807,
            "auditor_fn_violation": 0.010431993963403137,
            "auditor_fp_violation": 0.02720622865889556,
            "ave_precision_score": 0.8248554925710788,
            "fpr": 0.12390350877192982,
            "logloss": 0.9802378359728176,
            "mae": 0.2654370067942582,
            "precision": 0.7575107296137339,
            "recall": 0.7591397849462366
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8174598286524468,
            "auditor_fn_violation": 0.009564985105919698,
            "auditor_fp_violation": 0.013304997893050187,
            "ave_precision_score": 0.8178540332397959,
            "fpr": 0.10647639956092206,
            "logloss": 1.1401828251931678,
            "mae": 0.26902939445714197,
            "precision": 0.7853982300884956,
            "recall": 0.7259713701431493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 871,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8027607074923713,
            "auditor_fn_violation": 0.01088709677419355,
            "auditor_fp_violation": 0.02180472153538209,
            "ave_precision_score": 0.8030494068018802,
            "fpr": 0.1611842105263158,
            "logloss": 0.7180114995290884,
            "mae": 0.3029703396815217,
            "precision": 0.7048192771084337,
            "recall": 0.7548387096774194
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7979775386206055,
            "auditor_fn_violation": 0.00734714767699488,
            "auditor_fp_violation": 0.014212807133455766,
            "ave_precision_score": 0.7986592182105061,
            "fpr": 0.132821075740944,
            "logloss": 0.7370974041100647,
            "mae": 0.29408274450960525,
            "precision": 0.753061224489796,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 871,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.866340195930086,
            "auditor_fn_violation": 0.01015138653084324,
            "auditor_fp_violation": 0.014460438007771104,
            "ave_precision_score": 0.8634822261999318,
            "fpr": 0.12938596491228072,
            "logloss": 0.7313099116238373,
            "mae": 0.24669708972139728,
            "precision": 0.7616161616161616,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8741139642565332,
            "auditor_fn_violation": 0.00692288525385035,
            "auditor_fp_violation": 0.0066928171219585815,
            "ave_precision_score": 0.8713256494101037,
            "fpr": 0.10647639956092206,
            "logloss": 0.7796216946998452,
            "mae": 0.2358672787096809,
            "precision": 0.8008213552361396,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 871,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8182522288878077,
            "auditor_fn_violation": 0.009396811922278822,
            "auditor_fp_violation": 0.02179736253385141,
            "ave_precision_score": 0.8186029401764827,
            "fpr": 0.12171052631578948,
            "logloss": 0.9361139864449685,
            "mae": 0.27857192347311444,
            "precision": 0.7511210762331838,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8169442370918054,
            "auditor_fn_violation": 0.014633686436397678,
            "auditor_fp_violation": 0.007886755349311476,
            "ave_precision_score": 0.8172978186414587,
            "fpr": 0.10537870472008781,
            "logloss": 1.0242541938693344,
            "mae": 0.2802268038642448,
            "precision": 0.7837837837837838,
            "recall": 0.7116564417177914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 871,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7313625415198146,
            "auditor_fn_violation": 0.0062441048858705986,
            "auditor_fp_violation": 0.017926527728717768,
            "ave_precision_score": 0.7158636757951549,
            "fpr": 0.15350877192982457,
            "logloss": 1.8770299602118148,
            "mae": 0.30422858215673865,
            "precision": 0.7125256673511293,
            "recall": 0.7462365591397849
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7143734126120271,
            "auditor_fn_violation": 0.0037442842423548624,
            "auditor_fp_violation": 0.0053844272998267665,
            "ave_precision_score": 0.6945469576770158,
            "fpr": 0.14709110867178923,
            "logloss": 2.310666717992871,
            "mae": 0.3081224173694657,
            "precision": 0.7281947261663286,
            "recall": 0.7341513292433538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8395386975078728,
            "auditor_fn_violation": 0.00912563667232598,
            "auditor_fp_violation": 0.014534028023077829,
            "ave_precision_score": 0.8399191147770864,
            "fpr": 0.1611842105263158,
            "logloss": 0.6108016959114487,
            "mae": 0.27663727004535643,
            "precision": 0.7183908045977011,
            "recall": 0.8064516129032258
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8403750593783189,
            "auditor_fn_violation": 0.00844259774310349,
            "auditor_fp_violation": 0.0198521493489265,
            "ave_precision_score": 0.8406450219494093,
            "fpr": 0.141602634467618,
            "logloss": 0.695425725346233,
            "mae": 0.2759552513146796,
            "precision": 0.750965250965251,
            "recall": 0.7955010224948875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 871,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8426742970342505,
            "auditor_fn_violation": 0.005093378607809846,
            "auditor_fp_violation": 0.015397484202676715,
            "ave_precision_score": 0.8428899968615227,
            "fpr": 0.14364035087719298,
            "logloss": 0.8347480443417001,
            "mae": 0.2553032316283793,
            "precision": 0.7426326129666012,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.832758624329111,
            "auditor_fn_violation": 0.009387647902594737,
            "auditor_fp_violation": 0.009613933961429816,
            "ave_precision_score": 0.833129809723115,
            "fpr": 0.13062568605927552,
            "logloss": 0.9858189439360991,
            "mae": 0.25919488788095174,
            "precision": 0.7643564356435644,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 871,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6669099784275718,
            "auditor_fn_violation": 0.009748160724391625,
            "auditor_fp_violation": 0.009498017975587742,
            "ave_precision_score": 0.6610809777021898,
            "fpr": 0.03179824561403509,
            "logloss": 8.640002778886707,
            "mae": 0.4253182205835076,
            "precision": 0.7972027972027972,
            "recall": 0.24516129032258063
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.713322383597072,
            "auditor_fn_violation": 0.00955825078174281,
            "auditor_fp_violation": 0.004208697280734156,
            "ave_precision_score": 0.7013730178095889,
            "fpr": 0.019758507135016465,
            "logloss": 8.979743645976518,
            "mae": 0.43687438654596106,
            "precision": 0.8676470588235294,
            "recall": 0.24130879345603273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 871,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8656194253943377,
            "auditor_fn_violation": 0.00972222222222222,
            "auditor_fp_violation": 0.012885611680207229,
            "ave_precision_score": 0.8660253868254933,
            "fpr": 0.08114035087719298,
            "logloss": 0.5835788057705948,
            "mae": 0.25150914267892055,
            "precision": 0.8216867469879519,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8688380053171639,
            "auditor_fn_violation": 0.012945615842722104,
            "auditor_fp_violation": 0.01093272847399608,
            "ave_precision_score": 0.8690486849622515,
            "fpr": 0.07135016465422613,
            "logloss": 0.7587455429657508,
            "mae": 0.2617145528907615,
            "precision": 0.8422330097087378,
            "recall": 0.7096114519427403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8229547320768629,
            "auditor_fn_violation": 0.013186191284663272,
            "auditor_fp_violation": 0.02720622865889556,
            "ave_precision_score": 0.8232559513196012,
            "fpr": 0.12390350877192982,
            "logloss": 0.9310735124609468,
            "mae": 0.2673484677494806,
            "precision": 0.7564655172413793,
            "recall": 0.7548387096774194
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8161216628187657,
            "auditor_fn_violation": 0.014943465348534952,
            "auditor_fp_violation": 0.011065388277035291,
            "ave_precision_score": 0.8164963473769467,
            "fpr": 0.10976948408342481,
            "logloss": 1.0810932544092515,
            "mae": 0.2713255858654963,
            "precision": 0.7797356828193832,
            "recall": 0.7239263803680982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 871,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8328715902694284,
            "auditor_fn_violation": 0.010304659498207884,
            "auditor_fp_violation": 0.011347580360296716,
            "ave_precision_score": 0.8332587224019322,
            "fpr": 0.09539473684210527,
            "logloss": 0.83714200018243,
            "mae": 0.271646837585599,
            "precision": 0.7878048780487805,
            "recall": 0.6946236559139785
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8383158996903746,
            "auditor_fn_violation": 0.012240756578873533,
            "auditor_fp_violation": 0.007969992872787057,
            "ave_precision_score": 0.8385793693501906,
            "fpr": 0.08562019758507135,
            "logloss": 0.8889951964038298,
            "mae": 0.2724887602994881,
            "precision": 0.8138424821002387,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 871,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6609160443605842,
            "auditor_fn_violation": 0.0033790794189775494,
            "auditor_fp_violation": 0.01539503120216649,
            "ave_precision_score": 0.6625670012712865,
            "fpr": 0.1513157894736842,
            "logloss": 2.222426892168508,
            "mae": 0.3702879299195233,
            "precision": 0.6745283018867925,
            "recall": 0.6150537634408603
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7091828470907511,
            "auditor_fn_violation": 0.007798347396846991,
            "auditor_fp_violation": 0.01382263124216397,
            "ave_precision_score": 0.7107226391044204,
            "fpr": 0.13611416026344675,
            "logloss": 2.2099981933813817,
            "mae": 0.3596732397740227,
            "precision": 0.7019230769230769,
            "recall": 0.5971370143149284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8208530807696338,
            "auditor_fn_violation": 0.013051782682512737,
            "auditor_fp_violation": 0.02261666470426626,
            "ave_precision_score": 0.8212713828758034,
            "fpr": 0.12390350877192982,
            "logloss": 1.3138683155698938,
            "mae": 0.2766002193332991,
            "precision": 0.7521929824561403,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8254726742530027,
            "auditor_fn_violation": 0.012851335304245553,
            "auditor_fp_violation": 0.005530092965909034,
            "ave_precision_score": 0.8257459399328975,
            "fpr": 0.10757409440175632,
            "logloss": 1.3602373179690466,
            "mae": 0.2781317067398209,
            "precision": 0.7827050997782705,
            "recall": 0.721881390593047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 871,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7636162643561264,
            "auditor_fn_violation": 0.008474816072439164,
            "auditor_fp_violation": 0.009100631892931435,
            "ave_precision_score": 0.7641666087983453,
            "fpr": 0.29385964912280704,
            "logloss": 0.994768984609367,
            "mae": 0.36219732710052677,
            "precision": 0.6087591240875913,
            "recall": 0.896774193548387
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7814539602487209,
            "auditor_fn_violation": 0.002150494187155849,
            "auditor_fp_violation": 0.008864796250149588,
            "ave_precision_score": 0.7822930415482012,
            "fpr": 0.270032930845225,
            "logloss": 0.8838313757164038,
            "mae": 0.33199807622382993,
            "precision": 0.6460431654676259,
            "recall": 0.918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 871,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8227990465584325,
            "auditor_fn_violation": 0.011212507074136955,
            "auditor_fp_violation": 0.025977275403273287,
            "ave_precision_score": 0.8230979798454607,
            "fpr": 0.1425438596491228,
            "logloss": 0.9757130252509376,
            "mae": 0.2701843296900617,
            "precision": 0.7330595482546202,
            "recall": 0.7677419354838709
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8202921527837604,
            "auditor_fn_violation": 0.011241831825967104,
            "auditor_fp_violation": 0.01461338771518201,
            "ave_precision_score": 0.8206276038705166,
            "fpr": 0.1207464324917673,
            "logloss": 1.0818595746893485,
            "mae": 0.2638887723028258,
            "precision": 0.7736625514403292,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 871,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8377051409215746,
            "auditor_fn_violation": 0.010158460667798538,
            "auditor_fp_violation": 0.018294477805251386,
            "ave_precision_score": 0.8379644267736771,
            "fpr": 0.09868421052631579,
            "logloss": 0.892627581382183,
            "mae": 0.2556981763726487,
            "precision": 0.7902097902097902,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.83356020880413,
            "auditor_fn_violation": 0.007389798396781887,
            "auditor_fp_violation": 0.009463065950130321,
            "ave_precision_score": 0.8339211663379458,
            "fpr": 0.0889132821075741,
            "logloss": 1.011968816990011,
            "mae": 0.26048362391223817,
            "precision": 0.8116279069767441,
            "recall": 0.7137014314928425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 871,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8215729889695791,
            "auditor_fn_violation": 0.011259667987172234,
            "auditor_fp_violation": 0.023227461831312073,
            "ave_precision_score": 0.8218568673967711,
            "fpr": 0.12390350877192982,
            "logloss": 0.988494797652498,
            "mae": 0.2706119390260909,
            "precision": 0.755939524838013,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8115846176052571,
            "auditor_fn_violation": 0.013340696194433411,
            "auditor_fp_violation": 0.014904719047346542,
            "ave_precision_score": 0.8120032032974721,
            "fpr": 0.10976948408342481,
            "logloss": 1.0869322465571016,
            "mae": 0.271365460053593,
            "precision": 0.7816593886462883,
            "recall": 0.7321063394683026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 871,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.815114577114703,
            "auditor_fn_violation": 0.008920486700622529,
            "auditor_fp_violation": 0.02326425683896543,
            "ave_precision_score": 0.8154101001550031,
            "fpr": 0.1206140350877193,
            "logloss": 0.9784371024480075,
            "mae": 0.27533253775115674,
            "precision": 0.7577092511013216,
            "recall": 0.7397849462365591
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8107289849208494,
            "auditor_fn_violation": 0.011879347848046711,
            "auditor_fp_violation": 0.007683863885839745,
            "ave_precision_score": 0.8111314102056593,
            "fpr": 0.10537870472008781,
            "logloss": 1.0564892619533353,
            "mae": 0.27289393695558073,
            "precision": 0.7880794701986755,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 871,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.857055525298542,
            "auditor_fn_violation": 0.009585455574419921,
            "auditor_fp_violation": 0.01225028454805919,
            "ave_precision_score": 0.8574524188062563,
            "fpr": 0.09320175438596491,
            "logloss": 0.6210344526452656,
            "mae": 0.2548152870474074,
            "precision": 0.8023255813953488,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8618918461733194,
            "auditor_fn_violation": 0.011650380826032206,
            "auditor_fp_violation": 0.00794918349191816,
            "ave_precision_score": 0.8621254462757412,
            "fpr": 0.07903402854006586,
            "logloss": 0.818171250994958,
            "mae": 0.26302910984687344,
            "precision": 0.8273381294964028,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 871,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8007955351240352,
            "auditor_fn_violation": 0.003643180531975104,
            "auditor_fp_violation": 0.020995231367008125,
            "ave_precision_score": 0.8011930551978778,
            "fpr": 0.18311403508771928,
            "logloss": 0.9750182914283222,
            "mae": 0.289788006654359,
            "precision": 0.6935779816513762,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7853511906544819,
            "auditor_fn_violation": 0.011286727320479757,
            "auditor_fp_violation": 0.01596079512644301,
            "ave_precision_score": 0.7868727639204363,
            "fpr": 0.1602634467618002,
            "logloss": 1.0468443105704364,
            "mae": 0.28357673073943157,
            "precision": 0.7271028037383177,
            "recall": 0.7955010224948875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 871,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8694386970088532,
            "auditor_fn_violation": 0.013233352197698547,
            "auditor_fp_violation": 0.012054044507241256,
            "ave_precision_score": 0.8665099014638803,
            "fpr": 0.13486842105263158,
            "logloss": 0.8653130315179536,
            "mae": 0.24221761289946442,
            "precision": 0.754,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.869419804727988,
            "auditor_fn_violation": 0.009731098435616497,
            "auditor_fp_violation": 0.012750948127415842,
            "ave_precision_score": 0.8638562388264299,
            "fpr": 0.1119648737650933,
            "logloss": 0.9917431938241291,
            "mae": 0.235860945751667,
            "precision": 0.7926829268292683,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 871,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.817160632925328,
            "auditor_fn_violation": 0.004944821731748729,
            "auditor_fp_violation": 0.019150574983319592,
            "ave_precision_score": 0.8176344802069395,
            "fpr": 0.16557017543859648,
            "logloss": 0.8964273679594646,
            "mae": 0.27665979900910254,
            "precision": 0.7145557655954632,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8123820318008317,
            "auditor_fn_violation": 0.008269750089229802,
            "auditor_fp_violation": 0.019337117172421328,
            "ave_precision_score": 0.8129473956990367,
            "fpr": 0.15148188803512624,
            "logloss": 0.9546489720566964,
            "mae": 0.2724443465518914,
            "precision": 0.735632183908046,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 871,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8082487088841672,
            "auditor_fn_violation": 0.009019524617996611,
            "auditor_fp_violation": 0.019086796970053777,
            "ave_precision_score": 0.7891231957911747,
            "fpr": 0.1337719298245614,
            "logloss": 1.7574448838741734,
            "mae": 0.29722634241808,
            "precision": 0.7276785714285714,
            "recall": 0.7010752688172043
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8440814690863251,
            "auditor_fn_violation": 0.006774730121958612,
            "auditor_fp_violation": 0.015253276176900546,
            "ave_precision_score": 0.8300189414090183,
            "fpr": 0.1141602634467618,
            "logloss": 1.547556794678972,
            "mae": 0.27647663530449307,
            "precision": 0.7714285714285715,
            "recall": 0.7177914110429447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8336149868810805,
            "auditor_fn_violation": 0.00873891718543671,
            "auditor_fp_violation": 0.020580674280780257,
            "ave_precision_score": 0.8339739917946124,
            "fpr": 0.13048245614035087,
            "logloss": 0.8298787083996781,
            "mae": 0.26769640539231804,
            "precision": 0.750524109014675,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8356181682914143,
            "auditor_fn_violation": 0.012474213150339305,
            "auditor_fp_violation": 0.01130989850224481,
            "ave_precision_score": 0.8359091489966223,
            "fpr": 0.11306256860592755,
            "logloss": 0.8668518993832072,
            "mae": 0.26553816416410153,
            "precision": 0.7808510638297872,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8225344151404542,
            "auditor_fn_violation": 0.011106395019807584,
            "auditor_fp_violation": 0.02824875387574081,
            "ave_precision_score": 0.822829937349767,
            "fpr": 0.13267543859649122,
            "logloss": 0.9273711093995797,
            "mae": 0.2670072226561737,
            "precision": 0.7484407484407485,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8181493819521704,
            "auditor_fn_violation": 0.013293555925195133,
            "auditor_fp_violation": 0.008755547000587872,
            "ave_precision_score": 0.8184947549583163,
            "fpr": 0.11855104281009879,
            "logloss": 1.0519294818497158,
            "mae": 0.26583203556460727,
            "precision": 0.7726315789473684,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8246654775149989,
            "auditor_fn_violation": 0.00988964346349745,
            "auditor_fp_violation": 0.01722251658228345,
            "ave_precision_score": 0.8249473019152989,
            "fpr": 0.13706140350877194,
            "logloss": 0.8942734476998541,
            "mae": 0.27245320653716,
            "precision": 0.7390396659707724,
            "recall": 0.7612903225806451
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8194164402571681,
            "auditor_fn_violation": 0.017536180156640383,
            "auditor_fp_violation": 0.015406745360808653,
            "ave_precision_score": 0.8199387681190052,
            "fpr": 0.11306256860592755,
            "logloss": 0.9402644610459238,
            "mae": 0.2713097317726848,
            "precision": 0.7813163481953291,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 871,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6672721287717275,
            "auditor_fn_violation": 0.007958404074702888,
            "auditor_fp_violation": 0.027088484634404816,
            "ave_precision_score": 0.6634520640016945,
            "fpr": 0.22478070175438597,
            "logloss": 1.7206507847907002,
            "mae": 0.32758261912169206,
            "precision": 0.6600331674958541,
            "recall": 0.8559139784946237
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7200024542155041,
            "auditor_fn_violation": 0.0070777747099189875,
            "auditor_fp_violation": 0.023452172239245454,
            "ave_precision_score": 0.7147689976817271,
            "fpr": 0.18660812294182216,
            "logloss": 1.3688603914447506,
            "mae": 0.3034740594173834,
            "precision": 0.7103918228279387,
            "recall": 0.852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 871,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6510153572430931,
            "auditor_fn_violation": 0.017437747594793437,
            "auditor_fp_violation": 0.01925850700576947,
            "ave_precision_score": 0.6431536471985654,
            "fpr": 0.2576754385964912,
            "logloss": 1.947447033684101,
            "mae": 0.3573826954877773,
            "precision": 0.6221864951768489,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6899968654351729,
            "auditor_fn_violation": 0.012929902419642684,
            "auditor_fp_violation": 0.02887821830081001,
            "ave_precision_score": 0.6820391790892149,
            "fpr": 0.22722283205268934,
            "logloss": 1.6585385334628961,
            "mae": 0.3344116199975085,
            "precision": 0.6634146341463415,
            "recall": 0.8343558282208589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 871,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8082985174614519,
            "auditor_fn_violation": 0.008524335031126203,
            "auditor_fp_violation": 0.022584775697633345,
            "ave_precision_score": 0.8096112261657801,
            "fpr": 0.23355263157894737,
            "logloss": 1.1225372132367863,
            "mae": 0.2872932590602746,
            "precision": 0.6635071090047393,
            "recall": 0.9032258064516129
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8297538489051624,
            "auditor_fn_violation": 0.009535803034486475,
            "auditor_fp_violation": 0.020328163936302494,
            "ave_precision_score": 0.8310067131756008,
            "fpr": 0.2074643249176729,
            "logloss": 1.04547707611504,
            "mae": 0.2782921366809818,
            "precision": 0.6936790923824959,
            "recall": 0.8752556237218814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 871,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8703271090961029,
            "auditor_fn_violation": 0.007512733446519524,
            "auditor_fp_violation": 0.011678735429176978,
            "ave_precision_score": 0.8653191520093537,
            "fpr": 0.11403508771929824,
            "logloss": 1.2797432625379124,
            "mae": 0.2279861299423063,
            "precision": 0.7801268498942917,
            "recall": 0.7935483870967742
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8782099274738902,
            "auditor_fn_violation": 0.008105881534258636,
            "auditor_fp_violation": 0.007798315480618664,
            "ave_precision_score": 0.8714921356741561,
            "fpr": 0.08781558726673985,
            "logloss": 1.3709040178183518,
            "mae": 0.22053694756615588,
            "precision": 0.8257080610021786,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 871,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7075751341626577,
            "auditor_fn_violation": 0.05881437464629316,
            "auditor_fp_violation": 0.03122424349464265,
            "ave_precision_score": 0.7018250995203569,
            "fpr": 0.09649122807017543,
            "logloss": 7.3093156151883445,
            "mae": 0.37339966070029906,
            "precision": 0.7105263157894737,
            "recall": 0.4645161290322581
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.716695718922123,
            "auditor_fn_violation": 0.06092543082838923,
            "auditor_fp_violation": 0.01609605610209082,
            "ave_precision_score": 0.7092674544168229,
            "fpr": 0.05817782656421515,
            "logloss": 8.18869162239618,
            "mae": 0.3780143630760082,
            "precision": 0.7937743190661478,
            "recall": 0.4171779141104294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8202280448055054,
            "auditor_fn_violation": 0.013051782682512737,
            "auditor_fp_violation": 0.02372542093488756,
            "ave_precision_score": 0.8206471403493768,
            "fpr": 0.125,
            "logloss": 1.344925016387033,
            "mae": 0.277049929634755,
            "precision": 0.75054704595186,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8257723298802648,
            "auditor_fn_violation": 0.012851335304245553,
            "auditor_fp_violation": 0.005530092965909034,
            "ave_precision_score": 0.8260398719777622,
            "fpr": 0.10757409440175632,
            "logloss": 1.3901362483420654,
            "mae": 0.27848800610750823,
            "precision": 0.7827050997782705,
            "recall": 0.721881390593047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8324389500031304,
            "auditor_fn_violation": 0.008576212035465004,
            "auditor_fp_violation": 0.025940480395619928,
            "ave_precision_score": 0.832730131222261,
            "fpr": 0.13815789473684212,
            "logloss": 0.8092054199679227,
            "mae": 0.2678469197140336,
            "precision": 0.7428571428571429,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8326745854391996,
            "auditor_fn_violation": 0.008651361792587308,
            "auditor_fp_violation": 0.014384484525624157,
            "ave_precision_score": 0.833005113611831,
            "fpr": 0.11745334796926454,
            "logloss": 0.8550159533791462,
            "mae": 0.26262981476485153,
            "precision": 0.7770833333333333,
            "recall": 0.7627811860940695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.82788527550244,
            "auditor_fn_violation": 0.014803810601773252,
            "auditor_fp_violation": 0.019118685976686686,
            "ave_precision_score": 0.828158845959559,
            "fpr": 0.13706140350877194,
            "logloss": 0.9153361073358992,
            "mae": 0.26954186378228334,
            "precision": 0.7412008281573499,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8147643381530594,
            "auditor_fn_violation": 0.01781228744789317,
            "auditor_fp_violation": 0.017068894657711695,
            "ave_precision_score": 0.815577365131368,
            "fpr": 0.1141602634467618,
            "logloss": 0.9757566736121401,
            "mae": 0.27012278902367054,
            "precision": 0.7787234042553192,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 871,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7650935894600301,
            "auditor_fn_violation": 0.005138181475193367,
            "auditor_fp_violation": 0.012198771537344487,
            "ave_precision_score": 0.7613754082585511,
            "fpr": 0.13596491228070176,
            "logloss": 1.9279154522955466,
            "mae": 0.33161470034199175,
            "precision": 0.7082352941176471,
            "recall": 0.6473118279569893
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7930434143936733,
            "auditor_fn_violation": 0.007704066858370431,
            "auditor_fp_violation": 0.011572616935714625,
            "ave_precision_score": 0.7903865164718773,
            "fpr": 0.11086717892425905,
            "logloss": 1.9172872579259608,
            "mae": 0.3143543165349507,
            "precision": 0.7589498806682577,
            "recall": 0.6503067484662577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8173897408598825,
            "auditor_fn_violation": 0.011686474250141486,
            "auditor_fp_violation": 0.01984722712822325,
            "ave_precision_score": 0.8176440334204877,
            "fpr": 0.13048245614035087,
            "logloss": 0.9740964138752904,
            "mae": 0.2760168760134425,
            "precision": 0.7451820128479657,
            "recall": 0.7483870967741936
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8089032552030712,
            "auditor_fn_violation": 0.011039802100660193,
            "auditor_fp_violation": 0.009244567451006916,
            "ave_precision_score": 0.8098590657126462,
            "fpr": 0.11306256860592755,
            "logloss": 1.0275272488336649,
            "mae": 0.27345207823385304,
            "precision": 0.7784946236559139,
            "recall": 0.7402862985685071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 871,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8303024814488498,
            "auditor_fn_violation": 0.009927372193925676,
            "auditor_fp_violation": 0.023946190980807722,
            "ave_precision_score": 0.8305965614277703,
            "fpr": 0.13157894736842105,
            "logloss": 0.8373056113330286,
            "mae": 0.26909709170242074,
            "precision": 0.7473684210526316,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8310252202493809,
            "auditor_fn_violation": 0.012916433771288881,
            "auditor_fp_violation": 0.01294863724567035,
            "ave_precision_score": 0.8313468740070613,
            "fpr": 0.11525795828759605,
            "logloss": 0.8934683044574138,
            "mae": 0.2642621399366925,
            "precision": 0.7784810126582279,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 871,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8476458253861457,
            "auditor_fn_violation": 0.009493491794001137,
            "auditor_fp_violation": 0.022283056634875786,
            "ave_precision_score": 0.8481761465279967,
            "fpr": 0.09100877192982457,
            "logloss": 0.7572536414867997,
            "mae": 0.27413248313323896,
            "precision": 0.8004807692307693,
            "recall": 0.7161290322580646
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8641089311548606,
            "auditor_fn_violation": 0.005504187627250673,
            "auditor_fp_violation": 0.014569167780835604,
            "ave_precision_score": 0.8642933850581863,
            "fpr": 0.0801317233809001,
            "logloss": 0.8366105279305505,
            "mae": 0.27327832742277874,
            "precision": 0.8270142180094787,
            "recall": 0.7137014314928425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 871,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6225299608229635,
            "auditor_fn_violation": 0.009566591209205813,
            "auditor_fp_violation": 0.037182581733977,
            "ave_precision_score": 0.6058392300205477,
            "fpr": 0.16557017543859648,
            "logloss": 2.803761180980278,
            "mae": 0.36455913838351667,
            "precision": 0.6703056768558951,
            "recall": 0.6602150537634408
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6494715176544658,
            "auditor_fn_violation": 0.009293367364118173,
            "auditor_fp_violation": 0.024838597239635635,
            "ave_precision_score": 0.630504597979215,
            "fpr": 0.150384193194292,
            "logloss": 3.005438728579643,
            "mae": 0.36039840328750683,
            "precision": 0.7008733624454149,
            "recall": 0.656441717791411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 871,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7889675136552067,
            "auditor_fn_violation": 0.00625589511412941,
            "auditor_fp_violation": 0.01854468385729425,
            "ave_precision_score": 0.7893580566581857,
            "fpr": 0.22039473684210525,
            "logloss": 1.1424742855074448,
            "mae": 0.29809413185053724,
            "precision": 0.6638795986622074,
            "recall": 0.853763440860215
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7745669341155919,
            "auditor_fn_violation": 0.007773654874865034,
            "auditor_fp_violation": 0.014915123737780997,
            "ave_precision_score": 0.7754246992339883,
            "fpr": 0.20197585071350166,
            "logloss": 1.196041365154101,
            "mae": 0.2907578670496329,
            "precision": 0.6897133220910624,
            "recall": 0.83640081799591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8335973498421957,
            "auditor_fn_violation": 0.012738162610828148,
            "auditor_fp_violation": 0.02273931472977747,
            "ave_precision_score": 0.8338700758058889,
            "fpr": 0.10526315789473684,
            "logloss": 0.8299389170139874,
            "mae": 0.27016973691023594,
            "precision": 0.7725118483412322,
            "recall": 0.7010752688172043
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8327224622148864,
            "auditor_fn_violation": 0.011403455606212644,
            "auditor_fp_violation": 0.004096846858563844,
            "ave_precision_score": 0.8330575814033372,
            "fpr": 0.0889132821075741,
            "logloss": 0.8884775658212302,
            "mae": 0.2728472065224215,
            "precision": 0.8066825775656324,
            "recall": 0.6912065439672802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8154931820224132,
            "auditor_fn_violation": 0.009882569326542166,
            "auditor_fp_violation": 0.026892244593586877,
            "ave_precision_score": 0.8157936769229918,
            "fpr": 0.11951754385964912,
            "logloss": 0.980338149172154,
            "mae": 0.275524042420532,
            "precision": 0.7566964285714286,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8127510968653622,
            "auditor_fn_violation": 0.012198105859086516,
            "auditor_fp_violation": 0.006778655818042773,
            "ave_precision_score": 0.8131365392618418,
            "fpr": 0.10428100987925357,
            "logloss": 1.0534637483651825,
            "mae": 0.27302213307170037,
            "precision": 0.7888888888888889,
            "recall": 0.7259713701431493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 871,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8624813955678393,
            "auditor_fn_violation": 0.008639879268062632,
            "auditor_fp_violation": 0.01250784960163272,
            "ave_precision_score": 0.8575614440269792,
            "fpr": 0.1337719298245614,
            "logloss": 1.0402045852788764,
            "mae": 0.2456954305064941,
            "precision": 0.7555110220440882,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8704006376910698,
            "auditor_fn_violation": 0.0030035085828961643,
            "auditor_fp_violation": 0.011863948267879162,
            "ave_precision_score": 0.8638694067204189,
            "fpr": 0.10867178924259056,
            "logloss": 1.0987435831955044,
            "mae": 0.2390288753695765,
            "precision": 0.79375,
            "recall": 0.7791411042944786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 871,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8622226385575594,
            "auditor_fn_violation": 0.00926240332012828,
            "auditor_fp_violation": 0.017399132619019587,
            "ave_precision_score": 0.8592527499186051,
            "fpr": 0.13267543859649122,
            "logloss": 0.9578124037304055,
            "mae": 0.24958634116244346,
            "precision": 0.7570281124497992,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8609861539819075,
            "auditor_fn_violation": 0.005115841599716263,
            "auditor_fp_violation": 0.009533297610562845,
            "ave_precision_score": 0.8545806802133745,
            "fpr": 0.10867178924259056,
            "logloss": 1.0891411563760567,
            "mae": 0.24408482467724485,
            "precision": 0.7928870292887029,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 871,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7271550749450988,
            "auditor_fn_violation": 0.003968590831918507,
            "auditor_fp_violation": 0.021127693394560228,
            "ave_precision_score": 0.7278210642224627,
            "fpr": 0.11513157894736842,
            "logloss": 1.4870104332470815,
            "mae": 0.34985890996839797,
            "precision": 0.717741935483871,
            "recall": 0.5741935483870968
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.762917944818776,
            "auditor_fn_violation": 0.008202406847460824,
            "auditor_fp_violation": 0.007200045780637908,
            "ave_precision_score": 0.7633340689033532,
            "fpr": 0.10318331503841932,
            "logloss": 1.551935222085588,
            "mae": 0.33977592115707506,
            "precision": 0.7632241813602015,
            "recall": 0.6196319018404908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 871,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.824709378955296,
            "auditor_fn_violation": 0.010052348613469158,
            "auditor_fp_violation": 0.01722251658228345,
            "ave_precision_score": 0.8249866791563787,
            "fpr": 0.13706140350877194,
            "logloss": 0.8958449084242355,
            "mae": 0.2725388974153733,
            "precision": 0.7390396659707724,
            "recall": 0.7612903225806451
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8191021911390526,
            "auditor_fn_violation": 0.01849020941503416,
            "auditor_fp_violation": 0.013744596063905615,
            "ave_precision_score": 0.8195834965794947,
            "fpr": 0.1141602634467618,
            "logloss": 0.942463947747443,
            "mae": 0.27141415357468723,
            "precision": 0.7791932059447984,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 871,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8077530383552893,
            "auditor_fn_violation": 0.008597434446330883,
            "auditor_fp_violation": 0.017384414615958247,
            "ave_precision_score": 0.8048372766589789,
            "fpr": 0.13596491228070176,
            "logloss": 1.479784560610995,
            "mae": 0.29397499087969287,
            "precision": 0.7274725274725274,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8274967723072975,
            "auditor_fn_violation": 0.012647060804212993,
            "auditor_fp_violation": 0.009036473642317957,
            "ave_precision_score": 0.8228744718973757,
            "fpr": 0.11306256860592755,
            "logloss": 1.4965237469424335,
            "mae": 0.28255999951612815,
            "precision": 0.7700892857142857,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7922852053057947,
            "auditor_fn_violation": 0.007887662705149973,
            "auditor_fp_violation": 0.01946210604811807,
            "ave_precision_score": 0.7927137486578947,
            "fpr": 0.21820175438596492,
            "logloss": 1.0435509321291794,
            "mae": 0.29606745719541505,
            "precision": 0.6672240802675585,
            "recall": 0.8580645161290322
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7817964333829679,
            "auditor_fn_violation": 0.007986908473800111,
            "auditor_fp_violation": 0.012881006757846444,
            "ave_precision_score": 0.7822264355452195,
            "fpr": 0.19758507135016465,
            "logloss": 1.075418375002794,
            "mae": 0.28963579745604073,
            "precision": 0.6933560477001703,
            "recall": 0.8323108384458078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 871,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7939619184116926,
            "auditor_fn_violation": 0.012615544236936428,
            "auditor_fp_violation": 0.021483378468542726,
            "ave_precision_score": 0.7886155531865132,
            "fpr": 0.12280701754385964,
            "logloss": 1.9408206187788408,
            "mae": 0.28447733786365137,
            "precision": 0.7477477477477478,
            "recall": 0.7139784946236559
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7930544037131653,
            "auditor_fn_violation": 0.015661793260737328,
            "auditor_fp_violation": 0.01103417420573195,
            "ave_precision_score": 0.7862281434883704,
            "fpr": 0.10757409440175632,
            "logloss": 2.2185567234220027,
            "mae": 0.2892647862329277,
            "precision": 0.7777777777777778,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 871,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8678338364165666,
            "auditor_fn_violation": 0.006946802490096209,
            "auditor_fp_violation": 0.013636229836335811,
            "ave_precision_score": 0.8649114840351826,
            "fpr": 0.13486842105263158,
            "logloss": 0.7511502057951828,
            "mae": 0.24472262360189626,
            "precision": 0.7544910179640718,
            "recall": 0.8129032258064516
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8735870007561063,
            "auditor_fn_violation": 0.00478810448977393,
            "auditor_fp_violation": 0.007361318482371856,
            "ave_precision_score": 0.8690589283624504,
            "fpr": 0.10976948408342481,
            "logloss": 0.868766341540902,
            "mae": 0.23615518632325433,
            "precision": 0.797979797979798,
            "recall": 0.8077709611451943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 871,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8221942908489555,
            "auditor_fn_violation": 0.015185813997358992,
            "auditor_fp_violation": 0.026779406570116567,
            "ave_precision_score": 0.8224644019395968,
            "fpr": 0.12171052631578948,
            "logloss": 0.8808522590455988,
            "mae": 0.2770734551964037,
            "precision": 0.7511210762331838,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8220983360435681,
            "auditor_fn_violation": 0.012287896848111813,
            "auditor_fp_violation": 0.008188491371910458,
            "ave_precision_score": 0.8224636902378549,
            "fpr": 0.10318331503841932,
            "logloss": 0.9544585070749704,
            "mae": 0.27222006389750614,
            "precision": 0.7906458797327395,
            "recall": 0.7259713701431493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 871,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8588920707422506,
            "auditor_fn_violation": 0.01006413884172798,
            "auditor_fp_violation": 0.007179932493425962,
            "ave_precision_score": 0.8538190479861529,
            "fpr": 0.1074561403508772,
            "logloss": 1.0462275135363934,
            "mae": 0.24881483054007442,
            "precision": 0.7827050997782705,
            "recall": 0.7591397849462366
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8700806582078249,
            "auditor_fn_violation": 0.012195861084360885,
            "auditor_fp_violation": 0.005941078238069727,
            "ave_precision_score": 0.861472373453058,
            "fpr": 0.08562019758507135,
            "logloss": 1.0707633852081964,
            "mae": 0.24464721412014453,
            "precision": 0.8223234624145785,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 871,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8383905461962959,
            "auditor_fn_violation": 0.010599415204678369,
            "auditor_fp_violation": 0.025349307272655917,
            "ave_precision_score": 0.8387565649481055,
            "fpr": 0.14583333333333334,
            "logloss": 0.6050934140941912,
            "mae": 0.2752066403419947,
            "precision": 0.73558648111332,
            "recall": 0.7956989247311828
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8405682365174114,
            "auditor_fn_violation": 0.006489643731803296,
            "auditor_fp_violation": 0.010610183070528195,
            "ave_precision_score": 0.840849287642408,
            "fpr": 0.11964873765093303,
            "logloss": 0.7601131595559811,
            "mae": 0.2772800644513959,
            "precision": 0.7729166666666667,
            "recall": 0.7586912065439673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 871,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6617796825191903,
            "auditor_fn_violation": 0.009517072250518774,
            "auditor_fp_violation": 0.011112092311315202,
            "ave_precision_score": 0.6552819252237485,
            "fpr": 0.051535087719298246,
            "logloss": 8.530097731647702,
            "mae": 0.39432966426460153,
            "precision": 0.7853881278538812,
            "recall": 0.36989247311827955
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6987516559142788,
            "auditor_fn_violation": 0.012761544315220254,
            "auditor_fp_violation": 0.003990198781610751,
            "ave_precision_score": 0.6864125390188968,
            "fpr": 0.03951701427003293,
            "logloss": 9.000520823235794,
            "mae": 0.39786116583010084,
            "precision": 0.8317757009345794,
            "recall": 0.36400817995910023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 871,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8135339700220007,
            "auditor_fn_violation": 0.009373231465761177,
            "auditor_fp_violation": 0.013793221868990155,
            "ave_precision_score": 0.8106457461737117,
            "fpr": 0.12719298245614036,
            "logloss": 1.3639208210927452,
            "mae": 0.28934853429353535,
            "precision": 0.7399103139013453,
            "recall": 0.7096774193548387
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8289048668975716,
            "auditor_fn_violation": 0.01419820013962499,
            "auditor_fp_violation": 0.010623188933571257,
            "ave_precision_score": 0.8243170229325101,
            "fpr": 0.10757409440175632,
            "logloss": 1.4114332140789474,
            "mae": 0.2824744484975473,
            "precision": 0.776255707762557,
            "recall": 0.6952965235173824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8606907407038691,
            "auditor_fn_violation": 0.007427843803056031,
            "auditor_fp_violation": 0.02010233918128656,
            "ave_precision_score": 0.8558004719115941,
            "fpr": 0.16337719298245615,
            "logloss": 1.0933054938138336,
            "mae": 0.2576894458987608,
            "precision": 0.7220149253731343,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8645000192349913,
            "auditor_fn_violation": 0.006092318605366364,
            "auditor_fp_violation": 0.012925226692192841,
            "ave_precision_score": 0.8580579968793075,
            "fpr": 0.141602634467618,
            "logloss": 1.1434073439464294,
            "mae": 0.2502062829668162,
            "precision": 0.7547528517110266,
            "recall": 0.8118609406952966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8286716849184554,
            "auditor_fn_violation": 0.008621014902848521,
            "auditor_fp_violation": 0.01821843478943444,
            "ave_precision_score": 0.8289110559288457,
            "fpr": 0.1425438596491228,
            "logloss": 0.8832093067468118,
            "mae": 0.26769821854403514,
            "precision": 0.7389558232931727,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8272229527633903,
            "auditor_fn_violation": 0.013524767721935265,
            "auditor_fp_violation": 0.01601541975122386,
            "ave_precision_score": 0.8275829361089744,
            "fpr": 0.12623490669593854,
            "logloss": 0.9048890763696594,
            "mae": 0.2627230956150466,
            "precision": 0.7657841140529531,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 871,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8295035922748063,
            "auditor_fn_violation": 0.011146481795887574,
            "auditor_fp_violation": 0.0216845245103811,
            "ave_precision_score": 0.8297717279805685,
            "fpr": 0.11293859649122807,
            "logloss": 0.8329188471316495,
            "mae": 0.26713282573199926,
            "precision": 0.7690582959641256,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8329468528224886,
            "auditor_fn_violation": 0.011737927040331862,
            "auditor_fp_violation": 0.007345711446720182,
            "ave_precision_score": 0.8332701128105537,
            "fpr": 0.10098792535675083,
            "logloss": 0.880444738396613,
            "mae": 0.2638604468576138,
            "precision": 0.7951002227171492,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 871,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8190088912319404,
            "auditor_fn_violation": 0.008597434446330883,
            "auditor_fp_violation": 0.012735978649083556,
            "ave_precision_score": 0.8161047407253623,
            "fpr": 0.12390350877192982,
            "logloss": 1.3357447102777547,
            "mae": 0.28403903955557985,
            "precision": 0.7454954954954955,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8340694884038097,
            "auditor_fn_violation": 0.00842463954529844,
            "auditor_fp_violation": 0.009978098126635495,
            "ave_precision_score": 0.8294397313826252,
            "fpr": 0.10537870472008781,
            "logloss": 1.3890712481063512,
            "mae": 0.2757920766532234,
            "precision": 0.7808219178082192,
            "recall": 0.6993865030674846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8609531399548972,
            "auditor_fn_violation": 0.006826542161856254,
            "auditor_fp_violation": 0.022800639742533074,
            "ave_precision_score": 0.8560692371614036,
            "fpr": 0.1699561403508772,
            "logloss": 1.096977187998963,
            "mae": 0.2589774590866317,
            "precision": 0.714548802946593,
            "recall": 0.8344086021505376
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8659051380538172,
            "auditor_fn_violation": 0.0056052024899041295,
            "auditor_fp_violation": 0.012683317639591928,
            "ave_precision_score": 0.8593937290712244,
            "fpr": 0.14928649835345773,
            "logloss": 1.1395825250166973,
            "mae": 0.25050192696376933,
            "precision": 0.7453183520599251,
            "recall": 0.8139059304703476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 871,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8381707752788072,
            "auditor_fn_violation": 0.01039662327862668,
            "auditor_fp_violation": 0.01905736096393109,
            "ave_precision_score": 0.8385992110200937,
            "fpr": 0.12938596491228072,
            "logloss": 0.6259850226586848,
            "mae": 0.27391056525038615,
            "precision": 0.7526205450733753,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8441192568431094,
            "auditor_fn_violation": 0.007225929841810729,
            "auditor_fp_violation": 0.013775810135208951,
            "ave_precision_score": 0.844392184976809,
            "fpr": 0.10537870472008781,
            "logloss": 0.8027549902980098,
            "mae": 0.2735989528848702,
            "precision": 0.7913043478260869,
            "recall": 0.7443762781186094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8350948038133942,
            "auditor_fn_violation": 0.010967270326353522,
            "auditor_fp_violation": 0.021341104438949734,
            "ave_precision_score": 0.835361568528699,
            "fpr": 0.11403508771929824,
            "logloss": 0.813123062661055,
            "mae": 0.2636994192608293,
            "precision": 0.7688888888888888,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8361167004376865,
            "auditor_fn_violation": 0.009791707353208572,
            "auditor_fp_violation": 0.005150321765051685,
            "ave_precision_score": 0.8364219503106631,
            "fpr": 0.10098792535675083,
            "logloss": 0.8614053530110093,
            "mae": 0.26238562587387076,
            "precision": 0.7964601769911505,
            "recall": 0.7361963190184049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 871,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6696316108107805,
            "auditor_fn_violation": 0.007930107526881728,
            "auditor_fp_violation": 0.0032379606734958214,
            "ave_precision_score": 0.6637549045569613,
            "fpr": 0.029605263157894735,
            "logloss": 8.632110342578859,
            "mae": 0.4267896070214927,
            "precision": 0.8085106382978723,
            "recall": 0.24516129032258063
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7153730763295791,
            "auditor_fn_violation": 0.0030439145279575665,
            "auditor_fp_violation": 0.0035584041285811646,
            "ave_precision_score": 0.7034115311988691,
            "fpr": 0.02305159165751921,
            "logloss": 8.975239688921857,
            "mae": 0.437955029383438,
            "precision": 0.8478260869565217,
            "recall": 0.2392638036809816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 871,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8264906008521726,
            "auditor_fn_violation": 0.004661856253537071,
            "auditor_fp_violation": 0.01675644648534087,
            "ave_precision_score": 0.8267488914435894,
            "fpr": 0.14473684210526316,
            "logloss": 0.6448579500616101,
            "mae": 0.2846404814112616,
            "precision": 0.7333333333333333,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8295364753017616,
            "auditor_fn_violation": 0.003885705050069702,
            "auditor_fp_violation": 0.010487927957923434,
            "ave_precision_score": 0.830072806860751,
            "fpr": 0.12184412733260154,
            "logloss": 0.6523220963165809,
            "mae": 0.2760481441034417,
            "precision": 0.7716049382716049,
            "recall": 0.7668711656441718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 871,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8672142064290437,
            "auditor_fn_violation": 0.012759385021694021,
            "auditor_fp_violation": 0.016415479414419724,
            "ave_precision_score": 0.8641979433393767,
            "fpr": 0.13048245614035087,
            "logloss": 0.7952508755781041,
            "mae": 0.24334210310331128,
            "precision": 0.7600806451612904,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8793681262902581,
            "auditor_fn_violation": 0.008330359006821872,
            "auditor_fp_violation": 0.015809927115143507,
            "ave_precision_score": 0.8729327626268757,
            "fpr": 0.11745334796926454,
            "logloss": 0.8729679324674829,
            "mae": 0.2313195684008622,
            "precision": 0.7893700787401575,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8232638509343992,
            "auditor_fn_violation": 0.008177702320316924,
            "auditor_fp_violation": 0.028972389026256925,
            "ave_precision_score": 0.823678542022685,
            "fpr": 0.13596491228070176,
            "logloss": 0.930037146498212,
            "mae": 0.26908763992518214,
            "precision": 0.7422037422037422,
            "recall": 0.7677419354838709
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8191527686404418,
            "auditor_fn_violation": 0.007989153248525742,
            "auditor_fp_violation": 0.014774660416915952,
            "ave_precision_score": 0.8194791700903882,
            "fpr": 0.1163556531284303,
            "logloss": 1.0994885267725991,
            "mae": 0.2698812653743339,
            "precision": 0.771551724137931,
            "recall": 0.7321063394683026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 871,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8159532379074586,
            "auditor_fn_violation": 0.011389360498019242,
            "auditor_fp_violation": 0.00825679971741434,
            "ave_precision_score": 0.8163812622788169,
            "fpr": 0.06578947368421052,
            "logloss": 1.187068152561503,
            "mae": 0.3061755086202309,
            "precision": 0.8076923076923077,
            "recall": 0.5419354838709678
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8175515661118303,
            "auditor_fn_violation": 0.01255951458991333,
            "auditor_fp_violation": 0.008459013323206106,
            "ave_precision_score": 0.8178775043251565,
            "fpr": 0.06147091108671789,
            "logloss": 1.3358367591918345,
            "mae": 0.3129988576632919,
            "precision": 0.8323353293413174,
            "recall": 0.5685071574642127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8620903814698686,
            "auditor_fn_violation": 0.006508205998868139,
            "auditor_fp_violation": 0.025673103340005495,
            "ave_precision_score": 0.8572034096673276,
            "fpr": 0.18201754385964913,
            "logloss": 1.0186961835862853,
            "mae": 0.2615569263398162,
            "precision": 0.7035714285714286,
            "recall": 0.8473118279569892
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8712640288522611,
            "auditor_fn_violation": 0.0061619066218609655,
            "auditor_fp_violation": 0.02203713434016055,
            "ave_precision_score": 0.8647795252744253,
            "fpr": 0.15587266739846323,
            "logloss": 1.0359551787007018,
            "mae": 0.24876896910611082,
            "precision": 0.7404021937842779,
            "recall": 0.8282208588957055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 871,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8498640311849307,
            "auditor_fn_violation": 0.014110545180154692,
            "auditor_fp_violation": 0.013452254798069,
            "ave_precision_score": 0.8500900398496171,
            "fpr": 0.13486842105263158,
            "logloss": 0.8267422157619809,
            "mae": 0.2465174218550969,
            "precision": 0.7535070140280561,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8436042894552762,
            "auditor_fn_violation": 0.01841837662381392,
            "auditor_fp_violation": 0.01832265985506266,
            "ave_precision_score": 0.8438863173744935,
            "fpr": 0.11964873765093303,
            "logloss": 0.8850902052158948,
            "mae": 0.2497535320453211,
            "precision": 0.7789046653144016,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 871,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8742519665126197,
            "auditor_fn_violation": 0.009932088285229207,
            "auditor_fp_violation": 0.011134169315907218,
            "ave_precision_score": 0.8623055357153387,
            "fpr": 0.09539473684210527,
            "logloss": 1.1827591895010265,
            "mae": 0.2373335897668472,
            "precision": 0.8058035714285714,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8776285098208056,
            "auditor_fn_violation": 0.014276767255022126,
            "auditor_fp_violation": 0.008929825565364867,
            "ave_precision_score": 0.8663269421926637,
            "fpr": 0.07793633369923161,
            "logloss": 1.1991988053288576,
            "mae": 0.23456438164360208,
            "precision": 0.8386363636363636,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 871,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8518939282666778,
            "auditor_fn_violation": 0.012521222410865873,
            "auditor_fp_violation": 0.011090015306723185,
            "ave_precision_score": 0.8521232094292259,
            "fpr": 0.08881578947368421,
            "logloss": 0.8761360031582044,
            "mae": 0.24570872455468715,
            "precision": 0.8076009501187649,
            "recall": 0.7311827956989247
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8455661049588604,
            "auditor_fn_violation": 0.016420527118001082,
            "auditor_fp_violation": 0.011054983586600842,
            "ave_precision_score": 0.8458919212611349,
            "fpr": 0.08122941822173436,
            "logloss": 1.0251322278995214,
            "mae": 0.2563187104237412,
            "precision": 0.8225419664268585,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 871,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.834701114480428,
            "auditor_fn_violation": 0.01123372948500283,
            "auditor_fp_violation": 0.02467227913183406,
            "ave_precision_score": 0.8350082952915046,
            "fpr": 0.11951754385964912,
            "logloss": 0.8012596222386406,
            "mae": 0.2689090710399589,
            "precision": 0.7583148558758315,
            "recall": 0.7354838709677419
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8367093249867834,
            "auditor_fn_violation": 0.01035514580934231,
            "auditor_fp_violation": 0.008048028051045411,
            "ave_precision_score": 0.8370119007441273,
            "fpr": 0.10318331503841932,
            "logloss": 0.8645271222299395,
            "mae": 0.266494946571192,
            "precision": 0.7934065934065934,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 871,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6668452034483001,
            "auditor_fn_violation": 0.014725995095265045,
            "auditor_fp_violation": 0.02701489461909808,
            "ave_precision_score": 0.6622557752019435,
            "fpr": 0.2138157894736842,
            "logloss": 1.7791794707708009,
            "mae": 0.32672001795624417,
            "precision": 0.6655231560891939,
            "recall": 0.8344086021505376
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7144381748691107,
            "auditor_fn_violation": 0.014267788156119593,
            "auditor_fp_violation": 0.028467233028649327,
            "ave_precision_score": 0.7081106650127659,
            "fpr": 0.18660812294182216,
            "logloss": 1.402552594269368,
            "mae": 0.30913933371373475,
            "precision": 0.7033158813263525,
            "recall": 0.8241308793456033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8009822560564366,
            "auditor_fn_violation": 0.010141954348236183,
            "auditor_fp_violation": 0.0196289100828133,
            "ave_precision_score": 0.7984697869002183,
            "fpr": 0.11732456140350878,
            "logloss": 1.2820124996492472,
            "mae": 0.2802161859779208,
            "precision": 0.759009009009009,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.791012787076496,
            "auditor_fn_violation": 0.015677506683816754,
            "auditor_fp_violation": 0.008979247844928493,
            "ave_precision_score": 0.7868894522884807,
            "fpr": 0.10537870472008781,
            "logloss": 1.451111019334536,
            "mae": 0.280699785513355,
            "precision": 0.782312925170068,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 871,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8642302781833772,
            "auditor_fn_violation": 0.008948783248443693,
            "auditor_fp_violation": 0.013925683896542251,
            "ave_precision_score": 0.859316594639322,
            "fpr": 0.12938596491228072,
            "logloss": 1.0082834850556366,
            "mae": 0.24289680106755646,
            "precision": 0.7606490872210954,
            "recall": 0.8064516129032258
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8742083536322833,
            "auditor_fn_violation": 0.01233054756789883,
            "auditor_fp_violation": 0.015482179366458402,
            "ave_precision_score": 0.8676542933947068,
            "fpr": 0.10976948408342481,
            "logloss": 1.0759990396570471,
            "mae": 0.23412808910647062,
            "precision": 0.7950819672131147,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8247306074652693,
            "auditor_fn_violation": 0.005100452744765142,
            "auditor_fp_violation": 0.016712292476156836,
            "ave_precision_score": 0.8249884636193444,
            "fpr": 0.1513157894736842,
            "logloss": 0.6665699687947102,
            "mae": 0.2852709576407205,
            "precision": 0.7261904761904762,
            "recall": 0.7870967741935484
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8280298653178001,
            "auditor_fn_violation": 0.004740964220535652,
            "auditor_fp_violation": 0.009192543998834679,
            "ave_precision_score": 0.8285157812692991,
            "fpr": 0.12733260153677278,
            "logloss": 0.6732514234967822,
            "mae": 0.2771791030181613,
            "precision": 0.7627811860940695,
            "recall": 0.7627811860940695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 871,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8019233720764147,
            "auditor_fn_violation": 0.009981607243916243,
            "auditor_fp_violation": 0.01970985909965069,
            "ave_precision_score": 0.8022573317783674,
            "fpr": 0.14912280701754385,
            "logloss": 0.9880157695572712,
            "mae": 0.2900668927527912,
            "precision": 0.7195876288659794,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7973159027708416,
            "auditor_fn_violation": 0.012243001353599164,
            "auditor_fp_violation": 0.00933820966491695,
            "ave_precision_score": 0.7979222434857604,
            "fpr": 0.13391877058177826,
            "logloss": 1.0469245336817148,
            "mae": 0.291619930498945,
            "precision": 0.7453027139874739,
            "recall": 0.7300613496932515
        }
    }
]