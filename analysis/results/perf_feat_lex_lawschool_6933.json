[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.8683404981942597,
            "auditor_fn_violation": 0.01144462719298246,
            "auditor_fp_violation": 0.012198464912280707,
            "ave_precision_score": 0.868616502304376,
            "fpr": 0.09868421052631579,
            "logloss": 0.48770974211529716,
            "mae": 0.2776194915191777,
            "precision": 0.8105263157894737,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8580601553884981,
            "auditor_fn_violation": 0.010768525337298005,
            "auditor_fp_violation": 0.02178057657865851,
            "ave_precision_score": 0.8583407312499483,
            "fpr": 0.12733260153677278,
            "logloss": 0.5092469331311276,
            "mae": 0.28235638578969047,
            "precision": 0.7622950819672131,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.866307548340723,
            "auditor_fn_violation": 0.01332236842105263,
            "auditor_fp_violation": 0.01184819688109162,
            "ave_precision_score": 0.8666000797369302,
            "fpr": 0.125,
            "logloss": 0.49975595470624323,
            "mae": 0.2788131820960412,
            "precision": 0.77734375,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8561121930830351,
            "auditor_fn_violation": 0.013832344481651824,
            "auditor_fp_violation": 0.013998749080021203,
            "ave_precision_score": 0.8568266835403634,
            "fpr": 0.14050493962678376,
            "logloss": 0.49864096634263066,
            "mae": 0.2777433505850734,
            "precision": 0.7543186180422264,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8293950107067187,
            "auditor_fn_violation": 0.012643914473684213,
            "auditor_fp_violation": 0.018153021442495126,
            "ave_precision_score": 0.8297272510491762,
            "fpr": 0.125,
            "logloss": 0.6956537175902661,
            "mae": 0.26851194729408107,
            "precision": 0.7668711656441718,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7968519420527099,
            "auditor_fn_violation": 0.011393794550431439,
            "auditor_fp_violation": 0.026296950317376996,
            "ave_precision_score": 0.7982315621548224,
            "fpr": 0.15367727771679474,
            "logloss": 0.8332334921605526,
            "mae": 0.29514496841576254,
            "precision": 0.7233201581027668,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8690289573758982,
            "auditor_fn_violation": 0.014254385964912283,
            "auditor_fp_violation": 0.014041179337231976,
            "ave_precision_score": 0.8693332041779287,
            "fpr": 0.1118421052631579,
            "logloss": 0.4966485973509083,
            "mae": 0.27616274896896803,
            "precision": 0.7901234567901234,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8607432985135379,
            "auditor_fn_violation": 0.01571046793295262,
            "auditor_fp_violation": 0.02386795509749891,
            "ave_precision_score": 0.860993535995504,
            "fpr": 0.12733260153677278,
            "logloss": 0.5112675704223627,
            "mae": 0.27894255643724297,
            "precision": 0.7603305785123967,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8541247143354707,
            "auditor_fn_violation": 0.012575383771929825,
            "auditor_fp_violation": 0.008672941033138405,
            "ave_precision_score": 0.8543458704923057,
            "fpr": 0.09320175438596491,
            "logloss": 0.529428657250951,
            "mae": 0.30295065631001133,
            "precision": 0.7976190476190477,
            "recall": 0.6979166666666666
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8519526118980265,
            "auditor_fn_violation": 0.003487612722144259,
            "auditor_fp_violation": 0.005835114680224164,
            "ave_precision_score": 0.8523839917851694,
            "fpr": 0.10098792535675083,
            "logloss": 0.5175795522346224,
            "mae": 0.2970284154195637,
            "precision": 0.7870370370370371,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8471931463829827,
            "auditor_fn_violation": 0.026105628654970767,
            "auditor_fp_violation": 0.01224415204678363,
            "ave_precision_score": 0.8474566013967696,
            "fpr": 0.13157894736842105,
            "logloss": 0.5111894521966264,
            "mae": 0.2976107744483702,
            "precision": 0.757085020242915,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8297163920620181,
            "auditor_fn_violation": 0.018389862301824402,
            "auditor_fp_violation": 0.022107121954650387,
            "ave_precision_score": 0.8300764392060533,
            "fpr": 0.15587266739846323,
            "logloss": 0.5336671804964365,
            "mae": 0.3042782433351459,
            "precision": 0.723196881091618,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8794434083349076,
            "auditor_fn_violation": 0.009777046783625737,
            "auditor_fp_violation": 0.012020792722547108,
            "ave_precision_score": 0.8796479610463347,
            "fpr": 0.05701754385964912,
            "logloss": 0.5035397442371246,
            "mae": 0.2813109572915365,
            "precision": 0.8686868686868687,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8616855349168437,
            "auditor_fn_violation": 0.015034250858008311,
            "auditor_fp_violation": 0.014355437106104645,
            "ave_precision_score": 0.8621308887450572,
            "fpr": 0.0801317233809001,
            "logloss": 0.5206590127031877,
            "mae": 0.2854762746242673,
            "precision": 0.8175,
            "recall": 0.689873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8746843408830492,
            "auditor_fn_violation": 0.01419042397660819,
            "auditor_fp_violation": 0.008086622807017545,
            "ave_precision_score": 0.8748954918481597,
            "fpr": 0.05921052631578947,
            "logloss": 0.50550715278819,
            "mae": 0.2873070627677391,
            "precision": 0.8601036269430051,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8559926376665218,
            "auditor_fn_violation": 0.012296961191624182,
            "auditor_fp_violation": 0.011828478273429005,
            "ave_precision_score": 0.8564139348884153,
            "fpr": 0.07903402854006586,
            "logloss": 0.5258453800767917,
            "mae": 0.2899354397134347,
            "precision": 0.817258883248731,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8739451335977365,
            "auditor_fn_violation": 0.01040296052631579,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.8741544811522793,
            "fpr": 0.06140350877192982,
            "logloss": 0.5002948182502862,
            "mae": 0.2852129941991798,
            "precision": 0.8592964824120602,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8559471626218345,
            "auditor_fn_violation": 0.012463699648459755,
            "auditor_fp_violation": 0.01118543507147576,
            "ave_precision_score": 0.8563567314062108,
            "fpr": 0.08122941822173436,
            "logloss": 0.5211591339754589,
            "mae": 0.28843141166234143,
            "precision": 0.8154613466334164,
            "recall": 0.689873417721519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8749181982934758,
            "auditor_fn_violation": 0.02026681286549708,
            "auditor_fp_violation": 0.01630269249512671,
            "ave_precision_score": 0.8751520878303507,
            "fpr": 0.09539473684210527,
            "logloss": 0.4717599028844387,
            "mae": 0.2800000042546328,
            "precision": 0.8120950323974082,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.855603553544763,
            "auditor_fn_violation": 0.021036835304089268,
            "auditor_fp_violation": 0.020552263587427504,
            "ave_precision_score": 0.8561426032159707,
            "fpr": 0.10867178924259056,
            "logloss": 0.4984598222190912,
            "mae": 0.2847978061016007,
            "precision": 0.7889125799573561,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8522299239259352,
            "auditor_fn_violation": 0.015508497807017543,
            "auditor_fp_violation": 0.011939571150097465,
            "ave_precision_score": 0.8525448092877383,
            "fpr": 0.12280701754385964,
            "logloss": 0.5313919979760514,
            "mae": 0.29970636864808303,
            "precision": 0.7632135306553911,
            "recall": 0.7520833333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8485537426474278,
            "auditor_fn_violation": 0.008406397198793927,
            "auditor_fp_violation": 0.005566342716907767,
            "ave_precision_score": 0.8497962711697894,
            "fpr": 0.12184412733260154,
            "logloss": 0.514725852602872,
            "mae": 0.293648317223259,
            "precision": 0.7648305084745762,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8613817083633697,
            "auditor_fn_violation": 0.011033442982456143,
            "auditor_fp_violation": 0.022120187621832366,
            "ave_precision_score": 0.8615870190647171,
            "fpr": 0.13486842105263158,
            "logloss": 0.618962810420341,
            "mae": 0.25413017148405714,
            "precision": 0.7607003891050583,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8311319376416519,
            "auditor_fn_violation": 0.007299439110357701,
            "auditor_fp_violation": 0.01792985302946193,
            "ave_precision_score": 0.8317321943952869,
            "fpr": 0.141602634467618,
            "logloss": 0.7002162285427019,
            "mae": 0.2756029656707849,
            "precision": 0.7435387673956262,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.875314479298933,
            "auditor_fn_violation": 0.00963084795321638,
            "auditor_fp_violation": 0.005649975633528268,
            "ave_precision_score": 0.875504873550218,
            "fpr": 0.06359649122807018,
            "logloss": 0.5117683772832895,
            "mae": 0.27792645627854845,
            "precision": 0.8553615960099751,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.858013265891974,
            "auditor_fn_violation": 0.010949158665536547,
            "auditor_fp_violation": 0.017937388691984822,
            "ave_precision_score": 0.858708007617067,
            "fpr": 0.08562019758507135,
            "logloss": 0.5349695865332202,
            "mae": 0.2831741670270156,
            "precision": 0.8088235294117647,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.856230418321944,
            "auditor_fn_violation": 0.012184758771929828,
            "auditor_fp_violation": 0.007614522417154004,
            "ave_precision_score": 0.8574516459216145,
            "fpr": 0.08442982456140351,
            "logloss": 0.5377048819247232,
            "mae": 0.29960790971445184,
            "precision": 0.8246013667425968,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8574834022220439,
            "auditor_fn_violation": 0.01090747405132766,
            "auditor_fp_violation": 0.008603214713632264,
            "ave_precision_score": 0.8578553907573709,
            "fpr": 0.09879253567508232,
            "logloss": 0.4916196217729416,
            "mae": 0.3031304923165283,
            "precision": 0.8004434589800443,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8863627256282818,
            "auditor_fn_violation": 0.009548611111111112,
            "auditor_fp_violation": 0.012548732943469794,
            "ave_precision_score": 0.8865574357037169,
            "fpr": 0.09978070175438597,
            "logloss": 0.45702057531200485,
            "mae": 0.2773489904071552,
            "precision": 0.8067940552016986,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8720414921160027,
            "auditor_fn_violation": 0.011055686012959287,
            "auditor_fp_violation": 0.009479863453795083,
            "ave_precision_score": 0.8722615490278458,
            "fpr": 0.1163556531284303,
            "logloss": 0.46708928676461625,
            "mae": 0.2798842682977801,
            "precision": 0.7805383022774327,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8607063521305126,
            "auditor_fn_violation": 0.01581688596491228,
            "auditor_fp_violation": 0.01798042560103964,
            "ave_precision_score": 0.8609126923190447,
            "fpr": 0.13706140350877194,
            "logloss": 0.5655349130817464,
            "mae": 0.2606759460625159,
            "precision": 0.7623574144486692,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8348688978433549,
            "auditor_fn_violation": 0.012926862028558595,
            "auditor_fp_violation": 0.020805964225698116,
            "ave_precision_score": 0.8352330307486546,
            "fpr": 0.150384193194292,
            "logloss": 0.6247612448181232,
            "mae": 0.2783274019042903,
            "precision": 0.7350096711798839,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8648106630271994,
            "auditor_fn_violation": 0.012847222222222225,
            "auditor_fp_violation": 0.011310103963612735,
            "ave_precision_score": 0.8650246510739019,
            "fpr": 0.10635964912280702,
            "logloss": 0.5501972822109213,
            "mae": 0.25548699389947105,
            "precision": 0.7974947807933194,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.837323943353886,
            "auditor_fn_violation": 0.010347047571408067,
            "auditor_fp_violation": 0.02290590218207668,
            "ave_precision_score": 0.8381436040389737,
            "fpr": 0.1394072447859495,
            "logloss": 0.6106328840571276,
            "mae": 0.27664637915566687,
            "precision": 0.7413441955193483,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.7594746396228118,
            "auditor_fn_violation": 0.017029879385964914,
            "auditor_fp_violation": 0.011307565789473692,
            "ave_precision_score": 0.7623002210919507,
            "fpr": 0.14802631578947367,
            "logloss": 0.8341517123355091,
            "mae": 0.288603571651164,
            "precision": 0.7452830188679245,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7427214970558929,
            "auditor_fn_violation": 0.009513355287230149,
            "auditor_fp_violation": 0.012456450150336475,
            "ave_precision_score": 0.742627531909285,
            "fpr": 0.16245883644346873,
            "logloss": 0.9001121559633608,
            "mae": 0.2944180455324567,
            "precision": 0.7243947858472998,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.8735108671245082,
            "auditor_fn_violation": 0.013603344298245617,
            "auditor_fp_violation": 0.012670565302144254,
            "ave_precision_score": 0.8737101186236605,
            "fpr": 0.11403508771929824,
            "logloss": 0.4949991340399195,
            "mae": 0.25699977005598684,
            "precision": 0.7932405566600398,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8485129463486185,
            "auditor_fn_violation": 0.011366004807625507,
            "auditor_fp_violation": 0.014187140643093442,
            "ave_precision_score": 0.8498907224109223,
            "fpr": 0.13721185510428102,
            "logloss": 0.533916702041556,
            "mae": 0.2700309129853546,
            "precision": 0.7563352826510721,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7971491228070176,
            "auc_prc": 0.868723859743177,
            "auditor_fn_violation": 0.01144462719298246,
            "auditor_fp_violation": 0.0089546783625731,
            "ave_precision_score": 0.8689995835966119,
            "fpr": 0.09868421052631579,
            "logloss": 0.48648648293879776,
            "mae": 0.2772776907097483,
            "precision": 0.8105263157894737,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8577779082436614,
            "auditor_fn_violation": 0.012477594519862719,
            "auditor_fp_violation": 0.020682881737824253,
            "ave_precision_score": 0.8580691333106246,
            "fpr": 0.12733260153677278,
            "logloss": 0.508587337700461,
            "mae": 0.28220887802072014,
            "precision": 0.7618069815195072,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8596291566620934,
            "auditor_fn_violation": 0.014912280701754389,
            "auditor_fp_violation": 0.015597080084470439,
            "ave_precision_score": 0.859843483878046,
            "fpr": 0.11732456140350878,
            "logloss": 0.5949212927380327,
            "mae": 0.25333900768323636,
            "precision": 0.7855711422845691,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8334039631440848,
            "auditor_fn_violation": 0.011166844984183006,
            "auditor_fp_violation": 0.02080596422569813,
            "ave_precision_score": 0.8339305346799667,
            "fpr": 0.1437980241492865,
            "logloss": 0.6661716095853779,
            "mae": 0.27541278319435425,
            "precision": 0.7405940594059406,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.8447829517053658,
            "auditor_fn_violation": 0.007716557017543862,
            "auditor_fp_violation": 0.019828216374269014,
            "ave_precision_score": 0.845046911033728,
            "fpr": 0.28728070175438597,
            "logloss": 0.6941305133945708,
            "mae": 0.33513070647237136,
            "precision": 0.6304654442877292,
            "recall": 0.93125
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.8246113863093707,
            "auditor_fn_violation": 0.01338307697295595,
            "auditor_fp_violation": 0.021366115139899573,
            "ave_precision_score": 0.8261707612009443,
            "fpr": 0.2864983534577388,
            "logloss": 0.7067386406393619,
            "mae": 0.33334007317304576,
            "precision": 0.6271428571428571,
            "recall": 0.9261603375527426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8759074146119314,
            "auditor_fn_violation": 0.008931834795321638,
            "auditor_fp_violation": 0.011853273229369726,
            "ave_precision_score": 0.8760943457442283,
            "fpr": 0.11074561403508772,
            "logloss": 0.48734303219497627,
            "mae": 0.2674243165018739,
            "precision": 0.7908902691511387,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8576940434367619,
            "auditor_fn_violation": 0.0100112548458364,
            "auditor_fp_violation": 0.02171777939096776,
            "ave_precision_score": 0.8583925050653909,
            "fpr": 0.12403951701427003,
            "logloss": 0.518638696636746,
            "mae": 0.278493753449611,
            "precision": 0.7674897119341564,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8653871247517106,
            "auditor_fn_violation": 0.017166940789473686,
            "auditor_fp_violation": 0.01407163742690059,
            "ave_precision_score": 0.8655912553262217,
            "fpr": 0.09868421052631579,
            "logloss": 0.5678504814367804,
            "mae": 0.25502841221914385,
            "precision": 0.8064516129032258,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8364712230341065,
            "auditor_fn_violation": 0.010337784323806087,
            "auditor_fp_violation": 0.018140851580102837,
            "ave_precision_score": 0.8370437121035166,
            "fpr": 0.12403951701427003,
            "logloss": 0.6437791592052904,
            "mae": 0.27754849919808816,
            "precision": 0.7600849256900213,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8691815936336873,
            "auditor_fn_violation": 0.013815789473684214,
            "auditor_fp_violation": 0.013675682261208582,
            "ave_precision_score": 0.8695438457665267,
            "fpr": 0.10307017543859649,
            "logloss": 0.47978706321984493,
            "mae": 0.275651280882078,
            "precision": 0.803347280334728,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.860009535450192,
            "auditor_fn_violation": 0.016090261084633663,
            "auditor_fp_violation": 0.02029605106164926,
            "ave_precision_score": 0.8602777374772944,
            "fpr": 0.12294182217343579,
            "logloss": 0.5007913354596922,
            "mae": 0.27904664380794053,
            "precision": 0.7700205338809035,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8532499371634683,
            "auditor_fn_violation": 0.01295230263157895,
            "auditor_fp_violation": 0.015350877192982457,
            "ave_precision_score": 0.8537226191074785,
            "fpr": 0.14035087719298245,
            "logloss": 0.5330551795963776,
            "mae": 0.295555439872882,
            "precision": 0.7552581261950286,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8539387845563756,
            "auditor_fn_violation": 0.008906612569300676,
            "auditor_fp_violation": 0.02037140768687816,
            "ave_precision_score": 0.8546370813187655,
            "fpr": 0.1437980241492865,
            "logloss": 0.5194112863453563,
            "mae": 0.28989297667961655,
            "precision": 0.744140625,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8404329393971789,
            "auditor_fn_violation": 0.01290433114035089,
            "auditor_fp_violation": 0.01141416910331384,
            "ave_precision_score": 0.8407615027823097,
            "fpr": 0.0756578947368421,
            "logloss": 1.2484684536224167,
            "mae": 0.3001684350722972,
            "precision": 0.8283582089552238,
            "recall": 0.69375
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8227313307080142,
            "auditor_fn_violation": 0.016569634148035972,
            "auditor_fp_violation": 0.011562218197620239,
            "ave_precision_score": 0.8230289081813913,
            "fpr": 0.09001097694840834,
            "logloss": 1.52156807200589,
            "mae": 0.3117314393669093,
            "precision": 0.8024096385542169,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8698130596018736,
            "auditor_fn_violation": 0.010750182748538012,
            "auditor_fp_violation": 0.011553768680961668,
            "ave_precision_score": 0.8700475921303108,
            "fpr": 0.11951754385964912,
            "logloss": 0.5195649886414009,
            "mae": 0.26020255681165955,
            "precision": 0.782,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8465796936960421,
            "auditor_fn_violation": 0.011442426600341817,
            "auditor_fp_violation": 0.011476814022360825,
            "ave_precision_score": 0.8473872339358931,
            "fpr": 0.1350164654226125,
            "logloss": 0.561461744885268,
            "mae": 0.2758001146292923,
            "precision": 0.7530120481927711,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.834270255008901,
            "auditor_fn_violation": 0.01074104532163743,
            "auditor_fp_violation": 0.006203297595841455,
            "ave_precision_score": 0.8336346487848338,
            "fpr": 0.1074561403508772,
            "logloss": 1.1154945334716622,
            "mae": 0.25610227897534127,
            "precision": 0.7936842105263158,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8108196672946689,
            "auditor_fn_violation": 0.008123868146933638,
            "auditor_fp_violation": 0.016766849113429308,
            "ave_precision_score": 0.8086146215722896,
            "fpr": 0.12952799121844127,
            "logloss": 1.2328171470196678,
            "mae": 0.27517948598063946,
            "precision": 0.756701030927835,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8258383194894627,
            "auditor_fn_violation": 0.010946637426900585,
            "auditor_fp_violation": 0.009502923976608188,
            "ave_precision_score": 0.8270872368981615,
            "fpr": 0.09210526315789473,
            "logloss": 0.5515429986612715,
            "mae": 0.27776533420576,
            "precision": 0.8125,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8334280257996055,
            "auditor_fn_violation": 0.012790229126429435,
            "auditor_fp_violation": 0.0217881122411814,
            "ave_precision_score": 0.8349645356892686,
            "fpr": 0.1119648737650933,
            "logloss": 0.5388895573804605,
            "mae": 0.28019594778860685,
            "precision": 0.7796976241900648,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8773018327244436,
            "auditor_fn_violation": 0.00717288011695907,
            "auditor_fp_violation": 0.009685672514619883,
            "ave_precision_score": 0.8775529875536904,
            "fpr": 0.07894736842105263,
            "logloss": 0.4751750618032782,
            "mae": 0.26583578118726636,
            "precision": 0.8352402745995423,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8656909977349663,
            "auditor_fn_violation": 0.011032527893954345,
            "auditor_fp_violation": 0.00672934663294039,
            "ave_precision_score": 0.8659965359286478,
            "fpr": 0.09440175631174534,
            "logloss": 0.49203115489830446,
            "mae": 0.2678157673037174,
            "precision": 0.8067415730337079,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8714375269884481,
            "auditor_fn_violation": 0.011330409356725149,
            "auditor_fp_violation": 0.012901539148797924,
            "ave_precision_score": 0.8716129235029166,
            "fpr": 0.09758771929824561,
            "logloss": 0.4824712117411655,
            "mae": 0.2876037167397475,
            "precision": 0.8061002178649237,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8547461223480423,
            "auditor_fn_violation": 0.013158443218608012,
            "auditor_fp_violation": 0.021112414501628957,
            "ave_precision_score": 0.854987867917272,
            "fpr": 0.12403951701427003,
            "logloss": 0.5056659775287651,
            "mae": 0.2938348011478667,
            "precision": 0.7670103092783506,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8478267168364508,
            "auditor_fn_violation": 0.028819444444444446,
            "auditor_fp_violation": 0.015107212475633527,
            "ave_precision_score": 0.8480984594281242,
            "fpr": 0.12280701754385964,
            "logloss": 0.5001766531167322,
            "mae": 0.2852382451406141,
            "precision": 0.7718940936863544,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8378292814925387,
            "auditor_fn_violation": 0.013943503452875544,
            "auditor_fp_violation": 0.022069443642035936,
            "ave_precision_score": 0.8381121003859334,
            "fpr": 0.15148188803512624,
            "logloss": 0.5365225643463174,
            "mae": 0.2981938397886005,
            "precision": 0.7309941520467836,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.874585222433661,
            "auditor_fn_violation": 0.01419042397660819,
            "auditor_fp_violation": 0.008170382553606241,
            "ave_precision_score": 0.874796779937091,
            "fpr": 0.0581140350877193,
            "logloss": 0.5054576439126672,
            "mae": 0.2873207869064604,
            "precision": 0.8623376623376623,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8559603389195105,
            "auditor_fn_violation": 0.012296961191624182,
            "auditor_fp_violation": 0.011828478273429005,
            "ave_precision_score": 0.8563802598103296,
            "fpr": 0.07903402854006586,
            "logloss": 0.5258140688397177,
            "mae": 0.28996024648632096,
            "precision": 0.817258883248731,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8502178275017227,
            "auditor_fn_violation": 0.01085526315789474,
            "auditor_fp_violation": 0.0064190423976608225,
            "ave_precision_score": 0.8506420571875394,
            "fpr": 0.12390350877192982,
            "logloss": 0.5314474448728743,
            "mae": 0.2992387344417071,
            "precision": 0.7655601659751037,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8523805999414149,
            "auditor_fn_violation": 0.006887224592069739,
            "auditor_fp_violation": 0.011773216748261145,
            "ave_precision_score": 0.8536012867955671,
            "fpr": 0.1163556531284303,
            "logloss": 0.5110322792973606,
            "mae": 0.2920263354707786,
            "precision": 0.7730192719486081,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8736542403958665,
            "auditor_fn_violation": 0.008538925438596493,
            "auditor_fp_violation": 0.01602095516569201,
            "ave_precision_score": 0.8738502753348989,
            "fpr": 0.09649122807017543,
            "logloss": 0.48578872231161396,
            "mae": 0.2686214099177736,
            "precision": 0.8061674008810573,
            "recall": 0.7625
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.860890527573029,
            "auditor_fn_violation": 0.010849578753815306,
            "auditor_fp_violation": 0.015166776771069089,
            "ave_precision_score": 0.8611462562257631,
            "fpr": 0.10318331503841932,
            "logloss": 0.515429980767429,
            "mae": 0.2755808918823132,
            "precision": 0.7934065934065934,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 6933,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8257176599873555,
            "auditor_fn_violation": 0.010868969298245617,
            "auditor_fp_violation": 0.012411671539961025,
            "ave_precision_score": 0.826537845853679,
            "fpr": 0.1611842105263158,
            "logloss": 0.5506320751266017,
            "mae": 0.31945017701537726,
            "precision": 0.7307692307692307,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8334773611427326,
            "auditor_fn_violation": 0.0020934939580467536,
            "auditor_fp_violation": 0.020489466399736755,
            "ave_precision_score": 0.8338022392765939,
            "fpr": 0.15916575192096596,
            "logloss": 0.5419609328872823,
            "mae": 0.3086780098417179,
            "precision": 0.7284644194756554,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8469012468694759,
            "auditor_fn_violation": 0.01351425438596491,
            "auditor_fp_violation": 0.01056895711500975,
            "ave_precision_score": 0.8473753045980805,
            "fpr": 0.12390350877192982,
            "logloss": 0.528938881663412,
            "mae": 0.3067519723272039,
            "precision": 0.7631027253668763,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8489445703851558,
            "auditor_fn_violation": 0.010773156961098995,
            "auditor_fp_violation": 0.013252718490255137,
            "ave_precision_score": 0.8501665595506411,
            "fpr": 0.1141602634467618,
            "logloss": 0.5159757421715141,
            "mae": 0.2996728986042149,
            "precision": 0.7734204793028322,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8728850188708726,
            "auditor_fn_violation": 0.01047149122807018,
            "auditor_fp_violation": 0.012421824236517222,
            "ave_precision_score": 0.8730938479241399,
            "fpr": 0.06359649122807018,
            "logloss": 0.507242722120824,
            "mae": 0.28516084113199897,
            "precision": 0.853904282115869,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8565301302810652,
            "auditor_fn_violation": 0.00985609544850329,
            "auditor_fp_violation": 0.011554682535097349,
            "ave_precision_score": 0.8569923618978472,
            "fpr": 0.07574094401756312,
            "logloss": 0.5239048311593306,
            "mae": 0.2885119023523396,
            "precision": 0.827930174563591,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8599534824033727,
            "auditor_fn_violation": 0.015933388157894742,
            "auditor_fp_violation": 0.012665488953866152,
            "ave_precision_score": 0.8602299985137281,
            "fpr": 0.11074561403508772,
            "logloss": 0.5602535905597152,
            "mae": 0.25596995230764724,
            "precision": 0.7963709677419355,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8485887718665879,
            "auditor_fn_violation": 0.010518417652044634,
            "auditor_fp_violation": 0.024784794037783824,
            "ave_precision_score": 0.8489987678427011,
            "fpr": 0.15148188803512624,
            "logloss": 0.6148461580918282,
            "mae": 0.27655052822652454,
            "precision": 0.7315175097276264,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.847005267938892,
            "auditor_fn_violation": 0.009715369152046786,
            "auditor_fp_violation": 0.007721125730994151,
            "ave_precision_score": 0.8472623829291359,
            "fpr": 0.10855263157894737,
            "logloss": 0.614696738356438,
            "mae": 0.27307389230850976,
            "precision": 0.7875536480686696,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8150748139929188,
            "auditor_fn_violation": 0.007883023709282242,
            "auditor_fp_violation": 0.018575408118922807,
            "ave_precision_score": 0.8155228742603701,
            "fpr": 0.13062568605927552,
            "logloss": 0.720740073779618,
            "mae": 0.2897185826036225,
            "precision": 0.750524109014675,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8797459788613926,
            "auditor_fn_violation": 0.00709292763157895,
            "auditor_fp_violation": 0.007228719948018195,
            "ave_precision_score": 0.8799426343131918,
            "fpr": 0.0581140350877193,
            "logloss": 0.5008595896389515,
            "mae": 0.2715355865460113,
            "precision": 0.8668341708542714,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8628721407928206,
            "auditor_fn_violation": 0.009045561283330323,
            "auditor_fp_violation": 0.013564192541201236,
            "ave_precision_score": 0.8635643015603566,
            "fpr": 0.07683863885839737,
            "logloss": 0.5207339771967093,
            "mae": 0.2745738218335567,
            "precision": 0.8317307692307693,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8688124956897543,
            "auditor_fn_violation": 0.01288605628654971,
            "auditor_fp_violation": 0.009015594541910331,
            "ave_precision_score": 0.8689002395274426,
            "fpr": 0.07675438596491228,
            "logloss": 1.267275016771176,
            "mae": 0.26814122203458934,
            "precision": 0.8321342925659473,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8482010694297436,
            "auditor_fn_violation": 0.007711653628645671,
            "auditor_fp_violation": 0.0067569773955243224,
            "ave_precision_score": 0.848597461001551,
            "fpr": 0.09001097694840834,
            "logloss": 1.5644872906495189,
            "mae": 0.28026595959597556,
            "precision": 0.8056872037914692,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8512282389921277,
            "auditor_fn_violation": 0.011513157894736841,
            "auditor_fp_violation": 0.010609567901234572,
            "ave_precision_score": 0.851695649812191,
            "fpr": 0.1206140350877193,
            "logloss": 0.5332520727014181,
            "mae": 0.297131896126773,
            "precision": 0.7736625514403292,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8528764946163427,
            "auditor_fn_violation": 0.009362827513698026,
            "auditor_fp_violation": 0.011788288073306926,
            "ave_precision_score": 0.8540941070957433,
            "fpr": 0.1251372118551043,
            "logloss": 0.5140435131072649,
            "mae": 0.2904337843698834,
            "precision": 0.762993762993763,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8663512474807502,
            "auditor_fn_violation": 0.0027115314327485407,
            "auditor_fp_violation": 0.02042214912280702,
            "ave_precision_score": 0.8665636114973003,
            "fpr": 0.13815789473684212,
            "logloss": 0.5693156527751779,
            "mae": 0.24952801378277686,
            "precision": 0.7618147448015122,
            "recall": 0.8395833333333333
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8426610343568242,
            "auditor_fn_violation": 0.01002051809343838,
            "auditor_fp_violation": 0.013152242989949936,
            "ave_precision_score": 0.8430590680945533,
            "fpr": 0.14928649835345773,
            "logloss": 0.6373251140625084,
            "mae": 0.27035002569960864,
            "precision": 0.7389635316698656,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.866797651312482,
            "auditor_fn_violation": 0.01600877192982456,
            "auditor_fp_violation": 0.010409052144249515,
            "ave_precision_score": 0.866992562211615,
            "fpr": 0.11293859649122807,
            "logloss": 0.5601309397166091,
            "mae": 0.2544106755650406,
            "precision": 0.7919191919191919,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8405611389663386,
            "auditor_fn_violation": 0.011379899679028471,
            "auditor_fp_violation": 0.02341330345861791,
            "ave_precision_score": 0.8411922431203549,
            "fpr": 0.14818880351262348,
            "logloss": 0.6244162661047806,
            "mae": 0.2756223095685197,
            "precision": 0.733201581027668,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8503843481578759,
            "auditor_fn_violation": 0.010492050438596493,
            "auditor_fp_violation": 0.007543453541260564,
            "ave_precision_score": 0.8506545562637802,
            "fpr": 0.06359649122807018,
            "logloss": 0.5653096135638394,
            "mae": 0.3349522925079024,
            "precision": 0.833810888252149,
            "recall": 0.60625
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8356202234788785,
            "auditor_fn_violation": 0.008415660446395913,
            "auditor_fp_violation": 0.007985290386755321,
            "ave_precision_score": 0.8361637926479722,
            "fpr": 0.06915477497255763,
            "logloss": 0.5457297030723832,
            "mae": 0.3212294837355263,
            "precision": 0.8315508021390374,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.845923888869496,
            "auditor_fn_violation": 0.006875913742690068,
            "auditor_fp_violation": 0.011604532163742699,
            "ave_precision_score": 0.8462285592431713,
            "fpr": 0.12171052631578948,
            "logloss": 0.5364226775754484,
            "mae": 0.3092597388590787,
            "precision": 0.7618025751072961,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8489876684963822,
            "auditor_fn_violation": 0.007299439110357708,
            "auditor_fp_violation": 0.012926173114263256,
            "ave_precision_score": 0.8495248416845853,
            "fpr": 0.11525795828759605,
            "logloss": 0.5198208364864004,
            "mae": 0.30059058728827737,
            "precision": 0.7692307692307693,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.859443765406376,
            "auditor_fn_violation": 0.006853070175438601,
            "auditor_fp_violation": 0.004492568226120857,
            "ave_precision_score": 0.859426865800547,
            "fpr": 0.08552631578947369,
            "logloss": 1.5613980574714414,
            "mae": 0.253961856741991,
            "precision": 0.821917808219178,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8551433880786008,
            "auditor_fn_violation": 0.009309563839986665,
            "auditor_fp_violation": 0.006925273858535519,
            "ave_precision_score": 0.8553900277339875,
            "fpr": 0.09989023051591657,
            "logloss": 1.252176665701206,
            "mae": 0.2538792692785195,
            "precision": 0.796875,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8736424706568136,
            "auditor_fn_violation": 0.01088267543859649,
            "auditor_fp_violation": 0.008974983755685511,
            "ave_precision_score": 0.8738247565823963,
            "fpr": 0.11403508771929824,
            "logloss": 0.4908585087061408,
            "mae": 0.27050450337098975,
            "precision": 0.7855670103092783,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8534820017767858,
            "auditor_fn_violation": 0.010407258680820914,
            "auditor_fp_violation": 0.02270243929395867,
            "ave_precision_score": 0.8541778460038122,
            "fpr": 0.12733260153677278,
            "logloss": 0.5291099337761526,
            "mae": 0.2823920401322331,
            "precision": 0.7627811860940695,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8771409936423147,
            "auditor_fn_violation": 0.010348135964912283,
            "auditor_fp_violation": 0.011589303118908384,
            "ave_precision_score": 0.8773080754645132,
            "fpr": 0.08552631578947369,
            "logloss": 0.49893372198401864,
            "mae": 0.2697051546394441,
            "precision": 0.8194444444444444,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.863515401041691,
            "auditor_fn_violation": 0.01524267392905279,
            "auditor_fp_violation": 0.015136634120977533,
            "ave_precision_score": 0.8637293034487998,
            "fpr": 0.10098792535675083,
            "logloss": 0.5247573045582933,
            "mae": 0.27807888944465775,
            "precision": 0.7964601769911505,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8572885640623563,
            "auditor_fn_violation": 0.01527320906432749,
            "auditor_fp_violation": 0.012492893112410662,
            "ave_precision_score": 0.8575081756185047,
            "fpr": 0.09978070175438597,
            "logloss": 0.6348312191204807,
            "mae": 0.2599516636718589,
            "precision": 0.7986725663716814,
            "recall": 0.7520833333333333
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8302503368469034,
            "auditor_fn_violation": 0.008994613421519455,
            "auditor_fp_violation": 0.017005478426654144,
            "ave_precision_score": 0.8305937294199992,
            "fpr": 0.12403951701427003,
            "logloss": 0.7294758229254842,
            "mae": 0.28267366505388924,
            "precision": 0.7590618336886994,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.854274058306773,
            "auditor_fn_violation": 0.012616502192982462,
            "auditor_fp_violation": 0.011127355425601044,
            "ave_precision_score": 0.854475056194321,
            "fpr": 0.14035087719298245,
            "logloss": 0.5644589503555549,
            "mae": 0.27860228835559836,
            "precision": 0.7533718689788054,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8263734097255885,
            "auditor_fn_violation": 0.012005168892161902,
            "auditor_fp_violation": 0.021908682841547632,
            "ave_precision_score": 0.8267034550205459,
            "fpr": 0.16136114160263446,
            "logloss": 0.6361768100672851,
            "mae": 0.2951177320271921,
            "precision": 0.7215909090909091,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8148242649827204,
            "auditor_fn_violation": 0.015627284356725148,
            "auditor_fp_violation": 0.00961460363872645,
            "ave_precision_score": 0.8153159785535158,
            "fpr": 0.10087719298245613,
            "logloss": 0.5896768104496563,
            "mae": 0.3323978051055172,
            "precision": 0.7750611246943765,
            "recall": 0.6604166666666667
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8144524764206647,
            "auditor_fn_violation": 0.012482226143663707,
            "auditor_fp_violation": 0.014596578306837112,
            "ave_precision_score": 0.8157271003416329,
            "fpr": 0.11306256860592755,
            "logloss": 0.599519950812709,
            "mae": 0.33272854684232034,
            "precision": 0.7524038461538461,
            "recall": 0.6603375527426161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.840110511428048,
            "auditor_fn_violation": 0.018030427631578954,
            "auditor_fp_violation": 0.014843242365172189,
            "ave_precision_score": 0.8403483486003052,
            "fpr": 0.11732456140350878,
            "logloss": 0.6434819749742166,
            "mae": 0.26982039372512845,
            "precision": 0.7761506276150628,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8138168225695616,
            "auditor_fn_violation": 0.010754630465895037,
            "auditor_fp_violation": 0.025593621815240625,
            "ave_precision_score": 0.8143460785360517,
            "fpr": 0.15148188803512624,
            "logloss": 0.7230935877152977,
            "mae": 0.2954645369697786,
            "precision": 0.7200811359026369,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8558567507944801,
            "auditor_fn_violation": 0.018800255847953216,
            "auditor_fp_violation": 0.013980263157894746,
            "ave_precision_score": 0.8560750446902711,
            "fpr": 0.1118421052631579,
            "logloss": 0.6242842213419088,
            "mae": 0.25461030090812814,
            "precision": 0.7892561983471075,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8264513554656133,
            "auditor_fn_violation": 0.011254845836401791,
            "auditor_fp_violation": 0.021557018590479447,
            "ave_precision_score": 0.8270972174551688,
            "fpr": 0.14818880351262348,
            "logloss": 0.7154679384809562,
            "mae": 0.2787543200098958,
            "precision": 0.7321428571428571,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8742429924906318,
            "auditor_fn_violation": 0.012534265350877195,
            "auditor_fp_violation": 0.012020792722547111,
            "ave_precision_score": 0.874417783123046,
            "fpr": 0.1162280701754386,
            "logloss": 0.5309403293919573,
            "mae": 0.2600053973776978,
            "precision": 0.7805383022774327,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8475608417357424,
            "auditor_fn_violation": 0.008795453598076949,
            "auditor_fp_violation": 0.013129636002381272,
            "ave_precision_score": 0.8480167678444789,
            "fpr": 0.13172338090010977,
            "logloss": 0.5925718140529396,
            "mae": 0.2793265910437868,
            "precision": 0.7535934291581109,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8605043391697469,
            "auditor_fn_violation": 0.01980994152046784,
            "auditor_fp_violation": 0.013091902209226772,
            "ave_precision_score": 0.8607884527763366,
            "fpr": 0.07785087719298246,
            "logloss": 1.0396699942438787,
            "mae": 0.2835418778196067,
            "precision": 0.8289156626506025,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8431142631411557,
            "auditor_fn_violation": 0.002834553766204892,
            "auditor_fp_violation": 0.009901860555076906,
            "ave_precision_score": 0.8433918722661997,
            "fpr": 0.09220636663007684,
            "logloss": 1.1807009114356388,
            "mae": 0.29468111421012516,
            "precision": 0.7980769230769231,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8767964872013221,
            "auditor_fn_violation": 0.015302905701754386,
            "auditor_fp_violation": 0.01507675438596492,
            "ave_precision_score": 0.8769745826142454,
            "fpr": 0.10855263157894737,
            "logloss": 0.4935141789003582,
            "mae": 0.255519161913438,
            "precision": 0.7979591836734694,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8530726832739827,
            "auditor_fn_violation": 0.010212730481179398,
            "auditor_fp_violation": 0.013511442903541011,
            "ave_precision_score": 0.8538035188299409,
            "fpr": 0.12294182217343579,
            "logloss": 0.5381432711477733,
            "mae": 0.2680516890952983,
            "precision": 0.7718940936863544,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 6933,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7890550060888454,
            "auditor_fn_violation": 0.01736111111111112,
            "auditor_fp_violation": 0.020021117608836913,
            "ave_precision_score": 0.7895090402454584,
            "fpr": 0.14035087719298245,
            "logloss": 0.5694048918447813,
            "mae": 0.3471932746241484,
            "precision": 0.7480314960629921,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7595105105038564,
            "auditor_fn_violation": 0.011157581736581027,
            "auditor_fp_violation": 0.024541140949543714,
            "ave_precision_score": 0.760210517022985,
            "fpr": 0.15916575192096596,
            "logloss": 0.602335515638604,
            "mae": 0.3539101927713455,
            "precision": 0.7162426614481409,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8531793971439341,
            "auditor_fn_violation": 0.014551352339181289,
            "auditor_fp_violation": 0.009312560916179343,
            "ave_precision_score": 0.8536411694642452,
            "fpr": 0.11513157894736842,
            "logloss": 0.5275121268998422,
            "mae": 0.29759920375297216,
            "precision": 0.777542372881356,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8465405145965809,
            "auditor_fn_violation": 0.00996957023162751,
            "auditor_fp_violation": 0.008387192387976103,
            "ave_precision_score": 0.8477822469720193,
            "fpr": 0.11964873765093303,
            "logloss": 0.5189457571244448,
            "mae": 0.2938205083436096,
            "precision": 0.7680851063829788,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8378678390957426,
            "auditor_fn_violation": 0.01625548245614035,
            "auditor_fp_violation": 0.01755147417153996,
            "ave_precision_score": 0.8385965272951905,
            "fpr": 0.12390350877192982,
            "logloss": 0.5290634967464125,
            "mae": 0.31208426994884286,
            "precision": 0.7655601659751037,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8455283134930112,
            "auditor_fn_violation": 0.014916144451083108,
            "auditor_fp_violation": 0.01773643769137443,
            "ave_precision_score": 0.8458051713666923,
            "fpr": 0.12294182217343579,
            "logloss": 0.5168413493278163,
            "mae": 0.2982372171748808,
            "precision": 0.7728194726166329,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8744570321003593,
            "auditor_fn_violation": 0.008858735380116967,
            "auditor_fp_violation": 0.01665296052631579,
            "ave_precision_score": 0.8746494484731865,
            "fpr": 0.08881578947368421,
            "logloss": 0.4866794493942896,
            "mae": 0.2683226874853477,
            "precision": 0.8171557562076749,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8619663113474672,
            "auditor_fn_violation": 0.013598447479701911,
            "auditor_fp_violation": 0.01374504844175059,
            "ave_precision_score": 0.8622149633802325,
            "fpr": 0.10428100987925357,
            "logloss": 0.5166053660034564,
            "mae": 0.27587952320398784,
            "precision": 0.7907488986784141,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8531560277119067,
            "auditor_fn_violation": 0.012915752923976613,
            "auditor_fp_violation": 0.014751868096166342,
            "ave_precision_score": 0.8535348463359628,
            "fpr": 0.12938596491228072,
            "logloss": 0.5325221375005569,
            "mae": 0.29552419371338257,
            "precision": 0.764,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8573737400727174,
            "auditor_fn_violation": 0.008549977536624565,
            "auditor_fp_violation": 0.012079667024192,
            "ave_precision_score": 0.8575992271542988,
            "fpr": 0.12843029637760703,
            "logloss": 0.5108964546056866,
            "mae": 0.289160591760681,
            "precision": 0.7582644628099173,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.868334259600609,
            "auditor_fn_violation": 0.009059758771929828,
            "auditor_fp_violation": 0.012815241228070174,
            "ave_precision_score": 0.8685529154447195,
            "fpr": 0.10855263157894737,
            "logloss": 0.5264546296835041,
            "mae": 0.2600784377425857,
            "precision": 0.79375,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8403224003693925,
            "auditor_fn_violation": 0.0049975220812664735,
            "auditor_fp_violation": 0.016591016987895214,
            "ave_precision_score": 0.8406840848730535,
            "fpr": 0.12403951701427003,
            "logloss": 0.5888715049871653,
            "mae": 0.2792786054832515,
            "precision": 0.7616033755274262,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8777169157560833,
            "auditor_fn_violation": 0.008826754385964914,
            "auditor_fp_violation": 0.012383751624431453,
            "ave_precision_score": 0.8779003393513631,
            "fpr": 0.11293859649122807,
            "logloss": 0.47951299120399216,
            "mae": 0.2684595110742457,
            "precision": 0.7893660531697342,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8601802274074268,
            "auditor_fn_violation": 0.00914745700695207,
            "auditor_fp_violation": 0.019411866658963554,
            "ave_precision_score": 0.8608744256407341,
            "fpr": 0.12623490669593854,
            "logloss": 0.5081177410244241,
            "mae": 0.2784524635745583,
            "precision": 0.7657841140529531,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8554444958525071,
            "auditor_fn_violation": 0.011931195175438598,
            "auditor_fp_violation": 0.004629629629629632,
            "ave_precision_score": 0.8556905540946317,
            "fpr": 0.09429824561403509,
            "logloss": 0.5074984458182934,
            "mae": 0.30642595154661156,
            "precision": 0.8084632516703786,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8565153237478023,
            "auditor_fn_violation": 0.009592092891846952,
            "auditor_fp_violation": 0.005892888092899649,
            "ave_precision_score": 0.8572254148864896,
            "fpr": 0.10098792535675083,
            "logloss": 0.48920419894788836,
            "mae": 0.29458170959906926,
            "precision": 0.7973568281938326,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.869975571950598,
            "auditor_fn_violation": 0.010263614766081869,
            "auditor_fp_violation": 0.012472587719298251,
            "ave_precision_score": 0.8703042490779348,
            "fpr": 0.10855263157894737,
            "logloss": 0.4840733305169045,
            "mae": 0.2726659657854358,
            "precision": 0.7946058091286307,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.859906465061052,
            "auditor_fn_violation": 0.015464991871500236,
            "auditor_fp_violation": 0.02065776286274796,
            "ave_precision_score": 0.8601493601330039,
            "fpr": 0.1207464324917673,
            "logloss": 0.5102623317857334,
            "mae": 0.2764583012649102,
            "precision": 0.7698744769874477,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8649424451847356,
            "auditor_fn_violation": 0.021683114035087724,
            "auditor_fp_violation": 0.01589150828460039,
            "ave_precision_score": 0.8652588016962361,
            "fpr": 0.11293859649122807,
            "logloss": 0.4976366481593785,
            "mae": 0.27972507146376047,
            "precision": 0.790224032586558,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8565980351611279,
            "auditor_fn_violation": 0.016673845683558206,
            "auditor_fp_violation": 0.019972017573165007,
            "ave_precision_score": 0.8568438275547816,
            "fpr": 0.13172338090010977,
            "logloss": 0.5194317239636895,
            "mae": 0.2848522528633756,
            "precision": 0.7556008146639511,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8512253007132025,
            "auditor_fn_violation": 0.011513157894736841,
            "auditor_fp_violation": 0.010609567901234572,
            "ave_precision_score": 0.8516927095045619,
            "fpr": 0.1206140350877193,
            "logloss": 0.5332478751554544,
            "mae": 0.2971390784326487,
            "precision": 0.7736625514403292,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8528721553585119,
            "auditor_fn_violation": 0.009362827513698026,
            "auditor_fp_violation": 0.011788288073306926,
            "ave_precision_score": 0.8540897591123209,
            "fpr": 0.1251372118551043,
            "logloss": 0.5140751844479223,
            "mae": 0.29044311481245866,
            "precision": 0.762993762993763,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8116370292829722,
            "auditor_fn_violation": 0.0067251461988304196,
            "auditor_fp_violation": 0.004477339181286554,
            "ave_precision_score": 0.8119324093454078,
            "fpr": 0.05701754385964912,
            "logloss": 0.6296906674854847,
            "mae": 0.35819456092819263,
            "precision": 0.8311688311688312,
            "recall": 0.5333333333333333
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.822618925209147,
            "auditor_fn_violation": 0.014881407272575694,
            "auditor_fp_violation": 0.011275863021750434,
            "ave_precision_score": 0.8230777415145127,
            "fpr": 0.06147091108671789,
            "logloss": 0.6100639727650996,
            "mae": 0.3444813162624435,
            "precision": 0.8276923076923077,
            "recall": 0.5675105485232067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.874771024740643,
            "auditor_fn_violation": 0.01193576388888889,
            "auditor_fp_violation": 0.011002984892787525,
            "ave_precision_score": 0.8749475764792379,
            "fpr": 0.09539473684210527,
            "logloss": 0.49573797310022366,
            "mae": 0.2703875009381016,
            "precision": 0.8075221238938053,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8561918011981693,
            "auditor_fn_violation": 0.016298684155678145,
            "auditor_fp_violation": 0.021757969591089832,
            "ave_precision_score": 0.8564627346540469,
            "fpr": 0.12294182217343579,
            "logloss": 0.5416574227095067,
            "mae": 0.28514045667164967,
            "precision": 0.7656903765690377,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8732936803376457,
            "auditor_fn_violation": 0.010117415935672518,
            "auditor_fp_violation": 0.008771929824561401,
            "ave_precision_score": 0.873467358955073,
            "fpr": 0.08881578947368421,
            "logloss": 0.5039089313160781,
            "mae": 0.27810330427146573,
            "precision": 0.8133640552995391,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8594965081659112,
            "auditor_fn_violation": 0.012574858619683481,
            "auditor_fp_violation": 0.016987895214100737,
            "ave_precision_score": 0.8596971412508567,
            "fpr": 0.09659714599341383,
            "logloss": 0.530122386920033,
            "mae": 0.28697404534194076,
            "precision": 0.8018018018018018,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8761354532962523,
            "auditor_fn_violation": 0.01039610745614035,
            "auditor_fp_violation": 0.00825414230019493,
            "ave_precision_score": 0.8763108524100907,
            "fpr": 0.10964912280701754,
            "logloss": 0.4845863008216367,
            "mae": 0.2695402264520485,
            "precision": 0.7920997920997921,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8556074251233365,
            "auditor_fn_violation": 0.009976517667328995,
            "auditor_fp_violation": 0.022639642106267913,
            "ave_precision_score": 0.8563084314459517,
            "fpr": 0.12952799121844127,
            "logloss": 0.5237212557756102,
            "mae": 0.28154144517241125,
            "precision": 0.7601626016260162,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.866965283907004,
            "auditor_fn_violation": 0.015382858187134509,
            "auditor_fp_violation": 0.01489400584795322,
            "ave_precision_score": 0.8672327287580771,
            "fpr": 0.09868421052631579,
            "logloss": 0.4763863923590279,
            "mae": 0.27165203862118925,
            "precision": 0.8060344827586207,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8581229456309261,
            "auditor_fn_violation": 0.010768525337298005,
            "auditor_fp_violation": 0.018650764744151702,
            "ave_precision_score": 0.8583783086656289,
            "fpr": 0.12184412733260154,
            "logloss": 0.504971045565405,
            "mae": 0.28073239157553437,
            "precision": 0.7716049382716049,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8744827569648453,
            "auditor_fn_violation": 0.006414473684210527,
            "auditor_fp_violation": 0.01078216374269006,
            "ave_precision_score": 0.8746625215446442,
            "fpr": 0.09210526315789473,
            "logloss": 0.5299007866304253,
            "mae": 0.25039391407967304,
            "precision": 0.8173913043478261,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8535939518105193,
            "auditor_fn_violation": 0.0121302227347886,
            "auditor_fp_violation": 0.00975617107963437,
            "ave_precision_score": 0.8539783805142322,
            "fpr": 0.11745334796926454,
            "logloss": 0.5782560118849089,
            "mae": 0.2650071500403369,
            "precision": 0.773784355179704,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8734343082907433,
            "auditor_fn_violation": 0.01089638157894737,
            "auditor_fp_violation": 0.013624918778427553,
            "ave_precision_score": 0.8736093003635322,
            "fpr": 0.07456140350877193,
            "logloss": 0.5124672009047984,
            "mae": 0.2746152147189142,
            "precision": 0.8353510895883777,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8612116838317757,
            "auditor_fn_violation": 0.008677347191151749,
            "auditor_fp_violation": 0.014026379842605132,
            "ave_precision_score": 0.8614168370070676,
            "fpr": 0.09879253567508232,
            "logloss": 0.5356811637754012,
            "mae": 0.2826150644567682,
            "precision": 0.7949886104783599,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.877175252925793,
            "auditor_fn_violation": 0.009299616228070176,
            "auditor_fp_violation": 0.012437053281351529,
            "ave_precision_score": 0.8773718174994157,
            "fpr": 0.09978070175438597,
            "logloss": 0.4905345768415399,
            "mae": 0.2602554002165689,
            "precision": 0.8072033898305084,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8547780405935945,
            "auditor_fn_violation": 0.008851033083688814,
            "auditor_fp_violation": 0.01771131881629813,
            "ave_precision_score": 0.8554872924098502,
            "fpr": 0.11964873765093303,
            "logloss": 0.5389142692166667,
            "mae": 0.27312412012102244,
            "precision": 0.7743271221532091,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 6933,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8525269696817466,
            "auditor_fn_violation": 0.008486385233918136,
            "auditor_fp_violation": 0.004007776965562058,
            "ave_precision_score": 0.8527636220096033,
            "fpr": 0.07346491228070176,
            "logloss": 0.5115512691043249,
            "mae": 0.3152414183155327,
            "precision": 0.8290816326530612,
            "recall": 0.6770833333333334
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8514548823495174,
            "auditor_fn_violation": 0.007781127985660495,
            "auditor_fp_violation": 0.005960709055605653,
            "ave_precision_score": 0.852180004355545,
            "fpr": 0.08781558726673985,
            "logloss": 0.49927371327308784,
            "mae": 0.3057977794976261,
            "precision": 0.8076923076923077,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 6933,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8730111765932831,
            "auditor_fn_violation": 0.01361019736842105,
            "auditor_fp_violation": 0.012827932098765439,
            "ave_precision_score": 0.8731954251437848,
            "fpr": 0.12390350877192982,
            "logloss": 0.49557323734265635,
            "mae": 0.2710822203161865,
            "precision": 0.7717171717171717,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8539624807350344,
            "auditor_fn_violation": 0.011931062911346092,
            "auditor_fp_violation": 0.02096170125117117,
            "ave_precision_score": 0.8546642060448999,
            "fpr": 0.13062568605927552,
            "logloss": 0.5298378491080719,
            "mae": 0.2818034431070568,
            "precision": 0.7586206896551724,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8735826741065205,
            "auditor_fn_violation": 0.009356725146198834,
            "auditor_fp_violation": 0.01669864766081872,
            "ave_precision_score": 0.873777963010602,
            "fpr": 0.09100877192982457,
            "logloss": 0.48797747233478933,
            "mae": 0.2689148668381549,
            "precision": 0.814317673378076,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8616665830635183,
            "auditor_fn_violation": 0.013598447479701911,
            "auditor_fp_violation": 0.015558631222259341,
            "ave_precision_score": 0.8619053951901585,
            "fpr": 0.10428100987925357,
            "logloss": 0.5163530428790892,
            "mae": 0.27590266199143293,
            "precision": 0.7907488986784141,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8731401428270387,
            "auditor_fn_violation": 0.004708059210526317,
            "auditor_fp_violation": 0.01603872238466538,
            "ave_precision_score": 0.8733516233759091,
            "fpr": 0.26206140350877194,
            "logloss": 0.734807083148839,
            "mae": 0.3077392609700103,
            "precision": 0.6575931232091691,
            "recall": 0.95625
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8543640471677754,
            "auditor_fn_violation": 0.0052383665189178665,
            "auditor_fp_violation": 0.026852077456563206,
            "ave_precision_score": 0.8550790648548985,
            "fpr": 0.2678375411635565,
            "logloss": 0.7830568763303422,
            "mae": 0.31613934942460836,
            "precision": 0.6484149855907781,
            "recall": 0.9493670886075949
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 6933,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7894604938746197,
            "auditor_fn_violation": 0.0225671600877193,
            "auditor_fp_violation": 0.023566946881091618,
            "ave_precision_score": 0.7884157562897522,
            "fpr": 0.11513157894736842,
            "logloss": 1.1714150033674142,
            "mae": 0.27786200139846284,
            "precision": 0.7697368421052632,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7567622121672958,
            "auditor_fn_violation": 0.014610457280217882,
            "auditor_fp_violation": 0.023119412620225224,
            "ave_precision_score": 0.7561813992309848,
            "fpr": 0.13611416026344675,
            "logloss": 1.2857140484680192,
            "mae": 0.3013267570794178,
            "precision": 0.7310195227765727,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8654771543925925,
            "auditor_fn_violation": 0.012963724415204684,
            "auditor_fp_violation": 0.007807423651721895,
            "ave_precision_score": 0.8656716651376376,
            "fpr": 0.10307017543859649,
            "logloss": 0.581410515510355,
            "mae": 0.2517571127293343,
            "precision": 0.8037578288100209,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8385606276944835,
            "auditor_fn_violation": 0.008943665559708585,
            "auditor_fp_violation": 0.017475201390580924,
            "ave_precision_score": 0.8390558159098715,
            "fpr": 0.13172338090010977,
            "logloss": 0.6639398156177198,
            "mae": 0.27310621229581533,
            "precision": 0.7556008146639511,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8288609037582602,
            "auditor_fn_violation": 0.008771929824561401,
            "auditor_fp_violation": 0.0041423001949317745,
            "ave_precision_score": 0.8096550240867648,
            "fpr": 0.1337719298245614,
            "logloss": 1.3717950230414038,
            "mae": 0.27827407437348084,
            "precision": 0.769811320754717,
            "recall": 0.85
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8144202090768202,
            "auditor_fn_violation": 0.011657797107087775,
            "auditor_fp_violation": 0.01369229880409036,
            "ave_precision_score": 0.7920049215138913,
            "fpr": 0.15148188803512624,
            "logloss": 1.5715807023269819,
            "mae": 0.2810381768208966,
            "precision": 0.7444444444444445,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7960526315789473,
            "auc_prc": 0.8846865585681489,
            "auditor_fn_violation": 0.0025082236842105285,
            "auditor_fp_violation": 0.004637244152046785,
            "ave_precision_score": 0.88484372448967,
            "fpr": 0.09758771929824561,
            "logloss": 0.5050237674492027,
            "mae": 0.2508946120231469,
            "precision": 0.8114406779661016,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8608247182969169,
            "auditor_fn_violation": 0.011727271464102608,
            "auditor_fp_violation": 0.018030328529767128,
            "ave_precision_score": 0.8610463498101198,
            "fpr": 0.12952799121844127,
            "logloss": 0.5688537034139364,
            "mae": 0.26906764466824284,
            "precision": 0.757201646090535,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.852131885149735,
            "auditor_fn_violation": 0.01988304093567252,
            "auditor_fp_violation": 0.014269615009746592,
            "ave_precision_score": 0.8525465865152577,
            "fpr": 0.125,
            "logloss": 0.5316361060072125,
            "mae": 0.29604090053897125,
            "precision": 0.7673469387755102,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8527478219032916,
            "auditor_fn_violation": 0.01247064708416124,
            "auditor_fp_violation": 0.013511442903541011,
            "ave_precision_score": 0.8539663718579339,
            "fpr": 0.12294182217343579,
            "logloss": 0.512815946152212,
            "mae": 0.28972754738678785,
            "precision": 0.7671517671517671,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8536545225420964,
            "auditor_fn_violation": 0.01373355263157895,
            "auditor_fp_violation": 0.014894005847953225,
            "ave_precision_score": 0.8538824451540532,
            "fpr": 0.12171052631578948,
            "logloss": 0.6481098610329661,
            "mae": 0.2589646175772342,
            "precision": 0.7730061349693251,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8230429512621144,
            "auditor_fn_violation": 0.008151657889739568,
            "auditor_fp_violation": 0.018535217918800726,
            "ave_precision_score": 0.823428433416703,
            "fpr": 0.1350164654226125,
            "logloss": 0.7540866211337369,
            "mae": 0.2820404496329361,
            "precision": 0.7458677685950413,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8734010475089917,
            "auditor_fn_violation": 0.006903326023391819,
            "auditor_fp_violation": 0.013282265269655622,
            "ave_precision_score": 0.8735989613142132,
            "fpr": 0.0581140350877193,
            "logloss": 0.5114728270264546,
            "mae": 0.2858108625040857,
            "precision": 0.8619791666666666,
            "recall": 0.6895833333333333
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8554854375206409,
            "auditor_fn_violation": 0.013195496209015924,
            "auditor_fp_violation": 0.012072131361669102,
            "ave_precision_score": 0.8559606404272893,
            "fpr": 0.07683863885839737,
            "logloss": 0.5321865730409552,
            "mae": 0.28861138735768516,
            "precision": 0.821882951653944,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8749590559719682,
            "auditor_fn_violation": 0.009909539473684212,
            "auditor_fp_violation": 0.013010680636777131,
            "ave_precision_score": 0.8751698184073828,
            "fpr": 0.06359649122807018,
            "logloss": 0.49903413727592616,
            "mae": 0.28688762763149017,
            "precision": 0.855,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8569837937447027,
            "auditor_fn_violation": 0.009314195463787653,
            "auditor_fp_violation": 0.009733564092065702,
            "ave_precision_score": 0.857396112135708,
            "fpr": 0.08122941822173436,
            "logloss": 0.5162960471361331,
            "mae": 0.28917707166604856,
            "precision": 0.8177339901477833,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8601129883758835,
            "auditor_fn_violation": 0.008863304093567252,
            "auditor_fp_violation": 0.018508365821962313,
            "ave_precision_score": 0.8600784528591484,
            "fpr": 0.07346491228070176,
            "logloss": 1.5053899771660135,
            "mae": 0.2852883876090947,
            "precision": 0.830379746835443,
            "recall": 0.6833333333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8452038161534363,
            "auditor_fn_violation": 0.007971024561501023,
            "auditor_fp_violation": 0.0131070290148126,
            "ave_precision_score": 0.8451947532668564,
            "fpr": 0.07903402854006586,
            "logloss": 1.8458493877195847,
            "mae": 0.291745645540095,
            "precision": 0.817258883248731,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 6933,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8281462127162909,
            "auditor_fn_violation": 0.04732044956140351,
            "auditor_fp_violation": 0.03862085769980507,
            "ave_precision_score": 0.8284626875605402,
            "fpr": 0.13157894736842105,
            "logloss": 0.741040491950657,
            "mae": 0.29969936466087704,
            "precision": 0.7473684210526316,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.825509142911598,
            "auditor_fn_violation": 0.032203680288272266,
            "auditor_fp_violation": 0.039584835232738945,
            "ave_precision_score": 0.8268107133523834,
            "fpr": 0.1437980241492865,
            "logloss": 0.7280314164762833,
            "mae": 0.2908802558336484,
            "precision": 0.7374749498997996,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.873914594959375,
            "auditor_fn_violation": 0.008527503654970762,
            "auditor_fp_violation": 0.012982760721247565,
            "ave_precision_score": 0.8741203500853794,
            "fpr": 0.0625,
            "logloss": 0.4999317187877386,
            "mae": 0.28598924220045374,
            "precision": 0.8575,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8556067669133578,
            "auditor_fn_violation": 0.011203897974590912,
            "auditor_fp_violation": 0.01118543507147576,
            "ave_precision_score": 0.8560300741721134,
            "fpr": 0.08122941822173436,
            "logloss": 0.5198984372351221,
            "mae": 0.2889064625536861,
            "precision": 0.8163771712158809,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8586193558690267,
            "auditor_fn_violation": 0.017982456140350878,
            "auditor_fp_violation": 0.013320337881741388,
            "ave_precision_score": 0.8588325721970633,
            "fpr": 0.11403508771929824,
            "logloss": 0.6202836382309432,
            "mae": 0.2540768143511404,
            "precision": 0.7868852459016393,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8306480419310063,
            "auditor_fn_violation": 0.010495259533039692,
            "auditor_fp_violation": 0.02222015689249373,
            "ave_precision_score": 0.8312172219288516,
            "fpr": 0.14928649835345773,
            "logloss": 0.7067379852385275,
            "mae": 0.2788053590635416,
            "precision": 0.7296222664015904,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8761591165438578,
            "auditor_fn_violation": 0.019444444444444445,
            "auditor_fp_violation": 0.019983044996751142,
            "ave_precision_score": 0.876286738125633,
            "fpr": 0.12390350877192982,
            "logloss": 1.0092021342331978,
            "mae": 0.25910691176528566,
            "precision": 0.777120315581854,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8572734285205338,
            "auditor_fn_violation": 0.014186663702427433,
            "auditor_fp_violation": 0.01842469486846501,
            "ave_precision_score": 0.8574996603571341,
            "fpr": 0.12403951701427003,
            "logloss": 1.1761684963745898,
            "mae": 0.2711501172223521,
            "precision": 0.769857433808554,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8691799918640024,
            "auditor_fn_violation": 0.015837445175438596,
            "auditor_fp_violation": 0.018112410656270304,
            "ave_precision_score": 0.8695434515941174,
            "fpr": 0.10964912280701754,
            "logloss": 0.48143846536024315,
            "mae": 0.2752841897676454,
            "precision": 0.7955010224948875,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8608668950476284,
            "auditor_fn_violation": 0.018396809737525884,
            "auditor_fp_violation": 0.018595503218983848,
            "ave_precision_score": 0.8611415768650822,
            "fpr": 0.12843029637760703,
            "logloss": 0.49997537007462695,
            "mae": 0.27822016585242265,
            "precision": 0.7636363636363637,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8655637748727261,
            "auditor_fn_violation": 0.012963724415204684,
            "auditor_fp_violation": 0.006457115009746588,
            "ave_precision_score": 0.8657574855143644,
            "fpr": 0.10526315789473684,
            "logloss": 0.5818538557190157,
            "mae": 0.2518345026963664,
            "precision": 0.8004158004158004,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8379831810802328,
            "auditor_fn_violation": 0.008943665559708585,
            "auditor_fp_violation": 0.017475201390580924,
            "ave_precision_score": 0.8384793958588521,
            "fpr": 0.13172338090010977,
            "logloss": 0.6650574703493609,
            "mae": 0.2734611599811064,
            "precision": 0.7556008146639511,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 6933,
        "test": {
            "accuracy": 0.8004385964912281,
            "auc_prc": 0.8714909258589633,
            "auditor_fn_violation": 0.01362390350877193,
            "auditor_fp_violation": 0.010038478719948021,
            "ave_precision_score": 0.8717650501177783,
            "fpr": 0.11293859649122807,
            "logloss": 0.4794595631784296,
            "mae": 0.2682484316934725,
            "precision": 0.7956349206349206,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8594842010259521,
            "auditor_fn_violation": 0.010268309966791258,
            "auditor_fp_violation": 0.014277568593368121,
            "ave_precision_score": 0.8597528788230611,
            "fpr": 0.13611416026344675,
            "logloss": 0.5037866624532907,
            "mae": 0.27435537339147903,
            "precision": 0.7578125,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8722914019657464,
            "auditor_fn_violation": 0.012253289473684212,
            "auditor_fp_violation": 0.017838287849252767,
            "ave_precision_score": 0.8726550088811946,
            "fpr": 0.12390350877192982,
            "logloss": 0.48475963302910996,
            "mae": 0.26442453789008014,
            "precision": 0.7805825242718447,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.863754570974571,
            "auditor_fn_violation": 0.00960598776324992,
            "auditor_fp_violation": 0.022915949732107203,
            "ave_precision_score": 0.8640331444471426,
            "fpr": 0.141602634467618,
            "logloss": 0.5130945224536605,
            "mae": 0.273773723743492,
            "precision": 0.7533460803059273,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8444282333335399,
            "auditor_fn_violation": 0.011787280701754383,
            "auditor_fp_violation": 0.011025828460038994,
            "ave_precision_score": 0.8448633244182878,
            "fpr": 0.1206140350877193,
            "logloss": 0.5355581754457329,
            "mae": 0.3070900613105742,
            "precision": 0.7659574468085106,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8479248582031165,
            "auditor_fn_violation": 0.00886492795509178,
            "auditor_fp_violation": 0.01340845551572819,
            "ave_precision_score": 0.849148352500147,
            "fpr": 0.1119648737650933,
            "logloss": 0.5178278837338862,
            "mae": 0.2996728078323834,
            "precision": 0.775330396475771,
            "recall": 0.7426160337552743
        }
    }
]