[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7797534250945812,
            "auditor_fn_violation": 0.04984974009096816,
            "auditor_fp_violation": 0.04336288197018367,
            "ave_precision_score": 0.7724275563028319,
            "fpr": 0.17214912280701755,
            "logloss": 2.1543897998923254,
            "mae": 0.29079458779988376,
            "precision": 0.7103321033210332,
            "recall": 0.7921810699588477
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7922633238819683,
            "auditor_fn_violation": 0.03728409655961797,
            "auditor_fp_violation": 0.0512621012803136,
            "ave_precision_score": 0.7866462858875396,
            "fpr": 0.19758507135016465,
            "logloss": 1.7889765657623384,
            "mae": 0.28958106762019403,
            "precision": 0.6819787985865724,
            "recall": 0.8247863247863247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7877925346613431,
            "auditor_fn_violation": 0.05009340480831708,
            "auditor_fp_violation": 0.04175418005106663,
            "ave_precision_score": 0.7852274190344843,
            "fpr": 0.15679824561403508,
            "logloss": 1.7542814408673546,
            "mae": 0.28581428960695204,
            "precision": 0.7239382239382239,
            "recall": 0.7716049382716049
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7944799561898677,
            "auditor_fn_violation": 0.03518252694981564,
            "auditor_fp_violation": 0.0471488429602575,
            "ave_precision_score": 0.7943178663380458,
            "fpr": 0.18441273326015367,
            "logloss": 1.4671822660522953,
            "mae": 0.28898872653637797,
            "precision": 0.6934306569343066,
            "recall": 0.811965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7880681017730015,
            "auditor_fn_violation": 0.04985650855533896,
            "auditor_fp_violation": 0.032014455151964424,
            "ave_precision_score": 0.7882114315589558,
            "fpr": 0.13815789473684212,
            "logloss": 1.5010977370260314,
            "mae": 0.2866595972512259,
            "precision": 0.7385892116182573,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8193527266547753,
            "auditor_fn_violation": 0.03741544466023061,
            "auditor_fp_violation": 0.039566571599190234,
            "ave_precision_score": 0.8196106922925358,
            "fpr": 0.1668496158068057,
            "logloss": 1.207188187239519,
            "mae": 0.28502290679866865,
            "precision": 0.7076923076923077,
            "recall": 0.7863247863247863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8072111149561971,
            "auditor_fn_violation": 0.009462313190383367,
            "auditor_fp_violation": 0.0198295033358043,
            "ave_precision_score": 0.8077246354932205,
            "fpr": 0.125,
            "logloss": 0.9364088569459218,
            "mae": 0.28090861088976987,
            "precision": 0.759493670886076,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8296419388906124,
            "auditor_fn_violation": 0.007894959047538628,
            "auditor_fp_violation": 0.011487388898662694,
            "ave_precision_score": 0.829885478123372,
            "fpr": 0.1437980241492865,
            "logloss": 0.8776625219513708,
            "mae": 0.2784595598593518,
            "precision": 0.7342799188640974,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7308043818128738,
            "auditor_fn_violation": 0.03526369937188651,
            "auditor_fp_violation": 0.034804587760481016,
            "ave_precision_score": 0.7184929783886654,
            "fpr": 0.1206140350877193,
            "logloss": 2.015524905999185,
            "mae": 0.31705081643765315,
            "precision": 0.7447795823665894,
            "recall": 0.6604938271604939
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.715072667198508,
            "auditor_fn_violation": 0.044095433777102275,
            "auditor_fp_violation": 0.025601316242662427,
            "ave_precision_score": 0.7012081691558987,
            "fpr": 0.13172338090010977,
            "logloss": 2.093555638801137,
            "mae": 0.3077560462760064,
            "precision": 0.7272727272727273,
            "recall": 0.6837606837606838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8070674097908754,
            "auditor_fn_violation": 0.004106201718287492,
            "auditor_fp_violation": 0.01812041841693436,
            "ave_precision_score": 0.807443080097581,
            "fpr": 0.12280701754385964,
            "logloss": 0.9242437917284257,
            "mae": 0.2825500310559642,
            "precision": 0.7606837606837606,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8325041936829641,
            "auditor_fn_violation": 0.002807565650595288,
            "auditor_fp_violation": 0.015248790181701947,
            "ave_precision_score": 0.8327362168515691,
            "fpr": 0.1525795828759605,
            "logloss": 0.8612379007997818,
            "mae": 0.2770325477078955,
            "precision": 0.722,
            "recall": 0.7713675213675214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7907797413914461,
            "auditor_fn_violation": 0.0326465598151758,
            "auditor_fp_violation": 0.03540688575899843,
            "ave_precision_score": 0.7869467007916232,
            "fpr": 0.22149122807017543,
            "logloss": 1.3837358457907625,
            "mae": 0.2962742928165236,
            "precision": 0.6762820512820513,
            "recall": 0.8683127572016461
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8284058787614894,
            "auditor_fn_violation": 0.015135523093810692,
            "auditor_fp_violation": 0.03435314057184202,
            "ave_precision_score": 0.8276412644923173,
            "fpr": 0.22502744237102085,
            "logloss": 1.0973970997801068,
            "mae": 0.27691815396995106,
            "precision": 0.6735668789808917,
            "recall": 0.9038461538461539
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8449205390597925,
            "auditor_fn_violation": 0.01239305826294131,
            "auditor_fp_violation": 0.020699489333662797,
            "ave_precision_score": 0.8454238181779788,
            "fpr": 0.13706140350877194,
            "logloss": 0.6007236729366878,
            "mae": 0.2651850551496864,
            "precision": 0.7614503816793893,
            "recall": 0.8209876543209876
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8565793132327166,
            "auditor_fn_violation": 0.007275746573221873,
            "auditor_fp_violation": 0.011943316326909878,
            "ave_precision_score": 0.8567686789501727,
            "fpr": 0.1712403951701427,
            "logloss": 0.6041726964165618,
            "mae": 0.2758008230377006,
            "precision": 0.711645101663586,
            "recall": 0.8226495726495726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6526326507497902,
            "auditor_fn_violation": 0.010928813804057476,
            "auditor_fp_violation": 0.04641298080882959,
            "ave_precision_score": 0.6158860003201658,
            "fpr": 0.18201754385964913,
            "logloss": 3.8978821667366557,
            "mae": 0.32387305079116546,
            "precision": 0.6867924528301886,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6592574604364815,
            "auditor_fn_violation": 0.00895981686321972,
            "auditor_fp_violation": 0.041752049815027274,
            "ave_precision_score": 0.6252936477523976,
            "fpr": 0.19319429198682767,
            "logloss": 3.4650801874455266,
            "mae": 0.31492274437644474,
            "precision": 0.6782449725776966,
            "recall": 0.7927350427350427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7897995002332585,
            "auditor_fn_violation": 0.011371020142949967,
            "auditor_fp_violation": 0.02691808747220163,
            "ave_precision_score": 0.7903535583712993,
            "fpr": 0.13815789473684212,
            "logloss": 1.087358164729453,
            "mae": 0.27886606325227337,
            "precision": 0.7454545454545455,
            "recall": 0.7592592592592593
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8300278178200075,
            "auditor_fn_violation": 0.007629917344516688,
            "auditor_fp_violation": 0.008588285142960507,
            "ave_precision_score": 0.8302743051654762,
            "fpr": 0.1712403951701427,
            "logloss": 0.9718195325158074,
            "mae": 0.2774954874743717,
            "precision": 0.7051039697542533,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7937940662843206,
            "auditor_fn_violation": 0.011167966211825869,
            "auditor_fp_violation": 0.022887323943661976,
            "ave_precision_score": 0.7905407801643753,
            "fpr": 0.15350877192982457,
            "logloss": 1.229919508582431,
            "mae": 0.2719533275506926,
            "precision": 0.732824427480916,
            "recall": 0.7901234567901234
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8247463247025042,
            "auditor_fn_violation": 0.008629101109891454,
            "auditor_fp_violation": 0.01598719438614575,
            "ave_precision_score": 0.8240408728669616,
            "fpr": 0.1690450054884742,
            "logloss": 0.9959989834876187,
            "mae": 0.27051034480824443,
            "precision": 0.7132216014897579,
            "recall": 0.8183760683760684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8003567124244308,
            "auditor_fn_violation": 0.013888888888888897,
            "auditor_fp_violation": 0.017929948109710898,
            "ave_precision_score": 0.8017364597867246,
            "fpr": 0.09868421052631579,
            "logloss": 1.0206363501187108,
            "mae": 0.2934349324490717,
            "precision": 0.7777777777777778,
            "recall": 0.6481481481481481
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8139408366847127,
            "auditor_fn_violation": 0.015330199742933003,
            "auditor_fp_violation": 0.007559970562946485,
            "ave_precision_score": 0.814246867983174,
            "fpr": 0.10647639956092206,
            "logloss": 0.925146147930672,
            "mae": 0.2859178671781332,
            "precision": 0.7651331719128329,
            "recall": 0.6752136752136753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8077538813114754,
            "auditor_fn_violation": 0.013455707169157463,
            "auditor_fp_violation": 0.018802508030639983,
            "ave_precision_score": 0.8082434313332918,
            "fpr": 0.10416666666666667,
            "logloss": 0.872183164361691,
            "mae": 0.28674503384661426,
            "precision": 0.7835990888382688,
            "recall": 0.7078189300411523
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8361845823418038,
            "auditor_fn_violation": 0.007135016465422614,
            "auditor_fp_violation": 0.01206473178334527,
            "ave_precision_score": 0.8364152709880315,
            "fpr": 0.1119648737650933,
            "logloss": 0.7906120926225739,
            "mae": 0.2742991413828995,
            "precision": 0.7748344370860927,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7387441717171339,
            "auditor_fn_violation": 0.04532163742690061,
            "auditor_fp_violation": 0.033455852071493285,
            "ave_precision_score": 0.7347622090233238,
            "fpr": 0.1162280701754386,
            "logloss": 1.643418562823732,
            "mae": 0.3192378985938827,
            "precision": 0.7427184466019418,
            "recall": 0.6296296296296297
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.731338371556226,
            "auditor_fn_violation": 0.05054087271430851,
            "auditor_fp_violation": 0.037894011740131295,
            "ave_precision_score": 0.724877004987734,
            "fpr": 0.14050493962678376,
            "logloss": 1.6589409003805113,
            "mae": 0.3118410890246257,
            "precision": 0.7117117117117117,
            "recall": 0.6752136752136753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7564474694164796,
            "auditor_fn_violation": 0.04621507472384665,
            "auditor_fp_violation": 0.03589593114241002,
            "ave_precision_score": 0.7570919717149963,
            "fpr": 0.14364035087719298,
            "logloss": 1.6234856015251662,
            "mae": 0.3037656570958535,
            "precision": 0.7276507276507277,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7653321656318667,
            "auditor_fn_violation": 0.03542176813307439,
            "auditor_fp_violation": 0.033644470764892596,
            "ave_precision_score": 0.7656064079498979,
            "fpr": 0.16575192096597147,
            "logloss": 1.3844730774682918,
            "mae": 0.2989213802642121,
            "precision": 0.702755905511811,
            "recall": 0.7628205128205128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7918490416130743,
            "auditor_fn_violation": 0.009529997834091404,
            "auditor_fp_violation": 0.02525018532246109,
            "ave_precision_score": 0.7869667300080857,
            "fpr": 0.2138157894736842,
            "logloss": 1.4001053352014932,
            "mae": 0.27629714627878543,
            "precision": 0.6929133858267716,
            "recall": 0.9053497942386831
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8191393644412364,
            "auditor_fn_violation": 0.012222409862365955,
            "auditor_fp_violation": 0.025460077854564105,
            "ave_precision_score": 0.8173234912534626,
            "fpr": 0.2414928649835346,
            "logloss": 1.2468092924877046,
            "mae": 0.2981514156561811,
            "precision": 0.6578538102643857,
            "recall": 0.9038461538461539
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7821783316887787,
            "auditor_fn_violation": 0.04521334199696773,
            "auditor_fp_violation": 0.029883246849518166,
            "ave_precision_score": 0.7826301601753316,
            "fpr": 0.11074561403508772,
            "logloss": 2.212342290092748,
            "mae": 0.2899037655639765,
            "precision": 0.7709750566893424,
            "recall": 0.6995884773662552
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8010841482323062,
            "auditor_fn_violation": 0.03276196909566833,
            "auditor_fp_violation": 0.03278465110401341,
            "ave_precision_score": 0.8013363916174019,
            "fpr": 0.14489571899012074,
            "logloss": 1.71677326819292,
            "mae": 0.2897086926624567,
            "precision": 0.7215189873417721,
            "recall": 0.7307692307692307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6728403096198796,
            "auditor_fn_violation": 0.10093134069742257,
            "auditor_fp_violation": 0.04284037558685446,
            "ave_precision_score": 0.6680281743503277,
            "fpr": 0.12609649122807018,
            "logloss": 1.725221452326939,
            "mae": 0.39577552683531075,
            "precision": 0.6965699208443272,
            "recall": 0.5432098765432098
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6446753190098241,
            "auditor_fn_violation": 0.10182292399635978,
            "auditor_fp_violation": 0.04865043003372376,
            "ave_precision_score": 0.6372452565932966,
            "fpr": 0.14928649835345773,
            "logloss": 1.8459080729560378,
            "mae": 0.40508645538303895,
            "precision": 0.6530612244897959,
            "recall": 0.5470085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8138344186581493,
            "auditor_fn_violation": 0.024510865641469932,
            "auditor_fp_violation": 0.02412280701754386,
            "ave_precision_score": 0.8143527333549939,
            "fpr": 0.12938596491228072,
            "logloss": 0.960582077113715,
            "mae": 0.27290049993235616,
            "precision": 0.756701030927835,
            "recall": 0.7551440329218106
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8384263485462494,
            "auditor_fn_violation": 0.015473275352528924,
            "auditor_fp_violation": 0.022565929831777656,
            "ave_precision_score": 0.8386592581967524,
            "fpr": 0.1525795828759605,
            "logloss": 0.8897865103055285,
            "mae": 0.26863425673598695,
            "precision": 0.7263779527559056,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8084228742969806,
            "auditor_fn_violation": 0.011533463287849252,
            "auditor_fp_violation": 0.020905403179309782,
            "ave_precision_score": 0.8088796611743536,
            "fpr": 0.12280701754385964,
            "logloss": 0.9689747664876552,
            "mae": 0.27851015865500534,
            "precision": 0.7627118644067796,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8260414107313676,
            "auditor_fn_violation": 0.009733832456115662,
            "auditor_fp_violation": 0.0053224571514942825,
            "ave_precision_score": 0.8262954846275934,
            "fpr": 0.14709110867178923,
            "logloss": 0.9159369158011058,
            "mae": 0.2799262117593826,
            "precision": 0.7276422764227642,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8084228742969806,
            "auditor_fn_violation": 0.011533463287849252,
            "auditor_fp_violation": 0.020905403179309782,
            "ave_precision_score": 0.8088796611743536,
            "fpr": 0.12280701754385964,
            "logloss": 0.9689749146295686,
            "mae": 0.2785101569228262,
            "precision": 0.7627118644067796,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8260414107313676,
            "auditor_fn_violation": 0.009733832456115662,
            "auditor_fp_violation": 0.0053224571514942825,
            "ave_precision_score": 0.8262954846275934,
            "fpr": 0.14709110867178923,
            "logloss": 0.9159370091913324,
            "mae": 0.2799262133457969,
            "precision": 0.7276422764227642,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 12498,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7644029530655634,
            "auditor_fn_violation": 0.061362897985705,
            "auditor_fp_violation": 0.042222634049913534,
            "ave_precision_score": 0.7575367495378089,
            "fpr": 0.17763157894736842,
            "logloss": 2.3233056467262228,
            "mae": 0.3111032076316474,
            "precision": 0.6949152542372882,
            "recall": 0.7592592592592593
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7984928419479034,
            "auditor_fn_violation": 0.04504770750654396,
            "auditor_fp_violation": 0.05148510926152146,
            "ave_precision_score": 0.7975042432002504,
            "fpr": 0.1964873765093304,
            "logloss": 1.7420759331136435,
            "mae": 0.3000307969606897,
            "precision": 0.6786355475763016,
            "recall": 0.8076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7275249312085901,
            "auditor_fn_violation": 0.016941466320121296,
            "auditor_fp_violation": 0.007853039288361752,
            "ave_precision_score": 0.7149066486031002,
            "fpr": 0.08662280701754387,
            "logloss": 2.2544046717198807,
            "mae": 0.3526629262120951,
            "precision": 0.7515723270440252,
            "recall": 0.49176954732510286
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7275867979192561,
            "auditor_fn_violation": 0.006515803991105866,
            "auditor_fp_violation": 0.010610224172578444,
            "ave_precision_score": 0.7120276129956121,
            "fpr": 0.0867178924259056,
            "logloss": 2.16611820658838,
            "mae": 0.3218306134950658,
            "precision": 0.7655786350148368,
            "recall": 0.5512820512820513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8087061876653716,
            "auditor_fn_violation": 0.04163282434481265,
            "auditor_fp_violation": 0.07321009389671362,
            "ave_precision_score": 0.8091432434430788,
            "fpr": 0.2730263157894737,
            "logloss": 0.7162375552844921,
            "mae": 0.3630651674012325,
            "precision": 0.6316568047337278,
            "recall": 0.8786008230452675
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7937122265095741,
            "auditor_fn_violation": 0.034492949421599264,
            "auditor_fp_violation": 0.06877813927096214,
            "ave_precision_score": 0.7940120853682409,
            "fpr": 0.30735455543358947,
            "logloss": 0.7199782320620179,
            "mae": 0.3754467580869485,
            "precision": 0.5965417867435159,
            "recall": 0.8846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7648810640842001,
            "auditor_fn_violation": 0.06286549707602339,
            "auditor_fp_violation": 0.04090993328391401,
            "ave_precision_score": 0.7580040530393988,
            "fpr": 0.17324561403508773,
            "logloss": 2.260642300134242,
            "mae": 0.3089431927977532,
            "precision": 0.699047619047619,
            "recall": 0.7551440329218106
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.799773078425193,
            "auditor_fn_violation": 0.044433186035820506,
            "auditor_fp_violation": 0.050637678932931585,
            "ave_precision_score": 0.798876638414224,
            "fpr": 0.19209659714599342,
            "logloss": 1.6743051460123863,
            "mae": 0.2977521043746208,
            "precision": 0.6823956442831216,
            "recall": 0.8034188034188035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7989220532447412,
            "auditor_fn_violation": 0.015287704858854965,
            "auditor_fp_violation": 0.02240085248332098,
            "ave_precision_score": 0.8002652596270643,
            "fpr": 0.10855263157894737,
            "logloss": 0.948517386259155,
            "mae": 0.29091565816193976,
            "precision": 0.7713625866050808,
            "recall": 0.6872427983539094
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8322373450804466,
            "auditor_fn_violation": 0.0050099918376537555,
            "auditor_fp_violation": 0.012974108773381765,
            "ave_precision_score": 0.8324751112072797,
            "fpr": 0.1251372118551043,
            "logloss": 0.850317196645493,
            "mae": 0.277704061886769,
            "precision": 0.7532467532467533,
            "recall": 0.7435897435897436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7514013677727851,
            "auditor_fn_violation": 0.07051837412461195,
            "auditor_fp_violation": 0.05655938555308461,
            "ave_precision_score": 0.7439599715013655,
            "fpr": 0.21162280701754385,
            "logloss": 2.4880977100076116,
            "mae": 0.3365409976526783,
            "precision": 0.6553571428571429,
            "recall": 0.7551440329218106
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7868832163068507,
            "auditor_fn_violation": 0.05102170058262265,
            "auditor_fp_violation": 0.05978843976182747,
            "ave_precision_score": 0.7834076996125046,
            "fpr": 0.21844127332601537,
            "logloss": 1.9523599191504115,
            "mae": 0.31502290897086066,
            "precision": 0.6580756013745704,
            "recall": 0.8183760683760684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6553300929841215,
            "auditor_fn_violation": 0.004534871128438381,
            "auditor_fp_violation": 0.020671176179886345,
            "ave_precision_score": 0.6173952031876456,
            "fpr": 0.2598684210526316,
            "logloss": 5.120913921301291,
            "mae": 0.34247414933234477,
            "precision": 0.6376146788990825,
            "recall": 0.8580246913580247
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6522081653700247,
            "auditor_fn_violation": 0.008760449210504097,
            "auditor_fp_violation": 0.028755640243524734,
            "ave_precision_score": 0.6157430360061438,
            "fpr": 0.2667398463227223,
            "logloss": 4.8968640022403225,
            "mae": 0.33678908963678045,
            "precision": 0.625,
            "recall": 0.8653846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7830019974039462,
            "auditor_fn_violation": 0.0194751281495921,
            "auditor_fp_violation": 0.009448871592125858,
            "ave_precision_score": 0.7792271194414846,
            "fpr": 0.0712719298245614,
            "logloss": 2.3116486171632435,
            "mae": 0.309577206538135,
            "precision": 0.8121387283236994,
            "recall": 0.5781893004115226
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8087277303358846,
            "auditor_fn_violation": 0.011720472477881926,
            "auditor_fp_violation": 0.008216605174280743,
            "ave_precision_score": 0.8080233208609776,
            "fpr": 0.0801317233809001,
            "logloss": 1.6149666530859448,
            "mae": 0.29008674281264063,
            "precision": 0.7972222222222223,
            "recall": 0.6132478632478633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7935611731450951,
            "auditor_fn_violation": 0.02113114576564869,
            "auditor_fp_violation": 0.0268640350877193,
            "ave_precision_score": 0.7904783250856312,
            "fpr": 0.16337719298245615,
            "logloss": 1.1983327394349592,
            "mae": 0.2692724779056521,
            "precision": 0.7285974499089253,
            "recall": 0.823045267489712
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8295284350528718,
            "auditor_fn_violation": 0.013646129452935163,
            "auditor_fp_violation": 0.02326221030643775,
            "ave_precision_score": 0.8288295877301795,
            "fpr": 0.18441273326015367,
            "logloss": 0.9820986707943016,
            "mae": 0.26835881929227146,
            "precision": 0.7031802120141343,
            "recall": 0.8504273504273504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8327401416785951,
            "auditor_fn_violation": 0.05556232401992637,
            "auditor_fp_violation": 0.016050984268182196,
            "ave_precision_score": 0.8303952979565292,
            "fpr": 0.06359649122807018,
            "logloss": 2.3078511931490904,
            "mae": 0.24632185738732745,
            "precision": 0.8493506493506493,
            "recall": 0.6728395061728395
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8570605796644695,
            "auditor_fn_violation": 0.03949121375026974,
            "auditor_fp_violation": 0.019763462867932197,
            "ave_precision_score": 0.8572268495047346,
            "fpr": 0.07903402854006586,
            "logloss": 1.7748472365980394,
            "mae": 0.24416228988913077,
            "precision": 0.8177215189873418,
            "recall": 0.6901709401709402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7887649406964636,
            "auditor_fn_violation": 0.014258898274492816,
            "auditor_fp_violation": 0.021489683716333093,
            "ave_precision_score": 0.7848404319192632,
            "fpr": 0.2138157894736842,
            "logloss": 1.266000983486116,
            "mae": 0.2839037466124402,
            "precision": 0.6929133858267716,
            "recall": 0.9053497942386831
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8290446256683189,
            "auditor_fn_violation": 0.007317965605561656,
            "auditor_fp_violation": 0.025284149336055686,
            "ave_precision_score": 0.8273741731079469,
            "fpr": 0.2283205268935236,
            "logloss": 1.0608870945135476,
            "mae": 0.27913521082233866,
            "precision": 0.673469387755102,
            "recall": 0.9166666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8159604567397118,
            "auditor_fn_violation": 0.009178037686809623,
            "auditor_fp_violation": 0.015587678115476488,
            "ave_precision_score": 0.8165426568611697,
            "fpr": 0.12280701754385964,
            "logloss": 0.8581084442483062,
            "mae": 0.2742113695588216,
            "precision": 0.7656903765690377,
            "recall": 0.7530864197530864
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8368883107473786,
            "auditor_fn_violation": 0.008152964245170617,
            "auditor_fp_violation": 0.009232530422005437,
            "ave_precision_score": 0.8371132840090556,
            "fpr": 0.14050493962678376,
            "logloss": 0.830496166760747,
            "mae": 0.27499400563271253,
            "precision": 0.7414141414141414,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7635496059915317,
            "auditor_fn_violation": 0.05406874954876904,
            "auditor_fp_violation": 0.060739436619718305,
            "ave_precision_score": 0.7582427596670053,
            "fpr": 0.2236842105263158,
            "logloss": 2.2983933624180124,
            "mae": 0.3262526988371204,
            "precision": 0.6571428571428571,
            "recall": 0.8045267489711934
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7850303796789452,
            "auditor_fn_violation": 0.04144970775047614,
            "auditor_fp_violation": 0.0638645300850156,
            "ave_precision_score": 0.7825682580095283,
            "fpr": 0.23380900109769484,
            "logloss": 1.8196891772127401,
            "mae": 0.31234209672622887,
            "precision": 0.6508196721311476,
            "recall": 0.8482905982905983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7120822681196779,
            "auditor_fn_violation": 0.011993718865063894,
            "auditor_fp_violation": 0.03169014084507042,
            "ave_precision_score": 0.6880904751702953,
            "fpr": 0.23026315789473684,
            "logloss": 2.840927848040394,
            "mae": 0.3027955814763663,
            "precision": 0.6666666666666666,
            "recall": 0.8641975308641975
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.687623819590646,
            "auditor_fn_violation": 0.01045624700948521,
            "auditor_fp_violation": 0.02769511339955845,
            "ave_precision_score": 0.6678023927961332,
            "fpr": 0.2623490669593853,
            "logloss": 2.8038495189270893,
            "mae": 0.3237892214022283,
            "precision": 0.6362252663622526,
            "recall": 0.8931623931623932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7886165516849782,
            "auditor_fn_violation": 0.018712547830481555,
            "auditor_fp_violation": 0.022555287867556215,
            "ave_precision_score": 0.7890208904774927,
            "fpr": 0.15679824561403508,
            "logloss": 1.060459620134946,
            "mae": 0.28611580793121444,
            "precision": 0.723404255319149,
            "recall": 0.7695473251028807
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8051600466017815,
            "auditor_fn_violation": 0.0129964254552619,
            "auditor_fp_violation": 0.017352498804429434,
            "ave_precision_score": 0.8054481636226812,
            "fpr": 0.19538968166849616,
            "logloss": 1.0559555679331156,
            "mae": 0.30215499747443625,
            "precision": 0.6781193490054249,
            "recall": 0.8012820512820513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7442089128932126,
            "auditor_fn_violation": 0.06681376795899213,
            "auditor_fp_violation": 0.042207190511489995,
            "ave_precision_score": 0.743493288022445,
            "fpr": 0.16228070175438597,
            "logloss": 2.2299996313796355,
            "mae": 0.312892361264918,
            "precision": 0.7063492063492064,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7734742840242006,
            "auditor_fn_violation": 0.0505361817107152,
            "auditor_fp_violation": 0.05148510926152146,
            "ave_precision_score": 0.7737073899524433,
            "fpr": 0.1964873765093304,
            "logloss": 1.777584981970251,
            "mae": 0.30853387117185027,
            "precision": 0.6697416974169742,
            "recall": 0.7756410256410257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7930820864158874,
            "auditor_fn_violation": 0.0112852862609198,
            "auditor_fp_violation": 0.01780125195618153,
            "ave_precision_score": 0.7891044605994142,
            "fpr": 0.12390350877192982,
            "logloss": 1.2615951184642678,
            "mae": 0.2715988259442371,
            "precision": 0.7631027253668763,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8235840706993511,
            "auditor_fn_violation": 0.009961346130391138,
            "auditor_fp_violation": 0.012384376556409879,
            "ave_precision_score": 0.8227364713245772,
            "fpr": 0.1437980241492865,
            "logloss": 1.0000516437550082,
            "mae": 0.26989151637857955,
            "precision": 0.7369477911646586,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 12498,
        "test": {
            "accuracy": 0.3969298245614035,
            "auc_prc": 0.5367319974946728,
            "auditor_fn_violation": 0.03391000649772582,
            "auditor_fp_violation": 0.043540482662054215,
            "ave_precision_score": 0.4464258028419789,
            "fpr": 0.34649122807017546,
            "logloss": 17.03377040355177,
            "mae": 0.6117705854994352,
            "precision": 0.44366197183098594,
            "recall": 0.5185185185185185
        },
        "train": {
            "accuracy": 0.37980241492864986,
            "auc_prc": 0.5022933345175826,
            "auditor_fn_violation": 0.03346561963466464,
            "auditor_fp_violation": 0.03790392320596274,
            "ave_precision_score": 0.4221107477181275,
            "fpr": 0.3545554335894621,
            "logloss": 17.375092388327737,
            "mae": 0.6273085691157101,
            "precision": 0.4116575591985428,
            "recall": 0.4829059829059829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7480548993032251,
            "auditor_fn_violation": 0.03508771929824562,
            "auditor_fp_violation": 0.027937361008154186,
            "ave_precision_score": 0.74419787245533,
            "fpr": 0.12390350877192982,
            "logloss": 1.4754308336552053,
            "mae": 0.30741814782781335,
            "precision": 0.7402298850574712,
            "recall": 0.6625514403292181
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7395861546161191,
            "auditor_fn_violation": 0.042964901911114864,
            "auditor_fp_violation": 0.03554499433807515,
            "ave_precision_score": 0.7335026137761882,
            "fpr": 0.14489571899012074,
            "logloss": 1.5273345457266614,
            "mae": 0.3051201409161136,
            "precision": 0.7124183006535948,
            "recall": 0.6987179487179487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 12498,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.857110695878689,
            "auditor_fn_violation": 0.005893076312179639,
            "auditor_fp_violation": 0.012359978584960055,
            "ave_precision_score": 0.8574373232422637,
            "fpr": 0.09649122807017543,
            "logloss": 0.5145292936292467,
            "mae": 0.3107770178081537,
            "precision": 0.8,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8544165084571478,
            "auditor_fn_violation": 0.006529877001885785,
            "auditor_fp_violation": 0.0113734070416009,
            "ave_precision_score": 0.8546098581337158,
            "fpr": 0.10647639956092206,
            "logloss": 0.5042649500510484,
            "mae": 0.3099804679744567,
            "precision": 0.7868131868131868,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7822455648220512,
            "auditor_fn_violation": 0.018536567756840656,
            "auditor_fp_violation": 0.0096419158224199,
            "ave_precision_score": 0.7798360023098356,
            "fpr": 0.07017543859649122,
            "logloss": 2.404404393223484,
            "mae": 0.31335942710782755,
            "precision": 0.8095238095238095,
            "recall": 0.5596707818930041
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8078516279853817,
            "auditor_fn_violation": 0.010625123138844334,
            "auditor_fp_violation": 0.009931288763123401,
            "ave_precision_score": 0.8080166446476821,
            "fpr": 0.07793633369923161,
            "logloss": 1.6849162025909903,
            "mae": 0.2927593917595299,
            "precision": 0.7988668555240793,
            "recall": 0.6025641025641025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6633697478228197,
            "auditor_fn_violation": 0.06757634827810266,
            "auditor_fp_violation": 0.038199592290585616,
            "ave_precision_score": 0.5747942881880437,
            "fpr": 0.20285087719298245,
            "logloss": 9.619886810319365,
            "mae": 0.4276566850911531,
            "precision": 0.5986984815618221,
            "recall": 0.5679012345679012
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6684229233992838,
            "auditor_fn_violation": 0.06242553031795623,
            "auditor_fp_violation": 0.04409363361770981,
            "ave_precision_score": 0.580155061474876,
            "fpr": 0.19319429198682767,
            "logloss": 8.806493196097698,
            "mae": 0.3989680288372284,
            "precision": 0.6148796498905909,
            "recall": 0.6004273504273504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7655071729958753,
            "auditor_fn_violation": 0.06432297307053643,
            "auditor_fp_violation": 0.049182522032781485,
            "ave_precision_score": 0.7583115444848798,
            "fpr": 0.1699561403508772,
            "logloss": 2.6288914399904044,
            "mae": 0.310558503986263,
            "precision": 0.7019230769230769,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7871306638797494,
            "auditor_fn_violation": 0.046300205465957395,
            "auditor_fp_violation": 0.054297487691198375,
            "ave_precision_score": 0.783157709834134,
            "fpr": 0.20087815587266739,
            "logloss": 2.0973908012548543,
            "mae": 0.3040817228909364,
            "precision": 0.6720430107526881,
            "recall": 0.8012820512820513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7921658380599276,
            "auditor_fn_violation": 0.02924879070103242,
            "auditor_fp_violation": 0.032670805534964195,
            "ave_precision_score": 0.7889821909710044,
            "fpr": 0.22039473684210525,
            "logloss": 1.3234570965518448,
            "mae": 0.2958474801776568,
            "precision": 0.6789137380191693,
            "recall": 0.8744855967078189
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.827920820635073,
            "auditor_fn_violation": 0.011605542889845853,
            "auditor_fp_violation": 0.02951386737963145,
            "ave_precision_score": 0.8272047796517304,
            "fpr": 0.2261251372118551,
            "logloss": 1.0647532555071735,
            "mae": 0.27722216772885333,
            "precision": 0.6730158730158731,
            "recall": 0.905982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6521101606672848,
            "auditor_fn_violation": 0.023797920727745288,
            "auditor_fp_violation": 0.016825735112428967,
            "ave_precision_score": 0.642322936922907,
            "fpr": 0.16776315789473684,
            "logloss": 2.566907610852298,
            "mae": 0.33224628096019776,
            "precision": 0.6909090909090909,
            "recall": 0.7037037037037037
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6588661797093538,
            "auditor_fn_violation": 0.026551080338127545,
            "auditor_fp_violation": 0.024739018715325363,
            "ave_precision_score": 0.6456111762805212,
            "fpr": 0.19209659714599342,
            "logloss": 2.3811003988607715,
            "mae": 0.3271265598965273,
            "precision": 0.6679316888045541,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8401673108277504,
            "auditor_fn_violation": 0.0089546783625731,
            "auditor_fp_violation": 0.02001997364302776,
            "ave_precision_score": 0.8405917288144902,
            "fpr": 0.15021929824561403,
            "logloss": 0.6544234609707381,
            "mae": 0.2622622872556912,
            "precision": 0.7472324723247232,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8538829601698459,
            "auditor_fn_violation": 0.011441357764080048,
            "auditor_fp_violation": 0.01664630686393788,
            "ave_precision_score": 0.8540802978896378,
            "fpr": 0.18551042810098792,
            "logloss": 0.6652956449045282,
            "mae": 0.27406834087154647,
            "precision": 0.699288256227758,
            "recall": 0.8397435897435898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7544478877757103,
            "auditor_fn_violation": 0.024671052631578955,
            "auditor_fp_violation": 0.022460052713944488,
            "ave_precision_score": 0.7504078892747374,
            "fpr": 0.13596491228070176,
            "logloss": 1.4216089016482865,
            "mae": 0.2913020263881698,
            "precision": 0.7389473684210527,
            "recall": 0.7222222222222222
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7490598644721197,
            "auditor_fn_violation": 0.02237608714008275,
            "auditor_fp_violation": 0.025836713556159605,
            "ave_precision_score": 0.7427254501075082,
            "fpr": 0.15806805708013172,
            "logloss": 1.4559015468706638,
            "mae": 0.2947355583714175,
            "precision": 0.7108433734939759,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7918156156754668,
            "auditor_fn_violation": 0.026539148797920742,
            "auditor_fp_violation": 0.015731817807429372,
            "ave_precision_score": 0.7926255299449013,
            "fpr": 0.06798245614035088,
            "logloss": 1.3392425721640955,
            "mae": 0.3342429182228335,
            "precision": 0.7993527508090615,
            "recall": 0.5082304526748971
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8142254906972513,
            "auditor_fn_violation": 0.015142559599200658,
            "auditor_fp_violation": 0.007304750317786376,
            "ave_precision_score": 0.8146108541476296,
            "fpr": 0.054884742041712405,
            "logloss": 1.1696032867441917,
            "mae": 0.3076173198780196,
            "precision": 0.834983498349835,
            "recall": 0.5405982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.824549262075028,
            "auditor_fn_violation": 0.026681286549707604,
            "auditor_fp_violation": 0.025219298245614037,
            "ave_precision_score": 0.8254947310516922,
            "fpr": 0.13157894736842105,
            "logloss": 0.8015686844194121,
            "mae": 0.26898248364996497,
            "precision": 0.7551020408163265,
            "recall": 0.7613168724279835
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8467626476477996,
            "auditor_fn_violation": 0.01296593393190539,
            "auditor_fp_violation": 0.018363468319238407,
            "ave_precision_score": 0.8469754727899222,
            "fpr": 0.1394072447859495,
            "logloss": 0.7583887332107059,
            "mae": 0.266868902939837,
            "precision": 0.7434343434343434,
            "recall": 0.7863247863247863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7907004804621796,
            "auditor_fn_violation": 0.008650097465886944,
            "auditor_fp_violation": 0.019814059797380774,
            "ave_precision_score": 0.7910382835635077,
            "fpr": 0.11842105263157894,
            "logloss": 0.9973606780742653,
            "mae": 0.27920870524302227,
            "precision": 0.7677419354838709,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8153808964907622,
            "auditor_fn_violation": 0.0075994258211601814,
            "auditor_fp_violation": 0.013055878366491323,
            "ave_precision_score": 0.8156926356862233,
            "fpr": 0.15367727771679474,
            "logloss": 0.9145615533100154,
            "mae": 0.2805662679818636,
            "precision": 0.7183098591549296,
            "recall": 0.7628205128205128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8200856470364846,
            "auditor_fn_violation": 0.01794545520179049,
            "auditor_fp_violation": 0.02037002718062763,
            "ave_precision_score": 0.8189059118655772,
            "fpr": 0.1337719298245614,
            "logloss": 1.0106611069053293,
            "mae": 0.27952444082900524,
            "precision": 0.7520325203252033,
            "recall": 0.7613168724279835
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8431823942215035,
            "auditor_fn_violation": 0.011267790631127624,
            "auditor_fp_violation": 0.017384711068381686,
            "ave_precision_score": 0.8433792158944279,
            "fpr": 0.15367727771679474,
            "logloss": 0.8943991071833638,
            "mae": 0.2762362025012167,
            "precision": 0.7227722772277227,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7886207110998742,
            "auditor_fn_violation": 0.013241372464082017,
            "auditor_fp_violation": 0.021971007330532904,
            "ave_precision_score": 0.7847035544129488,
            "fpr": 0.2149122807017544,
            "logloss": 1.2692159201021087,
            "mae": 0.28427928541865144,
            "precision": 0.6913385826771653,
            "recall": 0.9032921810699589
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.829280019950156,
            "auditor_fn_violation": 0.007332038616341582,
            "auditor_fp_violation": 0.024793531777398396,
            "ave_precision_score": 0.82758971601235,
            "fpr": 0.22941822173435786,
            "logloss": 1.0624377168895511,
            "mae": 0.2789311115809325,
            "precision": 0.672926447574335,
            "recall": 0.9188034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6958327252946455,
            "auditor_fn_violation": 0.03458685293480615,
            "auditor_fp_violation": 0.08172720533728689,
            "ave_precision_score": 0.6322131245662476,
            "fpr": 0.28728070175438597,
            "logloss": 5.521637280001854,
            "mae": 0.3720870990398463,
            "precision": 0.6135693215339233,
            "recall": 0.8559670781893004
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6639278071457952,
            "auditor_fn_violation": 0.027261767382513815,
            "auditor_fp_violation": 0.07997809566051246,
            "ave_precision_score": 0.5954218271949964,
            "fpr": 0.31174533479692645,
            "logloss": 5.755594993944094,
            "mae": 0.3817013066518674,
            "precision": 0.5901875901875901,
            "recall": 0.8739316239316239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.8179939355829351,
            "auditor_fn_violation": 0.00243664717348928,
            "auditor_fp_violation": 0.015175850424182524,
            "ave_precision_score": 0.8131743814404762,
            "fpr": 0.36403508771929827,
            "logloss": 1.8961498435832174,
            "mae": 0.36202497431598224,
            "precision": 0.585,
            "recall": 0.9629629629629629
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.8426093009737816,
            "auditor_fn_violation": 0.00094289172225506,
            "auditor_fp_violation": 0.025626094907241066,
            "ave_precision_score": 0.8399541256952667,
            "fpr": 0.3743139407244786,
            "logloss": 1.843628078526506,
            "mae": 0.37434640517475937,
            "precision": 0.570528967254408,
            "recall": 0.967948717948718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8097782736380781,
            "auditor_fn_violation": 0.026566222655403943,
            "auditor_fp_violation": 0.026447059550284164,
            "ave_precision_score": 0.8112017006431717,
            "fpr": 0.12609649122807018,
            "logloss": 0.9657552144375288,
            "mae": 0.2741246335297185,
            "precision": 0.7594142259414226,
            "recall": 0.7469135802469136
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.837931389243169,
            "auditor_fn_violation": 0.014298178952405078,
            "auditor_fp_violation": 0.018155327536777736,
            "ave_precision_score": 0.8381726982540165,
            "fpr": 0.145993413830955,
            "logloss": 0.8852559149143074,
            "mae": 0.2675101696962599,
            "precision": 0.7345309381237525,
            "recall": 0.7863247863247863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 12498,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7945256805005398,
            "auditor_fn_violation": 0.026961049743700824,
            "auditor_fp_violation": 0.02964387200395355,
            "ave_precision_score": 0.7949318567086758,
            "fpr": 0.13486842105263158,
            "logloss": 1.1010188462227466,
            "mae": 0.2813319351274833,
            "precision": 0.7474332648870636,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8190255438305711,
            "auditor_fn_violation": 0.01747867938866841,
            "auditor_fp_violation": 0.028349270144434845,
            "ave_precision_score": 0.8193330911561143,
            "fpr": 0.15148188803512624,
            "logloss": 0.9644137087717091,
            "mae": 0.2774747356460395,
            "precision": 0.7261904761904762,
            "recall": 0.782051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7920629021736373,
            "auditor_fn_violation": 0.02437775250884413,
            "auditor_fp_violation": 0.03837204513631498,
            "ave_precision_score": 0.7924403421320189,
            "fpr": 0.36293859649122806,
            "logloss": 2.1234653077557666,
            "mae": 0.40928441599658355,
            "precision": 0.5656167979002624,
            "recall": 0.8868312757201646
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.8108773004522771,
            "auditor_fn_violation": 0.01719721917306989,
            "auditor_fp_violation": 0.02848555279961744,
            "ave_precision_score": 0.8118912515802509,
            "fpr": 0.3787047200878156,
            "logloss": 1.8555536666934822,
            "mae": 0.40703393806874355,
            "precision": 0.5542635658914729,
            "recall": 0.9166666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8003834132693087,
            "auditor_fn_violation": 0.02207873077756119,
            "auditor_fp_violation": 0.017585042418252206,
            "ave_precision_score": 0.7957570198968447,
            "fpr": 0.11951754385964912,
            "logloss": 1.149645065230158,
            "mae": 0.2687133903840952,
            "precision": 0.7743271221532091,
            "recall": 0.7695473251028807
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8340773001959825,
            "auditor_fn_violation": 0.012543743608507608,
            "auditor_fp_violation": 0.019981515116224327,
            "ave_precision_score": 0.832403711583781,
            "fpr": 0.1394072447859495,
            "logloss": 0.8791162261978697,
            "mae": 0.26004819149557595,
            "precision": 0.7465069860279441,
            "recall": 0.7991452991452992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7370208203347655,
            "auditor_fn_violation": 0.072422568767598,
            "auditor_fp_violation": 0.06483712214809324,
            "ave_precision_score": 0.7377077785117854,
            "fpr": 0.2324561403508772,
            "logloss": 1.7060851399973322,
            "mae": 0.36324572584718084,
            "precision": 0.6357388316151202,
            "recall": 0.7613168724279835
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7199108780823498,
            "auditor_fn_violation": 0.05925441188887951,
            "auditor_fp_violation": 0.063324355197201,
            "ave_precision_score": 0.7205316152810866,
            "fpr": 0.23929747530186607,
            "logloss": 1.4155953689624445,
            "mae": 0.35599980788247504,
            "precision": 0.6273504273504273,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8011858542312793,
            "auditor_fn_violation": 0.0146604938271605,
            "auditor_fp_violation": 0.02180112840787415,
            "ave_precision_score": 0.8021193030647145,
            "fpr": 0.12280701754385964,
            "logloss": 0.9809574544913368,
            "mae": 0.2788465187584727,
            "precision": 0.7656903765690377,
            "recall": 0.7530864197530864
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.818240640240441,
            "auditor_fn_violation": 0.012191918339009448,
            "auditor_fp_violation": 0.011028983603957654,
            "ave_precision_score": 0.8185263647856704,
            "fpr": 0.145993413830955,
            "logloss": 0.9284809351610496,
            "mae": 0.2830070344915235,
            "precision": 0.7291242362525459,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7412979493298104,
            "auditor_fn_violation": 0.07207737708468703,
            "auditor_fp_violation": 0.060255539082447906,
            "ave_precision_score": 0.7360466280981867,
            "fpr": 0.21271929824561403,
            "logloss": 2.519107453336793,
            "mae": 0.3437029793533453,
            "precision": 0.651705565529623,
            "recall": 0.7469135802469136
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7632780119414948,
            "auditor_fn_violation": 0.05617242252807565,
            "auditor_fp_violation": 0.06498204785751278,
            "ave_precision_score": 0.7615468196107951,
            "fpr": 0.21295279912184412,
            "logloss": 1.9286763294481153,
            "mae": 0.3220791926509982,
            "precision": 0.6590509666080844,
            "recall": 0.8012820512820513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7824707283872849,
            "auditor_fn_violation": 0.026072124756335302,
            "auditor_fp_violation": 0.0024658183016226013,
            "ave_precision_score": 0.7829515735898519,
            "fpr": 0.01425438596491228,
            "logloss": 2.782985333854339,
            "mae": 0.4484839890946569,
            "precision": 0.8673469387755102,
            "recall": 0.1748971193415638
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.758304840105303,
            "auditor_fn_violation": 0.015198851642320356,
            "auditor_fp_violation": 0.004665822540160021,
            "ave_precision_score": 0.7598951219850933,
            "fpr": 0.014270032930845226,
            "logloss": 2.523258490901608,
            "mae": 0.43558847245902566,
            "precision": 0.8631578947368421,
            "recall": 0.1752136752136752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8071077883173907,
            "auditor_fn_violation": 0.009462313190383367,
            "auditor_fp_violation": 0.02131723087060374,
            "ave_precision_score": 0.8076208308647733,
            "fpr": 0.12390350877192982,
            "logloss": 0.9367309753301133,
            "mae": 0.2806942936899079,
            "precision": 0.7610993657505285,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.829336180856237,
            "auditor_fn_violation": 0.006260144295270535,
            "auditor_fp_violation": 0.009262264819499825,
            "ave_precision_score": 0.829582031353215,
            "fpr": 0.150384193194292,
            "logloss": 0.8805507189476418,
            "mae": 0.27923439191138477,
            "precision": 0.7248995983935743,
            "recall": 0.7713675213675214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7740551702838873,
            "auditor_fn_violation": 0.05037542415710057,
            "auditor_fp_violation": 0.058971151470224865,
            "ave_precision_score": 0.7686265370122334,
            "fpr": 0.2598684210526316,
            "logloss": 2.283071477722606,
            "mae": 0.3444474460526232,
            "precision": 0.6319875776397516,
            "recall": 0.8374485596707819
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7934069928471453,
            "auditor_fn_violation": 0.03542176813307439,
            "auditor_fp_violation": 0.06775478042386385,
            "ave_precision_score": 0.7917471444491843,
            "fpr": 0.26344676180021953,
            "logloss": 1.8414329972093242,
            "mae": 0.32822773740435224,
            "precision": 0.6307692307692307,
            "recall": 0.8760683760683761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7593954229182979,
            "auditor_fn_violation": 0.06837953938343803,
            "auditor_fp_violation": 0.050747467259698545,
            "ave_precision_score": 0.7527035543637002,
            "fpr": 0.18421052631578946,
            "logloss": 2.885884676469771,
            "mae": 0.3206488437299398,
            "precision": 0.6824196597353497,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.774220201942484,
            "auditor_fn_violation": 0.05047988966759549,
            "auditor_fp_violation": 0.056681195223664625,
            "ave_precision_score": 0.7677157178933237,
            "fpr": 0.20417124039517015,
            "logloss": 2.370124161043968,
            "mae": 0.3105242876770526,
            "precision": 0.667262969588551,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7273690499954805,
            "auditor_fn_violation": 0.00526586528048516,
            "auditor_fp_violation": 0.01386314965818302,
            "ave_precision_score": 0.7200005168005368,
            "fpr": 0.14912280701754385,
            "logloss": 2.188225054362955,
            "mae": 0.2831166920256507,
            "precision": 0.7322834645669292,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7325497166046393,
            "auditor_fn_violation": 0.009063018942272513,
            "auditor_fp_violation": 0.004707946269943732,
            "ave_precision_score": 0.7295113325043913,
            "fpr": 0.1712403951701427,
            "logloss": 1.8207245761063842,
            "mae": 0.2877331011390692,
            "precision": 0.7045454545454546,
            "recall": 0.7948717948717948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8128045593219441,
            "auditor_fn_violation": 0.011190527759728541,
            "auditor_fp_violation": 0.019942755950910142,
            "ave_precision_score": 0.8132813746996688,
            "fpr": 0.11403508771929824,
            "logloss": 0.8854157138626767,
            "mae": 0.2776776911482072,
            "precision": 0.7719298245614035,
            "recall": 0.7242798353909465
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8266349820556275,
            "auditor_fn_violation": 0.007078724422302909,
            "auditor_fp_violation": 0.00711891033344649,
            "ave_precision_score": 0.8268999461758785,
            "fpr": 0.13391877058177826,
            "logloss": 0.8479878317361591,
            "mae": 0.27784410256112835,
            "precision": 0.7436974789915967,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7429231489462692,
            "auditor_fn_violation": 0.03782894736842106,
            "auditor_fp_violation": 0.029111069928341986,
            "ave_precision_score": 0.7388410400889821,
            "fpr": 0.125,
            "logloss": 1.49520408149633,
            "mae": 0.3125550061141609,
            "precision": 0.7354988399071926,
            "recall": 0.6522633744855967
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7358582548943825,
            "auditor_fn_violation": 0.04376237252197736,
            "auditor_fp_violation": 0.0362660534773139,
            "ave_precision_score": 0.7295978077251546,
            "fpr": 0.14270032930845225,
            "logloss": 1.5135877308333199,
            "mae": 0.3057782476317095,
            "precision": 0.7180043383947939,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7881778104001901,
            "auditor_fn_violation": 0.01916829109811566,
            "auditor_fp_violation": 0.01913454410674574,
            "ave_precision_score": 0.7857863481161003,
            "fpr": 0.12609649122807018,
            "logloss": 1.1661031392697814,
            "mae": 0.2807702324116274,
            "precision": 0.7594142259414226,
            "recall": 0.7469135802469136
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8135733159198124,
            "auditor_fn_violation": 0.008000506628388075,
            "auditor_fp_violation": 0.020861157708766447,
            "ave_precision_score": 0.8128844884676825,
            "fpr": 0.14928649835345773,
            "logloss": 0.9556819893257512,
            "mae": 0.2746029703405058,
            "precision": 0.7274549098196392,
            "recall": 0.7756410256410257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 12498,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6126346725841567,
            "auditor_fn_violation": 0.006078081004981591,
            "auditor_fp_violation": 0.02775718639321308,
            "ave_precision_score": 0.569273612612316,
            "fpr": 0.25109649122807015,
            "logloss": 5.024512605137187,
            "mae": 0.3395247582461875,
            "precision": 0.6433021806853583,
            "recall": 0.8497942386831275
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6187961995320466,
            "auditor_fn_violation": 0.010854982314916457,
            "auditor_fp_violation": 0.017015508966159776,
            "ave_precision_score": 0.5827100127847753,
            "fpr": 0.2645444566410538,
            "logloss": 4.345579211659485,
            "mae": 0.3288246700528558,
            "precision": 0.6309341500765697,
            "recall": 0.8803418803418803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7979599349477904,
            "auditor_fn_violation": 0.03668958919933579,
            "auditor_fp_violation": 0.019901573181780745,
            "ave_precision_score": 0.7964837995766341,
            "fpr": 0.11074561403508772,
            "logloss": 1.142246320073915,
            "mae": 0.28532151374683346,
            "precision": 0.7755555555555556,
            "recall": 0.7181069958847737
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8343075623058602,
            "auditor_fn_violation": 0.0262602381153424,
            "auditor_fp_violation": 0.02791564351430844,
            "ave_precision_score": 0.8335947949409922,
            "fpr": 0.1141602634467618,
            "logloss": 0.8224779743572445,
            "mae": 0.2576689887560712,
            "precision": 0.7758620689655172,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8172369758994406,
            "auditor_fn_violation": 0.021266515053064757,
            "auditor_fp_violation": 0.023574561403508776,
            "ave_precision_score": 0.8178292092348531,
            "fpr": 0.12828947368421054,
            "logloss": 0.9091131891036073,
            "mae": 0.27069482612141416,
            "precision": 0.7587628865979381,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8390393102579068,
            "auditor_fn_violation": 0.015022939007571283,
            "auditor_fp_violation": 0.021891950155238343,
            "ave_precision_score": 0.8392691388928112,
            "fpr": 0.145993413830955,
            "logloss": 0.8619766270075524,
            "mae": 0.2695250804705603,
            "precision": 0.7329317269076305,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7600410071742214,
            "auditor_fn_violation": 0.06871345029239766,
            "auditor_fp_violation": 0.04858537188040524,
            "ave_precision_score": 0.7531091804441284,
            "fpr": 0.17324561403508773,
            "logloss": 2.691686302278416,
            "mae": 0.31499604151265076,
            "precision": 0.6943907156673114,
            "recall": 0.7386831275720165
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7832538343540139,
            "auditor_fn_violation": 0.04828449998592699,
            "auditor_fp_violation": 0.05365819814506917,
            "ave_precision_score": 0.7792679926744142,
            "fpr": 0.1964873765093304,
            "logloss": 2.1378259584131056,
            "mae": 0.3063132089784776,
            "precision": 0.6757246376811594,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7894396795906489,
            "auditor_fn_violation": 0.02263825716554762,
            "auditor_fp_violation": 0.020318548719215887,
            "ave_precision_score": 0.7870291629163974,
            "fpr": 0.12280701754385964,
            "logloss": 1.116491078214988,
            "mae": 0.28190876876430454,
            "precision": 0.7637130801687764,
            "recall": 0.7448559670781894
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8161663588707828,
            "auditor_fn_violation": 0.012848658842072671,
            "auditor_fp_violation": 0.015694806144117675,
            "ave_precision_score": 0.8154378620639028,
            "fpr": 0.1437980241492865,
            "logloss": 0.9013924675145779,
            "mae": 0.27438835222884705,
            "precision": 0.7358870967741935,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8136231000257186,
            "auditor_fn_violation": 0.022769114143383146,
            "auditor_fp_violation": 0.027268141009801503,
            "ave_precision_score": 0.8143055899862885,
            "fpr": 0.13048245614035087,
            "logloss": 0.9547172036132537,
            "mae": 0.2712285872223775,
            "precision": 0.7546391752577319,
            "recall": 0.7530864197530864
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.836092636923242,
            "auditor_fn_violation": 0.009363243172244275,
            "auditor_fp_violation": 0.0248430891065557,
            "ave_precision_score": 0.8363191818509681,
            "fpr": 0.14709110867178923,
            "logloss": 0.8977612434047106,
            "mae": 0.26955652714933154,
            "precision": 0.7330677290836654,
            "recall": 0.7863247863247863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.864068806280289,
            "auditor_fn_violation": 0.03658354992419321,
            "auditor_fp_violation": 0.010928877357713538,
            "ave_precision_score": 0.8646068476874036,
            "fpr": 0.047149122807017545,
            "logloss": 0.5596772081064726,
            "mae": 0.3112700764558005,
            "precision": 0.8757225433526011,
            "recall": 0.6234567901234568
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.873837458934372,
            "auditor_fn_violation": 0.021644290579526597,
            "auditor_fp_violation": 0.007128821799277952,
            "ave_precision_score": 0.8740006818028159,
            "fpr": 0.048298572996706916,
            "logloss": 0.5241462060542045,
            "mae": 0.30489415479099385,
            "precision": 0.8698224852071006,
            "recall": 0.6282051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8066420909099463,
            "auditor_fn_violation": 0.01933073424301495,
            "auditor_fp_violation": 0.02042922741125113,
            "ave_precision_score": 0.8066711225602202,
            "fpr": 0.11293859649122807,
            "logloss": 0.9436746271903895,
            "mae": 0.2791313986409799,
            "precision": 0.7726269315673289,
            "recall": 0.720164609053498
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8325782214111324,
            "auditor_fn_violation": 0.010245151847786321,
            "auditor_fp_violation": 0.007034662873879083,
            "ave_precision_score": 0.8329380002771225,
            "fpr": 0.12623490669593854,
            "logloss": 0.852796067156654,
            "mae": 0.2712698358595123,
            "precision": 0.7558386411889597,
            "recall": 0.7606837606837606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 12498,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7865335156589526,
            "auditor_fn_violation": 0.011637246408201575,
            "auditor_fp_violation": 0.021149925871015583,
            "ave_precision_score": 0.7826116719530045,
            "fpr": 0.22039473684210525,
            "logloss": 1.3013335814343039,
            "mae": 0.29026283274360376,
            "precision": 0.687402799377916,
            "recall": 0.9094650205761317
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8268163523265393,
            "auditor_fn_violation": 0.01071425220711719,
            "auditor_fp_violation": 0.022414779977847885,
            "ave_precision_score": 0.825149133888457,
            "fpr": 0.23929747530186607,
            "logloss": 1.0970546848010903,
            "mae": 0.28430185605978386,
            "precision": 0.6656441717791411,
            "recall": 0.9273504273504274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8025210382783967,
            "auditor_fn_violation": 0.016311999133636564,
            "auditor_fp_violation": 0.011701054278889714,
            "ave_precision_score": 0.8034442891690695,
            "fpr": 0.07456140350877193,
            "logloss": 1.1534076303868508,
            "mae": 0.3078670374498508,
            "precision": 0.8073654390934845,
            "recall": 0.5864197530864198
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8074637595536629,
            "auditor_fn_violation": 0.01577584508429734,
            "auditor_fp_violation": 0.007564926295862213,
            "ave_precision_score": 0.8078101659915213,
            "fpr": 0.08232711306256861,
            "logloss": 1.0542697211103471,
            "mae": 0.3012294000874819,
            "precision": 0.7899159663865546,
            "recall": 0.6025641025641025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8095576759448931,
            "auditor_fn_violation": 0.016253339109089597,
            "auditor_fp_violation": 0.021126760563380285,
            "ave_precision_score": 0.8099459360961938,
            "fpr": 0.1162280701754386,
            "logloss": 0.8575757326549559,
            "mae": 0.27842392095866225,
            "precision": 0.7670329670329671,
            "recall": 0.7181069958847737
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8363225549933029,
            "auditor_fn_violation": 0.008235056808053514,
            "auditor_fp_violation": 0.011398185706179557,
            "ave_precision_score": 0.8365560356935728,
            "fpr": 0.12403951701427003,
            "logloss": 0.8121599644041,
            "mae": 0.2716979005279154,
            "precision": 0.7616033755274262,
            "recall": 0.7713675213675214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7418902143160258,
            "auditor_fn_violation": 0.02334443361490146,
            "auditor_fp_violation": 0.014789761963594435,
            "ave_precision_score": 0.7336527657568411,
            "fpr": 0.13706140350877194,
            "logloss": 1.8795799091127612,
            "mae": 0.3077203755776981,
            "precision": 0.7340425531914894,
            "recall": 0.7098765432098766
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7755628281494925,
            "auditor_fn_violation": 0.010761162243050284,
            "auditor_fp_violation": 0.013202072487505365,
            "ave_precision_score": 0.7701684156633252,
            "fpr": 0.15916575192096596,
            "logloss": 1.4752121737423858,
            "mae": 0.29815815213364516,
            "precision": 0.7052845528455285,
            "recall": 0.7414529914529915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7632644040670726,
            "auditor_fn_violation": 0.06695364955598875,
            "auditor_fp_violation": 0.04492525327403015,
            "ave_precision_score": 0.7595932888802068,
            "fpr": 0.1611842105263158,
            "logloss": 2.6989221496452647,
            "mae": 0.3098622347802113,
            "precision": 0.7083333333333334,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7564449931251109,
            "auditor_fn_violation": 0.05366508110745213,
            "auditor_fp_violation": 0.05344014589677705,
            "ave_precision_score": 0.7531378971028404,
            "fpr": 0.1986827661909989,
            "logloss": 2.2715469215636386,
            "mae": 0.3123134813514186,
            "precision": 0.6678899082568808,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7896460306876579,
            "auditor_fn_violation": 0.030015883329723485,
            "auditor_fp_violation": 0.0333117123795404,
            "ave_precision_score": 0.7864432449357892,
            "fpr": 0.22039473684210525,
            "logloss": 1.3830767150121133,
            "mae": 0.29820977218986233,
            "precision": 0.6784,
            "recall": 0.8724279835390947
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8243938378590735,
            "auditor_fn_violation": 0.012065261241990113,
            "auditor_fp_violation": 0.03168200053026343,
            "ave_precision_score": 0.823675872759745,
            "fpr": 0.2283205268935236,
            "logloss": 1.117334082632364,
            "mae": 0.27883444567064164,
            "precision": 0.6714060031595577,
            "recall": 0.9081196581196581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 12498,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.766341238669393,
            "auditor_fn_violation": 0.0632716049382716,
            "auditor_fp_violation": 0.05305627625401533,
            "ave_precision_score": 0.7605343646017322,
            "fpr": 0.19407894736842105,
            "logloss": 2.5566937801070284,
            "mae": 0.3161716421289717,
            "precision": 0.6775956284153005,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7832157577234145,
            "auditor_fn_violation": 0.04693114544925742,
            "auditor_fp_violation": 0.056517656037445525,
            "ave_precision_score": 0.7792329386048902,
            "fpr": 0.21624588364434688,
            "logloss": 2.1121724359886858,
            "mae": 0.30811796315178186,
            "precision": 0.6603448275862069,
            "recall": 0.8183760683760684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8033376794518221,
            "auditor_fn_violation": 0.03135603927514259,
            "auditor_fp_violation": 0.03084074623177663,
            "ave_precision_score": 0.8002248148211768,
            "fpr": 0.19298245614035087,
            "logloss": 1.1812020546789772,
            "mae": 0.2864885847594268,
            "precision": 0.704201680672269,
            "recall": 0.8621399176954733
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8363605494098771,
            "auditor_fn_violation": 0.017886796701286272,
            "auditor_fp_violation": 0.0352080044998055,
            "ave_precision_score": 0.8356405275810364,
            "fpr": 0.20087815587266739,
            "logloss": 0.9280868749362454,
            "mae": 0.27244260000812137,
            "precision": 0.6955074875207987,
            "recall": 0.8931623931623932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7854951216734745,
            "auditor_fn_violation": 0.04160575048732944,
            "auditor_fp_violation": 0.020349435796062937,
            "ave_precision_score": 0.7859417164401481,
            "fpr": 0.1074561403508772,
            "logloss": 1.118200734773629,
            "mae": 0.3161816573113139,
            "precision": 0.766109785202864,
            "recall": 0.6604938271604939
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7932885746950841,
            "auditor_fn_violation": 0.020384756114723186,
            "auditor_fp_violation": 0.0236710582719855,
            "ave_precision_score": 0.7936107762795153,
            "fpr": 0.14050493962678376,
            "logloss": 1.0228126050253497,
            "mae": 0.3152410399982578,
            "precision": 0.7149220489977728,
            "recall": 0.6858974358974359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7632007656312737,
            "auditor_fn_violation": 0.06358295429932859,
            "auditor_fp_violation": 0.042222634049913534,
            "ave_precision_score": 0.7562217925924385,
            "fpr": 0.17763157894736842,
            "logloss": 2.373450948331461,
            "mae": 0.3125412562108556,
            "precision": 0.6931818181818182,
            "recall": 0.7530864197530864
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7965179609277722,
            "auditor_fn_violation": 0.044761556287352115,
            "auditor_fp_violation": 0.05191378015873213,
            "ave_precision_score": 0.7946773816606972,
            "fpr": 0.19758507135016465,
            "logloss": 1.805062960382605,
            "mae": 0.30112298439318125,
            "precision": 0.6768402154398564,
            "recall": 0.8055555555555556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7032410024229259,
            "auditor_fn_violation": 0.021485362067720743,
            "auditor_fp_violation": 0.011644427971336793,
            "ave_precision_score": 0.6956177847767191,
            "fpr": 0.09649122807017543,
            "logloss": 7.675081936424674,
            "mae": 0.33383374037627844,
            "precision": 0.7615176151761518,
            "recall": 0.5781893004115226
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7011161506439385,
            "auditor_fn_violation": 0.01101447643708895,
            "auditor_fp_violation": 0.01882930721331705,
            "ave_precision_score": 0.6965624986699792,
            "fpr": 0.10757409440175632,
            "logloss": 7.469882234242273,
            "mae": 0.3367212135500415,
            "precision": 0.7277777777777777,
            "recall": 0.5598290598290598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8121789728266343,
            "auditor_fn_violation": 0.018407966933795396,
            "auditor_fp_violation": 0.027960526315789477,
            "ave_precision_score": 0.8131208242360132,
            "fpr": 0.13925438596491227,
            "logloss": 0.9250297755569113,
            "mae": 0.27157148821206284,
            "precision": 0.748015873015873,
            "recall": 0.7757201646090535
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8352316516102218,
            "auditor_fn_violation": 0.009963691632187792,
            "auditor_fp_violation": 0.022987167129614718,
            "ave_precision_score": 0.8354717088333656,
            "fpr": 0.15367727771679474,
            "logloss": 0.878223835588293,
            "mae": 0.27336564206649033,
            "precision": 0.7254901960784313,
            "recall": 0.7905982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7953554013207706,
            "auditor_fn_violation": 0.03128384232185402,
            "auditor_fp_violation": 0.028627172391071577,
            "ave_precision_score": 0.7957983395067959,
            "fpr": 0.12280701754385964,
            "logloss": 1.0776258966996872,
            "mae": 0.27783073360798993,
            "precision": 0.7622080679405521,
            "recall": 0.7386831275720165
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.816814164855908,
            "auditor_fn_violation": 0.017152654638933455,
            "auditor_fp_violation": 0.024659726988673678,
            "ave_precision_score": 0.8171141721834876,
            "fpr": 0.141602634467618,
            "logloss": 0.9555513629388844,
            "mae": 0.2768835212068482,
            "precision": 0.735655737704918,
            "recall": 0.7670940170940171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8350614737209123,
            "auditor_fn_violation": 0.03262399826727312,
            "auditor_fp_violation": 0.05976649369903633,
            "ave_precision_score": 0.834351356076927,
            "fpr": 0.2532894736842105,
            "logloss": 0.8166346154335,
            "mae": 0.3373303788186353,
            "precision": 0.6440677966101694,
            "recall": 0.8600823045267489
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.8553939967721469,
            "auditor_fn_violation": 0.026682428438740188,
            "auditor_fp_violation": 0.06337391252635832,
            "ave_precision_score": 0.8555552457437665,
            "fpr": 0.270032930845225,
            "logloss": 0.728330493955232,
            "mae": 0.34011369447937384,
            "precision": 0.6272727272727273,
            "recall": 0.8846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7718948088555659,
            "auditor_fn_violation": 0.02478611652588262,
            "auditor_fp_violation": 0.011127069434148757,
            "ave_precision_score": 0.7723905133153192,
            "fpr": 0.05592105263157895,
            "logloss": 3.22197294860988,
            "mae": 0.35244108195919766,
            "precision": 0.8138686131386861,
            "recall": 0.4588477366255144
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7846898965721256,
            "auditor_fn_violation": 0.013866606621820675,
            "auditor_fp_violation": 0.0127089770623902,
            "ave_precision_score": 0.7849941535622974,
            "fpr": 0.06366630076838639,
            "logloss": 2.5010865124035946,
            "mae": 0.32478185251789526,
            "precision": 0.8060200668896321,
            "recall": 0.5149572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.813073811420747,
            "auditor_fn_violation": 0.024438668688181366,
            "auditor_fp_violation": 0.026748208549542872,
            "ave_precision_score": 0.8113751039446121,
            "fpr": 0.15789473684210525,
            "logloss": 1.1077717119095554,
            "mae": 0.2986032487363544,
            "precision": 0.7198443579766537,
            "recall": 0.7613168724279835
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8488193076516045,
            "auditor_fn_violation": 0.01684070289997842,
            "auditor_fp_violation": 0.025608749842036014,
            "ave_precision_score": 0.8489593743629626,
            "fpr": 0.17672886937431395,
            "logloss": 0.8347612236094536,
            "mae": 0.28544673073669447,
            "precision": 0.7024029574861368,
            "recall": 0.811965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8185120571917492,
            "auditor_fn_violation": 0.023897191538517076,
            "auditor_fp_violation": 0.031736471460341,
            "ave_precision_score": 0.8191127618087265,
            "fpr": 0.14802631578947367,
            "logloss": 0.836402737813195,
            "mae": 0.2825048939609766,
            "precision": 0.7378640776699029,
            "recall": 0.7818930041152263
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8435161112486087,
            "auditor_fn_violation": 0.01787272369050635,
            "auditor_fp_violation": 0.03299526975293194,
            "ave_precision_score": 0.8437180981121708,
            "fpr": 0.16794731064763996,
            "logloss": 0.7779361149667761,
            "mae": 0.2791263275408283,
            "precision": 0.7150837988826816,
            "recall": 0.8205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 12498,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8123922063642041,
            "auditor_fn_violation": 0.01755514042307415,
            "auditor_fp_violation": 0.01854511572358126,
            "ave_precision_score": 0.8132185756008623,
            "fpr": 0.13048245614035087,
            "logloss": 0.9220149337889354,
            "mae": 0.2750899584613289,
            "precision": 0.7571428571428571,
            "recall": 0.7633744855967078
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8388334129551966,
            "auditor_fn_violation": 0.00880970474823384,
            "auditor_fp_violation": 0.020734786519415332,
            "ave_precision_score": 0.839046969169393,
            "fpr": 0.15587266739846323,
            "logloss": 0.869177241359975,
            "mae": 0.27155516121035733,
            "precision": 0.7242718446601941,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8010497273572995,
            "auditor_fn_violation": 0.030825842899429648,
            "auditor_fp_violation": 0.03390886253191665,
            "ave_precision_score": 0.7971531920028062,
            "fpr": 0.13706140350877194,
            "logloss": 1.233241899954094,
            "mae": 0.2658015766441929,
            "precision": 0.751984126984127,
            "recall": 0.779835390946502
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8237614138225597,
            "auditor_fn_violation": 0.018717104337301924,
            "auditor_fp_violation": 0.027021133723019137,
            "ave_precision_score": 0.8229197489129911,
            "fpr": 0.15697036223929747,
            "logloss": 0.9711666978330555,
            "mae": 0.2708990462087274,
            "precision": 0.7265774378585086,
            "recall": 0.811965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8370177684531752,
            "auditor_fn_violation": 0.009011082232329796,
            "auditor_fp_violation": 0.020781854871921593,
            "ave_precision_score": 0.8374575332496489,
            "fpr": 0.1425438596491228,
            "logloss": 0.6262910493346758,
            "mae": 0.26846933315634586,
            "precision": 0.7565543071161048,
            "recall": 0.831275720164609
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8532158146688715,
            "auditor_fn_violation": 0.002413521348757351,
            "auditor_fp_violation": 0.007867226003721757,
            "ave_precision_score": 0.853414346816969,
            "fpr": 0.17453347969264543,
            "logloss": 0.626654755366653,
            "mae": 0.2761911799948448,
            "precision": 0.7129963898916968,
            "recall": 0.844017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8092302608948252,
            "auditor_fn_violation": 0.00921864847303444,
            "auditor_fp_violation": 0.020493575488015815,
            "ave_precision_score": 0.8096670707510247,
            "fpr": 0.12171052631578948,
            "logloss": 0.9719613284001912,
            "mae": 0.27930547225350216,
            "precision": 0.7623126338329764,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.827308547683193,
            "auditor_fn_violation": 0.0051366489346730835,
            "auditor_fp_violation": 0.007354307646943682,
            "ave_precision_score": 0.8275573559340585,
            "fpr": 0.14818880351262348,
            "logloss": 0.9171332187227106,
            "mae": 0.2798722811751012,
            "precision": 0.7267206477732794,
            "recall": 0.7670940170940171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6816998840395507,
            "auditor_fn_violation": 0.015314778716338177,
            "auditor_fp_violation": 0.0019304423029404558,
            "ave_precision_score": 0.661403248486669,
            "fpr": 0.13815789473684212,
            "logloss": 2.6681638927204308,
            "mae": 0.37544676480758943,
            "precision": 0.6896551724137931,
            "recall": 0.5761316872427984
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.692678183709645,
            "auditor_fn_violation": 0.00754313377804048,
            "auditor_fp_violation": 0.015947548522819918,
            "ave_precision_score": 0.6710038965223055,
            "fpr": 0.13830954994511527,
            "logloss": 2.400114163022638,
            "mae": 0.3546715302071266,
            "precision": 0.6971153846153846,
            "recall": 0.6196581196581197
        }
    }
]