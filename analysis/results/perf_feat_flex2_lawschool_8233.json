[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8421753802090026,
            "auditor_fn_violation": 0.019578258663186892,
            "auditor_fp_violation": 0.024284206427283166,
            "ave_precision_score": 0.8426707323452975,
            "fpr": 0.15460526315789475,
            "logloss": 0.5625923317118079,
            "mae": 0.2862120386651664,
            "precision": 0.7441016333938294,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8514813201833213,
            "auditor_fn_violation": 0.015596608823598104,
            "auditor_fp_violation": 0.02305159165751922,
            "ave_precision_score": 0.8518340828801149,
            "fpr": 0.16136114160263446,
            "logloss": 0.5464071538477018,
            "mae": 0.2817898227513229,
            "precision": 0.73224043715847,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8662699322991227,
            "auditor_fn_violation": 0.009900137741046837,
            "auditor_fp_violation": 0.012235612395474669,
            "ave_precision_score": 0.8664448610148283,
            "fpr": 0.07017543859649122,
            "logloss": 0.5066532864795525,
            "mae": 0.2970380863346356,
            "precision": 0.8371501272264631,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8425775101238959,
            "auditor_fn_violation": 0.00670294509190275,
            "auditor_fp_violation": 0.013157403466326162,
            "ave_precision_score": 0.8433526224929133,
            "fpr": 0.07574094401756312,
            "logloss": 0.5125439984401211,
            "mae": 0.30007511086232397,
            "precision": 0.823076923076923,
            "recall": 0.6829787234042554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8505342613764929,
            "auditor_fn_violation": 0.023841887777294474,
            "auditor_fp_violation": 0.0193243769470405,
            "ave_precision_score": 0.8508358132168176,
            "fpr": 0.11951754385964912,
            "logloss": 0.5170787650622968,
            "mae": 0.2938027242729604,
            "precision": 0.7757201646090535,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8530886144032478,
            "auditor_fn_violation": 0.020543242170166058,
            "auditor_fp_violation": 0.021072754019280604,
            "ave_precision_score": 0.8543305343221292,
            "fpr": 0.12403951701427003,
            "logloss": 0.49696436978442726,
            "mae": 0.2890962542921027,
            "precision": 0.7665289256198347,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8019680346567548,
            "auditor_fn_violation": 0.0340863781354212,
            "auditor_fp_violation": 0.03161378914576161,
            "ave_precision_score": 0.8028476945300531,
            "fpr": 0.13596491228070176,
            "logloss": 1.225345967428713,
            "mae": 0.2923574629266364,
            "precision": 0.7427385892116183,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8203460307679331,
            "auditor_fn_violation": 0.03449564425345074,
            "auditor_fp_violation": 0.029428675970937228,
            "ave_precision_score": 0.8207535467313024,
            "fpr": 0.13172338090010977,
            "logloss": 1.1249098413244671,
            "mae": 0.28704999932461084,
            "precision": 0.7446808510638298,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8201111340117508,
            "auditor_fn_violation": 0.024707300275482097,
            "auditor_fp_violation": 0.026315789473684216,
            "ave_precision_score": 0.820755722579638,
            "fpr": 0.1600877192982456,
            "logloss": 0.5915018237776886,
            "mae": 0.29874931428846363,
            "precision": 0.7301293900184843,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8456494572661643,
            "auditor_fn_violation": 0.019739822967512907,
            "auditor_fp_violation": 0.02090847315874759,
            "ave_precision_score": 0.8458825025287597,
            "fpr": 0.16465422612513722,
            "logloss": 0.550418821691438,
            "mae": 0.28939681784124854,
            "precision": 0.7252747252747253,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8367876186064565,
            "auditor_fn_violation": 0.011984377265477743,
            "auditor_fp_violation": 0.019104053943269392,
            "ave_precision_score": 0.8372312004027793,
            "fpr": 0.15021929824561403,
            "logloss": 0.6349094005754155,
            "mae": 0.29132816141288476,
            "precision": 0.7313725490196078,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8279094396935451,
            "auditor_fn_violation": 0.01156549968470468,
            "auditor_fp_violation": 0.016958265194112778,
            "ave_precision_score": 0.828202169232361,
            "fpr": 0.16794731064763996,
            "logloss": 0.6482643113445765,
            "mae": 0.29168497288699796,
            "precision": 0.7096774193548387,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7886166226372028,
            "auditor_fn_violation": 0.02892108887922286,
            "auditor_fp_violation": 0.020922999672077388,
            "ave_precision_score": 0.7891005307669128,
            "fpr": 0.14583333333333334,
            "logloss": 0.7219987070179232,
            "mae": 0.3218046064863366,
            "precision": 0.72,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7835268562029971,
            "auditor_fn_violation": 0.012147044398253029,
            "auditor_fp_violation": 0.024811388148380468,
            "ave_precision_score": 0.7844236358368464,
            "fpr": 0.1525795828759605,
            "logloss": 0.6930692320124461,
            "mae": 0.3180392335627492,
            "precision": 0.7116182572614108,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8689234419649645,
            "auditor_fn_violation": 0.008769664346817457,
            "auditor_fp_violation": 0.01577102803738319,
            "ave_precision_score": 0.8691146147462023,
            "fpr": 0.12938596491228072,
            "logloss": 0.49642679107835286,
            "mae": 0.27829823566073747,
            "precision": 0.7717601547388782,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8503329614787645,
            "auditor_fn_violation": 0.011493098535628373,
            "auditor_fp_violation": 0.018354652508643415,
            "ave_precision_score": 0.8506933121001097,
            "fpr": 0.13721185510428102,
            "logloss": 0.5094696953712063,
            "mae": 0.28618125370936215,
            "precision": 0.751984126984127,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8357159150256787,
            "auditor_fn_violation": 0.010190118892272003,
            "auditor_fp_violation": 0.022242375799311365,
            "ave_precision_score": 0.8360936891487337,
            "fpr": 0.15570175438596492,
            "logloss": 0.6072956024754579,
            "mae": 0.29334875136070576,
            "precision": 0.7330827067669173,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8288844905627205,
            "auditor_fn_violation": 0.012892075577457557,
            "auditor_fp_violation": 0.02479645352469565,
            "ave_precision_score": 0.8291621865875636,
            "fpr": 0.1756311745334797,
            "logloss": 0.6276883133998091,
            "mae": 0.2953636836266691,
            "precision": 0.7064220183486238,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8170689955299619,
            "auditor_fn_violation": 0.02269102508336958,
            "auditor_fp_violation": 0.022301299393343174,
            "ave_precision_score": 0.8177334338674498,
            "fpr": 0.15021929824561403,
            "logloss": 0.6102057408683238,
            "mae": 0.2977567235452737,
            "precision": 0.7390476190476191,
            "recall": 0.8016528925619835
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8434045805537533,
            "auditor_fn_violation": 0.01818203050190345,
            "auditor_fp_violation": 0.021413761260083986,
            "ave_precision_score": 0.8436317720545075,
            "fpr": 0.16575192096597147,
            "logloss": 0.5644702089914474,
            "mae": 0.28724189031094643,
            "precision": 0.7193308550185874,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8600108569102347,
            "auditor_fn_violation": 0.022505255908365957,
            "auditor_fp_violation": 0.022124528611247755,
            "ave_precision_score": 0.8602242599086725,
            "fpr": 0.13596491228070176,
            "logloss": 0.49430040741809017,
            "mae": 0.31280883098799295,
            "precision": 0.7573385518590998,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8570924585227712,
            "auditor_fn_violation": 0.023803629399537566,
            "auditor_fp_violation": 0.016525161107253005,
            "ave_precision_score": 0.8576603618488705,
            "fpr": 0.13172338090010977,
            "logloss": 0.4899498840372246,
            "mae": 0.3128773076705119,
            "precision": 0.7619047619047619,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8541571100949792,
            "auditor_fn_violation": 0.022863201391909532,
            "auditor_fp_violation": 0.018876045253320223,
            "ave_precision_score": 0.8543786658224077,
            "fpr": 0.09868421052631579,
            "logloss": 0.5483063119443287,
            "mae": 0.2852105573652356,
            "precision": 0.801762114537445,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8467384412142939,
            "auditor_fn_violation": 0.019039166686129344,
            "auditor_fp_violation": 0.015467291929578273,
            "ave_precision_score": 0.8480364970896517,
            "fpr": 0.10647639956092206,
            "logloss": 0.5223817809222369,
            "mae": 0.28043760425790193,
            "precision": 0.7820224719101123,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8703713108592984,
            "auditor_fn_violation": 0.015495867768595042,
            "auditor_fp_violation": 0.013352598786686341,
            "ave_precision_score": 0.8705482601102161,
            "fpr": 0.08552631578947369,
            "logloss": 0.4789071285455859,
            "mae": 0.3039672096390604,
            "precision": 0.8227272727272728,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8534493949957616,
            "auditor_fn_violation": 0.009505570217437,
            "auditor_fp_violation": 0.009958904893827272,
            "ave_precision_score": 0.8541404826958108,
            "fpr": 0.08781558726673985,
            "logloss": 0.4761237575305145,
            "mae": 0.30638398272501616,
            "precision": 0.8126463700234192,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.728164449950323,
            "auditor_fn_violation": 0.015769990575612586,
            "auditor_fp_violation": 0.01431587145433678,
            "ave_precision_score": 0.7286386665574374,
            "fpr": 0.06578947368421052,
            "logloss": 2.745273742080963,
            "mae": 0.4528627792270614,
            "precision": 0.7209302325581395,
            "recall": 0.3202479338842975
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.698360810838484,
            "auditor_fn_violation": 0.006927155101945486,
            "auditor_fp_violation": 0.010703146974120786,
            "ave_precision_score": 0.6988184555276314,
            "fpr": 0.06476399560922064,
            "logloss": 2.8048827891402888,
            "mae": 0.45943678938482585,
            "precision": 0.700507614213198,
            "recall": 0.2936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.849802195353619,
            "auditor_fn_violation": 0.015754132231404976,
            "auditor_fp_violation": 0.009796687981636333,
            "ave_precision_score": 0.8500797861636754,
            "fpr": 0.05701754385964912,
            "logloss": 0.5397737208549175,
            "mae": 0.3259568937750724,
            "precision": 0.856353591160221,
            "recall": 0.640495867768595
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8470136054602933,
            "auditor_fn_violation": 0.013763224887311118,
            "auditor_fp_violation": 0.01049406224253331,
            "ave_precision_score": 0.847493886815639,
            "fpr": 0.06037321624588365,
            "logloss": 0.5389789272754678,
            "mae": 0.32744702217059846,
            "precision": 0.8410404624277457,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8190476018510295,
            "auditor_fn_violation": 0.01616644918080325,
            "auditor_fp_violation": 0.041758894900803416,
            "ave_precision_score": 0.819546867405109,
            "fpr": 0.18311403508771928,
            "logloss": 0.5922355082005173,
            "mae": 0.33294559360576004,
            "precision": 0.7012522361359571,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8072137210583878,
            "auditor_fn_violation": 0.004101174767031789,
            "auditor_fp_violation": 0.03787420566470277,
            "ave_precision_score": 0.8075641702652283,
            "fpr": 0.1964873765093304,
            "logloss": 0.6046701287422855,
            "mae": 0.339003308542187,
            "precision": 0.6786355475763016,
            "recall": 0.8042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8478464086146521,
            "auditor_fn_violation": 0.021367986080904743,
            "auditor_fp_violation": 0.0217299967207739,
            "ave_precision_score": 0.8480673139959951,
            "fpr": 0.1074561403508772,
            "logloss": 0.6162616369385747,
            "mae": 0.286033704507153,
            "precision": 0.7836644591611479,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8345786472145076,
            "auditor_fn_violation": 0.022392974753018657,
            "auditor_fp_violation": 0.023863039544394414,
            "ave_precision_score": 0.835328806680221,
            "fpr": 0.11745334796926454,
            "logloss": 0.5798100666556139,
            "mae": 0.28687526850313133,
            "precision": 0.7637969094922737,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.84165032920076,
            "auditor_fn_violation": 0.015038241264317822,
            "auditor_fp_violation": 0.025708620265617318,
            "ave_precision_score": 0.8418958483691206,
            "fpr": 0.14802631578947367,
            "logloss": 0.5923079592828621,
            "mae": 0.2860828605342632,
            "precision": 0.7448015122873346,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8356339705625948,
            "auditor_fn_violation": 0.015470490692949066,
            "auditor_fp_violation": 0.02305159165751922,
            "ave_precision_score": 0.836203162665711,
            "fpr": 0.15806805708013172,
            "logloss": 0.5950179544850598,
            "mae": 0.28275598300138893,
            "precision": 0.7288135593220338,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7071953624925092,
            "auditor_fn_violation": 0.029403635638683496,
            "auditor_fp_violation": 0.02120224626988032,
            "ave_precision_score": 0.7078064357882476,
            "fpr": 0.125,
            "logloss": 1.2825533776178946,
            "mae": 0.3951688227635291,
            "precision": 0.6752136752136753,
            "recall": 0.4896694214876033
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.701744802453867,
            "auditor_fn_violation": 0.009643365952775774,
            "auditor_fp_violation": 0.015086459025615367,
            "ave_precision_score": 0.7033150241986191,
            "fpr": 0.11086717892425905,
            "logloss": 1.357677582217668,
            "mae": 0.3865293018535733,
            "precision": 0.7097701149425287,
            "recall": 0.5255319148936171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.872292844268824,
            "auditor_fn_violation": 0.007385457445266057,
            "auditor_fp_violation": 0.010373114444990983,
            "ave_precision_score": 0.8724762473202812,
            "fpr": 0.09758771929824561,
            "logloss": 0.4714306380497274,
            "mae": 0.306588136076339,
            "precision": 0.8102345415778252,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8522213796775293,
            "auditor_fn_violation": 0.011187145292757553,
            "auditor_fp_violation": 0.004913491192305686,
            "ave_precision_score": 0.8525270552413639,
            "fpr": 0.09989023051591657,
            "logloss": 0.47981189811454045,
            "mae": 0.311358617980577,
            "precision": 0.7982261640798226,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8382801402035664,
            "auditor_fn_violation": 0.02013556618819777,
            "auditor_fp_violation": 0.02192982456140351,
            "ave_precision_score": 0.8385295418638175,
            "fpr": 0.14473684210526316,
            "logloss": 0.5707015072643808,
            "mae": 0.2991266522603518,
            "precision": 0.7446808510638298,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8279203723175314,
            "auditor_fn_violation": 0.016969895135109887,
            "auditor_fp_violation": 0.01948968390868971,
            "ave_precision_score": 0.8282929374096073,
            "fpr": 0.14818880351262348,
            "logloss": 0.5734902324949178,
            "mae": 0.2978691824575892,
            "precision": 0.7393822393822393,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8625480968792436,
            "auditor_fn_violation": 0.010838045527040744,
            "auditor_fp_violation": 0.023789760616494512,
            "ave_precision_score": 0.8627408216078131,
            "fpr": 0.1337719298245614,
            "logloss": 0.4964258028663829,
            "mae": 0.3123869990328482,
            "precision": 0.7621832358674464,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8473243787381397,
            "auditor_fn_violation": 0.017794334026204547,
            "auditor_fp_violation": 0.022969451227252698,
            "ave_precision_score": 0.8477319873578713,
            "fpr": 0.13721185510428102,
            "logloss": 0.49930012798346274,
            "mae": 0.3146394605438596,
            "precision": 0.755859375,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8500538547775216,
            "auditor_fn_violation": 0.017145135566188206,
            "auditor_fp_violation": 0.011679681095261518,
            "ave_precision_score": 0.8502996992328103,
            "fpr": 0.0581140350877193,
            "logloss": 0.5311177892876412,
            "mae": 0.330890912695363,
            "precision": 0.8547945205479452,
            "recall": 0.6446280991735537
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.844551435128332,
            "auditor_fn_violation": 0.013312469346287688,
            "auditor_fp_violation": 0.010342226901737648,
            "ave_precision_score": 0.8449705081567764,
            "fpr": 0.06586169045005488,
            "logloss": 0.534450779533213,
            "mae": 0.3337370576991257,
            "precision": 0.8285714285714286,
            "recall": 0.6170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8473332336851594,
            "auditor_fn_violation": 0.010833514571552851,
            "auditor_fp_violation": 0.019713785046728976,
            "ave_precision_score": 0.8480433637268497,
            "fpr": 0.14144736842105263,
            "logloss": 0.5285607991101707,
            "mae": 0.281132947102091,
            "precision": 0.7602230483271375,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8536242004315115,
            "auditor_fn_violation": 0.013090594857182898,
            "auditor_fp_violation": 0.020194100325823715,
            "ave_precision_score": 0.8539583012351967,
            "fpr": 0.15367727771679474,
            "logloss": 0.5167142237137782,
            "mae": 0.27808566036190463,
            "precision": 0.7383177570093458,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8530960149789576,
            "auditor_fn_violation": 0.012591525300855444,
            "auditor_fp_violation": 0.016734300705033612,
            "ave_precision_score": 0.8533228180968782,
            "fpr": 0.11842105263157894,
            "logloss": 0.5692085743190372,
            "mae": 0.2809545109190175,
            "precision": 0.7721518987341772,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.84439038710726,
            "auditor_fn_violation": 0.014073849172057836,
            "auditor_fp_violation": 0.02085620197585072,
            "ave_precision_score": 0.8456852034824349,
            "fpr": 0.12843029637760703,
            "logloss": 0.5543670854140172,
            "mae": 0.276815470998315,
            "precision": 0.7526427061310782,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8537410940730115,
            "auditor_fn_violation": 0.017695646657967235,
            "auditor_fp_violation": 0.02447122479094934,
            "ave_precision_score": 0.8539566564336374,
            "fpr": 0.13596491228070176,
            "logloss": 0.5241165857237279,
            "mae": 0.29352753967344924,
            "precision": 0.751503006012024,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8490065162901073,
            "auditor_fn_violation": 0.017539762243968516,
            "auditor_fp_violation": 0.02250149968512835,
            "ave_precision_score": 0.8495314520107956,
            "fpr": 0.1437980241492865,
            "logloss": 0.514615505041715,
            "mae": 0.29025795426729323,
            "precision": 0.7390438247011952,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8224419655167203,
            "auditor_fn_violation": 0.02840909090909091,
            "auditor_fp_violation": 0.026387522544679468,
            "ave_precision_score": 0.8228939117475759,
            "fpr": 0.1425438596491228,
            "logloss": 0.5348964085918531,
            "mae": 0.3218781869065041,
            "precision": 0.752851711026616,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8482284639100144,
            "auditor_fn_violation": 0.020589952588924963,
            "auditor_fp_violation": 0.01987549502054755,
            "ave_precision_score": 0.8485870023200568,
            "fpr": 0.13721185510428102,
            "logloss": 0.5071074643257095,
            "mae": 0.314004478088256,
            "precision": 0.7553816046966731,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8441989354380229,
            "auditor_fn_violation": 0.01453983616064956,
            "auditor_fp_violation": 0.02105878012788982,
            "ave_precision_score": 0.8444132136213552,
            "fpr": 0.14035087719298245,
            "logloss": 0.5977905277116624,
            "mae": 0.2932062973115152,
            "precision": 0.7408906882591093,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8343649409647184,
            "auditor_fn_violation": 0.020982320106499756,
            "auditor_fp_violation": 0.018665790502077163,
            "ave_precision_score": 0.8350989386407137,
            "fpr": 0.1437980241492865,
            "logloss": 0.5996757740536245,
            "mae": 0.29102198484289316,
            "precision": 0.7369477911646586,
            "recall": 0.7808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8371857503047295,
            "auditor_fn_violation": 0.014499057561258522,
            "auditor_fp_violation": 0.025390945236924086,
            "ave_precision_score": 0.837439000192174,
            "fpr": 0.15679824561403508,
            "logloss": 0.6103881643384365,
            "mae": 0.2898657704386814,
            "precision": 0.7404718693284936,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.831697060555598,
            "auditor_fn_violation": 0.011514118224069883,
            "auditor_fp_violation": 0.02022894778108829,
            "ave_precision_score": 0.8322828799448423,
            "fpr": 0.1712403951701427,
            "logloss": 0.6119869970126293,
            "mae": 0.2893502760294717,
            "precision": 0.7209302325581395,
            "recall": 0.8574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8427802858657343,
            "auditor_fn_violation": 0.019387958532695378,
            "auditor_fp_violation": 0.025219298245614037,
            "ave_precision_score": 0.843206727528757,
            "fpr": 0.15350877192982457,
            "logloss": 0.5566535806468119,
            "mae": 0.28563265576361263,
            "precision": 0.7440585009140768,
            "recall": 0.8409090909090909
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8485081717639902,
            "auditor_fn_violation": 0.016712987831935915,
            "auditor_fp_violation": 0.023405044418059944,
            "ave_precision_score": 0.8491100530703344,
            "fpr": 0.15916575192096596,
            "logloss": 0.5390310920353414,
            "mae": 0.2807683363338599,
            "precision": 0.7344322344322345,
            "recall": 0.8531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8214492000576044,
            "auditor_fn_violation": 0.010747426417282878,
            "auditor_fp_violation": 0.04184599934415478,
            "ave_precision_score": 0.8219473535702246,
            "fpr": 0.1787280701754386,
            "logloss": 0.6003703251054302,
            "mae": 0.3236115905484168,
            "precision": 0.7104795737122558,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.812688971767524,
            "auditor_fn_violation": 0.005068080435341105,
            "auditor_fp_violation": 0.031195939773640893,
            "ave_precision_score": 0.8130255212543,
            "fpr": 0.19319429198682767,
            "logloss": 0.610185801913179,
            "mae": 0.32961788633068867,
            "precision": 0.6890459363957597,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8371554878684406,
            "auditor_fn_violation": 0.021318145570537933,
            "auditor_fp_violation": 0.015371372356123961,
            "ave_precision_score": 0.8374651837723546,
            "fpr": 0.06469298245614036,
            "logloss": 0.5493487584933703,
            "mae": 0.3446657023272118,
            "precision": 0.8365650969529086,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8270585145449061,
            "auditor_fn_violation": 0.014863255249083314,
            "auditor_fp_violation": 0.01729429422702122,
            "ave_precision_score": 0.8274902324454347,
            "fpr": 0.07464324917672886,
            "logloss": 0.5518775416019455,
            "mae": 0.3467729804468976,
            "precision": 0.8105849582172702,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8464202712995768,
            "auditor_fn_violation": 0.019421940698854584,
            "auditor_fp_violation": 0.007982866043613706,
            "ave_precision_score": 0.8459839336046904,
            "fpr": 0.043859649122807015,
            "logloss": 0.6681565450231767,
            "mae": 0.3145153417530617,
            "precision": 0.8705501618122977,
            "recall": 0.5557851239669421
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8393174512176281,
            "auditor_fn_violation": 0.022173435784851824,
            "auditor_fp_violation": 0.014359640672954145,
            "ave_precision_score": 0.8385664118544303,
            "fpr": 0.042810098792535674,
            "logloss": 0.6620026461420424,
            "mae": 0.3027251560327844,
            "precision": 0.8785046728971962,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 8233,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8542616940136982,
            "auditor_fn_violation": 0.01299024938379006,
            "auditor_fp_violation": 0.016980242662731605,
            "ave_precision_score": 0.85447096961905,
            "fpr": 0.1206140350877193,
            "logloss": 0.575588805610718,
            "mae": 0.27967308363006677,
            "precision": 0.7689075630252101,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8448901110877338,
            "auditor_fn_violation": 0.014340098558983591,
            "auditor_fp_violation": 0.019116318316569226,
            "ave_precision_score": 0.8461787559239458,
            "fpr": 0.13172338090010977,
            "logloss": 0.5656000379138786,
            "mae": 0.2773453588638369,
            "precision": 0.7478991596638656,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8579838587912563,
            "auditor_fn_violation": 0.013103523270987388,
            "auditor_fp_violation": 0.022903344810624705,
            "ave_precision_score": 0.8581925630970687,
            "fpr": 0.13596491228070176,
            "logloss": 0.5132236645568795,
            "mae": 0.3000965736660363,
            "precision": 0.7651515151515151,
            "recall": 0.8347107438016529
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8507940742635225,
            "auditor_fn_violation": 0.014050493962678379,
            "auditor_fp_violation": 0.022319795096963052,
            "ave_precision_score": 0.8521118217029012,
            "fpr": 0.145993413830955,
            "logloss": 0.5006941133817375,
            "mae": 0.2986649084717657,
            "precision": 0.7442307692307693,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8575541412212091,
            "auditor_fn_violation": 0.010045128316659421,
            "auditor_fp_violation": 0.008351778980160684,
            "ave_precision_score": 0.8578300373960817,
            "fpr": 0.07456140350877193,
            "logloss": 0.49433933117647394,
            "mae": 0.33447650197501244,
            "precision": 0.8388625592417062,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8325147943179281,
            "auditor_fn_violation": 0.01471611742999276,
            "auditor_fp_violation": 0.0038979367817379485,
            "ave_precision_score": 0.8330102398258292,
            "fpr": 0.07903402854006586,
            "logloss": 0.5028512234292879,
            "mae": 0.34002366056001276,
            "precision": 0.8195488721804511,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8572266256239547,
            "auditor_fn_violation": 0.013085399449035823,
            "auditor_fp_violation": 0.011036645351697004,
            "ave_precision_score": 0.8574773113563021,
            "fpr": 0.06578947368421052,
            "logloss": 0.528017962154997,
            "mae": 0.31002813452505507,
            "precision": 0.8449612403100775,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8509957639673622,
            "auditor_fn_violation": 0.001247168180862751,
            "auditor_fp_violation": 0.007051631483182373,
            "ave_precision_score": 0.8517408113512696,
            "fpr": 0.07354555433589462,
            "logloss": 0.5339062963930304,
            "mae": 0.31303636343872665,
            "precision": 0.8184281842818428,
            "recall": 0.6425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8529918668515389,
            "auditor_fn_violation": 0.01784290271132377,
            "auditor_fp_violation": 0.022050233644859817,
            "ave_precision_score": 0.8532088486486389,
            "fpr": 0.13486842105263158,
            "logloss": 0.5956417736992079,
            "mae": 0.28914079351772926,
            "precision": 0.7458677685950413,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8542177286822975,
            "auditor_fn_violation": 0.01765653829086578,
            "auditor_fp_violation": 0.02389539789571152,
            "ave_precision_score": 0.8544216785091204,
            "fpr": 0.14489571899012074,
            "logloss": 0.5823992591447812,
            "mae": 0.2820960207558025,
            "precision": 0.7344064386317908,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8449004498587772,
            "auditor_fn_violation": 0.02405031172973757,
            "auditor_fp_violation": 0.02714840547630759,
            "ave_precision_score": 0.8454341869846065,
            "fpr": 0.14144736842105263,
            "logloss": 0.5643159203285655,
            "mae": 0.28410678810369544,
            "precision": 0.75,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.85262507858392,
            "auditor_fn_violation": 0.028068290632225525,
            "auditor_fp_violation": 0.02270311710487342,
            "ave_precision_score": 0.8529271377904921,
            "fpr": 0.13062568605927552,
            "logloss": 0.5334392842503041,
            "mae": 0.27704629767181366,
            "precision": 0.7600806451612904,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8452011481982551,
            "auditor_fn_violation": 0.012895099318544297,
            "auditor_fp_violation": 0.010934169535989503,
            "ave_precision_score": 0.8460716130023703,
            "fpr": 0.09978070175438597,
            "logloss": 0.4873016499385873,
            "mae": 0.32349907678323225,
            "precision": 0.8047210300429185,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8412355986959685,
            "auditor_fn_violation": 0.01843893780507742,
            "auditor_fp_violation": 0.003494701942247812,
            "ave_precision_score": 0.8417609468128999,
            "fpr": 0.10537870472008781,
            "logloss": 0.4884863195473567,
            "mae": 0.3251620736525166,
            "precision": 0.7917570498915402,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8379156778355341,
            "auditor_fn_violation": 0.01384659997100189,
            "auditor_fp_violation": 0.025390945236924086,
            "ave_precision_score": 0.8381694736143106,
            "fpr": 0.15679824561403508,
            "logloss": 0.6077452856886439,
            "mae": 0.28981603733566436,
            "precision": 0.7409420289855072,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8330980740830103,
            "auditor_fn_violation": 0.011514118224069883,
            "auditor_fp_violation": 0.0213540227653447,
            "ave_precision_score": 0.8335909620610285,
            "fpr": 0.17233809001097694,
            "logloss": 0.6096531441985815,
            "mae": 0.28949196872660615,
            "precision": 0.7196428571428571,
            "recall": 0.8574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 8233,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8476658153597915,
            "auditor_fn_violation": 0.025241953023053498,
            "auditor_fp_violation": 0.01995972700442696,
            "ave_precision_score": 0.8478896491620066,
            "fpr": 0.13925438596491227,
            "logloss": 0.5473766545221297,
            "mae": 0.2907925641532832,
            "precision": 0.7509803921568627,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8454548975213799,
            "auditor_fn_violation": 0.016820421795081395,
            "auditor_fp_violation": 0.025090167790497102,
            "ave_precision_score": 0.8461970078311271,
            "fpr": 0.14489571899012074,
            "logloss": 0.5241588570740798,
            "mae": 0.28476938875146723,
            "precision": 0.7426900584795322,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8367542675613517,
            "auditor_fn_violation": 0.011984377265477743,
            "auditor_fp_violation": 0.019104053943269392,
            "ave_precision_score": 0.8371978513648012,
            "fpr": 0.15021929824561403,
            "logloss": 0.636237019346376,
            "mae": 0.2914279288412664,
            "precision": 0.7313725490196078,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8277264268590075,
            "auditor_fn_violation": 0.01156549968470468,
            "auditor_fp_violation": 0.0175282699980834,
            "ave_precision_score": 0.8280193803686794,
            "fpr": 0.1690450054884742,
            "logloss": 0.6496021102337552,
            "mae": 0.29176873957743904,
            "precision": 0.7083333333333334,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7978233476763572,
            "auditor_fn_violation": 0.04250715890967088,
            "auditor_fp_violation": 0.028447286440400073,
            "ave_precision_score": 0.7992203659805365,
            "fpr": 0.1118421052631579,
            "logloss": 0.8178804203792984,
            "mae": 0.30815566994182025,
            "precision": 0.7738359201773836,
            "recall": 0.7210743801652892
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8155772591663788,
            "auditor_fn_violation": 0.04385174113085925,
            "auditor_fp_violation": 0.03697315003571865,
            "ave_precision_score": 0.8159888133369246,
            "fpr": 0.12294182217343579,
            "logloss": 0.7400435096822562,
            "mae": 0.29970918906796407,
            "precision": 0.75,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.685463311530744,
            "auditor_fn_violation": 0.012856586196897201,
            "auditor_fp_violation": 0.010949540908345629,
            "ave_precision_score": 0.6872853518066013,
            "fpr": 0.23903508771929824,
            "logloss": 1.1525039730203381,
            "mae": 0.3608120497404965,
            "precision": 0.646677471636953,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6727921116946435,
            "auditor_fn_violation": 0.00803419202653152,
            "auditor_fp_violation": 0.005207205458107149,
            "ave_precision_score": 0.6760321592726894,
            "fpr": 0.24807903402854006,
            "logloss": 1.250858238209368,
            "mae": 0.36557070337824776,
            "precision": 0.6331168831168831,
            "recall": 0.8297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.849296335783862,
            "auditor_fn_violation": 0.009403998115122525,
            "auditor_fp_violation": 0.007327020823085753,
            "ave_precision_score": 0.8495737381634724,
            "fpr": 0.06359649122807018,
            "logloss": 0.5202775324879533,
            "mae": 0.3133185089066964,
            "precision": 0.8524173027989822,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8521856223165734,
            "auditor_fn_violation": 0.0006305906532452072,
            "auditor_fp_violation": 0.01350587801897195,
            "ave_precision_score": 0.8526886859846208,
            "fpr": 0.06695938529088913,
            "logloss": 0.502295066281359,
            "mae": 0.3101261248495164,
            "precision": 0.8431876606683805,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8173451540392938,
            "auditor_fn_violation": 0.05090301942873713,
            "auditor_fp_violation": 0.03369917199540908,
            "ave_precision_score": 0.8185931964110184,
            "fpr": 0.10416666666666667,
            "logloss": 0.702521229969034,
            "mae": 0.3259766760406143,
            "precision": 0.7748815165876777,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8224149178495773,
            "auditor_fn_violation": 0.051395473760422264,
            "auditor_fp_violation": 0.029321644501196016,
            "ave_precision_score": 0.8227736827223439,
            "fpr": 0.09440175631174534,
            "logloss": 0.6532698175708681,
            "mae": 0.31604829519994987,
            "precision": 0.7937649880095923,
            "recall": 0.7042553191489361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8357187163750582,
            "auditor_fn_violation": 0.013529433086849355,
            "auditor_fp_violation": 0.017782115920642726,
            "ave_precision_score": 0.8360208687560072,
            "fpr": 0.13267543859649122,
            "logloss": 0.6029129458391759,
            "mae": 0.29057999936814766,
            "precision": 0.7489626556016598,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8345729993684317,
            "auditor_fn_violation": 0.014134572716444404,
            "auditor_fp_violation": 0.017585519388875204,
            "ave_precision_score": 0.8358391709700997,
            "fpr": 0.1394072447859495,
            "logloss": 0.5790078716166944,
            "mae": 0.2817342546184493,
            "precision": 0.7386831275720165,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8410192502284577,
            "auditor_fn_violation": 0.011891492677975936,
            "auditor_fp_violation": 0.021586530578783406,
            "ave_precision_score": 0.8412626973544342,
            "fpr": 0.15570175438596492,
            "logloss": 0.6055200813308173,
            "mae": 0.29028942747661285,
            "precision": 0.7404021937842779,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8331330714742249,
            "auditor_fn_violation": 0.01230819534297125,
            "auditor_fp_violation": 0.020106981687662263,
            "ave_precision_score": 0.8337105646827612,
            "fpr": 0.1690450054884742,
            "logloss": 0.6100467960567378,
            "mae": 0.29271394189984645,
            "precision": 0.7220216606498195,
            "recall": 0.851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.840637992338552,
            "auditor_fn_violation": 0.014055023923444975,
            "auditor_fp_violation": 0.022252623380882117,
            "ave_precision_score": 0.8408860166184726,
            "fpr": 0.14364035087719298,
            "logloss": 0.5877892719638522,
            "mae": 0.2872076220197701,
            "precision": 0.7485604606525912,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8345495798840447,
            "auditor_fn_violation": 0.014489571899012073,
            "auditor_fp_violation": 0.02217791617195726,
            "ave_precision_score": 0.8351287364898006,
            "fpr": 0.15148188803512624,
            "logloss": 0.5866643749579595,
            "mae": 0.2818831003515886,
            "precision": 0.7351247600767754,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8158674556451637,
            "auditor_fn_violation": 0.042908148470349426,
            "auditor_fp_violation": 0.03380677160190196,
            "ave_precision_score": 0.8171384717605849,
            "fpr": 0.13596491228070176,
            "logloss": 0.7866174017669956,
            "mae": 0.2951041096670802,
            "precision": 0.7479674796747967,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.828845392065767,
            "auditor_fn_violation": 0.04160029894668006,
            "auditor_fp_violation": 0.03705031225809022,
            "ave_precision_score": 0.8291690054668286,
            "fpr": 0.13721185510428102,
            "logloss": 0.7160808476693086,
            "mae": 0.2926280630065372,
            "precision": 0.7406639004149378,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8376620865444119,
            "auditor_fn_violation": 0.029462538060026102,
            "auditor_fp_violation": 0.02467617642236432,
            "ave_precision_score": 0.837937884731246,
            "fpr": 0.14035087719298245,
            "logloss": 0.5587484620663775,
            "mae": 0.2982832721127922,
            "precision": 0.7465346534653465,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8514382630127899,
            "auditor_fn_violation": 0.01690450054884743,
            "auditor_fp_violation": 0.02194891860879003,
            "ave_precision_score": 0.8516690377799185,
            "fpr": 0.150384193194292,
            "logloss": 0.5302105748538631,
            "mae": 0.2926738369861964,
            "precision": 0.732943469785575,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8411805080587303,
            "auditor_fn_violation": 0.011891492677975936,
            "auditor_fp_violation": 0.021586530578783406,
            "ave_precision_score": 0.8414247381732941,
            "fpr": 0.15570175438596492,
            "logloss": 0.6051229807815368,
            "mae": 0.2902974890139296,
            "precision": 0.7404021937842779,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8332598609752646,
            "auditor_fn_violation": 0.01230819534297125,
            "auditor_fp_violation": 0.020788996169269026,
            "ave_precision_score": 0.8338379284060269,
            "fpr": 0.16794731064763996,
            "logloss": 0.6095153107639036,
            "mae": 0.2927246865384553,
            "precision": 0.7233273056057866,
            "recall": 0.851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7550569101615114,
            "auditor_fn_violation": 0.009904668696534745,
            "auditor_fp_violation": 0.004662649614690935,
            "ave_precision_score": 0.755472164767637,
            "fpr": 0.04057017543859649,
            "logloss": 0.9182084833563998,
            "mae": 0.4066786639222093,
            "precision": 0.8082901554404145,
            "recall": 0.32231404958677684
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7664809094145203,
            "auditor_fn_violation": 0.018943410327673604,
            "auditor_fp_violation": 0.002785307317218875,
            "ave_precision_score": 0.7667950907796165,
            "fpr": 0.036223929747530186,
            "logloss": 0.9139946815018238,
            "mae": 0.39448486921238446,
            "precision": 0.8186813186813187,
            "recall": 0.3170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7853342287140381,
            "auditor_fn_violation": 0.015899122807017545,
            "auditor_fp_violation": 0.01970353746515822,
            "ave_precision_score": 0.7382785836095201,
            "fpr": 0.14364035087719298,
            "logloss": 4.381675662922365,
            "mae": 0.28601531272021236,
            "precision": 0.7348178137651822,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7818558245875613,
            "auditor_fn_violation": 0.013494639979447422,
            "auditor_fp_violation": 0.023280589220686446,
            "ave_precision_score": 0.7306852291649061,
            "fpr": 0.16355653128430298,
            "logloss": 4.401954789425007,
            "mae": 0.2838413687163465,
            "precision": 0.7117988394584139,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7122660166529986,
            "auditor_fn_violation": 0.01719497607655503,
            "auditor_fp_violation": 0.010936731431382195,
            "ave_precision_score": 0.7129890328413571,
            "fpr": 0.051535087719298246,
            "logloss": 3.3876701478449274,
            "mae": 0.453092093937123,
            "precision": 0.7564766839378239,
            "recall": 0.30165289256198347
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6929479223381118,
            "auditor_fn_violation": 0.010446785155428932,
            "auditor_fp_violation": 0.005416290189694614,
            "ave_precision_score": 0.6934565516920121,
            "fpr": 0.054884742041712405,
            "logloss": 3.449450280954755,
            "mae": 0.45491644336790066,
            "precision": 0.726775956284153,
            "recall": 0.28297872340425534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8462469831731224,
            "auditor_fn_violation": 0.01671469479483834,
            "auditor_fp_violation": 0.021878586653549765,
            "ave_precision_score": 0.8465229764724189,
            "fpr": 0.13157894736842105,
            "logloss": 0.6655304581289306,
            "mae": 0.31604779351369144,
            "precision": 0.7556008146639511,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8339486214764517,
            "auditor_fn_violation": 0.016171146974332633,
            "auditor_fp_violation": 0.01414308862952426,
            "ave_precision_score": 0.8344358259664086,
            "fpr": 0.1394072447859495,
            "logloss": 0.6283572876940807,
            "mae": 0.32519299628104953,
            "precision": 0.7402862985685071,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 8233,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8558438336333014,
            "auditor_fn_violation": 0.013461468754530961,
            "auditor_fp_violation": 0.024289330218068537,
            "ave_precision_score": 0.8560550949841528,
            "fpr": 0.14364035087719298,
            "logloss": 0.5353387463086965,
            "mae": 0.2804439637149794,
            "precision": 0.75,
            "recall": 0.8119834710743802
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8473545207266087,
            "auditor_fn_violation": 0.016012331550552355,
            "auditor_fp_violation": 0.01729429422702123,
            "ave_precision_score": 0.8480870321050689,
            "fpr": 0.15806805708013172,
            "logloss": 0.5395565342060636,
            "mae": 0.2804725858202443,
            "precision": 0.7272727272727273,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8413425490902056,
            "auditor_fn_violation": 0.013522636653617519,
            "auditor_fp_violation": 0.020110878832595516,
            "ave_precision_score": 0.8416032060656321,
            "fpr": 0.125,
            "logloss": 0.5655487639548574,
            "mae": 0.29069042016865415,
            "precision": 0.7678207739307535,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.829037234011713,
            "auditor_fn_violation": 0.010348693276035222,
            "auditor_fp_violation": 0.017383901969130137,
            "ave_precision_score": 0.8293732279771066,
            "fpr": 0.12843029637760703,
            "logloss": 0.5710413581840409,
            "mae": 0.2904744883815213,
            "precision": 0.75625,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8443898902022802,
            "auditor_fn_violation": 0.022215274757140788,
            "auditor_fp_violation": 0.020759038366945405,
            "ave_precision_score": 0.8447742399929653,
            "fpr": 0.12609649122807018,
            "logloss": 0.5064668468541881,
            "mae": 0.31677521586422236,
            "precision": 0.7727272727272727,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8559405256047362,
            "auditor_fn_violation": 0.02139337179157811,
            "auditor_fp_violation": 0.017406303904657375,
            "ave_precision_score": 0.8563974971091335,
            "fpr": 0.11525795828759605,
            "logloss": 0.490995238150044,
            "mae": 0.3126227837388172,
            "precision": 0.784394250513347,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8471960585776036,
            "auditor_fn_violation": 0.021207137161084532,
            "auditor_fp_violation": 0.01063955156583047,
            "ave_precision_score": 0.8474791008651519,
            "fpr": 0.06907894736842106,
            "logloss": 0.5274191448210199,
            "mae": 0.32726248891119386,
            "precision": 0.8384615384615385,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8462288186887127,
            "auditor_fn_violation": 0.010626620267650707,
            "auditor_fp_violation": 0.010633452063591628,
            "ave_precision_score": 0.8467072962717865,
            "fpr": 0.07244785949506037,
            "logloss": 0.5279873260723318,
            "mae": 0.3276105048221819,
            "precision": 0.8225806451612904,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.810256971640096,
            "auditor_fn_violation": 0.04921297303175295,
            "auditor_fp_violation": 0.02253443187407772,
            "ave_precision_score": 0.8110312585261825,
            "fpr": 0.07346491228070176,
            "logloss": 0.734799714942209,
            "mae": 0.3292504204595932,
            "precision": 0.8179347826086957,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8312451866248616,
            "auditor_fn_violation": 0.0482868953920172,
            "auditor_fp_violation": 0.01820530627179522,
            "ave_precision_score": 0.8315059814609891,
            "fpr": 0.06586169045005488,
            "logloss": 0.6741603830182825,
            "mae": 0.32022785420662886,
            "precision": 0.8309859154929577,
            "recall": 0.6276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8308496977049986,
            "auditor_fn_violation": 0.011300202986805856,
            "auditor_fp_violation": 0.019052816035415643,
            "ave_precision_score": 0.8312156853168611,
            "fpr": 0.14583333333333334,
            "logloss": 0.625679059890432,
            "mae": 0.29329644621088446,
            "precision": 0.7407407407407407,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8251171587446063,
            "auditor_fn_violation": 0.013802928743256187,
            "auditor_fp_violation": 0.017971330500733046,
            "ave_precision_score": 0.8254001885645917,
            "fpr": 0.16355653128430298,
            "logloss": 0.6403361848276661,
            "mae": 0.2926489021350516,
            "precision": 0.7204502814258912,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8410296454082165,
            "auditor_fn_violation": 0.025241953023053498,
            "auditor_fp_violation": 0.020374754058042305,
            "ave_precision_score": 0.8412359559559348,
            "fpr": 0.14144736842105263,
            "logloss": 0.5535219076874517,
            "mae": 0.29707972886880224,
            "precision": 0.748046875,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8404911584740429,
            "auditor_fn_violation": 0.018992456267370436,
            "auditor_fp_violation": 0.02497566900891349,
            "ave_precision_score": 0.8417648831206069,
            "fpr": 0.150384193194292,
            "logloss": 0.530641562598275,
            "mae": 0.29094661911591707,
            "precision": 0.7360308285163777,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8454823068952092,
            "auditor_fn_violation": 0.013078603015803977,
            "auditor_fp_violation": 0.011256968355468109,
            "ave_precision_score": 0.8458446359970802,
            "fpr": 0.09868421052631579,
            "logloss": 0.4865609433315892,
            "mae": 0.32059487296072275,
            "precision": 0.8089171974522293,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.825819754430556,
            "auditor_fn_violation": 0.018955087932363317,
            "auditor_fp_violation": 0.007751069692421426,
            "ave_precision_score": 0.8272772231427333,
            "fpr": 0.09879253567508232,
            "logloss": 0.4889654124141977,
            "mae": 0.32360407186244766,
            "precision": 0.799554565701559,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 8233,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8727252788208233,
            "auditor_fn_violation": 0.01878534145280558,
            "auditor_fp_violation": 0.007296278078373505,
            "ave_precision_score": 0.8729252218581232,
            "fpr": 0.039473684210526314,
            "logloss": 0.5203392814228526,
            "mae": 0.3317855798655696,
            "precision": 0.8956521739130435,
            "recall": 0.6384297520661157
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.861686043532187,
            "auditor_fn_violation": 0.018786930424831268,
            "auditor_fp_violation": 0.007290585462139486,
            "ave_precision_score": 0.8622483798751168,
            "fpr": 0.04500548847420417,
            "logloss": 0.5211341695877995,
            "mae": 0.33443210758350617,
            "precision": 0.8768768768768769,
            "recall": 0.6212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.819029545226658,
            "auditor_fn_violation": 0.01650627084239525,
            "auditor_fp_violation": 0.02010575504181013,
            "ave_precision_score": 0.8199349780348454,
            "fpr": 0.14144736842105263,
            "logloss": 0.5853569946689638,
            "mae": 0.3029043516718236,
            "precision": 0.7409638554216867,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8360761137053396,
            "auditor_fn_violation": 0.014634374197164679,
            "auditor_fp_violation": 0.019210904266573077,
            "ave_precision_score": 0.8363409026108706,
            "fpr": 0.14928649835345773,
            "logloss": 0.5478760939139327,
            "mae": 0.29322700464238444,
            "precision": 0.7301587301587301,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8455406623226316,
            "auditor_fn_violation": 0.01680078294910831,
            "auditor_fp_violation": 0.015899122807017545,
            "ave_precision_score": 0.8458133425807118,
            "fpr": 0.12390350877192982,
            "logloss": 0.6177134150342152,
            "mae": 0.2786024115573941,
            "precision": 0.7645833333333333,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8562543261544289,
            "auditor_fn_violation": 0.021262582619053182,
            "auditor_fp_violation": 0.02256123817986764,
            "ave_precision_score": 0.8564529216986085,
            "fpr": 0.12403951701427003,
            "logloss": 0.5916507813608194,
            "mae": 0.27251026157426667,
            "precision": 0.7590618336886994,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8520329143240432,
            "auditor_fn_violation": 0.010523144120632164,
            "auditor_fp_violation": 0.010109239219544191,
            "ave_precision_score": 0.852327015703738,
            "fpr": 0.0668859649122807,
            "logloss": 0.5190143406154362,
            "mae": 0.3186345402449533,
            "precision": 0.8419689119170984,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.842542326433213,
            "auditor_fn_violation": 0.008433566106920155,
            "auditor_fp_violation": 0.00913252238326725,
            "ave_precision_score": 0.8430410396569161,
            "fpr": 0.06805708013172337,
            "logloss": 0.5314595934378261,
            "mae": 0.3233989002699345,
            "precision": 0.8272980501392758,
            "recall": 0.6319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8594686234767223,
            "auditor_fn_violation": 0.021653436276642023,
            "auditor_fp_violation": 0.011379939334317106,
            "ave_precision_score": 0.8596523628013554,
            "fpr": 0.09429824561403509,
            "logloss": 0.5150132975570144,
            "mae": 0.32134050603500536,
            "precision": 0.8013856812933026,
            "recall": 0.7169421487603306
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8424307320403097,
            "auditor_fn_violation": 0.010981619450218378,
            "auditor_fp_violation": 0.011942720739960827,
            "ave_precision_score": 0.8431765044915763,
            "fpr": 0.09659714599341383,
            "logloss": 0.5227279811868105,
            "mae": 0.32650182525751015,
            "precision": 0.7924528301886793,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8559384129835959,
            "auditor_fn_violation": 0.01886689865158765,
            "auditor_fp_violation": 0.01927570093457944,
            "ave_precision_score": 0.8562744551863061,
            "fpr": 0.12828947368421054,
            "logloss": 0.48649327612829796,
            "mae": 0.3114184346989516,
            "precision": 0.7771428571428571,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.861117064840324,
            "auditor_fn_violation": 0.021556858257234277,
            "auditor_fp_violation": 0.014347195153216797,
            "ave_precision_score": 0.8615975903912162,
            "fpr": 0.132821075740944,
            "logloss": 0.4818494721701846,
            "mae": 0.31156447069345267,
            "precision": 0.7641325536062378,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8516840558301467,
            "auditor_fn_violation": 0.010176526025808328,
            "auditor_fp_violation": 0.02053102967699624,
            "ave_precision_score": 0.8519193770180565,
            "fpr": 0.1337719298245614,
            "logloss": 0.5945528527734926,
            "mae": 0.2818562786704748,
            "precision": 0.7530364372469636,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8433290944084386,
            "auditor_fn_violation": 0.014975360254104682,
            "auditor_fp_violation": 0.021309218894290244,
            "ave_precision_score": 0.8446449519616688,
            "fpr": 0.145993413830955,
            "logloss": 0.5821989745882489,
            "mae": 0.2782984053370779,
            "precision": 0.7345309381237525,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8517740820195856,
            "auditor_fn_violation": 0.014723339857909244,
            "auditor_fp_violation": 0.021778672733234958,
            "ave_precision_score": 0.8519777010820664,
            "fpr": 0.15021929824561403,
            "logloss": 0.5903996324317664,
            "mae": 0.2884155027274749,
            "precision": 0.7334630350194552,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.847934479536504,
            "auditor_fn_violation": 0.015484503818576733,
            "auditor_fp_violation": 0.023858061336499474,
            "ave_precision_score": 0.8484831070922707,
            "fpr": 0.15806805708013172,
            "logloss": 0.5883880228102444,
            "mae": 0.28384421798185894,
            "precision": 0.722007722007722,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.870524987908665,
            "auditor_fn_violation": 0.009759678120922143,
            "auditor_fp_violation": 0.020154431054271196,
            "ave_precision_score": 0.8707091238462732,
            "fpr": 0.1524122807017544,
            "logloss": 0.5032926214104736,
            "mae": 0.31066107127627585,
            "precision": 0.7481884057971014,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8472043908253681,
            "auditor_fn_violation": 0.012623490669593852,
            "auditor_fp_violation": 0.01281390712157531,
            "ave_precision_score": 0.8476025195344108,
            "fpr": 0.1712403951701427,
            "logloss": 0.52691344137519,
            "mae": 0.32041527782633294,
            "precision": 0.7219251336898396,
            "recall": 0.8617021276595744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8574776396648955,
            "auditor_fn_violation": 0.010004349717268381,
            "auditor_fp_violation": 0.01752336448598131,
            "ave_precision_score": 0.8576852447692362,
            "fpr": 0.12171052631578948,
            "logloss": 0.5172598601579896,
            "mae": 0.2916899440630611,
            "precision": 0.7692307692307693,
            "recall": 0.7644628099173554
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8500227081848143,
            "auditor_fn_violation": 0.01677838241819838,
            "auditor_fp_violation": 0.02183690893115388,
            "ave_precision_score": 0.8504409542704967,
            "fpr": 0.132821075740944,
            "logloss": 0.5118051703185471,
            "mae": 0.2899357284617055,
            "precision": 0.7494824016563147,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7817581430122,
            "auditor_fn_violation": 0.04698600840945339,
            "auditor_fp_violation": 0.04124139203148057,
            "ave_precision_score": 0.7827486004270968,
            "fpr": 0.1524122807017544,
            "logloss": 0.8916896685482839,
            "mae": 0.309172368362775,
            "precision": 0.7258382642998028,
            "recall": 0.7603305785123967
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7993281050656678,
            "auditor_fn_violation": 0.04652357708386856,
            "auditor_fp_violation": 0.04150331922011396,
            "ave_precision_score": 0.8000284944728352,
            "fpr": 0.14928649835345773,
            "logloss": 0.8195123764162562,
            "mae": 0.30345267166127055,
            "precision": 0.7285429141716567,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8338295280631469,
            "auditor_fn_violation": 0.038644519356241844,
            "auditor_fp_violation": 0.018525065584522056,
            "ave_precision_score": 0.8343940972157732,
            "fpr": 0.0800438596491228,
            "logloss": 0.5336315257594166,
            "mae": 0.30901550861572585,
            "precision": 0.8206388206388207,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8539180431609732,
            "auditor_fn_violation": 0.0338323563070743,
            "auditor_fp_violation": 0.014245141891370525,
            "ave_precision_score": 0.85442073659065,
            "fpr": 0.07025246981339188,
            "logloss": 0.500903006183543,
            "mae": 0.30124943389475006,
            "precision": 0.8379746835443038,
            "recall": 0.7042553191489361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8474059680820202,
            "auditor_fn_violation": 0.019394754965927213,
            "auditor_fp_violation": 0.015350877192982459,
            "ave_precision_score": 0.8476928670858679,
            "fpr": 0.13596491228070176,
            "logloss": 0.5836761267700409,
            "mae": 0.2862318044215882,
            "precision": 0.751503006012024,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8487583228924122,
            "auditor_fn_violation": 0.017773314337763038,
            "auditor_fp_violation": 0.018904744481034276,
            "ave_precision_score": 0.8490004229417498,
            "fpr": 0.1437980241492865,
            "logloss": 0.5808198603046822,
            "mae": 0.28492275661657,
            "precision": 0.741106719367589,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8567675840810485,
            "auditor_fn_violation": 0.016818906771059884,
            "auditor_fp_violation": 0.019214215445154944,
            "ave_precision_score": 0.8569750350346057,
            "fpr": 0.12280701754385964,
            "logloss": 0.5180391851269855,
            "mae": 0.29213428970506994,
            "precision": 0.768595041322314,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8486507127752185,
            "auditor_fn_violation": 0.01677838241819838,
            "auditor_fp_violation": 0.021535727353510014,
            "ave_precision_score": 0.8491652550303701,
            "fpr": 0.132821075740944,
            "logloss": 0.5121429211583303,
            "mae": 0.29011245972848,
            "precision": 0.7494824016563147,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8679479492548454,
            "auditor_fn_violation": 0.01891447368421053,
            "auditor_fp_violation": 0.013137399573700609,
            "ave_precision_score": 0.8681361831077781,
            "fpr": 0.08333333333333333,
            "logloss": 0.48790242443429666,
            "mae": 0.29712164344464165,
            "precision": 0.826879271070615,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8494147536868529,
            "auditor_fn_violation": 0.015166872971016187,
            "auditor_fp_violation": 0.013553170993973882,
            "ave_precision_score": 0.8500843233272815,
            "fpr": 0.10428100987925357,
            "logloss": 0.49402854539713326,
            "mae": 0.302814308457326,
            "precision": 0.7902869757174393,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8634472380526617,
            "auditor_fn_violation": 0.016134732492388,
            "auditor_fp_violation": 0.017103213641580593,
            "ave_precision_score": 0.8636460353701358,
            "fpr": 0.10964912280701754,
            "logloss": 0.5008604319330398,
            "mae": 0.2877509809085607,
            "precision": 0.7920997920997921,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8536939686650631,
            "auditor_fn_violation": 0.011607539061587692,
            "auditor_fp_violation": 0.021182274592969286,
            "ave_precision_score": 0.8541690839216279,
            "fpr": 0.11745334796926454,
            "logloss": 0.4983732492649898,
            "mae": 0.28700486806213127,
            "precision": 0.7756813417190775,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8207446535376607,
            "auditor_fn_violation": 0.021685152965057276,
            "auditor_fp_violation": 0.021012666010821447,
            "ave_precision_score": 0.8211351292063782,
            "fpr": 0.13048245614035087,
            "logloss": 0.5772608408179983,
            "mae": 0.3048263763777326,
            "precision": 0.7546391752577319,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8463708286658933,
            "auditor_fn_violation": 0.02188383118854661,
            "auditor_fp_violation": 0.02770372693534055,
            "ave_precision_score": 0.8466168379522256,
            "fpr": 0.13062568605927552,
            "logloss": 0.539908467790464,
            "mae": 0.29360963426413816,
            "precision": 0.7566462167689162,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8448860173645563,
            "auditor_fn_violation": 0.02127736697114688,
            "auditor_fp_violation": 0.02028508771929825,
            "ave_precision_score": 0.8451278629267616,
            "fpr": 0.13048245614035087,
            "logloss": 0.5921884899575338,
            "mae": 0.2817077165632407,
            "precision": 0.7595959595959596,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.839319721146357,
            "auditor_fn_violation": 0.017030618679496467,
            "auditor_fp_violation": 0.02039571774556878,
            "ave_precision_score": 0.8396053171963132,
            "fpr": 0.1394072447859495,
            "logloss": 0.5880685277706093,
            "mae": 0.28141169430755497,
            "precision": 0.7465069860279441,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8619871868386332,
            "auditor_fn_violation": 0.01798789328693635,
            "auditor_fp_violation": 0.016872643056238725,
            "ave_precision_score": 0.8622275736643525,
            "fpr": 0.11951754385964912,
            "logloss": 0.4847257177224849,
            "mae": 0.3069228413351403,
            "precision": 0.782435129740519,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8523387629798522,
            "auditor_fn_violation": 0.01835252353037346,
            "auditor_fp_violation": 0.013747321101876535,
            "ave_precision_score": 0.8527767783247227,
            "fpr": 0.1141602634467618,
            "logloss": 0.4863979538417487,
            "mae": 0.307334154780901,
            "precision": 0.7864476386036962,
            "recall": 0.8148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8490962320866476,
            "auditor_fn_violation": 0.017543859649122806,
            "auditor_fp_violation": 0.01599903672733236,
            "ave_precision_score": 0.8493174659275065,
            "fpr": 0.10197368421052631,
            "logloss": 0.6120238507196979,
            "mae": 0.28163777358429026,
            "precision": 0.7960526315789473,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8392994781339833,
            "auditor_fn_violation": 0.021320970642501807,
            "auditor_fp_violation": 0.020654584556105644,
            "ave_precision_score": 0.8397692898721567,
            "fpr": 0.1141602634467618,
            "logloss": 0.5765391312883598,
            "mae": 0.28217414605024715,
            "precision": 0.7724288840262582,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8497322579769971,
            "auditor_fn_violation": 0.026116427432216913,
            "auditor_fp_violation": 0.02556259222823414,
            "ave_precision_score": 0.8499248097259844,
            "fpr": 0.1162280701754386,
            "logloss": 0.6738033354010685,
            "mae": 0.29295866394152387,
            "precision": 0.7633928571428571,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8410246552515006,
            "auditor_fn_violation": 0.025947637620571267,
            "auditor_fp_violation": 0.028686922994591177,
            "ave_precision_score": 0.8417445395963594,
            "fpr": 0.12733260153677278,
            "logloss": 0.631348776829624,
            "mae": 0.28818116093349566,
            "precision": 0.7456140350877193,
            "recall": 0.723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6895847406613353,
            "auditor_fn_violation": 0.015794910830796004,
            "auditor_fp_violation": 0.006573823577635679,
            "ave_precision_score": 0.6913742918872829,
            "fpr": 0.046052631578947366,
            "logloss": 2.0104678350593246,
            "mae": 0.45699267557402856,
            "precision": 0.7653631284916201,
            "recall": 0.2830578512396694
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6730462451035214,
            "auditor_fn_violation": 0.0034682485928486427,
            "auditor_fp_violation": 0.005846905172606914,
            "ave_precision_score": 0.6740681788009044,
            "fpr": 0.04939626783754116,
            "logloss": 2.039609461214144,
            "mae": 0.45690066792986767,
            "precision": 0.7352941176470589,
            "recall": 0.26595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7124554611993466,
            "auditor_fn_violation": 0.019082119037262604,
            "auditor_fp_violation": 0.010214276930644367,
            "ave_precision_score": 0.7131773941094554,
            "fpr": 0.051535087719298246,
            "logloss": 3.401172681605492,
            "mae": 0.4530771196921166,
            "precision": 0.7552083333333334,
            "recall": 0.29958677685950413
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6926353885736207,
            "auditor_fn_violation": 0.007940771189013714,
            "auditor_fp_violation": 0.005122575923893157,
            "ave_precision_score": 0.6931505999495825,
            "fpr": 0.05378704720087816,
            "logloss": 3.4631012375122316,
            "mae": 0.45465828370795786,
            "precision": 0.7292817679558011,
            "recall": 0.28085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8489856669221236,
            "auditor_fn_violation": 0.01963942656227346,
            "auditor_fp_violation": 0.011971737170027875,
            "ave_precision_score": 0.849261309998948,
            "fpr": 0.0712719298245614,
            "logloss": 0.5268418867603945,
            "mae": 0.3257243927290434,
            "precision": 0.8350253807106599,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.846381878379157,
            "auditor_fn_violation": 0.011630894270967142,
            "auditor_fp_violation": 0.01010825113067547,
            "ave_precision_score": 0.8468657177006159,
            "fpr": 0.07354555433589462,
            "logloss": 0.5282907736959445,
            "mae": 0.3271526954163369,
            "precision": 0.8189189189189189,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8565363410487222,
            "auditor_fn_violation": 0.008692638103523269,
            "auditor_fp_violation": 0.01672149122807018,
            "ave_precision_score": 0.8567447340784322,
            "fpr": 0.11732456140350878,
            "logloss": 0.560554825719628,
            "mae": 0.279925735607417,
            "precision": 0.7742616033755274,
            "recall": 0.7582644628099173
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8456882132404583,
            "auditor_fn_violation": 0.01363010019384824,
            "auditor_fp_violation": 0.01907151444551476,
            "ave_precision_score": 0.8469948211709039,
            "fpr": 0.1251372118551043,
            "logloss": 0.5483079967549472,
            "mae": 0.2764406982318214,
            "precision": 0.7564102564102564,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 8233,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8562524587909477,
            "auditor_fn_violation": 0.018730969986950848,
            "auditor_fp_violation": 0.006850508280045909,
            "ave_precision_score": 0.8564747271670619,
            "fpr": 0.0712719298245614,
            "logloss": 0.512597474396589,
            "mae": 0.3145168993572026,
            "precision": 0.8387096774193549,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8508525270240945,
            "auditor_fn_violation": 0.007987481607772622,
            "auditor_fp_violation": 0.009042914641158332,
            "ave_precision_score": 0.8514277732220532,
            "fpr": 0.07574094401756312,
            "logloss": 0.5145819669166775,
            "mae": 0.31584204368254437,
            "precision": 0.8198433420365535,
            "recall": 0.6680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8265963556232133,
            "auditor_fn_violation": 0.01797203494272872,
            "auditor_fp_violation": 0.02020823085751763,
            "ave_precision_score": 0.8273139247819343,
            "fpr": 0.1425438596491228,
            "logloss": 0.6191474241349753,
            "mae": 0.2907039846732483,
            "precision": 0.7425742574257426,
            "recall": 0.7747933884297521
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.83633072260528,
            "auditor_fn_violation": 0.01828479342317304,
            "auditor_fp_violation": 0.022820104990404502,
            "ave_precision_score": 0.836528983775952,
            "fpr": 0.15587266739846323,
            "logloss": 0.6046146618011964,
            "mae": 0.2865575210349256,
            "precision": 0.7221135029354208,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8176406980609043,
            "auditor_fn_violation": 0.015523053501522405,
            "auditor_fp_violation": 0.03892031480570587,
            "ave_precision_score": 0.8181379959892238,
            "fpr": 0.19188596491228072,
            "logloss": 0.5992548859342981,
            "mae": 0.33598530476579946,
            "precision": 0.6924428822495606,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8039738049074103,
            "auditor_fn_violation": 0.003951701427003298,
            "auditor_fp_violation": 0.035736065373826086,
            "ave_precision_score": 0.804328421159992,
            "fpr": 0.1986827661909989,
            "logloss": 0.614519593824248,
            "mae": 0.3427387682228326,
            "precision": 0.6750448833034112,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8404453102822189,
            "auditor_fn_violation": 0.0238962592431492,
            "auditor_fp_violation": 0.019608747335628795,
            "ave_precision_score": 0.8407331903480725,
            "fpr": 0.14144736842105263,
            "logloss": 0.5856212178829892,
            "mae": 0.28662633259470266,
            "precision": 0.7495145631067961,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8428134358046347,
            "auditor_fn_violation": 0.02200527827731976,
            "auditor_fp_violation": 0.021431184987716272,
            "ave_precision_score": 0.8430689999322256,
            "fpr": 0.15148188803512624,
            "logloss": 0.5743860596133412,
            "mae": 0.2829446473606667,
            "precision": 0.7366412213740458,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8441488376840321,
            "auditor_fn_violation": 0.020017761345512544,
            "auditor_fp_violation": 0.01967023282505329,
            "ave_precision_score": 0.8443959250450338,
            "fpr": 0.13925438596491227,
            "logloss": 0.5732836241484848,
            "mae": 0.2874066946883032,
            "precision": 0.7548262548262549,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8409671457322634,
            "auditor_fn_violation": 0.01689048742321975,
            "auditor_fp_violation": 0.020659562764000584,
            "ave_precision_score": 0.8413214604552217,
            "fpr": 0.1525795828759605,
            "logloss": 0.5714050844143593,
            "mae": 0.2872575599067404,
            "precision": 0.7357414448669202,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8522953523828992,
            "auditor_fn_violation": 0.02189810787298826,
            "auditor_fp_violation": 0.019770146745368092,
            "ave_precision_score": 0.8525329041842216,
            "fpr": 0.13706140350877194,
            "logloss": 0.5128406470755197,
            "mae": 0.31294588240173954,
            "precision": 0.7605363984674329,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8509442401940157,
            "auditor_fn_violation": 0.01909989023051592,
            "auditor_fp_violation": 0.02451518477863154,
            "ave_precision_score": 0.8511952572066422,
            "fpr": 0.16136114160263446,
            "logloss": 0.5140861197395311,
            "mae": 0.3161637111731552,
            "precision": 0.724202626641651,
            "recall": 0.8212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8405354147529179,
            "auditor_fn_violation": 0.02054108670436422,
            "auditor_fp_violation": 0.022121966715855063,
            "ave_precision_score": 0.8407955172219698,
            "fpr": 0.1524122807017544,
            "logloss": 0.6358460427827839,
            "mae": 0.28656183495705345,
            "precision": 0.7337164750957854,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.855589126452504,
            "auditor_fn_violation": 0.015470490692949066,
            "auditor_fp_violation": 0.02419409036940792,
            "ave_precision_score": 0.8557725750784484,
            "fpr": 0.16794731064763996,
            "logloss": 0.6058727806435159,
            "mae": 0.28120991034168824,
            "precision": 0.7166666666666667,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8292878376408067,
            "auditor_fn_violation": 0.01611207771494853,
            "auditor_fp_violation": 0.012179250696835557,
            "ave_precision_score": 0.8295930073800699,
            "fpr": 0.1600877192982456,
            "logloss": 0.5616343530000834,
            "mae": 0.3354955195993585,
            "precision": 0.7213740458015268,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8120588749320936,
            "auditor_fn_violation": 0.02595230866244716,
            "auditor_fp_violation": 0.011342846688620567,
            "ave_precision_score": 0.8125133563054208,
            "fpr": 0.16136114160263446,
            "logloss": 0.5775021109323926,
            "mae": 0.33563649498946496,
            "precision": 0.7145631067961165,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8678911172381347,
            "auditor_fn_violation": 0.00986842105263158,
            "auditor_fp_violation": 0.03112190523036563,
            "ave_precision_score": 0.8680814356057972,
            "fpr": 0.19736842105263158,
            "logloss": 0.6200120786022939,
            "mae": 0.2957440794845369,
            "precision": 0.7096774193548387,
            "recall": 0.9090909090909091
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8574639826601995,
            "auditor_fn_violation": 0.008856295396688234,
            "auditor_fp_violation": 0.027424947293223916,
            "ave_precision_score": 0.8582262551962699,
            "fpr": 0.2052689352360044,
            "logloss": 0.6166686528525027,
            "mae": 0.29911811193492177,
            "precision": 0.6954397394136808,
            "recall": 0.9085106382978724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8727282124136866,
            "auditor_fn_violation": 0.021630781499202553,
            "auditor_fp_violation": 0.01971378504672897,
            "ave_precision_score": 0.8729459596855551,
            "fpr": 0.12171052631578948,
            "logloss": 0.475757949032555,
            "mae": 0.3066701111342889,
            "precision": 0.7844660194174757,
            "recall": 0.8347107438016529
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8637669218326209,
            "auditor_fn_violation": 0.017124039517014272,
            "auditor_fp_violation": 0.012256347837342037,
            "ave_precision_score": 0.864083456192806,
            "fpr": 0.1141602634467618,
            "logloss": 0.4829038288606999,
            "mae": 0.31129832664334944,
            "precision": 0.7868852459016393,
            "recall": 0.8170212765957446
        }
    }
]