[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8384127781747897,
            "auditor_fn_violation": 0.02220003930396256,
            "auditor_fp_violation": 0.029563591282243618,
            "ave_precision_score": 0.8386472617836217,
            "fpr": 0.14912280701754385,
            "logloss": 0.8683272987493136,
            "mae": 0.27494651894103334,
            "precision": 0.7379576107899807,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8054696268707192,
            "auditor_fn_violation": 0.014850886572323394,
            "auditor_fp_violation": 0.026726909204955317,
            "ave_precision_score": 0.8061762976127744,
            "fpr": 0.1251372118551043,
            "logloss": 0.8615988955676547,
            "mae": 0.2742858240776833,
            "precision": 0.7494505494505495,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7740830330569541,
            "auditor_fn_violation": 0.044605531139457616,
            "auditor_fp_violation": 0.017142767845980747,
            "ave_precision_score": 0.7745480921793199,
            "fpr": 0.1206140350877193,
            "logloss": 0.6867470001059532,
            "mae": 0.38064309572027405,
            "precision": 0.7539149888143176,
            "recall": 0.6863543788187373
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7644618585415788,
            "auditor_fn_violation": 0.03647997951601853,
            "auditor_fp_violation": 0.021164928649835345,
            "ave_precision_score": 0.765582686400589,
            "fpr": 0.10757409440175632,
            "logloss": 0.6246088819291018,
            "mae": 0.37328831595692147,
            "precision": 0.7694117647058824,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7967693040244053,
            "auditor_fn_violation": 0.013428109479401155,
            "auditor_fp_violation": 0.015197212151518941,
            "ave_precision_score": 0.7579990605215079,
            "fpr": 0.15350877192982457,
            "logloss": 2.525734013453066,
            "mae": 0.30113847342082617,
            "precision": 0.7397769516728625,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7933533614215391,
            "auditor_fn_violation": 0.0023423812154303196,
            "auditor_fp_violation": 0.018428042182844603,
            "ave_precision_score": 0.7635038227617117,
            "fpr": 0.141602634467618,
            "logloss": 2.049089656950648,
            "mae": 0.3036916644291228,
            "precision": 0.7435387673956262,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8002759762997198,
            "auditor_fn_violation": 0.007434255189909594,
            "auditor_fp_violation": 0.0012631787306746677,
            "ave_precision_score": 0.8017758460961878,
            "fpr": 0.006578947368421052,
            "logloss": 3.2791284776552154,
            "mae": 0.39830501723754586,
            "precision": 0.9552238805970149,
            "recall": 0.2606924643584521
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7361790440427849,
            "auditor_fn_violation": 0.014753682493545422,
            "auditor_fp_violation": 0.002589873765093304,
            "ave_precision_score": 0.7381398963662915,
            "fpr": 0.009879253567508232,
            "logloss": 3.506052918850718,
            "mae": 0.3970998519185179,
            "precision": 0.9291338582677166,
            "recall": 0.2548596112311015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8291616553925895,
            "auditor_fn_violation": 0.0014247686425840642,
            "auditor_fp_violation": 0.01042838688169355,
            "ave_precision_score": 0.7619128484979845,
            "fpr": 0.07236842105263158,
            "logloss": 0.5394651895955632,
            "mae": 0.3594761432655025,
            "precision": 0.835,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.793188960279259,
            "auditor_fn_violation": 0.0042058545305398674,
            "auditor_fp_violation": 0.005593833307197745,
            "ave_precision_score": 0.7219884226779933,
            "fpr": 0.07135016465422613,
            "logloss": 0.5560714623367101,
            "mae": 0.37023720321880343,
            "precision": 0.8184357541899442,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6200169833843593,
            "auditor_fn_violation": 0.01355316754207311,
            "auditor_fp_violation": 0.02296380797599701,
            "ave_precision_score": 0.5825417453024418,
            "fpr": 0.32894736842105265,
            "logloss": 0.6574675382390597,
            "mae": 0.459042079035977,
            "precision": 0.601593625498008,
            "recall": 0.9226069246435845
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6093584142147249,
            "auditor_fn_violation": 0.0004741662379413588,
            "auditor_fp_violation": 0.026241767288693756,
            "ave_precision_score": 0.5694951571609956,
            "fpr": 0.34577387486278816,
            "logloss": 0.648782885033087,
            "mae": 0.4560750970937941,
            "precision": 0.5766129032258065,
            "recall": 0.9265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8785840974262911,
            "auditor_fn_violation": 0.01443304034015793,
            "auditor_fp_violation": 0.018004854773513355,
            "ave_precision_score": 0.8708675993310747,
            "fpr": 0.07675438596491228,
            "logloss": 0.4697208193575138,
            "mae": 0.30958029749525484,
            "precision": 0.8401826484018264,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8472101800947884,
            "auditor_fn_violation": 0.018983245335982342,
            "auditor_fp_violation": 0.01027128743923475,
            "ave_precision_score": 0.8377261177696506,
            "fpr": 0.08781558726673985,
            "logloss": 0.49562772446661635,
            "mae": 0.3189194223564425,
            "precision": 0.8014888337468983,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6933223652507932,
            "auditor_fn_violation": 0.00215278522171008,
            "auditor_fp_violation": 0.0012527607617618885,
            "ave_precision_score": 0.6704814319331974,
            "fpr": 0.42214912280701755,
            "logloss": 3.1125958101709115,
            "mae": 0.42585877865030053,
            "precision": 0.5569620253164557,
            "recall": 0.9857433808553971
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6361533290354802,
            "auditor_fn_violation": 0.0034116260819880844,
            "auditor_fp_violation": 0.004939626783754113,
            "ave_precision_score": 0.6136577518175479,
            "fpr": 0.45773874862788144,
            "logloss": 3.3884547923254913,
            "mae": 0.46070981271049716,
            "precision": 0.522883295194508,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7939273900974751,
            "auditor_fn_violation": 0.0006275234930503495,
            "auditor_fp_violation": 0.014861232654081765,
            "ave_precision_score": 0.7734683209819433,
            "fpr": 0.12609649122807018,
            "logloss": 0.5571748309614882,
            "mae": 0.37694915640576365,
            "precision": 0.7532188841201717,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7686476994783035,
            "auditor_fn_violation": 0.00463260414468709,
            "auditor_fp_violation": 0.017043672573310336,
            "ave_precision_score": 0.7496063348152989,
            "fpr": 0.1163556531284303,
            "logloss": 0.568842616281957,
            "mae": 0.3859589586502634,
            "precision": 0.7494089834515366,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.788154395224343,
            "auditor_fn_violation": 0.015268249544431341,
            "auditor_fp_violation": 0.036369129474517654,
            "ave_precision_score": 0.6192737415718049,
            "fpr": 0.27960526315789475,
            "logloss": 0.6379677525105375,
            "mae": 0.44804514679861696,
            "precision": 0.6298984034833092,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7721890769391072,
            "auditor_fn_violation": 0.004713212405137116,
            "auditor_fp_violation": 0.040254527991218446,
            "ave_precision_score": 0.5922917095177989,
            "fpr": 0.29308452250274425,
            "logloss": 0.6389980251700489,
            "mae": 0.44793158282171097,
            "precision": 0.6038575667655787,
            "recall": 0.8790496760259179
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6932311344037901,
            "auditor_fn_violation": 0.005491388859113169,
            "auditor_fp_violation": 0.0009271992332374901,
            "ave_precision_score": 0.6889248862432352,
            "fpr": 0.039473684210526314,
            "logloss": 0.6911419202464797,
            "mae": 0.44865644226471585,
            "precision": 0.7272727272727273,
            "recall": 0.1955193482688391
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6785031322322868,
            "auditor_fn_violation": 0.004383666869767886,
            "auditor_fp_violation": 0.0056256860592755215,
            "ave_precision_score": 0.6749349891272968,
            "fpr": 0.04610318331503842,
            "logloss": 0.6602699233843036,
            "mae": 0.4373308589802615,
            "precision": 0.6956521739130435,
            "recall": 0.20734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8373299449837863,
            "auditor_fn_violation": 0.006342230321220566,
            "auditor_fp_violation": 0.011048256032004003,
            "ave_precision_score": 0.8021417308369523,
            "fpr": 0.08333333333333333,
            "logloss": 0.5191092082362696,
            "mae": 0.34820517864927913,
            "precision": 0.8295964125560538,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8029931929397269,
            "auditor_fn_violation": 0.0006069327845649521,
            "auditor_fp_violation": 0.011319978046103185,
            "ave_precision_score": 0.761082520640233,
            "fpr": 0.09220636663007684,
            "logloss": 0.5567479245520128,
            "mae": 0.3665152332458224,
            "precision": 0.7925925925925926,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.40813445050204233,
            "auditor_fn_violation": 0.0015520598849465856,
            "auditor_fp_violation": 0.009759032379047381,
            "ave_precision_score": 0.589672329992849,
            "fpr": 0.30153508771929827,
            "logloss": 0.6804274340109191,
            "mae": 0.4785811998146145,
            "precision": 0.5788667687595712,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.46161264924589857,
            "auditor_fn_violation": 0.004229562842436928,
            "auditor_fp_violation": 0.0009604829857299798,
            "ave_precision_score": 0.5636139787257394,
            "fpr": 0.3227222832052689,
            "logloss": 0.6884095974637087,
            "mae": 0.4822516570237806,
            "precision": 0.5462962962962963,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6771437346581393,
            "auditor_fn_violation": 0.008235966698824456,
            "auditor_fp_violation": 0.029717256323707135,
            "ave_precision_score": 0.6788072568618088,
            "fpr": 0.32456140350877194,
            "logloss": 0.7795375920458691,
            "mae": 0.4220723251632431,
            "precision": 0.6115485564304461,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.6143430783859563,
            "auditor_fn_violation": 0.0036226300578719906,
            "auditor_fp_violation": 0.03120834640112907,
            "ave_precision_score": 0.615904074209936,
            "fpr": 0.3391877058177827,
            "logloss": 0.8316428724994221,
            "mae": 0.44323461498701217,
            "precision": 0.5835579514824798,
            "recall": 0.9352051835853131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8710925976246285,
            "auditor_fn_violation": 0.004611516061028336,
            "auditor_fp_violation": 0.010662791182231113,
            "ave_precision_score": 0.8642041968421005,
            "fpr": 0.08662280701754387,
            "logloss": 1.8878903104591491,
            "mae": 0.22328042960322103,
            "precision": 0.8259911894273128,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8310008783690392,
            "auditor_fn_violation": 0.0009554449694518446,
            "auditor_fp_violation": 0.011339579739689512,
            "ave_precision_score": 0.8203411747700158,
            "fpr": 0.10208562019758508,
            "logloss": 2.257136231144557,
            "mae": 0.25608148237012396,
            "precision": 0.777511961722488,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7538657042914544,
            "auditor_fn_violation": 0.026277825418944523,
            "auditor_fp_violation": 0.003948410217943911,
            "ave_precision_score": 0.7288470392397257,
            "fpr": 0.07675438596491228,
            "logloss": 0.6243745920258814,
            "mae": 0.39841904520800564,
            "precision": 0.77491961414791,
            "recall": 0.4908350305498982
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7598931381247754,
            "auditor_fn_violation": 0.011832818467826644,
            "auditor_fp_violation": 0.006821389368041401,
            "ave_precision_score": 0.7272395523024143,
            "fpr": 0.07464324917672886,
            "logloss": 0.6043746848879022,
            "mae": 0.3851116160288633,
            "precision": 0.7733333333333333,
            "recall": 0.5010799136069114
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 21924,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7636213122347126,
            "auditor_fn_violation": 0.01635580805373924,
            "auditor_fp_violation": 0.018614305954911033,
            "ave_precision_score": 0.759733569684631,
            "fpr": 0.14035087719298245,
            "logloss": 1.167678168361529,
            "mae": 0.2872494341714237,
            "precision": 0.7450199203187251,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7512450382249936,
            "auditor_fn_violation": 0.00871991711574161,
            "auditor_fp_violation": 0.015240316763368355,
            "ave_precision_score": 0.7450478730149382,
            "fpr": 0.12952799121844127,
            "logloss": 1.2387733631330409,
            "mae": 0.28703479579148555,
            "precision": 0.7412280701754386,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8770198108094858,
            "auditor_fn_violation": 0.0027468110194018786,
            "auditor_fp_violation": 0.002984748093511691,
            "ave_precision_score": 0.877183934926804,
            "fpr": 0.03508771929824561,
            "logloss": 0.5856484484147594,
            "mae": 0.34831050288273235,
            "precision": 0.8904109589041096,
            "recall": 0.5295315682281059
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8211734180002787,
            "auditor_fn_violation": 0.002415876982311245,
            "auditor_fp_violation": 0.004400580210130158,
            "ave_precision_score": 0.8216087870875526,
            "fpr": 0.03951701427003293,
            "logloss": 0.6309465414391503,
            "mae": 0.3578018626478285,
            "precision": 0.8636363636363636,
            "recall": 0.4924406047516199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8479185627990327,
            "auditor_fn_violation": 0.018352270697109378,
            "auditor_fp_violation": 0.0075295870317122985,
            "ave_precision_score": 0.8462919116007146,
            "fpr": 0.05592105263157895,
            "logloss": 0.5358029964315452,
            "mae": 0.33191741814248654,
            "precision": 0.864,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8245074498152682,
            "auditor_fn_violation": 0.01598888554338266,
            "auditor_fp_violation": 0.009908656107887723,
            "ave_precision_score": 0.8223115314622098,
            "fpr": 0.0570801317233809,
            "logloss": 0.5529645554309818,
            "mae": 0.338085946795642,
            "precision": 0.8409785932721713,
            "recall": 0.593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7893150235925754,
            "auditor_fn_violation": 0.010277092936006009,
            "auditor_fp_violation": 0.022432491561445184,
            "ave_precision_score": 0.7334903894062041,
            "fpr": 0.15570175438596492,
            "logloss": 5.717304390802222,
            "mae": 0.31655030522100924,
            "precision": 0.7096114519427403,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7663439171563365,
            "auditor_fn_violation": 0.014130153890652525,
            "auditor_fp_violation": 0.017259291202759916,
            "ave_precision_score": 0.7108528514673405,
            "fpr": 0.15477497255762898,
            "logloss": 5.874905267755976,
            "mae": 0.31187742952893455,
            "precision": 0.6961206896551724,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6199304633366186,
            "auditor_fn_violation": 0.0024922285346768154,
            "auditor_fp_violation": 0.003466579155727806,
            "ave_precision_score": 0.5378667348218871,
            "fpr": 0.43640350877192985,
            "logloss": 6.777244930156933,
            "mae": 0.45574755459158933,
            "precision": 0.5466970387243736,
            "recall": 0.9775967413441955
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6022186188864705,
            "auditor_fn_violation": 0.0004955037186487215,
            "auditor_fp_violation": 0.0034842010349694216,
            "ave_precision_score": 0.5229349092741207,
            "fpr": 0.4621295279912184,
            "logloss": 6.596061357841377,
            "mae": 0.4709805138940738,
            "precision": 0.5210466439135382,
            "recall": 0.9892008639308856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 21924,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.5900112668606943,
            "auditor_fn_violation": 0.004162646943223674,
            "auditor_fp_violation": 0.00019012793265824898,
            "ave_precision_score": 0.5419221912154293,
            "fpr": 0.007675438596491228,
            "logloss": 18.34122494776857,
            "mae": 0.5328947365153254,
            "precision": 0.631578947368421,
            "recall": 0.024439918533604887
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5607708013435764,
            "auditor_fn_violation": 0.002157456382633196,
            "auditor_fp_violation": 0.0023718049239454296,
            "ave_precision_score": 0.5149961263252618,
            "fpr": 0.006586169045005488,
            "logloss": 17.329165555063323,
            "mae": 0.5049396232506577,
            "precision": 0.6,
            "recall": 0.019438444924406047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.762475269681212,
            "mae": 0.4734630063502935,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7500918453269436,
            "mae": 0.46324364265220486,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.6333619788580727,
            "auditor_fn_violation": 0.006058616500518103,
            "auditor_fp_violation": 0.012467704296370384,
            "ave_precision_score": 0.6196386175800825,
            "fpr": 0.08223684210526316,
            "logloss": 0.8766027716997158,
            "mae": 0.472431049098081,
            "precision": 0.563953488372093,
            "recall": 0.1975560081466395
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.620962575797785,
            "auditor_fn_violation": 0.008402225736320908,
            "auditor_fp_violation": 0.015269719303747844,
            "ave_precision_score": 0.5979736855265986,
            "fpr": 0.08562019758507135,
            "logloss": 0.8483497931828258,
            "mae": 0.45292384412986125,
            "precision": 0.5873015873015873,
            "recall": 0.23974082073434125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.799674681568363,
            "auditor_fn_violation": 0.026601636474077248,
            "auditor_fp_violation": 0.027201316831270576,
            "ave_precision_score": 0.7998408684834597,
            "fpr": 0.18201754385964913,
            "logloss": 0.9146409986895252,
            "mae": 0.29728103853016574,
            "precision": 0.7137931034482758,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7933257406561263,
            "auditor_fn_violation": 0.02202502175237617,
            "auditor_fp_violation": 0.024482515289321,
            "ave_precision_score": 0.7940839801786445,
            "fpr": 0.1734357848518112,
            "logloss": 0.7651386594644742,
            "mae": 0.2976302881188923,
            "precision": 0.7084870848708487,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7789941216929066,
            "auditor_fn_violation": 0.013689391503197916,
            "auditor_fp_violation": 0.02863899654123433,
            "ave_precision_score": 0.6956474519897586,
            "fpr": 0.16447368421052633,
            "logloss": 6.241698921668274,
            "mae": 0.2950477657192582,
            "precision": 0.7237569060773481,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7548953766503171,
            "auditor_fn_violation": 0.008881133636641675,
            "auditor_fp_violation": 0.01929541712403952,
            "ave_precision_score": 0.6729336544221559,
            "fpr": 0.17233809001097694,
            "logloss": 6.436325528089597,
            "mae": 0.3069858120654355,
            "precision": 0.700381679389313,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4375,
            "auc_prc": 0.4988902470441951,
            "auditor_fn_violation": 0.005259138171293824,
            "auditor_fp_violation": 0.0040760303371254756,
            "ave_precision_score": 0.5000829574541191,
            "fpr": 0.07346491228070176,
            "logloss": 12.19328149369209,
            "mae": 0.5542407264022091,
            "precision": 0.4017857142857143,
            "recall": 0.09164969450101833
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.4708597328946138,
            "auditor_fn_violation": 0.005995832078768506,
            "auditor_fp_violation": 0.010153677277716796,
            "ave_precision_score": 0.4716009277081151,
            "fpr": 0.06147091108671789,
            "logloss": 11.759937936375986,
            "mae": 0.5309195588071934,
            "precision": 0.3978494623655914,
            "recall": 0.07991360691144708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7237502320057664,
            "auditor_fn_violation": 0.02943777468110194,
            "auditor_fp_violation": 0.06631297662207776,
            "ave_precision_score": 0.7241238426165573,
            "fpr": 0.34539473684210525,
            "logloss": 0.6875961401148297,
            "mae": 0.4141758433134671,
            "precision": 0.5893089960886571,
            "recall": 0.9205702647657841
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7192984007400186,
            "auditor_fn_violation": 0.024791781750764002,
            "auditor_fp_violation": 0.0752165987141289,
            "ave_precision_score": 0.716524336833337,
            "fpr": 0.3578485181119649,
            "logloss": 0.6922222315349742,
            "mae": 0.4179356169164115,
            "precision": 0.5676392572944297,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6212138729855343,
            "auditor_fn_violation": 0.020766337942616217,
            "auditor_fp_violation": 0.024602033587531786,
            "ave_precision_score": 0.6044985750920879,
            "fpr": 0.20723684210526316,
            "logloss": 2.640082623536623,
            "mae": 0.3990195180953044,
            "precision": 0.6420454545454546,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6003712417202804,
            "auditor_fn_violation": 0.015555023435666313,
            "auditor_fp_violation": 0.019273365218754893,
            "ave_precision_score": 0.5825779474689416,
            "fpr": 0.20087815587266739,
            "logloss": 2.6383670034811426,
            "mae": 0.39298132293266164,
            "precision": 0.6376237623762376,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8727744135398136,
            "auditor_fn_violation": 0.0040755529352913935,
            "auditor_fp_violation": 0.0077223194565987415,
            "ave_precision_score": 0.8729327925094064,
            "fpr": 0.039473684210526314,
            "logloss": 0.5267838818809663,
            "mae": 0.36390475079972756,
            "precision": 0.8791946308724832,
            "recall": 0.5336048879837068
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8252411931441258,
            "auditor_fn_violation": 0.0025059685675200864,
            "auditor_fp_violation": 0.00588050807589776,
            "ave_precision_score": 0.8257053390584264,
            "fpr": 0.043907793633369926,
            "logloss": 0.5545369129732614,
            "mae": 0.3733753850836916,
            "precision": 0.8507462686567164,
            "recall": 0.4924406047516199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6389612158824608,
            "auditor_fn_violation": 0.009236431200200108,
            "auditor_fp_violation": 0.012024940617577197,
            "ave_precision_score": 0.7213643458066119,
            "fpr": 0.10307017543859649,
            "logloss": 0.6468179296573667,
            "mae": 0.3968841684655401,
            "precision": 0.7777777777777778,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.579116616087118,
            "auditor_fn_violation": 0.004246158660764886,
            "auditor_fp_violation": 0.007076211384663637,
            "ave_precision_score": 0.6757576732832843,
            "fpr": 0.1119648737650933,
            "logloss": 0.667308093593559,
            "mae": 0.40436075577097325,
            "precision": 0.7404580152671756,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7528905284909093,
            "auditor_fn_violation": 0.014723353699932116,
            "auditor_fp_violation": 0.022007959328249366,
            "ave_precision_score": 0.733410909949801,
            "fpr": 0.1524122807017544,
            "logloss": 1.9321551934688403,
            "mae": 0.3840462919978196,
            "precision": 0.7104166666666667,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.738831160910339,
            "auditor_fn_violation": 0.013795866692903868,
            "auditor_fp_violation": 0.017136780617845387,
            "ave_precision_score": 0.7228996693344203,
            "fpr": 0.15148188803512624,
            "logloss": 1.6686009371939126,
            "mae": 0.39147266523113106,
            "precision": 0.6946902654867256,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7945051976928026,
            "auditor_fn_violation": 0.01170632793797121,
            "auditor_fp_violation": 0.017629807892653247,
            "ave_precision_score": 0.7545729499288235,
            "fpr": 0.12828947368421054,
            "logloss": 2.609975663295061,
            "mae": 0.2915013696168133,
            "precision": 0.7572614107883817,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7906152054517035,
            "auditor_fn_violation": 0.011481935451750037,
            "auditor_fp_violation": 0.011251372118551043,
            "ave_precision_score": 0.7606882034695988,
            "fpr": 0.12294182217343579,
            "logloss": 2.1075274475776884,
            "mae": 0.2894269197849039,
            "precision": 0.7533039647577092,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.866506915771676,
            "auditor_fn_violation": 0.008758530746417978,
            "auditor_fp_violation": 0.012353106638329794,
            "ave_precision_score": 0.8503062518256445,
            "fpr": 0.07456140350877193,
            "logloss": 0.4880866782333688,
            "mae": 0.31330819764550316,
            "precision": 0.8361445783132531,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8379292097217887,
            "auditor_fn_violation": 0.009407458160756589,
            "auditor_fp_violation": 0.008066096910773092,
            "ave_precision_score": 0.819709262104004,
            "fpr": 0.08122941822173436,
            "logloss": 0.5111282064472706,
            "mae": 0.3251129442787066,
            "precision": 0.8087855297157622,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7402593682405473,
            "auditor_fn_violation": 0.010174366670239757,
            "auditor_fp_violation": 0.02290650914697671,
            "ave_precision_score": 0.6754847557988591,
            "fpr": 0.16447368421052633,
            "logloss": 0.616741063051652,
            "mae": 0.44263975204605804,
            "precision": 0.7242647058823529,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6986579565408935,
            "auditor_fn_violation": 0.009080283456577045,
            "auditor_fp_violation": 0.020513172338090017,
            "ave_precision_score": 0.636070253705361,
            "fpr": 0.17233809001097694,
            "logloss": 0.6261338330102635,
            "mae": 0.44730846359753323,
            "precision": 0.6963249516441006,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8269491928554562,
            "auditor_fn_violation": 0.009785793404080468,
            "auditor_fp_violation": 0.010670604658915698,
            "ave_precision_score": 0.8079259382992922,
            "fpr": 0.0712719298245614,
            "logloss": 0.5006427058212048,
            "mae": 0.3236448094085382,
            "precision": 0.8495370370370371,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7669145098226405,
            "auditor_fn_violation": 0.002631622620574547,
            "auditor_fp_violation": 0.010085071350164657,
            "ave_precision_score": 0.7808595025987152,
            "fpr": 0.09220636663007684,
            "logloss": 0.5380354775797666,
            "mae": 0.34129201884163723,
            "precision": 0.7931034482758621,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7880311985323086,
            "auditor_fn_violation": 0.022557348054453856,
            "auditor_fp_violation": 0.021898570654665165,
            "ave_precision_score": 0.7689021983581801,
            "fpr": 0.14583333333333334,
            "logloss": 2.2743936275945202,
            "mae": 0.2947896785839419,
            "precision": 0.7302231237322515,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7814142901007122,
            "auditor_fn_violation": 0.013888329109302438,
            "auditor_fp_violation": 0.022468441273326017,
            "ave_precision_score": 0.7656428396797212,
            "fpr": 0.13062568605927552,
            "logloss": 2.0416064718139095,
            "mae": 0.2878253155113017,
            "precision": 0.7367256637168141,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6301360130123351,
            "auditor_fn_violation": 0.008419087433451246,
            "auditor_fp_violation": 0.026063153727549276,
            "ave_precision_score": 0.6673205384101505,
            "fpr": 0.16776315789473684,
            "logloss": 0.6292857382339333,
            "mae": 0.435073958742514,
            "precision": 0.697029702970297,
            "recall": 0.7169042769857433
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.674269334360984,
            "auditor_fn_violation": 0.0154815276687854,
            "auditor_fp_violation": 0.01895483769797711,
            "ave_precision_score": 0.6715254463304537,
            "fpr": 0.1668496158068057,
            "logloss": 0.6160764716151288,
            "mae": 0.42958669155083684,
            "precision": 0.6833333333333333,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7192332050501407,
            "auditor_fn_violation": 0.014205256011719729,
            "auditor_fp_violation": 0.026722090261282666,
            "ave_precision_score": 0.7229827852463673,
            "fpr": 0.09100877192982457,
            "logloss": 0.6222323545647843,
            "mae": 0.3369728475155538,
            "precision": 0.8056206088992974,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7157066971366692,
            "auditor_fn_violation": 0.005896257168800814,
            "auditor_fp_violation": 0.017920848361298414,
            "ave_precision_score": 0.7172751317923414,
            "fpr": 0.09440175631174534,
            "logloss": 0.6234820114158048,
            "mae": 0.34899192491523784,
            "precision": 0.7789203084832905,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8083037282762603,
            "auditor_fn_violation": 0.006201540000714622,
            "auditor_fp_violation": 0.00838906946701671,
            "ave_precision_score": 0.8079069212680504,
            "fpr": 0.05592105263157895,
            "logloss": 0.6401231604348314,
            "mae": 0.3713452180309743,
            "precision": 0.8473053892215568,
            "recall": 0.5763747454175153
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7695932126005399,
            "auditor_fn_violation": 0.004551995884237054,
            "auditor_fp_violation": 0.00883546338403638,
            "ave_precision_score": 0.7704985420279301,
            "fpr": 0.06695938529088913,
            "logloss": 0.667033313048297,
            "mae": 0.37041983180605265,
            "precision": 0.8081761006289309,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8638160316385666,
            "auditor_fn_violation": 0.020706042090970808,
            "auditor_fp_violation": 0.01622598658165604,
            "ave_precision_score": 0.8534916560053909,
            "fpr": 0.09978070175438597,
            "logloss": 0.4914769222458306,
            "mae": 0.32794312565799866,
            "precision": 0.8100208768267223,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8369921080015026,
            "auditor_fn_violation": 0.014986023950136679,
            "auditor_fp_violation": 0.0067429825936961,
            "ave_precision_score": 0.8262281066642467,
            "fpr": 0.10537870472008781,
            "logloss": 0.5239120108444878,
            "mae": 0.3459226151623658,
            "precision": 0.7762237762237763,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.5971879997289602,
            "auditor_fn_violation": 0.09441883731732591,
            "auditor_fp_violation": 0.0908863607950994,
            "ave_precision_score": 0.594430157615012,
            "fpr": 0.2642543859649123,
            "logloss": 0.7170705144195338,
            "mae": 0.47492373641478225,
            "precision": 0.5929054054054054,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5811826363234321,
            "auditor_fn_violation": 0.09751939932620977,
            "auditor_fp_violation": 0.10359985102712875,
            "ave_precision_score": 0.5866502492632943,
            "fpr": 0.2667398463227223,
            "logloss": 0.7079741059528023,
            "mae": 0.471026861492205,
            "precision": 0.5729349736379613,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.5191472819619235,
            "auditor_fn_violation": 0.0018490727837924708,
            "auditor_fp_violation": 0.0020445263991332252,
            "ave_precision_score": 0.5735650294938016,
            "fpr": 0.006578947368421052,
            "logloss": 0.7325452477497099,
            "mae": 0.5053051582684642,
            "precision": 0.3333333333333333,
            "recall": 0.006109979633401222
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.48813835788355714,
            "auditor_fn_violation": 3.556246784562036e-05,
            "auditor_fp_violation": 0.0022835973028069627,
            "ave_precision_score": 0.5284480858461408,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7214767471812172,
            "mae": 0.5003755019014675,
            "precision": 0.3333333333333333,
            "recall": 0.004319654427645789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.853779420823708,
            "auditor_fn_violation": 0.011297656054596782,
            "auditor_fp_violation": 0.00759990832187357,
            "ave_precision_score": 0.853976957933208,
            "fpr": 0.039473684210526314,
            "logloss": 0.6051711719885742,
            "mae": 0.3411101242670332,
            "precision": 0.886435331230284,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8043352771945046,
            "auditor_fn_violation": 0.014059028954961323,
            "auditor_fp_violation": 0.008605143484397055,
            "ave_precision_score": 0.8048620470042148,
            "fpr": 0.03951701427003293,
            "logloss": 0.6530298096911441,
            "mae": 0.3496573937729177,
            "precision": 0.8705035971223022,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7788918151691605,
            "auditor_fn_violation": 0.004495390717118669,
            "auditor_fp_violation": 0.008751093886735844,
            "ave_precision_score": 0.7247550732571624,
            "fpr": 0.07456140350877193,
            "logloss": 0.5912998290879605,
            "mae": 0.39246476166309757,
            "precision": 0.8147138964577657,
            "recall": 0.6089613034623218
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7539937269371333,
            "auditor_fn_violation": 0.001448577856910855,
            "auditor_fp_violation": 0.014610612356907639,
            "ave_precision_score": 0.6990840259008746,
            "fpr": 0.08232711306256861,
            "logloss": 0.625411003399874,
            "mae": 0.40415535973534233,
            "precision": 0.7851002865329513,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.862067027767658,
            "auditor_fn_violation": 0.0016905170257619662,
            "auditor_fp_violation": 0.007803058715672794,
            "ave_precision_score": 0.8530491422470854,
            "fpr": 0.05921052631578947,
            "logloss": 0.48626796064922934,
            "mae": 0.3014675980370508,
            "precision": 0.8679706601466992,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8296261084829873,
            "auditor_fn_violation": 0.006740273072336443,
            "auditor_fp_violation": 0.009639132821075742,
            "ave_precision_score": 0.8217532759962157,
            "fpr": 0.07244785949506037,
            "logloss": 0.534842974353741,
            "mae": 0.31937225694685323,
            "precision": 0.8253968253968254,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.7720091024404188,
            "auditor_fn_violation": 0.0021326866044949567,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5440182048808375,
            "fpr": 0.0,
            "logloss": 0.688754089170941,
            "mae": 0.4968428520257013,
            "precision": 1.0,
            "recall": 0.012219959266802444
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.685874181343523,
            "auditor_fn_violation": 0.0018468774967816065,
            "auditor_fp_violation": 0.0005708993257017407,
            "ave_precision_score": 0.5127542250751979,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6925407810475788,
            "mae": 0.4973434085510957,
            "precision": 0.8571428571428571,
            "recall": 0.012958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7936723130179579,
            "auditor_fn_violation": 0.012525904884410617,
            "auditor_fp_violation": 0.02424261366004084,
            "ave_precision_score": 0.7939926908790372,
            "fpr": 0.15570175438596492,
            "logloss": 1.1520372655551805,
            "mae": 0.3039745463460981,
            "precision": 0.72265625,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7701586331389663,
            "auditor_fn_violation": 0.012352030498372434,
            "auditor_fp_violation": 0.020699388427160112,
            "ave_precision_score": 0.7705985742566248,
            "fpr": 0.14928649835345773,
            "logloss": 1.1658508467047497,
            "mae": 0.3109467982910146,
            "precision": 0.7062634989200864,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8708256700858462,
            "auditor_fn_violation": 0.021000821810126125,
            "auditor_fp_violation": 0.023841521856898782,
            "ave_precision_score": 0.8711710696232333,
            "fpr": 0.09978070175438597,
            "logloss": 0.4732906913560522,
            "mae": 0.3200579138448168,
            "precision": 0.8055555555555556,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8409414614701036,
            "auditor_fn_violation": 0.017688771506402433,
            "auditor_fp_violation": 0.024357554492708173,
            "ave_precision_score": 0.8414203074903062,
            "fpr": 0.09549945115257959,
            "logloss": 0.4984999557457554,
            "mae": 0.33506753975456494,
            "precision": 0.795774647887324,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.6355619849928553,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010313789223652958,
            "ave_precision_score": 0.6372310132363248,
            "fpr": 0.0021929824561403508,
            "logloss": 0.9555993209268854,
            "mae": 0.4971929606505447,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6493668910975465,
            "auditor_fn_violation": 0.0025367893729862957,
            "auditor_fp_violation": 0.0005341461502273797,
            "ave_precision_score": 0.6505254911437194,
            "fpr": 0.0010976948408342481,
            "logloss": 0.8854182191568268,
            "mae": 0.4729199500064346,
            "precision": 0.8333333333333334,
            "recall": 0.01079913606911447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.6336007931840905,
            "auditor_fn_violation": 0.022865526851752593,
            "auditor_fp_violation": 0.0203098303954661,
            "ave_precision_score": 0.6399890662434258,
            "fpr": 0.08333333333333333,
            "logloss": 0.7847520511401286,
            "mae": 0.47536478177930247,
            "precision": 0.6180904522613065,
            "recall": 0.2505091649694501
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.620306208289581,
            "auditor_fn_violation": 0.02398332831507399,
            "auditor_fp_violation": 0.021228634153990903,
            "ave_precision_score": 0.6174562064662059,
            "fpr": 0.08562019758507135,
            "logloss": 0.7657402519563974,
            "mae": 0.46437587287853566,
            "precision": 0.6119402985074627,
            "recall": 0.265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.718867677872683,
            "auditor_fn_violation": 0.006913924322006651,
            "auditor_fp_violation": 0.02301068883610452,
            "ave_precision_score": 0.7195253348920593,
            "fpr": 0.1787280701754386,
            "logloss": 0.8141369573196888,
            "mae": 0.40004174091950934,
            "precision": 0.693609022556391,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7008875727850787,
            "auditor_fn_violation": 0.010872631835995383,
            "auditor_fp_violation": 0.02232632899482516,
            "ave_precision_score": 0.7017580417997277,
            "fpr": 0.18880351262349068,
            "logloss": 0.791227269608288,
            "mae": 0.3942133638492434,
            "precision": 0.6587301587301587,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8315715318344742,
            "auditor_fn_violation": 0.0074186229320756065,
            "auditor_fp_violation": 0.007852544068008503,
            "ave_precision_score": 0.7958894316451044,
            "fpr": 0.0537280701754386,
            "logloss": 0.5730946594793602,
            "mae": 0.36178660016964403,
            "precision": 0.8653846153846154,
            "recall": 0.6415478615071283
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7845025710175494,
            "auditor_fn_violation": 0.006735531409957023,
            "auditor_fp_violation": 0.005789850243061002,
            "ave_precision_score": 0.7501304028201471,
            "fpr": 0.05817782656421515,
            "logloss": 0.6024805727652947,
            "mae": 0.36976313772565317,
            "precision": 0.8364197530864198,
            "recall": 0.5853131749460043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8191374398862017,
            "auditor_fn_violation": 0.009245363918962378,
            "auditor_fp_violation": 0.010662791182231113,
            "ave_precision_score": 0.7921845391420688,
            "fpr": 0.08662280701754387,
            "logloss": 0.5245547907013117,
            "mae": 0.36082592256890056,
            "precision": 0.8244444444444444,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7567610984428206,
            "auditor_fn_violation": 0.004004333879414788,
            "auditor_fp_violation": 0.010364395483769797,
            "ave_precision_score": 0.7285467134240307,
            "fpr": 0.09549945115257959,
            "logloss": 0.5569494275013386,
            "mae": 0.3757242176325994,
            "precision": 0.7872860635696821,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 21924,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5599584010797913,
            "auditor_fn_violation": 0.003870100403758889,
            "auditor_fp_violation": 0.009199066549985431,
            "ave_precision_score": 0.5616329128608876,
            "fpr": 0.4276315789473684,
            "logloss": 0.7330379286095142,
            "mae": 0.49057243192535743,
            "precision": 0.5496535796766744,
            "recall": 0.9694501018329938
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5262391947293027,
            "auditor_fn_violation": 0.00600057374114791,
            "auditor_fp_violation": 0.011591951544613462,
            "ave_precision_score": 0.5275408028567585,
            "fpr": 0.4621295279912184,
            "logloss": 0.6940599307045144,
            "mae": 0.49470494303169416,
            "precision": 0.5149769585253456,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6163666259654856,
            "auditor_fn_violation": 0.013207024690034654,
            "auditor_fp_violation": 0.0015314414301787727,
            "ave_precision_score": 0.5694614817192325,
            "fpr": 0.07456140350877193,
            "logloss": 0.7441734027589825,
            "mae": 0.4979669373939958,
            "precision": 0.6324324324324324,
            "recall": 0.23828920570264767
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5756713538733905,
            "auditor_fn_violation": 0.00957341634403605,
            "auditor_fp_violation": 0.009979712247138155,
            "ave_precision_score": 0.5358671334341312,
            "fpr": 0.09110867178924259,
            "logloss": 0.7375356954624873,
            "mae": 0.494657234829553,
            "precision": 0.5561497326203209,
            "recall": 0.22462203023758098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8508233166383455,
            "auditor_fn_violation": 0.012458909493693496,
            "auditor_fp_violation": 0.0031592490728007683,
            "ave_precision_score": 0.8386563565329486,
            "fpr": 0.06907894736842106,
            "logloss": 1.0088912749059886,
            "mae": 0.3040699240550008,
            "precision": 0.8467153284671532,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8090075004619622,
            "auditor_fn_violation": 0.006147565274909733,
            "auditor_fp_violation": 0.015705856986043595,
            "ave_precision_score": 0.7963759551611209,
            "fpr": 0.08562019758507135,
            "logloss": 1.0376204655586836,
            "mae": 0.3257297881505834,
            "precision": 0.7958115183246073,
            "recall": 0.6565874730021598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7278722435661564,
            "auditor_fn_violation": 0.008550845035194914,
            "auditor_fp_violation": 0.01921854815185232,
            "ave_precision_score": 0.7284805263896311,
            "fpr": 0.16557017543859648,
            "logloss": 1.675273847894202,
            "mae": 0.3178788978906649,
            "precision": 0.6955645161290323,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7103964652280192,
            "auditor_fn_violation": 0.016263901961388647,
            "auditor_fp_violation": 0.02085620197585072,
            "ave_precision_score": 0.7104427823566373,
            "fpr": 0.14928649835345773,
            "logloss": 1.8074515524189507,
            "mae": 0.3181586382039934,
            "precision": 0.7017543859649122,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8751596742002998,
            "auditor_fn_violation": 0.01416059241790832,
            "auditor_fp_violation": 0.03026419969162813,
            "ave_precision_score": 0.8709414049263348,
            "fpr": 0.15570175438596492,
            "logloss": 0.48422866051495783,
            "mae": 0.3209453701008961,
            "precision": 0.7477797513321492,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8500233703671354,
            "auditor_fn_violation": 0.016052897985504744,
            "auditor_fp_violation": 0.024137035439862006,
            "ave_precision_score": 0.8463864988249473,
            "fpr": 0.13721185510428102,
            "logloss": 0.48998910311864063,
            "mae": 0.32438775211466325,
            "precision": 0.7479838709677419,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8477629431042757,
            "auditor_fn_violation": 0.011505341765819846,
            "auditor_fp_violation": 0.03654102596157854,
            "ave_precision_score": 0.8480073804319758,
            "fpr": 0.3092105263157895,
            "logloss": 1.2285693850581576,
            "mae": 0.33703608669569357,
            "precision": 0.6229946524064172,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8110081874907762,
            "auditor_fn_violation": 0.005294066046615283,
            "auditor_fp_violation": 0.0342637603888976,
            "ave_precision_score": 0.8119655536035428,
            "fpr": 0.3205268935236004,
            "logloss": 1.2905352560901744,
            "mae": 0.3534721120145135,
            "precision": 0.6,
            "recall": 0.9460043196544277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8622041635181346,
            "auditor_fn_violation": 0.008010415550076831,
            "auditor_fp_violation": 0.006341938575655291,
            "ave_precision_score": 0.8623611686777051,
            "fpr": 0.051535087719298246,
            "logloss": 0.5299722310694892,
            "mae": 0.36463422918684063,
            "precision": 0.8621700879765396,
            "recall": 0.5987780040733197
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8062628585645049,
            "auditor_fn_violation": 0.0012162364003195894,
            "auditor_fp_violation": 0.00597851654382939,
            "ave_precision_score": 0.8067666620583785,
            "fpr": 0.054884742041712405,
            "logloss": 0.5567128816535428,
            "mae": 0.3767527728929347,
            "precision": 0.8360655737704918,
            "recall": 0.550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6278352729578579,
            "auditor_fn_violation": 0.004026422982098829,
            "auditor_fp_violation": 0.01064455973663375,
            "ave_precision_score": 0.5710763513686589,
            "fpr": 0.09868421052631579,
            "logloss": 1.3269010621321242,
            "mae": 0.5034870814479451,
            "precision": 0.5982142857142857,
            "recall": 0.2729124236252546
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5995383687504467,
            "auditor_fn_violation": 0.004490354273304689,
            "auditor_fp_violation": 0.0184525442998275,
            "ave_precision_score": 0.5369785092814522,
            "fpr": 0.11306256860592755,
            "logloss": 1.271616578883738,
            "mae": 0.4859576242697056,
            "precision": 0.5654008438818565,
            "recall": 0.2894168466522678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6806261062931984,
            "auditor_fn_violation": 0.008912620145067355,
            "auditor_fp_violation": 0.0148976955452765,
            "ave_precision_score": 0.6818077415216659,
            "fpr": 0.12938596491228072,
            "logloss": 0.9401655665416957,
            "mae": 0.40396812051364545,
            "precision": 0.6958762886597938,
            "recall": 0.5498981670061099
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6454202800227226,
            "auditor_fn_violation": 0.011697681090013347,
            "auditor_fp_violation": 0.010146326642621925,
            "ave_precision_score": 0.6458958266000097,
            "fpr": 0.141602634467618,
            "logloss": 1.0887219928977225,
            "mae": 0.3962087051407677,
            "precision": 0.6631853785900783,
            "recall": 0.5485961123110151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7240661683748391,
            "auditor_fn_violation": 0.04187435237788975,
            "auditor_fp_violation": 0.03074342626161604,
            "ave_precision_score": 0.6955170685897263,
            "fpr": 0.14473684210526316,
            "logloss": 0.6379641982983703,
            "mae": 0.41833653298549744,
            "precision": 0.7124183006535948,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7109570636839175,
            "auditor_fn_violation": 0.01823643351122471,
            "auditor_fp_violation": 0.03830170926768073,
            "ave_precision_score": 0.6790436639868667,
            "fpr": 0.15806805708013172,
            "logloss": 0.6231871042964133,
            "mae": 0.41033581608311404,
            "precision": 0.6835164835164835,
            "recall": 0.67170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6388061348503496,
            "auditor_fn_violation": 0.00893718512166364,
            "auditor_fp_violation": 0.010881568529399517,
            "ave_precision_score": 0.6403594203189388,
            "fpr": 0.2149122807017544,
            "logloss": 0.6832067476523138,
            "mae": 0.49126580550351684,
            "precision": 0.6126482213438735,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.572002183365958,
            "auditor_fn_violation": 0.01011870751766862,
            "auditor_fp_violation": 0.01047710522189118,
            "ave_precision_score": 0.5733215794111215,
            "fpr": 0.24698133918770582,
            "logloss": 0.6862612745490173,
            "mae": 0.4928033145964473,
            "precision": 0.5517928286852589,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.5304706202879909,
            "auditor_fn_violation": 0.0030237253010326243,
            "auditor_fp_violation": 0.0011563945493186661,
            "ave_precision_score": 0.5365013220423769,
            "fpr": 0.02631578947368421,
            "logloss": 0.7052510527453194,
            "mae": 0.5037502615075362,
            "precision": 0.5,
            "recall": 0.048879837067209775
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.41648474326285284,
            "auditor_fn_violation": 0.006766352215423219,
            "auditor_fp_violation": 0.012846459934138311,
            "ave_precision_score": 0.4984033751022908,
            "fpr": 0.05598243688254665,
            "logloss": 0.7034949458002074,
            "mae": 0.5029334457985787,
            "precision": 0.3013698630136986,
            "recall": 0.047516198704103674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 21924,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7498904838996425,
            "auditor_fn_violation": 0.008072944581412804,
            "auditor_fp_violation": 0.025115118556486227,
            "ave_precision_score": 0.7499118697529316,
            "fpr": 0.15899122807017543,
            "logloss": 0.6169988637626271,
            "mae": 0.42566685262544635,
            "precision": 0.7040816326530612,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7515831772084102,
            "auditor_fn_violation": 0.014656478414767435,
            "auditor_fp_violation": 0.022767367100517483,
            "ave_precision_score": 0.7512111421583959,
            "fpr": 0.16245883644346873,
            "logloss": 0.6021826073801524,
            "mae": 0.418732967256322,
            "precision": 0.6864406779661016,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8556048268935026,
            "auditor_fn_violation": 0.006096580555257802,
            "auditor_fp_violation": 0.008021836062841192,
            "ave_precision_score": 0.7569215531036342,
            "fpr": 0.08552631578947369,
            "logloss": 0.5315062757115436,
            "mae": 0.3705188123541966,
            "precision": 0.825503355704698,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8184724732221142,
            "auditor_fn_violation": 0.004632604144687091,
            "auditor_fp_violation": 0.011172965344205744,
            "ave_precision_score": 0.7043620348289825,
            "fpr": 0.09659714599341383,
            "logloss": 0.5634051031946277,
            "mae": 0.3851948098476841,
            "precision": 0.7858880778588808,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.4972745801084336,
            "auditor_fn_violation": 0.0178944688605424,
            "auditor_fp_violation": 0.023601908571904837,
            "ave_precision_score": 0.49216920543437115,
            "fpr": 0.22039473684210525,
            "logloss": 4.3938235698937875,
            "mae": 0.5259449487209227,
            "precision": 0.5523385300668151,
            "recall": 0.505091649694501
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.4729356779956136,
            "auditor_fn_violation": 0.025047831519252342,
            "auditor_fp_violation": 0.015838168417751295,
            "ave_precision_score": 0.4719595970083097,
            "fpr": 0.21624588364434688,
            "logloss": 5.027842023995367,
            "mae": 0.5173294046548296,
            "precision": 0.535377358490566,
            "recall": 0.490280777537797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.610630923622996,
            "auditor_fn_violation": 0.0015609926037088682,
            "auditor_fp_violation": 0.002289348668583583,
            "ave_precision_score": 0.5434058899028215,
            "fpr": 0.35964912280701755,
            "logloss": 0.7575863032140392,
            "mae": 0.5024123978065816,
            "precision": 0.5327635327635327,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5966257585664927,
            "auditor_fn_violation": 0.00046705374437223794,
            "auditor_fp_violation": 0.008781558726673981,
            "ave_precision_score": 0.5253642970070813,
            "fpr": 0.36443468715697036,
            "logloss": 0.7439878384174466,
            "mae": 0.49484969980597626,
            "precision": 0.5131964809384164,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7262212963659669,
            "auditor_fn_violation": 0.026521242005216723,
            "auditor_fp_violation": 0.022867441763553785,
            "ave_precision_score": 0.726887784004661,
            "fpr": 0.1337719298245614,
            "logloss": 0.9547161196195759,
            "mae": 0.41146550519931174,
            "precision": 0.7129411764705882,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6891027588813895,
            "auditor_fn_violation": 0.021432313954949475,
            "auditor_fp_violation": 0.014135271287439239,
            "ave_precision_score": 0.6898330424536432,
            "fpr": 0.141602634467618,
            "logloss": 0.8414538057588801,
            "mae": 0.4086620438543682,
            "precision": 0.6742424242424242,
            "recall": 0.5766738660907127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7800697434145818,
            "auditor_fn_violation": 0.013338782291778328,
            "auditor_fp_violation": 0.02173709213651706,
            "ave_precision_score": 0.6483829878529949,
            "fpr": 0.20394736842105263,
            "logloss": 0.6309228043485027,
            "mae": 0.4447183904417774,
            "precision": 0.6660682226211849,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7542374051216332,
            "auditor_fn_violation": 0.006766352215423209,
            "auditor_fp_violation": 0.025928140191312548,
            "ave_precision_score": 0.609886859838322,
            "fpr": 0.2261251372118551,
            "logloss": 0.6432629717686944,
            "mae": 0.45000033774111586,
            "precision": 0.6261343012704175,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7098365415769693,
            "auditor_fn_violation": 0.11258575410011792,
            "auditor_fp_violation": 0.09785337750552152,
            "ave_precision_score": 0.7104056665030085,
            "fpr": 0.19298245614035087,
            "logloss": 1.5066665147682765,
            "mae": 0.3884162695841313,
            "precision": 0.6325678496868476,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6873691020573425,
            "auditor_fn_violation": 0.10790838159950497,
            "auditor_fp_violation": 0.10103692959071665,
            "ave_precision_score": 0.688003301265398,
            "fpr": 0.1734357848518112,
            "logloss": 1.513493773824148,
            "mae": 0.3891617045737752,
            "precision": 0.6211031175059952,
            "recall": 0.5593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8024925305364595,
            "auditor_fn_violation": 0.006808964876549835,
            "auditor_fp_violation": 0.010014272617410513,
            "ave_precision_score": 0.8078497423690131,
            "fpr": 0.06907894736842106,
            "logloss": 0.5086084559957045,
            "mae": 0.32921493390019524,
            "precision": 0.8467153284671532,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7763854938387105,
            "auditor_fn_violation": 0.000836903409966497,
            "auditor_fp_violation": 0.006346048298572996,
            "ave_precision_score": 0.7817141814423721,
            "fpr": 0.07683863885839737,
            "logloss": 0.5347291185681051,
            "mae": 0.3446809722092228,
            "precision": 0.8138297872340425,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7757325122299189,
            "auditor_fn_violation": 0.013396844963733166,
            "auditor_fp_violation": 0.024786952535733636,
            "ave_precision_score": 0.7459143001674461,
            "fpr": 0.15460526315789475,
            "logloss": 2.32571013179357,
            "mae": 0.31893798692270364,
            "precision": 0.7128309572301426,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7639131463068707,
            "auditor_fn_violation": 0.007878272043395704,
            "auditor_fp_violation": 0.018719617374941197,
            "ave_precision_score": 0.74218698570757,
            "fpr": 0.150384193194292,
            "logloss": 1.906050458270363,
            "mae": 0.31904770299878166,
            "precision": 0.7021739130434783,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.793684799959521,
            "auditor_fn_violation": 0.0072444349162111045,
            "auditor_fp_violation": 0.008469808726090763,
            "ave_precision_score": 0.754013303030541,
            "fpr": 0.08442982456140351,
            "logloss": 0.5652967163738039,
            "mae": 0.3717013029381633,
            "precision": 0.823394495412844,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7599355341114394,
            "auditor_fn_violation": 0.0009649282942106702,
            "auditor_fp_violation": 0.0088844676180022,
            "ave_precision_score": 0.7109072700610012,
            "fpr": 0.09110867178924259,
            "logloss": 0.5894050337167581,
            "mae": 0.3804912443971006,
            "precision": 0.7909319899244333,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.777148299651766,
            "auditor_fn_violation": 0.010230196162504016,
            "auditor_fp_violation": 0.023281556027836818,
            "ave_precision_score": 0.7241822742183717,
            "fpr": 0.14364035087719298,
            "logloss": 3.191033769516487,
            "mae": 0.3614208759380537,
            "precision": 0.7145969498910676,
            "recall": 0.6680244399185336
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7544202647698467,
            "auditor_fn_violation": 0.010358161467829008,
            "auditor_fp_violation": 0.018033558099419787,
            "ave_precision_score": 0.7069206287378504,
            "fpr": 0.14050493962678376,
            "logloss": 2.890519561290788,
            "mae": 0.36555847095409416,
            "precision": 0.7009345794392523,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8485839688815144,
            "auditor_fn_violation": 0.013765319612677317,
            "auditor_fp_violation": 0.012621369337833898,
            "ave_precision_score": 0.8455116125106655,
            "fpr": 0.11842105263157894,
            "logloss": 0.5169954511664586,
            "mae": 0.35241957755939085,
            "precision": 0.7768595041322314,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8021886175099829,
            "auditor_fn_violation": 0.008397484073941492,
            "auditor_fp_violation": 0.01662223616120433,
            "ave_precision_score": 0.7985571373972309,
            "fpr": 0.13172338090010977,
            "logloss": 0.5322308393783401,
            "mae": 0.3597764550543643,
            "precision": 0.7408207343412527,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7237157690339268,
            "auditor_fn_violation": 0.002791474613213278,
            "auditor_fp_violation": 0.0006980039171563163,
            "ave_precision_score": 0.6918274537482886,
            "fpr": 0.45614035087719296,
            "logloss": 0.6796232504237653,
            "mae": 0.4464844142724025,
            "precision": 0.5388026607538803,
            "recall": 0.9898167006109979
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6998658354401113,
            "auditor_fn_violation": 0.0005049870434075483,
            "auditor_fp_violation": 0.001965069782029171,
            "ave_precision_score": 0.6698290823900264,
            "fpr": 0.4862788144895719,
            "logloss": 0.6866123747928179,
            "mae": 0.4508780445147032,
            "precision": 0.5104972375690607,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7192829534156566,
            "auditor_fn_violation": 0.0102391288812663,
            "auditor_fp_violation": 0.025479747468433553,
            "ave_precision_score": 0.7199836493424168,
            "fpr": 0.23135964912280702,
            "logloss": 1.3542769201050333,
            "mae": 0.33651563879551794,
            "precision": 0.6713395638629284,
            "recall": 0.8778004073319755
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7218871206742141,
            "auditor_fn_violation": 0.004874428926037183,
            "auditor_fp_violation": 0.016289007370236797,
            "ave_precision_score": 0.7214113707543117,
            "fpr": 0.23710208562019758,
            "logloss": 1.209308615209202,
            "mae": 0.3438528640682346,
            "precision": 0.6470588235294118,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 21924,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8057889637806579,
            "auditor_fn_violation": 0.02392182084539251,
            "auditor_fp_violation": 0.039372109013626706,
            "ave_precision_score": 0.804982200774798,
            "fpr": 0.13267543859649122,
            "logloss": 0.5624997210459444,
            "mae": 0.38979413328700485,
            "precision": 0.7397849462365591,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7890876328696087,
            "auditor_fn_violation": 0.034713710279686956,
            "auditor_fp_violation": 0.02642308295436726,
            "ave_precision_score": 0.7865830602554901,
            "fpr": 0.1207464324917673,
            "logloss": 0.558634934725853,
            "mae": 0.38507954517029774,
            "precision": 0.7387173396674585,
            "recall": 0.67170626349892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7592950080180111,
            "auditor_fn_violation": 0.012588433915746603,
            "auditor_fp_violation": 0.021744905613201655,
            "ave_precision_score": 0.7327411495575675,
            "fpr": 0.14144736842105263,
            "logloss": 0.5700510431781326,
            "mae": 0.40499400769017246,
            "precision": 0.7409638554216867,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7171195756506717,
            "auditor_fn_violation": 0.015806331541775243,
            "auditor_fp_violation": 0.018111964873765096,
            "ave_precision_score": 0.6701311611200264,
            "fpr": 0.1756311745334797,
            "logloss": 0.6031598632081735,
            "mae": 0.42037152224981955,
            "precision": 0.6701030927835051,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4024122807017544,
            "auc_prc": 0.4226000841867683,
            "auditor_fn_violation": 0.004162646943223633,
            "auditor_fp_violation": 0.008743280410051258,
            "ave_precision_score": 0.42412863647258736,
            "fpr": 0.33223684210526316,
            "logloss": 1.2923986609310667,
            "mae": 0.5836777013763296,
            "precision": 0.45108695652173914,
            "recall": 0.5071283095723014
        },
        "train": {
            "accuracy": 0.3918770581778266,
            "auc_prc": 0.39485541566285665,
            "auditor_fn_violation": 0.006240027691308302,
            "auditor_fp_violation": 0.007164419005802095,
            "ave_precision_score": 0.3960026254704038,
            "fpr": 0.36663007683863885,
            "logloss": 1.3484106111465268,
            "mae": 0.5836839768238178,
            "precision": 0.42114384748700173,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.854672964386961,
            "auditor_fn_violation": 0.012968074463143601,
            "auditor_fp_violation": 0.010863337083802143,
            "ave_precision_score": 0.8549077685339573,
            "fpr": 0.08442982456140351,
            "logloss": 0.5026876419995622,
            "mae": 0.3084351618512811,
            "precision": 0.8246013667425968,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8117112064857941,
            "auditor_fn_violation": 0.00110243650321367,
            "auditor_fp_violation": 0.009085384977262039,
            "ave_precision_score": 0.8122517474042258,
            "fpr": 0.09549945115257959,
            "logloss": 0.533690706977946,
            "mae": 0.3270091398094671,
            "precision": 0.7846534653465347,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6634127706344941,
            "auditor_fn_violation": 0.00598715475041984,
            "auditor_fp_violation": 0.023440430053756726,
            "ave_precision_score": 0.6364123134399654,
            "fpr": 0.23355263157894737,
            "logloss": 3.002451016039366,
            "mae": 0.33015909996168946,
            "precision": 0.6712962962962963,
            "recall": 0.8859470468431772
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6184095836131471,
            "auditor_fn_violation": 0.0015694902475858993,
            "auditor_fp_violation": 0.022502744237102093,
            "ave_precision_score": 0.5912283652733599,
            "fpr": 0.24588364434687157,
            "logloss": 3.2028525497916536,
            "mae": 0.35283008386375597,
            "precision": 0.6357723577235772,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6979542070966442,
            "auditor_fn_violation": 0.0052680708900561,
            "auditor_fp_violation": 0.022458536483727143,
            "ave_precision_score": 0.6988203409614455,
            "fpr": 0.15679824561403508,
            "logloss": 0.6423753165727601,
            "mae": 0.41618716230272856,
            "precision": 0.7039337474120083,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7016558678815843,
            "auditor_fn_violation": 0.014936236495152844,
            "auditor_fp_violation": 0.01599253175474362,
            "ave_precision_score": 0.7034169105760928,
            "fpr": 0.14818880351262348,
            "logloss": 0.6165818536172122,
            "mae": 0.40602674602268163,
            "precision": 0.7039473684210527,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.833611391309344,
            "auditor_fn_violation": 0.01077062564762211,
            "auditor_fp_violation": 0.010951889819560783,
            "ave_precision_score": 0.8321637958907748,
            "fpr": 0.06798245614035088,
            "logloss": 0.4922007333447699,
            "mae": 0.33269380903884505,
            "precision": 0.8541176470588235,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.823935323773875,
            "auditor_fn_violation": 0.004938441368159263,
            "auditor_fp_violation": 0.012400521405049401,
            "ave_precision_score": 0.8091115351537804,
            "fpr": 0.08232711306256861,
            "logloss": 0.5142377191545867,
            "mae": 0.3443176798955931,
            "precision": 0.8081841432225064,
            "recall": 0.6825053995680346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6008340297735265,
            "auditor_fn_violation": 0.011174831171615395,
            "auditor_fp_violation": 0.006323707130057926,
            "ave_precision_score": 0.5397940124874379,
            "fpr": 0.03728070175438596,
            "logloss": 0.8812621101228023,
            "mae": 0.5230518047485435,
            "precision": 0.6699029126213593,
            "recall": 0.14052953156822812
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5639121477556572,
            "auditor_fn_violation": 0.004073087983916303,
            "auditor_fp_violation": 0.0073604359416653605,
            "ave_precision_score": 0.5113729465464214,
            "fpr": 0.04939626783754116,
            "logloss": 0.8523192227848633,
            "mae": 0.5085208353665213,
            "precision": 0.5909090909090909,
            "recall": 0.14038876889848811
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.780249984061414,
            "auditor_fn_violation": 0.015826544467074006,
            "auditor_fp_violation": 0.015809267825144812,
            "ave_precision_score": 0.7261798945202426,
            "fpr": 0.1206140350877193,
            "logloss": 4.728719087771126,
            "mae": 0.33009793493628103,
            "precision": 0.7243107769423559,
            "recall": 0.5885947046843177
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7572679006714781,
            "auditor_fn_violation": 0.01290443416557411,
            "auditor_fp_violation": 0.012706797867335745,
            "ave_precision_score": 0.7081991008253337,
            "fpr": 0.1119648737650933,
            "logloss": 4.766912920823221,
            "mae": 0.32872215838874175,
            "precision": 0.7197802197802198,
            "recall": 0.5658747300215983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7099676155826653,
            "auditor_fn_violation": 0.03312698752992461,
            "auditor_fp_violation": 0.02953754635996167,
            "ave_precision_score": 0.6416185668728733,
            "fpr": 0.23903508771929824,
            "logloss": 8.33873798258131,
            "mae": 0.38457649408885436,
            "precision": 0.6221837088388215,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6898212021748391,
            "auditor_fn_violation": 0.026854404885808918,
            "auditor_fp_violation": 0.03845852281637134,
            "ave_precision_score": 0.6189186333984413,
            "fpr": 0.2722283205268935,
            "logloss": 8.136094861786239,
            "mae": 0.4096773372671902,
            "precision": 0.5664335664335665,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6118110801289651,
            "auditor_fn_violation": 0.0011210562046664629,
            "auditor_fp_violation": 0.004664645580697588,
            "ave_precision_score": 0.6037404446096284,
            "fpr": 0.025219298245614034,
            "logloss": 15.221154363502277,
            "mae": 0.4886768213725169,
            "precision": 0.7472527472527473,
            "recall": 0.1384928716904277
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5783743185107526,
            "auditor_fn_violation": 0.007968363628604567,
            "auditor_fp_violation": 0.0023080994197898705,
            "ave_precision_score": 0.570097238926182,
            "fpr": 0.029637760702524697,
            "logloss": 14.56625981432687,
            "mae": 0.47355565108218284,
            "precision": 0.686046511627907,
            "recall": 0.12742980561555076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7206332638156048,
            "auditor_fn_violation": 0.028729856719191062,
            "auditor_fp_violation": 0.01267866816685419,
            "ave_precision_score": 0.6044848701680058,
            "fpr": 0.14473684210526316,
            "logloss": 0.6720389682722553,
            "mae": 0.4713986054422301,
            "precision": 0.6597938144329897,
            "recall": 0.5213849287169042
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.713762367017237,
            "auditor_fn_violation": 0.013900183265250969,
            "auditor_fp_violation": 0.011663007683863887,
            "ave_precision_score": 0.5879725830550372,
            "fpr": 0.15367727771679474,
            "logloss": 0.6631686066801658,
            "mae": 0.46591987355349485,
            "precision": 0.6473551637279596,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7867359788090644,
            "auditor_fn_violation": 0.007648640440204386,
            "auditor_fp_violation": 0.019083114555986175,
            "ave_precision_score": 0.7868114972231952,
            "fpr": 0.17982456140350878,
            "logloss": 0.7748476224759839,
            "mae": 0.348806633397512,
            "precision": 0.6784313725490196,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7541607086858299,
            "auditor_fn_violation": 0.012029597456572304,
            "auditor_fp_violation": 0.023438725105849146,
            "ave_precision_score": 0.7544653048803163,
            "fpr": 0.18331503841931943,
            "logloss": 0.7622680124528526,
            "mae": 0.34751929835499185,
            "precision": 0.6633064516129032,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 21924,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7052818291386723,
            "auditor_fn_violation": 0.009010880051452461,
            "auditor_fp_violation": 0.026667395924490567,
            "ave_precision_score": 0.5795022381600656,
            "fpr": 0.4024122807017544,
            "logloss": 0.6724388196982671,
            "mae": 0.47315567604413156,
            "precision": 0.564650059311981,
            "recall": 0.9694501018329938
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6642249573011028,
            "auditor_fn_violation": 0.0041726628938839674,
            "auditor_fp_violation": 0.029314332758350322,
            "ave_precision_score": 0.5585395512930104,
            "fpr": 0.41822173435784854,
            "logloss": 0.6562903373232485,
            "mae": 0.46656417791066135,
            "precision": 0.5442583732057417,
            "recall": 0.9827213822894169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8207994961040357,
            "auditor_fn_violation": 0.022950387679994286,
            "auditor_fp_violation": 0.024073321665208158,
            "ave_precision_score": 0.7672409262323571,
            "fpr": 0.13267543859649122,
            "logloss": 0.5427863355871959,
            "mae": 0.3588844313318923,
            "precision": 0.7641325536062378,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7642208588708208,
            "auditor_fn_violation": 0.025142664766840617,
            "auditor_fp_violation": 0.0306962521561863,
            "ave_precision_score": 0.7038441940684619,
            "fpr": 0.16245883644346873,
            "logloss": 0.6171171076333037,
            "mae": 0.3853984504414704,
            "precision": 0.7016129032258065,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8648369366056461,
            "auditor_fn_violation": 0.008124307714295929,
            "auditor_fp_violation": 0.010863337083802143,
            "ave_precision_score": 0.8571639122750521,
            "fpr": 0.08552631578947369,
            "logloss": 0.4858323836717327,
            "mae": 0.3246869031552291,
            "precision": 0.8247191011235955,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8303192610244442,
            "auditor_fn_violation": 0.0031271263392232723,
            "auditor_fp_violation": 0.008472832052689356,
            "ave_precision_score": 0.8193360411335143,
            "fpr": 0.10318331503841932,
            "logloss": 0.5138537267417161,
            "mae": 0.3364599471345429,
            "precision": 0.7701711491442543,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.8752761348759264,
            "auditor_fn_violation": 0.01345937399506914,
            "auditor_fp_violation": 0.02753469183647957,
            "ave_precision_score": 0.8674703056296154,
            "fpr": 0.35635964912280704,
            "logloss": 2.1222977208000087,
            "mae": 0.3848668525412222,
            "precision": 0.5891276864728192,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.8457254825542047,
            "auditor_fn_violation": 0.004065975490347161,
            "auditor_fp_violation": 0.03173024149286499,
            "ave_precision_score": 0.8367996197191674,
            "fpr": 0.36663007683863885,
            "logloss": 2.1941883479675717,
            "mae": 0.39359080531425994,
            "precision": 0.5684754521963824,
            "recall": 0.9503239740820735
        }
    }
]