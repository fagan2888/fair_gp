[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.800438327294781,
            "auditor_fn_violation": 0.00823811172668514,
            "auditor_fp_violation": 0.01537251846722068,
            "ave_precision_score": 0.7959694651539847,
            "fpr": 0.0800438596491228,
            "logloss": 0.8765531355643121,
            "mae": 0.29202409223106524,
            "precision": 0.8137755102040817,
            "recall": 0.6995614035087719
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8146517162626337,
            "auditor_fn_violation": 0.007807299450270894,
            "auditor_fp_violation": 0.014756420717461855,
            "ave_precision_score": 0.8129947476006116,
            "fpr": 0.10098792535675083,
            "logloss": 0.7094827598981269,
            "mae": 0.32425805277103054,
            "precision": 0.7904328018223234,
            "recall": 0.6967871485943775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7958358259529373,
            "auditor_fn_violation": 0.0014836295783317982,
            "auditor_fp_violation": 0.011455447830101571,
            "ave_precision_score": 0.7957790770818494,
            "fpr": 0.07236842105263158,
            "logloss": 1.9908481714786455,
            "mae": 0.34008010011878687,
            "precision": 0.8006042296072508,
            "recall": 0.581140350877193
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7982093089481344,
            "auditor_fn_violation": 0.007595695625531778,
            "auditor_fp_violation": 0.010336404929792714,
            "ave_precision_score": 0.7982065162618963,
            "fpr": 0.07574094401756312,
            "logloss": 2.2247644504152717,
            "mae": 0.36280853838694194,
            "precision": 0.8056338028169014,
            "recall": 0.5742971887550201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7370783351505246,
            "auditor_fn_violation": 0.019207833179439835,
            "auditor_fp_violation": 0.01411972914742998,
            "ave_precision_score": 0.7339991718956724,
            "fpr": 0.043859649122807015,
            "logloss": 1.3781137505546037,
            "mae": 0.3488575204793043,
            "precision": 0.8305084745762712,
            "recall": 0.4298245614035088
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7666556646689955,
            "auditor_fn_violation": 0.018524151490704865,
            "auditor_fp_violation": 0.01087860770831617,
            "ave_precision_score": 0.7658106269708109,
            "fpr": 0.04171240395170143,
            "logloss": 1.1972165902810474,
            "mae": 0.3805632539741738,
            "precision": 0.8423236514522822,
            "recall": 0.40763052208835343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7929949490201709,
            "auditor_fn_violation": 0.010221895198522627,
            "auditor_fp_violation": 0.01951321560480149,
            "ave_precision_score": 0.7709342744382311,
            "fpr": 0.15679824561403508,
            "logloss": 1.6806605930481624,
            "mae": 0.27658902576909067,
            "precision": 0.7228682170542635,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7926810282166947,
            "auditor_fn_violation": 0.004104232517336086,
            "auditor_fp_violation": 0.02353266373062091,
            "ave_precision_score": 0.7730928324246026,
            "fpr": 0.17014270032930845,
            "logloss": 1.7859560835876354,
            "mae": 0.30793286865266833,
            "precision": 0.7181818181818181,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 6126,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7702725746500161,
            "auditor_fn_violation": 0.0038377192982456147,
            "auditor_fp_violation": 0.026676477377654672,
            "ave_precision_score": 0.7702853606094848,
            "fpr": 0.18092105263157895,
            "logloss": 2.181054178325649,
            "mae": 0.3189859695444165,
            "precision": 0.6745562130177515,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7652906307197205,
            "auditor_fn_violation": 0.010805020300741942,
            "auditor_fp_violation": 0.023875527252334265,
            "ave_precision_score": 0.7653909317769185,
            "fpr": 0.18551042810098792,
            "logloss": 2.484776359561525,
            "mae": 0.3404229411598647,
            "precision": 0.6841121495327103,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8425121235793464,
            "auditor_fn_violation": 0.003950734841489688,
            "auditor_fp_violation": 0.012600030778701142,
            "ave_precision_score": 0.8428190058223114,
            "fpr": 0.08114035087719298,
            "logloss": 0.589477055686586,
            "mae": 0.2908787108882729,
            "precision": 0.811704834605598,
            "recall": 0.6995614035087719
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8176131624630865,
            "auditor_fn_violation": 0.0014018753388967587,
            "auditor_fp_violation": 0.014464056474140388,
            "ave_precision_score": 0.8179682947685576,
            "fpr": 0.11086717892425905,
            "logloss": 0.6917999933907707,
            "mae": 0.32770973919480145,
            "precision": 0.7730337078651686,
            "recall": 0.6907630522088354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8448316876934855,
            "auditor_fn_violation": 0.005771006463527241,
            "auditor_fp_violation": 0.010565751000307787,
            "ave_precision_score": 0.8452042419923512,
            "fpr": 0.1074561403508772,
            "logloss": 0.5048062474620271,
            "mae": 0.2894736210459597,
            "precision": 0.7782805429864253,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8168870896400108,
            "auditor_fn_violation": 0.026373330864622055,
            "auditor_fp_violation": 0.018923940113171545,
            "ave_precision_score": 0.8173020541210034,
            "fpr": 0.12403951701427003,
            "logloss": 0.5830814629618173,
            "mae": 0.31836032830181293,
            "precision": 0.7585470085470085,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8185028284069253,
            "auditor_fn_violation": 0.008382386888273316,
            "auditor_fp_violation": 0.020790050784856882,
            "ave_precision_score": 0.8191496659796482,
            "fpr": 0.16447368421052633,
            "logloss": 0.5096948198942828,
            "mae": 0.3116490350522534,
            "precision": 0.719626168224299,
            "recall": 0.8442982456140351
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.816646389632457,
            "auditor_fn_violation": 0.017098029880223423,
            "auditor_fp_violation": 0.021454219746281002,
            "ave_precision_score": 0.8169597313538302,
            "fpr": 0.1756311745334797,
            "logloss": 0.564441809705551,
            "mae": 0.33090727314640256,
            "precision": 0.718804920913884,
            "recall": 0.821285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 6126,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8145690262209891,
            "auditor_fn_violation": 0.011118805786395817,
            "auditor_fp_violation": 0.0184648160972607,
            "ave_precision_score": 0.8152322895491362,
            "fpr": 0.10635964912280702,
            "logloss": 0.7383247429434474,
            "mae": 0.27751644065331527,
            "precision": 0.7701421800947867,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8036797476140141,
            "auditor_fn_violation": 0.016895242881515088,
            "auditor_fp_violation": 0.022942619530463025,
            "ave_precision_score": 0.8049247697003228,
            "fpr": 0.132821075740944,
            "logloss": 0.8718273563776031,
            "mae": 0.3200756068911248,
            "precision": 0.7380952380952381,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 6126,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.4903080571241274,
            "auditor_fn_violation": 0.0036261157279162772,
            "auditor_fp_violation": 0.0010964912280701758,
            "ave_precision_score": 0.5159808881083782,
            "fpr": 0.020833333333333332,
            "logloss": 15.35902618374734,
            "mae": 0.49765838605587126,
            "precision": 0.5681818181818182,
            "recall": 0.05482456140350877
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5526506962741798,
            "auditor_fn_violation": 0.004384166743813886,
            "auditor_fp_violation": 0.004093099406500587,
            "ave_precision_score": 0.5598736139736917,
            "fpr": 0.02305159165751921,
            "logloss": 16.69995767707997,
            "mae": 0.5367151646493004,
            "precision": 0.5961538461538461,
            "recall": 0.06224899598393574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7990264724269625,
            "auditor_fn_violation": 0.013653239458294865,
            "auditor_fp_violation": 0.0028855032317636198,
            "ave_precision_score": 0.7994010641584808,
            "fpr": 0.02631578947368421,
            "logloss": 0.7227892271906904,
            "mae": 0.3705316640364145,
            "precision": 0.8762886597938144,
            "recall": 0.37280701754385964
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7687141325229155,
            "auditor_fn_violation": 0.004840437490907656,
            "auditor_fp_violation": 0.0073489739343987805,
            "ave_precision_score": 0.7693051971551417,
            "fpr": 0.038419319429198684,
            "logloss": 0.8185234304302735,
            "mae": 0.411430496968836,
            "precision": 0.8284313725490197,
            "recall": 0.3393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8508832604122083,
            "auditor_fn_violation": 0.0053670360110803315,
            "auditor_fp_violation": 0.004472530009233612,
            "ave_precision_score": 0.8511339630694246,
            "fpr": 0.03618421052631579,
            "logloss": 0.6063278289064019,
            "mae": 0.32615125045013454,
            "precision": 0.8817204301075269,
            "recall": 0.5394736842105263
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8269397171956118,
            "auditor_fn_violation": 0.003927895996720154,
            "auditor_fp_violation": 0.008552983045531743,
            "ave_precision_score": 0.8272269557888088,
            "fpr": 0.04939626783754116,
            "logloss": 0.6819233889804593,
            "mae": 0.3649078266351774,
            "precision": 0.8464163822525598,
            "recall": 0.4979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7938252732906231,
            "auditor_fn_violation": 0.007694675284702988,
            "auditor_fp_violation": 0.016904239766081876,
            "ave_precision_score": 0.7945032543719366,
            "fpr": 0.10416666666666667,
            "logloss": 0.527669869552439,
            "mae": 0.3057849920439542,
            "precision": 0.7816091954022989,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7901862299665465,
            "auditor_fn_violation": 0.019220680747137838,
            "auditor_fp_violation": 0.030068333497234503,
            "ave_precision_score": 0.7908322124589684,
            "fpr": 0.1350164654226125,
            "logloss": 0.581329070371455,
            "mae": 0.32340271874156123,
            "precision": 0.7525150905432596,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7602907798539129,
            "auditor_fn_violation": 0.0005290089258233414,
            "auditor_fp_violation": 0.022545398584179754,
            "ave_precision_score": 0.7605655313725642,
            "fpr": 0.1337719298245614,
            "logloss": 1.9959508907038221,
            "mae": 0.33652714343448814,
            "precision": 0.7195402298850575,
            "recall": 0.6864035087719298
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7624402865742909,
            "auditor_fn_violation": 0.015585944215941712,
            "auditor_fp_violation": 0.017693352434463898,
            "ave_precision_score": 0.7629156349840791,
            "fpr": 0.13172338090010977,
            "logloss": 2.24991083339625,
            "mae": 0.3512634958854036,
            "precision": 0.738562091503268,
            "recall": 0.6807228915662651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6235832089912776,
            "auditor_fn_violation": 0.004943828870421668,
            "auditor_fp_violation": 0.01980897968605726,
            "ave_precision_score": 0.6141057873261551,
            "fpr": 0.3442982456140351,
            "logloss": 2.3704093950908467,
            "mae": 0.3735277610515671,
            "precision": 0.5796519410977242,
            "recall": 0.9495614035087719
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.632270206243637,
            "auditor_fn_violation": 0.010306869630001896,
            "auditor_fp_violation": 0.012561031035793358,
            "ave_precision_score": 0.6236933219978362,
            "fpr": 0.3172338090010977,
            "logloss": 2.395127301798278,
            "mae": 0.3658316106005875,
            "precision": 0.6162018592297477,
            "recall": 0.9317269076305221
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7317584385118252,
            "auditor_fn_violation": 0.01725530932594645,
            "auditor_fp_violation": 0.00265466297322253,
            "ave_precision_score": 0.7325254807004679,
            "fpr": 0.013157894736842105,
            "logloss": 1.2182047689574294,
            "mae": 0.41464605858864373,
            "precision": 0.8846153846153846,
            "recall": 0.20175438596491227
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7346621858705863,
            "auditor_fn_violation": 0.004589157949029933,
            "auditor_fp_violation": 0.004746932168837692,
            "ave_precision_score": 0.7352249769076186,
            "fpr": 0.019758507135016465,
            "logloss": 1.3469239976068286,
            "mae": 0.45246468712410526,
            "precision": 0.8536585365853658,
            "recall": 0.21084337349397592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7669847576853657,
            "auditor_fn_violation": 0.026315789473684213,
            "auditor_fp_violation": 0.03785539781471223,
            "ave_precision_score": 0.7681658489626437,
            "fpr": 0.13925438596491227,
            "logloss": 1.0754370465479905,
            "mae": 0.31452557580996304,
            "precision": 0.7292110874200426,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8040955091430991,
            "auditor_fn_violation": 0.04325975692010634,
            "auditor_fp_violation": 0.029512841434923706,
            "ave_precision_score": 0.8045294310473085,
            "fpr": 0.11855104281009879,
            "logloss": 1.2409551946962487,
            "mae": 0.3283211570986612,
            "precision": 0.7711864406779662,
            "recall": 0.7309236947791165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8043077538051459,
            "auditor_fn_violation": 0.010594606032625426,
            "auditor_fp_violation": 0.011679074330563251,
            "ave_precision_score": 0.8038401785486525,
            "fpr": 0.11951754385964912,
            "logloss": 0.7731059410527825,
            "mae": 0.25976210024173363,
            "precision": 0.7665952890792291,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8066562058037587,
            "auditor_fn_violation": 0.001988194269944762,
            "auditor_fp_violation": 0.018780415848268273,
            "ave_precision_score": 0.8061198256504314,
            "fpr": 0.14709110867178923,
            "logloss": 0.8715050626677177,
            "mae": 0.2996770533306404,
            "precision": 0.7403100775193798,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.869104165137548,
            "auditor_fn_violation": 0.009709718374884586,
            "auditor_fp_violation": 0.013706140350877197,
            "ave_precision_score": 0.8694931323307975,
            "fpr": 0.08662280701754387,
            "logloss": 0.45979291527726474,
            "mae": 0.28281610181355127,
            "precision": 0.8136792452830188,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8434850777833647,
            "auditor_fn_violation": 0.01535450253263328,
            "auditor_fp_violation": 0.013850091563165298,
            "ave_precision_score": 0.8437360003582577,
            "fpr": 0.10647639956092206,
            "logloss": 0.5422554583769332,
            "mae": 0.3181940371313891,
            "precision": 0.787746170678337,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8353652485947308,
            "auditor_fn_violation": 0.013432017543859668,
            "auditor_fp_violation": 0.0037583679593721155,
            "ave_precision_score": 0.8357736877575903,
            "fpr": 0.01644736842105263,
            "logloss": 0.9733706486009089,
            "mae": 0.3312169829506945,
            "precision": 0.926829268292683,
            "recall": 0.4166666666666667
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.82946365958238,
            "auditor_fn_violation": 0.013723389716935801,
            "auditor_fp_violation": 0.006248621236807065,
            "ave_precision_score": 0.8296997970833795,
            "fpr": 0.026344676180021953,
            "logloss": 1.0892821104695798,
            "mae": 0.37157267053638393,
            "precision": 0.8914027149321267,
            "recall": 0.39558232931726905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7408784057132783,
            "auditor_fn_violation": 0.0020919898430286302,
            "auditor_fp_violation": 0.008829639889196678,
            "ave_precision_score": 0.7410891798485921,
            "fpr": 0.07894736842105263,
            "logloss": 2.1647319993045016,
            "mae": 0.35346066914055996,
            "precision": 0.7647058823529411,
            "recall": 0.5131578947368421
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7550296245659395,
            "auditor_fn_violation": 0.009870436741477443,
            "auditor_fp_violation": 0.008848005145610684,
            "ave_precision_score": 0.7555649916041024,
            "fpr": 0.07903402854006586,
            "logloss": 2.4010947730794063,
            "mae": 0.36915338628615474,
            "precision": 0.788235294117647,
            "recall": 0.5381526104417671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8218869912766349,
            "auditor_fn_violation": 0.008615631732840873,
            "auditor_fp_violation": 0.02135753308710372,
            "ave_precision_score": 0.8223155920462781,
            "fpr": 0.15021929824561403,
            "logloss": 0.7442898973303858,
            "mae": 0.2731664616057566,
            "precision": 0.7204081632653061,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8124553892229687,
            "auditor_fn_violation": 0.0174639281605015,
            "auditor_fp_violation": 0.023056907371034156,
            "ave_precision_score": 0.8136854094093691,
            "fpr": 0.16245883644346873,
            "logloss": 0.8591626429487761,
            "mae": 0.30562337380377946,
            "precision": 0.7170172084130019,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7583924173092175,
            "auditor_fn_violation": 0.00885849492151431,
            "auditor_fp_violation": 0.03340931825176978,
            "ave_precision_score": 0.7355305834708674,
            "fpr": 0.26535087719298245,
            "logloss": 1.8708192824246046,
            "mae": 0.3614296383416411,
            "precision": 0.6294027565084227,
            "recall": 0.9013157894736842
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7647512198229138,
            "auditor_fn_violation": 0.011647027186683066,
            "auditor_fp_violation": 0.029350712172718164,
            "ave_precision_score": 0.7422738296760865,
            "fpr": 0.265642151481888,
            "logloss": 2.004217393949152,
            "mae": 0.3714484453183915,
            "precision": 0.6467153284671533,
            "recall": 0.8895582329317269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 6126,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7008147101250659,
            "auditor_fn_violation": 0.010659529855340107,
            "auditor_fp_violation": 0.01879424438288704,
            "ave_precision_score": 0.6988353253320325,
            "fpr": 0.0800438596491228,
            "logloss": 1.0890347458406795,
            "mae": 0.3800161167805128,
            "precision": 0.7125984251968503,
            "recall": 0.3969298245614035
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.752459917298767,
            "auditor_fn_violation": 0.00851044132622698,
            "auditor_fp_violation": 0.008244671661665467,
            "ave_precision_score": 0.751867216537028,
            "fpr": 0.09001097694840834,
            "logloss": 0.8693014371055838,
            "mae": 0.3916730341909435,
            "precision": 0.7328990228013029,
            "recall": 0.45180722891566266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7076868677927766,
            "auditor_fn_violation": 0.02552708525700216,
            "auditor_fp_violation": 0.023449522930132354,
            "ave_precision_score": 0.6977679899746275,
            "fpr": 0.07017543859649122,
            "logloss": 1.4883221318031756,
            "mae": 0.35116638512054255,
            "precision": 0.7777777777777778,
            "recall": 0.49122807017543857
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7247730200280522,
            "auditor_fn_violation": 0.03643553357226933,
            "auditor_fp_violation": 0.02347419088195661,
            "ave_precision_score": 0.7169295105372182,
            "fpr": 0.09001097694840834,
            "logloss": 1.3618885272548231,
            "mae": 0.3891620796489261,
            "precision": 0.7328990228013029,
            "recall": 0.45180722891566266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.5990739337603476,
            "auditor_fn_violation": 0.013042474607571582,
            "auditor_fp_violation": 0.002616189596799015,
            "ave_precision_score": 0.5985144066794184,
            "fpr": 0.04824561403508772,
            "logloss": 5.872280965674669,
            "mae": 0.4281188105868631,
            "precision": 0.7380952380952381,
            "recall": 0.2719298245614035
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.635493332072674,
            "auditor_fn_violation": 0.01124586160228179,
            "auditor_fp_violation": 0.001932261862679174,
            "ave_precision_score": 0.6343683648674392,
            "fpr": 0.05159165751920966,
            "logloss": 6.083041877186794,
            "mae": 0.4635781391669581,
            "precision": 0.7388888888888889,
            "recall": 0.26706827309236947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.761948739992556,
            "auditor_fn_violation": 0.01309056632810096,
            "auditor_fp_violation": 0.020758791166512774,
            "ave_precision_score": 0.76308914075502,
            "fpr": 0.07785087719298246,
            "logloss": 0.6405002132027547,
            "mae": 0.34495164368409825,
            "precision": 0.7808641975308642,
            "recall": 0.5548245614035088
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7528393640868656,
            "auditor_fn_violation": 0.00271999083050093,
            "auditor_fp_violation": 0.018998360102380644,
            "ave_precision_score": 0.7539847094600565,
            "fpr": 0.0867178924259056,
            "logloss": 0.7103541230719936,
            "mae": 0.3774164107975265,
            "precision": 0.7669616519174042,
            "recall": 0.5220883534136547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8621588234738707,
            "auditor_fn_violation": 0.0044532933210218555,
            "auditor_fp_violation": 0.02055921052631579,
            "ave_precision_score": 0.86238687784631,
            "fpr": 0.125,
            "logloss": 0.5883328392416265,
            "mae": 0.27305265941157186,
            "precision": 0.7605042016806722,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8245018017846362,
            "auditor_fn_violation": 0.007139424878438013,
            "auditor_fp_violation": 0.014995627825633972,
            "ave_precision_score": 0.824832049734044,
            "fpr": 0.150384193194292,
            "logloss": 0.7076173768354876,
            "mae": 0.3118226729600778,
            "precision": 0.7313725490196078,
            "recall": 0.748995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6706105057744183,
            "auditor_fn_violation": 0.003986803631886736,
            "auditor_fp_violation": 0.007223376423514943,
            "ave_precision_score": 0.6713812262063708,
            "fpr": 0.37609649122807015,
            "logloss": 1.0679057288625573,
            "mae": 0.4170481111191054,
            "precision": 0.5533854166666666,
            "recall": 0.9320175438596491
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7186117666219846,
            "auditor_fn_violation": 0.00505865393516988,
            "auditor_fp_violation": 0.01353114875226915,
            "ave_precision_score": 0.7191685479720198,
            "fpr": 0.35016465422612514,
            "logloss": 0.9882876331042147,
            "mae": 0.40058281921815336,
            "precision": 0.589974293059126,
            "recall": 0.9216867469879518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 6126,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7792704177783465,
            "auditor_fn_violation": 0.003597260695598647,
            "auditor_fp_violation": 0.017293782702369993,
            "ave_precision_score": 0.7797477379014901,
            "fpr": 0.3508771929824561,
            "logloss": 0.895781414415302,
            "mae": 0.38209464473715216,
            "precision": 0.5755968169761273,
            "recall": 0.9517543859649122
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7775213460025489,
            "auditor_fn_violation": 0.003925691790212442,
            "auditor_fp_violation": 0.017789035277732755,
            "ave_precision_score": 0.7781288613462888,
            "fpr": 0.32491767288693746,
            "logloss": 0.8828257322388506,
            "mae": 0.3739489534487447,
            "precision": 0.6130718954248366,
            "recall": 0.9417670682730924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6691511735441132,
            "auditor_fn_violation": 0.002409395198522634,
            "auditor_fp_violation": 0.008531471221914437,
            "ave_precision_score": 0.6706483975848552,
            "fpr": 0.05701754385964912,
            "logloss": 1.3464045575431818,
            "mae": 0.37079747893043746,
            "precision": 0.792,
            "recall": 0.4342105263157895
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6883692875615768,
            "auditor_fn_violation": 0.010414875748879176,
            "auditor_fp_violation": 0.011580281892287696,
            "ave_precision_score": 0.6901733986719494,
            "fpr": 0.07244785949506037,
            "logloss": 1.4175073243226082,
            "mae": 0.40884596314395305,
            "precision": 0.7509433962264151,
            "recall": 0.39959839357429716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8593908022140531,
            "auditor_fn_violation": 0.013860033856571256,
            "auditor_fp_violation": 0.013564269775315484,
            "ave_precision_score": 0.859696273793557,
            "fpr": 0.0712719298245614,
            "logloss": 0.595752416722247,
            "mae": 0.27767663543271465,
            "precision": 0.8257372654155496,
            "recall": 0.6754385964912281
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8420714759416363,
            "auditor_fn_violation": 0.03000145477629509,
            "auditor_fp_violation": 0.017749167426370727,
            "ave_precision_score": 0.8423041419758087,
            "fpr": 0.09220636663007684,
            "logloss": 0.7120096411823359,
            "mae": 0.3198185044314589,
            "precision": 0.7985611510791367,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6271513552405077,
            "auditor_fn_violation": 0.0008728647276084999,
            "auditor_fp_violation": 0.008329485995690982,
            "ave_precision_score": 0.6226749315684434,
            "fpr": 0.07017543859649122,
            "logloss": 9.485080508719125,
            "mae": 0.446653059290806,
            "precision": 0.678391959798995,
            "recall": 0.29605263157894735
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6470073144010047,
            "auditor_fn_violation": 0.015751259704019163,
            "auditor_fp_violation": 0.00045183564876954594,
            "ave_precision_score": 0.6487124224946685,
            "fpr": 0.07135016465422613,
            "logloss": 10.269627014963776,
            "mae": 0.48025053627733644,
            "precision": 0.6976744186046512,
            "recall": 0.30120481927710846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.7937847490951935,
            "auditor_fn_violation": 0.011282317636195758,
            "auditor_fp_violation": 0.02223280240073869,
            "ave_precision_score": 0.7794747332350155,
            "fpr": 0.12171052631578948,
            "logloss": 1.3981016146083276,
            "mae": 0.2612354317569563,
            "precision": 0.7658227848101266,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7946857760345468,
            "auditor_fn_violation": 0.011863039424437598,
            "auditor_fp_violation": 0.02664501399361583,
            "ave_precision_score": 0.7817318782772871,
            "fpr": 0.14709110867178923,
            "logloss": 1.4910809476606783,
            "mae": 0.3029735037627186,
            "precision": 0.7351778656126482,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6580712019922033,
            "auditor_fn_violation": 0.02827793167128349,
            "auditor_fp_violation": 0.01145063865804863,
            "ave_precision_score": 0.6586651881347354,
            "fpr": 0.03179824561403509,
            "logloss": 2.23386466137382,
            "mae": 0.4208521701683565,
            "precision": 0.8,
            "recall": 0.2543859649122807
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.681184884533548,
            "auditor_fn_violation": 0.006617027936113278,
            "auditor_fp_violation": 0.010046698543228712,
            "ave_precision_score": 0.6818175498653631,
            "fpr": 0.03512623490669594,
            "logloss": 2.287030866004237,
            "mae": 0.4583994919724281,
            "precision": 0.7948717948717948,
            "recall": 0.24899598393574296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7625852382453374,
            "auditor_fn_violation": 0.0041118421052631655,
            "auditor_fp_violation": 0.02039088950446291,
            "ave_precision_score": 0.7412212162575063,
            "fpr": 0.14912280701754385,
            "logloss": 2.825889074234506,
            "mae": 0.30138105428551143,
            "precision": 0.7136842105263158,
            "recall": 0.743421052631579
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7650559996338206,
            "auditor_fn_violation": 0.012087868488222924,
            "auditor_fp_violation": 0.023856922255031995,
            "ave_precision_score": 0.7471688062822097,
            "fpr": 0.15806805708013172,
            "logloss": 3.045756658784875,
            "mae": 0.330393126070961,
            "precision": 0.7142857142857143,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6687085726315226,
            "auditor_fn_violation": 0.018765389350569414,
            "auditor_fp_violation": 0.008651700523237922,
            "ave_precision_score": 0.670026986992712,
            "fpr": 0.08991228070175439,
            "logloss": 2.3102675948841567,
            "mae": 0.40816704343220117,
            "precision": 0.7018181818181818,
            "recall": 0.4232456140350877
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6867963741036088,
            "auditor_fn_violation": 0.006885941130052604,
            "auditor_fp_violation": 0.012446743195222237,
            "ave_precision_score": 0.6882442489673322,
            "fpr": 0.09220636663007684,
            "logloss": 2.526430533193603,
            "mae": 0.4265253163244004,
            "precision": 0.7181208053691275,
            "recall": 0.42971887550200805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6450739308195519,
            "auditor_fn_violation": 0.004155124653739614,
            "auditor_fp_violation": 0.01465354724530624,
            "ave_precision_score": 0.6399888249490586,
            "fpr": 0.31798245614035087,
            "logloss": 1.8142438130724114,
            "mae": 0.3571188206166098,
            "precision": 0.5983379501385041,
            "recall": 0.9473684210526315
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6506229854759505,
            "auditor_fn_violation": 0.009561847830399534,
            "auditor_fp_violation": 0.012744423152058641,
            "ave_precision_score": 0.6481090308968631,
            "fpr": 0.300768386388584,
            "logloss": 1.7364150532552027,
            "mae": 0.35326066620570723,
            "precision": 0.6277173913043478,
            "recall": 0.927710843373494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7571331230779679,
            "auditor_fn_violation": 0.0043787511542012995,
            "auditor_fp_violation": 0.013569078947368422,
            "ave_precision_score": 0.7551219879611737,
            "fpr": 0.09758771929824561,
            "logloss": 2.2600280033901767,
            "mae": 0.3031203838800752,
            "precision": 0.770618556701031,
            "recall": 0.6557017543859649
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7700233038669866,
            "auditor_fn_violation": 0.011832180533329803,
            "auditor_fp_violation": 0.018216950215685073,
            "ave_precision_score": 0.7673241207467706,
            "fpr": 0.10976948408342481,
            "logloss": 2.5340765335215742,
            "mae": 0.34126230259522716,
            "precision": 0.7524752475247525,
            "recall": 0.6104417670682731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6514140848094474,
            "auditor_fn_violation": 0.004097414589104339,
            "auditor_fp_violation": 0.02028508771929824,
            "ave_precision_score": 0.6462939127708909,
            "fpr": 0.31469298245614036,
            "logloss": 1.7358538673719843,
            "mae": 0.35299570339868713,
            "precision": 0.6008344923504868,
            "recall": 0.9473684210526315
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6562636220887997,
            "auditor_fn_violation": 0.008151155665471988,
            "auditor_fp_violation": 0.01209059038972154,
            "ave_precision_score": 0.6537929827354562,
            "fpr": 0.29747530186608123,
            "logloss": 1.6561555279869447,
            "mae": 0.35012223336018333,
            "precision": 0.6297814207650273,
            "recall": 0.9257028112449799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8370407351019669,
            "auditor_fn_violation": 0.01072445367805479,
            "auditor_fp_violation": 0.015918359495229305,
            "ave_precision_score": 0.837465531757626,
            "fpr": 0.12390350877192982,
            "logloss": 0.5559918313092376,
            "mae": 0.2556788487442023,
            "precision": 0.7674897119341564,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8159306729219887,
            "auditor_fn_violation": 0.010743302518526355,
            "auditor_fp_violation": 0.019548536451176504,
            "ave_precision_score": 0.8164999295847022,
            "fpr": 0.1437980241492865,
            "logloss": 0.6833164974866889,
            "mae": 0.29290521427477595,
            "precision": 0.7495219885277247,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6667908072394764,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010623461064943059,
            "ave_precision_score": 0.666116635261802,
            "fpr": 0.1074561403508772,
            "logloss": 1.2161088555420987,
            "mae": 0.3541523047708899,
            "precision": 0.7277777777777777,
            "recall": 0.5745614035087719
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7350665802494908,
            "auditor_fn_violation": 0.0011505957970190388,
            "auditor_fp_violation": 0.01765880029661682,
            "ave_precision_score": 0.7342430247031781,
            "fpr": 0.10318331503841932,
            "logloss": 0.91539495305506,
            "mae": 0.35656609828087116,
            "precision": 0.7614213197969543,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.636304921520024,
            "auditor_fn_violation": 0.0004520621729763119,
            "auditor_fp_violation": 0.006867497691597418,
            "ave_precision_score": 0.6317489912999525,
            "fpr": 0.07894736842105263,
            "logloss": 9.466878208128918,
            "mae": 0.4468527567674266,
            "precision": 0.660377358490566,
            "recall": 0.30701754385964913
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6524043246634159,
            "auditor_fn_violation": 0.013657263521704838,
            "auditor_fp_violation": 0.003489765922555374,
            "ave_precision_score": 0.6540824929043298,
            "fpr": 0.07793633369923161,
            "logloss": 10.248643758461103,
            "mae": 0.47809002254046684,
            "precision": 0.6844444444444444,
            "recall": 0.3092369477911647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7229406448144099,
            "auditor_fn_violation": 0.005903258694983075,
            "auditor_fp_violation": 0.014413088642659283,
            "ave_precision_score": 0.7243892371788333,
            "fpr": 0.09429824561403509,
            "logloss": 2.1279653116727437,
            "mae": 0.35078222898111416,
            "precision": 0.7463126843657817,
            "recall": 0.5548245614035088
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7543803708894891,
            "auditor_fn_violation": 0.013502969066165873,
            "auditor_fp_violation": 0.019506010743057016,
            "ave_precision_score": 0.7550176087948908,
            "fpr": 0.09549945115257959,
            "logloss": 2.317223848766058,
            "mae": 0.3637606752465142,
            "precision": 0.768,
            "recall": 0.5783132530120482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7466351327603383,
            "auditor_fn_violation": 0.002373326408125582,
            "auditor_fp_violation": 0.007737957833179441,
            "ave_precision_score": 0.7410229826378436,
            "fpr": 0.08991228070175439,
            "logloss": 3.3245186951765087,
            "mae": 0.3428430819965158,
            "precision": 0.7476923076923077,
            "recall": 0.5328947368421053
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7557962979893225,
            "auditor_fn_violation": 0.0006215862351712132,
            "auditor_fp_violation": 0.01525078207435089,
            "ave_precision_score": 0.7518096620360484,
            "fpr": 0.09659714599341383,
            "logloss": 3.681166856034942,
            "mae": 0.3673955455159994,
            "precision": 0.7569060773480663,
            "recall": 0.5502008032128514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.7919035430226069,
            "auditor_fn_violation": 0.0022651200369344427,
            "auditor_fp_violation": 0.015326831332717759,
            "ave_precision_score": 0.7880495352898883,
            "fpr": 0.12609649122807018,
            "logloss": 1.0197116498455294,
            "mae": 0.2614455873039977,
            "precision": 0.7594142259414226,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7973968598622326,
            "auditor_fn_violation": 0.006841856999898612,
            "auditor_fp_violation": 0.02269809670877598,
            "ave_precision_score": 0.7940713924267886,
            "fpr": 0.16136114160263446,
            "logloss": 1.1219501652989454,
            "mae": 0.30251317312015424,
            "precision": 0.722117202268431,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7943031528396407,
            "auditor_fn_violation": 0.010084833795013856,
            "auditor_fp_violation": 0.011462661588180979,
            "ave_precision_score": 0.7947113847446774,
            "fpr": 0.09539473684210527,
            "logloss": 0.6117618246843487,
            "mae": 0.33269389853050696,
            "precision": 0.7583333333333333,
            "recall": 0.5986842105263158
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7816791402261606,
            "auditor_fn_violation": 0.027720101040826322,
            "auditor_fp_violation": 0.015458094901433388,
            "ave_precision_score": 0.7821040500249352,
            "fpr": 0.09879253567508232,
            "logloss": 0.6864372922616637,
            "mae": 0.3596762746785933,
            "precision": 0.7692307692307693,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8410488379929877,
            "auditor_fn_violation": 0.0025969529085872584,
            "auditor_fp_violation": 0.017139889196675903,
            "ave_precision_score": 0.8422186464620354,
            "fpr": 0.11513157894736842,
            "logloss": 0.8567785905934121,
            "mae": 0.26373091430477397,
            "precision": 0.7756410256410257,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8271308001488398,
            "auditor_fn_violation": 0.016430155308390537,
            "auditor_fp_violation": 0.012731133868271304,
            "ave_precision_score": 0.8271117849335815,
            "fpr": 0.13721185510428102,
            "logloss": 1.2242567479687598,
            "mae": 0.2973739486564936,
            "precision": 0.7539370078740157,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6479306957161564,
            "auditor_fn_violation": 0.016961949830717155,
            "auditor_fp_violation": 0.008447310710988004,
            "ave_precision_score": 0.649147269268926,
            "fpr": 0.12828947368421054,
            "logloss": 1.7737920539817915,
            "mae": 0.40668535208662676,
            "precision": 0.6598837209302325,
            "recall": 0.49780701754385964
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.674171190555539,
            "auditor_fn_violation": 0.014693240580323494,
            "auditor_fp_violation": 0.009087212253782796,
            "ave_precision_score": 0.6749175003393404,
            "fpr": 0.1251372118551043,
            "logloss": 2.3502632690165233,
            "mae": 0.43607027801693177,
            "precision": 0.6779661016949152,
            "recall": 0.4819277108433735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7148836197907394,
            "auditor_fn_violation": 0.011171706678978155,
            "auditor_fp_violation": 0.0019188596491228095,
            "ave_precision_score": 0.7150643785261646,
            "fpr": 0.08114035087719298,
            "logloss": 1.0801458776155208,
            "mae": 0.3265557337000613,
            "precision": 0.7927170868347339,
            "recall": 0.6206140350877193
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7612987434166948,
            "auditor_fn_violation": 0.01239866160580853,
            "auditor_fp_violation": 0.009788886437754324,
            "ave_precision_score": 0.7602991358165091,
            "fpr": 0.07574094401756312,
            "logloss": 0.8713658242022784,
            "mae": 0.3395920644471326,
            "precision": 0.8184210526315789,
            "recall": 0.6244979919678715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7211781038385255,
            "auditor_fn_violation": 0.0031956948291782094,
            "auditor_fp_violation": 0.018447983995075412,
            "ave_precision_score": 0.7178335009315894,
            "fpr": 0.2412280701754386,
            "logloss": 1.0294681519661673,
            "mae": 0.31784394995861875,
            "precision": 0.6524486571879937,
            "recall": 0.9057017543859649
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.720872977869324,
            "auditor_fn_violation": 0.00823932392577996,
            "auditor_fp_violation": 0.018216950215685073,
            "ave_precision_score": 0.7197678219826161,
            "fpr": 0.23600439077936333,
            "logloss": 0.9033429049831727,
            "mae": 0.3260673200149339,
            "precision": 0.6757164404223228,
            "recall": 0.8995983935742972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.4898958561181382,
            "auditor_fn_violation": 0.0036261157279162772,
            "auditor_fp_violation": 0.0018034395198522634,
            "ave_precision_score": 0.5156029505590163,
            "fpr": 0.019736842105263157,
            "logloss": 15.370845902740692,
            "mae": 0.4976716994738962,
            "precision": 0.5813953488372093,
            "recall": 0.05482456140350877
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.5545685083799607,
            "auditor_fn_violation": 0.003833115116889085,
            "auditor_fp_violation": 0.0034791344955254996,
            "ave_precision_score": 0.5612745790581686,
            "fpr": 0.021953896816684963,
            "logloss": 16.708648712297702,
            "mae": 0.5371877602120706,
            "precision": 0.6078431372549019,
            "recall": 0.06224899598393574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7008901452067678,
            "auditor_fn_violation": 0.016091489689135124,
            "auditor_fp_violation": 0.03125,
            "ave_precision_score": 0.701521861570616,
            "fpr": 0.125,
            "logloss": 0.6981538986334518,
            "mae": 0.35218581135166205,
            "precision": 0.75054704595186,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7353900010380083,
            "auditor_fn_violation": 0.010924047452157701,
            "auditor_fp_violation": 0.031437129727330475,
            "ave_precision_score": 0.7371715228930311,
            "fpr": 0.13172338090010977,
            "logloss": 0.6762827136849919,
            "mae": 0.35932005947784434,
            "precision": 0.7560975609756098,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6072389749449918,
            "auditor_fn_violation": 0.010330101569713776,
            "auditor_fp_violation": 0.01054170514004309,
            "ave_precision_score": 0.6057520066846098,
            "fpr": 0.043859649122807015,
            "logloss": 5.79555647336264,
            "mae": 0.4246018049083804,
            "precision": 0.7560975609756098,
            "recall": 0.2719298245614035
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6432099490319254,
            "auditor_fn_violation": 0.008880748019520456,
            "auditor_fp_violation": 0.00552834205553326,
            "ave_precision_score": 0.6421625081227444,
            "fpr": 0.048298572996706916,
            "logloss": 6.0546631414997645,
            "mae": 0.4654981668307982,
            "precision": 0.7456647398843931,
            "recall": 0.25903614457831325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7944385536246994,
            "auditor_fn_violation": 0.007882232994767622,
            "auditor_fp_violation": 0.005771006463527238,
            "ave_precision_score": 0.7943782324975265,
            "fpr": 0.05263157894736842,
            "logloss": 2.019006296241499,
            "mae": 0.3494840048563858,
            "precision": 0.8273381294964028,
            "recall": 0.5043859649122807
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7695005729473536,
            "auditor_fn_violation": 0.019454326636953973,
            "auditor_fp_violation": 0.010160986383799833,
            "ave_precision_score": 0.7696305168474129,
            "fpr": 0.06256860592755215,
            "logloss": 2.31202785529122,
            "mae": 0.38532928622786367,
            "precision": 0.8067796610169492,
            "recall": 0.4779116465863454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8528899303921069,
            "auditor_fn_violation": 0.020580851800554023,
            "auditor_fp_violation": 0.018580236226531245,
            "ave_precision_score": 0.8531678999771233,
            "fpr": 0.09100877192982457,
            "logloss": 0.6927875299054715,
            "mae": 0.29154285553133963,
            "precision": 0.7995169082125604,
            "recall": 0.7258771929824561
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8354423855589057,
            "auditor_fn_violation": 0.03532020507937348,
            "auditor_fp_violation": 0.023745292271218337,
            "ave_precision_score": 0.8357106942626489,
            "fpr": 0.10647639956092206,
            "logloss": 0.8895026328320803,
            "mae": 0.32168090053908976,
            "precision": 0.7868131868131868,
            "recall": 0.7188755020080321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7863719899992097,
            "auditor_fn_violation": 0.008793571098799632,
            "auditor_fp_violation": 0.01727935518621114,
            "ave_precision_score": 0.7779704844476836,
            "fpr": 0.1206140350877193,
            "logloss": 1.2488198400134054,
            "mae": 0.2589023664139158,
            "precision": 0.7624190064794817,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.792399609764691,
            "auditor_fn_violation": 0.015061343067109278,
            "auditor_fp_violation": 0.02498385352019838,
            "ave_precision_score": 0.7863274369015221,
            "fpr": 0.1437980241492865,
            "logloss": 1.3439125433187586,
            "mae": 0.3040425442398642,
            "precision": 0.7390438247011952,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7006875745434148,
            "auditor_fn_violation": 0.011498730378578024,
            "auditor_fp_violation": 0.021136311172668516,
            "ave_precision_score": 0.701551081349432,
            "fpr": 0.17763157894736842,
            "logloss": 1.2896329222923453,
            "mae": 0.3804298294837371,
            "precision": 0.6516129032258065,
            "recall": 0.6644736842105263
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6996901543647825,
            "auditor_fn_violation": 0.015612394694034101,
            "auditor_fp_violation": 0.017092676807276153,
            "ave_precision_score": 0.7003696715984954,
            "fpr": 0.16794731064763996,
            "logloss": 1.744048945981407,
            "mae": 0.4171147318400718,
            "precision": 0.6688311688311688,
            "recall": 0.6204819277108434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5429220116951032,
            "auditor_fn_violation": 0.02826350415512467,
            "auditor_fp_violation": 0.017094202062172978,
            "ave_precision_score": 0.5443489947048559,
            "fpr": 0.0581140350877193,
            "logloss": 1.3950569342628516,
            "mae": 0.478677835975138,
            "precision": 0.6102941176470589,
            "recall": 0.18201754385964913
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5902533224304863,
            "auditor_fn_violation": 0.016125974810328025,
            "auditor_fp_violation": 0.022679491711473702,
            "ave_precision_score": 0.5915671683546778,
            "fpr": 0.06147091108671789,
            "logloss": 1.42934064676511,
            "mae": 0.5030629624869932,
            "precision": 0.6363636363636364,
            "recall": 0.19678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8280975039115822,
            "auditor_fn_violation": 0.00827177593105571,
            "auditor_fp_violation": 0.018842336103416436,
            "ave_precision_score": 0.827283135447485,
            "fpr": 0.1337719298245614,
            "logloss": 0.8853319797964062,
            "mae": 0.29266267421395564,
            "precision": 0.7330415754923414,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8103579884097768,
            "auditor_fn_violation": 0.01972764824390868,
            "auditor_fp_violation": 0.013446097336030173,
            "ave_precision_score": 0.8096207285263852,
            "fpr": 0.14928649835345773,
            "logloss": 1.0406549853559794,
            "mae": 0.3288334804494531,
            "precision": 0.7235772357723578,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7917603546895116,
            "auditor_fn_violation": 0.0022218374884579867,
            "auditor_fp_violation": 0.025378000923361035,
            "ave_precision_score": 0.7917700985759297,
            "fpr": 0.1611842105263158,
            "logloss": 1.9674503042978007,
            "mae": 0.33334045585009614,
            "precision": 0.6931106471816284,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7855510247724626,
            "auditor_fn_violation": 0.014684423754292691,
            "auditor_fp_violation": 0.012255377508684556,
            "ave_precision_score": 0.7856733028791799,
            "fpr": 0.15148188803512624,
            "logloss": 2.2196700875224296,
            "mae": 0.3506782084165252,
            "precision": 0.7183673469387755,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8607720524148925,
            "auditor_fn_violation": 0.012845298553401049,
            "auditor_fp_violation": 0.024055478608802708,
            "ave_precision_score": 0.8612237727002967,
            "fpr": 0.10087719298245613,
            "logloss": 0.6236627864421335,
            "mae": 0.26061517651119864,
            "precision": 0.7899543378995434,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8422065540397152,
            "auditor_fn_violation": 0.02827556108076654,
            "auditor_fp_violation": 0.020385761329778894,
            "ave_precision_score": 0.8424220699138365,
            "fpr": 0.12952799121844127,
            "logloss": 0.7595648558126893,
            "mae": 0.30706439026528015,
            "precision": 0.7541666666666667,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8000196964782404,
            "auditor_fn_violation": 0.007069482917820878,
            "auditor_fp_violation": 0.008108264081255773,
            "ave_precision_score": 0.7992223202107441,
            "fpr": 0.06578947368421052,
            "logloss": 1.1570560277207753,
            "mae": 0.30404303339889793,
            "precision": 0.8076923076923077,
            "recall": 0.5526315789473685
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7969039853196566,
            "auditor_fn_violation": 0.010540515519818022,
            "auditor_fp_violation": 0.015426200620343769,
            "ave_precision_score": 0.7961543055659972,
            "fpr": 0.0801317233809001,
            "logloss": 1.3059184154238122,
            "mae": 0.34216688218510366,
            "precision": 0.7871720116618076,
            "recall": 0.5421686746987951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8658378587537081,
            "auditor_fn_violation": 0.0038208871960603258,
            "auditor_fp_violation": 0.02073234072022161,
            "ave_precision_score": 0.8660461218673512,
            "fpr": 0.12609649122807018,
            "logloss": 0.5650116024157963,
            "mae": 0.27095140466326095,
            "precision": 0.7604166666666666,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.825620865696772,
            "auditor_fn_violation": 0.008503828706703884,
            "auditor_fp_violation": 0.017749167426370727,
            "ave_precision_score": 0.8259433470981437,
            "fpr": 0.15148188803512624,
            "logloss": 0.6830173311724721,
            "mae": 0.3096085322932735,
            "precision": 0.73046875,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 6126,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7118232500078946,
            "auditor_fn_violation": 0.005617112957833179,
            "auditor_fp_violation": 0.010462353801169593,
            "ave_precision_score": 0.7135103073783248,
            "fpr": 0.10416666666666667,
            "logloss": 1.3140478571730871,
            "mae": 0.3654093307616005,
            "precision": 0.7323943661971831,
            "recall": 0.5701754385964912
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.724482474912677,
            "auditor_fn_violation": 0.008741883009535401,
            "auditor_fp_violation": 0.00693966399374872,
            "ave_precision_score": 0.7259758474956878,
            "fpr": 0.11525795828759605,
            "logloss": 1.579040066633955,
            "mae": 0.38887523308780797,
            "precision": 0.7244094488188977,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7098128911298507,
            "auditor_fn_violation": 0.009868421052631589,
            "auditor_fp_violation": 0.0015581717451523549,
            "ave_precision_score": 0.7106129474204147,
            "fpr": 0.009868421052631578,
            "logloss": 1.445714636417688,
            "mae": 0.4539063644568632,
            "precision": 0.8085106382978723,
            "recall": 0.08333333333333333
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.7014433863122453,
            "auditor_fn_violation": 0.0036193070856422632,
            "auditor_fp_violation": 0.005993466988090145,
            "ave_precision_score": 0.702290652683424,
            "fpr": 0.014270032930845226,
            "logloss": 1.661033823117275,
            "mae": 0.5001724451392098,
            "precision": 0.7450980392156863,
            "recall": 0.07630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8631323713857952,
            "auditor_fn_violation": 0.004349896121883657,
            "auditor_fp_violation": 0.018481648199445987,
            "ave_precision_score": 0.863355731418557,
            "fpr": 0.12828947368421054,
            "logloss": 0.5826190826079044,
            "mae": 0.2727953312790966,
            "precision": 0.75625,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8249145717265367,
            "auditor_fn_violation": 0.010143758348432149,
            "auditor_fp_violation": 0.01837907947789062,
            "ave_precision_score": 0.8252451524026658,
            "fpr": 0.15477497255762898,
            "logloss": 0.70060955734232,
            "mae": 0.31136780284110316,
            "precision": 0.7267441860465116,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8006209637468951,
            "auditor_fn_violation": 0.009392313019390584,
            "auditor_fp_violation": 0.012443732686980619,
            "ave_precision_score": 0.7992093995804859,
            "fpr": 0.12828947368421054,
            "logloss": 0.8311033659811112,
            "mae": 0.2603771993610966,
            "precision": 0.755741127348643,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8039312712369852,
            "auditor_fn_violation": 0.005717711680971971,
            "auditor_fp_violation": 0.019947214964796685,
            "ave_precision_score": 0.8033924128932862,
            "fpr": 0.15587266739846323,
            "logloss": 0.9193130173042001,
            "mae": 0.30051584381254554,
            "precision": 0.7290076335877863,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7862245501372916,
            "auditor_fn_violation": 0.009216778239458299,
            "auditor_fp_violation": 0.01595683287165282,
            "ave_precision_score": 0.7673715338389482,
            "fpr": 0.12171052631578948,
            "logloss": 1.6359551347682464,
            "mae": 0.26156625247638166,
            "precision": 0.7607758620689655,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7893671508927167,
            "auditor_fn_violation": 0.011223819537204811,
            "auditor_fp_violation": 0.020327288481114595,
            "ave_precision_score": 0.7748140042659064,
            "fpr": 0.14709110867178923,
            "logloss": 1.6987894367945624,
            "mae": 0.304206816959739,
            "precision": 0.7341269841269841,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8037201876526809,
            "auditor_fn_violation": 0.004462911665127736,
            "auditor_fp_violation": 0.012999192059095107,
            "ave_precision_score": 0.8036683621756446,
            "fpr": 0.08881578947368421,
            "logloss": 2.0052041715414886,
            "mae": 0.3222976872202991,
            "precision": 0.7780821917808219,
            "recall": 0.6228070175438597
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.792860367674117,
            "auditor_fn_violation": 0.00931056828852182,
            "auditor_fp_violation": 0.013358388063033737,
            "ave_precision_score": 0.7928981100815282,
            "fpr": 0.0867178924259056,
            "logloss": 2.2735416576051772,
            "mae": 0.35337538091551823,
            "precision": 0.7915567282321899,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7525428902587825,
            "auditor_fn_violation": 0.0040974145891043414,
            "auditor_fp_violation": 0.005597876269621424,
            "ave_precision_score": 0.7526778518059565,
            "fpr": 0.07894736842105263,
            "logloss": 2.092883232408484,
            "mae": 0.34876456653417565,
            "precision": 0.7707006369426752,
            "recall": 0.5307017543859649
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7603753380891918,
            "auditor_fn_violation": 0.012026150706007353,
            "auditor_fp_violation": 0.01452784503631961,
            "ave_precision_score": 0.7608477593800936,
            "fpr": 0.07903402854006586,
            "logloss": 2.33414007315114,
            "mae": 0.36577942107443984,
            "precision": 0.7942857142857143,
            "recall": 0.5582329317269076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6466385165957748,
            "auditor_fn_violation": 0.00699013157894737,
            "auditor_fp_violation": 0.011604532163742692,
            "ave_precision_score": 0.6416034586788586,
            "fpr": 0.041666666666666664,
            "logloss": 9.561744468593545,
            "mae": 0.4298341666779258,
            "precision": 0.7777777777777778,
            "recall": 0.2916666666666667
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6529956788168356,
            "auditor_fn_violation": 0.017549892214301793,
            "auditor_fp_violation": 0.009283893653835421,
            "ave_precision_score": 0.6524008588506411,
            "fpr": 0.059275521405049394,
            "logloss": 10.130351703229309,
            "mae": 0.46404702681891496,
            "precision": 0.7403846153846154,
            "recall": 0.3092369477911647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7434175456357971,
            "auditor_fn_violation": 0.02420937211449677,
            "auditor_fp_violation": 0.028099992305324718,
            "ave_precision_score": 0.7403728130275323,
            "fpr": 0.0800438596491228,
            "logloss": 1.0177911462547111,
            "mae": 0.32974371543606823,
            "precision": 0.7859237536656891,
            "recall": 0.5877192982456141
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7740515138995714,
            "auditor_fn_violation": 0.010337728521109696,
            "auditor_fp_violation": 0.022663544570928895,
            "ave_precision_score": 0.7727188708032884,
            "fpr": 0.0867178924259056,
            "logloss": 0.839391754571675,
            "mae": 0.35171536894158756,
            "precision": 0.7887700534759359,
            "recall": 0.5923694779116466
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6909217191644321,
            "auditor_fn_violation": 0.004876500461680518,
            "auditor_fp_violation": 0.014667974761465068,
            "ave_precision_score": 0.6917392109190403,
            "fpr": 0.3706140350877193,
            "logloss": 1.168459130553338,
            "mae": 0.4153215643258463,
            "precision": 0.554089709762533,
            "recall": 0.9210526315789473
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7419204569108712,
            "auditor_fn_violation": 0.0043070195160444195,
            "auditor_fp_violation": 0.007011426126200364,
            "ave_precision_score": 0.74236745314388,
            "fpr": 0.36663007683863885,
            "logloss": 1.0934577046296707,
            "mae": 0.4059427281489962,
            "precision": 0.5793450881612091,
            "recall": 0.9236947791164659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8289430831757308,
            "auditor_fn_violation": 0.009029220529393662,
            "auditor_fp_violation": 0.023459141274238232,
            "ave_precision_score": 0.8293051326678351,
            "fpr": 0.16776315789473684,
            "logloss": 0.767351012030969,
            "mae": 0.27100559947951486,
            "precision": 0.7057692307692308,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8157348648238081,
            "auditor_fn_violation": 0.011170918581020017,
            "auditor_fp_violation": 0.025191166347280886,
            "ave_precision_score": 0.816964429413576,
            "fpr": 0.17672886937431395,
            "logloss": 0.8784206057941812,
            "mae": 0.29967098519816654,
            "precision": 0.7099099099099099,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6414469002680616,
            "auditor_fn_violation": 0.0017313019390581717,
            "auditor_fp_violation": 0.02077321868267159,
            "ave_precision_score": 0.6364420794996961,
            "fpr": 0.24451754385964913,
            "logloss": 1.5417768086790427,
            "mae": 0.345341665050106,
            "precision": 0.6326194398682042,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6456391079326104,
            "auditor_fn_violation": 0.009072513985690292,
            "auditor_fp_violation": 0.010984921978614892,
            "ave_precision_score": 0.6432372368072587,
            "fpr": 0.24368825466520308,
            "logloss": 1.4958239813087806,
            "mae": 0.3635523389194679,
            "precision": 0.6476190476190476,
            "recall": 0.8192771084337349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7773415658679618,
            "auditor_fn_violation": 0.010541705140043094,
            "auditor_fp_violation": 0.0006588565712526947,
            "ave_precision_score": 0.7777595310186152,
            "fpr": 0.02850877192982456,
            "logloss": 0.7802843489986145,
            "mae": 0.38611507329915185,
            "precision": 0.856353591160221,
            "recall": 0.3399122807017544
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7498733295620231,
            "auditor_fn_violation": 0.0003703066932934961,
            "auditor_fp_violation": 0.007665258888537462,
            "ave_precision_score": 0.7505123407027361,
            "fpr": 0.043907793633369926,
            "logloss": 0.8862803062743236,
            "mae": 0.42773214450543573,
            "precision": 0.7927461139896373,
            "recall": 0.3072289156626506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7959117438046133,
            "auditor_fn_violation": 0.007509522160664819,
            "auditor_fp_violation": 0.004862072945521701,
            "ave_precision_score": 0.7958407986197025,
            "fpr": 0.046052631578947366,
            "logloss": 2.0150943768839302,
            "mae": 0.34927482878462124,
            "precision": 0.8450184501845018,
            "recall": 0.5021929824561403
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7729799213505852,
            "auditor_fn_violation": 0.021213283430098026,
            "auditor_fp_violation": 0.010809503432622004,
            "ave_precision_score": 0.7730912761093597,
            "fpr": 0.06147091108671789,
            "logloss": 2.3090100179543684,
            "mae": 0.38535477732208656,
            "precision": 0.8095238095238095,
            "recall": 0.4779116465863454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8052508926959339,
            "auditor_fn_violation": 0.010099261311172683,
            "auditor_fp_violation": 0.013138658048630347,
            "ave_precision_score": 0.8056954033151911,
            "fpr": 0.09649122807017543,
            "logloss": 0.7822992956651265,
            "mae": 0.28863710942862214,
            "precision": 0.7810945273631841,
            "recall": 0.6885964912280702
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8023664494145244,
            "auditor_fn_violation": 0.010950497930250092,
            "auditor_fp_violation": 0.017711957431766172,
            "ave_precision_score": 0.802748441719427,
            "fpr": 0.11525795828759605,
            "logloss": 0.8882287987917387,
            "mae": 0.32568961584981476,
            "precision": 0.75177304964539,
            "recall": 0.6385542168674698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7917775071094185,
            "auditor_fn_violation": 0.018181074946137275,
            "auditor_fp_violation": 0.025926246537396128,
            "ave_precision_score": 0.7927691566383865,
            "fpr": 0.10855263157894737,
            "logloss": 0.9806943837905144,
            "mae": 0.3036375724968643,
            "precision": 0.7620192307692307,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8157377412519962,
            "auditor_fn_violation": 0.041491983300931505,
            "auditor_fp_violation": 0.025236349912157834,
            "ave_precision_score": 0.8160690217808664,
            "fpr": 0.10867178924259056,
            "logloss": 1.1902151704070827,
            "mae": 0.3223963356774759,
            "precision": 0.7804878048780488,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.748348072887807,
            "auditor_fn_violation": 0.00026209987688520026,
            "auditor_fp_violation": 0.021270967990150814,
            "ave_precision_score": 0.7487408078957282,
            "fpr": 0.13267543859649122,
            "logloss": 1.9922956245549959,
            "mae": 0.3393078710198664,
            "precision": 0.7132701421800948,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7578756231203634,
            "auditor_fn_violation": 0.01501285052393989,
            "auditor_fp_violation": 0.01706609823970148,
            "ave_precision_score": 0.7583320352450331,
            "fpr": 0.12184412733260154,
            "logloss": 2.2433476920815543,
            "mae": 0.35313717681499335,
            "precision": 0.7477272727272727,
            "recall": 0.6606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8542495098617723,
            "auditor_fn_violation": 0.00448695752539243,
            "auditor_fp_violation": 0.020982417666974455,
            "ave_precision_score": 0.8546164300915919,
            "fpr": 0.10635964912280702,
            "logloss": 0.5681088705068084,
            "mae": 0.29745340103226336,
            "precision": 0.7849223946784922,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8170552909089634,
            "auditor_fn_violation": 0.009557439417384142,
            "auditor_fp_violation": 0.017443513899261916,
            "ave_precision_score": 0.8183821342052156,
            "fpr": 0.12623490669593854,
            "logloss": 0.7914472791364243,
            "mae": 0.329053793149529,
            "precision": 0.7633744855967078,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6783612174640069,
            "auditor_fn_violation": 0.008168378731917522,
            "auditor_fp_violation": 0.01804160895660204,
            "ave_precision_score": 0.6793135663462877,
            "fpr": 0.22039473684210525,
            "logloss": 0.9243317548074754,
            "mae": 0.39452015316217576,
            "precision": 0.6221804511278195,
            "recall": 0.7258771929824561
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7188406168528984,
            "auditor_fn_violation": 0.010126124696370555,
            "auditor_fp_violation": 0.022881488825041266,
            "ave_precision_score": 0.7194736479576334,
            "fpr": 0.20197585071350166,
            "logloss": 0.8949616082065607,
            "mae": 0.392838094192043,
            "precision": 0.6528301886792452,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7099294690813905,
            "auditor_fn_violation": 0.009413954293628821,
            "auditor_fp_violation": 0.010661934441366577,
            "ave_precision_score": 0.7100451146125405,
            "fpr": 0.046052631578947366,
            "logloss": 2.6609478681435026,
            "mae": 0.38708569857568026,
            "precision": 0.7951219512195122,
            "recall": 0.3574561403508772
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7205212201450646,
            "auditor_fn_violation": 0.006747076120067555,
            "auditor_fp_violation": 0.010086566394590732,
            "ave_precision_score": 0.7213763233460505,
            "fpr": 0.04061470911086718,
            "logloss": 2.891136128715024,
            "mae": 0.4179529076830459,
            "precision": 0.8131313131313131,
            "recall": 0.3232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7237643920943102,
            "auditor_fn_violation": 0.015733206371191143,
            "auditor_fp_violation": 0.00018755771006463654,
            "ave_precision_score": 0.7245442859969109,
            "fpr": 0.01864035087719298,
            "logloss": 2.079088284051662,
            "mae": 0.4108462255775595,
            "precision": 0.8629032258064516,
            "recall": 0.23464912280701755
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7470093605522966,
            "auditor_fn_violation": 0.01151918320923652,
            "auditor_fp_violation": 0.007994833126463484,
            "ave_precision_score": 0.7474231205407764,
            "fpr": 0.021953896816684963,
            "logloss": 2.198097627457355,
            "mae": 0.4529202454143643,
            "precision": 0.84,
            "recall": 0.21084337349397592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6061131075838369,
            "auditor_fn_violation": 0.015158510310864891,
            "auditor_fp_violation": 0.004289781471221916,
            "ave_precision_score": 0.605712457682023,
            "fpr": 0.03070175438596491,
            "logloss": 6.042987106672433,
            "mae": 0.4288552591412832,
            "precision": 0.7971014492753623,
            "recall": 0.2412280701754386
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6389230079532087,
            "auditor_fn_violation": 0.013569095261396841,
            "auditor_fp_violation": 0.004316359374127891,
            "ave_precision_score": 0.6371233235620046,
            "fpr": 0.03512623490669594,
            "logloss": 6.3244552243215795,
            "mae": 0.4765008665238106,
            "precision": 0.7538461538461538,
            "recall": 0.19678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6250055579225794,
            "auditor_fn_violation": 0.0005843144044321408,
            "auditor_fp_violation": 0.0070189866112650035,
            "ave_precision_score": 0.6204017040455909,
            "fpr": 0.05592105263157895,
            "logloss": 9.510742089257615,
            "mae": 0.44283691557120386,
            "precision": 0.7166666666666667,
            "recall": 0.28289473684210525
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6452148477510183,
            "auditor_fn_violation": 0.012358985888669953,
            "auditor_fp_violation": 0.003263848098170599,
            "ave_precision_score": 0.6469675838634524,
            "fpr": 0.059275521405049394,
            "logloss": 10.296960462030764,
            "mae": 0.47923057162117,
            "precision": 0.7230769230769231,
            "recall": 0.28313253012048195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7781664117325664,
            "auditor_fn_violation": 0.009986245767928595,
            "auditor_fp_violation": 0.012919840720221606,
            "ave_precision_score": 0.7731541834397276,
            "fpr": 0.0800438596491228,
            "logloss": 0.9964922944321426,
            "mae": 0.30984043518106597,
            "precision": 0.7914285714285715,
            "recall": 0.6074561403508771
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8000266282454975,
            "auditor_fn_violation": 0.020459444804464842,
            "auditor_fp_violation": 0.00933970864574225,
            "ave_precision_score": 0.7973301016809029,
            "fpr": 0.07683863885839737,
            "logloss": 0.8010941565108712,
            "mae": 0.3398044262392973,
            "precision": 0.8076923076923077,
            "recall": 0.5903614457831325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6894001915569942,
            "auditor_fn_violation": 0.011772853185595577,
            "auditor_fp_violation": 0.009637580794090488,
            "ave_precision_score": 0.6903281591959399,
            "fpr": 0.0756578947368421,
            "logloss": 1.023521828467872,
            "mae": 0.376992824387064,
            "precision": 0.7553191489361702,
            "recall": 0.46710526315789475
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7405562223100479,
            "auditor_fn_violation": 0.006187207667111917,
            "auditor_fp_violation": 0.013337125208973991,
            "ave_precision_score": 0.7411110200649085,
            "fpr": 0.0889132821075741,
            "logloss": 0.9901449515832838,
            "mae": 0.3914975393869094,
            "precision": 0.7317880794701986,
            "recall": 0.44377510040160645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7713186860991251,
            "auditor_fn_violation": 0.0045446675900277025,
            "auditor_fp_violation": 0.028220221606648204,
            "ave_precision_score": 0.7505715822464187,
            "fpr": 0.24013157894736842,
            "logloss": 2.7930732099609092,
            "mae": 0.3131037828708737,
            "precision": 0.6427406199021207,
            "recall": 0.8640350877192983
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7712562860291456,
            "auditor_fn_violation": 0.011882877283006896,
            "auditor_fp_violation": 0.024877539249899678,
            "ave_precision_score": 0.7531398988362933,
            "fpr": 0.23380900109769484,
            "logloss": 3.0464123254405857,
            "mae": 0.3273041283005687,
            "precision": 0.6650943396226415,
            "recall": 0.8493975903614458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8263515215455869,
            "auditor_fn_violation": 0.005121768236380426,
            "auditor_fp_violation": 0.007848568790397048,
            "ave_precision_score": 0.8276608373480381,
            "fpr": 0.046052631578947366,
            "logloss": 0.8320717845915996,
            "mae": 0.2964018394783538,
            "precision": 0.86,
            "recall": 0.5657894736842105
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.823227252937395,
            "auditor_fn_violation": 0.0049021552731232316,
            "auditor_fp_violation": 0.0110832626786412,
            "ave_precision_score": 0.8234759934914667,
            "fpr": 0.06695938529088913,
            "logloss": 0.9450469621716836,
            "mae": 0.33261499731343747,
            "precision": 0.8134556574923547,
            "recall": 0.5341365461847389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5366096540289761,
            "auditor_fn_violation": 0.002935999538319491,
            "auditor_fp_violation": 0.0018611495844875353,
            "ave_precision_score": 0.5368342709467829,
            "fpr": 0.009868421052631578,
            "logloss": 13.890945419695758,
            "mae": 0.4855024846336027,
            "precision": 0.7352941176470589,
            "recall": 0.05482456140350877
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.6053192461031205,
            "auditor_fn_violation": 0.0027508497216087334,
            "auditor_fp_violation": 0.0014910576409394995,
            "ave_precision_score": 0.5928203464475243,
            "fpr": 0.014270032930845226,
            "logloss": 15.013192957519502,
            "mae": 0.5270683653736388,
            "precision": 0.675,
            "recall": 0.05421686746987952
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7778123447409446,
            "auditor_fn_violation": 0.009926131117266857,
            "auditor_fp_violation": 0.01815702908587258,
            "ave_precision_score": 0.7747405478248766,
            "fpr": 0.13267543859649122,
            "logloss": 1.0653235127016467,
            "mae": 0.26857195415740664,
            "precision": 0.7505154639175258,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7633308760712015,
            "auditor_fn_violation": 0.012973959504318044,
            "auditor_fp_violation": 0.025278875620277332,
            "ave_precision_score": 0.7564981608506552,
            "fpr": 0.15806805708013172,
            "logloss": 1.3349403176699337,
            "mae": 0.30645596463499386,
            "precision": 0.7246653919694073,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5418156149257141,
            "auditor_fn_violation": 0.0017024469067405295,
            "auditor_fp_violation": 0.004645660203139428,
            "ave_precision_score": 0.5420266654970887,
            "fpr": 0.013157894736842105,
            "logloss": 13.746986716612646,
            "mae": 0.4813562334608321,
            "precision": 0.6923076923076923,
            "recall": 0.05921052631578947
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.6077140165400008,
            "auditor_fn_violation": 0.0028720810795321797,
            "auditor_fp_violation": 0.00303261456027089,
            "ave_precision_score": 0.5952008501512995,
            "fpr": 0.01756311745334797,
            "logloss": 14.823206779610212,
            "mae": 0.5230253728174948,
            "precision": 0.6595744680851063,
            "recall": 0.06224899598393574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6898040573263113,
            "auditor_fn_violation": 0.013333429516774395,
            "auditor_fp_violation": 0.00311634349030471,
            "ave_precision_score": 0.6864657293528582,
            "fpr": 0.013157894736842105,
            "logloss": 6.396410183628374,
            "mae": 0.41045373594909346,
            "precision": 0.905511811023622,
            "recall": 0.25219298245614036
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.684857270044708,
            "auditor_fn_violation": 0.007921918188671263,
            "auditor_fp_violation": 0.006009414128634952,
            "ave_precision_score": 0.6827624410854324,
            "fpr": 0.02305159165751921,
            "logloss": 6.882192013077134,
            "mae": 0.46452163890719356,
            "precision": 0.8292682926829268,
            "recall": 0.20481927710843373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.76669787847526,
            "auditor_fn_violation": 0.0069636811326562005,
            "auditor_fp_violation": 0.021881732840874114,
            "ave_precision_score": 0.7665004946875172,
            "fpr": 0.13925438596491227,
            "logloss": 2.2615476478027703,
            "mae": 0.35673259341616426,
            "precision": 0.6976190476190476,
            "recall": 0.6425438596491229
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7528948012631415,
            "auditor_fn_violation": 0.015493367542618338,
            "auditor_fp_violation": 0.01267000316284954,
            "ave_precision_score": 0.7529339098293477,
            "fpr": 0.12294182217343579,
            "logloss": 2.5671961818900124,
            "mae": 0.3751101377054986,
            "precision": 0.7339667458432304,
            "recall": 0.6204819277108434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8368724237727929,
            "auditor_fn_violation": 0.018092105263157895,
            "auditor_fp_violation": 0.00791830178516467,
            "ave_precision_score": 0.8382394148526654,
            "fpr": 0.025219298245614034,
            "logloss": 0.7873705690280317,
            "mae": 0.3075785814033012,
            "precision": 0.9083665338645418,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8354348177337775,
            "auditor_fn_violation": 0.03246796185841059,
            "auditor_fp_violation": 0.011638754740951994,
            "ave_precision_score": 0.8356703034223432,
            "fpr": 0.03951701427003293,
            "logloss": 0.9162727869468089,
            "mae": 0.34449497526576395,
            "precision": 0.8723404255319149,
            "recall": 0.4939759036144578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7953169002967958,
            "auditor_fn_violation": 0.010791782086795945,
            "auditor_fp_violation": 0.004587950138504157,
            "ave_precision_score": 0.7952523828336358,
            "fpr": 0.05043859649122807,
            "logloss": 2.0092099944436086,
            "mae": 0.34863088426960187,
            "precision": 0.8351254480286738,
            "recall": 0.5109649122807017
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7702509747141375,
            "auditor_fn_violation": 0.021010496431389664,
            "auditor_fp_violation": 0.011109841246215876,
            "ave_precision_score": 0.770384916545357,
            "fpr": 0.06366630076838639,
            "logloss": 2.302044522826388,
            "mae": 0.3842683757989201,
            "precision": 0.8060200668896321,
            "recall": 0.4839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6587398254090003,
            "auditor_fn_violation": 0.01722404970760234,
            "auditor_fp_violation": 0.015903931979070477,
            "ave_precision_score": 0.6600630861024817,
            "fpr": 0.24780701754385964,
            "logloss": 1.2664821671430486,
            "mae": 0.40463143907674637,
            "precision": 0.583793738489871,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6770354282825072,
            "auditor_fn_violation": 0.004489968656183472,
            "auditor_fp_violation": 0.017246832499209296,
            "ave_precision_score": 0.6787325908632688,
            "fpr": 0.23819978046103182,
            "logloss": 1.2494378136122646,
            "mae": 0.3968869735649664,
            "precision": 0.6245674740484429,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8071864123944675,
            "auditor_fn_violation": 0.0033760387811634404,
            "auditor_fp_violation": 0.0050977223761157296,
            "ave_precision_score": 0.802959290996002,
            "fpr": 0.0537280701754386,
            "logloss": 0.8893387955410395,
            "mae": 0.2893383467328317,
            "precision": 0.8563049853372434,
            "recall": 0.6403508771929824
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8242906887603367,
            "auditor_fn_violation": 0.004963873055338817,
            "auditor_fp_violation": 0.01198427611942282,
            "ave_precision_score": 0.8225073901372154,
            "fpr": 0.07574094401756312,
            "logloss": 0.7451257387278479,
            "mae": 0.3198107000861167,
            "precision": 0.8207792207792208,
            "recall": 0.6345381526104418
        }
    }
]