[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7077513135319948,
            "auditor_fn_violation": 0.0034388907278678905,
            "auditor_fp_violation": 0.015449183303085314,
            "ave_precision_score": 0.7048278592493303,
            "fpr": 0.25877192982456143,
            "logloss": 1.6928767196643493,
            "mae": 0.37656901125292797,
            "precision": 0.6143790849673203,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7249093257295735,
            "auditor_fn_violation": 0.008001435978156564,
            "auditor_fp_violation": 0.016270670302043138,
            "ave_precision_score": 0.7226382168291468,
            "fpr": 0.2535675082327113,
            "logloss": 1.424377704903894,
            "mae": 0.3728059831054627,
            "precision": 0.6181818181818182,
            "recall": 0.7840670859538784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7762190145821861,
            "auditor_fn_violation": 0.032239600573761455,
            "auditor_fp_violation": 0.023633797136519464,
            "ave_precision_score": 0.7743950366628449,
            "fpr": 0.11732456140350878,
            "logloss": 2.1984698811166066,
            "mae": 0.3035256036080962,
            "precision": 0.7632743362831859,
            "recall": 0.7232704402515723
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8011941116003074,
            "auditor_fn_violation": 0.030544452038559697,
            "auditor_fp_violation": 0.02481953795646654,
            "ave_precision_score": 0.8018804908961016,
            "fpr": 0.12623490669593854,
            "logloss": 2.2236582158899605,
            "mae": 0.29694481256407823,
            "precision": 0.7542735042735043,
            "recall": 0.740041928721174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7845997842392876,
            "auditor_fn_violation": 0.009889109566368752,
            "auditor_fp_violation": 0.0391938898971567,
            "ave_precision_score": 0.7635269540602573,
            "fpr": 0.3267543859649123,
            "logloss": 2.440448906478406,
            "mae": 0.36110379811417465,
            "precision": 0.5967523680649527,
            "recall": 0.9245283018867925
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7841331381858123,
            "auditor_fn_violation": 0.006728846361843484,
            "auditor_fp_violation": 0.03278414867947818,
            "ave_precision_score": 0.7560226160239172,
            "fpr": 0.31174533479692645,
            "logloss": 2.755039368147129,
            "mae": 0.3458363097370726,
            "precision": 0.6104252400548696,
            "recall": 0.9329140461215933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7806403002704679,
            "auditor_fn_violation": 0.05710489536209496,
            "auditor_fp_violation": 0.027563520871143377,
            "ave_precision_score": 0.7810032388850232,
            "fpr": 0.09868421052631579,
            "logloss": 3.0987488697309136,
            "mae": 0.31515883111948284,
            "precision": 0.7587131367292225,
            "recall": 0.5932914046121593
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8015675708814156,
            "auditor_fn_violation": 0.055050431829008144,
            "auditor_fp_violation": 0.035285577706171876,
            "ave_precision_score": 0.8018444742013373,
            "fpr": 0.11745334796926454,
            "logloss": 2.964878200854717,
            "mae": 0.29831772929765404,
            "precision": 0.7464454976303317,
            "recall": 0.660377358490566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7828672980685962,
            "auditor_fn_violation": 0.07368558976056494,
            "auditor_fp_violation": 0.0249697519661222,
            "ave_precision_score": 0.7832282741574255,
            "fpr": 0.08881578947368421,
            "logloss": 2.8026165703661303,
            "mae": 0.31864031009447524,
            "precision": 0.7762430939226519,
            "recall": 0.589098532494759
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8094111646686784,
            "auditor_fn_violation": 0.06692716783224831,
            "auditor_fp_violation": 0.02901050650776227,
            "ave_precision_score": 0.8096861418076027,
            "fpr": 0.10208562019758508,
            "logloss": 2.398530127974882,
            "mae": 0.2959610879535128,
            "precision": 0.7698019801980198,
            "recall": 0.6519916142557652
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6375203282779821,
            "auditor_fn_violation": 0.017088712346905004,
            "auditor_fp_violation": 0.037739463601532575,
            "ave_precision_score": 0.6190833153705051,
            "fpr": 0.19846491228070176,
            "logloss": 2.4601487479099786,
            "mae": 0.3674312026808003,
            "precision": 0.6539196940726577,
            "recall": 0.7169811320754716
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6374004681605726,
            "auditor_fn_violation": 0.013816687262827733,
            "auditor_fp_violation": 0.021316525618781203,
            "ave_precision_score": 0.6152135026444253,
            "fpr": 0.19758507135016465,
            "logloss": 2.70892184488886,
            "mae": 0.36199566386806425,
            "precision": 0.6577946768060836,
            "recall": 0.7253668763102725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.826864608575313,
            "auditor_fn_violation": 0.04092188017212844,
            "auditor_fp_violation": 0.019787255495059487,
            "ave_precision_score": 0.8272218327700069,
            "fpr": 0.07675438596491228,
            "logloss": 0.6763624364104363,
            "mae": 0.33633030785848655,
            "precision": 0.8181818181818182,
            "recall": 0.660377358490566
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8409922275104249,
            "auditor_fn_violation": 0.03985529758576172,
            "auditor_fp_violation": 0.01656153414235635,
            "ave_precision_score": 0.8412653084510836,
            "fpr": 0.06586169045005488,
            "logloss": 0.7055126982125349,
            "mae": 0.3336998154011143,
            "precision": 0.8387096774193549,
            "recall": 0.6540880503144654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7545907429155914,
            "auditor_fn_violation": 0.05256491595865976,
            "auditor_fp_violation": 0.022451603145795525,
            "ave_precision_score": 0.7527484030819882,
            "fpr": 0.07894736842105263,
            "logloss": 3.3072299231130553,
            "mae": 0.3261475687222927,
            "precision": 0.7906976744186046,
            "recall": 0.570230607966457
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7866634230867615,
            "auditor_fn_violation": 0.04629878931392923,
            "auditor_fp_violation": 0.02488782772767051,
            "ave_precision_score": 0.7873907930178445,
            "fpr": 0.0867178924259056,
            "logloss": 3.2794997727576187,
            "mae": 0.3077850535744849,
            "precision": 0.7921052631578948,
            "recall": 0.6310272536687631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7501223111258399,
            "auditor_fn_violation": 0.029681121041597716,
            "auditor_fp_violation": 0.01060193587416818,
            "ave_precision_score": 0.7505540488994789,
            "fpr": 0.0800438596491228,
            "logloss": 0.8554628342798941,
            "mae": 0.3792182403097292,
            "precision": 0.7767584097859327,
            "recall": 0.5324947589098532
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7646810907619674,
            "auditor_fn_violation": 0.03263628560316836,
            "auditor_fp_violation": 0.012325039076924636,
            "ave_precision_score": 0.7651995019653628,
            "fpr": 0.07793633369923161,
            "logloss": 0.8472438673527671,
            "mae": 0.3710350996743105,
            "precision": 0.7815384615384615,
            "recall": 0.5324947589098532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7516686043980645,
            "auditor_fn_violation": 0.0219298245614035,
            "auditor_fp_violation": 0.002576124218592462,
            "ave_precision_score": 0.7521129652474513,
            "fpr": 0.08991228070175439,
            "logloss": 0.7833315082576973,
            "mae": 0.377668935300646,
            "precision": 0.7630057803468208,
            "recall": 0.5534591194968553
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7619786243851848,
            "auditor_fn_violation": 0.03257875442702402,
            "auditor_fp_violation": 0.011194463975881069,
            "ave_precision_score": 0.7633631578146717,
            "fpr": 0.08342480790340286,
            "logloss": 0.761976590598564,
            "mae": 0.3723053655542798,
            "precision": 0.7717717717717718,
            "recall": 0.5387840670859538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8588546475160065,
            "auditor_fn_violation": 0.01384521313766597,
            "auditor_fp_violation": 0.018511796733212335,
            "ave_precision_score": 0.8593307389242892,
            "fpr": 0.2324561403508772,
            "logloss": 0.582407454928563,
            "mae": 0.3164712071496372,
            "precision": 0.6718266253869969,
            "recall": 0.909853249475891
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8783527344031167,
            "auditor_fn_violation": 0.008719425056438085,
            "auditor_fp_violation": 0.02432127555175606,
            "ave_precision_score": 0.8785187588034156,
            "fpr": 0.21953896816684962,
            "logloss": 0.5439234939595743,
            "mae": 0.3038786353111987,
            "precision": 0.6879875195007801,
            "recall": 0.9245283018867925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6311187111608217,
            "auditor_fn_violation": 0.0027538710507926008,
            "auditor_fp_violation": 0.024891611211937892,
            "ave_precision_score": 0.5661949017758663,
            "fpr": 0.3399122807017544,
            "logloss": 6.189596974397784,
            "mae": 0.37241170995280537,
            "precision": 0.5963541666666666,
            "recall": 0.960167714884696
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6448783385866849,
            "auditor_fn_violation": 0.0032516620756788107,
            "auditor_fp_violation": 0.026405378198869935,
            "ave_precision_score": 0.5885589831947173,
            "fpr": 0.32491767288693746,
            "logloss": 5.28131279934128,
            "mae": 0.35449315646224994,
            "precision": 0.6079470198675496,
            "recall": 0.9622641509433962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7010555668785287,
            "auditor_fn_violation": 0.060624241421162975,
            "auditor_fp_violation": 0.04975045372050817,
            "ave_precision_score": 0.702751788813625,
            "fpr": 0.12171052631578948,
            "logloss": 1.0883881165520761,
            "mae": 0.3714752772155902,
            "precision": 0.7063492063492064,
            "recall": 0.559748427672956
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7666292478353585,
            "auditor_fn_violation": 0.07234430337800055,
            "auditor_fp_violation": 0.04051859758102455,
            "ave_precision_score": 0.7670522523425619,
            "fpr": 0.09549945115257959,
            "logloss": 0.9364001432044486,
            "mae": 0.3395747881093336,
            "precision": 0.7622950819672131,
            "recall": 0.5849056603773585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6677424095046176,
            "auditor_fn_violation": 0.008194950163669133,
            "auditor_fp_violation": 0.0266182698124622,
            "ave_precision_score": 0.5749968806914881,
            "fpr": 0.25219298245614036,
            "logloss": 7.075204759895907,
            "mae": 0.3768627364743428,
            "precision": 0.6223316912972086,
            "recall": 0.7945492662473794
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6814699042994428,
            "auditor_fn_violation": 0.006130522129942217,
            "auditor_fp_violation": 0.014356027457546527,
            "ave_precision_score": 0.5865534666703511,
            "fpr": 0.24807903402854006,
            "logloss": 7.060245900334361,
            "mae": 0.3842082896682913,
            "precision": 0.6188870151770658,
            "recall": 0.7693920335429769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7468030855805964,
            "auditor_fn_violation": 0.07518665636838427,
            "auditor_fp_violation": 0.07795170397257513,
            "ave_precision_score": 0.7418539506121113,
            "fpr": 0.25877192982456143,
            "logloss": 3.5250492339634425,
            "mae": 0.3756338282265863,
            "precision": 0.6066666666666667,
            "recall": 0.7631027253668763
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7910485490474096,
            "auditor_fn_violation": 0.0656752894393472,
            "auditor_fp_violation": 0.07302958717568682,
            "ave_precision_score": 0.7870547976967384,
            "fpr": 0.25466520307354557,
            "logloss": 3.0840403897052586,
            "mae": 0.3471065034717112,
            "precision": 0.6252019386106623,
            "recall": 0.8113207547169812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8093372270179499,
            "auditor_fn_violation": 0.008516771488469604,
            "auditor_fp_violation": 0.017460677555958874,
            "ave_precision_score": 0.8096877638851708,
            "fpr": 0.24780701754385964,
            "logloss": 0.7143233085443593,
            "mae": 0.34210002033183917,
            "precision": 0.6490683229813664,
            "recall": 0.8763102725366876
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8407118368994039,
            "auditor_fn_violation": 0.0015165218031651358,
            "auditor_fp_violation": 0.014565955272729117,
            "ave_precision_score": 0.8409575432434362,
            "fpr": 0.2491767288693743,
            "logloss": 0.6335544153449721,
            "mae": 0.3210730837809094,
            "precision": 0.656060606060606,
            "recall": 0.9077568134171907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7848692941162855,
            "auditor_fn_violation": 0.053049946669609035,
            "auditor_fp_violation": 0.02297590239967736,
            "ave_precision_score": 0.7764640088968552,
            "fpr": 0.08333333333333333,
            "logloss": 2.3410968361881714,
            "mae": 0.30268160414820006,
            "precision": 0.7984084880636605,
            "recall": 0.6310272536687631
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7895854282197993,
            "auditor_fn_violation": 0.051317809120762545,
            "auditor_fp_violation": 0.02643067070672326,
            "ave_precision_score": 0.7788465008238847,
            "fpr": 0.09549945115257959,
            "logloss": 2.41936615276463,
            "mae": 0.28807921902869177,
            "precision": 0.7938388625592417,
            "recall": 0.7023060796645703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.817059231139426,
            "auditor_fn_violation": 0.014440582588546838,
            "auditor_fp_violation": 0.033494656180681585,
            "ave_precision_score": 0.8146697328335748,
            "fpr": 0.2949561403508772,
            "logloss": 1.3168113822618381,
            "mae": 0.33241274319344055,
            "precision": 0.6221910112359551,
            "recall": 0.9287211740041929
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.8547698972587192,
            "auditor_fn_violation": 0.010914814738106583,
            "auditor_fp_violation": 0.03422329237633228,
            "ave_precision_score": 0.8549116153599479,
            "fpr": 0.27771679473106475,
            "logloss": 1.0570309948090468,
            "mae": 0.31488967746926594,
            "precision": 0.6401137980085349,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.791395011401732,
            "auditor_fn_violation": 0.026026150281363784,
            "auditor_fp_violation": 0.01829249848759831,
            "ave_precision_score": 0.7444059828606424,
            "fpr": 0.16337719298245615,
            "logloss": 3.0715579821484655,
            "mae": 0.29572977987212196,
            "precision": 0.726605504587156,
            "recall": 0.8301886792452831
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7973905746662224,
            "auditor_fn_violation": 0.018702234741006154,
            "auditor_fp_violation": 0.030103142847025862,
            "ave_precision_score": 0.7492004592044225,
            "fpr": 0.18660812294182216,
            "logloss": 3.0469098735991347,
            "mae": 0.2888733337240286,
            "precision": 0.708904109589041,
            "recall": 0.8679245283018868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.8434486170113626,
            "auditor_fn_violation": 0.00032641877229762063,
            "auditor_fp_violation": 0.005260637225247013,
            "ave_precision_score": 0.843869391254612,
            "fpr": 0.4594298245614035,
            "logloss": 3.4163232826513203,
            "mae": 0.47071673828503935,
            "precision": 0.5270880361173815,
            "recall": 0.9790356394129979
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.873869491372717,
            "auditor_fn_violation": 0.0005361905616653664,
            "auditor_fp_violation": 0.008467931629292776,
            "ave_precision_score": 0.8740337376092969,
            "fpr": 0.442371020856202,
            "logloss": 3.198811460516573,
            "mae": 0.44735592527214835,
            "precision": 0.5415244596131968,
            "recall": 0.9979035639412998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7694973627517677,
            "auditor_fn_violation": 0.006891573798227224,
            "auditor_fp_violation": 0.042407743496672735,
            "ave_precision_score": 0.6079542183734509,
            "fpr": 0.3684210526315789,
            "logloss": 10.09376464829301,
            "mae": 0.39357278215051866,
            "precision": 0.58,
            "recall": 0.9727463312368972
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7676302373818666,
            "auditor_fn_violation": 0.011381967888398722,
            "auditor_fp_violation": 0.045349466581009384,
            "ave_precision_score": 0.5947569563587289,
            "fpr": 0.38309549945115257,
            "logloss": 10.941429608757813,
            "mae": 0.4067798850409139,
            "precision": 0.5686032138442522,
            "recall": 0.9643605870020965
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8335366644593732,
            "auditor_fn_violation": 0.025302052300562733,
            "auditor_fp_violation": 0.008882839282113331,
            "ave_precision_score": 0.8311766867057746,
            "fpr": 0.07017543859649122,
            "logloss": 0.867070495869266,
            "mae": 0.3162847276817216,
            "precision": 0.827027027027027,
            "recall": 0.6415094339622641
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8600430912525533,
            "auditor_fn_violation": 0.017708096017231747,
            "auditor_fp_violation": 0.01060261929211329,
            "ave_precision_score": 0.8602310479576173,
            "fpr": 0.05159165751920966,
            "logloss": 0.6720048299274336,
            "mae": 0.3140797183463821,
            "precision": 0.8633720930232558,
            "recall": 0.6226415094339622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8328140863954372,
            "auditor_fn_violation": 0.013762459082717279,
            "auditor_fp_violation": 0.008925690663440213,
            "ave_precision_score": 0.8332109272330658,
            "fpr": 0.1337719298245614,
            "logloss": 0.5356317090825699,
            "mae": 0.3139145772065763,
            "precision": 0.7409766454352441,
            "recall": 0.7316561844863732
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8490963832696596,
            "auditor_fn_violation": 0.002340368245552271,
            "auditor_fp_violation": 0.009016779049709893,
            "ave_precision_score": 0.8492978294831799,
            "fpr": 0.10208562019758508,
            "logloss": 0.5309821142049825,
            "mae": 0.3128587312385047,
            "precision": 0.7862068965517242,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8199340196127969,
            "auditor_fn_violation": 0.006211151568649088,
            "auditor_fp_violation": 0.014919842710223851,
            "ave_precision_score": 0.8202752930447551,
            "fpr": 0.28289473684210525,
            "logloss": 0.8046188125806716,
            "mae": 0.34650290939469797,
            "precision": 0.6314285714285715,
            "recall": 0.9266247379454927
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8502304816048097,
            "auditor_fn_violation": 0.003058357323833786,
            "auditor_fp_violation": 0.021448046659618497,
            "ave_precision_score": 0.8504597812529262,
            "fpr": 0.28210757409440174,
            "logloss": 0.7325448090925747,
            "mae": 0.3301960470057251,
            "precision": 0.6359773371104815,
            "recall": 0.9412997903563941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5550200722389933,
            "auditor_fn_violation": 0.0022136709698775416,
            "auditor_fp_violation": 0.001852692075015124,
            "ave_precision_score": 0.5553204035608355,
            "fpr": 0.01644736842105263,
            "logloss": 12.401382540665184,
            "mae": 0.5345641775586928,
            "precision": 0.4230769230769231,
            "recall": 0.023060796645702306
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.6106219463276905,
            "auditor_fn_violation": 0.002639530361502914,
            "auditor_fp_violation": 0.002772058860724276,
            "ave_precision_score": 0.6108137081643733,
            "fpr": 0.01756311745334797,
            "logloss": 11.915540405646766,
            "mae": 0.5202497209058321,
            "precision": 0.5428571428571428,
            "recall": 0.039832285115303984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7171457345058583,
            "auditor_fn_violation": 0.015337084850491012,
            "auditor_fp_violation": 0.020447670901391414,
            "ave_precision_score": 0.6475087981261615,
            "fpr": 0.20614035087719298,
            "logloss": 4.687388646116702,
            "mae": 0.31027262603882416,
            "precision": 0.6797274275979557,
            "recall": 0.8364779874213837
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6942334672104327,
            "auditor_fn_violation": 0.013130915643187045,
            "auditor_fp_violation": 0.010966831405201168,
            "ave_precision_score": 0.6231953342131251,
            "fpr": 0.23380900109769484,
            "logloss": 5.091497768116751,
            "mae": 0.3369123257633385,
            "precision": 0.6519607843137255,
            "recall": 0.8364779874213837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 6832,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6199034058160344,
            "auditor_fn_violation": 0.0008068520357497524,
            "auditor_fp_violation": 0.00989110707803992,
            "ave_precision_score": 0.5980667717749824,
            "fpr": 0.42105263157894735,
            "logloss": 3.463360922591997,
            "mae": 0.4270295734280361,
            "precision": 0.5492957746478874,
            "recall": 0.9811320754716981
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6231763109437715,
            "auditor_fn_violation": 0.002071122341196695,
            "auditor_fp_violation": 0.00714513346856395,
            "ave_precision_score": 0.5967587448334359,
            "fpr": 0.429198682766191,
            "logloss": 3.7351537336436436,
            "mae": 0.43058751249311716,
            "precision": 0.5448195576251456,
            "recall": 0.9811320754716981
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6765594844393028,
            "auditor_fn_violation": 0.0003379123910405002,
            "auditor_fp_violation": 0.026275458761847167,
            "ave_precision_score": 0.6737431739530588,
            "fpr": 0.2883771929824561,
            "logloss": 1.757270176733071,
            "mae": 0.3802353881983111,
            "precision": 0.6015151515151516,
            "recall": 0.8322851153039832
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7009931162146981,
            "auditor_fn_violation": 0.00661378400955478,
            "auditor_fp_violation": 0.021068659041818635,
            "ave_precision_score": 0.6988227179125122,
            "fpr": 0.2843029637760702,
            "logloss": 1.4363474185903997,
            "mae": 0.37520823871975306,
            "precision": 0.6021505376344086,
            "recall": 0.8218029350104822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7849159144100164,
            "auditor_fn_violation": 0.07195235205413955,
            "auditor_fp_violation": 0.03328291994353701,
            "ave_precision_score": 0.7825028819538016,
            "fpr": 0.11951754385964912,
            "logloss": 3.0271661393794633,
            "mae": 0.33644921405910044,
            "precision": 0.7435294117647059,
            "recall": 0.6624737945492662
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8360438197122568,
            "auditor_fn_violation": 0.06695938529088913,
            "auditor_fp_violation": 0.039587833292022236,
            "ave_precision_score": 0.8361300954002265,
            "fpr": 0.12843029637760703,
            "logloss": 2.5283346130404762,
            "mae": 0.30654407829917657,
            "precision": 0.7515923566878981,
            "recall": 0.7421383647798742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8041369879781353,
            "auditor_fn_violation": 0.015330188679245283,
            "auditor_fp_violation": 0.0324712643678161,
            "ave_precision_score": 0.8045038870923982,
            "fpr": 0.26644736842105265,
            "logloss": 0.9214694527480414,
            "mae": 0.3413130301165487,
            "precision": 0.6340361445783133,
            "recall": 0.8825995807127882
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8473297483403636,
            "auditor_fn_violation": 0.017869183310435927,
            "auditor_fp_violation": 0.02698710587949639,
            "ave_precision_score": 0.8475704845349632,
            "fpr": 0.24259055982436883,
            "logloss": 0.7578123184630241,
            "mae": 0.3116066022063911,
            "precision": 0.6636225266362252,
            "recall": 0.9140461215932913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.795535296684226,
            "auditor_fn_violation": 0.01325214241053367,
            "auditor_fp_violation": 0.011078342407743505,
            "ave_precision_score": 0.7808951468060154,
            "fpr": 0.1337719298245614,
            "logloss": 1.4815026658884443,
            "mae": 0.2729416311749441,
            "precision": 0.7535353535353535,
            "recall": 0.7819706498951782
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7945526981131562,
            "auditor_fn_violation": 0.014649738693397954,
            "auditor_fp_violation": 0.01613409075963518,
            "ave_precision_score": 0.7811262269697723,
            "fpr": 0.14818880351262348,
            "logloss": 1.5253165700153337,
            "mae": 0.2762057994362744,
            "precision": 0.7393822393822393,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7794496518743343,
            "auditor_fn_violation": 0.015081926514399211,
            "auditor_fp_violation": 0.01085652349263965,
            "ave_precision_score": 0.7576420826791838,
            "fpr": 0.13925438596491227,
            "logloss": 2.075403759392908,
            "mae": 0.29296164839162414,
            "precision": 0.7365145228215768,
            "recall": 0.7442348008385744
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7812330124678546,
            "auditor_fn_violation": 0.003051453582696468,
            "auditor_fp_violation": 0.017047150293140176,
            "ave_precision_score": 0.7558076469821082,
            "fpr": 0.16355653128430298,
            "logloss": 2.2657264943560635,
            "mae": 0.29640883539037144,
            "precision": 0.7129094412331407,
            "recall": 0.7756813417190775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6733398707692265,
            "auditor_fn_violation": 0.019148368825628016,
            "auditor_fp_violation": 0.034475196612220205,
            "ave_precision_score": 0.6743672097380471,
            "fpr": 0.20394736842105263,
            "logloss": 1.1836317865110344,
            "mae": 0.3770485216512958,
            "precision": 0.6463878326996197,
            "recall": 0.7127882599580713
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6879608723923571,
            "auditor_fn_violation": 0.01740893390128111,
            "auditor_fp_violation": 0.021829963528203676,
            "ave_precision_score": 0.6887868307281186,
            "fpr": 0.19209659714599342,
            "logloss": 1.0709300203396073,
            "mae": 0.3701760655385199,
            "precision": 0.6506986027944112,
            "recall": 0.6834381551362684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 6832,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6433795447035222,
            "auditor_fn_violation": 0.005567508919048145,
            "auditor_fp_violation": 0.0229229683403912,
            "ave_precision_score": 0.535915047298518,
            "fpr": 0.4100877192982456,
            "logloss": 9.317334616373886,
            "mae": 0.4394728713771919,
            "precision": 0.5439024390243903,
            "recall": 0.9350104821802935
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6559010330307927,
            "auditor_fn_violation": 0.004701447714516496,
            "auditor_fp_violation": 0.02563648596012891,
            "ave_precision_score": 0.549084730381268,
            "fpr": 0.3995609220636663,
            "logloss": 9.14093367401362,
            "mae": 0.4213319299062848,
            "precision": 0.5555555555555556,
            "recall": 0.9538784067085954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7945708397090944,
            "auditor_fn_violation": 0.0004137702747434625,
            "auditor_fp_violation": 0.017115345835854022,
            "ave_precision_score": 0.7947710070314692,
            "fpr": 0.4024122807017544,
            "logloss": 1.0692939273596558,
            "mae": 0.3825241533432793,
            "precision": 0.5604790419161677,
            "recall": 0.9811320754716981
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.831565905842951,
            "auditor_fn_violation": 0.002269029587133268,
            "auditor_fp_violation": 0.027100922164836352,
            "ave_precision_score": 0.832764882629677,
            "fpr": 0.36553238199780463,
            "logloss": 0.9253058346447836,
            "mae": 0.3629580204969049,
            "precision": 0.5853051058530511,
            "recall": 0.9853249475890985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7128945675134427,
            "auditor_fn_violation": 0.014778494979587338,
            "auditor_fp_violation": 0.03152853397862472,
            "ave_precision_score": 0.7138076994763765,
            "fpr": 0.18969298245614036,
            "logloss": 1.1258374319482536,
            "mae": 0.3518809109536841,
            "precision": 0.6647286821705426,
            "recall": 0.7190775681341719
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7247235947824501,
            "auditor_fn_violation": 0.011922760944155649,
            "auditor_fp_violation": 0.023415803770607077,
            "ave_precision_score": 0.7255085515567365,
            "fpr": 0.1712403951701427,
            "logloss": 1.015582298161083,
            "mae": 0.337545267251941,
            "precision": 0.6861167002012073,
            "recall": 0.7148846960167715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 6832,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7941000240118612,
            "auditor_fn_violation": 0.015808323218948837,
            "auditor_fp_violation": 0.02247176850171406,
            "ave_precision_score": 0.7686127935737718,
            "fpr": 0.19188596491228072,
            "logloss": 2.1621717254693342,
            "mae": 0.30502940136367424,
            "precision": 0.7048903878583473,
            "recall": 0.8763102725366876
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7985176777288446,
            "auditor_fn_violation": 0.010162306954138448,
            "auditor_fp_violation": 0.024736072680550576,
            "ave_precision_score": 0.7688413114082742,
            "fpr": 0.18990120746432493,
            "logloss": 2.19311133104539,
            "mae": 0.3010291786563841,
            "precision": 0.7111853088480802,
            "recall": 0.8930817610062893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5438336864387989,
            "auditor_fn_violation": 0.015583048291588512,
            "auditor_fp_violation": 0.008643375680580765,
            "ave_precision_score": 0.5160151767811855,
            "fpr": 0.24342105263157895,
            "logloss": 6.31147201585276,
            "mae": 0.4506930194868668,
            "precision": 0.5963636363636363,
            "recall": 0.6876310272536688
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.5593805912559315,
            "auditor_fn_violation": 0.009934483496606817,
            "auditor_fp_violation": 0.015387961777962134,
            "ave_precision_score": 0.5281615869072206,
            "fpr": 0.2283205268935236,
            "logloss": 6.326538273416821,
            "mae": 0.44063510467808076,
            "precision": 0.6285714285714286,
            "recall": 0.7379454926624738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7733430140258253,
            "auditor_fn_violation": 0.05045928500496525,
            "auditor_fp_violation": 0.02821889493849566,
            "ave_precision_score": 0.7712723003040276,
            "fpr": 0.10307017543859649,
            "logloss": 3.541568578690692,
            "mae": 0.32039047452662767,
            "precision": 0.7438692098092643,
            "recall": 0.5723270440251572
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8079347991739876,
            "auditor_fn_violation": 0.043684572669929846,
            "auditor_fp_violation": 0.03397542579936971,
            "ave_precision_score": 0.8080732461196165,
            "fpr": 0.11964873765093303,
            "logloss": 3.30034371312622,
            "mae": 0.3083368629275641,
            "precision": 0.7367149758454107,
            "recall": 0.639412997903564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7003530703781298,
            "auditor_fn_violation": 0.012364835043583806,
            "auditor_fp_violation": 0.018060596894535194,
            "ave_precision_score": 0.6765050170580206,
            "fpr": 0.1962719298245614,
            "logloss": 2.4295633030965673,
            "mae": 0.3056127237853161,
            "precision": 0.6892361111111112,
            "recall": 0.8322851153039832
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6870550301777797,
            "auditor_fn_violation": 0.00842946792867055,
            "auditor_fp_violation": 0.011229873486875723,
            "ave_precision_score": 0.6570038912719971,
            "fpr": 0.21624588364434688,
            "logloss": 2.8340009626786733,
            "mae": 0.32357537168930456,
            "precision": 0.6677908937605397,
            "recall": 0.8301886792452831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8068618039292091,
            "auditor_fn_violation": 0.023817076758983417,
            "auditor_fp_violation": 0.019232708207299866,
            "ave_precision_score": 0.8045642602522356,
            "fpr": 0.13706140350877194,
            "logloss": 1.8566763708614415,
            "mae": 0.3012708283583385,
            "precision": 0.7282608695652174,
            "recall": 0.7023060796645703
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8226109934815463,
            "auditor_fn_violation": 0.008694111338934576,
            "auditor_fp_violation": 0.02173891049993171,
            "ave_precision_score": 0.8228622440804512,
            "fpr": 0.15916575192096596,
            "logloss": 1.8090850490097525,
            "mae": 0.3148171432601385,
            "precision": 0.6991701244813278,
            "recall": 0.7064989517819706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8264212219611624,
            "auditor_fn_violation": 0.030032825775129657,
            "auditor_fp_violation": 0.010778382738455331,
            "ave_precision_score": 0.8240720613483158,
            "fpr": 0.07456140350877193,
            "logloss": 0.9033803329924656,
            "mae": 0.31753547620728895,
            "precision": 0.8196286472148541,
            "recall": 0.6477987421383647
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8520383824480889,
            "auditor_fn_violation": 0.02015202037984384,
            "auditor_fp_violation": 0.015822992913039305,
            "ave_precision_score": 0.8522369277541093,
            "fpr": 0.06586169045005488,
            "logloss": 0.7327356236702283,
            "mae": 0.3164474039750182,
            "precision": 0.8342541436464088,
            "recall": 0.6331236897274634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6475734081798928,
            "auditor_fn_violation": 0.002751572327044026,
            "auditor_fp_violation": 0.023911070780399293,
            "ave_precision_score": 0.5948154660687986,
            "fpr": 0.39144736842105265,
            "logloss": 5.384827946257017,
            "mae": 0.4103549095209114,
            "precision": 0.5625,
            "recall": 0.9622641509433962
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.682092097435692,
            "auditor_fn_violation": 0.0027822076783408935,
            "auditor_fp_violation": 0.02567189547112356,
            "ave_precision_score": 0.6310793002255919,
            "fpr": 0.36882546652030734,
            "logloss": 4.820863074992192,
            "mae": 0.3827988097583498,
            "precision": 0.5805243445692884,
            "recall": 0.9748427672955975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7021739597375241,
            "auditor_fn_violation": 0.010436205818529571,
            "auditor_fp_violation": 0.010208711433756805,
            "ave_precision_score": 0.7035429475592184,
            "fpr": 0.08333333333333333,
            "logloss": 4.476199451629352,
            "mae": 0.4183956452801577,
            "precision": 0.7556270096463023,
            "recall": 0.49266247379454925
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7109500336752853,
            "auditor_fn_violation": 0.019091145491741974,
            "auditor_fp_violation": 0.015236206730842194,
            "ave_precision_score": 0.711288893652989,
            "fpr": 0.09659714599341383,
            "logloss": 4.770096565961053,
            "mae": 0.41840246577754325,
            "precision": 0.7275541795665634,
            "recall": 0.49266247379454925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7019869031664147,
            "auditor_fn_violation": 0.017674886902791575,
            "auditor_fp_violation": 0.0507486388384755,
            "ave_precision_score": 0.6761806840900404,
            "fpr": 0.2532894736842105,
            "logloss": 2.998482693017039,
            "mae": 0.3423748742266318,
            "precision": 0.6333333333333333,
            "recall": 0.8364779874213837
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7306911025758668,
            "auditor_fn_violation": 0.00827298312955791,
            "auditor_fp_violation": 0.0377161877108763,
            "ave_precision_score": 0.7066660564601899,
            "fpr": 0.24259055982436883,
            "logloss": 2.6233657953210265,
            "mae": 0.31343364595459,
            "precision": 0.6525157232704403,
            "recall": 0.870020964360587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 6832,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7855569904995532,
            "auditor_fn_violation": 0.06960995255434184,
            "auditor_fp_violation": 0.03720256100020165,
            "ave_precision_score": 0.7832260718929729,
            "fpr": 0.12938596491228072,
            "logloss": 2.874931238321471,
            "mae": 0.31084123465002816,
            "precision": 0.7348314606741573,
            "recall": 0.6855345911949685
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.825747164013932,
            "auditor_fn_violation": 0.06006254789470414,
            "auditor_fp_violation": 0.03915786065851574,
            "ave_precision_score": 0.8259632729105058,
            "fpr": 0.1394072447859495,
            "logloss": 2.5436240627653324,
            "mae": 0.28036017628037796,
            "precision": 0.7392197125256673,
            "recall": 0.7547169811320755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6398099326733793,
            "auditor_fn_violation": 0.003448085622862188,
            "auditor_fp_violation": 0.02528483565234926,
            "ave_precision_score": 0.6294294795078288,
            "fpr": 0.33114035087719296,
            "logloss": 2.406156025331637,
            "mae": 0.3698171029468383,
            "precision": 0.5907859078590786,
            "recall": 0.9140461215932913
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.686074787840332,
            "auditor_fn_violation": 0.005134082159122028,
            "auditor_fp_violation": 0.019854618664859113,
            "ave_precision_score": 0.6775720907394247,
            "fpr": 0.31394072447859495,
            "logloss": 1.913225977660334,
            "mae": 0.34617906369385815,
            "precision": 0.6108843537414966,
            "recall": 0.9412997903563941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6979650159362343,
            "auditor_fn_violation": 0.014594597079701352,
            "auditor_fp_violation": 0.015673522887678974,
            "ave_precision_score": 0.693106043004761,
            "fpr": 0.26096491228070173,
            "logloss": 1.6616439834753887,
            "mae": 0.3551070648939921,
            "precision": 0.6421052631578947,
            "recall": 0.8951781970649895
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6882501999943258,
            "auditor_fn_violation": 0.00688302991391035,
            "auditor_fp_violation": 0.014469843742886481,
            "ave_precision_score": 0.6863440163545409,
            "fpr": 0.27771679473106475,
            "logloss": 1.9652348866328415,
            "mae": 0.3473578062701794,
            "precision": 0.6322674418604651,
            "recall": 0.9119496855345912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.841467159079692,
            "auditor_fn_violation": 0.007919103313840159,
            "auditor_fp_violation": 0.005558076225045373,
            "ave_precision_score": 0.841848551800758,
            "fpr": 0.03837719298245614,
            "logloss": 0.5681258805784717,
            "mae": 0.3463888758718478,
            "precision": 0.8837209302325582,
            "recall": 0.5576519916142557
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8459115234064041,
            "auditor_fn_violation": 0.011819204827095812,
            "auditor_fp_violation": 0.0037382326607212422,
            "ave_precision_score": 0.846208344280449,
            "fpr": 0.043907793633369926,
            "logloss": 0.5779286351406815,
            "mae": 0.34876131235861785,
            "precision": 0.8620689655172413,
            "recall": 0.5241090146750524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.8264827874153627,
            "auditor_fn_violation": 0.0016895619552024833,
            "auditor_fp_violation": 0.005784936479128857,
            "ave_precision_score": 0.8268850006324022,
            "fpr": 0.017543859649122806,
            "logloss": 0.8451967656517504,
            "mae": 0.39212389528292596,
            "precision": 0.8865248226950354,
            "recall": 0.2620545073375262
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.790380928378696,
            "auditor_fn_violation": 0.003686597767330119,
            "auditor_fp_violation": 0.003753408165433236,
            "ave_precision_score": 0.7908547918203307,
            "fpr": 0.025246981339187707,
            "logloss": 0.9031987239685887,
            "mae": 0.4112537811226196,
            "precision": 0.8270676691729323,
            "recall": 0.23060796645702306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8488802583795764,
            "auditor_fn_violation": 0.00256537570340947,
            "auditor_fp_violation": 0.010170901391409559,
            "ave_precision_score": 0.8492139190002962,
            "fpr": 0.08114035087719298,
            "logloss": 0.5902873886241568,
            "mae": 0.3127739089209061,
            "precision": 0.8159203980099502,
            "recall": 0.6876310272536688
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8651455734315916,
            "auditor_fn_violation": 0.007248928194188441,
            "auditor_fp_violation": 0.007871028443954335,
            "ave_precision_score": 0.8653232820924759,
            "fpr": 0.06586169045005488,
            "logloss": 0.5421774134602171,
            "mae": 0.31251052011656344,
            "precision": 0.84251968503937,
            "recall": 0.6729559748427673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7735170867711378,
            "auditor_fn_violation": 0.002744676155798301,
            "auditor_fp_violation": 0.008663541036499292,
            "ave_precision_score": 0.7749033176131983,
            "fpr": 0.35964912280701755,
            "logloss": 0.7803730721500886,
            "mae": 0.3763773987692591,
            "precision": 0.5773195876288659,
            "recall": 0.939203354297694
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.7856275640355792,
            "auditor_fn_violation": 0.000485563126658337,
            "auditor_fp_violation": 0.011427155048131635,
            "ave_precision_score": 0.786928660404383,
            "fpr": 0.3424807903402854,
            "logloss": 0.8379159086305962,
            "mae": 0.37664501283021057,
            "precision": 0.5834445927903872,
            "recall": 0.9161425576519916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6883092405146434,
            "auditor_fn_violation": 0.0035791128765309496,
            "auditor_fp_violation": 0.012288263762855415,
            "ave_precision_score": 0.5962840334895437,
            "fpr": 0.41118421052631576,
            "logloss": 7.225255791237893,
            "mae": 0.41743671564991425,
            "precision": 0.5541022592152199,
            "recall": 0.9769392033542977
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.7124222405534008,
            "auditor_fn_violation": 0.006395165540206238,
            "auditor_fp_violation": 0.018008265591566475,
            "ave_precision_score": 0.6182710583912897,
            "fpr": 0.3907793633369923,
            "logloss": 6.969317218239046,
            "mae": 0.40005604073513457,
            "precision": 0.5669099756690997,
            "recall": 0.9769392033542977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7470965313817711,
            "auditor_fn_violation": 0.020116131523778013,
            "auditor_fp_violation": 0.011184210526315791,
            "ave_precision_score": 0.7471173053377221,
            "fpr": 0.08991228070175439,
            "logloss": 2.4087164596550976,
            "mae": 0.3251835380934524,
            "precision": 0.770949720670391,
            "recall": 0.5786163522012578
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7537770089044492,
            "auditor_fn_violation": 0.012311671694891462,
            "auditor_fp_violation": 0.021088893048101298,
            "ave_precision_score": 0.7536053092366684,
            "fpr": 0.11855104281009879,
            "logloss": 2.4067465711679326,
            "mae": 0.330467395045751,
            "precision": 0.7320099255583127,
            "recall": 0.6184486373165619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.642677819933297,
            "auditor_fn_violation": 0.009252363088013539,
            "auditor_fp_violation": 0.029186832022585214,
            "ave_precision_score": 0.5941372356569272,
            "fpr": 0.19956140350877194,
            "logloss": 4.908031669126731,
            "mae": 0.3649539530935654,
            "precision": 0.6578947368421053,
            "recall": 0.7337526205450734
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6435020108081039,
            "auditor_fn_violation": 0.004777388867027043,
            "auditor_fp_violation": 0.018660812294182223,
            "ave_precision_score": 0.5910705327404604,
            "fpr": 0.20417124039517015,
            "logloss": 5.2303075655813736,
            "mae": 0.35938954218197733,
            "precision": 0.651685393258427,
            "recall": 0.7295597484276729
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7822424155352456,
            "auditor_fn_violation": 0.015468112104159777,
            "auditor_fp_violation": 0.012018552127445048,
            "ave_precision_score": 0.7633960107188529,
            "fpr": 0.08442982456140351,
            "logloss": 1.9860171998313607,
            "mae": 0.3095851684694106,
            "precision": 0.78,
            "recall": 0.5723270440251572
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7787511182664962,
            "auditor_fn_violation": 0.006422780504755532,
            "auditor_fp_violation": 0.007238715747621242,
            "ave_precision_score": 0.7580758020719441,
            "fpr": 0.10537870472008781,
            "logloss": 2.1238470160773586,
            "mae": 0.3113210639906907,
            "precision": 0.7493472584856397,
            "recall": 0.6016771488469602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.848550601991467,
            "auditor_fn_violation": 0.012068299680017656,
            "auditor_fp_violation": 0.006130268199233717,
            "ave_precision_score": 0.8461756929837457,
            "fpr": 0.08662280701754387,
            "logloss": 0.684510994878261,
            "mae": 0.3061411703842423,
            "precision": 0.8127962085308057,
            "recall": 0.7190775681341719
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8767769009589138,
            "auditor_fn_violation": 0.015823374686742754,
            "auditor_fp_violation": 0.01095165590048916,
            "ave_precision_score": 0.8769476084721453,
            "fpr": 0.07464324917672886,
            "logloss": 0.5126507212717814,
            "mae": 0.30056309617805205,
            "precision": 0.8337408312958435,
            "recall": 0.7148846960167715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.692540674129442,
            "auditor_fn_violation": 0.011698205156497122,
            "auditor_fp_violation": 0.013611615245009074,
            "ave_precision_score": 0.6418431171560774,
            "fpr": 0.18092105263157895,
            "logloss": 6.255459862354673,
            "mae": 0.29565540183257755,
            "precision": 0.6955719557195572,
            "recall": 0.790356394129979
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.677767518378944,
            "auditor_fn_violation": 0.00789097611995941,
            "auditor_fp_violation": 0.020767678198364083,
            "ave_precision_score": 0.6328484173287662,
            "fpr": 0.19209659714599342,
            "logloss": 5.757649065852777,
            "mae": 0.28620090766770656,
            "precision": 0.6935201401050788,
            "recall": 0.8301886792452831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7589295688482318,
            "auditor_fn_violation": 0.013953253153848981,
            "auditor_fp_violation": 0.017221213954426298,
            "ave_precision_score": 0.7426049174552924,
            "fpr": 0.18201754385964913,
            "logloss": 1.9241216167128847,
            "mae": 0.31669620332138326,
            "precision": 0.6885553470919324,
            "recall": 0.7693920335429769
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7656144304059078,
            "auditor_fn_violation": 0.0006673616432744936,
            "auditor_fp_violation": 0.01919701346067268,
            "ave_precision_score": 0.7472446334857368,
            "fpr": 0.19319429198682767,
            "logloss": 2.0954602660501847,
            "mae": 0.32041220601746023,
            "precision": 0.68,
            "recall": 0.7840670859538784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6255206239713041,
            "auditor_fn_violation": 0.006532972893449558,
            "auditor_fp_violation": 0.027097197015527326,
            "ave_precision_score": 0.5608020141882031,
            "fpr": 0.3399122807017544,
            "logloss": 6.1715676408576,
            "mae": 0.37611010506774173,
            "precision": 0.5942408376963351,
            "recall": 0.9517819706498952
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.6367091635181181,
            "auditor_fn_violation": 0.0009734275003624469,
            "auditor_fp_violation": 0.024306100047044067,
            "ave_precision_score": 0.5806808678958504,
            "fpr": 0.32491767288693746,
            "logloss": 5.300942933474287,
            "mae": 0.35682332594560506,
            "precision": 0.6063829787234043,
            "recall": 0.9559748427672956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7994498505619829,
            "auditor_fn_violation": 0.07376604509176506,
            "auditor_fp_violation": 0.03305353901996371,
            "ave_precision_score": 0.7969465731725752,
            "fpr": 0.1118421052631579,
            "logloss": 3.1884156864458677,
            "mae": 0.33017001056923345,
            "precision": 0.7548076923076923,
            "recall": 0.6582809224318659
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8457526565197239,
            "auditor_fn_violation": 0.06689725162065323,
            "auditor_fp_violation": 0.033866668015600426,
            "ave_precision_score": 0.8457149545768229,
            "fpr": 0.1141602634467618,
            "logloss": 2.6602344309552577,
            "mae": 0.2970929095076047,
            "precision": 0.7714285714285715,
            "recall": 0.7358490566037735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8322132917054871,
            "auditor_fn_violation": 0.03180744050902939,
            "auditor_fp_violation": 0.012666364186327892,
            "ave_precision_score": 0.8326261349222578,
            "fpr": 0.0712719298245614,
            "logloss": 0.6460417519358282,
            "mae": 0.3243214401931798,
            "precision": 0.8293963254593176,
            "recall": 0.6624737945492662
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8677621460942988,
            "auditor_fn_violation": 0.035121632412604395,
            "auditor_fp_violation": 0.014290266937127885,
            "ave_precision_score": 0.8679400195617548,
            "fpr": 0.06695938529088913,
            "logloss": 0.5656856121795826,
            "mae": 0.3114333607210296,
            "precision": 0.8398950131233596,
            "recall": 0.6708595387840671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8459083880450409,
            "auditor_fn_violation": 0.005519235720328083,
            "auditor_fp_violation": 0.013898971566848157,
            "ave_precision_score": 0.8462476856774509,
            "fpr": 0.10197368421052631,
            "logloss": 0.5140768446747813,
            "mae": 0.33095014463785083,
            "precision": 0.7924107142857143,
            "recall": 0.7442348008385744
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8630653728550466,
            "auditor_fn_violation": 0.018205165379118943,
            "auditor_fp_violation": 0.003806522431925215,
            "ave_precision_score": 0.8632992715247699,
            "fpr": 0.0845225027442371,
            "logloss": 0.4829832072339563,
            "mae": 0.3262788697586512,
            "precision": 0.8162291169451074,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.8108163474608397,
            "auditor_fn_violation": 0.009309831181727905,
            "auditor_fp_violation": 0.02187941117160718,
            "ave_precision_score": 0.8084828462025442,
            "fpr": 0.3530701754385965,
            "logloss": 1.117929092724024,
            "mae": 0.3676505921345476,
            "precision": 0.582901554404145,
            "recall": 0.9433962264150944
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.8558339635442478,
            "auditor_fn_violation": 0.004365465645833478,
            "auditor_fp_violation": 0.02399247294966286,
            "ave_precision_score": 0.8560300621232309,
            "fpr": 0.3402854006586169,
            "logloss": 0.928305526280843,
            "mae": 0.34541052300061287,
            "precision": 0.599483204134367,
            "recall": 0.9727463312368972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.793350650631724,
            "auditor_fn_violation": 0.015992221118834835,
            "auditor_fp_violation": 0.014413188142770723,
            "ave_precision_score": 0.7755557493963414,
            "fpr": 0.10087719298245613,
            "logloss": 1.5615407020614116,
            "mae": 0.28779209346174794,
            "precision": 0.7772397094430993,
            "recall": 0.6729559748427673
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7902664247669222,
            "auditor_fn_violation": 0.013006648302715246,
            "auditor_fp_violation": 0.010471098251276009,
            "ave_precision_score": 0.770715864296921,
            "fpr": 0.10976948408342481,
            "logloss": 1.6805117566151977,
            "mae": 0.28790241902423896,
            "precision": 0.76905311778291,
            "recall": 0.6981132075471698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.836609857042822,
            "auditor_fn_violation": 0.01678528081209313,
            "auditor_fp_violation": 0.0169767090139141,
            "ave_precision_score": 0.837060442315407,
            "fpr": 0.12609649122807018,
            "logloss": 0.6799761747779757,
            "mae": 0.26675668028238114,
            "precision": 0.7653061224489796,
            "recall": 0.7861635220125787
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8348821561180635,
            "auditor_fn_violation": 0.0070832384068927005,
            "auditor_fp_violation": 0.018997202648631424,
            "ave_precision_score": 0.8351624074185736,
            "fpr": 0.145993413830955,
            "logloss": 0.703639754015351,
            "mae": 0.27694859861483717,
            "precision": 0.7397260273972602,
            "recall": 0.7924528301886793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.6926665488613175,
            "auditor_fn_violation": 0.016904814447019016,
            "auditor_fp_violation": 0.016964105666465022,
            "ave_precision_score": 0.6724914804444344,
            "fpr": 0.20833333333333334,
            "logloss": 2.2543177998458064,
            "mae": 0.30648043304789124,
            "precision": 0.6875,
            "recall": 0.8763102725366876
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6757570723219013,
            "auditor_fn_violation": 0.01075832993899394,
            "auditor_fp_violation": 0.01212016976331272,
            "ave_precision_score": 0.6514647433115907,
            "fpr": 0.2349066959385291,
            "logloss": 2.6279805184783176,
            "mae": 0.323829539346359,
            "precision": 0.657051282051282,
            "recall": 0.859538784067086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7947171638891382,
            "auditor_fn_violation": 0.02081264481959616,
            "auditor_fp_violation": 0.012968844525105877,
            "ave_precision_score": 0.7443014085834669,
            "fpr": 0.17324561403508773,
            "logloss": 3.378323144537679,
            "mae": 0.2806033519336026,
            "precision": 0.7193605683836589,
            "recall": 0.8490566037735849
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8008805510275259,
            "auditor_fn_violation": 0.014438023965186736,
            "auditor_fp_violation": 0.026278915659603316,
            "ave_precision_score": 0.7481531311663615,
            "fpr": 0.18990120746432493,
            "logloss": 3.3845318630721386,
            "mae": 0.27958623474148475,
            "precision": 0.7077702702702703,
            "recall": 0.8784067085953878
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6133722293699782,
            "auditor_fn_violation": 0.0019447202912942737,
            "auditor_fp_violation": 0.012515124016938921,
            "ave_precision_score": 0.545183343889196,
            "fpr": 0.4166666666666667,
            "logloss": 6.4878339331106165,
            "mae": 0.41773775097323795,
            "precision": 0.5508274231678487,
            "recall": 0.9769392033542977
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.615988837700587,
            "auditor_fn_violation": 0.001139117287658182,
            "auditor_fp_violation": 0.02166303297637174,
            "ave_precision_score": 0.5566167899448252,
            "fpr": 0.3940724478594951,
            "logloss": 5.839961875144124,
            "mae": 0.39623962205519814,
            "precision": 0.5685096153846154,
            "recall": 0.9916142557651991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6067011463457203,
            "auditor_fn_violation": 0.010620103718415536,
            "auditor_fp_violation": 0.06229078443234524,
            "ave_precision_score": 0.5927300102701617,
            "fpr": 0.24232456140350878,
            "logloss": 2.7312802302247685,
            "mae": 0.3543644159095461,
            "precision": 0.6525157232704403,
            "recall": 0.870020964360587
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6480347908183297,
            "auditor_fn_violation": 0.015567936264661823,
            "auditor_fp_violation": 0.05508202360296833,
            "ave_precision_score": 0.6324118588743566,
            "fpr": 0.21953896816684962,
            "logloss": 2.289499591931676,
            "mae": 0.329453506205143,
            "precision": 0.6758508914100486,
            "recall": 0.8742138364779874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8026136923841902,
            "auditor_fn_violation": 0.023955000183897904,
            "auditor_fp_violation": 0.01675236942932043,
            "ave_precision_score": 0.8003218502059128,
            "fpr": 0.13596491228070176,
            "logloss": 1.4643629301719605,
            "mae": 0.2960002381087299,
            "precision": 0.7292576419213974,
            "recall": 0.70020964360587
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8212880931337793,
            "auditor_fn_violation": 0.01076983617422281,
            "auditor_fp_violation": 0.023107235174796525,
            "ave_precision_score": 0.8215478343986903,
            "fpr": 0.15806805708013172,
            "logloss": 1.3856915416826354,
            "mae": 0.3047553359540741,
            "precision": 0.7037037037037037,
            "recall": 0.7169811320754716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7874944616499536,
            "auditor_fn_violation": 0.02310906984442238,
            "auditor_fp_violation": 0.019953619681387376,
            "ave_precision_score": 0.7406202744892082,
            "fpr": 0.1787280701754386,
            "logloss": 3.170768771853047,
            "mae": 0.29866299121197626,
            "precision": 0.7120141342756183,
            "recall": 0.8448637316561844
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7901041038402274,
            "auditor_fn_violation": 0.018506628742115352,
            "auditor_fp_violation": 0.029106618037604903,
            "ave_precision_score": 0.7394779973191605,
            "fpr": 0.19538968166849616,
            "logloss": 3.276107476467402,
            "mae": 0.2935107203889108,
            "precision": 0.7028380634390651,
            "recall": 0.8825995807127882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7943796945107461,
            "auditor_fn_violation": 0.01392107102136894,
            "auditor_fp_violation": 0.0077762653760838915,
            "ave_precision_score": 0.7626388233922725,
            "fpr": 0.11293859649122807,
            "logloss": 2.253976638853987,
            "mae": 0.28335747219237417,
            "precision": 0.7680180180180181,
            "recall": 0.7148846960167715
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7890571770717061,
            "auditor_fn_violation": 0.010019629637300452,
            "auditor_fp_violation": 0.01481888035126235,
            "ave_precision_score": 0.7511216232676042,
            "fpr": 0.13062568605927552,
            "logloss": 2.53432803673984,
            "mae": 0.2884839520538636,
            "precision": 0.746268656716418,
            "recall": 0.7337526205450734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6753062994102201,
            "auditor_fn_violation": 0.00893743793445879,
            "auditor_fp_violation": 0.018640350877192992,
            "ave_precision_score": 0.626157471090411,
            "fpr": 0.3618421052631579,
            "logloss": 4.733487667875368,
            "mae": 0.3882834476091845,
            "precision": 0.5769230769230769,
            "recall": 0.9433962264150944
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7086840670860883,
            "auditor_fn_violation": 0.007605621486283418,
            "auditor_fp_violation": 0.025383560881595664,
            "ave_precision_score": 0.6536259944326323,
            "fpr": 0.3391877058177827,
            "logloss": 4.620441594121789,
            "mae": 0.35941040980991873,
            "precision": 0.5987012987012987,
            "recall": 0.9664570230607966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6695042907991857,
            "auditor_fn_violation": 0.02395729890764648,
            "auditor_fp_violation": 0.025937689050211744,
            "ave_precision_score": 0.6646794891492118,
            "fpr": 0.2412280701754386,
            "logloss": 1.556108652566524,
            "mae": 0.3972530891514269,
            "precision": 0.6375617792421746,
            "recall": 0.8113207547169812
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6683272666329954,
            "auditor_fn_violation": 0.012765017362908963,
            "auditor_fp_violation": 0.015534658323511417,
            "ave_precision_score": 0.6664408583519152,
            "fpr": 0.2349066959385291,
            "logloss": 1.8886197027193155,
            "mae": 0.3881324869135863,
            "precision": 0.653160453808752,
            "recall": 0.8448637316561844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.8339501408355776,
            "auditor_fn_violation": 0.013629133105299946,
            "auditor_fp_violation": 0.00676799758015729,
            "ave_precision_score": 0.834307886125131,
            "fpr": 0.017543859649122806,
            "logloss": 0.775836468322373,
            "mae": 0.3819442601764836,
            "precision": 0.9058823529411765,
            "recall": 0.3228511530398323
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.818209912016909,
            "auditor_fn_violation": 0.0032309508522668515,
            "auditor_fp_violation": 0.0036142993722399555,
            "ave_precision_score": 0.818552857431963,
            "fpr": 0.01646542261251372,
            "logloss": 0.8141817862457239,
            "mae": 0.39477591459044364,
            "precision": 0.8958333333333334,
            "recall": 0.27044025157232704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.781930969324827,
            "auditor_fn_violation": 0.01722433704807091,
            "auditor_fp_violation": 0.022769207501512404,
            "ave_precision_score": 0.7488769106483214,
            "fpr": 0.23684210526315788,
            "logloss": 3.6308970528457065,
            "mae": 0.29988190972368384,
            "precision": 0.6598425196850394,
            "recall": 0.8784067085953878
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7775022386186016,
            "auditor_fn_violation": 0.006413575516572433,
            "auditor_fp_violation": 0.02962258519781272,
            "ave_precision_score": 0.7366513309380963,
            "fpr": 0.23929747530186607,
            "logloss": 3.988038993933206,
            "mae": 0.3020910239795605,
            "precision": 0.6577708006279435,
            "recall": 0.8784067085953878
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.806892110813561,
            "auditor_fn_violation": 0.007923700761337306,
            "auditor_fp_violation": 0.02083333333333335,
            "ave_precision_score": 0.8072529396065702,
            "fpr": 0.30153508771929827,
            "logloss": 0.9347477709311706,
            "mae": 0.3557807355842159,
            "precision": 0.6191135734072022,
            "recall": 0.9371069182389937
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.840310832779231,
            "auditor_fn_violation": 0.005180107100037511,
            "auditor_fp_violation": 0.027589067566405487,
            "ave_precision_score": 0.8405608255511523,
            "fpr": 0.29637760702524696,
            "logloss": 0.8565635735116578,
            "mae": 0.3384267902402994,
            "precision": 0.6270718232044199,
            "recall": 0.9517819706498952
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.756292248011968,
            "auditor_fn_violation": 0.0029101842656956856,
            "auditor_fp_violation": 0.005260637225247013,
            "ave_precision_score": 0.5255063136738185,
            "fpr": 0.4594298245614035,
            "logloss": 15.953297890655485,
            "mae": 0.47257667571735956,
            "precision": 0.5260180995475113,
            "recall": 0.9748427672955975
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.770149681388117,
            "auditor_fn_violation": 0.0010815861115138293,
            "auditor_fp_violation": 0.00899654504342726,
            "ave_precision_score": 0.5422291667750103,
            "fpr": 0.44017563117453345,
            "logloss": 15.21476137613561,
            "mae": 0.44238984897431327,
            "precision": 0.5422374429223744,
            "recall": 0.9958071278825996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8067374357821244,
            "auditor_fn_violation": 0.0072478759792563175,
            "auditor_fp_violation": 0.021271929824561418,
            "ave_precision_score": 0.807084980830783,
            "fpr": 0.30043859649122806,
            "logloss": 0.9309813667715823,
            "mae": 0.3552501496014884,
            "precision": 0.6183844011142061,
            "recall": 0.9308176100628931
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.838867377967194,
            "auditor_fn_violation": 0.0020112899180065686,
            "auditor_fp_violation": 0.02447303059887601,
            "ave_precision_score": 0.8391143730921682,
            "fpr": 0.29418221734357847,
            "logloss": 0.8528880497148481,
            "mae": 0.3385270782378344,
            "precision": 0.6277777777777778,
            "recall": 0.9475890985324947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7777500521424099,
            "auditor_fn_violation": 0.01567729596528008,
            "auditor_fp_violation": 0.02860959870941722,
            "ave_precision_score": 0.7589996921352469,
            "fpr": 0.15350877192982457,
            "logloss": 1.9283759167301213,
            "mae": 0.29840333801968766,
            "precision": 0.7194388777555111,
            "recall": 0.7526205450733753
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7798352764903799,
            "auditor_fn_violation": 0.00945352286404003,
            "auditor_fp_violation": 0.014191626156499925,
            "ave_precision_score": 0.7575509340235851,
            "fpr": 0.17014270032930845,
            "logloss": 2.123121117012213,
            "mae": 0.3001322891577859,
            "precision": 0.7047619047619048,
            "recall": 0.7756813417190775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8361253061856909,
            "auditor_fn_violation": 0.013911876126374633,
            "auditor_fp_violation": 0.018201754385964913,
            "ave_precision_score": 0.8368741689249126,
            "fpr": 0.12719298245614036,
            "logloss": 0.679680440986993,
            "mae": 0.2669565245012855,
            "precision": 0.7642276422764228,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8397318131508934,
            "auditor_fn_violation": 0.009211891924233745,
            "auditor_fp_violation": 0.01979391664601112,
            "ave_precision_score": 0.8399833710583526,
            "fpr": 0.15367727771679474,
            "logloss": 0.6914601000467553,
            "mae": 0.27544174552641,
            "precision": 0.7292069632495164,
            "recall": 0.790356394129979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7659093179352996,
            "auditor_fn_violation": 0.07221440656147707,
            "auditor_fp_violation": 0.07312462189957654,
            "ave_precision_score": 0.7637317520657804,
            "fpr": 0.24671052631578946,
            "logloss": 2.418387249480963,
            "mae": 0.36464529079871894,
            "precision": 0.6179966044142614,
            "recall": 0.7631027253668763
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8057733805373082,
            "auditor_fn_violation": 0.06787067912101567,
            "auditor_fp_violation": 0.06422779444273019,
            "ave_precision_score": 0.8061509656846966,
            "fpr": 0.24259055982436883,
            "logloss": 2.144819978967856,
            "mae": 0.3384831106477185,
            "precision": 0.632890365448505,
            "recall": 0.7987421383647799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.855585348326897,
            "auditor_fn_violation": 0.014337140019860972,
            "auditor_fp_violation": 0.0132637628554144,
            "ave_precision_score": 0.856800850430093,
            "fpr": 0.10526315789473684,
            "logloss": 0.7441306317297482,
            "mae": 0.2844286389775226,
            "precision": 0.7894736842105263,
            "recall": 0.7547169811320755
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8737599550521222,
            "auditor_fn_violation": 0.008388045481846613,
            "auditor_fp_violation": 0.010906129386353174,
            "ave_precision_score": 0.8739802192880926,
            "fpr": 0.09220636663007684,
            "logloss": 0.5237059570621428,
            "mae": 0.2743563685134817,
            "precision": 0.8145695364238411,
            "recall": 0.7735849056603774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 6832,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6335538062058881,
            "auditor_fn_violation": 0.0118545183714002,
            "auditor_fp_violation": 0.056773038919136924,
            "ave_precision_score": 0.5954413395139772,
            "fpr": 0.26535087719298245,
            "logloss": 4.073880932703445,
            "mae": 0.3492165864366127,
            "precision": 0.6388059701492538,
            "recall": 0.8972746331236897
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6641012901630523,
            "auditor_fn_violation": 0.007041815960068761,
            "auditor_fp_violation": 0.042911268823948974,
            "ave_precision_score": 0.6301809122725901,
            "fpr": 0.2623490669593853,
            "logloss": 3.3805681898744706,
            "mae": 0.32958857668001457,
            "precision": 0.6454005934718101,
            "recall": 0.9119496855345912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7526511107810248,
            "auditor_fn_violation": 0.008822501747030049,
            "auditor_fp_violation": 0.023908550110909452,
            "ave_precision_score": 0.753170179350702,
            "fpr": 0.30153508771929827,
            "logloss": 1.5868916451072221,
            "mae": 0.34376426398679594,
            "precision": 0.6180555555555556,
            "recall": 0.9329140461215933
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7577909710969433,
            "auditor_fn_violation": 0.004162955905805356,
            "auditor_fp_violation": 0.030017148320324573,
            "ave_precision_score": 0.7595644084666897,
            "fpr": 0.29857299670691545,
            "logloss": 1.5452613566023439,
            "mae": 0.3398208889680812,
            "precision": 0.6201117318435754,
            "recall": 0.9308176100628931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7756632633043892,
            "auditor_fn_violation": 0.014571609842215609,
            "auditor_fp_violation": 0.02391863278886873,
            "ave_precision_score": 0.757700591935121,
            "fpr": 0.15679824561403508,
            "logloss": 1.8848462531535588,
            "mae": 0.30316361026313204,
            "precision": 0.7116935483870968,
            "recall": 0.740041928721174
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7798705271180932,
            "auditor_fn_violation": 0.008063569648392473,
            "auditor_fp_violation": 0.01476576608477038,
            "ave_precision_score": 0.7577136084191172,
            "fpr": 0.1668496158068057,
            "logloss": 2.0858034759202853,
            "mae": 0.3002527456991139,
            "precision": 0.7071290944123314,
            "recall": 0.7693920335429769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7582374730599772,
            "auditor_fn_violation": 0.0725776049137519,
            "auditor_fp_violation": 0.04360254083484574,
            "ave_precision_score": 0.7558563263995693,
            "fpr": 0.14473684210526316,
            "logloss": 3.3455305306996608,
            "mae": 0.33898563095107054,
            "precision": 0.7111597374179431,
            "recall": 0.6813417190775681
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8119228007538288,
            "auditor_fn_violation": 0.06458219709260449,
            "auditor_fp_violation": 0.04725652167314998,
            "ave_precision_score": 0.8119442470011151,
            "fpr": 0.15806805708013172,
            "logloss": 2.8037625736328633,
            "mae": 0.31085665544731494,
            "precision": 0.7131474103585658,
            "recall": 0.750524109014675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.679542069177574,
            "auditor_fn_violation": 0.012964801941961824,
            "auditor_fp_violation": 0.058114035087719305,
            "ave_precision_score": 0.6811131075012656,
            "fpr": 0.19078947368421054,
            "logloss": 1.0386836596014515,
            "mae": 0.3429837411678276,
            "precision": 0.6859205776173285,
            "recall": 0.7966457023060797
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7187769616380895,
            "auditor_fn_violation": 0.01614094677905958,
            "auditor_fp_violation": 0.04818222746058162,
            "ave_precision_score": 0.719816006457892,
            "fpr": 0.1602634467618002,
            "logloss": 0.7991635762097437,
            "mae": 0.31787045269094827,
            "precision": 0.724007561436673,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7765175963287506,
            "auditor_fn_violation": 0.013054452168156245,
            "auditor_fp_violation": 0.01658348457350273,
            "ave_precision_score": 0.7768241123999267,
            "fpr": 0.18201754385964913,
            "logloss": 1.0456232479306233,
            "mae": 0.28624455287144857,
            "precision": 0.7030411449016101,
            "recall": 0.8238993710691824
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.79071290765754,
            "auditor_fn_violation": 0.009736576250670238,
            "auditor_fp_violation": 0.019257715479520657,
            "ave_precision_score": 0.7919803851047159,
            "fpr": 0.18880351262349068,
            "logloss": 1.0231090731825472,
            "mae": 0.2851238788335111,
            "precision": 0.6966490299823633,
            "recall": 0.8280922431865828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7613777917060912,
            "auditor_fn_violation": 0.07207648313656259,
            "auditor_fp_violation": 0.03793103448275862,
            "ave_precision_score": 0.7590887048656138,
            "fpr": 0.12171052631578948,
            "logloss": 4.82229194889845,
            "mae": 0.3523000467316967,
            "precision": 0.7272727272727273,
            "recall": 0.6205450733752621
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.795083143816274,
            "auditor_fn_violation": 0.06439809732894256,
            "auditor_fp_violation": 0.035338691972663865,
            "ave_precision_score": 0.795390479473983,
            "fpr": 0.12294182217343579,
            "logloss": 4.44382973938945,
            "mae": 0.3204048850892777,
            "precision": 0.7407407407407407,
            "recall": 0.6708595387840671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7859549949322846,
            "auditor_fn_violation": 0.020497719666041414,
            "auditor_fp_violation": 0.018804194394031064,
            "ave_precision_score": 0.7364703355995563,
            "fpr": 0.18859649122807018,
            "logloss": 3.313275789875603,
            "mae": 0.3007497192865037,
            "precision": 0.7044673539518901,
            "recall": 0.859538784067086
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7932352217743078,
            "auditor_fn_violation": 0.015839483416063165,
            "auditor_fp_violation": 0.028163207494675928,
            "ave_precision_score": 0.7422391859280053,
            "fpr": 0.1986827661909989,
            "logloss": 3.295267386637795,
            "mae": 0.2955841601544605,
            "precision": 0.7013201320132013,
            "recall": 0.8909853249475891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6057400543883718,
            "auditor_fn_violation": 0.01559454191033139,
            "auditor_fp_violation": 0.023800161322847357,
            "ave_precision_score": 0.6000293586348086,
            "fpr": 0.24780701754385964,
            "logloss": 2.8711687768782195,
            "mae": 0.4245180313725084,
            "precision": 0.5853211009174312,
            "recall": 0.6687631027253669
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6170575479539794,
            "auditor_fn_violation": 0.01218050061328234,
            "auditor_fp_violation": 0.021405049396267844,
            "ave_precision_score": 0.6150256396346725,
            "fpr": 0.23819978046103182,
            "logloss": 2.5426872600025434,
            "mae": 0.4364448233423659,
            "precision": 0.5769980506822612,
            "recall": 0.6205450733752621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8020093153900534,
            "auditor_fn_violation": 0.01191198646511457,
            "auditor_fp_violation": 0.02711736237144586,
            "ave_precision_score": 0.8024535485216091,
            "fpr": 0.2565789473684211,
            "logloss": 0.7654837664151249,
            "mae": 0.32950227903743406,
            "precision": 0.6507462686567164,
            "recall": 0.9140461215932913
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8403535527971377,
            "auditor_fn_violation": 0.0051616971236713195,
            "auditor_fp_violation": 0.042794923287823694,
            "ave_precision_score": 0.8405980714674876,
            "fpr": 0.23929747530186607,
            "logloss": 0.6963088217134772,
            "mae": 0.306319551979438,
            "precision": 0.6716867469879518,
            "recall": 0.9350104821802935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7809011399819055,
            "auditor_fn_violation": 0.015272720585530915,
            "auditor_fp_violation": 0.022801976204880014,
            "ave_precision_score": 0.7813914663301375,
            "fpr": 0.23903508771929824,
            "logloss": 1.1473692367642077,
            "mae": 0.3007844642750274,
            "precision": 0.6635802469135802,
            "recall": 0.9014675052410901
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7939289137607862,
            "auditor_fn_violation": 0.004749773902477754,
            "auditor_fp_violation": 0.023491681294167056,
            "ave_precision_score": 0.7952116005183245,
            "fpr": 0.23929747530186607,
            "logloss": 1.1630743412742075,
            "mae": 0.29505974952280367,
            "precision": 0.6676829268292683,
            "recall": 0.9182389937106918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.795122940521765,
            "auditor_fn_violation": 0.018819651329581816,
            "auditor_fp_violation": 0.01319570477918936,
            "ave_precision_score": 0.7767128728680964,
            "fpr": 0.10964912280701754,
            "logloss": 1.814341880163786,
            "mae": 0.27537503267226404,
            "precision": 0.7752808988764045,
            "recall": 0.7232704402515723
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7893192726274689,
            "auditor_fn_violation": 0.019178592879481395,
            "auditor_fp_violation": 0.017295016870102743,
            "ave_precision_score": 0.7674686042049339,
            "fpr": 0.13721185510428102,
            "logloss": 2.022078156880196,
            "mae": 0.27933819231680285,
            "precision": 0.7422680412371134,
            "recall": 0.7547169811320755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7710535460363659,
            "auditor_fn_violation": 0.05269364448857994,
            "auditor_fp_violation": 0.027185420447670902,
            "ave_precision_score": 0.7688547346432206,
            "fpr": 0.09868421052631579,
            "logloss": 4.0263332615303,
            "mae": 0.3256538322259231,
            "precision": 0.75,
            "recall": 0.5660377358490566
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.807325958460863,
            "auditor_fn_violation": 0.04330716815442289,
            "auditor_fp_violation": 0.03397542579936971,
            "ave_precision_score": 0.8074183894693736,
            "fpr": 0.11964873765093303,
            "logloss": 3.7274392464260777,
            "mae": 0.31244205691861654,
            "precision": 0.7334963325183375,
            "recall": 0.6289308176100629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7504512966013959,
            "auditor_fn_violation": 0.00028274302107470395,
            "auditor_fp_violation": 0.008217382536801786,
            "ave_precision_score": 0.7474328822843568,
            "fpr": 0.26864035087719296,
            "logloss": 1.5192990276286158,
            "mae": 0.3641139295165492,
            "precision": 0.6141732283464567,
            "recall": 0.8176100628930818
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7554404139119666,
            "auditor_fn_violation": 0.013103300678637755,
            "auditor_fp_violation": 0.013020583042891054,
            "ave_precision_score": 0.7530967404298252,
            "fpr": 0.2667398463227223,
            "logloss": 1.2924235285167132,
            "mae": 0.36847128786873007,
            "precision": 0.6105769230769231,
            "recall": 0.7987421383647799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6889945223511342,
            "auditor_fn_violation": 0.02941217036301446,
            "auditor_fp_violation": 0.029970760233918127,
            "ave_precision_score": 0.68994076603027,
            "fpr": 0.15899122807017543,
            "logloss": 0.9799635118521512,
            "mae": 0.35610295709972106,
            "precision": 0.6927966101694916,
            "recall": 0.6855345911949685
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7306887640815835,
            "auditor_fn_violation": 0.02619279387500087,
            "auditor_fp_violation": 0.020701917677945447,
            "ave_precision_score": 0.7319174960503734,
            "fpr": 0.150384193194292,
            "logloss": 0.88937226397166,
            "mae": 0.33449051634273624,
            "precision": 0.7145833333333333,
            "recall": 0.7190775681341719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7691919361533103,
            "auditor_fn_violation": 0.06769281694803045,
            "auditor_fp_violation": 0.024727767695099823,
            "ave_precision_score": 0.7688551285222297,
            "fpr": 0.08223684210526316,
            "logloss": 2.9027447355955123,
            "mae": 0.35155323410211375,
            "precision": 0.7893258426966292,
            "recall": 0.589098532494759
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7779372685941188,
            "auditor_fn_violation": 0.059586189756228904,
            "auditor_fp_violation": 0.024397153075316032,
            "ave_precision_score": 0.7792208419348647,
            "fpr": 0.08122941822173436,
            "logloss": 2.7356402763060643,
            "mae": 0.33276506755768936,
            "precision": 0.8052631578947368,
            "recall": 0.6415094339622641
        }
    }
]