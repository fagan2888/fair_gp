[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 31658,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5420075043039639,
            "auditor_fn_violation": 0.01078479051839043,
            "auditor_fp_violation": 0.0008152734778121975,
            "ave_precision_score": 0.5442173820969342,
            "fpr": 0.3059210526315789,
            "logloss": 0.6966764482924223,
            "mae": 0.5013664442261583,
            "precision": 0.5147826086956522,
            "recall": 0.6078028747433265
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.5943413829600301,
            "auditor_fn_violation": 0.007070377047600469,
            "auditor_fp_violation": 0.004146023081259115,
            "ave_precision_score": 0.5957250764831653,
            "fpr": 0.2996706915477497,
            "logloss": 0.6918542506986701,
            "mae": 0.49897625954038616,
            "precision": 0.5341296928327645,
            "recall": 0.6702355460385439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5536593086926762,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5469244454705926,
            "fpr": 0.46600877192982454,
            "logloss": 0.8127688898199537,
            "mae": 0.48353100907907154,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6219000876542888,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5462019943332802,
            "fpr": 0.48737650933040616,
            "logloss": 0.7985216532799554,
            "mae": 0.48591236251638437,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7562401540676135,
            "auditor_fn_violation": 0.015994812493245428,
            "auditor_fp_violation": 0.017476780185758517,
            "ave_precision_score": 0.7094736195995175,
            "fpr": 0.1337719298245614,
            "logloss": 2.8276590793349614,
            "mae": 0.37975776294019614,
            "precision": 0.7175925925925926,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7470765717563373,
            "auditor_fn_violation": 0.013360380032766316,
            "auditor_fp_violation": 0.016603870610456782,
            "ave_precision_score": 0.694552001217537,
            "fpr": 0.15367727771679474,
            "logloss": 3.123728832522994,
            "mae": 0.38819858415535846,
            "precision": 0.6895787139689579,
            "recall": 0.6659528907922913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 31658,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5426857151272085,
            "auditor_fn_violation": 0.01078479051839043,
            "auditor_fp_violation": 0.0008152734778121975,
            "ave_precision_score": 0.544837601104817,
            "fpr": 0.3059210526315789,
            "logloss": 0.6966780889088109,
            "mae": 0.501365330364359,
            "precision": 0.5147826086956522,
            "recall": 0.6078028747433265
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.5945190038973022,
            "auditor_fn_violation": 0.007070377047600469,
            "auditor_fp_violation": 0.004146023081259115,
            "ave_precision_score": 0.5958998824636527,
            "fpr": 0.2996706915477497,
            "logloss": 0.6918424703786378,
            "mae": 0.498968058373088,
            "precision": 0.5341296928327645,
            "recall": 0.6702355460385439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 31658,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6194533207435834,
            "auditor_fn_violation": 0.005889981627580268,
            "auditor_fp_violation": 0.0017182662538699702,
            "ave_precision_score": 0.5671658819091391,
            "fpr": 0.020833333333333332,
            "logloss": 0.7165592913991493,
            "mae": 0.4950848144168655,
            "precision": 0.6885245901639344,
            "recall": 0.08624229979466119
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5942889939552007,
            "auditor_fn_violation": 0.005211112338607139,
            "auditor_fp_violation": 0.0043091939359776905,
            "ave_precision_score": 0.550799967597323,
            "fpr": 0.01646542261251372,
            "logloss": 0.6948195358751135,
            "mae": 0.48639850112334565,
            "precision": 0.6875,
            "recall": 0.07066381156316917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5262927316837671,
            "auditor_fn_violation": 0.005495965272524227,
            "auditor_fp_violation": 0.009656862745098043,
            "ave_precision_score": 0.5283875679784803,
            "fpr": 0.41885964912280704,
            "logloss": 0.6928413770652689,
            "mae": 0.49977467970497774,
            "precision": 0.520702634880803,
            "recall": 0.8521560574948666
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5082297141102137,
            "auditor_fn_violation": 0.004028798623532982,
            "auditor_fp_violation": 0.010220428991010768,
            "ave_precision_score": 0.5095966343218042,
            "fpr": 0.42371020856201974,
            "logloss": 0.6926404676743285,
            "mae": 0.49967439686951076,
            "precision": 0.5175,
            "recall": 0.8865096359743041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5345112002237913,
            "auditor_fn_violation": 0.003244443243632696,
            "auditor_fp_violation": 0.007432920536635721,
            "ave_precision_score": 0.5361985244965033,
            "fpr": 0.37719298245614036,
            "logloss": 0.8279276231532099,
            "mae": 0.4827965792356903,
            "precision": 0.538255033557047,
            "recall": 0.8234086242299795
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5466336553215048,
            "auditor_fn_violation": 0.008760404008114007,
            "auditor_fp_violation": 0.007683863885839738,
            "ave_precision_score": 0.5482696796649162,
            "fpr": 0.36553238199780463,
            "logloss": 0.8282712596984718,
            "mae": 0.48088586342039574,
            "precision": 0.5269886363636364,
            "recall": 0.7944325481798715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5624081649794236,
            "auditor_fn_violation": 0.005464443964119742,
            "auditor_fp_violation": 0.0017182662538699702,
            "ave_precision_score": 0.5597014669423113,
            "fpr": 0.020833333333333332,
            "logloss": 0.7174637393479062,
            "mae": 0.4954127831253828,
            "precision": 0.6833333333333333,
            "recall": 0.08418891170431211
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.5541512541574267,
            "auditor_fn_violation": 0.004007643904973021,
            "auditor_fp_violation": 0.0043091939359776905,
            "ave_precision_score": 0.552644378235071,
            "fpr": 0.01646542261251372,
            "logloss": 0.6941102122769626,
            "mae": 0.4862183457573735,
            "precision": 0.6808510638297872,
            "recall": 0.06852248394004283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5163767664555873,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5326691839627069,
            "fpr": 0.46600877192982454,
            "logloss": 1.1572060120929564,
            "mae": 0.5025494715623688,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5120612666369474,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.520420694272271,
            "fpr": 0.48737650933040616,
            "logloss": 0.977896368028317,
            "mae": 0.49997020382781715,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.765668948512689,
            "auditor_fn_violation": 0.0025487229367052136,
            "auditor_fp_violation": 0.0031785345717234275,
            "ave_precision_score": 0.5427034683239701,
            "fpr": 0.43969298245614036,
            "logloss": 15.182208604587593,
            "mae": 0.4537200071244386,
            "precision": 0.5427594070695553,
            "recall": 0.9774127310061602
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7633281199482987,
            "auditor_fn_violation": 0.0019368320103799153,
            "auditor_fp_violation": 0.008524441016208301,
            "ave_precision_score": 0.5308063957786747,
            "fpr": 0.4500548847420417,
            "logloss": 15.524710821332135,
            "mae": 0.45843713644699785,
            "precision": 0.5303550973654066,
            "recall": 0.9914346895074947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 31658,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5521526877891445,
            "auditor_fn_violation": 0.009201970532079693,
            "auditor_fp_violation": 0.009055727554179577,
            "ave_precision_score": 0.5482526141818336,
            "fpr": 0.2949561403508772,
            "logloss": 2.176134543433617,
            "mae": 0.4510393617531742,
            "precision": 0.5661290322580645,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5426592646233507,
            "auditor_fn_violation": 0.009568984361961946,
            "auditor_fp_violation": 0.018136687730540647,
            "ave_precision_score": 0.5367780049187387,
            "fpr": 0.31174533479692645,
            "logloss": 2.3820365515993247,
            "mae": 0.4539049374455324,
            "precision": 0.55625,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.49741647154236485,
            "auditor_fn_violation": 0.0028324147123455572,
            "auditor_fp_violation": 0.005515995872033025,
            "ave_precision_score": 0.5303134664677921,
            "fpr": 0.023026315789473683,
            "logloss": 0.8455564519119101,
            "mae": 0.5017134536776626,
            "precision": 0.475,
            "recall": 0.039014373716632446
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5961286788165912,
            "auditor_fn_violation": 0.004000592332119678,
            "auditor_fp_violation": 0.0036045925178746253,
            "ave_precision_score": 0.5304154343489866,
            "fpr": 0.015367727771679473,
            "logloss": 0.7971695463793157,
            "mae": 0.4880548012897814,
            "precision": 0.72,
            "recall": 0.07708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5143957863701414,
            "auditor_fn_violation": 0.01822381930184806,
            "auditor_fp_violation": 0.009778121775025803,
            "ave_precision_score": 0.5278847302139422,
            "fpr": 0.18859649122807018,
            "logloss": 2.2817063732396043,
            "mae": 0.5141184848645153,
            "precision": 0.5413333333333333,
            "recall": 0.41683778234086244
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5537150826375425,
            "auditor_fn_violation": 0.015663893831519126,
            "auditor_fp_violation": 0.02130368568348811,
            "ave_precision_score": 0.5294584848765829,
            "fpr": 0.18990120746432493,
            "logloss": 1.9654305844440731,
            "mae": 0.4956800255978582,
            "precision": 0.5349462365591398,
            "recall": 0.4261241970021413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.533338823305477,
            "auditor_fn_violation": 0.001474746928923953,
            "auditor_fp_violation": 0.009184726522187839,
            "ave_precision_score": 0.5350519025591844,
            "fpr": 0.3782894736842105,
            "logloss": 0.8157973086899848,
            "mae": 0.486099949237286,
            "precision": 0.5362903225806451,
            "recall": 0.8193018480492813
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.538666782989115,
            "auditor_fn_violation": 0.00817747398557248,
            "auditor_fp_violation": 0.006447721047062439,
            "ave_precision_score": 0.5403267834138026,
            "fpr": 0.3732162458836443,
            "logloss": 0.8142502992320693,
            "mae": 0.4869898707737776,
            "precision": 0.5224719101123596,
            "recall": 0.7965738758029979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 31658,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5071905944233943,
            "auditor_fn_violation": 0.005955275766418103,
            "auditor_fp_violation": 0.006867905056759557,
            "ave_precision_score": 0.5083593270241106,
            "fpr": 0.40350877192982454,
            "logloss": 0.8729735541306985,
            "mae": 0.4839003545271914,
            "precision": 0.5306122448979592,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5105165164096781,
            "auditor_fn_violation": 0.00907537426222919,
            "auditor_fp_violation": 0.006366135619703143,
            "ave_precision_score": 0.5116922491597043,
            "fpr": 0.39626783754116357,
            "logloss": 0.8894424448918183,
            "mae": 0.4896718667830463,
            "precision": 0.5186666666666667,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7039232940856035,
            "auditor_fn_violation": 0.010005763896393969,
            "auditor_fp_violation": 0.020531475748194014,
            "ave_precision_score": 0.7033726639845417,
            "fpr": 0.17763157894736842,
            "logloss": 1.3104811851158502,
            "mae": 0.3077942373429004,
            "precision": 0.705989110707804,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.716670189261765,
            "auditor_fn_violation": 0.009033064825109243,
            "auditor_fp_violation": 0.020302409984078482,
            "ave_precision_score": 0.7157645881731132,
            "fpr": 0.18880351262349068,
            "logloss": 1.2260782903943075,
            "mae": 0.30477629880891216,
            "precision": 0.6895306859205776,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6959592194394412,
            "auditor_fn_violation": 0.010253431319572034,
            "auditor_fp_violation": 0.02754127966976265,
            "ave_precision_score": 0.695424409909319,
            "fpr": 0.17982456140350878,
            "logloss": 1.516406997331901,
            "mae": 0.3148870679958378,
            "precision": 0.7018181818181818,
            "recall": 0.7926078028747433
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7210770293441753,
            "auditor_fn_violation": 0.00810460773275479,
            "auditor_fp_violation": 0.024445960779660023,
            "ave_precision_score": 0.7206929429796693,
            "fpr": 0.18441273326015367,
            "logloss": 1.3227658340692938,
            "mae": 0.29579139272400884,
            "precision": 0.6967509025270758,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7570268831920853,
            "auditor_fn_violation": 0.015994812493245428,
            "auditor_fp_violation": 0.01705366357069144,
            "ave_precision_score": 0.708935272353346,
            "fpr": 0.13267543859649122,
            "logloss": 2.8858630829468903,
            "mae": 0.3777136171161066,
            "precision": 0.7192575406032483,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.747746177887695,
            "auditor_fn_violation": 0.012431922940411863,
            "auditor_fp_violation": 0.016603870610456782,
            "ave_precision_score": 0.6951404994520385,
            "fpr": 0.15367727771679474,
            "logloss": 3.1639191279912056,
            "mae": 0.3862511631812896,
            "precision": 0.6902654867256637,
            "recall": 0.6680942184154176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.69324611875444,
            "auditor_fn_violation": 0.011755196512842682,
            "auditor_fp_violation": 0.027043343653250784,
            "ave_precision_score": 0.693606747860992,
            "fpr": 0.20394736842105263,
            "logloss": 1.7519690911882848,
            "mae": 0.3348057548365871,
            "precision": 0.671957671957672,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7119780521554497,
            "auditor_fn_violation": 0.010892329534102586,
            "auditor_fp_violation": 0.027279200166137593,
            "ave_precision_score": 0.7121130954490293,
            "fpr": 0.20417124039517015,
            "logloss": 1.399145611536665,
            "mae": 0.3176150053152932,
            "precision": 0.6736842105263158,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7039071522974985,
            "auditor_fn_violation": 0.010005763896393969,
            "auditor_fp_violation": 0.020531475748194014,
            "ave_precision_score": 0.7033565332119733,
            "fpr": 0.17763157894736842,
            "logloss": 1.3107917902653796,
            "mae": 0.307816349486302,
            "precision": 0.705989110707804,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7165896598089834,
            "auditor_fn_violation": 0.009033064825109243,
            "auditor_fp_violation": 0.020302409984078482,
            "ave_precision_score": 0.7157029911873725,
            "fpr": 0.18880351262349068,
            "logloss": 1.2262486664982053,
            "mae": 0.30478754203865727,
            "precision": 0.6895306859205776,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6767208107393836,
            "auditor_fn_violation": 0.04301983140603048,
            "auditor_fp_violation": 0.033477812177502585,
            "ave_precision_score": 0.6753840671745882,
            "fpr": 0.15570175438596492,
            "logloss": 1.6959608077184098,
            "mae": 0.3412613270028212,
            "precision": 0.7010526315789474,
            "recall": 0.6837782340862423
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.707627041145235,
            "auditor_fn_violation": 0.044681116122951225,
            "auditor_fp_violation": 0.03589758803809298,
            "ave_precision_score": 0.7058292780117335,
            "fpr": 0.141602634467618,
            "logloss": 1.7282215282797004,
            "mae": 0.3172586808450315,
            "precision": 0.7146017699115044,
            "recall": 0.6916488222698073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7572794691001876,
            "auditor_fn_violation": 0.015994812493245428,
            "auditor_fp_violation": 0.01705366357069144,
            "ave_precision_score": 0.7091948741400855,
            "fpr": 0.13267543859649122,
            "logloss": 2.8828660686625276,
            "mae": 0.37704857673650205,
            "precision": 0.7192575406032483,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7478201307621936,
            "auditor_fn_violation": 0.012431922940411863,
            "auditor_fp_violation": 0.016603870610456782,
            "ave_precision_score": 0.695234176722315,
            "fpr": 0.15367727771679474,
            "logloss": 3.156848701093142,
            "mae": 0.3855554842610939,
            "precision": 0.6902654867256637,
            "recall": 0.6680942184154176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7571840214601884,
            "auditor_fn_violation": 0.015994812493245428,
            "auditor_fp_violation": 0.01705366357069144,
            "ave_precision_score": 0.7091105972778029,
            "fpr": 0.13267543859649122,
            "logloss": 2.883189167256424,
            "mae": 0.37742377315487574,
            "precision": 0.7192575406032483,
            "recall": 0.6365503080082136
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.747702510160149,
            "auditor_fn_violation": 0.012431922940411863,
            "auditor_fp_violation": 0.016603870610456782,
            "ave_precision_score": 0.6951151891542575,
            "fpr": 0.15367727771679474,
            "logloss": 3.157409309940012,
            "mae": 0.3859504347109429,
            "precision": 0.6902654867256637,
            "recall": 0.6680942184154176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.504603524098661,
            "auditor_fn_violation": 0.0009501422961922262,
            "auditor_fp_violation": 0.0032765737874097074,
            "ave_precision_score": 0.5429391826588984,
            "fpr": 0.4550438596491228,
            "logloss": 0.9616338260518065,
            "mae": 0.5006063090016445,
            "precision": 0.5363128491620112,
            "recall": 0.9856262833675564
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5983686053107157,
            "auditor_fn_violation": 0.000575878449688203,
            "auditor_fp_violation": 0.0008381048446910201,
            "ave_precision_score": 0.5389992111020153,
            "fpr": 0.47310647639956094,
            "logloss": 0.92127832846523,
            "mae": 0.4881151747428756,
            "precision": 0.5135440180586908,
            "recall": 0.974304068522484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5046060876498225,
            "auditor_fn_violation": 1.350913217335e-05,
            "auditor_fp_violation": 0.00517285861713108,
            "ave_precision_score": 0.5429417459706889,
            "fpr": 0.42543859649122806,
            "logloss": 0.958612152965426,
            "mae": 0.5007455883253562,
            "precision": 0.5467289719626168,
            "recall": 0.9609856262833676
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5983733570291015,
            "auditor_fn_violation": 0.0023646274301482952,
            "auditor_fp_violation": 0.0026107336754976765,
            "ave_precision_score": 0.5390122284340416,
            "fpr": 0.4500548847420417,
            "logloss": 0.9194922557105587,
            "mae": 0.4881786931097573,
            "precision": 0.5221445221445221,
            "recall": 0.9593147751605996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.5635687310970885,
            "auditor_fn_violation": 0.0028324147123455572,
            "auditor_fp_violation": 0.005515995872033025,
            "ave_precision_score": 0.5583623992585778,
            "fpr": 0.023026315789473683,
            "logloss": 0.7744997052522478,
            "mae": 0.502038713806031,
            "precision": 0.475,
            "recall": 0.039014373716632446
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5739295441313381,
            "auditor_fn_violation": 0.004000592332119678,
            "auditor_fp_violation": 0.0036045925178746253,
            "ave_precision_score": 0.5703431077109383,
            "fpr": 0.015367727771679473,
            "logloss": 0.7228240350311371,
            "mae": 0.4876688437783757,
            "precision": 0.72,
            "recall": 0.07708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6822043792037142,
            "auditor_fn_violation": 0.016604974963075038,
            "auditor_fp_violation": 0.03316563467492261,
            "ave_precision_score": 0.680966429755108,
            "fpr": 0.2138157894736842,
            "logloss": 1.8493485846843334,
            "mae": 0.338951631981755,
            "precision": 0.6632124352331606,
            "recall": 0.7885010266940452
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6951104939113459,
            "auditor_fn_violation": 0.010915834776947,
            "auditor_fp_violation": 0.030082772124484528,
            "ave_precision_score": 0.6940152911692854,
            "fpr": 0.21734357848518113,
            "logloss": 1.5358532105986167,
            "mae": 0.3210040794268451,
            "precision": 0.6597938144329897,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6723628204064285,
            "auditor_fn_violation": 0.04143250837566196,
            "auditor_fp_violation": 0.030815273477812183,
            "ave_precision_score": 0.670995766835737,
            "fpr": 0.1600877192982456,
            "logloss": 1.7509233320793813,
            "mae": 0.34140074354786465,
            "precision": 0.6977225672877847,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7028209260957909,
            "auditor_fn_violation": 0.04527344824263053,
            "auditor_fp_violation": 0.03475044748370765,
            "ave_precision_score": 0.701028039323512,
            "fpr": 0.14709110867178923,
            "logloss": 1.7619673437179035,
            "mae": 0.3182904929982769,
            "precision": 0.706140350877193,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5536593086926762,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5469244454705926,
            "fpr": 0.46600877192982454,
            "logloss": 0.8161882071715406,
            "mae": 0.4832810202057947,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6219000876542888,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5462019943332802,
            "fpr": 0.48737650933040616,
            "logloss": 0.8022505050966001,
            "mae": 0.4859215377714448,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6723628204064285,
            "auditor_fn_violation": 0.04143250837566196,
            "auditor_fp_violation": 0.030815273477812183,
            "ave_precision_score": 0.670995766835737,
            "fpr": 0.1600877192982456,
            "logloss": 1.7509234410594232,
            "mae": 0.3414007385094953,
            "precision": 0.6977225672877847,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7028209260957909,
            "auditor_fn_violation": 0.04527344824263053,
            "auditor_fp_violation": 0.03475044748370765,
            "ave_precision_score": 0.701028039323512,
            "fpr": 0.14709110867178923,
            "logloss": 1.761967459902286,
            "mae": 0.3182904796865749,
            "precision": 0.706140350877193,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5337975793337444,
            "auditor_fn_violation": 0.001310385820814871,
            "auditor_fp_violation": 0.003588751289989694,
            "ave_precision_score": 0.5357759269974012,
            "fpr": 0.45614035087719296,
            "logloss": 0.7557966250651483,
            "mae": 0.44057105739780683,
            "precision": 0.5382907880133185,
            "recall": 0.9958932238193019
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5982185037206971,
            "auditor_fn_violation": 0.002797123898485557,
            "auditor_fp_violation": 0.0009493577001809785,
            "ave_precision_score": 0.6002537659957441,
            "fpr": 0.47200878155872666,
            "logloss": 0.6673333152154083,
            "mae": 0.41184288557745624,
            "precision": 0.5179372197309418,
            "recall": 0.9892933618843683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6816546680126311,
            "auditor_fn_violation": 0.015916009222234233,
            "auditor_fp_violation": 0.02993034055727555,
            "ave_precision_score": 0.6804848278412756,
            "fpr": 0.21820175438596492,
            "logloss": 1.8748006962400579,
            "mae": 0.33902025271691494,
            "precision": 0.6615646258503401,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6943774977247618,
            "auditor_fn_violation": 0.011651548877977234,
            "auditor_fp_violation": 0.030750289257424287,
            "ave_precision_score": 0.6933003909668687,
            "fpr": 0.21844127332601537,
            "logloss": 1.5472859691357725,
            "mae": 0.3213095967873535,
            "precision": 0.6592465753424658,
            "recall": 0.8244111349036403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 31658,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.4972590492018416,
            "auditor_fn_violation": 0.03838169602651393,
            "auditor_fp_violation": 0.027631578947368424,
            "ave_precision_score": 0.49798807181758276,
            "fpr": 0.3541666666666667,
            "logloss": 1.1655418120793903,
            "mae": 0.5040423471415252,
            "precision": 0.522189349112426,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5120464578609197,
            "auditor_fn_violation": 0.0375167181039731,
            "auditor_fp_violation": 0.030305277835464467,
            "ave_precision_score": 0.5127038049851071,
            "fpr": 0.3578485181119649,
            "logloss": 0.9838193055932122,
            "mae": 0.5000057084042207,
            "precision": 0.5282199710564399,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7039071522974985,
            "auditor_fn_violation": 0.010005763896393969,
            "auditor_fp_violation": 0.020531475748194014,
            "ave_precision_score": 0.7033565332119733,
            "fpr": 0.17763157894736842,
            "logloss": 1.310791761194421,
            "mae": 0.30781634854586454,
            "precision": 0.705989110707804,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7165896598089834,
            "auditor_fn_violation": 0.009033064825109243,
            "auditor_fp_violation": 0.020302409984078482,
            "ave_precision_score": 0.7157029911873725,
            "fpr": 0.18880351262349068,
            "logloss": 1.2262486444813971,
            "mae": 0.304787541315751,
            "precision": 0.6895306859205776,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6792919088376114,
            "auditor_fn_violation": 0.0442896898303253,
            "auditor_fp_violation": 0.03214654282765739,
            "ave_precision_score": 0.6780177286182851,
            "fpr": 0.15789473684210525,
            "logloss": 1.6964960439917962,
            "mae": 0.34134724489272233,
            "precision": 0.6962025316455697,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7027620181559546,
            "auditor_fn_violation": 0.045614274263874564,
            "auditor_fp_violation": 0.03554157890052512,
            "ave_precision_score": 0.7015639383991816,
            "fpr": 0.14489571899012074,
            "logloss": 1.8033184467460914,
            "mae": 0.3193460339008426,
            "precision": 0.7092511013215859,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 31658,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.49731756591534365,
            "auditor_fn_violation": 0.03838169602651393,
            "auditor_fp_violation": 0.027631578947368424,
            "ave_precision_score": 0.49803834372283873,
            "fpr": 0.3541666666666667,
            "logloss": 1.1660801584891551,
            "mae": 0.5040173028644762,
            "precision": 0.522189349112426,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5119246957931252,
            "auditor_fn_violation": 0.036926736508578244,
            "auditor_fp_violation": 0.02973417984394933,
            "ave_precision_score": 0.5125909549989084,
            "fpr": 0.3567508232711306,
            "logloss": 0.9843506659785486,
            "mae": 0.49993936859815497,
            "precision": 0.5283018867924528,
            "recall": 0.7794432548179872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5075278144313383,
            "auditor_fn_violation": 0.007682193162577904,
            "auditor_fp_violation": 0.0019298245614035082,
            "ave_precision_score": 0.5090563180487169,
            "fpr": 0.4100877192982456,
            "logloss": 0.8837693861028937,
            "mae": 0.4841185148528497,
            "precision": 0.5319148936170213,
            "recall": 0.8726899383983573
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5413377395264978,
            "auditor_fn_violation": 0.00946321076916206,
            "auditor_fp_violation": 0.008751891298543327,
            "ave_precision_score": 0.5425921747368163,
            "fpr": 0.4039517014270033,
            "logloss": 0.8887742243370358,
            "mae": 0.4851607378506016,
            "precision": 0.5282051282051282,
            "recall": 0.8822269807280514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.5136882617200922,
            "auditor_fn_violation": 0.0028324147123455572,
            "auditor_fp_violation": 0.005515995872033025,
            "ave_precision_score": 0.5190539594841403,
            "fpr": 0.023026315789473683,
            "logloss": 1.0061909399780513,
            "mae": 0.5106139989863885,
            "precision": 0.475,
            "recall": 0.039014373716632446
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.528761415483746,
            "auditor_fn_violation": 0.004000592332119678,
            "auditor_fp_violation": 0.0036045925178746253,
            "ave_precision_score": 0.5318206706763664,
            "fpr": 0.015367727771679473,
            "logloss": 0.9526326171581648,
            "mae": 0.4889953940223522,
            "precision": 0.72,
            "recall": 0.07708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5057503252851687,
            "auditor_fn_violation": 0.005955275766418103,
            "auditor_fp_violation": 0.0058978328173374655,
            "ave_precision_score": 0.5069147518870373,
            "fpr": 0.4067982456140351,
            "logloss": 0.8616784644107122,
            "mae": 0.48705383216994896,
            "precision": 0.5285895806861499,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5054091980299056,
            "auditor_fn_violation": 0.008153968742728071,
            "auditor_fp_violation": 0.007654196457709099,
            "ave_precision_score": 0.5065572418974893,
            "fpr": 0.4039517014270033,
            "logloss": 0.8751244066893823,
            "mae": 0.4958088146410187,
            "precision": 0.5138705416116248,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.5270286136000284,
            "auditor_fn_violation": 0.0001936308944846717,
            "auditor_fp_violation": 0.0020252837977296303,
            "ave_precision_score": 0.5304276368447846,
            "fpr": 0.4605263157894737,
            "logloss": 0.692124786350534,
            "mae": 0.4991337112886341,
            "precision": 0.5348837209302325,
            "recall": 0.9917864476386037
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5069307713313342,
            "auditor_fn_violation": 0.0024915557415081434,
            "auditor_fp_violation": 0.0026453456749834523,
            "ave_precision_score": 0.5098705180063385,
            "fpr": 0.47530186608122943,
            "logloss": 0.6919064398215842,
            "mae": 0.49896944154761363,
            "precision": 0.5162011173184358,
            "recall": 0.9892933618843683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.505785203417601,
            "auditor_fn_violation": 0.005955275766418103,
            "auditor_fp_violation": 0.0058978328173374655,
            "ave_precision_score": 0.5069480399802692,
            "fpr": 0.4067982456140351,
            "logloss": 0.8616778356772833,
            "mae": 0.48705391474721726,
            "precision": 0.5285895806861499,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5054335356442949,
            "auditor_fn_violation": 0.008153968742728071,
            "auditor_fp_violation": 0.007654196457709099,
            "ave_precision_score": 0.5065843662326766,
            "fpr": 0.4039517014270033,
            "logloss": 0.8751237306523354,
            "mae": 0.4958088601132779,
            "precision": 0.5138705416116248,
            "recall": 0.8329764453961456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7177181580845094,
            "auditor_fn_violation": 0.005196512842681654,
            "auditor_fp_violation": 0.01809855521155831,
            "ave_precision_score": 0.7064593330119446,
            "fpr": 0.39364035087719296,
            "logloss": 0.7159286233187224,
            "mae": 0.41605487349034664,
            "precision": 0.5674698795180723,
            "recall": 0.9671457905544147
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6825170991935949,
            "auditor_fn_violation": 0.0030674341911963465,
            "auditor_fp_violation": 0.016158859188496955,
            "ave_precision_score": 0.6767885944985429,
            "fpr": 0.41931942919868276,
            "logloss": 0.746661298495598,
            "mae": 0.423136574229477,
            "precision": 0.5425149700598803,
            "recall": 0.9700214132762313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.688190371264676,
            "auditor_fn_violation": 0.016573453654670563,
            "auditor_fp_violation": 0.030724974200206395,
            "ave_precision_score": 0.6868297995916135,
            "fpr": 0.18201754385964913,
            "logloss": 1.393876751823094,
            "mae": 0.3088710108572661,
            "precision": 0.7051509769094139,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7288416924296082,
            "auditor_fn_violation": 0.010492740405747505,
            "auditor_fp_violation": 0.02574391076037618,
            "ave_precision_score": 0.7269444432656764,
            "fpr": 0.1877058177826564,
            "logloss": 1.156635570758437,
            "mae": 0.28361866076305925,
            "precision": 0.7005253940455342,
            "recall": 0.8565310492505354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 31658,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5527725608493494,
            "auditor_fn_violation": 0.009201970532079693,
            "auditor_fp_violation": 0.009055727554179577,
            "ave_precision_score": 0.5490797869773683,
            "fpr": 0.2949561403508772,
            "logloss": 2.1628304776242895,
            "mae": 0.45093343289900395,
            "precision": 0.5661290322580645,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.543356591464626,
            "auditor_fn_violation": 0.009568984361961946,
            "auditor_fp_violation": 0.018136687730540647,
            "ave_precision_score": 0.537675759005989,
            "fpr": 0.31174533479692645,
            "logloss": 2.3488580679300854,
            "mae": 0.45380762475863795,
            "precision": 0.55625,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5526700846878623,
            "auditor_fn_violation": 0.009201970532079693,
            "auditor_fp_violation": 0.009662022703818367,
            "ave_precision_score": 0.5488634299680893,
            "fpr": 0.29385964912280704,
            "logloss": 2.165610492806424,
            "mae": 0.45092031796651244,
            "precision": 0.567043618739903,
            "recall": 0.7207392197125256
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5429126919281299,
            "auditor_fn_violation": 0.009568984361961946,
            "auditor_fp_violation": 0.018136687730540647,
            "ave_precision_score": 0.5369786804353902,
            "fpr": 0.31174533479692645,
            "logloss": 2.3713209386297907,
            "mae": 0.45377757327548246,
            "precision": 0.55625,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7570275401294614,
            "auditor_fn_violation": 0.012905724269606261,
            "auditor_fp_violation": 0.018949948400412798,
            "ave_precision_score": 0.7171852628036847,
            "fpr": 0.11513157894736842,
            "logloss": 0.6430663324750389,
            "mae": 0.3986674219762024,
            "precision": 0.7457627118644068,
            "recall": 0.6324435318275154
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7646914024046734,
            "auditor_fn_violation": 0.013893949045334565,
            "auditor_fp_violation": 0.013575320655452392,
            "ave_precision_score": 0.719805943308427,
            "fpr": 0.13062568605927552,
            "logloss": 0.6519486988403099,
            "mae": 0.3948784382721464,
            "precision": 0.7295454545454545,
            "recall": 0.6873661670235546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6981673594025932,
            "auditor_fn_violation": 0.01307233689974423,
            "auditor_fp_violation": 0.025534055727554187,
            "ave_precision_score": 0.6970378524971005,
            "fpr": 0.17324561403508773,
            "logloss": 1.2862879059918515,
            "mae": 0.31072226123136826,
            "precision": 0.7090239410681399,
            "recall": 0.7905544147843943
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7125535357507158,
            "auditor_fn_violation": 0.008861476552345001,
            "auditor_fp_violation": 0.0241196190702228,
            "ave_precision_score": 0.7116708693547475,
            "fpr": 0.18660812294182216,
            "logloss": 1.2079640808211098,
            "mae": 0.30460811582943476,
            "precision": 0.6897810218978102,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7459503547639398,
            "auditor_fn_violation": 0.0114332288627112,
            "auditor_fp_violation": 0.016973684210526318,
            "ave_precision_score": 0.691175777170594,
            "fpr": 0.1118421052631579,
            "logloss": 0.6442791061051525,
            "mae": 0.40540065908837214,
            "precision": 0.7475247524752475,
            "recall": 0.6201232032854209
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7264517592705416,
            "auditor_fn_violation": 0.012791553155931437,
            "auditor_fp_violation": 0.013575320655452392,
            "ave_precision_score": 0.6689322237385824,
            "fpr": 0.13062568605927552,
            "logloss": 0.6606306729391441,
            "mae": 0.40645831425875656,
            "precision": 0.7238979118329466,
            "recall": 0.6680942184154176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6773580858135602,
            "auditor_fn_violation": 0.04496289491696386,
            "auditor_fp_violation": 0.03464912280701755,
            "ave_precision_score": 0.6760822152298424,
            "fpr": 0.15460526315789475,
            "logloss": 1.712676714314194,
            "mae": 0.3422610119456714,
            "precision": 0.7,
            "recall": 0.675564681724846
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7009723353785089,
            "auditor_fn_violation": 0.0462089569078383,
            "auditor_fp_violation": 0.0356404703276273,
            "ave_precision_score": 0.6997653036435629,
            "fpr": 0.14270032930845225,
            "logloss": 1.785200151081432,
            "mae": 0.32006266740962835,
            "precision": 0.7117516629711752,
            "recall": 0.6873661670235546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6500432115045622,
            "auditor_fn_violation": 0.01205014589862748,
            "auditor_fp_violation": 0.03200980392156864,
            "ave_precision_score": 0.6512649067763776,
            "fpr": 0.16557017543859648,
            "logloss": 1.388567723285411,
            "mae": 0.3771346345433573,
            "precision": 0.6905737704918032,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7025531140225441,
            "auditor_fn_violation": 0.0029969184626631026,
            "auditor_fp_violation": 0.03698044916486191,
            "ave_precision_score": 0.70267104183608,
            "fpr": 0.1602634467618002,
            "logloss": 1.1168262617413487,
            "mae": 0.3350005802344232,
            "precision": 0.7142857142857143,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5046060876498225,
            "auditor_fn_violation": 1.350913217335e-05,
            "auditor_fp_violation": 0.00517285861713108,
            "ave_precision_score": 0.5429417459706889,
            "fpr": 0.42543859649122806,
            "logloss": 0.9586273694068789,
            "mae": 0.5007460433009424,
            "precision": 0.5467289719626168,
            "recall": 0.9609856262833676
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5983733570291015,
            "auditor_fn_violation": 0.0023646274301482952,
            "auditor_fp_violation": 0.0026107336754976765,
            "ave_precision_score": 0.5390122284340416,
            "fpr": 0.4500548847420417,
            "logloss": 0.9194994351228555,
            "mae": 0.4881782984498042,
            "precision": 0.5221445221445221,
            "recall": 0.9593147751605996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5536593086926762,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5469244454705926,
            "fpr": 0.46600877192982454,
            "logloss": 0.8157945000592124,
            "mae": 0.48330518263473843,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6219000876542888,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5462019943332802,
            "fpr": 0.48737650933040616,
            "logloss": 0.801814407401764,
            "mae": 0.48591951782172127,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5396608480495954,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.538422809961885,
            "fpr": 0.46600877192982454,
            "logloss": 0.8173703410764045,
            "mae": 0.4831782434985303,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5820714465030093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5475682473756892,
            "fpr": 0.48737650933040616,
            "logloss": 0.8035165955221627,
            "mae": 0.4858966696798867,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5270523462196319,
            "auditor_fn_violation": 0.0009298785979322022,
            "auditor_fp_violation": 0.0020252837977296303,
            "ave_precision_score": 0.5304963866482723,
            "fpr": 0.4605263157894737,
            "logloss": 0.6913544464286036,
            "mae": 0.49850039422642767,
            "precision": 0.5353982300884956,
            "recall": 0.9938398357289527
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.506948602911274,
            "auditor_fn_violation": 0.0021248739531352467,
            "auditor_fp_violation": 0.0026453456749834523,
            "ave_precision_score": 0.5098761279327733,
            "fpr": 0.47530186608122943,
            "logloss": 0.6918572736455508,
            "mae": 0.49871286072662974,
            "precision": 0.5167410714285714,
            "recall": 0.9914346895074947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6784953613503785,
            "auditor_fn_violation": 0.04516102885550633,
            "auditor_fp_violation": 0.03460010319917441,
            "ave_precision_score": 0.6771667052641619,
            "fpr": 0.15021929824561403,
            "logloss": 1.7009169556539394,
            "mae": 0.3409198483365533,
            "precision": 0.7041036717062635,
            "recall": 0.6694045174537988
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7068985010571833,
            "auditor_fn_violation": 0.04494202431852425,
            "auditor_fp_violation": 0.03245616637493696,
            "ave_precision_score": 0.7050944454845338,
            "fpr": 0.13611416026344675,
            "logloss": 1.739016311261338,
            "mae": 0.3186607750072383,
            "precision": 0.7188208616780045,
            "recall": 0.6788008565310493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.697563845633906,
            "auditor_fn_violation": 0.008461219784574375,
            "auditor_fp_violation": 0.02272445820433436,
            "ave_precision_score": 0.696267948338058,
            "fpr": 0.17763157894736842,
            "logloss": 1.370023024519245,
            "mae": 0.30963401356964887,
            "precision": 0.705989110707804,
            "recall": 0.7987679671457906
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7074164926006083,
            "auditor_fn_violation": 0.010788906465587155,
            "auditor_fp_violation": 0.021716557391639718,
            "ave_precision_score": 0.7063849427991885,
            "fpr": 0.18880351262349068,
            "logloss": 1.3222791281512327,
            "mae": 0.3081893888205301,
            "precision": 0.6884057971014492,
            "recall": 0.8137044967880086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.628850494723941,
            "auditor_fn_violation": 0.052154256277243426,
            "auditor_fp_violation": 0.029099587203302378,
            "ave_precision_score": 0.6078530615895765,
            "fpr": 0.19407894736842105,
            "logloss": 3.270723358608381,
            "mae": 0.3754928846998779,
            "precision": 0.6536203522504892,
            "recall": 0.6858316221765913
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6423013039877709,
            "auditor_fn_violation": 0.05115446000230352,
            "auditor_fp_violation": 0.031828205812838094,
            "ave_precision_score": 0.6185893578398827,
            "fpr": 0.18660812294182216,
            "logloss": 3.3958162615790553,
            "mae": 0.3526033457391108,
            "precision": 0.6586345381526104,
            "recall": 0.702355460385439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 31658,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6784572417236681,
            "auditor_fn_violation": 0.018570553694297345,
            "auditor_fp_violation": 0.027427760577915378,
            "ave_precision_score": 0.6788011236451313,
            "fpr": 0.19517543859649122,
            "logloss": 1.7812119614645976,
            "mae": 0.3369062680982635,
            "precision": 0.677536231884058,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7188461731178959,
            "auditor_fn_violation": 0.013212297002846485,
            "auditor_fp_violation": 0.033390690361052605,
            "ave_precision_score": 0.718795386118256,
            "fpr": 0.19209659714599342,
            "logloss": 1.3090029317337601,
            "mae": 0.308023487025982,
            "precision": 0.6818181818181818,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6793951860664837,
            "auditor_fn_violation": 0.0442896898303253,
            "auditor_fp_violation": 0.03274767801857586,
            "ave_precision_score": 0.6780519707776735,
            "fpr": 0.15570175438596492,
            "logloss": 1.6848278558831193,
            "mae": 0.34266296452175377,
            "precision": 0.6991525423728814,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7098033964027154,
            "auditor_fn_violation": 0.04527344824263053,
            "auditor_fp_violation": 0.03772955172516095,
            "ave_precision_score": 0.7080041232083262,
            "fpr": 0.1394072447859495,
            "logloss": 1.7231257450858573,
            "mae": 0.31775313672293876,
            "precision": 0.7171492204899778,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6744486435053428,
            "auditor_fn_violation": 0.03965380597283764,
            "auditor_fp_violation": 0.030472136222910215,
            "ave_precision_score": 0.6730803604103255,
            "fpr": 0.1600877192982456,
            "logloss": 1.731673389208242,
            "mae": 0.34043031048128103,
            "precision": 0.694560669456067,
            "recall": 0.6817248459958932
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7045896313554463,
            "auditor_fn_violation": 0.04417575340179628,
            "auditor_fp_violation": 0.035660248613047736,
            "ave_precision_score": 0.7027837998848028,
            "fpr": 0.14818880351262348,
            "logloss": 1.740125947284793,
            "mae": 0.31689223593457333,
            "precision": 0.7045951859956237,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.5658316118042855,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005753353973168292,
            "ave_precision_score": 0.5676019221030313,
            "fpr": 0.4649122807017544,
            "logloss": 0.7877802553111527,
            "mae": 0.4847860130105625,
            "precision": 0.5345773874862788,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5819006442330256,
            "auditor_fn_violation": 0.0005171153425771619,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5836866225218846,
            "fpr": 0.48737650933040616,
            "logloss": 0.7742937780452109,
            "mae": 0.48601109751231325,
            "precision": 0.512087912087912,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 31658,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5080510755476126,
            "auditor_fn_violation": 0.006144403616844989,
            "auditor_fp_violation": 0.006578947368421057,
            "ave_precision_score": 0.5095933635300942,
            "fpr": 0.41118421052631576,
            "logloss": 0.8837087566267599,
            "mae": 0.4841322244105928,
            "precision": 0.5300751879699248,
            "recall": 0.8685831622176592
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5411009357732086,
            "auditor_fn_violation": 0.00946321076916206,
            "auditor_fp_violation": 0.008751891298543327,
            "ave_precision_score": 0.5423552743318322,
            "fpr": 0.4039517014270033,
            "logloss": 0.8886904594214793,
            "mae": 0.4851589182931637,
            "precision": 0.5282051282051282,
            "recall": 0.8822269807280514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6972920772297718,
            "auditor_fn_violation": 0.0033502647789905994,
            "auditor_fp_violation": 0.028351393188854497,
            "ave_precision_score": 0.6967533479310272,
            "fpr": 0.16666666666666666,
            "logloss": 1.486856697347246,
            "mae": 0.3152186984714273,
            "precision": 0.7115749525616698,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.727001812823066,
            "auditor_fn_violation": 0.008574712589643119,
            "auditor_fp_violation": 0.02226787709773441,
            "ave_precision_score": 0.7267566132509222,
            "fpr": 0.17892425905598244,
            "logloss": 1.2554231778660894,
            "mae": 0.29456402005533444,
            "precision": 0.7030965391621129,
            "recall": 0.8265524625267666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.741458948597912,
            "auditor_fn_violation": 0.04606839223314962,
            "auditor_fp_violation": 0.020755933952528387,
            "ave_precision_score": 0.7402705066061122,
            "fpr": 0.12171052631578948,
            "logloss": 1.4024888944202254,
            "mae": 0.3288662022380386,
            "precision": 0.7394366197183099,
            "recall": 0.6468172484599589
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.754102048670545,
            "auditor_fn_violation": 0.04496788008565311,
            "auditor_fp_violation": 0.016860988320922463,
            "ave_precision_score": 0.7542944200606758,
            "fpr": 0.10428100987925357,
            "logloss": 1.5966670244591468,
            "mae": 0.3054730492548948,
            "precision": 0.7648514851485149,
            "recall": 0.6616702355460385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 31658,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.49727037981400307,
            "auditor_fn_violation": 0.03838169602651393,
            "auditor_fp_violation": 0.027631578947368424,
            "ave_precision_score": 0.49799294899256075,
            "fpr": 0.3541666666666667,
            "logloss": 1.1655411594881406,
            "mae": 0.504042159275789,
            "precision": 0.522189349112426,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5120388437579122,
            "auditor_fn_violation": 0.0375167181039731,
            "auditor_fp_violation": 0.030305277835464467,
            "ave_precision_score": 0.512694489096056,
            "fpr": 0.3578485181119649,
            "logloss": 0.9838202135073375,
            "mae": 0.5000064559485334,
            "precision": 0.5282199710564399,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6557911365987662,
            "auditor_fn_violation": 0.011075236860117445,
            "auditor_fp_violation": 0.005178018575851393,
            "ave_precision_score": 0.6571934854506489,
            "fpr": 0.2598684210526316,
            "logloss": 0.8500093478682792,
            "mae": 0.4345054621011705,
            "precision": 0.5878260869565217,
            "recall": 0.6940451745379876
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6434562701637178,
            "auditor_fn_violation": 0.006235940926623689,
            "auditor_fp_violation": 0.010027590708161511,
            "ave_precision_score": 0.6461925645283995,
            "fpr": 0.270032930845225,
            "logloss": 0.8632044419016874,
            "mae": 0.42888537280015887,
            "precision": 0.5802047781569966,
            "recall": 0.728051391862955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6882202635049979,
            "auditor_fn_violation": 0.016573453654670563,
            "auditor_fp_violation": 0.030724974200206395,
            "ave_precision_score": 0.6868811882206287,
            "fpr": 0.18201754385964913,
            "logloss": 1.371509945383823,
            "mae": 0.308898075976151,
            "precision": 0.7051509769094139,
            "recall": 0.8151950718685832
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7268651835188594,
            "auditor_fn_violation": 0.010492740405747505,
            "auditor_fp_violation": 0.02574391076037618,
            "ave_precision_score": 0.7255761736491622,
            "fpr": 0.1877058177826564,
            "logloss": 1.158189238599926,
            "mae": 0.2836928763153533,
            "precision": 0.7005253940455342,
            "recall": 0.8565310492505354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 31658,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.4972272361861527,
            "auditor_fn_violation": 0.03838169602651393,
            "auditor_fp_violation": 0.027631578947368424,
            "ave_precision_score": 0.49792637258969386,
            "fpr": 0.3541666666666667,
            "logloss": 1.1655487325000893,
            "mae": 0.5040425946445841,
            "precision": 0.522189349112426,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.5119919440213399,
            "auditor_fn_violation": 0.0375167181039731,
            "auditor_fp_violation": 0.02973417984394933,
            "ave_precision_score": 0.5126463391189,
            "fpr": 0.3567508232711306,
            "logloss": 0.9838222362729772,
            "mae": 0.500003959979498,
            "precision": 0.5289855072463768,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6795436418686092,
            "auditor_fn_violation": 0.043866403688893704,
            "auditor_fp_violation": 0.03318885448916409,
            "ave_precision_score": 0.6782183708860294,
            "fpr": 0.15460526315789475,
            "logloss": 1.6834802405781009,
            "mae": 0.3428307783386557,
            "precision": 0.7,
            "recall": 0.675564681724846
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7100498681859215,
            "auditor_fn_violation": 0.04527344824263053,
            "auditor_fp_violation": 0.03772955172516095,
            "ave_precision_score": 0.7082502135829476,
            "fpr": 0.1394072447859495,
            "logloss": 1.721114999244031,
            "mae": 0.31769770722666674,
            "precision": 0.7171492204899778,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6961142078900189,
            "auditor_fn_violation": 0.00788483014517814,
            "auditor_fp_violation": 0.025283797729618168,
            "ave_precision_score": 0.6974962199552391,
            "fpr": 0.20175438596491227,
            "logloss": 1.7115005171384845,
            "mae": 0.33439181892450565,
            "precision": 0.6743362831858407,
            "recall": 0.7823408624229979
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7161588007752206,
            "auditor_fn_violation": 0.007965926799972737,
            "auditor_fp_violation": 0.02756104073337882,
            "ave_precision_score": 0.7166259823109726,
            "fpr": 0.20417124039517015,
            "logloss": 1.363343548985904,
            "mae": 0.3160330590895311,
            "precision": 0.6736842105263158,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6812018554745285,
            "auditor_fn_violation": 0.042270074570409606,
            "auditor_fp_violation": 0.03318885448916409,
            "ave_precision_score": 0.6799304267668114,
            "fpr": 0.15460526315789475,
            "logloss": 1.6439653984943252,
            "mae": 0.3415452317748959,
            "precision": 0.7025316455696202,
            "recall": 0.6837782340862423
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7108929137534528,
            "auditor_fn_violation": 0.042572695839807065,
            "auditor_fp_violation": 0.03772955172516095,
            "ave_precision_score": 0.7096562480283943,
            "fpr": 0.1394072447859495,
            "logloss": 1.7061554813483786,
            "mae": 0.3163126259327711,
            "precision": 0.7196467991169978,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.695351593954489,
            "auditor_fn_violation": 0.013795075471018414,
            "auditor_fp_violation": 0.029066047471620237,
            "ave_precision_score": 0.6939679383678509,
            "fpr": 0.17434210526315788,
            "logloss": 1.3799354343864816,
            "mae": 0.30650694236036696,
            "precision": 0.7066420664206642,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7277275906804941,
            "auditor_fn_violation": 0.008264443384096824,
            "auditor_fp_violation": 0.025138200769375306,
            "ave_precision_score": 0.7264026232614167,
            "fpr": 0.1756311745334797,
            "logloss": 1.1663542667367839,
            "mae": 0.2837680143083163,
            "precision": 0.7101449275362319,
            "recall": 0.8394004282655246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6762295790988795,
            "auditor_fn_violation": 0.04456212399582118,
            "auditor_fp_violation": 0.03274767801857586,
            "ave_precision_score": 0.6749023963044224,
            "fpr": 0.15570175438596492,
            "logloss": 1.705656305985693,
            "mae": 0.3440597873382355,
            "precision": 0.6978723404255319,
            "recall": 0.6735112936344969
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7069533463594069,
            "auditor_fn_violation": 0.044681116122951225,
            "auditor_fp_violation": 0.03838965200106803,
            "ave_precision_score": 0.7051561058221214,
            "fpr": 0.14050493962678376,
            "logloss": 1.7304738322379576,
            "mae": 0.3183847692243345,
            "precision": 0.7161862527716186,
            "recall": 0.6916488222698073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.696072014594088,
            "auditor_fn_violation": 0.0033412586908750357,
            "auditor_fp_violation": 0.027982456140350876,
            "ave_precision_score": 0.69553428559638,
            "fpr": 0.16776315789473684,
            "logloss": 1.501086063216264,
            "mae": 0.31595446996013454,
            "precision": 0.7096774193548387,
            "recall": 0.7679671457905544
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7257665121286271,
            "auditor_fn_violation": 0.008428980084007744,
            "auditor_fp_violation": 0.023630106506067006,
            "ave_precision_score": 0.7254549433496658,
            "fpr": 0.17892425905598244,
            "logloss": 1.2652820000768688,
            "mae": 0.29471082458259495,
            "precision": 0.7009174311926606,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5046449961294956,
            "auditor_fn_violation": 1.350913217335e-05,
            "auditor_fp_violation": 0.00517285861713108,
            "ave_precision_score": 0.5429804748157655,
            "fpr": 0.42543859649122806,
            "logloss": 0.9583181438441568,
            "mae": 0.5007449885862961,
            "precision": 0.5467289719626168,
            "recall": 0.9609856262833676
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5983659431303554,
            "auditor_fn_violation": 0.0023646274301482952,
            "auditor_fp_violation": 0.0026107336754976765,
            "ave_precision_score": 0.539004689278135,
            "fpr": 0.4500548847420417,
            "logloss": 0.9196377318934531,
            "mae": 0.4882556054450809,
            "precision": 0.5221445221445221,
            "recall": 0.9593147751605996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 31658,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.685790399207794,
            "auditor_fn_violation": 0.013583432400302608,
            "auditor_fp_violation": 0.025531475748194025,
            "ave_precision_score": 0.6861663404925429,
            "fpr": 0.19846491228070176,
            "logloss": 1.787513031024564,
            "mae": 0.3372771492785179,
            "precision": 0.6691042047531993,
            "recall": 0.7515400410677618
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7228023377653385,
            "auditor_fn_violation": 0.01602117352275425,
            "auditor_fp_violation": 0.02458688106328062,
            "ave_precision_score": 0.7227300778608607,
            "fpr": 0.20087815587266739,
            "logloss": 1.3710468362626318,
            "mae": 0.3136449858628679,
            "precision": 0.6690777576853526,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6500540848224473,
            "auditor_fn_violation": 0.01205014589862748,
            "auditor_fp_violation": 0.03200980392156864,
            "ave_precision_score": 0.6512757592124756,
            "fpr": 0.16557017543859648,
            "logloss": 1.3885615604225525,
            "mae": 0.37713364532356264,
            "precision": 0.6905737704918032,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7025531216794403,
            "auditor_fn_violation": 0.0029969184626631026,
            "auditor_fp_violation": 0.03698044916486191,
            "ave_precision_score": 0.7026692424654462,
            "fpr": 0.1602634467618002,
            "logloss": 1.116825058416573,
            "mae": 0.3350002007845339,
            "precision": 0.7142857142857143,
            "recall": 0.7815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7570275401294614,
            "auditor_fn_violation": 0.000614665513887388,
            "auditor_fp_violation": 0.0036842105263157994,
            "ave_precision_score": 0.7171852628036847,
            "fpr": 0.4594298245614035,
            "logloss": 2.9275407381467007,
            "mae": 0.4601247900219485,
            "precision": 0.5370165745856353,
            "recall": 0.997946611909651
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7646914024046734,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002655234817693654,
            "ave_precision_score": 0.719805943308427,
            "fpr": 0.4807903402854007,
            "logloss": 3.08323012388439,
            "mae": 0.4802735298225384,
            "precision": 0.5160220994475138,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6485546664825699,
            "auditor_fn_violation": 0.012953006232212978,
            "auditor_fp_violation": 0.024331785345717245,
            "ave_precision_score": 0.6223569289050124,
            "fpr": 0.24013157894736842,
            "logloss": 3.0901267368347636,
            "mae": 0.33272372233491215,
            "precision": 0.6562009419152276,
            "recall": 0.8583162217659137
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6645709602073964,
            "auditor_fn_violation": 0.006264147218036985,
            "auditor_fp_violation": 0.018816566291868158,
            "ave_precision_score": 0.6377885511383719,
            "fpr": 0.24478594950603733,
            "logloss": 2.970980047596039,
            "mae": 0.3137790810117978,
            "precision": 0.6547987616099071,
            "recall": 0.9057815845824411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.761624401497882,
            "auditor_fn_violation": 0.017066536978997814,
            "auditor_fp_violation": 0.013975748194014453,
            "ave_precision_score": 0.714866618392271,
            "fpr": 0.12280701754385964,
            "logloss": 2.8540963625847513,
            "mae": 0.3751622904396515,
            "precision": 0.7234567901234568,
            "recall": 0.6016427104722792
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7470251227198479,
            "auditor_fn_violation": 0.012711635330260413,
            "auditor_fp_violation": 0.0117606629681273,
            "ave_precision_score": 0.6945161499356409,
            "fpr": 0.1437980241492865,
            "logloss": 3.1639763716080527,
            "mae": 0.38770934029664533,
            "precision": 0.6880952380952381,
            "recall": 0.6188436830835118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6482857607865224,
            "auditor_fn_violation": 0.014092276378832095,
            "auditor_fp_violation": 0.036803405572755424,
            "ave_precision_score": 0.6278531946510433,
            "fpr": 0.20065789473684212,
            "logloss": 2.777866852978789,
            "mae": 0.32679561832876,
            "precision": 0.682842287694974,
            "recall": 0.8090349075975359
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.6703388264881189,
            "auditor_fn_violation": 0.008849723930922792,
            "auditor_fp_violation": 0.031576032673727515,
            "ave_precision_score": 0.6517161881801846,
            "fpr": 0.20197585071350166,
            "logloss": 2.4021901810712287,
            "mae": 0.30269748276680936,
            "precision": 0.6838487972508591,
            "recall": 0.8522483940042827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6707004335695523,
            "auditor_fn_violation": 0.0442896898303253,
            "auditor_fp_violation": 0.03516769865841073,
            "ave_precision_score": 0.6692924302668453,
            "fpr": 0.1524122807017544,
            "logloss": 1.7808038558605337,
            "mae": 0.34268185748271407,
            "precision": 0.7036247334754797,
            "recall": 0.6776180698151951
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6972522497613165,
            "auditor_fn_violation": 0.04553435643820355,
            "auditor_fp_violation": 0.035979173465452284,
            "ave_precision_score": 0.6953429430322319,
            "fpr": 0.1437980241492865,
            "logloss": 1.7976512771012505,
            "mae": 0.32120834803027415,
            "precision": 0.7069351230425056,
            "recall": 0.6766595289079229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6956475913231592,
            "auditor_fn_violation": 0.018248586044165856,
            "auditor_fp_violation": 0.024078947368421054,
            "ave_precision_score": 0.6959590617879465,
            "fpr": 0.14912280701754385,
            "logloss": 1.693513223027204,
            "mae": 0.319011195631137,
            "precision": 0.720164609053498,
            "recall": 0.7186858316221766
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.720669430378448,
            "auditor_fn_violation": 0.022600290994906423,
            "auditor_fp_violation": 0.0351559023348266,
            "ave_precision_score": 0.7204553659110576,
            "fpr": 0.15367727771679474,
            "logloss": 1.5016144646155307,
            "mae": 0.30685013262118865,
            "precision": 0.7131147540983607,
            "recall": 0.7451820128479657
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6871189235266981,
            "auditor_fn_violation": 0.010996433589106238,
            "auditor_fp_violation": 0.026269349845201233,
            "ave_precision_score": 0.6867269741167916,
            "fpr": 0.20723684210526316,
            "logloss": 1.7994980233894615,
            "mae": 0.3307335500694531,
            "precision": 0.6695804195804196,
            "recall": 0.7864476386036962
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7023653464781323,
            "auditor_fn_violation": 0.008722795619562948,
            "auditor_fp_violation": 0.02673035274572047,
            "ave_precision_score": 0.7022104297370078,
            "fpr": 0.21295279912184412,
            "logloss": 1.4546713223539427,
            "mae": 0.31567055508854197,
            "precision": 0.6660929432013769,
            "recall": 0.828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6462924758771711,
            "auditor_fn_violation": 0.01707329154508448,
            "auditor_fp_violation": 0.024896800825593396,
            "ave_precision_score": 0.6205305658607576,
            "fpr": 0.24013157894736842,
            "logloss": 3.046612022729061,
            "mae": 0.3361957340050076,
            "precision": 0.6540284360189573,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6638580025437839,
            "auditor_fn_violation": 0.005871609662535228,
            "auditor_fp_violation": 0.0205793059799646,
            "ave_precision_score": 0.6376217491053285,
            "fpr": 0.2414928649835346,
            "logloss": 2.922396825404571,
            "mae": 0.312538130526005,
            "precision": 0.65625,
            "recall": 0.8993576017130621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7021282616228997,
            "auditor_fn_violation": 0.008816960265139239,
            "auditor_fp_violation": 0.021199690402476788,
            "ave_precision_score": 0.7008833520938984,
            "fpr": 0.1787280701754386,
            "logloss": 1.3361188338128873,
            "mae": 0.30746728149088803,
            "precision": 0.7057761732851986,
            "recall": 0.8028747433264887
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7127543236184709,
            "auditor_fn_violation": 0.009806387314690544,
            "auditor_fp_violation": 0.02130615796916566,
            "ave_precision_score": 0.7116100061226188,
            "fpr": 0.18990120746432493,
            "logloss": 1.2880354900998026,
            "mae": 0.30539216270936576,
            "precision": 0.6877256317689531,
            "recall": 0.815845824411135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 31658,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5521682445186685,
            "auditor_fn_violation": 0.01135667711372888,
            "auditor_fp_violation": 0.009256965944272461,
            "ave_precision_score": 0.5482756677928466,
            "fpr": 0.29385964912280704,
            "logloss": 2.2040257798458907,
            "mae": 0.45034002029659176,
            "precision": 0.5663430420711975,
            "recall": 0.7186858316221766
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5440398191279385,
            "auditor_fn_violation": 0.009568984361961946,
            "auditor_fp_violation": 0.018136687730540647,
            "ave_precision_score": 0.5381242469771322,
            "fpr": 0.31174533479692645,
            "logloss": 2.3878612781715884,
            "mae": 0.45274434434490557,
            "precision": 0.55625,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7030745961740688,
            "auditor_fn_violation": 0.0036069382902842325,
            "auditor_fp_violation": 0.01136222910216719,
            "ave_precision_score": 0.7009475703608488,
            "fpr": 0.4232456140350877,
            "logloss": 2.8790392919278758,
            "mae": 0.4291657552334795,
            "precision": 0.5506402793946449,
            "recall": 0.971252566735113
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7315065376957034,
            "auditor_fn_violation": 0.003309538192493836,
            "auditor_fp_violation": 0.015211973773993534,
            "ave_precision_score": 0.7283080017810971,
            "fpr": 0.424807903402854,
            "logloss": 2.8965387343993054,
            "mae": 0.4294698348974472,
            "precision": 0.5425531914893617,
            "recall": 0.9828693790149893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6676528410076632,
            "auditor_fn_violation": 0.015247307179653447,
            "auditor_fp_violation": 0.026929824561403505,
            "ave_precision_score": 0.6670328818820521,
            "fpr": 0.2050438596491228,
            "logloss": 2.0126410685758023,
            "mae": 0.34285635827423105,
            "precision": 0.6624548736462094,
            "recall": 0.7535934291581109
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6978987144395554,
            "auditor_fn_violation": 0.01602117352275425,
            "auditor_fp_violation": 0.022349462525093698,
            "ave_precision_score": 0.6973362135013506,
            "fpr": 0.20636663007683864,
            "logloss": 1.5958737229205497,
            "mae": 0.3190027834831645,
            "precision": 0.6630824372759857,
            "recall": 0.7922912205567452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6511794025596125,
            "auditor_fn_violation": 0.014688929716488348,
            "auditor_fp_violation": 0.025846233230134165,
            "ave_precision_score": 0.6256558517515922,
            "fpr": 0.23903508771929824,
            "logloss": 3.0082210454964273,
            "mae": 0.3310200737018662,
            "precision": 0.655608214849921,
            "recall": 0.8521560574948666
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6658292689431794,
            "auditor_fn_violation": 0.005521381544153425,
            "auditor_fp_violation": 0.020448274839054204,
            "ave_precision_score": 0.6400197388729434,
            "fpr": 0.24039517014270034,
            "logloss": 2.922682301638408,
            "mae": 0.31169753783953547,
            "precision": 0.6583463338533542,
            "recall": 0.9036402569593148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6612565993352253,
            "auditor_fn_violation": 0.041621636226088846,
            "auditor_fp_violation": 0.034525283797729615,
            "ave_precision_score": 0.6601886206146185,
            "fpr": 0.14583333333333334,
            "logloss": 3.0942083944586374,
            "mae": 0.35826556810552074,
            "precision": 0.6984126984126984,
            "recall": 0.6324435318275154
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6861879402368761,
            "auditor_fn_violation": 0.0451653241255462,
            "auditor_fp_violation": 0.034557609200858375,
            "ave_precision_score": 0.6844925767433303,
            "fpr": 0.1437980241492865,
            "logloss": 2.789978363254,
            "mae": 0.3359319635454573,
            "precision": 0.6981566820276498,
            "recall": 0.6488222698072805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.681606267237172,
            "auditor_fn_violation": 0.010595662667963548,
            "auditor_fp_violation": 0.024953560371517032,
            "ave_precision_score": 0.6811125284953513,
            "fpr": 0.19517543859649122,
            "logloss": 1.7968046546038088,
            "mae": 0.3314638162869645,
            "precision": 0.6804308797127468,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7011437323092682,
            "auditor_fn_violation": 0.0157414611329057,
            "auditor_fp_violation": 0.025691992761147545,
            "ave_precision_score": 0.7009272091826522,
            "fpr": 0.20856201975850713,
            "logloss": 1.43088982055029,
            "mae": 0.31776430654089377,
            "precision": 0.6660808435852372,
            "recall": 0.8115631691648822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6725744126059405,
            "auditor_fn_violation": 0.04100697071220145,
            "auditor_fp_violation": 0.030815273477812183,
            "ave_precision_score": 0.6712090188434641,
            "fpr": 0.1600877192982456,
            "logloss": 1.750015875215659,
            "mae": 0.3412723873191339,
            "precision": 0.6970954356846473,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7030434179438769,
            "auditor_fn_violation": 0.04527344824263053,
            "auditor_fp_violation": 0.03475044748370765,
            "ave_precision_score": 0.7012500505728021,
            "fpr": 0.14709110867178923,
            "logloss": 1.7610561204867619,
            "mae": 0.31812719333513156,
            "precision": 0.706140350877193,
            "recall": 0.6895074946466809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6811840716953937,
            "auditor_fn_violation": 0.04097094635973919,
            "auditor_fp_violation": 0.03318885448916409,
            "ave_precision_score": 0.679910848243063,
            "fpr": 0.15460526315789475,
            "logloss": 1.6422566477662859,
            "mae": 0.3412228451086117,
            "precision": 0.7031578947368421,
            "recall": 0.6858316221765913
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7107239932603442,
            "auditor_fn_violation": 0.042572695839807065,
            "auditor_fp_violation": 0.037291957160233785,
            "ave_precision_score": 0.7094814940798911,
            "fpr": 0.14050493962678376,
            "logloss": 1.7031476753090156,
            "mae": 0.3159903289416599,
            "precision": 0.7180616740088106,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.652437199316561,
            "auditor_fn_violation": 0.012221261572823229,
            "auditor_fp_violation": 0.03331269349845201,
            "ave_precision_score": 0.6536546378144517,
            "fpr": 0.16228070175438597,
            "logloss": 1.2981653934199102,
            "mae": 0.3757270385180348,
            "precision": 0.6948453608247422,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.704403780179499,
            "auditor_fn_violation": 0.0038736640207598337,
            "auditor_fp_violation": 0.03773944086787117,
            "ave_precision_score": 0.704513513039364,
            "fpr": 0.15916575192096596,
            "logloss": 1.0839400567394255,
            "mae": 0.33394292837031836,
            "precision": 0.716796875,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6989343081421707,
            "auditor_fn_violation": 0.008332883028927556,
            "auditor_fp_violation": 0.023929308565531476,
            "ave_precision_score": 0.7003723006785773,
            "fpr": 0.19188596491228072,
            "logloss": 1.6652802374217097,
            "mae": 0.3278196794105554,
            "precision": 0.6823956442831216,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7232518500699952,
            "auditor_fn_violation": 0.011914807597834703,
            "auditor_fp_violation": 0.02508875505582422,
            "ave_precision_score": 0.7237316390511938,
            "fpr": 0.19978046103183314,
            "logloss": 1.3068627291745885,
            "mae": 0.31025943604497747,
            "precision": 0.6773049645390071,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6500540848224473,
            "auditor_fn_violation": 0.01205014589862748,
            "auditor_fp_violation": 0.03200980392156864,
            "ave_precision_score": 0.6512757592124756,
            "fpr": 0.16557017543859648,
            "logloss": 1.3885601694158225,
            "mae": 0.37713338425148096,
            "precision": 0.6905737704918032,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7025531216794403,
            "auditor_fn_violation": 0.0029969184626631026,
            "auditor_fp_violation": 0.03698044916486191,
            "ave_precision_score": 0.7026692424654462,
            "fpr": 0.1602634467618002,
            "logloss": 1.1168247109859266,
            "mae": 0.33500010243493267,
            "precision": 0.7142857142857143,
            "recall": 0.7815845824411135
        }
    }
]