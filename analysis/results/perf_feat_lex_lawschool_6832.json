[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8359943708464874,
            "auditor_fn_violation": 0.02030232814741256,
            "auditor_fp_violation": 0.012500000000000004,
            "ave_precision_score": 0.8364906712500996,
            "fpr": 0.11951754385964912,
            "logloss": 0.6971133863482496,
            "mae": 0.26211110807143595,
            "precision": 0.7775510204081633,
            "recall": 0.7987421383647799
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8488895731002954,
            "auditor_fn_violation": 0.01374304735736296,
            "auditor_fp_violation": 0.014947872141314312,
            "ave_precision_score": 0.849121777590688,
            "fpr": 0.14270032930845225,
            "logloss": 0.673684274662853,
            "mae": 0.26267189375217503,
            "precision": 0.749034749034749,
            "recall": 0.8134171907756813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.5208816483552203,
            "auditor_fn_violation": 0.003880245687594249,
            "auditor_fp_violation": 0.014556866303690267,
            "ave_precision_score": 0.5135588941466895,
            "fpr": 0.2719298245614035,
            "logloss": 4.116212708484927,
            "mae": 0.438393115573117,
            "precision": 0.5947712418300654,
            "recall": 0.7631027253668763
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5000988265877826,
            "auditor_fn_violation": 0.00912214328944855,
            "auditor_fp_violation": 0.008285825572748848,
            "ave_precision_score": 0.49428039627954756,
            "fpr": 0.29198682766191,
            "logloss": 4.31678229335001,
            "mae": 0.44996344312690545,
            "precision": 0.5757575757575758,
            "recall": 0.7568134171907757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6263103139855444,
            "auditor_fn_violation": 0.0030550038618558945,
            "auditor_fp_violation": 0.01947721314781206,
            "ave_precision_score": 0.6192116658532073,
            "fpr": 0.08662280701754387,
            "logloss": 1.962534119095471,
            "mae": 0.42540327678546563,
            "precision": 0.7256944444444444,
            "recall": 0.4381551362683438
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6497735440110946,
            "auditor_fn_violation": 0.013772963568958027,
            "auditor_fp_violation": 0.012780304218284464,
            "ave_precision_score": 0.6397704212235282,
            "fpr": 0.07793633369923161,
            "logloss": 1.9141073047832702,
            "mae": 0.4128765201162418,
            "precision": 0.7446043165467626,
            "recall": 0.4339622641509434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.748624368661998,
            "auditor_fn_violation": 0.011732686012725736,
            "auditor_fp_violation": 0.02402198023795121,
            "ave_precision_score": 0.7220524511252842,
            "fpr": 0.19188596491228072,
            "logloss": 1.9686334416492965,
            "mae": 0.34056312450934856,
            "precision": 0.6961805555555556,
            "recall": 0.8406708595387841
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7887178950603793,
            "auditor_fn_violation": 0.003900613742587112,
            "auditor_fp_violation": 0.012916883760692407,
            "ave_precision_score": 0.7614764077988037,
            "fpr": 0.17892425905598244,
            "logloss": 1.8128346127523844,
            "mae": 0.319419607740922,
            "precision": 0.7189655172413794,
            "recall": 0.8742138364779874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7204799022976023,
            "auditor_fn_violation": 0.012495862297252568,
            "auditor_fp_violation": 0.019804900181488203,
            "ave_precision_score": 0.6981440818871516,
            "fpr": 0.15789473684210525,
            "logloss": 2.296169318379188,
            "mae": 0.3015963329834775,
            "precision": 0.7170923379174853,
            "recall": 0.7651991614255765
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7289000774183623,
            "auditor_fn_violation": 0.00838114174070929,
            "auditor_fp_violation": 0.017289958368532074,
            "ave_precision_score": 0.706145194623354,
            "fpr": 0.1712403951701427,
            "logloss": 2.3094321771847692,
            "mae": 0.3004262873825684,
            "precision": 0.7045454545454546,
            "recall": 0.779874213836478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8667159130768246,
            "auditor_fn_violation": 0.011955662216337492,
            "auditor_fp_violation": 0.002142569066344025,
            "ave_precision_score": 0.8674033931456303,
            "fpr": 0.12390350877192982,
            "logloss": 0.4985721549198557,
            "mae": 0.2687836538563971,
            "precision": 0.7730923694779116,
            "recall": 0.8071278825995807
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8828838539172931,
            "auditor_fn_violation": 0.017784037169742285,
            "auditor_fp_violation": 0.011052825931902453,
            "ave_precision_score": 0.883051962228792,
            "fpr": 0.1163556531284303,
            "logloss": 0.4854643958719757,
            "mae": 0.26363234398653984,
            "precision": 0.7836734693877551,
            "recall": 0.8050314465408805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7977069607585294,
            "auditor_fn_violation": 0.020704604803413143,
            "auditor_fp_violation": 0.013510788465416422,
            "ave_precision_score": 0.7829777282453159,
            "fpr": 0.13267543859649122,
            "logloss": 2.3848204314231762,
            "mae": 0.2713692422898098,
            "precision": 0.7520491803278688,
            "recall": 0.7693920335429769
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7933559545751748,
            "auditor_fn_violation": 0.011653515039800067,
            "auditor_fp_violation": 0.016475539615655056,
            "ave_precision_score": 0.7782886217540548,
            "fpr": 0.14489571899012074,
            "logloss": 2.2855833158716723,
            "mae": 0.27806358000410514,
            "precision": 0.7426900584795322,
            "recall": 0.7987421383647799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.869547337654349,
            "auditor_fn_violation": 0.01961041229909155,
            "auditor_fp_violation": 0.010087719298245614,
            "ave_precision_score": 0.8698702048737201,
            "fpr": 0.05921052631578947,
            "logloss": 0.7696336363811676,
            "mae": 0.27700081590971914,
            "precision": 0.8575197889182058,
            "recall": 0.6813417190775681
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8751590268237365,
            "auditor_fn_violation": 0.017784037169742292,
            "auditor_fp_violation": 0.008928255272223264,
            "ave_precision_score": 0.8753655170521102,
            "fpr": 0.06366630076838639,
            "logloss": 0.621496660712346,
            "mae": 0.27870307732522986,
            "precision": 0.8485639686684073,
            "recall": 0.6813417190775681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.640628319416875,
            "auditor_fn_violation": 0.009130530729339078,
            "auditor_fp_violation": 0.009182798951401498,
            "ave_precision_score": 0.6425137290113584,
            "fpr": 0.13267543859649122,
            "logloss": 3.455600727454566,
            "mae": 0.40884352941363544,
            "precision": 0.672972972972973,
            "recall": 0.5220125786163522
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.604836017026841,
            "auditor_fn_violation": 0.0099091697791033,
            "auditor_fp_violation": 0.006629166308356141,
            "ave_precision_score": 0.6058640272327998,
            "fpr": 0.141602634467618,
            "logloss": 3.6950428863567826,
            "mae": 0.4297688051108206,
            "precision": 0.6578249336870027,
            "recall": 0.519916142557652
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7563533050802242,
            "auditor_fn_violation": 0.018107046967523632,
            "auditor_fp_violation": 0.02535541439806413,
            "ave_precision_score": 0.7173222545753986,
            "fpr": 0.13815789473684212,
            "logloss": 3.9224619408774104,
            "mae": 0.29039908586054775,
            "precision": 0.7418032786885246,
            "recall": 0.7589098532494759
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7611973484506562,
            "auditor_fn_violation": 0.008512312822318414,
            "auditor_fp_violation": 0.01967757110988583,
            "ave_precision_score": 0.717331578662141,
            "fpr": 0.16465422612513722,
            "logloss": 4.065795750633828,
            "mae": 0.28849695881219256,
            "precision": 0.7159090909090909,
            "recall": 0.7924528301886793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 6832,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7523232256934065,
            "auditor_fn_violation": 0.020412666887344146,
            "auditor_fp_violation": 0.020820729985884256,
            "ave_precision_score": 0.7222033527394932,
            "fpr": 0.16557017543859648,
            "logloss": 3.106067182538909,
            "mae": 0.2826027581140668,
            "precision": 0.7172284644194756,
            "recall": 0.8029350104821803
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.75962243518252,
            "auditor_fn_violation": 0.004800401337484785,
            "auditor_fp_violation": 0.01913884069261004,
            "ave_precision_score": 0.7306355177097159,
            "fpr": 0.17672886937431395,
            "logloss": 2.9430074196554705,
            "mae": 0.2844859880459044,
            "precision": 0.7119856887298748,
            "recall": 0.8343815513626834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7938316757101805,
            "auditor_fn_violation": 0.016024403251314868,
            "auditor_fp_violation": 0.014834139947570078,
            "ave_precision_score": 0.7685241797224905,
            "fpr": 0.13925438596491227,
            "logloss": 3.187683744331407,
            "mae": 0.2807112310645702,
            "precision": 0.7381443298969073,
            "recall": 0.750524109014675
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7886106396807715,
            "auditor_fn_violation": 0.016465422612513728,
            "auditor_fp_violation": 0.022050008346527594,
            "ave_precision_score": 0.7579202763063756,
            "fpr": 0.1525795828759605,
            "logloss": 3.4688517328056734,
            "mae": 0.2885309603686623,
            "precision": 0.7274509803921568,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8405952102376973,
            "auditor_fn_violation": 0.01620140497995513,
            "auditor_fp_violation": 0.007221718088324259,
            "ave_precision_score": 0.8411567499460142,
            "fpr": 0.10087719298245613,
            "logloss": 0.6892573310353562,
            "mae": 0.27128869905433856,
            "precision": 0.7927927927927928,
            "recall": 0.7379454926624738
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8534547129435723,
            "auditor_fn_violation": 0.01485685092751762,
            "auditor_fp_violation": 0.013501140692104185,
            "ave_precision_score": 0.8536679335868833,
            "fpr": 0.11855104281009879,
            "logloss": 0.638161755793102,
            "mae": 0.27160941443908326,
            "precision": 0.7721518987341772,
            "recall": 0.7672955974842768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8277874341070776,
            "auditor_fn_violation": 0.017350766854242524,
            "auditor_fp_violation": 0.016636418632788873,
            "ave_precision_score": 0.8281318945399421,
            "fpr": 0.11293859649122807,
            "logloss": 0.7586559600571123,
            "mae": 0.2715694465221737,
            "precision": 0.7780172413793104,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8338985042487271,
            "auditor_fn_violation": 0.014166476813785396,
            "auditor_fp_violation": 0.015651003859636702,
            "ave_precision_score": 0.8341494507638559,
            "fpr": 0.1394072447859495,
            "logloss": 0.7368859226149085,
            "mae": 0.27425031596932525,
            "precision": 0.7465069860279441,
            "recall": 0.7840670859538784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6714496304592195,
            "auditor_fn_violation": 0.017888668211409022,
            "auditor_fp_violation": 0.03710425489009882,
            "ave_precision_score": 0.6508542808158565,
            "fpr": 0.1699561403508772,
            "logloss": 2.6045048642643813,
            "mae": 0.3106345283786759,
            "precision": 0.7075471698113207,
            "recall": 0.7861635220125787
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.676129525939707,
            "auditor_fn_violation": 0.0025612879619465847,
            "auditor_fp_violation": 0.033289998836544654,
            "ave_precision_score": 0.6562563295380687,
            "fpr": 0.18660812294182216,
            "logloss": 2.4899236324433995,
            "mae": 0.30819898696204184,
            "precision": 0.6958855098389982,
            "recall": 0.8155136268343816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8039284329945965,
            "auditor_fn_violation": 0.01768867924528302,
            "auditor_fp_violation": 0.010448175035289376,
            "ave_precision_score": 0.8005119687045382,
            "fpr": 0.10087719298245613,
            "logloss": 0.9726395848710614,
            "mae": 0.272016677222002,
            "precision": 0.7880184331797235,
            "recall": 0.7169811320754716
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8043387126637319,
            "auditor_fn_violation": 0.009207289430142197,
            "auditor_fp_violation": 0.013597252221946817,
            "ave_precision_score": 0.7999887816411309,
            "fpr": 0.11525795828759605,
            "logloss": 0.9918605272182516,
            "mae": 0.2749059092418877,
            "precision": 0.7737068965517241,
            "recall": 0.7526205450733753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.4520666885377926,
            "auditor_fn_violation": 0.01730479237927103,
            "auditor_fp_violation": 0.009762552934059286,
            "ave_precision_score": 0.4302016224759412,
            "fpr": 0.28728070175438597,
            "logloss": 8.395917603984786,
            "mae": 0.5513327026794451,
            "precision": 0.5,
            "recall": 0.549266247379455
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0.446099165885423,
            "auditor_fn_violation": 0.01390183340352137,
            "auditor_fp_violation": 0.022925129118252594,
            "ave_precision_score": 0.42203946871957065,
            "fpr": 0.29308452250274425,
            "logloss": 9.42024847991611,
            "mae": 0.561475288589695,
            "precision": 0.48455598455598453,
            "recall": 0.5262054507337526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8290938190311777,
            "auditor_fn_violation": 0.015895674721394686,
            "auditor_fp_violation": 0.012709215567654772,
            "ave_precision_score": 0.8295083194948899,
            "fpr": 0.14912280701754385,
            "logloss": 0.7149408050428464,
            "mae": 0.27343884719419514,
            "precision": 0.7429111531190926,
            "recall": 0.8238993710691824
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.834512092918218,
            "auditor_fn_violation": 0.014444927706324056,
            "auditor_fp_violation": 0.02184766828370101,
            "ave_precision_score": 0.8347609511324989,
            "fpr": 0.1734357848518112,
            "logloss": 0.7326002830908361,
            "mae": 0.2785523946886789,
            "precision": 0.7137681159420289,
            "recall": 0.8259958071278826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8229474323900714,
            "auditor_fn_violation": 0.016840450182058923,
            "auditor_fp_violation": 0.013455333736640453,
            "ave_precision_score": 0.823302614688939,
            "fpr": 0.14583333333333334,
            "logloss": 0.7526237700520649,
            "mae": 0.2701037656712416,
            "precision": 0.7442307692307693,
            "recall": 0.8113207547169812
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8257945637149753,
            "auditor_fn_violation": 0.011681130004349359,
            "auditor_fp_violation": 0.019404412025069935,
            "ave_precision_score": 0.8261176576849948,
            "fpr": 0.1690450054884742,
            "logloss": 0.7715084979870548,
            "mae": 0.2744257851814828,
            "precision": 0.7184643510054844,
            "recall": 0.8238993710691824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8306043526548492,
            "auditor_fn_violation": 0.01978051785648608,
            "auditor_fp_violation": 0.016144888082274655,
            "ave_precision_score": 0.8309814175462067,
            "fpr": 0.11732456140350878,
            "logloss": 0.7408690829209365,
            "mae": 0.2699336240169689,
            "precision": 0.7713675213675214,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8352221342258828,
            "auditor_fn_violation": 0.015261870407573869,
            "auditor_fp_violation": 0.0193386515046513,
            "ave_precision_score": 0.8354875201896326,
            "fpr": 0.14489571899012074,
            "logloss": 0.7542159669055681,
            "mae": 0.2743502110981868,
            "precision": 0.7421875,
            "recall": 0.7966457023060797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8120210921343454,
            "auditor_fn_violation": 0.015550866159108463,
            "auditor_fp_violation": 0.015227364387981447,
            "ave_precision_score": 0.8123546050528776,
            "fpr": 0.1074561403508772,
            "logloss": 0.9022698929251616,
            "mae": 0.2720495446365153,
            "precision": 0.7802690582959642,
            "recall": 0.7295597484276729
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8139513639926093,
            "auditor_fn_violation": 0.01419409177833468,
            "auditor_fp_violation": 0.014138511890007947,
            "ave_precision_score": 0.8142862072668303,
            "fpr": 0.13391877058177826,
            "logloss": 0.9008575360766021,
            "mae": 0.2775027242307264,
            "precision": 0.75,
            "recall": 0.7672955974842768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8289044322322418,
            "auditor_fn_violation": 0.016502537791018432,
            "auditor_fp_violation": 0.016480137124420247,
            "ave_precision_score": 0.8292632001113629,
            "fpr": 0.14912280701754385,
            "logloss": 0.766710496978003,
            "mae": 0.2721057388897051,
            "precision": 0.7414448669201521,
            "recall": 0.8176100628930818
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8339873580736733,
            "auditor_fn_violation": 0.014686558646130339,
            "auditor_fp_violation": 0.022431925215112787,
            "ave_precision_score": 0.8342350192461649,
            "fpr": 0.17233809001097694,
            "logloss": 0.7768049804215105,
            "mae": 0.27585361673276726,
            "precision": 0.7140255009107468,
            "recall": 0.8218029350104822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8153781071733198,
            "auditor_fn_violation": 0.015594541910331383,
            "auditor_fp_violation": 0.013951905626134301,
            "ave_precision_score": 0.8157627263567175,
            "fpr": 0.12609649122807018,
            "logloss": 0.7558030287339043,
            "mae": 0.27310496778077215,
            "precision": 0.7633744855967078,
            "recall": 0.7777777777777778
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8125655034081589,
            "auditor_fn_violation": 0.012930707150204702,
            "auditor_fp_violation": 0.01792227106486517,
            "ave_precision_score": 0.8129170226378093,
            "fpr": 0.14270032930845225,
            "logloss": 0.789328259588114,
            "mae": 0.2795162127861895,
            "precision": 0.7425742574257426,
            "recall": 0.7861635220125787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8007284701424304,
            "auditor_fn_violation": 0.020336809003641182,
            "auditor_fp_violation": 0.012376487194998996,
            "ave_precision_score": 0.7912595700067001,
            "fpr": 0.13048245614035087,
            "logloss": 1.9210226258479808,
            "mae": 0.26617663699876326,
            "precision": 0.7605633802816901,
            "recall": 0.7924528301886793
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8004935565082754,
            "auditor_fn_violation": 0.011349750429757891,
            "auditor_fp_violation": 0.016060742486860558,
            "ave_precision_score": 0.7916032124297532,
            "fpr": 0.14928649835345773,
            "logloss": 1.708658368431058,
            "mae": 0.27219138455841085,
            "precision": 0.739961759082218,
            "recall": 0.8113207547169812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5184677987120454,
            "auditor_fn_violation": 0.004680201552098279,
            "auditor_fp_violation": 0.018831921758419058,
            "ave_precision_score": 0.504736579202949,
            "fpr": 0.36403508771929827,
            "logloss": 4.2875565514096206,
            "mae": 0.45068433987824624,
            "precision": 0.5482993197278911,
            "recall": 0.8448637316561844
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5149123203024591,
            "auditor_fn_violation": 0.0044644192688017646,
            "auditor_fp_violation": 0.007276654509401235,
            "ave_precision_score": 0.4974596495850257,
            "fpr": 0.3699231613611416,
            "logloss": 4.555909790466565,
            "mae": 0.44446698529134027,
            "precision": 0.5536423841059602,
            "recall": 0.8763102725366876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5009582436401355,
            "auditor_fn_violation": 0.02146318364044283,
            "auditor_fp_violation": 0.011648013712442023,
            "ave_precision_score": 0.4936528182088385,
            "fpr": 0.21820175438596492,
            "logloss": 5.437326967942047,
            "mae": 0.481423366163755,
            "precision": 0.5774946921443737,
            "recall": 0.570230607966457
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.47121474273838587,
            "auditor_fn_violation": 0.011662720027983164,
            "auditor_fp_violation": 0.01294470551933107,
            "ave_precision_score": 0.465400085413323,
            "fpr": 0.2349066959385291,
            "logloss": 5.908289413612259,
            "mae": 0.5069523136568792,
            "precision": 0.5541666666666667,
            "recall": 0.5576519916142557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8280945813595604,
            "auditor_fn_violation": 0.013275129648019423,
            "auditor_fp_violation": 0.014829098608590448,
            "ave_precision_score": 0.8284238366154197,
            "fpr": 0.14473684210526316,
            "logloss": 0.7095969556816023,
            "mae": 0.27465880487422234,
            "precision": 0.7441860465116279,
            "recall": 0.8050314465408805
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8337409236816804,
            "auditor_fn_violation": 0.014290744154257202,
            "auditor_fp_violation": 0.02371931386484696,
            "ave_precision_score": 0.8339999533369759,
            "fpr": 0.1668496158068057,
            "logloss": 0.7228376468622716,
            "mae": 0.2769075940662739,
            "precision": 0.7179962894248608,
            "recall": 0.8113207547169812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7907941509040982,
            "auditor_fn_violation": 0.011971753282577515,
            "auditor_fp_violation": 0.01351582980439605,
            "ave_precision_score": 0.7608266160347934,
            "fpr": 0.14035087719298245,
            "logloss": 3.5378459940575184,
            "mae": 0.2827355042564511,
            "precision": 0.7408906882591093,
            "recall": 0.7672955974842768
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7865939611993885,
            "auditor_fn_violation": 0.011071299537219222,
            "auditor_fp_violation": 0.01918436720674602,
            "ave_precision_score": 0.751590433882644,
            "fpr": 0.15916575192096596,
            "logloss": 3.747388920458856,
            "mae": 0.2864713723654189,
            "precision": 0.7216890595009597,
            "recall": 0.7882599580712788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6402497136218288,
            "auditor_fn_violation": 0.00787312883886867,
            "auditor_fp_violation": 0.0010964912280701788,
            "ave_precision_score": 0.6412906259590652,
            "fpr": 0.06359649122807018,
            "logloss": 5.12425150694562,
            "mae": 0.45859249139312214,
            "precision": 0.6666666666666666,
            "recall": 0.2431865828092243
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6942098912124609,
            "auditor_fn_violation": 0.002819027631073275,
            "auditor_fp_violation": 0.0016465422612513716,
            "ave_precision_score": 0.6946613370797015,
            "fpr": 0.05159165751920966,
            "logloss": 4.581718145228092,
            "mae": 0.4213598551866546,
            "precision": 0.7513227513227513,
            "recall": 0.2976939203354298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8249431396221999,
            "auditor_fn_violation": 0.016217496046195153,
            "auditor_fp_violation": 0.014808933252671916,
            "ave_precision_score": 0.8252909670244077,
            "fpr": 0.1425438596491228,
            "logloss": 0.7521813130432968,
            "mae": 0.26998474945748197,
            "precision": 0.74609375,
            "recall": 0.80083857442348
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8283841709867039,
            "auditor_fn_violation": 0.011681130004349359,
            "auditor_fp_violation": 0.01794756357271849,
            "ave_precision_score": 0.8286884920338549,
            "fpr": 0.16355653128430298,
            "logloss": 0.7702134041792407,
            "mae": 0.2745273608573277,
            "precision": 0.7250922509225092,
            "recall": 0.8238993710691824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8272092484426259,
            "auditor_fn_violation": 0.020012688955092138,
            "auditor_fp_violation": 0.01082879612825167,
            "ave_precision_score": 0.8275451103023042,
            "fpr": 0.10197368421052631,
            "logloss": 0.7711329289519859,
            "mae": 0.2681677752904727,
            "precision": 0.7910112359550562,
            "recall": 0.7379454926624738
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8324896445764196,
            "auditor_fn_violation": 0.017816254628383123,
            "auditor_fp_violation": 0.015178033962779546,
            "ave_precision_score": 0.8327742187664,
            "fpr": 0.12184412733260154,
            "logloss": 0.7640274287523161,
            "mae": 0.27139833822677967,
            "precision": 0.7692307692307693,
            "recall": 0.7756813417190775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 6832,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8226679363912189,
            "auditor_fn_violation": 0.015856596417668917,
            "auditor_fp_violation": 0.014140955837870546,
            "ave_precision_score": 0.8230220623660991,
            "fpr": 0.11951754385964912,
            "logloss": 0.7476349600642901,
            "mae": 0.2707434254482445,
            "precision": 0.7695560253699789,
            "recall": 0.7631027253668763
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8259206324753681,
            "auditor_fn_violation": 0.017376716442640272,
            "auditor_fp_violation": 0.018868210858579475,
            "ave_precision_score": 0.8262275205187763,
            "fpr": 0.14050493962678376,
            "logloss": 0.7642326186119395,
            "mae": 0.2762921482993323,
            "precision": 0.7470355731225297,
            "recall": 0.7924528301886793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8293060762539458,
            "auditor_fn_violation": 0.017268012799293835,
            "auditor_fp_violation": 0.013382234321435775,
            "ave_precision_score": 0.8296565388101851,
            "fpr": 0.11403508771929824,
            "logloss": 0.7158192686525413,
            "mae": 0.27130718285770333,
            "precision": 0.7773019271948608,
            "recall": 0.7610062893081762
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8419821075940102,
            "auditor_fn_violation": 0.013660202463715085,
            "auditor_fp_violation": 0.0118065426659315,
            "ave_precision_score": 0.8422230219248965,
            "fpr": 0.13391877058177826,
            "logloss": 0.6972795002849439,
            "mae": 0.2721254193821052,
            "precision": 0.7525354969574036,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 6832,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7961052775048956,
            "auditor_fn_violation": 0.017012854463202037,
            "auditor_fp_violation": 0.01808076225045372,
            "ave_precision_score": 0.7804662932449777,
            "fpr": 0.14473684210526316,
            "logloss": 2.47962462090526,
            "mae": 0.27210673704492183,
            "precision": 0.7426900584795322,
            "recall": 0.7987421383647799
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7926291337169411,
            "auditor_fn_violation": 0.010514397752141892,
            "auditor_fp_violation": 0.02034529331721358,
            "ave_precision_score": 0.7751839155042837,
            "fpr": 0.1602634467618002,
            "logloss": 2.418397208280547,
            "mae": 0.2738220610206335,
            "precision": 0.7281191806331471,
            "recall": 0.8197064989517819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8529159688032251,
            "auditor_fn_violation": 0.013383169664202436,
            "auditor_fp_violation": 0.019751966122202053,
            "ave_precision_score": 0.8532586589931973,
            "fpr": 0.2236842105263158,
            "logloss": 0.6882460818273963,
            "mae": 0.32802939214288446,
            "precision": 0.6787401574803149,
            "recall": 0.9035639412997903
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8663772686073727,
            "auditor_fn_violation": 0.009036997148754911,
            "auditor_fp_violation": 0.021083834546530636,
            "ave_precision_score": 0.8671099122496986,
            "fpr": 0.2052689352360044,
            "logloss": 0.5125344382749204,
            "mae": 0.30341443213432273,
            "precision": 0.7027027027027027,
            "recall": 0.9266247379454927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.74212375983016,
            "auditor_fn_violation": 0.011737283460222889,
            "auditor_fp_violation": 0.00907441016333939,
            "ave_precision_score": 0.7435534560815387,
            "fpr": 0.21052631578947367,
            "logloss": 0.9888150026912484,
            "mae": 0.34218160170967804,
            "precision": 0.6745762711864407,
            "recall": 0.8343815513626834
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7504284281824114,
            "auditor_fn_violation": 0.011915857203018316,
            "auditor_fp_violation": 0.013450555676397531,
            "ave_precision_score": 0.7521836672214177,
            "fpr": 0.21405049396267836,
            "logloss": 0.7974495837480988,
            "mae": 0.3401990641817311,
            "precision": 0.6733668341708543,
            "recall": 0.8427672955974843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7346582204142216,
            "auditor_fn_violation": 0.027605373496634666,
            "auditor_fp_violation": 0.034356725146198835,
            "ave_precision_score": 0.7151940832119216,
            "fpr": 0.15899122807017543,
            "logloss": 1.9459497219465818,
            "mae": 0.2860058910678656,
            "precision": 0.7248576850094877,
            "recall": 0.80083857442348
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7433576393253796,
            "auditor_fn_violation": 0.00755499405127639,
            "auditor_fp_violation": 0.029458183896766105,
            "ave_precision_score": 0.7232594322248489,
            "fpr": 0.17453347969264543,
            "logloss": 1.9252604756718237,
            "mae": 0.2869351605624054,
            "precision": 0.7145421903052065,
            "recall": 0.8343815513626834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8233609175043163,
            "auditor_fn_violation": 0.01716227150685939,
            "auditor_fp_violation": 0.015023190159306313,
            "ave_precision_score": 0.8239191491890162,
            "fpr": 0.13706140350877194,
            "logloss": 0.8640089836692781,
            "mae": 0.27171328699339126,
            "precision": 0.7459349593495935,
            "recall": 0.7693920335429769
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8344184438661381,
            "auditor_fn_violation": 0.015059360667545747,
            "auditor_fp_violation": 0.018860623106223474,
            "ave_precision_score": 0.8346730874531403,
            "fpr": 0.15697036223929747,
            "logloss": 0.8307452243973121,
            "mae": 0.2747789247750786,
            "precision": 0.7276190476190476,
            "recall": 0.80083857442348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7453804632450219,
            "auditor_fn_violation": 0.013348688807973819,
            "auditor_fp_violation": 0.021491228070175436,
            "ave_precision_score": 0.7166860123027736,
            "fpr": 0.14912280701754385,
            "logloss": 2.521336680516682,
            "mae": 0.2921080782751386,
            "precision": 0.7263581488933601,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7444299404039381,
            "auditor_fn_violation": 0.0008054364660209377,
            "auditor_fp_violation": 0.01184195217692615,
            "ave_precision_score": 0.7160609889751195,
            "fpr": 0.16465422612513722,
            "logloss": 2.5691682866495458,
            "mae": 0.30097350934512535,
            "precision": 0.7164461247637051,
            "recall": 0.7945492662473794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8538617424684027,
            "auditor_fn_violation": 0.01223150906616647,
            "auditor_fp_violation": 0.016031457955232913,
            "ave_precision_score": 0.8542644496705067,
            "fpr": 0.11293859649122807,
            "logloss": 0.5488281270162927,
            "mae": 0.2843656109249523,
            "precision": 0.7822410147991543,
            "recall": 0.7756813417190775
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8622473082724096,
            "auditor_fn_violation": 0.01696249197440093,
            "auditor_fp_violation": 0.019242539974808664,
            "ave_precision_score": 0.8624434475455465,
            "fpr": 0.132821075740944,
            "logloss": 0.519657904813362,
            "mae": 0.28356852049503256,
            "precision": 0.7618110236220472,
            "recall": 0.8113207547169812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.46722886709360123,
            "auditor_fn_violation": 0.014150943396226412,
            "auditor_fp_violation": 0.02874067352288768,
            "ave_precision_score": 0.4396665503681462,
            "fpr": 0.30043859649122806,
            "logloss": 7.944392458373112,
            "mae": 0.5388868076522997,
            "precision": 0.5045207956600362,
            "recall": 0.5849056603773585
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.47584846571522893,
            "auditor_fn_violation": 0.014702667375450758,
            "auditor_fp_violation": 0.01690045374759089,
            "ave_precision_score": 0.44328785012145316,
            "fpr": 0.287596048298573,
            "logloss": 8.424608956094756,
            "mae": 0.527358158978915,
            "precision": 0.5192660550458715,
            "recall": 0.5932914046121593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.591146115601124,
            "auditor_fn_violation": 0.007365110890433637,
            "auditor_fp_violation": 0.007950191570881232,
            "ave_precision_score": 0.591270228646728,
            "fpr": 0.21271929824561403,
            "logloss": 1.877744725510713,
            "mae": 0.39528624548311275,
            "precision": 0.6427255985267035,
            "recall": 0.7316561844863732
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.5610205331638286,
            "auditor_fn_violation": 0.019924196922312204,
            "auditor_fp_violation": 0.006277600449194946,
            "ave_precision_score": 0.5601038089422042,
            "fpr": 0.22941822173435786,
            "logloss": 2.165200421275544,
            "mae": 0.4188778213365778,
            "precision": 0.6234234234234234,
            "recall": 0.7253668763102725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 6832,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.47127346897976874,
            "auditor_fn_violation": 0.018812755158336105,
            "auditor_fp_violation": 0.029564932446057676,
            "ave_precision_score": 0.44427739069649497,
            "fpr": 0.27850877192982454,
            "logloss": 7.839125386249546,
            "mae": 0.5391532760526647,
            "precision": 0.50293542074364,
            "recall": 0.5387840670859538
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.4737846681370399,
            "auditor_fn_violation": 0.012507277693782258,
            "auditor_fp_violation": 0.01347331893346555,
            "ave_precision_score": 0.4444530026276009,
            "fpr": 0.2689352360043908,
            "logloss": 8.261230499195893,
            "mae": 0.5310177854266865,
            "precision": 0.5205479452054794,
            "recall": 0.5576519916142557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6298995718542992,
            "auditor_fn_violation": 0.0049859318106587214,
            "auditor_fp_violation": 0.017319520064529137,
            "ave_precision_score": 0.622777985913844,
            "fpr": 0.03070175438596491,
            "logloss": 4.033783623451951,
            "mae": 0.4873890276894986,
            "precision": 0.6585365853658537,
            "recall": 0.11320754716981132
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6645452899686594,
            "auditor_fn_violation": 0.020469592472160673,
            "auditor_fp_violation": 0.017775574519315888,
            "ave_precision_score": 0.654500297585638,
            "fpr": 0.02854006586169045,
            "logloss": 3.9059496323363057,
            "mae": 0.47806251333581334,
            "precision": 0.6976744186046512,
            "recall": 0.12578616352201258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7362856538537398,
            "auditor_fn_violation": 0.016815164220824602,
            "auditor_fp_violation": 0.023590945755192584,
            "ave_precision_score": 0.7104758240072525,
            "fpr": 0.15021929824561403,
            "logloss": 2.4880967314605047,
            "mae": 0.29081340116579024,
            "precision": 0.7254509018036072,
            "recall": 0.7589098532494759
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7434790344669782,
            "auditor_fn_violation": 0.007831143696769278,
            "auditor_fp_violation": 0.018792333335019503,
            "ave_precision_score": 0.7180511914388896,
            "fpr": 0.1602634467618002,
            "logloss": 2.440729653539804,
            "mae": 0.2920284655787766,
            "precision": 0.7234848484848485,
            "recall": 0.80083857442348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7991910982649988,
            "auditor_fn_violation": 0.01361993821030564,
            "auditor_fp_violation": 0.013805706795724949,
            "ave_precision_score": 0.7995583687332681,
            "fpr": 0.11732456140350878,
            "logloss": 0.7424003027969995,
            "mae": 0.2863005067870296,
            "precision": 0.7648351648351648,
            "recall": 0.7295597484276729
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8180478078509374,
            "auditor_fn_violation": 0.013535935123243288,
            "auditor_fp_violation": 0.016235260791048475,
            "ave_precision_score": 0.818380100199283,
            "fpr": 0.13062568605927552,
            "logloss": 0.7267576131928675,
            "mae": 0.28074255743774823,
            "precision": 0.750524109014675,
            "recall": 0.750524109014675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8263523825477945,
            "auditor_fn_violation": 0.018454154253558428,
            "auditor_fp_violation": 0.016008771929824566,
            "ave_precision_score": 0.8266992332881418,
            "fpr": 0.12719298245614036,
            "logloss": 0.7558956321255923,
            "mae": 0.26712702263516774,
            "precision": 0.7608247422680412,
            "recall": 0.7735849056603774
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.829310368331716,
            "auditor_fn_violation": 0.01677609096369323,
            "auditor_fp_violation": 0.0171432618229828,
            "ave_precision_score": 0.829622906816803,
            "fpr": 0.14489571899012074,
            "logloss": 0.7742406871955584,
            "mae": 0.27167711693657326,
            "precision": 0.7411764705882353,
            "recall": 0.7924528301886793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 6832,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6240357537668783,
            "auditor_fn_violation": 0.003445786899113638,
            "auditor_fp_violation": 0.017279189352692077,
            "ave_precision_score": 0.6169383770852274,
            "fpr": 0.08662280701754387,
            "logloss": 2.00514259734941,
            "mae": 0.4274151129585103,
            "precision": 0.7247386759581882,
            "recall": 0.4360587002096436
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6473730006756093,
            "auditor_fn_violation": 0.013255182983658853,
            "auditor_fp_violation": 0.013738890265925431,
            "ave_precision_score": 0.6373711154049876,
            "fpr": 0.07574094401756312,
            "logloss": 1.9583741555673393,
            "mae": 0.41538710587950434,
            "precision": 0.7472527472527473,
            "recall": 0.4276729559748428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6869576901085785,
            "auditor_fn_violation": 0.01055803817720402,
            "auditor_fp_violation": 0.01922010485985078,
            "ave_precision_score": 0.6798022287985969,
            "fpr": 0.19188596491228072,
            "logloss": 1.505169614961063,
            "mae": 0.3774950536975858,
            "precision": 0.6722846441947565,
            "recall": 0.7526205450733753
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.687959946658605,
            "auditor_fn_violation": 0.00702800847779412,
            "auditor_fp_violation": 0.020360468821925572,
            "ave_precision_score": 0.6779167103467467,
            "fpr": 0.18880351262349068,
            "logloss": 1.4815729525484826,
            "mae": 0.38196267158255126,
            "precision": 0.6698656429942419,
            "recall": 0.7316561844863732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7551152608741641,
            "auditor_fn_violation": 0.020254054948692483,
            "auditor_fp_violation": 0.022459165154264975,
            "ave_precision_score": 0.722381235809257,
            "fpr": 0.14802631578947367,
            "logloss": 3.157078799941215,
            "mae": 0.28588676224583615,
            "precision": 0.7373540856031129,
            "recall": 0.7945492662473794
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7590048992883363,
            "auditor_fn_violation": 0.0026901577965099343,
            "auditor_fp_violation": 0.01670064293554963,
            "ave_precision_score": 0.7237379717773688,
            "fpr": 0.17014270032930845,
            "logloss": 3.1217165221834775,
            "mae": 0.28511618290517726,
            "precision": 0.7150735294117647,
            "recall": 0.8155136268343816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.49089098685711524,
            "auditor_fn_violation": 0.010608610099672667,
            "auditor_fp_violation": 0.028697822141560803,
            "ave_precision_score": 0.46881971235157527,
            "fpr": 0.2905701754385965,
            "logloss": 6.075963527862913,
            "mae": 0.49465101591652416,
            "precision": 0.5391304347826087,
            "recall": 0.649895178197065
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.48701904534822515,
            "auditor_fn_violation": 0.01261313505788788,
            "auditor_fp_violation": 0.01044074724185202,
            "ave_precision_score": 0.4633440252162825,
            "fpr": 0.283205268935236,
            "logloss": 6.262918759268865,
            "mae": 0.49604685689410727,
            "precision": 0.551304347826087,
            "recall": 0.6645702306079665
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 6832,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7867701538627446,
            "auditor_fn_violation": 0.014412997903563944,
            "auditor_fp_violation": 0.013157894736842111,
            "ave_precision_score": 0.7825877489557687,
            "fpr": 0.13706140350877194,
            "logloss": 1.1418484812420495,
            "mae": 0.2857010657837432,
            "precision": 0.7406639004149378,
            "recall": 0.7484276729559748
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.783492704763902,
            "auditor_fn_violation": 0.014884465892066915,
            "auditor_fp_violation": 0.017479652177432005,
            "ave_precision_score": 0.7779164068154704,
            "fpr": 0.150384193194292,
            "logloss": 1.2453113358474828,
            "mae": 0.2875505994216916,
            "precision": 0.7276341948310139,
            "recall": 0.7672955974842768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7279506660330902,
            "auditor_fn_violation": 0.014438283864798276,
            "auditor_fp_violation": 0.02818864690461788,
            "ave_precision_score": 0.72072214870373,
            "fpr": 0.15570175438596492,
            "logloss": 1.710130448592766,
            "mae": 0.31792515633805946,
            "precision": 0.7078189300411523,
            "recall": 0.7211740041928721
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7397266110689047,
            "auditor_fn_violation": 0.016065005626549028,
            "auditor_fp_violation": 0.015514424317228749,
            "ave_precision_score": 0.733887098206274,
            "fpr": 0.16465422612513722,
            "logloss": 1.7161925818556454,
            "mae": 0.3114962613257438,
            "precision": 0.7053045186640472,
            "recall": 0.7526205450733753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8229523581245572,
            "auditor_fn_violation": 0.019031133914450694,
            "auditor_fp_violation": 0.014692982456140357,
            "ave_precision_score": 0.8233073060640226,
            "fpr": 0.125,
            "logloss": 0.7500124234530147,
            "mae": 0.27060361364205465,
            "precision": 0.7634854771784232,
            "recall": 0.7714884696016772
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8263286106747998,
            "auditor_fn_violation": 0.016322745295675723,
            "auditor_fp_violation": 0.01577240789733266,
            "ave_precision_score": 0.8266383792799944,
            "fpr": 0.14818880351262348,
            "logloss": 0.7676289928793778,
            "mae": 0.27506446714091964,
            "precision": 0.7378640776699029,
            "recall": 0.7966457023060797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7419973713083763,
            "auditor_fn_violation": 0.01827945124866674,
            "auditor_fp_violation": 0.023366606170598915,
            "ave_precision_score": 0.714935535409824,
            "fpr": 0.13815789473684212,
            "logloss": 2.9423496953388404,
            "mae": 0.28648479739418753,
            "precision": 0.7449392712550608,
            "recall": 0.7714884696016772
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7459208453292899,
            "auditor_fn_violation": 0.0010746823703765079,
            "auditor_fp_violation": 0.016055683985289875,
            "ave_precision_score": 0.719848598281149,
            "fpr": 0.15148188803512624,
            "logloss": 2.760521887895383,
            "mae": 0.289587495097897,
            "precision": 0.7330754352030948,
            "recall": 0.7945492662473794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6005178141525446,
            "auditor_fn_violation": 0.0035745154290338236,
            "auditor_fp_violation": 0.022935571687840297,
            "ave_precision_score": 0.6009357132093601,
            "fpr": 0.08442982456140351,
            "logloss": 7.256488866924766,
            "mae": 0.41846607081041687,
            "precision": 0.717948717948718,
            "recall": 0.4109014675052411
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6078306743487756,
            "auditor_fn_violation": 0.01203091955530704,
            "auditor_fp_violation": 0.013258332616712281,
            "ave_precision_score": 0.606352457743369,
            "fpr": 0.08232711306256861,
            "logloss": 7.629334248799975,
            "mae": 0.4181075081602129,
            "precision": 0.7262773722627737,
            "recall": 0.4171907756813417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.472843556127569,
            "auditor_fn_violation": 0.016541616094744197,
            "auditor_fp_violation": 0.023265779391006266,
            "ave_precision_score": 0.4454006008052227,
            "fpr": 0.31359649122807015,
            "logloss": 7.553869070203029,
            "mae": 0.5316012740177988,
            "precision": 0.5077452667814114,
            "recall": 0.6184486373165619
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.47919345057990204,
            "auditor_fn_violation": 0.013089493196363117,
            "auditor_fp_violation": 0.009277291880599135,
            "ave_precision_score": 0.447744356449669,
            "fpr": 0.2996706915477497,
            "logloss": 7.918436617818717,
            "mae": 0.521076613147349,
            "precision": 0.521891418563923,
            "recall": 0.6247379454926625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8348656144846054,
            "auditor_fn_violation": 0.02086551546581338,
            "auditor_fp_violation": 0.009351683807219204,
            "ave_precision_score": 0.8351827345932068,
            "fpr": 0.10087719298245613,
            "logloss": 0.7313155976641972,
            "mae": 0.26508518814101306,
            "precision": 0.7918552036199095,
            "recall": 0.7337526205450734
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8432077982488876,
            "auditor_fn_violation": 0.01680140468119674,
            "auditor_fp_violation": 0.01195829771305144,
            "ave_precision_score": 0.8434683484215806,
            "fpr": 0.1141602634467618,
            "logloss": 0.6954914672009627,
            "mae": 0.26688265938295935,
            "precision": 0.7763440860215054,
            "recall": 0.7568134171907757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.4543287181025416,
            "auditor_fn_violation": 0.017495586450402747,
            "auditor_fp_violation": 0.009301270417422881,
            "ave_precision_score": 0.4324647049488864,
            "fpr": 0.2894736842105263,
            "logloss": 8.259580982065811,
            "mae": 0.5481404034190624,
            "precision": 0.5,
            "recall": 0.5534591194968553
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.44610870591584084,
            "auditor_fn_violation": 0.0119434721675676,
            "auditor_fp_violation": 0.018251073666958377,
            "ave_precision_score": 0.4227874838752307,
            "fpr": 0.29747530186608123,
            "logloss": 9.264799923951134,
            "mae": 0.5601956914225278,
            "precision": 0.48867924528301887,
            "recall": 0.5429769392033543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6565004657797887,
            "auditor_fn_violation": 0.007043289565633162,
            "auditor_fp_violation": 0.01856473079249849,
            "ave_precision_score": 0.6493558157991475,
            "fpr": 0.03289473684210526,
            "logloss": 2.9420853613915194,
            "mae": 0.4574482981951077,
            "precision": 0.7457627118644068,
            "recall": 0.18448637316561844
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6848653816181465,
            "auditor_fn_violation": 0.015098481867323904,
            "auditor_fp_violation": 0.017335484882668055,
            "ave_precision_score": 0.6747983234454544,
            "fpr": 0.029637760702524697,
            "logloss": 2.881337836311403,
            "mae": 0.4493717822773652,
            "precision": 0.775,
            "recall": 0.1949685534591195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 6832,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8309240938940003,
            "auditor_fn_violation": 0.018743793445878853,
            "auditor_fp_violation": 0.016666666666666673,
            "ave_precision_score": 0.8312576816401761,
            "fpr": 0.12280701754385964,
            "logloss": 0.7067319115526283,
            "mae": 0.2642851526385275,
            "precision": 0.7714285714285715,
            "recall": 0.7924528301886793
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8345170253172802,
            "auditor_fn_violation": 0.015521911323746342,
            "auditor_fp_violation": 0.01834212669523034,
            "ave_precision_score": 0.8348153161436445,
            "fpr": 0.145993413830955,
            "logloss": 0.7121616356924798,
            "mae": 0.2678005037704094,
            "precision": 0.7432432432432432,
            "recall": 0.8071278825995807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.508391239164637,
            "auditor_fn_violation": 0.005792783846408472,
            "auditor_fp_violation": 0.02127697116354104,
            "ave_precision_score": 0.4901267908105866,
            "fpr": 0.2883771929824561,
            "logloss": 5.158365322560904,
            "mae": 0.46060889026878404,
            "precision": 0.5674342105263158,
            "recall": 0.7232704402515723
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5046670407777653,
            "auditor_fn_violation": 0.013706227404630572,
            "auditor_fp_violation": 0.016045566982148558,
            "ave_precision_score": 0.4840632831047382,
            "fpr": 0.29747530186608123,
            "logloss": 5.283912084104783,
            "mae": 0.45813405687568426,
            "precision": 0.5718799368088467,
            "recall": 0.7589098532494759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 6832,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.46787880380941,
            "auditor_fn_violation": 0.02074598183088749,
            "auditor_fp_violation": 0.018421052631578953,
            "ave_precision_score": 0.4463311489384128,
            "fpr": 0.27631578947368424,
            "logloss": 7.63566092263186,
            "mae": 0.5304186210448563,
            "precision": 0.5153846153846153,
            "recall": 0.5618448637316562
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.4547630530834371,
            "auditor_fn_violation": 0.010990755890617132,
            "auditor_fp_violation": 0.010374986721433391,
            "ave_precision_score": 0.4332748675326935,
            "fpr": 0.2843029637760702,
            "logloss": 8.357675947088012,
            "mae": 0.542252602376113,
            "precision": 0.50853889943074,
            "recall": 0.5618448637316562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7299755926034348,
            "auditor_fn_violation": 0.017893265658906175,
            "auditor_fp_violation": 0.021634906231094982,
            "ave_precision_score": 0.7227747249886433,
            "fpr": 0.15789473684210525,
            "logloss": 1.5907578449567592,
            "mae": 0.28434284528053433,
            "precision": 0.7283018867924528,
            "recall": 0.8092243186582809
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7456652440830764,
            "auditor_fn_violation": 0.0067334488559350324,
            "auditor_fp_violation": 0.02159980170673843,
            "ave_precision_score": 0.7355558183785893,
            "fpr": 0.18221734357848518,
            "logloss": 1.5498543735330537,
            "mae": 0.2833373385314165,
            "precision": 0.7040998217468806,
            "recall": 0.8280922431865828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8379349980351517,
            "auditor_fn_violation": 0.01891619772702196,
            "auditor_fp_violation": 0.009389493849566447,
            "ave_precision_score": 0.838310129656114,
            "fpr": 0.1206140350877193,
            "logloss": 0.6812438411884482,
            "mae": 0.26648433454784926,
            "precision": 0.7717842323651453,
            "recall": 0.779874213836478
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8479275768465526,
            "auditor_fn_violation": 0.01102757584334951,
            "auditor_fp_violation": 0.014705064065922395,
            "ave_precision_score": 0.84815665242158,
            "fpr": 0.14489571899012074,
            "logloss": 0.6767728071490484,
            "mae": 0.2705601943370181,
            "precision": 0.7436893203883496,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 6832,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8277247206876319,
            "auditor_fn_violation": 0.020295431976166838,
            "auditor_fp_violation": 0.011411070780399275,
            "ave_precision_score": 0.8280517378758763,
            "fpr": 0.10526315789473684,
            "logloss": 0.7578928554261969,
            "mae": 0.2690687721674877,
            "precision": 0.785234899328859,
            "recall": 0.7358490566037735
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8354099088510624,
            "auditor_fn_violation": 0.01638027647182008,
            "auditor_fp_violation": 0.013420204666973554,
            "ave_precision_score": 0.8356772993409551,
            "fpr": 0.12623490669593854,
            "logloss": 0.7491828146769526,
            "mae": 0.2710632782331598,
            "precision": 0.7628865979381443,
            "recall": 0.7756813417190775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8009722541984747,
            "auditor_fn_violation": 0.0201345213137666,
            "auditor_fp_violation": 0.014292196007259532,
            "ave_precision_score": 0.7878716363295523,
            "fpr": 0.13486842105263158,
            "logloss": 2.2148872213149917,
            "mae": 0.2685543227677804,
            "precision": 0.754,
            "recall": 0.790356394129979
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7987745917450981,
            "auditor_fn_violation": 0.011941170920521833,
            "auditor_fp_violation": 0.018425591971146307,
            "ave_precision_score": 0.7862126265988509,
            "fpr": 0.15916575192096596,
            "logloss": 2.0720465585235726,
            "mae": 0.27461396704228463,
            "precision": 0.7279549718574109,
            "recall": 0.8134171907756813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8299648617992101,
            "auditor_fn_violation": 0.019812699988966127,
            "auditor_fp_violation": 0.010974994958661026,
            "ave_precision_score": 0.8303117301749321,
            "fpr": 0.10087719298245613,
            "logloss": 0.7474659308530935,
            "mae": 0.2667057343520039,
            "precision": 0.7909090909090909,
            "recall": 0.7295597484276729
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8358532334237752,
            "auditor_fn_violation": 0.011927363438247187,
            "auditor_fp_violation": 0.012823301481635112,
            "ave_precision_score": 0.8361275652250262,
            "fpr": 0.11964873765093303,
            "logloss": 0.7339879629171776,
            "mae": 0.27105603325321903,
            "precision": 0.7714884696016772,
            "recall": 0.7714884696016772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 6832,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.45726920853852193,
            "auditor_fn_violation": 0.015171576740593619,
            "auditor_fp_violation": 0.0333257713248639,
            "ave_precision_score": 0.42836814616726543,
            "fpr": 0.2730263157894737,
            "logloss": 9.21589023518173,
            "mae": 0.5670005791673309,
            "precision": 0.48125,
            "recall": 0.48427672955974843
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.46194238835395257,
            "auditor_fn_violation": 0.01950306871293555,
            "auditor_fp_violation": 0.015056629925083588,
            "ave_precision_score": 0.4286564155596889,
            "fpr": 0.2623490669593853,
            "logloss": 9.736351203296998,
            "mae": 0.5630951174495095,
            "precision": 0.4936440677966102,
            "recall": 0.48846960167714887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.5315017695214651,
            "auditor_fn_violation": 0.009592574202802604,
            "auditor_fp_violation": 0.013011695906432768,
            "ave_precision_score": 0.484309567554068,
            "fpr": 0.34978070175438597,
            "logloss": 5.668232528349578,
            "mae": 0.47632271718695146,
            "precision": 0.5383502170767004,
            "recall": 0.779874213836478
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5301655155024787,
            "auditor_fn_violation": 0.006675917679790677,
            "auditor_fp_violation": 0.007456231315159842,
            "ave_precision_score": 0.47726034041244936,
            "fpr": 0.34906695938529086,
            "logloss": 6.3654313546478605,
            "mae": 0.4783242398453314,
            "precision": 0.5350877192982456,
            "recall": 0.7672955974842768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.4576803052775351,
            "auditor_fn_violation": 0.01530950016550811,
            "auditor_fp_violation": 0.02526971163541038,
            "ave_precision_score": 0.42865344333593935,
            "fpr": 0.2949561403508772,
            "logloss": 8.633977257239911,
            "mae": 0.5629412573935989,
            "precision": 0.4836852207293666,
            "recall": 0.5283018867924528
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.4619411839449336,
            "auditor_fn_violation": 0.018412277613238614,
            "auditor_fp_violation": 0.009249470121960477,
            "ave_precision_score": 0.4283981914763194,
            "fpr": 0.27991218441273324,
            "logloss": 9.147858138064958,
            "mae": 0.5592168403173722,
            "precision": 0.49404761904761907,
            "recall": 0.5220125786163522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.828378613743194,
            "auditor_fn_violation": 0.019536853139137153,
            "auditor_fp_violation": 0.01082879612825167,
            "ave_precision_score": 0.8287048892594748,
            "fpr": 0.10197368421052631,
            "logloss": 0.7665684712212762,
            "mae": 0.2679401188484559,
            "precision": 0.7895927601809954,
            "recall": 0.7316561844863732
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8343751747763848,
            "auditor_fn_violation": 0.01671395729345733,
            "auditor_fp_violation": 0.015023749664874277,
            "ave_precision_score": 0.8346497042898999,
            "fpr": 0.11964873765093303,
            "logloss": 0.7566292368272187,
            "mae": 0.2705737496081074,
            "precision": 0.7719665271966527,
            "recall": 0.7735849056603774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.47211062822450617,
            "auditor_fn_violation": 0.02251599911729008,
            "auditor_fp_violation": 0.016447368421052645,
            "ave_precision_score": 0.45194389259030365,
            "fpr": 0.2850877192982456,
            "logloss": 7.225419156912416,
            "mae": 0.5229001261181232,
            "precision": 0.5220588235294118,
            "recall": 0.5953878406708596
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.460344721209773,
            "auditor_fn_violation": 0.014953503303440138,
            "auditor_fp_violation": 0.011123644953891766,
            "ave_precision_score": 0.43896991367159816,
            "fpr": 0.283205268935236,
            "logloss": 7.875816166319808,
            "mae": 0.5352813516357137,
            "precision": 0.5113636363636364,
            "recall": 0.5660377358490566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7936099923891358,
            "auditor_fn_violation": 0.018557596822244293,
            "auditor_fp_violation": 0.019116757410768303,
            "ave_precision_score": 0.76543663588636,
            "fpr": 0.1524122807017544,
            "logloss": 3.1170756227464094,
            "mae": 0.2758630813142134,
            "precision": 0.7263779527559056,
            "recall": 0.7735849056603774
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7897319427662324,
            "auditor_fn_violation": 0.014000787026489658,
            "auditor_fp_violation": 0.024650078153849272,
            "ave_precision_score": 0.7566821398963722,
            "fpr": 0.16575192096597147,
            "logloss": 3.441005063661539,
            "mae": 0.27947715609342366,
            "precision": 0.7177570093457943,
            "recall": 0.8050314465408805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7218531636690693,
            "auditor_fn_violation": 0.018169112508735152,
            "auditor_fp_violation": 0.02106019358741682,
            "ave_precision_score": 0.7025126924772702,
            "fpr": 0.16447368421052633,
            "logloss": 2.2000717451758574,
            "mae": 0.2899278255599591,
            "precision": 0.7262773722627737,
            "recall": 0.8343815513626834
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7272667810916005,
            "auditor_fn_violation": 0.01534701654826751,
            "auditor_fp_violation": 0.024417387081598695,
            "ave_precision_score": 0.7078751782032585,
            "fpr": 0.18880351262349068,
            "logloss": 2.107696404887454,
            "mae": 0.28608662908633625,
            "precision": 0.7044673539518901,
            "recall": 0.859538784067086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 6832,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.5209563917434388,
            "auditor_fn_violation": 0.008454705947258086,
            "auditor_fp_violation": 0.01943184109699536,
            "ave_precision_score": 0.5139059169916904,
            "fpr": 0.041666666666666664,
            "logloss": 8.370952807305638,
            "mae": 0.542590067651712,
            "precision": 0.3333333333333333,
            "recall": 0.039832285115303984
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.549901066333885,
            "auditor_fn_violation": 0.016196176708158157,
            "auditor_fp_violation": 0.017950092823503825,
            "ave_precision_score": 0.5399633311672655,
            "fpr": 0.042810098792535674,
            "logloss": 8.175614549506584,
            "mae": 0.5362352736442173,
            "precision": 0.38095238095238093,
            "recall": 0.050314465408805034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8229802992871059,
            "auditor_fn_violation": 0.01643817352605833,
            "auditor_fp_violation": 0.01533323250655374,
            "ave_precision_score": 0.8233400301916438,
            "fpr": 0.13596491228070176,
            "logloss": 0.7842093428325084,
            "mae": 0.26926300853426466,
            "precision": 0.7524950099800399,
            "recall": 0.790356394129979
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8250479497491144,
            "auditor_fn_violation": 0.013038865761356079,
            "auditor_fp_violation": 0.018144845133974418,
            "ave_precision_score": 0.8253689859792314,
            "fpr": 0.15587266739846323,
            "logloss": 0.8058341862933879,
            "mae": 0.2742030062179578,
            "precision": 0.7320754716981132,
            "recall": 0.8134171907756813
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8252639354076868,
            "auditor_fn_violation": 0.006041046011254552,
            "auditor_fp_violation": 0.016863278886872363,
            "ave_precision_score": 0.8257542685249342,
            "fpr": 0.27631578947368424,
            "logloss": 0.6672515958884913,
            "mae": 0.35199034528392203,
            "precision": 0.6363636363636364,
            "recall": 0.9245283018867925
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.8006762409250123,
            "auditor_fn_violation": 0.010452264081905987,
            "auditor_fp_violation": 0.01873668981774219,
            "ave_precision_score": 0.8022265188789104,
            "fpr": 0.2897914379802415,
            "logloss": 0.6871305645957515,
            "mae": 0.35713380360699837,
            "precision": 0.6265912305516266,
            "recall": 0.9287211740041929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8592677076827567,
            "auditor_fn_violation": 0.016608279083452866,
            "auditor_fp_violation": 0.004832123411978226,
            "ave_precision_score": 0.8597094009604083,
            "fpr": 0.11842105263157894,
            "logloss": 0.5217389152457728,
            "mae": 0.27578771840217886,
            "precision": 0.7768595041322314,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8777975768870834,
            "auditor_fn_violation": 0.018021065615457015,
            "auditor_fp_violation": 0.01402216635388265,
            "ave_precision_score": 0.8779663243484619,
            "fpr": 0.12294182217343579,
            "logloss": 0.5069040796305686,
            "mae": 0.2672929857565944,
            "precision": 0.7751004016064257,
            "recall": 0.8092243186582809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.687252631664435,
            "auditor_fn_violation": 0.0015746257677737563,
            "auditor_fp_violation": 0.006578947368421056,
            "ave_precision_score": 0.6926933731077142,
            "fpr": 0.049342105263157895,
            "logloss": 5.434725159762864,
            "mae": 0.3995057449345007,
            "precision": 0.8034934497816594,
            "recall": 0.3857442348008386
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6845520162154977,
            "auditor_fn_violation": 0.012410625317859759,
            "auditor_fp_violation": 0.011030062674834465,
            "ave_precision_score": 0.6899504998959979,
            "fpr": 0.04939626783754116,
            "logloss": 5.958460578871065,
            "mae": 0.410224312568329,
            "precision": 0.7991071428571429,
            "recall": 0.3752620545073375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.46040237574030696,
            "auditor_fn_violation": 0.01618071646621797,
            "auditor_fp_violation": 0.016742286751361166,
            "ave_precision_score": 0.44178703401905045,
            "fpr": 0.23793859649122806,
            "logloss": 6.8530456242940705,
            "mae": 0.5404838188021274,
            "precision": 0.5241228070175439,
            "recall": 0.5010482180293501
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.44642323210657053,
            "auditor_fn_violation": 0.008795366208948621,
            "auditor_fp_violation": 0.015828051414609957,
            "ave_precision_score": 0.4272936218513974,
            "fpr": 0.24588364434687157,
            "logloss": 7.697497623109848,
            "mae": 0.5609226844222477,
            "precision": 0.4977578475336323,
            "recall": 0.46540880503144655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5456400555145479,
            "auditor_fn_violation": 0.008388042958549431,
            "auditor_fp_violation": 0.0148064125831821,
            "ave_precision_score": 0.5438131608742148,
            "fpr": 0.14473684210526316,
            "logloss": 2.753119993039989,
            "mae": 0.4414873556991054,
            "precision": 0.6292134831460674,
            "recall": 0.469601677148847
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5054714911768976,
            "auditor_fn_violation": 0.0190267105744603,
            "auditor_fp_violation": 0.014457197488959826,
            "ave_precision_score": 0.5044898206163988,
            "fpr": 0.18990120746432493,
            "logloss": 3.0409833817244554,
            "mae": 0.48079432362103836,
            "precision": 0.5597964376590331,
            "recall": 0.4612159329140461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8250299936543662,
            "auditor_fn_violation": 0.016509433962264158,
            "auditor_fp_violation": 0.02183151845130067,
            "ave_precision_score": 0.825400945094172,
            "fpr": 0.14035087719298245,
            "logloss": 0.7842465202461002,
            "mae": 0.2710685132760447,
            "precision": 0.7470355731225297,
            "recall": 0.7924528301886793
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8291092298269572,
            "auditor_fn_violation": 0.014012293261718527,
            "auditor_fp_violation": 0.021989306327679613,
            "ave_precision_score": 0.8293932500772138,
            "fpr": 0.1690450054884742,
            "logloss": 0.7790456085206622,
            "mae": 0.2748290744807502,
            "precision": 0.7148148148148148,
            "recall": 0.8092243186582809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8413028968292285,
            "auditor_fn_violation": 0.01649104417227555,
            "auditor_fp_violation": 0.009220608993748746,
            "ave_precision_score": 0.8418604161131377,
            "fpr": 0.10635964912280702,
            "logloss": 0.700317018638924,
            "mae": 0.26765376185843154,
            "precision": 0.7882096069868996,
            "recall": 0.7568134171907757
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8546871993350879,
            "auditor_fn_violation": 0.013975473308986141,
            "auditor_fp_violation": 0.01590898743974061,
            "ave_precision_score": 0.8548976083819216,
            "fpr": 0.12952799121844127,
            "logloss": 0.6472432047995933,
            "mae": 0.2678057476405841,
            "precision": 0.7596741344195519,
            "recall": 0.7819706498951782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 6832,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.46287027202443093,
            "auditor_fn_violation": 0.01602670197506344,
            "auditor_fp_violation": 0.026807320024198434,
            "ave_precision_score": 0.43697572848870836,
            "fpr": 0.3125,
            "logloss": 7.291436318101024,
            "mae": 0.5434999674253082,
            "precision": 0.4973544973544973,
            "recall": 0.5911949685534591
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.4640096182179034,
            "auditor_fn_violation": 0.012608532563796328,
            "auditor_fp_violation": 0.011523266577974284,
            "ave_precision_score": 0.43299959595686877,
            "fpr": 0.31394072447859495,
            "logloss": 7.956922258115859,
            "mae": 0.5471756199228024,
            "precision": 0.5034722222222222,
            "recall": 0.6079664570230608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8277146132662527,
            "auditor_fn_violation": 0.015658906175291486,
            "auditor_fp_violation": 0.014418229481750363,
            "ave_precision_score": 0.8280786242413777,
            "fpr": 0.14583333333333334,
            "logloss": 0.7405566268744486,
            "mae": 0.2720519841181172,
            "precision": 0.7422480620155039,
            "recall": 0.8029350104821803
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8301795614981362,
            "auditor_fn_violation": 0.014490952647239543,
            "auditor_fp_violation": 0.02206012534966893,
            "ave_precision_score": 0.8304571276102599,
            "fpr": 0.1668496158068057,
            "logloss": 0.7521331721458415,
            "mae": 0.2774420695518829,
            "precision": 0.7205882352941176,
            "recall": 0.8218029350104822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7726845776708902,
            "auditor_fn_violation": 0.016923204237007616,
            "auditor_fp_violation": 0.022509578544061305,
            "ave_precision_score": 0.7114310296952816,
            "fpr": 0.15350877192982457,
            "logloss": 3.7191550407047407,
            "mae": 0.29274805158316314,
            "precision": 0.7233201581027668,
            "recall": 0.7672955974842768
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7688086770045608,
            "auditor_fn_violation": 0.012666063739940676,
            "auditor_fp_violation": 0.019227364470096667,
            "ave_precision_score": 0.7044376837481763,
            "fpr": 0.1712403951701427,
            "logloss": 3.980594919804321,
            "mae": 0.2927473172587747,
            "precision": 0.708411214953271,
            "recall": 0.7945492662473794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6841506552616614,
            "auditor_fn_violation": 0.008978814961933155,
            "auditor_fp_violation": 0.013145291389393023,
            "ave_precision_score": 0.6895992707247394,
            "fpr": 0.08771929824561403,
            "logloss": 5.496618162265466,
            "mae": 0.39874835532669967,
            "precision": 0.738562091503268,
            "recall": 0.47379454926624737
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6806063162479876,
            "auditor_fn_violation": 0.011342846688620562,
            "auditor_fp_violation": 0.0198546186648591,
            "ave_precision_score": 0.6860254987780098,
            "fpr": 0.09330406147091108,
            "logloss": 6.056052324212461,
            "mae": 0.40763398723352806,
            "precision": 0.714765100671141,
            "recall": 0.44654088050314467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.5391230615668219,
            "auditor_fn_violation": 0.009450053330390968,
            "auditor_fp_violation": 0.007045271224037105,
            "ave_precision_score": 0.5343962126595828,
            "fpr": 0.2719298245614035,
            "logloss": 3.3446586643876928,
            "mae": 0.41930124884966347,
            "precision": 0.6025641025641025,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.5109804396360011,
            "auditor_fn_violation": 0.011096613254722736,
            "auditor_fp_violation": 0.0075675183497144515,
            "ave_precision_score": 0.508917206610009,
            "fpr": 0.305159165751921,
            "logloss": 3.631222117353489,
            "mae": 0.4446411591756655,
            "precision": 0.5775075987841946,
            "recall": 0.7966457023060797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6343756066476935,
            "auditor_fn_violation": 0.0075765934753025095,
            "auditor_fp_violation": 0.003518854607783833,
            "ave_precision_score": 0.6024398948869079,
            "fpr": 0.20175438596491227,
            "logloss": 3.754008067186285,
            "mae": 0.3385204857869342,
            "precision": 0.6731793960923623,
            "recall": 0.7945492662473794
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6248458958796088,
            "auditor_fn_violation": 0.012891585950426542,
            "auditor_fp_violation": 0.004405954868048987,
            "ave_precision_score": 0.5907604082000644,
            "fpr": 0.2261251372118551,
            "logloss": 3.8713477299303416,
            "mae": 0.34938448966836066,
            "precision": 0.6549413735343383,
            "recall": 0.8197064989517819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7610381451144358,
            "auditor_fn_violation": 0.017240428114310938,
            "auditor_fp_violation": 0.02583686227061908,
            "ave_precision_score": 0.7182036249131855,
            "fpr": 0.14035087719298245,
            "logloss": 4.15611440473275,
            "mae": 0.2907876920509899,
            "precision": 0.7344398340248963,
            "recall": 0.7421383647798742
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7630780444813574,
            "auditor_fn_violation": 0.012564808869926614,
            "auditor_fp_violation": 0.0184483552282143,
            "ave_precision_score": 0.7137003696485236,
            "fpr": 0.16136114160263446,
            "logloss": 4.3874196881930665,
            "mae": 0.2902214045504583,
            "precision": 0.7183908045977011,
            "recall": 0.7861635220125787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.6122895090769207,
            "auditor_fn_violation": 0.007530619000331028,
            "auditor_fp_violation": 0.018040431538616657,
            "ave_precision_score": 0.6051898612333539,
            "fpr": 0.02850877192982456,
            "logloss": 5.261171116461834,
            "mae": 0.5169447796351847,
            "precision": 0.5094339622641509,
            "recall": 0.05660377358490566
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.6452203398191347,
            "auditor_fn_violation": 0.016631112399809463,
            "auditor_fp_violation": 0.017421479409369358,
            "ave_precision_score": 0.6351989230667476,
            "fpr": 0.026344676180021953,
            "logloss": 5.137863623858311,
            "mae": 0.5102703878876028,
            "precision": 0.52,
            "recall": 0.05450733752620545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6878286587006344,
            "auditor_fn_violation": 0.0021929824561403477,
            "auditor_fp_violation": 0.0034381931841097006,
            "ave_precision_score": 0.6932650362566142,
            "fpr": 0.03070175438596491,
            "logloss": 5.684562512848834,
            "mae": 0.40904974382623077,
            "precision": 0.8502673796791443,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6782850148699748,
            "auditor_fn_violation": 0.011736359933447939,
            "auditor_fp_violation": 0.0042870800811383655,
            "ave_precision_score": 0.683725184152305,
            "fpr": 0.031833150384193196,
            "logloss": 6.266467317302168,
            "mae": 0.4191447950043881,
            "precision": 0.8333333333333334,
            "recall": 0.3039832285115304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.561339730966944,
            "auditor_fn_violation": 0.003241200485490458,
            "auditor_fp_violation": 0.009449989917322044,
            "ave_precision_score": 0.5117873232589544,
            "fpr": 0.3267543859649123,
            "logloss": 5.490013672867935,
            "mae": 0.4313144210725937,
            "precision": 0.5779036827195467,
            "recall": 0.8553459119496856
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.5619836828969894,
            "auditor_fn_violation": 0.00337592941615061,
            "auditor_fp_violation": 0.0040468012565318115,
            "ave_precision_score": 0.5056386779360817,
            "fpr": 0.32491767288693746,
            "logloss": 6.142328874134034,
            "mae": 0.4290072842237549,
            "precision": 0.5830985915492958,
            "recall": 0.8679245283018868
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.46138161722426596,
            "auditor_fn_violation": 0.02554341829416309,
            "auditor_fp_violation": 0.02836257309941521,
            "ave_precision_score": 0.43399026037728644,
            "fpr": 0.27521929824561403,
            "logloss": 8.62426494560325,
            "mae": 0.5567295611233992,
            "precision": 0.48879837067209775,
            "recall": 0.5031446540880503
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.46579337261318576,
            "auditor_fn_violation": 0.027255970010148508,
            "auditor_fp_violation": 0.022560917005164733,
            "ave_precision_score": 0.4346705690138435,
            "fpr": 0.26344676180021953,
            "logloss": 9.07427867150384,
            "mae": 0.5495806924337584,
            "precision": 0.5071868583162218,
            "recall": 0.5178197064989518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7703339806420151,
            "auditor_fn_violation": 0.014068189341277728,
            "auditor_fp_violation": 0.022721314781205888,
            "ave_precision_score": 0.7472180498515577,
            "fpr": 0.19298245614035087,
            "logloss": 3.135743791335277,
            "mae": 0.30944187567335807,
            "precision": 0.6823104693140795,
            "recall": 0.7924528301886793
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7650360695809555,
            "auditor_fn_violation": 0.016536761270932714,
            "auditor_fp_violation": 0.020021549216691047,
            "ave_precision_score": 0.7359598392789545,
            "fpr": 0.20856201975850713,
            "logloss": 3.521841052954876,
            "mae": 0.3113226985021557,
            "precision": 0.6718480138169257,
            "recall": 0.8155136268343816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7229055912219189,
            "auditor_fn_violation": 0.01613704071499504,
            "auditor_fp_violation": 0.022640653357531768,
            "ave_precision_score": 0.7028119802190885,
            "fpr": 0.1524122807017544,
            "logloss": 2.211149741387247,
            "mae": 0.28572676630413524,
            "precision": 0.7326923076923076,
            "recall": 0.7987421383647799
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7268603397233682,
            "auditor_fn_violation": 0.010051847095941292,
            "auditor_fp_violation": 0.02427069053604942,
            "ave_precision_score": 0.7073257739266265,
            "fpr": 0.1800219538968167,
            "logloss": 2.1128401565645154,
            "mae": 0.2841111947004585,
            "precision": 0.7087033747779752,
            "recall": 0.8364779874213837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 6832,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8068748310576644,
            "auditor_fn_violation": 0.01895757475449631,
            "auditor_fp_violation": 0.018491631377293816,
            "ave_precision_score": 0.8034479490244192,
            "fpr": 0.12938596491228072,
            "logloss": 0.9695239473994915,
            "mae": 0.26763577906977415,
            "precision": 0.7596741344195519,
            "recall": 0.7819706498951782
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.800988330451283,
            "auditor_fn_violation": 0.01311020441977508,
            "auditor_fp_violation": 0.023329809243905777,
            "ave_precision_score": 0.7966439686337922,
            "fpr": 0.15587266739846323,
            "logloss": 1.0612570513842665,
            "mae": 0.2757372723278355,
            "precision": 0.7315689981096408,
            "recall": 0.8113207547169812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8570250900888475,
            "auditor_fn_violation": 0.025839953657729228,
            "auditor_fp_violation": 0.013162936075821738,
            "ave_precision_score": 0.8574138864951455,
            "fpr": 0.09429824561403509,
            "logloss": 0.7839167316969167,
            "mae": 0.26780988041742093,
            "precision": 0.8071748878923767,
            "recall": 0.7547169811320755
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8677382133235356,
            "auditor_fn_violation": 0.017466465077425455,
            "auditor_fp_violation": 0.01552454132037008,
            "ave_precision_score": 0.8679453506181379,
            "fpr": 0.1207464324917673,
            "logloss": 0.6286910349098436,
            "mae": 0.2678080112448634,
            "precision": 0.7674418604651163,
            "recall": 0.7610062893081762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7997084425135619,
            "auditor_fn_violation": 0.01906561477067932,
            "auditor_fp_violation": 0.013442730389191372,
            "ave_precision_score": 0.7911549937193127,
            "fpr": 0.11732456140350878,
            "logloss": 1.187219200311567,
            "mae": 0.27338025734025684,
            "precision": 0.7733050847457628,
            "recall": 0.7651991614255765
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7970142645148037,
            "auditor_fn_violation": 0.014428818977003639,
            "auditor_fp_violation": 0.017181200584762784,
            "ave_precision_score": 0.7882430201125166,
            "fpr": 0.1437980241492865,
            "logloss": 1.2250044777015898,
            "mae": 0.27691067043286255,
            "precision": 0.7416173570019724,
            "recall": 0.7882599580712788
        }
    }
]