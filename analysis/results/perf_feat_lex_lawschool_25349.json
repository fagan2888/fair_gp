[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8387960802815297,
            "auditor_fn_violation": 0.011183300575089178,
            "auditor_fp_violation": 0.01817625458996328,
            "ave_precision_score": 0.8391044722236433,
            "fpr": 0.16666666666666666,
            "logloss": 0.5618227088516228,
            "mae": 0.30217350149892774,
            "precision": 0.7132075471698113,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8548449933993035,
            "auditor_fn_violation": 0.013890956110811365,
            "auditor_fp_violation": 0.016055349824593876,
            "ave_precision_score": 0.8551548025723917,
            "fpr": 0.14709110867178923,
            "logloss": 0.5133267373616035,
            "mae": 0.28321856624278063,
            "precision": 0.7437858508604207,
            "recall": 0.8241525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8427387314736559,
            "auditor_fn_violation": 0.01939106063914975,
            "auditor_fp_violation": 0.016896164830681352,
            "ave_precision_score": 0.8429818185741204,
            "fpr": 0.10635964912280702,
            "logloss": 0.6243713328751926,
            "mae": 0.27389799425783057,
            "precision": 0.7858719646799117,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8247720041034399,
            "auditor_fn_violation": 0.01860499730227539,
            "auditor_fp_violation": 0.014340045358051057,
            "ave_precision_score": 0.8253979047598796,
            "fpr": 0.10976948408342481,
            "logloss": 0.6393737646305334,
            "mae": 0.2684460500862406,
            "precision": 0.7821350762527233,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8186321955781343,
            "auditor_fn_violation": 0.0214566499235641,
            "auditor_fp_violation": 0.013022745818033463,
            "ave_precision_score": 0.8190394262405708,
            "fpr": 0.09758771929824561,
            "logloss": 0.6176859146028582,
            "mae": 0.32493354805561875,
            "precision": 0.7834549878345499,
            "recall": 0.6680497925311203
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8517669182445345,
            "auditor_fn_violation": 0.01588401644681762,
            "auditor_fp_violation": 0.011006953734287839,
            "ave_precision_score": 0.8522121349320817,
            "fpr": 0.06366630076838639,
            "logloss": 0.5458650587323206,
            "mae": 0.29737477302885335,
            "precision": 0.8473684210526315,
            "recall": 0.6822033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8448039829018388,
            "auditor_fn_violation": 0.021411152362233392,
            "auditor_fp_violation": 0.024464504283965727,
            "ave_precision_score": 0.8450551173855643,
            "fpr": 0.12280701754385964,
            "logloss": 0.535615461661924,
            "mae": 0.3203385691750762,
            "precision": 0.759656652360515,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8621670605379994,
            "auditor_fn_violation": 0.010279261009507153,
            "auditor_fp_violation": 0.0064686481850528485,
            "ave_precision_score": 0.8624502154344502,
            "fpr": 0.09110867178924259,
            "logloss": 0.482900451373137,
            "mae": 0.29918629697942645,
            "precision": 0.8105022831050228,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8021485812116573,
            "auditor_fn_violation": 0.017648504040183446,
            "auditor_fp_violation": 0.018166054671562626,
            "ave_precision_score": 0.8035586158228529,
            "fpr": 0.10635964912280702,
            "logloss": 0.6198476548309045,
            "mae": 0.33928227080778334,
            "precision": 0.7738927738927739,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8478801063447183,
            "auditor_fn_violation": 0.01239557945264099,
            "auditor_fp_violation": 0.005638500833898018,
            "ave_precision_score": 0.848563169866998,
            "fpr": 0.06915477497255763,
            "logloss": 0.5267225698691839,
            "mae": 0.3071004426493396,
            "precision": 0.8428927680798005,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.799235271893297,
            "auditor_fn_violation": 0.013913154254931935,
            "auditor_fp_violation": 0.01945889432884537,
            "ave_precision_score": 0.7579215127646773,
            "fpr": 0.13267543859649122,
            "logloss": 4.907759742092306,
            "mae": 0.2942734370502241,
            "precision": 0.7363834422657952,
            "recall": 0.7012448132780082
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7584831152523541,
            "auditor_fn_violation": 0.012469999441850083,
            "auditor_fp_violation": 0.022431481587981878,
            "ave_precision_score": 0.7023208420064796,
            "fpr": 0.17014270032930845,
            "logloss": 5.750677652451349,
            "mae": 0.3251109662393017,
            "precision": 0.6849593495934959,
            "recall": 0.7139830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8299832233809641,
            "auditor_fn_violation": 0.0011146902526024598,
            "auditor_fp_violation": 0.01368064055487556,
            "ave_precision_score": 0.8303785092291558,
            "fpr": 0.11732456140350878,
            "logloss": 0.5605349421331338,
            "mae": 0.3185130280928621,
            "precision": 0.7648351648351648,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8473227281909073,
            "auditor_fn_violation": 0.0034698319968743687,
            "auditor_fp_violation": 0.011844602416929008,
            "ave_precision_score": 0.8476928701511001,
            "fpr": 0.09330406147091108,
            "logloss": 0.5089692345667359,
            "mae": 0.30023401463532084,
            "precision": 0.804147465437788,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8408098713944192,
            "auditor_fn_violation": 0.0016652107447040923,
            "auditor_fp_violation": 0.008743880048959606,
            "ave_precision_score": 0.8410680564163017,
            "fpr": 0.11732456140350878,
            "logloss": 0.5458867640321116,
            "mae": 0.31639910794987564,
            "precision": 0.7668845315904139,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8540837830101544,
            "auditor_fn_violation": 0.0033628532623862792,
            "auditor_fp_violation": 0.010536870294477271,
            "ave_precision_score": 0.8543405340721764,
            "fpr": 0.09549945115257959,
            "logloss": 0.49825494689877775,
            "mae": 0.29705459248626237,
            "precision": 0.8022727272727272,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.810087438836363,
            "auditor_fn_violation": 0.004563405401470482,
            "auditor_fp_violation": 0.017406160750714005,
            "ave_precision_score": 0.8108465165301815,
            "fpr": 0.20614035087719298,
            "logloss": 0.5877908259032537,
            "mae": 0.38203429348415513,
            "precision": 0.6642857142857143,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.818284806379781,
            "auditor_fn_violation": 0.009311801149788837,
            "auditor_fp_violation": 0.025812081644491898,
            "ave_precision_score": 0.8187863532981503,
            "fpr": 0.18990120746432493,
            "logloss": 0.5546950207030229,
            "mae": 0.36961258640339034,
            "precision": 0.6882882882882883,
            "recall": 0.809322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8404110225182019,
            "auditor_fn_violation": 0.014440925966368206,
            "auditor_fp_violation": 0.02051458588331294,
            "ave_precision_score": 0.84065731760734,
            "fpr": 0.12609649122807018,
            "logloss": 0.6448994603160201,
            "mae": 0.2691507305502502,
            "precision": 0.7619047619047619,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8192482424990335,
            "auditor_fn_violation": 0.01450259539712367,
            "auditor_fp_violation": 0.01316483675852464,
            "ave_precision_score": 0.8198828697029064,
            "fpr": 0.1350164654226125,
            "logloss": 0.6720733744197491,
            "mae": 0.26855959873530877,
            "precision": 0.7525150905432596,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8568188135124015,
            "auditor_fn_violation": 0.008649086408968491,
            "auditor_fp_violation": 0.010358017135862915,
            "ave_precision_score": 0.85703021812255,
            "fpr": 0.041666666666666664,
            "logloss": 0.6672350531298137,
            "mae": 0.32845602089096165,
            "precision": 0.8720538720538721,
            "recall": 0.5373443983402489
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8643825231845068,
            "auditor_fn_violation": 0.011444398965562158,
            "auditor_fp_violation": 0.0059360536495227925,
            "ave_precision_score": 0.8646486852851243,
            "fpr": 0.04171240395170143,
            "logloss": 0.6121275708735374,
            "mae": 0.31180614043350086,
            "precision": 0.8737541528239202,
            "recall": 0.5572033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8691486061411771,
            "auditor_fn_violation": 0.008417048846181847,
            "auditor_fp_violation": 0.015886372909016733,
            "ave_precision_score": 0.8693464640213504,
            "fpr": 0.15350877192982457,
            "logloss": 0.5144545647935501,
            "mae": 0.2743245732937092,
            "precision": 0.7440585009140768,
            "recall": 0.8443983402489627
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8680610042670804,
            "auditor_fn_violation": 0.011981618262665354,
            "auditor_fp_violation": 0.014097502306659432,
            "ave_precision_score": 0.8686081134647036,
            "fpr": 0.1437980241492865,
            "logloss": 0.4849119794990648,
            "mae": 0.261023888072757,
            "precision": 0.7551401869158878,
            "recall": 0.8559322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 25349,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.828330281660402,
            "auditor_fn_violation": 0.02187522748780666,
            "auditor_fp_violation": 0.02205732354141168,
            "ave_precision_score": 0.8286683290912783,
            "fpr": 0.10635964912280702,
            "logloss": 0.5687840295590271,
            "mae": 0.3374763669802505,
            "precision": 0.7749419953596288,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8603461201402163,
            "auditor_fn_violation": 0.015539823996725523,
            "auditor_fp_violation": 0.009784236702014611,
            "ave_precision_score": 0.8605831429234366,
            "fpr": 0.07354555433589462,
            "logloss": 0.500816415317878,
            "mae": 0.3093065787134866,
            "precision": 0.8381642512077294,
            "recall": 0.7351694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.818403859469096,
            "auditor_fn_violation": 0.014657039382689092,
            "auditor_fp_violation": 0.014871481028151777,
            "ave_precision_score": 0.8197290635597098,
            "fpr": 0.1162280701754386,
            "logloss": 0.5610975664839143,
            "mae": 0.3342569867131635,
            "precision": 0.7670329670329671,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8658820106616343,
            "auditor_fn_violation": 0.010904854043796163,
            "auditor_fp_violation": 0.006858717422342465,
            "ave_precision_score": 0.8660789980626171,
            "fpr": 0.08232711306256861,
            "logloss": 0.4873537786457292,
            "mae": 0.3048363460816185,
            "precision": 0.8271889400921659,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6878769224854551,
            "auditor_fn_violation": 0.018785943073451265,
            "auditor_fp_violation": 0.027463280293757653,
            "ave_precision_score": 0.6892404932249981,
            "fpr": 0.19298245614035087,
            "logloss": 0.7948260476074832,
            "mae": 0.38052936271726556,
            "precision": 0.6621880998080614,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7167577646288494,
            "auditor_fn_violation": 0.017460789968185456,
            "auditor_fp_violation": 0.008544016562939932,
            "ave_precision_score": 0.7182010324299268,
            "fpr": 0.1668496158068057,
            "logloss": 0.7445631922265625,
            "mae": 0.34822401413734916,
            "precision": 0.7019607843137254,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7764633148583665,
            "auditor_fn_violation": 0.07586263376283031,
            "auditor_fp_violation": 0.056068951448388415,
            "ave_precision_score": 0.7736495087426642,
            "fpr": 0.17105263157894737,
            "logloss": 4.233380772948161,
            "mae": 0.38122099072553967,
            "precision": 0.6680851063829787,
            "recall": 0.6514522821576764
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7946473789237449,
            "auditor_fn_violation": 0.06871755753595417,
            "auditor_fp_violation": 0.051621662845155014,
            "ave_precision_score": 0.790804870545851,
            "fpr": 0.14709110867178923,
            "logloss": 3.7442849386460484,
            "mae": 0.3548291526186872,
            "precision": 0.7086956521739131,
            "recall": 0.690677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7975666632671841,
            "auditor_fn_violation": 0.018371915265341775,
            "auditor_fp_violation": 0.014264585883312931,
            "ave_precision_score": 0.7979510106684353,
            "fpr": 0.15460526315789475,
            "logloss": 0.6329257630463191,
            "mae": 0.3503715953370454,
            "precision": 0.7218934911242604,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8430616090919509,
            "auditor_fn_violation": 0.010488567229157756,
            "auditor_fp_violation": 0.007961413150834276,
            "ave_precision_score": 0.8434626789516498,
            "fpr": 0.10318331503841932,
            "logloss": 0.5332468532590985,
            "mae": 0.31897466585784334,
            "precision": 0.7956521739130434,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8183584608811969,
            "auditor_fn_violation": 0.02218006114872243,
            "auditor_fp_violation": 0.021858425132598943,
            "ave_precision_score": 0.818683384428143,
            "fpr": 0.13486842105263158,
            "logloss": 0.5613004001126548,
            "mae": 0.34495678788899614,
            "precision": 0.7410526315789474,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8527583701890566,
            "auditor_fn_violation": 0.013451413049545106,
            "auditor_fp_violation": 0.009919260668768705,
            "ave_precision_score": 0.8532353518601874,
            "fpr": 0.11306256860592755,
            "logloss": 0.49162403461444826,
            "mae": 0.31528476577785797,
            "precision": 0.783157894736842,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8069104513440476,
            "auditor_fn_violation": 0.01919087136929461,
            "auditor_fp_violation": 0.010745614035087723,
            "ave_precision_score": 0.8072984827618562,
            "fpr": 0.14144736842105263,
            "logloss": 0.6172594081021124,
            "mae": 0.3474902911809949,
            "precision": 0.7323651452282157,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8568437194119068,
            "auditor_fn_violation": 0.008558298759046687,
            "auditor_fp_violation": 0.008381487714069246,
            "ave_precision_score": 0.8571114632671504,
            "fpr": 0.09549945115257959,
            "logloss": 0.515241927436426,
            "mae": 0.31356230656819317,
            "precision": 0.8018223234624146,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8189150374680745,
            "auditor_fn_violation": 0.011535906675402198,
            "auditor_fp_violation": 0.012392900856793149,
            "ave_precision_score": 0.8192716009354015,
            "fpr": 0.19736842105263158,
            "logloss": 0.5986998553130444,
            "mae": 0.3198446595988412,
            "precision": 0.689119170984456,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8309680248798456,
            "auditor_fn_violation": 0.008514111890453776,
            "auditor_fp_violation": 0.012762265302091125,
            "ave_precision_score": 0.8313729362551836,
            "fpr": 0.17233809001097694,
            "logloss": 0.5442915706287655,
            "mae": 0.3008971980609471,
            "precision": 0.7155797101449275,
            "recall": 0.836864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.825559745686476,
            "auditor_fn_violation": 0.016511065006915633,
            "auditor_fp_violation": 0.01660036719706243,
            "ave_precision_score": 0.8258293536819129,
            "fpr": 0.1206140350877193,
            "logloss": 0.5681604983790154,
            "mae": 0.3364940813102804,
            "precision": 0.7587719298245614,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8604209536302707,
            "auditor_fn_violation": 0.008600160002976807,
            "auditor_fp_violation": 0.005646002165384357,
            "ave_precision_score": 0.8606579816260651,
            "fpr": 0.08232711306256861,
            "logloss": 0.4937730526758312,
            "mae": 0.3084104011161406,
            "precision": 0.8235294117647058,
            "recall": 0.7415254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8347428285381527,
            "auditor_fn_violation": 0.01452509645483003,
            "auditor_fp_violation": 0.006117401060791515,
            "ave_precision_score": 0.8350028307702424,
            "fpr": 0.03618421052631579,
            "logloss": 0.7336740870996145,
            "mae": 0.35532030292393246,
            "precision": 0.875,
            "recall": 0.47925311203319504
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8438833911849457,
            "auditor_fn_violation": 0.015844480827550293,
            "auditor_fp_violation": 0.01061188360934066,
            "ave_precision_score": 0.8443813348432072,
            "fpr": 0.03293084522502744,
            "logloss": 0.6593739017042655,
            "mae": 0.33567987686808953,
            "precision": 0.8884758364312267,
            "recall": 0.5063559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8282747113085714,
            "auditor_fn_violation": 0.012985004003785397,
            "auditor_fp_violation": 0.01484088127294982,
            "ave_precision_score": 0.8285559343164488,
            "fpr": 0.13157894736842105,
            "logloss": 0.5708675505276589,
            "mae": 0.3375823876331356,
            "precision": 0.7468354430379747,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8513922027865292,
            "auditor_fn_violation": 0.008730394984092726,
            "auditor_fp_violation": 0.006413638420819698,
            "ave_precision_score": 0.8517327314792748,
            "fpr": 0.10208562019758508,
            "logloss": 0.5031380244569436,
            "mae": 0.31220674912806123,
            "precision": 0.7956043956043956,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8560316439366749,
            "auditor_fn_violation": 0.007607192254495163,
            "auditor_fp_violation": 0.013509791921664627,
            "ave_precision_score": 0.8562405273726152,
            "fpr": 0.10526315789473684,
            "logloss": 0.5922504288446455,
            "mae": 0.2646300415614068,
            "precision": 0.7917570498915402,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8374542583104583,
            "auditor_fn_violation": 0.01597704143332899,
            "auditor_fp_violation": 0.008276469073260512,
            "ave_precision_score": 0.8379837247530704,
            "fpr": 0.1119648737650933,
            "logloss": 0.6038274609018204,
            "mae": 0.2608148346729885,
            "precision": 0.7834394904458599,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8072235973232077,
            "auditor_fn_violation": 0.015082441581131254,
            "auditor_fp_violation": 0.015962872297021626,
            "ave_precision_score": 0.7962577720624453,
            "fpr": 0.14692982456140352,
            "logloss": 1.742167672857711,
            "mae": 0.2666069456458684,
            "precision": 0.7392996108949417,
            "recall": 0.7883817427385892
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7893796804181231,
            "auditor_fn_violation": 0.015737502093062197,
            "auditor_fp_violation": 0.01651543148908932,
            "ave_precision_score": 0.7778246182697426,
            "fpr": 0.150384193194292,
            "logloss": 1.9312974562963308,
            "mae": 0.27092033484567923,
            "precision": 0.7344961240310077,
            "recall": 0.8029661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8347495862892458,
            "auditor_fn_violation": 0.02156584407075781,
            "auditor_fp_violation": 0.017503059975520197,
            "ave_precision_score": 0.8350360159332615,
            "fpr": 0.125,
            "logloss": 0.5639628093873905,
            "mae": 0.3208163054906324,
            "precision": 0.7564102564102564,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8556188004561871,
            "auditor_fn_violation": 0.015163072801354448,
            "auditor_fp_violation": 0.0065511628314025745,
            "ave_precision_score": 0.8561712576478792,
            "fpr": 0.09110867178924259,
            "logloss": 0.49490455907318687,
            "mae": 0.29523533962410903,
            "precision": 0.8126410835214447,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8030278570181514,
            "auditor_fn_violation": 0.004859139550120117,
            "auditor_fp_violation": 0.012550999592003264,
            "ave_precision_score": 0.8043567828990261,
            "fpr": 0.10197368421052631,
            "logloss": 0.6091388202138059,
            "mae": 0.32108542646816013,
            "precision": 0.777511961722488,
            "recall": 0.6742738589211619
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8419594571685343,
            "auditor_fn_violation": 0.0094513386295559,
            "auditor_fp_violation": 0.007721370543271433,
            "ave_precision_score": 0.842392293471194,
            "fpr": 0.07903402854006586,
            "logloss": 0.5210131653838788,
            "mae": 0.29268926313697974,
            "precision": 0.8222222222222222,
            "recall": 0.7055084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8239200085721057,
            "auditor_fn_violation": 0.019720917958797407,
            "auditor_fp_violation": 0.021486128110975115,
            "ave_precision_score": 0.8243283153606831,
            "fpr": 0.12171052631578948,
            "logloss": 0.5609787100998495,
            "mae": 0.3341533189104347,
            "precision": 0.756578947368421,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8625625263763239,
            "auditor_fn_violation": 0.011290907737818382,
            "auditor_fp_violation": 0.006081079391592011,
            "ave_precision_score": 0.8627990698432195,
            "fpr": 0.08232711306256861,
            "logloss": 0.487892100017463,
            "mae": 0.30513838891787953,
            "precision": 0.8263888888888888,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7807999330790133,
            "auditor_fn_violation": 0.01411334352478707,
            "auditor_fp_violation": 0.005915952672378621,
            "ave_precision_score": 0.781168743875451,
            "fpr": 0.05043859649122807,
            "logloss": 1.0709932108427525,
            "mae": 0.3779417407908041,
            "precision": 0.8203125,
            "recall": 0.43568464730290457
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7904076456394066,
            "auditor_fn_violation": 0.012453720069210606,
            "auditor_fp_violation": 0.003690655091278702,
            "ave_precision_score": 0.7908605961168911,
            "fpr": 0.04061470911086718,
            "logloss": 0.9672919194905188,
            "mae": 0.3608605196766685,
            "precision": 0.8495934959349594,
            "recall": 0.4427966101694915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.823439098415508,
            "auditor_fn_violation": 0.0017471063550993707,
            "auditor_fp_violation": 0.012948796409628722,
            "ave_precision_score": 0.8237072351281465,
            "fpr": 0.1337719298245614,
            "logloss": 0.5962351755418563,
            "mae": 0.3275506501877476,
            "precision": 0.7415254237288136,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8467999099575503,
            "auditor_fn_violation": 0.012883960631825713,
            "auditor_fp_violation": 0.008671539198207684,
            "ave_precision_score": 0.8472350892548866,
            "fpr": 0.09659714599341383,
            "logloss": 0.5193741510695368,
            "mae": 0.3040927448878617,
            "precision": 0.7939110070257611,
            "recall": 0.7182203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8257783945834489,
            "auditor_fn_violation": 0.010196003494212713,
            "auditor_fp_violation": 0.01376478988168095,
            "ave_precision_score": 0.8260989174294944,
            "fpr": 0.16885964912280702,
            "logloss": 0.5963647071965325,
            "mae": 0.3086519666854305,
            "precision": 0.7230215827338129,
            "recall": 0.8340248962655602
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.853716674923612,
            "auditor_fn_violation": 0.010286237883495508,
            "auditor_fp_violation": 0.01982351867456474,
            "ave_precision_score": 0.8539283518567644,
            "fpr": 0.1734357848518112,
            "logloss": 0.5348579912135526,
            "mae": 0.2921989395633431,
            "precision": 0.7213403880070547,
            "recall": 0.8665254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.619242315863545,
            "auditor_fn_violation": 0.0189861323433064,
            "auditor_fp_violation": 0.023676560587515313,
            "ave_precision_score": 0.5735105395315556,
            "fpr": 0.2576754385964912,
            "logloss": 4.40060138146009,
            "mae": 0.39205675756710934,
            "precision": 0.6293375394321766,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6427621253691295,
            "auditor_fn_violation": 0.01355374053470762,
            "auditor_fp_violation": 0.014162513846207703,
            "ave_precision_score": 0.5984105873403086,
            "fpr": 0.21514818880351264,
            "logloss": 4.009525202827619,
            "mae": 0.35856283328656424,
            "precision": 0.6722408026755853,
            "recall": 0.8516949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7600182159295119,
            "auditor_fn_violation": 0.04479234913008663,
            "auditor_fp_violation": 0.07156772745818034,
            "ave_precision_score": 0.7604928230644232,
            "fpr": 0.28728070175438597,
            "logloss": 0.8318977302972939,
            "mae": 0.36011459137692947,
            "precision": 0.6124260355029586,
            "recall": 0.8589211618257261
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7445057810155467,
            "auditor_fn_violation": 0.037675119537107664,
            "auditor_fp_violation": 0.05581240670218967,
            "ave_precision_score": 0.7449989905141656,
            "fpr": 0.29088913282107576,
            "logloss": 0.8624434026765248,
            "mae": 0.35652700060125925,
            "precision": 0.6108663729809104,
            "recall": 0.8813559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8165727338244619,
            "auditor_fn_violation": 0.0058373371187304375,
            "auditor_fp_violation": 0.008685230518155854,
            "ave_precision_score": 0.8168538551135933,
            "fpr": 0.12171052631578948,
            "logloss": 0.6343746992613921,
            "mae": 0.3299305769187572,
            "precision": 0.7482993197278912,
            "recall": 0.6846473029045643
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8316410715908203,
            "auditor_fn_violation": 0.013851420491544031,
            "auditor_fp_violation": 0.012842279504612067,
            "ave_precision_score": 0.8321568986368125,
            "fpr": 0.09659714599341383,
            "logloss": 0.5600988061606256,
            "mae": 0.30433029463366706,
            "precision": 0.7948717948717948,
            "recall": 0.722457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8199089268828716,
            "auditor_fn_violation": 0.001769855135764723,
            "auditor_fp_violation": 0.004824561403508765,
            "ave_precision_score": 0.8202483604727585,
            "fpr": 0.4243421052631579,
            "logloss": 1.959120023926684,
            "mae": 0.4244854755518948,
            "precision": 0.5505226480836237,
            "recall": 0.983402489626556
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.8450880896258322,
            "auditor_fn_violation": 0.002911682077806099,
            "auditor_fp_violation": 0.01092193864410934,
            "ave_precision_score": 0.8453295878203841,
            "fpr": 0.433589462129528,
            "logloss": 1.9200417201557591,
            "mae": 0.4392723595695013,
            "precision": 0.536928487690504,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8634384693943586,
            "auditor_fn_violation": 0.012079602533304217,
            "auditor_fp_violation": 0.0144201346389229,
            "ave_precision_score": 0.8636332987187637,
            "fpr": 0.12609649122807018,
            "logloss": 0.5064994735644104,
            "mae": 0.28245520088775694,
            "precision": 0.7695390781563126,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8625041188239913,
            "auditor_fn_violation": 0.011237418370574338,
            "auditor_fp_violation": 0.01458258840944268,
            "ave_precision_score": 0.8629505599152938,
            "fpr": 0.11745334796926454,
            "logloss": 0.4830119174890516,
            "mae": 0.2674783469613797,
            "precision": 0.7820773930753564,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8278288770843696,
            "auditor_fn_violation": 0.017832769163572838,
            "auditor_fp_violation": 0.015085679314565484,
            "ave_precision_score": 0.8280656411444783,
            "fpr": 0.13048245614035087,
            "logloss": 0.5830836391385755,
            "mae": 0.3424643438085791,
            "precision": 0.7457264957264957,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8447278912742331,
            "auditor_fn_violation": 0.010758339690040747,
            "auditor_fp_violation": 0.008218958865198576,
            "ave_precision_score": 0.8450988912185318,
            "fpr": 0.09879253567508232,
            "logloss": 0.512702733384927,
            "mae": 0.3158399352359634,
            "precision": 0.7991071428571429,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.5588812137517309,
            "auditor_fn_violation": 0.008030319574870786,
            "auditor_fp_violation": 0.005650754793961655,
            "ave_precision_score": 0.5527567229663625,
            "fpr": 0.22916666666666666,
            "logloss": 2.6445013839683598,
            "mae": 0.4487022404861305,
            "precision": 0.5925925925925926,
            "recall": 0.6307053941908713
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5552526092048642,
            "auditor_fn_violation": 0.017321252488418388,
            "auditor_fp_violation": 0.008946588019373444,
            "ave_precision_score": 0.5482577552193155,
            "fpr": 0.2217343578485181,
            "logloss": 2.37026263449721,
            "mae": 0.4571642527349307,
            "precision": 0.5877551020408164,
            "recall": 0.6101694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.46059551464737025,
            "auditor_fn_violation": 0.015460071340176169,
            "auditor_fp_violation": 0.009962770297837622,
            "ave_precision_score": 0.46053827912452217,
            "fpr": 0.2817982456140351,
            "logloss": 4.339151673132151,
            "mae": 0.5267746926873222,
            "precision": 0.5267034990791897,
            "recall": 0.5933609958506224
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.4942350294894652,
            "auditor_fn_violation": 0.011414165844945956,
            "auditor_fp_violation": 0.01236719517714395,
            "ave_precision_score": 0.489709116677921,
            "fpr": 0.22502744237102085,
            "logloss": 3.865230822789872,
            "mae": 0.4861159645025438,
            "precision": 0.5755693581780539,
            "recall": 0.5889830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 25349,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.745982083004257,
            "auditor_fn_violation": 0.021069920652253042,
            "auditor_fp_violation": 0.03238984088127296,
            "ave_precision_score": 0.7354696489029602,
            "fpr": 0.17763157894736842,
            "logloss": 1.523327421598557,
            "mae": 0.28463859114670714,
            "precision": 0.7112299465240641,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7256633883140806,
            "auditor_fn_violation": 0.019646877151202818,
            "auditor_fp_violation": 0.032405752020983725,
            "ave_precision_score": 0.7123398449601723,
            "fpr": 0.16794731064763996,
            "logloss": 1.770932006502964,
            "mae": 0.2758711042857357,
            "precision": 0.7208029197080292,
            "recall": 0.836864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7785396875879007,
            "auditor_fn_violation": 0.03217132561694693,
            "auditor_fp_violation": 0.013627090983272137,
            "ave_precision_score": 0.7791607035850643,
            "fpr": 0.06359649122807018,
            "logloss": 0.7207877388089962,
            "mae": 0.3650960188718097,
            "precision": 0.81875,
            "recall": 0.5435684647302904
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8387768972090024,
            "auditor_fn_violation": 0.03095871551098625,
            "auditor_fp_violation": 0.009566698088910783,
            "ave_precision_score": 0.8392141965824018,
            "fpr": 0.03732162458836443,
            "logloss": 0.6502442353889862,
            "mae": 0.339306549117257,
            "precision": 0.8815331010452961,
            "recall": 0.5360169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8411372905973514,
            "auditor_fn_violation": 0.014484148649632381,
            "auditor_fp_violation": 0.013999388004895967,
            "ave_precision_score": 0.8414046112204051,
            "fpr": 0.07675438596491228,
            "logloss": 0.6460081488397782,
            "mae": 0.2838642329193035,
            "precision": 0.8227848101265823,
            "recall": 0.6742738589211619
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8212828235532591,
            "auditor_fn_violation": 0.01621890639825858,
            "auditor_fp_violation": 0.007911404274258682,
            "ave_precision_score": 0.8219358214037414,
            "fpr": 0.08122941822173436,
            "logloss": 0.655418777837418,
            "mae": 0.2792636975759082,
            "precision": 0.8126582278481013,
            "recall": 0.6800847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8603754262911711,
            "auditor_fn_violation": 0.012652871806071195,
            "auditor_fp_violation": 0.022541819665442678,
            "ave_precision_score": 0.8605637529029248,
            "fpr": 0.17105263157894737,
            "logloss": 0.5209391384179677,
            "mae": 0.29788253611344806,
            "precision": 0.7248677248677249,
            "recall": 0.8526970954356846
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8630227417579845,
            "auditor_fn_violation": 0.016697985078792162,
            "auditor_fp_violation": 0.011687074455715893,
            "ave_precision_score": 0.8636091449303509,
            "fpr": 0.14050493962678376,
            "logloss": 0.48724101412524384,
            "mae": 0.27991003959435096,
            "precision": 0.7607476635514019,
            "recall": 0.8622881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8317507559897064,
            "auditor_fn_violation": 0.014070120841522893,
            "auditor_fp_violation": 0.017105263157894735,
            "ave_precision_score": 0.8319978475048646,
            "fpr": 0.14144736842105263,
            "logloss": 0.5651485924493459,
            "mae": 0.33878840115370656,
            "precision": 0.735655737704918,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8488674750783038,
            "auditor_fn_violation": 0.010776944687343023,
            "auditor_fp_violation": 0.006991240945267785,
            "ave_precision_score": 0.8492038299226987,
            "fpr": 0.10428100987925357,
            "logloss": 0.500084208179461,
            "mae": 0.313756827715862,
            "precision": 0.7925764192139738,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8461778144271033,
            "auditor_fn_violation": 0.020073524059110438,
            "auditor_fp_violation": 0.0158608731130151,
            "ave_precision_score": 0.8464518641130345,
            "fpr": 0.12171052631578948,
            "logloss": 0.5319843465070788,
            "mae": 0.30994812711944913,
            "precision": 0.7648305084745762,
            "recall": 0.7489626556016598
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8652382168202022,
            "auditor_fn_violation": 0.021851569331522453,
            "auditor_fp_violation": 0.012167159670841579,
            "ave_precision_score": 0.8655386223840176,
            "fpr": 0.10757409440175632,
            "logloss": 0.46672287800688644,
            "mae": 0.2841828960854929,
            "precision": 0.7910447761194029,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8569585981421595,
            "auditor_fn_violation": 0.02513057800101915,
            "auditor_fp_violation": 0.01885964912280702,
            "ave_precision_score": 0.8571705004658319,
            "fpr": 0.1074561403508772,
            "logloss": 0.5256815980276359,
            "mae": 0.29869846971233893,
            "precision": 0.7807606263982103,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.864826613667598,
            "auditor_fn_violation": 0.02204227055387077,
            "auditor_fp_violation": 0.009471681223417159,
            "ave_precision_score": 0.86518758567936,
            "fpr": 0.08781558726673985,
            "logloss": 0.483886339078345,
            "mae": 0.2804032950810311,
            "precision": 0.8190045248868778,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.8146075652954863,
            "auditor_fn_violation": 0.001769855135764723,
            "auditor_fp_violation": 0.006186250509995926,
            "ave_precision_score": 0.8149639612728499,
            "fpr": 0.42653508771929827,
            "logloss": 2.006948040336184,
            "mae": 0.42600582177308016,
            "precision": 0.5492468134414832,
            "recall": 0.983402489626556
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.8425995112384175,
            "auditor_fn_violation": 0.0030465683082475953,
            "auditor_fp_violation": 0.01092193864410934,
            "ave_precision_score": 0.8428425856909478,
            "fpr": 0.433589462129528,
            "logloss": 1.9693163827299582,
            "mae": 0.44068897230215587,
            "precision": 0.5374707259953162,
            "recall": 0.972457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8054784280264369,
            "auditor_fn_violation": 0.004804542476523258,
            "auditor_fp_violation": 0.012686148510811915,
            "ave_precision_score": 0.8068432331124117,
            "fpr": 0.13048245614035087,
            "logloss": 0.5946760731421175,
            "mae": 0.30447878764781316,
            "precision": 0.7586206896551724,
            "recall": 0.7759336099585062
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8263609470614117,
            "auditor_fn_violation": 0.006267558466204027,
            "auditor_fp_violation": 0.0135499051081567,
            "ave_precision_score": 0.8271633653702755,
            "fpr": 0.10757409440175632,
            "logloss": 0.5488397399264348,
            "mae": 0.28591245239432117,
            "precision": 0.7910447761194029,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8426928622532821,
            "auditor_fn_violation": 0.006337810293368275,
            "auditor_fp_violation": 0.01478988168094655,
            "ave_precision_score": 0.8429395712429044,
            "fpr": 0.12280701754385964,
            "logloss": 0.5626675171167089,
            "mae": 0.29852277441196157,
            "precision": 0.7637130801687764,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.848467884388605,
            "auditor_fn_violation": 0.009714134216450546,
            "auditor_fp_violation": 0.01164706735445542,
            "ave_precision_score": 0.8488223211819635,
            "fpr": 0.11964873765093303,
            "logloss": 0.518110482816353,
            "mae": 0.28333279406162426,
            "precision": 0.7729166666666667,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.695678428791042,
            "auditor_fn_violation": 0.013012302540583828,
            "auditor_fp_violation": 0.013667890656874742,
            "ave_precision_score": 0.5847345670674534,
            "fpr": 0.38596491228070173,
            "logloss": 9.512377442370967,
            "mae": 0.4520202488448163,
            "precision": 0.5446313065976714,
            "recall": 0.8734439834024896
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6781205575697498,
            "auditor_fn_violation": 0.009316452399114406,
            "auditor_fp_violation": 0.008321477062178543,
            "ave_precision_score": 0.5645275332223415,
            "fpr": 0.37980241492864986,
            "logloss": 9.635426501863712,
            "mae": 0.4525501639739401,
            "precision": 0.5392809587217043,
            "recall": 0.8580508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.817052401680279,
            "auditor_fn_violation": 0.001769855135764723,
            "auditor_fp_violation": 0.006186250509995926,
            "ave_precision_score": 0.8173946865644619,
            "fpr": 0.42653508771929827,
            "logloss": 2.0267738003471463,
            "mae": 0.4265832148447085,
            "precision": 0.5492468134414832,
            "recall": 0.983402489626556
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.8438430377428124,
            "auditor_fn_violation": 0.0036186719752925632,
            "auditor_fp_violation": 0.01092193864410934,
            "ave_precision_score": 0.8440880779293194,
            "fpr": 0.433589462129528,
            "logloss": 1.9896834281482951,
            "mae": 0.4418568194123229,
            "precision": 0.536928487690504,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7831692809591709,
            "auditor_fn_violation": 0.02303086554560676,
            "auditor_fp_violation": 0.03048245614035089,
            "ave_precision_score": 0.7835797919884435,
            "fpr": 0.1611842105263158,
            "logloss": 0.7499889592102094,
            "mae": 0.3137077127146831,
            "precision": 0.711764705882353,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7533717943765336,
            "auditor_fn_violation": 0.02595397123667418,
            "auditor_fp_violation": 0.029052656846590273,
            "ave_precision_score": 0.7545053049096007,
            "fpr": 0.18221734357848518,
            "logloss": 0.7935927247355136,
            "mae": 0.3180128328285389,
            "precision": 0.6937269372693727,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8393149858401412,
            "auditor_fn_violation": 0.019764140642061587,
            "auditor_fp_violation": 0.02244492044063648,
            "ave_precision_score": 0.8396038956860922,
            "fpr": 0.14912280701754385,
            "logloss": 0.5788466980353852,
            "mae": 0.27928842402985365,
            "precision": 0.7414448669201521,
            "recall": 0.8091286307053942
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8347332258615869,
            "auditor_fn_violation": 0.016949152542372885,
            "auditor_fp_violation": 0.015110182057315171,
            "ave_precision_score": 0.8354037574741999,
            "fpr": 0.141602634467618,
            "logloss": 0.5927163497100648,
            "mae": 0.2666495177807047,
            "precision": 0.7523992322456814,
            "recall": 0.8305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8110510458877638,
            "auditor_fn_violation": 0.01889058746451191,
            "auditor_fp_violation": 0.01869135046919625,
            "ave_precision_score": 0.8123966525774902,
            "fpr": 0.10855263157894737,
            "logloss": 0.5899369843894026,
            "mae": 0.33916465092050585,
            "precision": 0.7703016241299304,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8542266874022661,
            "auditor_fn_violation": 0.012986288116988222,
            "auditor_fp_violation": 0.006398635757847022,
            "ave_precision_score": 0.8547819826949128,
            "fpr": 0.07354555433589462,
            "logloss": 0.514384195915887,
            "mae": 0.30754957806926503,
            "precision": 0.8361858190709046,
            "recall": 0.7245762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8513085398450293,
            "auditor_fn_violation": 0.012680170342869621,
            "auditor_fp_violation": 0.016875764993880053,
            "ave_precision_score": 0.8515250410613162,
            "fpr": 0.14692982456140352,
            "logloss": 0.5234595395791062,
            "mae": 0.29478104718707565,
            "precision": 0.750465549348231,
            "recall": 0.8360995850622407
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8483701467986228,
            "auditor_fn_violation": 0.017479394965487734,
            "auditor_fp_violation": 0.011804595315668532,
            "ave_precision_score": 0.8488845519162523,
            "fpr": 0.1251372118551043,
            "logloss": 0.5029410715733791,
            "mae": 0.2785721813578007,
            "precision": 0.7786407766990291,
            "recall": 0.8495762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8082560215801203,
            "auditor_fn_violation": 0.003655729052922766,
            "auditor_fp_violation": 0.012905446756425949,
            "ave_precision_score": 0.8096491909326298,
            "fpr": 0.13048245614035087,
            "logloss": 0.5887061901416752,
            "mae": 0.30302946712969425,
            "precision": 0.758130081300813,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8342832883216427,
            "auditor_fn_violation": 0.008151314443059407,
            "auditor_fp_violation": 0.014780123471916273,
            "ave_precision_score": 0.835035427958283,
            "fpr": 0.11086717892425905,
            "logloss": 0.5454365416853073,
            "mae": 0.2857314387974906,
            "precision": 0.7860169491525424,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.794291732355241,
            "auditor_fn_violation": 0.027598820703210306,
            "auditor_fp_violation": 0.03276723786209711,
            "ave_precision_score": 0.7937104548845506,
            "fpr": 0.15350877192982457,
            "logloss": 0.8756030464029982,
            "mae": 0.3058776720976302,
            "precision": 0.7194388777555111,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7744158993578463,
            "auditor_fn_violation": 0.024526037693724537,
            "auditor_fp_violation": 0.02947023096599647,
            "ave_precision_score": 0.7730170036825267,
            "fpr": 0.1602634467618002,
            "logloss": 0.9890078230183756,
            "mae": 0.3011632603596994,
            "precision": 0.7186897880539499,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8350509304675499,
            "auditor_fn_violation": 0.02047617747688724,
            "auditor_fp_violation": 0.015554875560995515,
            "ave_precision_score": 0.8353491969165505,
            "fpr": 0.07675438596491228,
            "logloss": 0.6860693477960508,
            "mae": 0.287277144482942,
            "precision": 0.8181818181818182,
            "recall": 0.6535269709543569
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.810989091461904,
            "auditor_fn_violation": 0.013358388063033732,
            "auditor_fp_violation": 0.00811894111204739,
            "ave_precision_score": 0.8116035197966788,
            "fpr": 0.0845225027442371,
            "logloss": 0.7084325047043165,
            "mae": 0.2873406174153942,
            "precision": 0.8020565552699229,
            "recall": 0.6610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8420642038436512,
            "auditor_fn_violation": 0.00910406202227561,
            "auditor_fp_violation": 0.025484496124031007,
            "ave_precision_score": 0.8423233488531736,
            "fpr": 0.13815789473684212,
            "logloss": 0.6685324702572689,
            "mae": 0.2623360646618384,
            "precision": 0.7495029821073559,
            "recall": 0.7821576763485477
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8158848017572559,
            "auditor_fn_violation": 0.012260693222199482,
            "auditor_fp_violation": 0.015180194484521002,
            "ave_precision_score": 0.8164394090191233,
            "fpr": 0.13721185510428102,
            "logloss": 0.7154826849948738,
            "mae": 0.2679572867574018,
            "precision": 0.7484909456740443,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8554015359903716,
            "auditor_fn_violation": 0.01856300502293077,
            "auditor_fp_violation": 0.013540391676866588,
            "ave_precision_score": 0.8556051815568664,
            "fpr": 0.09868421052631579,
            "logloss": 0.5420201396875808,
            "mae": 0.2930823513192273,
            "precision": 0.7887323943661971,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8506351953587528,
            "auditor_fn_violation": 0.022009711808591785,
            "auditor_fp_violation": 0.011179484358473627,
            "ave_precision_score": 0.8513438404316143,
            "fpr": 0.08122941822173436,
            "logloss": 0.5047395340317045,
            "mae": 0.27118931917613637,
            "precision": 0.8262910798122066,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8465116623434357,
            "auditor_fn_violation": 0.014768508407949335,
            "auditor_fp_violation": 0.01950734394124848,
            "ave_precision_score": 0.8467324909859252,
            "fpr": 0.11513157894736842,
            "logloss": 0.6276104696650685,
            "mae": 0.2764722316516501,
            "precision": 0.7722342733188721,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.828879471728033,
            "auditor_fn_violation": 0.016725892574745584,
            "auditor_fp_violation": 0.014167514733865263,
            "ave_precision_score": 0.8294814959919125,
            "fpr": 0.11964873765093303,
            "logloss": 0.6409184520843837,
            "mae": 0.27068346077244304,
            "precision": 0.7655913978494624,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7822740875820198,
            "auditor_fn_violation": 0.027416830457887464,
            "auditor_fp_violation": 0.030446756425948598,
            "ave_precision_score": 0.7826688276052125,
            "fpr": 0.1513157894736842,
            "logloss": 0.7273808420088875,
            "mae": 0.3176473553114448,
            "precision": 0.7206477732793523,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7558005214272379,
            "auditor_fn_violation": 0.027751679101006534,
            "auditor_fp_violation": 0.02252149756581793,
            "ave_precision_score": 0.7569896683787014,
            "fpr": 0.1668496158068057,
            "logloss": 0.7541903930978787,
            "mae": 0.3183686159414434,
            "precision": 0.7048543689320388,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8528522065770536,
            "auditor_fn_violation": 0.014800356700880837,
            "auditor_fp_violation": 0.019599143206854353,
            "ave_precision_score": 0.853063668397072,
            "fpr": 0.16776315789473684,
            "logloss": 0.537809001220555,
            "mae": 0.2999674999078515,
            "precision": 0.7277580071174378,
            "recall": 0.8485477178423236
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8515848751822335,
            "auditor_fn_violation": 0.014897951589797023,
            "auditor_fp_violation": 0.015187695816007348,
            "ave_precision_score": 0.8520596984220432,
            "fpr": 0.14489571899012074,
            "logloss": 0.5171768305772788,
            "mae": 0.2854618463815015,
            "precision": 0.756007393715342,
            "recall": 0.8665254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7699168132104215,
            "auditor_fn_violation": 0.009781975686103233,
            "auditor_fp_violation": 0.028870869033047735,
            "ave_precision_score": 0.7708078918925747,
            "fpr": 0.15570175438596492,
            "logloss": 1.0561711422355538,
            "mae": 0.27683207427961976,
            "precision": 0.7290076335877863,
            "recall": 0.7925311203319502
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7175469302513985,
            "auditor_fn_violation": 0.014097936705799176,
            "auditor_fp_violation": 0.01830324882666674,
            "ave_precision_score": 0.7184923406154924,
            "fpr": 0.1712403951701427,
            "logloss": 1.233976336726536,
            "mae": 0.2892617534988368,
            "precision": 0.7121771217712177,
            "recall": 0.8177966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 25349,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.814116656938267,
            "auditor_fn_violation": 0.0018608502584261488,
            "auditor_fp_violation": 0.007537739698082409,
            "ave_precision_score": 0.814579111428043,
            "fpr": 0.40899122807017546,
            "logloss": 1.4461265259116285,
            "mae": 0.4053499056796698,
            "precision": 0.5596221959858324,
            "recall": 0.983402489626556
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.8373599394565672,
            "auditor_fn_violation": 0.004009376918640347,
            "auditor_fp_violation": 0.008386488601726808,
            "ave_precision_score": 0.8377024507664717,
            "fpr": 0.42041712403951703,
            "logloss": 1.3937340716085378,
            "mae": 0.41753825161127633,
            "precision": 0.544589774078478,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8417597633739942,
            "auditor_fn_violation": 0.02532394263667468,
            "auditor_fp_violation": 0.01989749082007344,
            "ave_precision_score": 0.841969089632237,
            "fpr": 0.10197368421052631,
            "logloss": 0.5595748854179271,
            "mae": 0.32914306990878367,
            "precision": 0.7811764705882352,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8689534011750568,
            "auditor_fn_violation": 0.020174793949654882,
            "auditor_fp_violation": 0.014582588409442676,
            "ave_precision_score": 0.8692154853993475,
            "fpr": 0.06586169045005488,
            "logloss": 0.4862578810451476,
            "mae": 0.29965691074333334,
            "precision": 0.8488664987405542,
            "recall": 0.7139830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.844994485796065,
            "auditor_fn_violation": 0.020417030647157317,
            "auditor_fp_violation": 0.02408200734394125,
            "ave_precision_score": 0.8452812850085624,
            "fpr": 0.14583333333333334,
            "logloss": 0.5334755037481274,
            "mae": 0.30248893928160614,
            "precision": 0.7392156862745098,
            "recall": 0.7821576763485477
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8487241079291017,
            "auditor_fn_violation": 0.02038177454464269,
            "auditor_fp_violation": 0.014257530711701332,
            "ave_precision_score": 0.8491510234093792,
            "fpr": 0.13611416026344675,
            "logloss": 0.5024199368837976,
            "mae": 0.28969421437491677,
            "precision": 0.7578125,
            "recall": 0.8220338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8420858057628471,
            "auditor_fn_violation": 0.004326818082550784,
            "auditor_fp_violation": 0.013795389636882904,
            "ave_precision_score": 0.8423407603845138,
            "fpr": 0.08662280701754387,
            "logloss": 0.6275089371461676,
            "mae": 0.27784928032336137,
            "precision": 0.8114558472553699,
            "recall": 0.7053941908713693
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8183236845948759,
            "auditor_fn_violation": 0.010893225920482245,
            "auditor_fp_violation": 0.012584733790247769,
            "ave_precision_score": 0.8188872942109067,
            "fpr": 0.09110867178924259,
            "logloss": 0.6578269178457516,
            "mae": 0.2772569404616649,
            "precision": 0.8028503562945368,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8528418306164293,
            "auditor_fn_violation": 0.004804542476523258,
            "auditor_fp_violation": 0.009799571603427175,
            "ave_precision_score": 0.8530527014047149,
            "fpr": 0.13486842105263158,
            "logloss": 0.5290587894185876,
            "mae": 0.29734699718120966,
            "precision": 0.7515151515151515,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8592340991386628,
            "auditor_fn_violation": 0.006074531619192917,
            "auditor_fp_violation": 0.016595445691610266,
            "ave_precision_score": 0.8595686371020788,
            "fpr": 0.1141602634467618,
            "logloss": 0.49203970338485786,
            "mae": 0.2821128816358156,
            "precision": 0.7819706498951782,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7598222668171152,
            "auditor_fn_violation": 0.011529082041202602,
            "auditor_fp_violation": 0.01435638514891881,
            "ave_precision_score": 0.760642671453478,
            "fpr": 0.09210526315789473,
            "logloss": 0.714619835317454,
            "mae": 0.36513028732447866,
            "precision": 0.7704918032786885,
            "recall": 0.5850622406639004
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8143100851956206,
            "auditor_fn_violation": 0.021909709948092056,
            "auditor_fp_violation": 0.00745882394124957,
            "ave_precision_score": 0.8156205890867759,
            "fpr": 0.06586169045005488,
            "logloss": 0.6406643413448964,
            "mae": 0.3373837928879601,
            "precision": 0.8290598290598291,
            "recall": 0.6165254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7759419764323198,
            "auditor_fn_violation": 0.010796571303778117,
            "auditor_fp_violation": 0.03859649122807019,
            "ave_precision_score": 0.6345028998281543,
            "fpr": 0.28289473684210525,
            "logloss": 9.420487917990759,
            "mae": 0.32937366421661957,
            "precision": 0.6319543509272468,
            "recall": 0.9190871369294605
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7493871785797253,
            "auditor_fn_violation": 0.007188505832666655,
            "auditor_fp_violation": 0.035481297930382655,
            "ave_precision_score": 0.6053666226933968,
            "fpr": 0.2996706915477497,
            "logloss": 10.228478658824352,
            "mae": 0.36189355713177646,
            "precision": 0.6043478260869565,
            "recall": 0.8834745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.842573370477375,
            "auditor_fn_violation": 0.024250200189269856,
            "auditor_fp_violation": 0.023934108527131785,
            "ave_precision_score": 0.8427996134295542,
            "fpr": 0.15570175438596492,
            "logloss": 0.5865365163149223,
            "mae": 0.28963132810857034,
            "precision": 0.737037037037037,
            "recall": 0.8257261410788381
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.838165884833163,
            "auditor_fn_violation": 0.019405012186273236,
            "auditor_fp_violation": 0.02643219171402925,
            "ave_precision_score": 0.8386443880320283,
            "fpr": 0.14270032930845225,
            "logloss": 0.5716902068078766,
            "mae": 0.27898739218473145,
            "precision": 0.7556390977443609,
            "recall": 0.8516949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8497174528389766,
            "auditor_fn_violation": 0.015264431826454105,
            "auditor_fp_violation": 0.019328845369237048,
            "ave_precision_score": 0.8499532225838471,
            "fpr": 0.10964912280701754,
            "logloss": 0.5728340328756361,
            "mae": 0.2724278583405226,
            "precision": 0.7854077253218884,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8345339219602466,
            "auditor_fn_violation": 0.015637500232562464,
            "auditor_fp_violation": 0.017903177814062,
            "ave_precision_score": 0.8351680889089662,
            "fpr": 0.10208562019758508,
            "logloss": 0.5790945357993499,
            "mae": 0.26506308303614745,
            "precision": 0.7964989059080962,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 25349,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8351960372229188,
            "auditor_fn_violation": 0.004372315643881491,
            "auditor_fp_violation": 0.01147235822113423,
            "ave_precision_score": 0.8354598546909688,
            "fpr": 0.09758771929824561,
            "logloss": 0.5614448454132311,
            "mae": 0.3126451715408557,
            "precision": 0.7910798122065728,
            "recall": 0.6991701244813278
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8646602723451406,
            "auditor_fn_violation": 0.006511749055796397,
            "auditor_fp_violation": 0.008869074260681271,
            "ave_precision_score": 0.864852877825399,
            "fpr": 0.0801317233809001,
            "logloss": 0.49619483584802926,
            "mae": 0.29313381643548997,
            "precision": 0.8266033254156769,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.8420041681930156,
            "auditor_fn_violation": 0.004436012229744486,
            "auditor_fp_violation": 0.016585067319461456,
            "ave_precision_score": 0.8422617610086586,
            "fpr": 0.3432017543859649,
            "logloss": 0.8814995882741495,
            "mae": 0.35277832393917935,
            "precision": 0.5971685971685972,
            "recall": 0.9626556016597511
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8507115150752758,
            "auditor_fn_violation": 0.007004781484306686,
            "auditor_fp_violation": 0.020773687329500995,
            "ave_precision_score": 0.8511401545805513,
            "fpr": 0.3391877058177827,
            "logloss": 0.8441730210923177,
            "mae": 0.352033510078721,
            "precision": 0.5950196592398427,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7659021457828841,
            "auditor_fn_violation": 0.03766288126956396,
            "auditor_fp_violation": 0.04096797225622195,
            "ave_precision_score": 0.7646716547472536,
            "fpr": 0.18311403508771928,
            "logloss": 0.8360743657995812,
            "mae": 0.31467341785001307,
            "precision": 0.7017857142857142,
            "recall": 0.8153526970954357
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7745544830480057,
            "auditor_fn_violation": 0.027423766023553932,
            "auditor_fp_violation": 0.03821428303523876,
            "ave_precision_score": 0.7733939145856306,
            "fpr": 0.15477497255762898,
            "logloss": 0.7830234276691955,
            "mae": 0.2908180838849617,
            "precision": 0.7393715341959335,
            "recall": 0.847457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8456918926680866,
            "auditor_fn_violation": 0.00975922690543787,
            "auditor_fp_violation": 0.015452876376988988,
            "ave_precision_score": 0.8459446972986944,
            "fpr": 0.08552631578947369,
            "logloss": 0.6257103573301607,
            "mae": 0.2749880699332711,
            "precision": 0.8147268408551069,
            "recall": 0.7116182572614108
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8220629260127318,
            "auditor_fn_violation": 0.015770060838341177,
            "auditor_fp_violation": 0.008471503691905318,
            "ave_precision_score": 0.8226624290299751,
            "fpr": 0.08781558726673985,
            "logloss": 0.6483362030657392,
            "mae": 0.273146251152369,
            "precision": 0.8072289156626506,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8083939645419365,
            "auditor_fn_violation": 0.025305743612142394,
            "auditor_fp_violation": 0.017446960424316607,
            "ave_precision_score": 0.8097235920072829,
            "fpr": 0.13486842105263158,
            "logloss": 0.5434844478057138,
            "mae": 0.3315319663703568,
            "precision": 0.7469135802469136,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.831666525274779,
            "auditor_fn_violation": 0.02581443375690711,
            "auditor_fp_violation": 0.01393997434544632,
            "ave_precision_score": 0.8320620197397328,
            "fpr": 0.12843029637760703,
            "logloss": 0.5120698479216564,
            "mae": 0.3181073402947083,
            "precision": 0.7577639751552795,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7792335247724538,
            "auditor_fn_violation": 0.03776070102642499,
            "auditor_fp_violation": 0.020348837209302327,
            "ave_precision_score": 0.780706713692839,
            "fpr": 0.08114035087719298,
            "logloss": 0.7532912874275811,
            "mae": 0.3403893005054703,
            "precision": 0.7983651226158038,
            "recall": 0.6078838174273858
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8406872561150869,
            "auditor_fn_violation": 0.028344713390016558,
            "auditor_fp_violation": 0.007981416701464511,
            "ave_precision_score": 0.841386215558703,
            "fpr": 0.05159165751920966,
            "logloss": 0.6570656912993127,
            "mae": 0.30480920661842886,
            "precision": 0.8641618497109826,
            "recall": 0.6334745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8258941712873926,
            "auditor_fn_violation": 0.006651743466550195,
            "auditor_fp_violation": 0.012423500611995104,
            "ave_precision_score": 0.8262350391588286,
            "fpr": 0.13815789473684212,
            "logloss": 0.562288869944315,
            "mae": 0.30705497494720574,
            "precision": 0.7469879518072289,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8395821363930374,
            "auditor_fn_violation": 0.0031442445440845418,
            "auditor_fp_violation": 0.009041604884867067,
            "ave_precision_score": 0.8400029207841992,
            "fpr": 0.12843029637760703,
            "logloss": 0.5169097682925758,
            "mae": 0.29088156170659757,
            "precision": 0.7592592592592593,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8172251522564005,
            "auditor_fn_violation": 0.011692873261993158,
            "auditor_fp_violation": 0.018109955120359036,
            "ave_precision_score": 0.7866549743021379,
            "fpr": 0.16666666666666666,
            "logloss": 1.8886417627479715,
            "mae": 0.296792151609113,
            "precision": 0.7333333333333333,
            "recall": 0.8672199170124482
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.7970178814007813,
            "auditor_fn_violation": 0.007600141397979499,
            "auditor_fp_violation": 0.01588531964423686,
            "ave_precision_score": 0.7573120091131408,
            "fpr": 0.15916575192096596,
            "logloss": 2.317507282869273,
            "mae": 0.29209986416383776,
            "precision": 0.7396768402154399,
            "recall": 0.8728813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6948185804237712,
            "auditor_fn_violation": 0.004449661498143706,
            "auditor_fp_violation": 0.010391166870665042,
            "ave_precision_score": 0.6966992993349823,
            "fpr": 0.13706140350877194,
            "logloss": 0.7180214055051952,
            "mae": 0.34133162107425224,
            "precision": 0.7368421052631579,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7299819998277468,
            "auditor_fn_violation": 0.0038419319429198674,
            "auditor_fp_violation": 0.006138589599653941,
            "ave_precision_score": 0.7311194838189385,
            "fpr": 0.1141602634467618,
            "logloss": 0.6367929413452847,
            "mae": 0.3112497524309996,
            "precision": 0.7729257641921398,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7701614133395289,
            "auditor_fn_violation": 0.015796753294023455,
            "auditor_fp_violation": 0.0032869237046103646,
            "ave_precision_score": 0.7710089408925762,
            "fpr": 0.029605263157894735,
            "logloss": 1.2946317395081612,
            "mae": 0.411787381803227,
            "precision": 0.8669950738916257,
            "recall": 0.3651452282157676
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.793657797777205,
            "auditor_fn_violation": 0.010507172226460021,
            "auditor_fp_violation": 0.005268435147238635,
            "ave_precision_score": 0.794188418829251,
            "fpr": 0.01756311745334797,
            "logloss": 1.1592057341729765,
            "mae": 0.3926829342206376,
            "precision": 0.9153439153439153,
            "recall": 0.3665254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.855172976775656,
            "auditor_fn_violation": 0.016203956467933323,
            "auditor_fp_violation": 0.017401060791513673,
            "ave_precision_score": 0.8554052671823833,
            "fpr": 0.14473684210526316,
            "logloss": 0.5323058434000728,
            "mae": 0.2972105596910982,
            "precision": 0.7375745526838966,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.867067238305485,
            "auditor_fn_violation": 0.013463041172859028,
            "auditor_fp_violation": 0.011512043387701322,
            "ave_precision_score": 0.8673675216267605,
            "fpr": 0.12623490669593854,
            "logloss": 0.47683579595649384,
            "mae": 0.2731302279232578,
            "precision": 0.7690763052208835,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8537921798482013,
            "auditor_fn_violation": 0.013640168886947666,
            "auditor_fp_violation": 0.016052121583027337,
            "ave_precision_score": 0.8540040165756861,
            "fpr": 0.10416666666666667,
            "logloss": 0.6107587455639617,
            "mae": 0.2691604400643671,
            "precision": 0.7912087912087912,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8307384093939407,
            "auditor_fn_violation": 0.018235222980892665,
            "auditor_fp_violation": 0.01157205403959203,
            "ave_precision_score": 0.8312665975910529,
            "fpr": 0.10098792535675083,
            "logloss": 0.631923558685892,
            "mae": 0.2679729468432589,
            "precision": 0.7941834451901566,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.84099592212336,
            "auditor_fn_violation": 0.006911079566135259,
            "auditor_fp_violation": 0.010041819665442677,
            "ave_precision_score": 0.8413158384006014,
            "fpr": 0.13815789473684212,
            "logloss": 0.5595348005767056,
            "mae": 0.2905278050748315,
            "precision": 0.7459677419354839,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8368011777367963,
            "auditor_fn_violation": 0.0053233548531135474,
            "auditor_fp_violation": 0.012534724913672177,
            "ave_precision_score": 0.8372085651435734,
            "fpr": 0.14818880351262348,
            "logloss": 0.5340502957288789,
            "mae": 0.28103464132008693,
            "precision": 0.733201581027668,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7750625166720735,
            "auditor_fn_violation": 0.008667285433500765,
            "auditor_fp_violation": 0.007433190534475728,
            "ave_precision_score": 0.7762463309764003,
            "fpr": 0.09758771929824561,
            "logloss": 0.9295039630117337,
            "mae": 0.32399666698531926,
            "precision": 0.7807881773399015,
            "recall": 0.6576763485477178
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.7755082544386221,
            "auditor_fn_violation": 0.010637407207575954,
            "auditor_fp_violation": 0.004660827296845192,
            "ave_precision_score": 0.7767081555106394,
            "fpr": 0.07903402854006586,
            "logloss": 0.9291407191715702,
            "mae": 0.3049344264256836,
            "precision": 0.8222222222222222,
            "recall": 0.7055084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 25349,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8521628547447007,
            "auditor_fn_violation": 0.012006806435175077,
            "auditor_fp_violation": 0.020858833129334967,
            "ave_precision_score": 0.8523756478228509,
            "fpr": 0.17214912280701755,
            "logloss": 0.5431493188485503,
            "mae": 0.30063126455244954,
            "precision": 0.7235915492957746,
            "recall": 0.8526970954356846
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8511831889471291,
            "auditor_fn_violation": 0.01571192022177157,
            "auditor_fp_violation": 0.012497218256240483,
            "ave_precision_score": 0.8516246047492575,
            "fpr": 0.15148188803512624,
            "logloss": 0.522440790219232,
            "mae": 0.28665040105156514,
            "precision": 0.7467889908256881,
            "recall": 0.8622881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8309744283572105,
            "auditor_fn_violation": 0.010382543495668632,
            "auditor_fp_violation": 0.019665442676458592,
            "ave_precision_score": 0.8312972745550471,
            "fpr": 0.12828947368421054,
            "logloss": 0.6389614588687111,
            "mae": 0.2632152971526369,
            "precision": 0.7669322709163346,
            "recall": 0.7987551867219918
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8083987560678525,
            "auditor_fn_violation": 0.012232785726246073,
            "auditor_fp_violation": 0.011694575787202227,
            "ave_precision_score": 0.8089812989179024,
            "fpr": 0.13062568605927552,
            "logloss": 0.681423789361541,
            "mae": 0.26734637613924694,
            "precision": 0.7615230460921844,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8435050025535924,
            "auditor_fn_violation": 0.03120905219480236,
            "auditor_fp_violation": 0.023495512035903717,
            "ave_precision_score": 0.8437594038486476,
            "fpr": 0.08991228070175439,
            "logloss": 0.5560519173558582,
            "mae": 0.3206189420913385,
            "precision": 0.7913486005089059,
            "recall": 0.6452282157676349
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8488442386798867,
            "auditor_fn_violation": 0.02368416156579657,
            "auditor_fp_violation": 0.01939344233601464,
            "ave_precision_score": 0.8491375156671054,
            "fpr": 0.08562019758507135,
            "logloss": 0.5191673759057929,
            "mae": 0.3064376647028516,
            "precision": 0.8097560975609757,
            "recall": 0.7033898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8301595565891803,
            "auditor_fn_violation": 0.021643189925020023,
            "auditor_fp_violation": 0.020851183190534476,
            "ave_precision_score": 0.830466153900254,
            "fpr": 0.11732456140350878,
            "logloss": 0.5639126561444544,
            "mae": 0.3365978078447944,
            "precision": 0.7606263982102909,
            "recall": 0.7053941908713693
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8644050295058378,
            "auditor_fn_violation": 0.01200952575861877,
            "auditor_fp_violation": 0.009586701639541022,
            "ave_precision_score": 0.8646013043504437,
            "fpr": 0.08562019758507135,
            "logloss": 0.492381854164332,
            "mae": 0.3076792818114098,
            "precision": 0.8202764976958525,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8315436781333753,
            "auditor_fn_violation": 0.012684720099002697,
            "auditor_fp_violation": 0.019563443492452065,
            "ave_precision_score": 0.8318022729801345,
            "fpr": 0.13267543859649122,
            "logloss": 0.566307127036688,
            "mae": 0.3383798367206493,
            "precision": 0.7463312368972747,
            "recall": 0.7385892116182573
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8528363155690073,
            "auditor_fn_violation": 0.009388546763660717,
            "auditor_fp_violation": 0.005233428933635724,
            "ave_precision_score": 0.8531144595022963,
            "fpr": 0.09879253567508232,
            "logloss": 0.5023784983374145,
            "mae": 0.31324988143527766,
            "precision": 0.8004434589800443,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8172006964745329,
            "auditor_fn_violation": 0.012006806435175077,
            "auditor_fp_violation": 0.020032639738882096,
            "ave_precision_score": 0.8158912791917714,
            "fpr": 0.16885964912280702,
            "logloss": 0.758565374055762,
            "mae": 0.28922662805237914,
            "precision": 0.727433628318584,
            "recall": 0.8526970954356846
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8020979281494114,
            "auditor_fn_violation": 0.012623490669593855,
            "auditor_fp_violation": 0.020361114097752354,
            "ave_precision_score": 0.7996056208122185,
            "fpr": 0.15367727771679474,
            "logloss": 0.8215765433371539,
            "mae": 0.2841733029959713,
            "precision": 0.7468354430379747,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8558593328505656,
            "auditor_fn_violation": 0.02550138312586446,
            "auditor_fp_violation": 0.012316401468788254,
            "ave_precision_score": 0.8560522256815102,
            "fpr": 0.08442982456140351,
            "logloss": 0.5788467074665676,
            "mae": 0.30422738398578586,
            "precision": 0.8035714285714286,
            "recall": 0.6535269709543569
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8433918375022089,
            "auditor_fn_violation": 0.018172431114997507,
            "auditor_fp_violation": 0.008666538310550123,
            "ave_precision_score": 0.8447351884272705,
            "fpr": 0.07464324917672886,
            "logloss": 0.5435792677086759,
            "mae": 0.28956214005187164,
            "precision": 0.8287153652392947,
            "recall": 0.6970338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7630840114332607,
            "auditor_fn_violation": 0.04598438523695131,
            "auditor_fp_violation": 0.024752651978784172,
            "ave_precision_score": 0.763279345567945,
            "fpr": 0.08881578947368421,
            "logloss": 2.307505197961989,
            "mae": 0.36558204029179486,
            "precision": 0.7810810810810811,
            "recall": 0.5995850622406639
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7823490462557986,
            "auditor_fn_violation": 0.03211920221771568,
            "auditor_fp_violation": 0.026669733877763304,
            "ave_precision_score": 0.782153288892655,
            "fpr": 0.08342480790340286,
            "logloss": 2.1716873314736658,
            "mae": 0.34665987949322385,
            "precision": 0.7929155313351499,
            "recall": 0.6165254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 25349,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7851115594979287,
            "auditor_fn_violation": 0.06692236296134528,
            "auditor_fp_violation": 0.03195889432884537,
            "ave_precision_score": 0.7822755698428641,
            "fpr": 0.10197368421052631,
            "logloss": 4.17221395158164,
            "mae": 0.35496103236660576,
            "precision": 0.7596899224806202,
            "recall": 0.6099585062240664
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.817031418837511,
            "auditor_fn_violation": 0.05705222422742749,
            "auditor_fp_violation": 0.018175726191398976,
            "ave_precision_score": 0.8128865414625441,
            "fpr": 0.06586169045005488,
            "logloss": 3.6977985389844625,
            "mae": 0.3164657360906575,
            "precision": 0.8342541436464088,
            "recall": 0.6398305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8268393251745098,
            "auditor_fn_violation": 0.006280938341704892,
            "auditor_fp_violation": 0.015121379028967777,
            "ave_precision_score": 0.8272002750994457,
            "fpr": 0.14364035087719298,
            "logloss": 0.5592236334936782,
            "mae": 0.3052523878987542,
            "precision": 0.741106719367589,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8411321167502765,
            "auditor_fn_violation": 0.0022884146681798733,
            "auditor_fp_violation": 0.013077321224517355,
            "ave_precision_score": 0.8415249708533894,
            "fpr": 0.132821075740944,
            "logloss": 0.5154775688543941,
            "mae": 0.28965865041136446,
            "precision": 0.7550607287449392,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8570443189946683,
            "auditor_fn_violation": 0.010901215694838758,
            "auditor_fp_violation": 0.010755813953488376,
            "ave_precision_score": 0.8572536472350588,
            "fpr": 0.1074561403508772,
            "logloss": 0.5132237469572987,
            "mae": 0.2908934729266707,
            "precision": 0.7887931034482759,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8557624381590713,
            "auditor_fn_violation": 0.007562931403374948,
            "auditor_fp_violation": 0.014997662085020092,
            "ave_precision_score": 0.8560692817604143,
            "fpr": 0.11525795828759605,
            "logloss": 0.4871985171581033,
            "mae": 0.28050793984377886,
            "precision": 0.7807933194154488,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8551395180544743,
            "auditor_fn_violation": 0.01085571813350805,
            "auditor_fp_violation": 0.016768665850673197,
            "ave_precision_score": 0.8553720794697018,
            "fpr": 0.14583333333333334,
            "logloss": 0.5316628853860245,
            "mae": 0.2971552963041304,
            "precision": 0.7366336633663366,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8671883574737624,
            "auditor_fn_violation": 0.013463041172859028,
            "auditor_fp_violation": 0.014412558229085666,
            "ave_precision_score": 0.8674883053108259,
            "fpr": 0.13062568605927552,
            "logloss": 0.47643990696603866,
            "mae": 0.2732632514409137,
            "precision": 0.7629482071713147,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 25349,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.815706880226419,
            "auditor_fn_violation": 0.015514668413773023,
            "auditor_fp_violation": 0.0144124847001224,
            "ave_precision_score": 0.8160252397515304,
            "fpr": 0.16337719298245615,
            "logloss": 0.688496336363679,
            "mae": 0.32448264683412914,
            "precision": 0.7156488549618321,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8521651971152358,
            "auditor_fn_violation": 0.016791010065303546,
            "auditor_fp_violation": 0.018590799866976395,
            "ave_precision_score": 0.8524097580268588,
            "fpr": 0.13172338090010977,
            "logloss": 0.6683535825313045,
            "mae": 0.30656418880521896,
            "precision": 0.7575757575757576,
            "recall": 0.7944915254237288
        }
    }
]