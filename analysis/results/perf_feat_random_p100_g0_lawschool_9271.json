[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8284374721527549,
            "auditor_fn_violation": 0.013432017543859648,
            "auditor_fp_violation": 0.017943930772878144,
            "ave_precision_score": 0.8287014237873964,
            "fpr": 0.13706140350877194,
            "logloss": 0.8822624343291661,
            "mae": 0.27610326330938517,
            "precision": 0.7373949579831933,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8236107001650222,
            "auditor_fn_violation": 0.014041911163511361,
            "auditor_fp_violation": 0.02673984632272229,
            "ave_precision_score": 0.8241944143532798,
            "fpr": 0.13062568605927552,
            "logloss": 0.8618648886971255,
            "mae": 0.2668022979970694,
            "precision": 0.7610441767068273,
            "recall": 0.779835390946502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6324665504790947,
            "auditor_fn_violation": 0.007253711201079627,
            "auditor_fp_violation": 0.008176762288604394,
            "ave_precision_score": 0.5996740326960025,
            "fpr": 0.11074561403508772,
            "logloss": 0.7011533365818784,
            "mae": 0.4741006279364228,
            "precision": 0.6405693950177936,
            "recall": 0.38461538461538464
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6431567626549337,
            "auditor_fn_violation": 0.01261219751279515,
            "auditor_fp_violation": 0.011710466843158778,
            "ave_precision_score": 0.6102780418826138,
            "fpr": 0.10318331503841932,
            "logloss": 0.7137974356418857,
            "mae": 0.4813948399361742,
            "precision": 0.6690140845070423,
            "recall": 0.39094650205761317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6878431941991234,
            "auditor_fn_violation": 0.0039642375168690985,
            "auditor_fp_violation": 0.006312233285917492,
            "ave_precision_score": 0.6896044617680358,
            "fpr": 0.2598684210526316,
            "logloss": 0.6354718094503691,
            "mae": 0.40655232910393624,
            "precision": 0.6255924170616114,
            "recall": 0.8461538461538461
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7222871587858326,
            "auditor_fn_violation": 0.005307783695391941,
            "auditor_fp_violation": 0.013650158197197651,
            "ave_precision_score": 0.70904767055914,
            "fpr": 0.22941822173435786,
            "logloss": 0.6269463256615199,
            "mae": 0.4041328829611957,
            "precision": 0.6607142857142857,
            "recall": 0.8374485596707819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7642588033187481,
            "auditor_fn_violation": 0.007038161643424814,
            "auditor_fp_violation": 0.004805792634740006,
            "ave_precision_score": 0.7656924529547129,
            "fpr": 0.03399122807017544,
            "logloss": 1.7509837008586484,
            "mae": 0.361165948041784,
            "precision": 0.8603603603603603,
            "recall": 0.4081196581196581
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7674010925197763,
            "auditor_fn_violation": 0.009170043320549487,
            "auditor_fp_violation": 0.0022547943436430564,
            "ave_precision_score": 0.7686663416297661,
            "fpr": 0.031833150384193196,
            "logloss": 1.8908039381572783,
            "mae": 0.3909130741631304,
            "precision": 0.8557213930348259,
            "recall": 0.35390946502057613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7087402826785264,
            "auditor_fn_violation": 0.013101664417453895,
            "auditor_fp_violation": 0.016022601548917336,
            "ave_precision_score": 0.6970672035192003,
            "fpr": 0.18640350877192982,
            "logloss": 0.6100916879673027,
            "mae": 0.39786356858288247,
            "precision": 0.669260700389105,
            "recall": 0.7350427350427351
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7432806489022903,
            "auditor_fn_violation": 0.013253648818961667,
            "auditor_fp_violation": 0.02169819848905534,
            "ave_precision_score": 0.7325954035487804,
            "fpr": 0.1712403951701427,
            "logloss": 0.5790880528702024,
            "mae": 0.38639489644739683,
            "precision": 0.7028571428571428,
            "recall": 0.7592592592592593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6831042994624802,
            "auditor_fn_violation": 0.07956590193432299,
            "auditor_fp_violation": 0.09390311363995575,
            "ave_precision_score": 0.6001782404881648,
            "fpr": 0.25877192982456143,
            "logloss": 0.69722412335314,
            "mae": 0.4453663535808262,
            "precision": 0.5986394557823129,
            "recall": 0.7521367521367521
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6897204193021733,
            "auditor_fn_violation": 0.08859255645449085,
            "auditor_fp_violation": 0.08752889520242785,
            "ave_precision_score": 0.6067270313476529,
            "fpr": 0.25905598243688255,
            "logloss": 0.7114713463476088,
            "mae": 0.44959138951271477,
            "precision": 0.6053511705685619,
            "recall": 0.7448559670781894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.5348635620601487,
            "auditor_fn_violation": 0.007944875543559757,
            "auditor_fp_violation": 0.028528528528528534,
            "ave_precision_score": 0.5362572087860493,
            "fpr": 0.3607456140350877,
            "logloss": 0.8221692557474709,
            "mae": 0.4651363010175134,
            "precision": 0.5636604774535809,
            "recall": 0.9081196581196581
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.5547186798211778,
            "auditor_fn_violation": 0.0037764316334873726,
            "auditor_fp_violation": 0.020040033576548093,
            "ave_precision_score": 0.5563325231826688,
            "fpr": 0.3413830954994512,
            "logloss": 0.8061159715252039,
            "mae": 0.45449098717302705,
            "precision": 0.5923984272608126,
            "recall": 0.9300411522633745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6451493879343941,
            "auditor_fn_violation": 0.008757872244714365,
            "auditor_fp_violation": 0.01467421368737158,
            "ave_precision_score": 0.6465332272157095,
            "fpr": 0.051535087719298246,
            "logloss": 1.263012945872252,
            "mae": 0.4471756210018902,
            "precision": 0.6666666666666666,
            "recall": 0.20085470085470086
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6974638436688188,
            "auditor_fn_violation": 0.007785502297028095,
            "auditor_fp_violation": 0.013278233357009107,
            "ave_precision_score": 0.698331785655612,
            "fpr": 0.042810098792535674,
            "logloss": 1.330681042314164,
            "mae": 0.4509933436778439,
            "precision": 0.7291666666666666,
            "recall": 0.21604938271604937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6617987635369549,
            "auditor_fn_violation": 0.006820269155795473,
            "auditor_fp_violation": 0.02563418681839736,
            "ave_precision_score": 0.6632432791718301,
            "fpr": 0.29385964912280704,
            "logloss": 0.6749441230872997,
            "mae": 0.43526505070264665,
            "precision": 0.5883256528417818,
            "recall": 0.8183760683760684
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7118718989244384,
            "auditor_fn_violation": 0.013048113365225211,
            "auditor_fp_violation": 0.017945373539097323,
            "ave_precision_score": 0.7125401008899349,
            "fpr": 0.287596048298573,
            "logloss": 0.6525322027379842,
            "mae": 0.42292882168397683,
            "precision": 0.6095380029806259,
            "recall": 0.8415637860082305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8528049782824969,
            "auditor_fn_violation": 0.03229728969860549,
            "auditor_fp_violation": 0.020102339181286552,
            "ave_precision_score": 0.8527582466967112,
            "fpr": 0.08114035087719298,
            "logloss": 1.7139647624363517,
            "mae": 0.28488077962194186,
            "precision": 0.8126582278481013,
            "recall": 0.6858974358974359
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8423166478269846,
            "auditor_fn_violation": 0.037935972318214065,
            "auditor_fp_violation": 0.019758507135016472,
            "ave_precision_score": 0.8424767362110486,
            "fpr": 0.08781558726673985,
            "logloss": 2.0144046921201055,
            "mae": 0.29589207003703516,
            "precision": 0.8072289156626506,
            "recall": 0.6893004115226338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5940118473272198,
            "auditor_fn_violation": 0.019483805668016208,
            "auditor_fp_violation": 0.007329698119171803,
            "ave_precision_score": 0.5950657403022634,
            "fpr": 0.08771929824561403,
            "logloss": 2.025692079351588,
            "mae": 0.46744873590205754,
            "precision": 0.6694214876033058,
            "recall": 0.34615384615384615
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.627934801003725,
            "auditor_fn_violation": 0.006798480392821176,
            "auditor_fp_violation": 0.006717892425905598,
            "ave_precision_score": 0.6285372765571298,
            "fpr": 0.07574094401756312,
            "logloss": 2.173308491583444,
            "mae": 0.46854052524606044,
            "precision": 0.7063829787234043,
            "recall": 0.34156378600823045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7568841797192957,
            "auditor_fn_violation": 0.011733393312340685,
            "auditor_fp_violation": 0.017166014698909438,
            "ave_precision_score": 0.6547020279814565,
            "fpr": 0.18969298245614036,
            "logloss": 9.188793945062109,
            "mae": 0.347084417381616,
            "precision": 0.6490872210953347,
            "recall": 0.6837606837606838
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7904598889806145,
            "auditor_fn_violation": 0.012553473097441875,
            "auditor_fp_violation": 0.021669787563763154,
            "ave_precision_score": 0.6960789191207004,
            "fpr": 0.1756311745334797,
            "logloss": 8.432407134673381,
            "mae": 0.3198474932955029,
            "precision": 0.6881091617933723,
            "recall": 0.7263374485596708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8343105357021777,
            "auditor_fn_violation": 0.0003373819163292901,
            "auditor_fp_violation": 0.014313655761024191,
            "ave_precision_score": 0.8096584551004926,
            "fpr": 0.13815789473684212,
            "logloss": 0.5508652599602591,
            "mae": 0.2998523685852425,
            "precision": 0.7514792899408284,
            "recall": 0.8141025641025641
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8442465574256292,
            "auditor_fn_violation": 0.009879253567508232,
            "auditor_fp_violation": 0.016245883644346877,
            "ave_precision_score": 0.837509932441925,
            "fpr": 0.1207464324917673,
            "logloss": 0.5166219315143235,
            "mae": 0.28755610032593903,
            "precision": 0.7808764940239044,
            "recall": 0.8065843621399177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5750187526224859,
            "auditor_fn_violation": 0.025387989203778674,
            "auditor_fp_violation": 0.012268847795163598,
            "ave_precision_score": 0.5765794338766315,
            "fpr": 0.3059210526315789,
            "logloss": 0.7299900522480565,
            "mae": 0.47135927520713794,
            "precision": 0.5694444444444444,
            "recall": 0.7884615384615384
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6032106656863919,
            "auditor_fn_violation": 0.01492051876245071,
            "auditor_fp_violation": 0.022134693613998842,
            "ave_precision_score": 0.6045562351172311,
            "fpr": 0.300768386388584,
            "logloss": 0.703083442531837,
            "mae": 0.46281089274285303,
            "precision": 0.5958702064896755,
            "recall": 0.831275720164609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.8390272469769439,
            "auditor_fn_violation": 0.040654520917678814,
            "auditor_fp_violation": 0.005986249407302039,
            "ave_precision_score": 0.8392494225093918,
            "fpr": 0.017543859649122806,
            "logloss": 1.1820539713965885,
            "mae": 0.36887148869186204,
            "precision": 0.9101123595505618,
            "recall": 0.34615384615384615
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.8344807515119895,
            "auditor_fn_violation": 0.03535661530538955,
            "auditor_fp_violation": 0.0013688900368050622,
            "ave_precision_score": 0.8350610686573071,
            "fpr": 0.01646542261251372,
            "logloss": 1.1208787682232133,
            "mae": 0.3879815147042187,
            "precision": 0.9127906976744186,
            "recall": 0.3230452674897119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6260180568573481,
            "auditor_fn_violation": 0.007827729044834315,
            "auditor_fp_violation": 0.02520448079658607,
            "ave_precision_score": 0.6262325873098781,
            "fpr": 0.125,
            "logloss": 9.981877832806477,
            "mae": 0.46302506482608374,
            "precision": 0.5971731448763251,
            "recall": 0.3611111111111111
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6324455274760002,
            "auditor_fn_violation": 0.006685548824834108,
            "auditor_fp_violation": 0.0185471685930135,
            "ave_precision_score": 0.6313734869364784,
            "fpr": 0.11306256860592755,
            "logloss": 10.392662208185824,
            "mae": 0.4683703423284994,
            "precision": 0.6268115942028986,
            "recall": 0.3559670781893004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6857260958671341,
            "auditor_fn_violation": 0.006607062528115159,
            "auditor_fp_violation": 0.004334103840682803,
            "ave_precision_score": 0.6468528935404638,
            "fpr": 0.24671052631578946,
            "logloss": 0.6445251264652937,
            "mae": 0.4533461135272917,
            "precision": 0.6231155778894473,
            "recall": 0.7948717948717948
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.673696036673382,
            "auditor_fn_violation": 0.00916100879511052,
            "auditor_fp_violation": 0.015917866597791697,
            "ave_precision_score": 0.6349181828246977,
            "fpr": 0.24368825466520308,
            "logloss": 0.6740680191334231,
            "mae": 0.46576026091853034,
            "precision": 0.6145833333333334,
            "recall": 0.7283950617283951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.7930824869687818,
            "auditor_fn_violation": 0.009034337981706405,
            "auditor_fp_violation": 0.01071795479690217,
            "ave_precision_score": 0.7946286703163894,
            "fpr": 0.09429824561403509,
            "logloss": 0.5542609656121713,
            "mae": 0.37422598920468436,
            "precision": 0.8036529680365296,
            "recall": 0.7521367521367521
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8001426204281914,
            "auditor_fn_violation": 0.009777615156319886,
            "auditor_fp_violation": 0.01196358235939821,
            "ave_precision_score": 0.8015581484148253,
            "fpr": 0.10318331503841932,
            "logloss": 0.557882224505626,
            "mae": 0.37685839233165513,
            "precision": 0.7924944812362031,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8597932499434744,
            "auditor_fn_violation": 0.01573980356875094,
            "auditor_fp_violation": 0.011320531057373164,
            "ave_precision_score": 0.8552392693165302,
            "fpr": 0.10526315789473684,
            "logloss": 0.47869732524708253,
            "mae": 0.28761563709275306,
            "precision": 0.7939914163090128,
            "recall": 0.7905982905982906
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8714108970162823,
            "auditor_fn_violation": 0.01747277219895832,
            "auditor_fp_violation": 0.014822754568347645,
            "ave_precision_score": 0.867895303485046,
            "fpr": 0.0889132821075741,
            "logloss": 0.46420889336876414,
            "mae": 0.28463126883998463,
            "precision": 0.8250539956803455,
            "recall": 0.7860082304526749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8381004113168229,
            "auditor_fn_violation": 0.005440283400809719,
            "auditor_fp_violation": 0.014765587956377432,
            "ave_precision_score": 0.7465183912328308,
            "fpr": 0.17653508771929824,
            "logloss": 0.5347676043131302,
            "mae": 0.35401581336842164,
            "precision": 0.7119856887298748,
            "recall": 0.8504273504273504
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8460105487135241,
            "auditor_fn_violation": 0.005592371246719336,
            "auditor_fp_violation": 0.010274423710208569,
            "ave_precision_score": 0.7602736783854328,
            "fpr": 0.14928649835345773,
            "logloss": 0.5263725007151652,
            "mae": 0.34901824528116293,
            "precision": 0.7504587155963303,
            "recall": 0.8415637860082305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.678195170236416,
            "auditor_fn_violation": 0.014713600239916035,
            "auditor_fp_violation": 0.024261103208471642,
            "ave_precision_score": 0.6576328268011156,
            "fpr": 0.20833333333333334,
            "logloss": 0.6553540638475549,
            "mae": 0.45882135929474444,
            "precision": 0.623015873015873,
            "recall": 0.6709401709401709
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6915972075493655,
            "auditor_fn_violation": 0.022213639423055202,
            "auditor_fp_violation": 0.008926196164525089,
            "ave_precision_score": 0.6719843645754445,
            "fpr": 0.18551042810098792,
            "logloss": 0.6475879933553987,
            "mae": 0.45545172607924883,
            "precision": 0.6578947368421053,
            "recall": 0.668724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5780674731061171,
            "auditor_fn_violation": 0.0051450742240215916,
            "auditor_fp_violation": 0.014928579895685178,
            "ave_precision_score": 0.5799163000377997,
            "fpr": 0.4375,
            "logloss": 0.687469852309166,
            "mae": 0.49523501621003735,
            "precision": 0.5333333333333333,
            "recall": 0.9743589743589743
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5629737088061895,
            "auditor_fn_violation": 0.011017603772817823,
            "auditor_fp_violation": 0.011041518693097448,
            "ave_precision_score": 0.5644388269108812,
            "fpr": 0.43249176728869376,
            "logloss": 0.6892015107651669,
            "mae": 0.49622817699001076,
            "precision": 0.54292343387471,
            "recall": 0.9629629629629629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6423645201167273,
            "auditor_fn_violation": 0.0010355750487329417,
            "auditor_fp_violation": 0.030701754385964924,
            "ave_precision_score": 0.6148740423137764,
            "fpr": 0.3651315789473684,
            "logloss": 0.6745060369533279,
            "mae": 0.46827252707525824,
            "precision": 0.5309859154929577,
            "recall": 0.8055555555555556
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6316070697084841,
            "auditor_fn_violation": 0.010995017459220413,
            "auditor_fp_violation": 0.039132175372893395,
            "ave_precision_score": 0.6078829592677204,
            "fpr": 0.32711306256860595,
            "logloss": 0.6687812094680917,
            "mae": 0.463648612883952,
            "precision": 0.5578635014836796,
            "recall": 0.7736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7476423743886926,
            "auditor_fn_violation": 0.017658663217873745,
            "auditor_fp_violation": 0.01904783072546232,
            "ave_precision_score": 0.5822180074645298,
            "fpr": 0.26644736842105265,
            "logloss": 0.6810114564198212,
            "mae": 0.4679483945824598,
            "precision": 0.601639344262295,
            "recall": 0.7841880341880342
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7516057190130534,
            "auditor_fn_violation": 0.02635145207410118,
            "auditor_fp_violation": 0.010357073674694904,
            "ave_precision_score": 0.5985524641894311,
            "fpr": 0.24478594950603733,
            "logloss": 0.6717117729316139,
            "mae": 0.464740874803943,
            "precision": 0.6207482993197279,
            "recall": 0.7510288065843621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6334563161106813,
            "auditor_fn_violation": 0.0036127980206927804,
            "auditor_fp_violation": 0.004262486170380907,
            "ave_precision_score": 0.6152204231596767,
            "fpr": 0.041666666666666664,
            "logloss": 0.7138139621212057,
            "mae": 0.4631743104638238,
            "precision": 0.6346153846153846,
            "recall": 0.14102564102564102
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.660765435250145,
            "auditor_fn_violation": 0.01195267715575072,
            "auditor_fp_violation": 0.004005940466197457,
            "ave_precision_score": 0.6397632181714659,
            "fpr": 0.030735455543358946,
            "logloss": 0.7392441771610889,
            "mae": 0.469561405128234,
            "precision": 0.7021276595744681,
            "recall": 0.13580246913580246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6531969347146235,
            "auditor_fn_violation": 0.011470985155195693,
            "auditor_fp_violation": 0.016459716295242607,
            "ave_precision_score": 0.6599958161324575,
            "fpr": 0.09320175438596491,
            "logloss": 0.668995250062399,
            "mae": 0.43065676806298525,
            "precision": 0.6996466431095406,
            "recall": 0.4230769230769231
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6988606257750206,
            "auditor_fn_violation": 0.008501488438066076,
            "auditor_fp_violation": 0.017175695744818236,
            "ave_precision_score": 0.7036748084233552,
            "fpr": 0.0801317233809001,
            "logloss": 0.6619245222846759,
            "mae": 0.4273372884639401,
            "precision": 0.7296296296296296,
            "recall": 0.4053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7956763326055136,
            "auditor_fn_violation": 0.03438249737591843,
            "auditor_fp_violation": 0.01354067883673147,
            "ave_precision_score": 0.7964096671986732,
            "fpr": 0.09100877192982457,
            "logloss": 1.5706345926281229,
            "mae": 0.33648360005383676,
            "precision": 0.7893401015228426,
            "recall": 0.6645299145299145
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7901575991646143,
            "auditor_fn_violation": 0.027117128105053467,
            "auditor_fp_violation": 0.011878349583521663,
            "ave_precision_score": 0.790736501727245,
            "fpr": 0.09659714599341383,
            "logloss": 1.8150711194920275,
            "mae": 0.3563841556043759,
            "precision": 0.7755102040816326,
            "recall": 0.6255144032921811
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.5036171444861944,
            "auditor_fn_violation": 0.007309941520467835,
            "auditor_fp_violation": 0.02524893314366999,
            "ave_precision_score": 0.765340946387264,
            "fpr": 0.23574561403508773,
            "logloss": 0.5483600483824339,
            "mae": 0.371561498593934,
            "precision": 0.6498371335504886,
            "recall": 0.8525641025641025
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.5068089562451494,
            "auditor_fn_violation": 0.008528592014382967,
            "auditor_fp_violation": 0.017167947310647635,
            "ave_precision_score": 0.7589226222422947,
            "fpr": 0.22063666300768386,
            "logloss": 0.5625637649200086,
            "mae": 0.375916731131911,
            "precision": 0.6655574043261231,
            "recall": 0.823045267489712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8136989081032426,
            "auditor_fn_violation": 0.02030148822911981,
            "auditor_fp_violation": 0.02118895211000475,
            "ave_precision_score": 0.8139859384613339,
            "fpr": 0.15460526315789475,
            "logloss": 0.9249744827741521,
            "mae": 0.29394035916907707,
            "precision": 0.7110655737704918,
            "recall": 0.7414529914529915
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8052618677407066,
            "auditor_fn_violation": 0.014450723439624528,
            "auditor_fp_violation": 0.028819009491831863,
            "ave_precision_score": 0.8055837188422581,
            "fpr": 0.14489571899012074,
            "logloss": 0.9058962340003357,
            "mae": 0.2803144508033128,
            "precision": 0.7401574803149606,
            "recall": 0.7736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7929838269628564,
            "auditor_fn_violation": 0.04576210826210826,
            "auditor_fp_violation": 0.05052750118539593,
            "ave_precision_score": 0.7935328934202116,
            "fpr": 0.18421052631578946,
            "logloss": 0.5984995799154983,
            "mae": 0.36169757566016963,
            "precision": 0.681214421252372,
            "recall": 0.7670940170940171
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7883938338113601,
            "auditor_fn_violation": 0.05465887890573829,
            "auditor_fp_violation": 0.044233227868534904,
            "ave_precision_score": 0.7889339261047432,
            "fpr": 0.1668496158068057,
            "logloss": 0.6242480412085132,
            "mae": 0.37767897392528055,
            "precision": 0.7007874015748031,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8571027986506956,
            "auditor_fn_violation": 0.0033550757234967806,
            "auditor_fp_violation": 0.01602260154891734,
            "ave_precision_score": 0.8572285503043654,
            "fpr": 0.16666666666666666,
            "logloss": 0.5083484078090554,
            "mae": 0.3500250503706762,
            "precision": 0.7251356238698011,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8474383158352723,
            "auditor_fn_violation": 0.0021999069443879773,
            "auditor_fp_violation": 0.013301478659520896,
            "ave_precision_score": 0.8477693033755012,
            "fpr": 0.14818880351262348,
            "logloss": 0.505313410328026,
            "mae": 0.3489876496539125,
            "precision": 0.753199268738574,
            "recall": 0.8477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8105929153494897,
            "auditor_fn_violation": 0.011339781076623185,
            "auditor_fp_violation": 0.015328651019440491,
            "ave_precision_score": 0.7791214699199027,
            "fpr": 0.15021929824561403,
            "logloss": 0.5455689644083974,
            "mae": 0.3686755477173025,
            "precision": 0.7127882599580713,
            "recall": 0.7264957264957265
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8149968770969432,
            "auditor_fn_violation": 0.012232747444358618,
            "auditor_fp_violation": 0.002838509717827857,
            "ave_precision_score": 0.7871665409477336,
            "fpr": 0.12952799121844127,
            "logloss": 0.546442222031738,
            "mae": 0.3687212324397624,
            "precision": 0.7445887445887446,
            "recall": 0.7078189300411523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7968734058564246,
            "auditor_fn_violation": 0.00610098965362124,
            "auditor_fp_violation": 0.015686739370949897,
            "ave_precision_score": 0.7981624227156885,
            "fpr": 0.14035087719298245,
            "logloss": 1.4213897449957797,
            "mae": 0.3014221337955465,
            "precision": 0.729957805907173,
            "recall": 0.7393162393162394
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8344307891353844,
            "auditor_fn_violation": 0.003455705980404113,
            "auditor_fp_violation": 0.020040033576548075,
            "ave_precision_score": 0.8347285135429222,
            "fpr": 0.1251372118551043,
            "logloss": 1.3658022798554976,
            "mae": 0.28112039069095374,
            "precision": 0.7673469387755102,
            "recall": 0.7736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6087383881277846,
            "auditor_fn_violation": 0.00815105338131654,
            "auditor_fp_violation": 0.008347162952426115,
            "ave_precision_score": 0.6140978276175908,
            "fpr": 0.08771929824561403,
            "logloss": 0.7538933236163938,
            "mae": 0.45849745167141553,
            "precision": 0.6536796536796536,
            "recall": 0.32264957264957267
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6500974681710614,
            "auditor_fn_violation": 0.01257831804239903,
            "auditor_fp_violation": 0.0077639310389358805,
            "ave_precision_score": 0.6557426502223355,
            "fpr": 0.06476399560922064,
            "logloss": 0.7563598895753667,
            "mae": 0.4588074798682453,
            "precision": 0.7412280701754386,
            "recall": 0.3477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.39450297509508037,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5116166728008834,
            "fpr": 0.4868421052631579,
            "logloss": 0.6930817630311075,
            "mae": 0.49947728197041313,
            "precision": 0.5131578947368421,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.3586088555597033,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5320325259342213,
            "fpr": 0.4665203073545554,
            "logloss": 0.6913388289642614,
            "mae": 0.49860631726052446,
            "precision": 0.5334796926454446,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6684522903116024,
            "auditor_fn_violation": 0.007225596041385517,
            "auditor_fp_violation": 0.03876244665718351,
            "ave_precision_score": 0.6370107912969738,
            "fpr": 0.2982456140350877,
            "logloss": 0.6531802433140711,
            "mae": 0.41912280176684524,
            "precision": 0.6052249637155298,
            "recall": 0.8910256410256411
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6828332672183349,
            "auditor_fn_violation": 0.008722834311320713,
            "auditor_fp_violation": 0.03512623490669595,
            "ave_precision_score": 0.6540302675580641,
            "fpr": 0.27991218441273324,
            "logloss": 0.625951229093405,
            "mae": 0.4070737935708985,
            "precision": 0.6357142857142857,
            "recall": 0.9156378600823045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.7986117592683631,
            "auditor_fn_violation": 0.008842217723796675,
            "auditor_fp_violation": 0.009631341868183976,
            "ave_precision_score": 0.7773449656578825,
            "fpr": 0.06907894736842106,
            "logloss": 0.5471159862487962,
            "mae": 0.37136003772090925,
            "precision": 0.8359375,
            "recall": 0.6858974358974359
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7842937604435356,
            "auditor_fn_violation": 0.0072298789825317525,
            "auditor_fp_violation": 0.010563698585910762,
            "ave_precision_score": 0.7627492877019788,
            "fpr": 0.08562019758507135,
            "logloss": 0.5786749204203617,
            "mae": 0.3859871244783852,
            "precision": 0.8092909535452323,
            "recall": 0.6810699588477366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8226103870251564,
            "auditor_fn_violation": 0.01127652196731145,
            "auditor_fp_violation": 0.00832987592856014,
            "ave_precision_score": 0.8099919613012252,
            "fpr": 0.0712719298245614,
            "logloss": 0.5430723008112874,
            "mae": 0.34739704150298056,
            "precision": 0.8307291666666666,
            "recall": 0.6816239316239316
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8133872099790483,
            "auditor_fn_violation": 0.010326462576737005,
            "auditor_fp_violation": 0.0040782591851230105,
            "ave_precision_score": 0.7995786131095645,
            "fpr": 0.0801317233809001,
            "logloss": 0.5451546597508417,
            "mae": 0.3559037082870496,
            "precision": 0.8132992327365729,
            "recall": 0.654320987654321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7150938624050752,
            "auditor_fn_violation": 0.017487629329734602,
            "auditor_fp_violation": 0.023233760075865348,
            "ave_precision_score": 0.5700816473127686,
            "fpr": 0.22149122807017543,
            "logloss": 0.6756548595903654,
            "mae": 0.4750583322816773,
            "precision": 0.6007905138339921,
            "recall": 0.6495726495726496
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7161229977050848,
            "auditor_fn_violation": 0.025418637322528043,
            "auditor_fp_violation": 0.013399625492348428,
            "ave_precision_score": 0.5803277689399718,
            "fpr": 0.21295279912184412,
            "logloss": 0.6807728126706105,
            "mae": 0.477689749879188,
            "precision": 0.6088709677419355,
            "recall": 0.6213991769547325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6994689446758562,
            "auditor_fn_violation": 0.016131072874493935,
            "auditor_fp_violation": 0.04379790975185712,
            "ave_precision_score": 0.6444493611923974,
            "fpr": 0.21820175438596492,
            "logloss": 3.89464394256818,
            "mae": 0.38629903697972895,
            "precision": 0.6273408239700374,
            "recall": 0.7158119658119658
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7272510995875142,
            "auditor_fn_violation": 0.011541606248277799,
            "auditor_fp_violation": 0.038008652418157166,
            "ave_precision_score": 0.669579535467514,
            "fpr": 0.19978046103183314,
            "logloss": 3.983565641385841,
            "mae": 0.36379432645013543,
            "precision": 0.662962962962963,
            "recall": 0.7366255144032922
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.6201985135517134,
            "auditor_fn_violation": 0.001244095816464238,
            "auditor_fp_violation": 0.0033783783783783833,
            "ave_precision_score": 0.6215490876981211,
            "fpr": 0.4616228070175439,
            "logloss": 1.2889050020008732,
            "mae": 0.4730842397875038,
            "precision": 0.5215909090909091,
            "recall": 0.9807692307692307
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6500838572464325,
            "auditor_fn_violation": 0.0020463200119255737,
            "auditor_fp_violation": 0.00807128559436948,
            "ave_precision_score": 0.6513653001880719,
            "fpr": 0.43907793633369924,
            "logloss": 1.232137700518472,
            "mae": 0.45119319902784083,
            "precision": 0.5454545454545454,
            "recall": 0.9876543209876543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8683117797993587,
            "auditor_fn_violation": 0.014015407107512376,
            "auditor_fp_violation": 0.01513355460723882,
            "ave_precision_score": 0.8685048823931276,
            "fpr": 0.10087719298245613,
            "logloss": 0.4832853232557599,
            "mae": 0.30654005542639523,
            "precision": 0.7978021978021979,
            "recall": 0.7756410256410257
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.866807405597106,
            "auditor_fn_violation": 0.015986592764248575,
            "auditor_fp_violation": 0.02449538322464002,
            "ave_precision_score": 0.8673509853667024,
            "fpr": 0.09659714599341383,
            "logloss": 0.47420512108429463,
            "mae": 0.30577685897474705,
            "precision": 0.8103448275862069,
            "recall": 0.7736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6959258567316572,
            "auditor_fn_violation": 0.00728182636077375,
            "auditor_fp_violation": 0.0018669985775248933,
            "ave_precision_score": 0.6864321165527102,
            "fpr": 0.005482456140350877,
            "logloss": 1.0467070536264917,
            "mae": 0.4514510541482371,
            "precision": 0.8275862068965517,
            "recall": 0.05128205128205128
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.7223637301043909,
            "auditor_fn_violation": 0.005447818839695929,
            "auditor_fp_violation": 0.0037967327435913995,
            "ave_precision_score": 0.716856099793195,
            "fpr": 0.007683863885839737,
            "logloss": 1.0805858669023027,
            "mae": 0.46148778531295537,
            "precision": 0.72,
            "recall": 0.037037037037037035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8249139382717899,
            "auditor_fn_violation": 0.00284665991902834,
            "auditor_fp_violation": 0.007312411095305838,
            "ave_precision_score": 0.8132106946797206,
            "fpr": 0.07346491228070176,
            "logloss": 0.5431989434890191,
            "mae": 0.330022475698538,
            "precision": 0.8325,
            "recall": 0.7115384615384616
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8252856527098585,
            "auditor_fn_violation": 0.009045818595763712,
            "auditor_fp_violation": 0.010488797055595018,
            "ave_precision_score": 0.8093790552521963,
            "fpr": 0.07574094401756312,
            "logloss": 0.5336663545608054,
            "mae": 0.338952552866596,
            "precision": 0.8283582089552238,
            "recall": 0.6851851851851852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 9271,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8146607854329884,
            "auditor_fn_violation": 0.007202166741640431,
            "auditor_fp_violation": 0.015350877192982462,
            "ave_precision_score": 0.8149970758058716,
            "fpr": 0.13596491228070176,
            "logloss": 0.9115882609870065,
            "mae": 0.28403177747837144,
            "precision": 0.7367303609341825,
            "recall": 0.7414529914529915
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8189579477287598,
            "auditor_fn_violation": 0.010547808449991647,
            "auditor_fp_violation": 0.019461483825143674,
            "ave_precision_score": 0.8193436650486114,
            "fpr": 0.12623490669593854,
            "logloss": 0.8856801188621791,
            "mae": 0.2730073550440802,
            "precision": 0.7648261758691206,
            "recall": 0.7695473251028807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8073636562132013,
            "auditor_fn_violation": 0.047673939121307546,
            "auditor_fp_violation": 0.01167614983404457,
            "ave_precision_score": 0.8077556109555225,
            "fpr": 0.05482456140350877,
            "logloss": 0.5712454983398606,
            "mae": 0.37221288098392014,
            "precision": 0.84472049689441,
            "recall": 0.5811965811965812
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8062992332973552,
            "auditor_fn_violation": 0.05073789486522748,
            "auditor_fp_violation": 0.012521469619681022,
            "ave_precision_score": 0.8067680122688393,
            "fpr": 0.05378704720087816,
            "logloss": 0.6054774570754452,
            "mae": 0.3871509776206362,
            "precision": 0.8403908794788274,
            "recall": 0.5308641975308642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8534716983154657,
            "auditor_fn_violation": 0.010037112010796224,
            "auditor_fp_violation": 0.010510510510510513,
            "ave_precision_score": 0.8544460384420185,
            "fpr": 0.07675438596491228,
            "logloss": 0.4832305344313911,
            "mae": 0.2937549661289443,
            "precision": 0.8300970873786407,
            "recall": 0.7307692307692307
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8652318554072721,
            "auditor_fn_violation": 0.013341735441991576,
            "auditor_fp_violation": 0.005899141215212763,
            "ave_precision_score": 0.8628852918466934,
            "fpr": 0.08342480790340286,
            "logloss": 0.47464364161631,
            "mae": 0.2967690512022713,
            "precision": 0.8244803695150116,
            "recall": 0.7345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7602362309483588,
            "auditor_fn_violation": 0.012000487329434702,
            "auditor_fp_violation": 0.015587956377430065,
            "ave_precision_score": 0.6374133836086944,
            "fpr": 0.17543859649122806,
            "logloss": 10.449369632234298,
            "mae": 0.3265618276733549,
            "precision": 0.6701030927835051,
            "recall": 0.6944444444444444
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.789530998274161,
            "auditor_fn_violation": 0.012070125986457252,
            "auditor_fp_violation": 0.023991735003551378,
            "ave_precision_score": 0.6748467146174093,
            "fpr": 0.15806805708013172,
            "logloss": 9.700227896072983,
            "mae": 0.3037708588573835,
            "precision": 0.7096774193548387,
            "recall": 0.7242798353909465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6681057667352305,
            "auditor_fn_violation": 0.00922177237966712,
            "auditor_fp_violation": 0.013197407934250036,
            "ave_precision_score": 0.6564538752179585,
            "fpr": 0.10087719298245613,
            "logloss": 0.6787787212214114,
            "mae": 0.43201478945271093,
            "precision": 0.6870748299319728,
            "recall": 0.43162393162393164
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7210713176540051,
            "auditor_fn_violation": 0.012451834686253535,
            "auditor_fp_violation": 0.022392974753018664,
            "ave_precision_score": 0.7080732595061667,
            "fpr": 0.09330406147091108,
            "logloss": 0.6666483345752469,
            "mae": 0.42527835254693397,
            "precision": 0.7275641025641025,
            "recall": 0.4670781893004115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5938037204518976,
            "auditor_fn_violation": 0.035818713450292396,
            "auditor_fp_violation": 0.04218033823296982,
            "ave_precision_score": 0.5948773614719601,
            "fpr": 0.35635964912280704,
            "logloss": 0.6745767372919454,
            "mae": 0.4736339452210814,
            "precision": 0.5473537604456824,
            "recall": 0.8397435897435898
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6235919411591307,
            "auditor_fn_violation": 0.03130463064601374,
            "auditor_fp_violation": 0.043305998579453754,
            "ave_precision_score": 0.6245305788771243,
            "fpr": 0.3260153677277717,
            "logloss": 0.6618339531785103,
            "mae": 0.4682611964773857,
            "precision": 0.5875,
            "recall": 0.8703703703703703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8203728045755798,
            "auditor_fn_violation": 0.013752998950367374,
            "auditor_fp_violation": 0.016684447605500245,
            "ave_precision_score": 0.7973854626094385,
            "fpr": 0.14144736842105263,
            "logloss": 0.5639813605743987,
            "mae": 0.37513971041373323,
            "precision": 0.7139689578713969,
            "recall": 0.688034188034188
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.817214224013797,
            "auditor_fn_violation": 0.014270032930845226,
            "auditor_fp_violation": 0.019244527668367026,
            "ave_precision_score": 0.7953117892594856,
            "fpr": 0.13391877058177826,
            "logloss": 0.5739261586354392,
            "mae": 0.3764486866139293,
            "precision": 0.7420718816067653,
            "recall": 0.7222222222222222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7210209086642103,
            "auditor_fn_violation": 0.01397323436797121,
            "auditor_fp_violation": 0.023305377746167224,
            "ave_precision_score": 0.6959520329683782,
            "fpr": 0.30153508771929827,
            "logloss": 0.6865319362254058,
            "mae": 0.4204126428996556,
            "precision": 0.5889387144992526,
            "recall": 0.8418803418803419
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7555658377977411,
            "auditor_fn_violation": 0.021944862291246002,
            "auditor_fp_violation": 0.031195195970814237,
            "ave_precision_score": 0.7275240398782614,
            "fpr": 0.2897914379802415,
            "logloss": 0.6643213951620013,
            "mae": 0.41201132650228484,
            "precision": 0.6047904191616766,
            "recall": 0.831275720164609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6114005508826071,
            "auditor_fn_violation": 0.008293972109761584,
            "auditor_fp_violation": 0.02126797850482062,
            "ave_precision_score": 0.5976696522215613,
            "fpr": 0.3399122807017544,
            "logloss": 0.7534430077565314,
            "mae": 0.4366149885065265,
            "precision": 0.5633802816901409,
            "recall": 0.8547008547008547
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6610708902555342,
            "auditor_fn_violation": 0.006470978845658689,
            "auditor_fp_violation": 0.020081358558791243,
            "ave_precision_score": 0.6469418500690882,
            "fpr": 0.3238199780461032,
            "logloss": 0.7199189395769579,
            "mae": 0.42391156716298817,
            "precision": 0.5856741573033708,
            "recall": 0.8580246913580247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.4824137418006431,
            "auditor_fn_violation": 0.0027974583895636527,
            "auditor_fp_violation": 0.0005112019914651486,
            "ave_precision_score": 0.4918436419271339,
            "fpr": 0.48135964912280704,
            "logloss": 0.6936911324440741,
            "mae": 0.49915872801814165,
            "precision": 0.5127635960044395,
            "recall": 0.9871794871794872
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5308776161355987,
            "auditor_fn_violation": 0.0012332127224187232,
            "auditor_fp_violation": 0.0016917414605798495,
            "ave_precision_score": 0.5558407980674707,
            "fpr": 0.4588364434687157,
            "logloss": 0.6904933988772696,
            "mae": 0.4975530757404185,
            "precision": 0.534521158129176,
            "recall": 0.9876543209876543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7719896900407321,
            "auditor_fn_violation": 0.01598815414604889,
            "auditor_fp_violation": 0.016294254781096886,
            "ave_precision_score": 0.7220034952064162,
            "fpr": 0.14364035087719298,
            "logloss": 4.6247879552218745,
            "mae": 0.30302313864778296,
            "precision": 0.7236286919831224,
            "recall": 0.7329059829059829
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7841895858606805,
            "auditor_fn_violation": 0.010773671585965771,
            "auditor_fp_violation": 0.02115839090850391,
            "ave_precision_score": 0.7328694087405152,
            "fpr": 0.14709110867178923,
            "logloss": 4.702660000440964,
            "mae": 0.29648497068561075,
            "precision": 0.7303822937625755,
            "recall": 0.7469135802469136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7214518668466037,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.565419759334233,
            "fpr": 0.4868421052631579,
            "logloss": 0.7086004024833873,
            "mae": 0.47845850584276933,
            "precision": 0.5131578947368421,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7270336907097213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5837239835063404,
            "fpr": 0.4665203073545554,
            "logloss": 0.6961010937911114,
            "mae": 0.4738833641901236,
            "precision": 0.5334796926454446,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7628591878527714,
            "auditor_fn_violation": 0.013635852451641927,
            "auditor_fp_violation": 0.016143610715979147,
            "ave_precision_score": 0.7106330661920397,
            "fpr": 0.15460526315789475,
            "logloss": 5.309302959005655,
            "mae": 0.32523127856929596,
            "precision": 0.6941431670281996,
            "recall": 0.6837606837606838
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7776116014622272,
            "auditor_fn_violation": 0.011496433621082972,
            "auditor_fp_violation": 0.01444308129398851,
            "ave_precision_score": 0.7240326144110343,
            "fpr": 0.14709110867178923,
            "logloss": 5.389700430522087,
            "mae": 0.3129942364526276,
            "precision": 0.7196652719665272,
            "recall": 0.7078189300411523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8643454831262856,
            "auditor_fn_violation": 0.006635177687809266,
            "auditor_fp_violation": 0.013424608819345664,
            "ave_precision_score": 0.8645547247506795,
            "fpr": 0.15789473684210525,
            "logloss": 0.5028297346268917,
            "mae": 0.30171008392649684,
            "precision": 0.7328385899814471,
            "recall": 0.844017094017094
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8652234300854142,
            "auditor_fn_violation": 0.007042412579673225,
            "auditor_fp_violation": 0.015409052753922653,
            "ave_precision_score": 0.8657624888882575,
            "fpr": 0.13830954994511527,
            "logloss": 0.48621003668181845,
            "mae": 0.29598405680585443,
            "precision": 0.7657992565055762,
            "recall": 0.8477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8285203690321863,
            "auditor_fn_violation": 0.006501630679262261,
            "auditor_fp_violation": 0.01489153627311522,
            "ave_precision_score": 0.7406060797968237,
            "fpr": 0.17763157894736842,
            "logloss": 0.5527951350417806,
            "mae": 0.3602313339350778,
            "precision": 0.7112299465240641,
            "recall": 0.8525641025641025
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8280913181469448,
            "auditor_fn_violation": 0.0043636757870200975,
            "auditor_fp_violation": 0.011625234067282242,
            "ave_precision_score": 0.7483624036024509,
            "fpr": 0.15148188803512624,
            "logloss": 0.5396204346553518,
            "mae": 0.3534650691058057,
            "precision": 0.7486338797814208,
            "recall": 0.845679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5798631124487115,
            "auditor_fn_violation": 0.0021625243664717374,
            "auditor_fp_violation": 0.0035858226647700513,
            "ave_precision_score": 0.5812424020702086,
            "fpr": 0.39473684210526316,
            "logloss": 0.7797652291315526,
            "mae": 0.49052939329525097,
            "precision": 0.530638852672751,
            "recall": 0.8696581196581197
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5949968669283571,
            "auditor_fn_violation": 0.004309468634386308,
            "auditor_fp_violation": 0.011090592109511205,
            "ave_precision_score": 0.5957954217906196,
            "fpr": 0.3556531284302964,
            "logloss": 0.7730733499429582,
            "mae": 0.4876458127088395,
            "precision": 0.5691489361702128,
            "recall": 0.8806584362139918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 9271,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8401771963876243,
            "auditor_fn_violation": 0.0010215174688858937,
            "auditor_fp_violation": 0.011073573573573576,
            "ave_precision_score": 0.8060444863078638,
            "fpr": 0.07785087719298246,
            "logloss": 0.5360993840012274,
            "mae": 0.3294303468336645,
            "precision": 0.8141361256544503,
            "recall": 0.6645299145299145
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8506234897020535,
            "auditor_fn_violation": 0.004756677643615086,
            "auditor_fp_violation": 0.009737198941047331,
            "ave_precision_score": 0.8186580949017037,
            "fpr": 0.07683863885839737,
            "logloss": 0.5420537344950079,
            "mae": 0.32924536110947783,
            "precision": 0.8223350253807107,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.756578947368421,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5131578947368421,
            "fpr": 0.4868421052631579,
            "logloss": 0.6931858417963003,
            "mae": 0.49928901540605647,
            "precision": 0.5131578947368421,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7667398463227223,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5334796926454446,
            "fpr": 0.4665203073545554,
            "logloss": 0.6909875308568356,
            "mae": 0.4981909305282534,
            "precision": 0.5334796926454446,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6020272359060401,
            "auditor_fn_violation": 0.0047655195681511565,
            "auditor_fp_violation": 0.0036895448079658664,
            "ave_precision_score": 0.6301333940816027,
            "fpr": 0.0625,
            "logloss": 0.7822915898201451,
            "mae": 0.46901119417069775,
            "precision": 0.5365853658536586,
            "recall": 0.14102564102564102
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.6586452962349665,
            "auditor_fn_violation": 0.0010705912645173471,
            "auditor_fp_violation": 0.004997740040033577,
            "ave_precision_score": 0.6649795602415909,
            "fpr": 0.04939626783754116,
            "logloss": 0.78714415657725,
            "mae": 0.47257976898050463,
            "precision": 0.6017699115044248,
            "recall": 0.13991769547325103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7432188020128316,
            "auditor_fn_violation": 0.02188765182186235,
            "auditor_fp_violation": 0.052987197724039835,
            "ave_precision_score": 0.6516411311962549,
            "fpr": 0.24671052631578946,
            "logloss": 0.6330832762875755,
            "mae": 0.4333222115314321,
            "precision": 0.6268656716417911,
            "recall": 0.8076923076923077
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7565310341790898,
            "auditor_fn_violation": 0.011720038125697354,
            "auditor_fp_violation": 0.05249047588299865,
            "ave_precision_score": 0.6710118740800626,
            "fpr": 0.21185510428100987,
            "logloss": 0.6281695002234114,
            "mae": 0.42999275808931053,
            "precision": 0.6614035087719298,
            "recall": 0.7757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6985366792290615,
            "auditor_fn_violation": 0.01196300044984256,
            "auditor_fp_violation": 0.021430970444128353,
            "ave_precision_score": 0.7010077360621358,
            "fpr": 0.17324561403508773,
            "logloss": 0.617033815693037,
            "mae": 0.432456328174132,
            "precision": 0.6762295081967213,
            "recall": 0.7051282051282052
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7309288118511588,
            "auditor_fn_violation": 0.013651167938276124,
            "auditor_fp_violation": 0.018017692258022872,
            "ave_precision_score": 0.7245516622121236,
            "fpr": 0.16245883644346873,
            "logloss": 0.6106437075758772,
            "mae": 0.4292716716143224,
            "precision": 0.7045908183632734,
            "recall": 0.7263374485596708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8418354361580533,
            "auditor_fn_violation": 0.01924014095066727,
            "auditor_fp_violation": 0.02417466808914177,
            "ave_precision_score": 0.83524555363293,
            "fpr": 0.17434210526315788,
            "logloss": 0.5270356833333845,
            "mae": 0.33590416550603613,
            "precision": 0.702803738317757,
            "recall": 0.8034188034188035
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8308263752129452,
            "auditor_fn_violation": 0.01824070686127035,
            "auditor_fp_violation": 0.024438561374055666,
            "ave_precision_score": 0.8261835292980857,
            "fpr": 0.1602634467618002,
            "logloss": 0.5123828414298479,
            "mae": 0.3293822267420925,
            "precision": 0.7364620938628159,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 9271,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7164564878152675,
            "auditor_fn_violation": 0.011864597390913192,
            "auditor_fp_violation": 0.0178525565038723,
            "ave_precision_score": 0.7001425279285131,
            "fpr": 0.15679824561403508,
            "logloss": 0.6134623968139564,
            "mae": 0.39101866349218445,
            "precision": 0.6836283185840708,
            "recall": 0.6602564102564102
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7622978031809025,
            "auditor_fn_violation": 0.01369182330275146,
            "auditor_fp_violation": 0.01949506037321625,
            "ave_precision_score": 0.7443861962950217,
            "fpr": 0.14928649835345773,
            "logloss": 0.5896349062834972,
            "mae": 0.37858172876578394,
            "precision": 0.7166666666666667,
            "recall": 0.7078189300411523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6457928413693477,
            "auditor_fn_violation": 0.032571412505623044,
            "auditor_fp_violation": 0.0012520744428639252,
            "ave_precision_score": 0.6373745268957636,
            "fpr": 0.12828947368421054,
            "logloss": 0.6965386761676122,
            "mae": 0.45831631287409547,
            "precision": 0.629746835443038,
            "recall": 0.4252136752136752
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6563380498395228,
            "auditor_fn_violation": 0.0348280955672101,
            "auditor_fp_violation": 0.009168980435203726,
            "ave_precision_score": 0.6487987075514694,
            "fpr": 0.11525795828759605,
            "logloss": 0.6968327216551017,
            "mae": 0.4608276745817664,
            "precision": 0.6579804560260586,
            "recall": 0.4156378600823045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.49816484389469623,
            "auditor_fn_violation": 0.0074833183385815015,
            "auditor_fp_violation": 0.004455113007744601,
            "ave_precision_score": 0.4983787092599872,
            "fpr": 0.38048245614035087,
            "logloss": 0.6952899850219311,
            "mae": 0.5004058410985428,
            "precision": 0.48208955223880595,
            "recall": 0.6901709401709402
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5651356342759724,
            "auditor_fn_violation": 0.012634783826392564,
            "auditor_fp_violation": 0.010860721895783574,
            "ave_precision_score": 0.5663498569373606,
            "fpr": 0.3534577387486279,
            "logloss": 0.690420261518641,
            "mae": 0.4979873126869537,
            "precision": 0.5208333333333334,
            "recall": 0.720164609053498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7039436889202872,
            "auditor_fn_violation": 0.11101973684210528,
            "auditor_fp_violation": 0.1131608582266477,
            "ave_precision_score": 0.5700797715765925,
            "fpr": 0.19078947368421054,
            "logloss": 0.6749831639900816,
            "mae": 0.4846685933635423,
            "precision": 0.610738255033557,
            "recall": 0.5833333333333334
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7126603932311946,
            "auditor_fn_violation": 0.12164085051022482,
            "auditor_fp_violation": 0.10967908568476788,
            "ave_precision_score": 0.5820159431575458,
            "fpr": 0.19758507135016465,
            "logloss": 0.6772690234773622,
            "mae": 0.48570247784535003,
            "precision": 0.6153846153846154,
            "recall": 0.5925925925925926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6313549652436135,
            "auditor_fn_violation": 0.005932298695456614,
            "auditor_fp_violation": 0.014758179231863445,
            "ave_precision_score": 0.630499648250432,
            "fpr": 0.07017543859649122,
            "logloss": 9.935894034744466,
            "mae": 0.4464644967657977,
            "precision": 0.6831683168316832,
            "recall": 0.2948717948717949
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6752195647344831,
            "auditor_fn_violation": 0.006509375578774299,
            "auditor_fp_violation": 0.010271840898818364,
            "ave_precision_score": 0.6730436912094222,
            "fpr": 0.05159165751920966,
            "logloss": 10.355598640492808,
            "mae": 0.43790365161645584,
            "precision": 0.7696078431372549,
            "recall": 0.3230452674897119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 9271,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5801795918384572,
            "auditor_fn_violation": 0.01311572199730096,
            "auditor_fp_violation": 0.02062588904694168,
            "ave_precision_score": 0.6016397764775541,
            "fpr": 0.08333333333333333,
            "logloss": 4.807117065491749,
            "mae": 0.48164043956250063,
            "precision": 0.680672268907563,
            "recall": 0.34615384615384615
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6485670333057216,
            "auditor_fn_violation": 0.019982111639630856,
            "auditor_fp_violation": 0.011648479369794023,
            "ave_precision_score": 0.6371443946661597,
            "fpr": 0.07683863885839737,
            "logloss": 5.1497145745269055,
            "mae": 0.48216996034602105,
            "precision": 0.7233201581027668,
            "recall": 0.3765432098765432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.799867243258426,
            "auditor_fn_violation": 0.0033878767431399026,
            "auditor_fp_violation": 0.02497727991149044,
            "ave_precision_score": 0.7508416004189217,
            "fpr": 0.1787280701754386,
            "logloss": 2.7379543382541347,
            "mae": 0.3027951316111476,
            "precision": 0.7109929078014184,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8081023077213235,
            "auditor_fn_violation": 0.013061665153383658,
            "auditor_fp_violation": 0.015140440369342034,
            "ave_precision_score": 0.7571344366802906,
            "fpr": 0.1668496158068057,
            "logloss": 2.8926754254875515,
            "mae": 0.2928397541325928,
            "precision": 0.7401709401709402,
            "recall": 0.8909465020576132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7747611500454387,
            "auditor_fn_violation": 0.0027552856500224925,
            "auditor_fp_violation": 0.02865694642010432,
            "ave_precision_score": 0.6611503010621603,
            "fpr": 0.23464912280701755,
            "logloss": 6.607906286432443,
            "mae": 0.32525007464819444,
            "precision": 0.6445182724252492,
            "recall": 0.8290598290598291
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7977374302774292,
            "auditor_fn_violation": 0.00983408094031341,
            "auditor_fp_violation": 0.02101375347065281,
            "ave_precision_score": 0.6912188499393684,
            "fpr": 0.22063666300768386,
            "logloss": 6.204353751533054,
            "mae": 0.3077347187708596,
            "precision": 0.6726384364820847,
            "recall": 0.8497942386831275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.5712931048191013,
            "auditor_fn_violation": 0.009053081421502476,
            "auditor_fp_violation": 0.027481428797218273,
            "ave_precision_score": 0.5615311964055607,
            "fpr": 0.34649122807017546,
            "logloss": 0.7266999923538321,
            "mae": 0.4697636761294122,
            "precision": 0.5641379310344827,
            "recall": 0.8739316239316239
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6235138255427438,
            "auditor_fn_violation": 0.008451798548151764,
            "auditor_fp_violation": 0.02199263898753793,
            "ave_precision_score": 0.5999806381652321,
            "fpr": 0.33479692645444564,
            "logloss": 0.7083706890770373,
            "mae": 0.46157464100422113,
            "precision": 0.5816186556927297,
            "recall": 0.8724279835390947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8381877572147853,
            "auditor_fn_violation": 0.0035893687209476747,
            "auditor_fp_violation": 0.008401493598862018,
            "ave_precision_score": 0.79817726608644,
            "fpr": 0.08991228070175439,
            "logloss": 0.5201497909099247,
            "mae": 0.3430436948935191,
            "precision": 0.8075117370892019,
            "recall": 0.7350427350427351
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8372381738531067,
            "auditor_fn_violation": 0.011586778875472624,
            "auditor_fp_violation": 0.010003228514237747,
            "ave_precision_score": 0.7962009735028497,
            "fpr": 0.09440175631174534,
            "logloss": 0.5234745203243775,
            "mae": 0.3464470718027339,
            "precision": 0.8032036613272311,
            "recall": 0.7222222222222222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8148173900393836,
            "auditor_fn_violation": 0.013223496776128357,
            "auditor_fp_violation": 0.014432195353247993,
            "ave_precision_score": 0.8152253438426735,
            "fpr": 0.125,
            "logloss": 0.5286594700824723,
            "mae": 0.34843952604033374,
            "precision": 0.7553648068669528,
            "recall": 0.7521367521367521
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8027054299554559,
            "auditor_fn_violation": 0.006281253811440417,
            "auditor_fp_violation": 0.013655323819978044,
            "ave_precision_score": 0.8042349865344101,
            "fpr": 0.1119648737650933,
            "logloss": 0.5190698733884248,
            "mae": 0.34289873585216246,
            "precision": 0.7834394904458599,
            "recall": 0.7592592592592593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6943142213358182,
            "auditor_fn_violation": 0.016060784975258664,
            "auditor_fp_violation": 0.00018768768768768744,
            "ave_precision_score": 0.682873956242821,
            "fpr": 0.05043859649122807,
            "logloss": 0.8070701782941937,
            "mae": 0.4172675219426051,
            "precision": 0.7430167597765364,
            "recall": 0.2841880341880342
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7289182833658855,
            "auditor_fn_violation": 0.010184168801073312,
            "auditor_fp_violation": 0.0020636663007683872,
            "ave_precision_score": 0.7109732695466177,
            "fpr": 0.03732162458836443,
            "logloss": 0.7869562398039854,
            "mae": 0.4204848713784748,
            "precision": 0.7988165680473372,
            "recall": 0.2777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7381329557430061,
            "auditor_fn_violation": 0.005742521367521374,
            "auditor_fp_violation": 0.010784633317528056,
            "ave_precision_score": 0.7083199648215219,
            "fpr": 0.11293859649122807,
            "logloss": 0.5681103315022137,
            "mae": 0.398183489708524,
            "precision": 0.7711111111111111,
            "recall": 0.7414529914529915
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.739675960023279,
            "auditor_fn_violation": 0.010010254186373229,
            "auditor_fp_violation": 0.006591334667785887,
            "ave_precision_score": 0.7049575897539064,
            "fpr": 0.11855104281009879,
            "logloss": 0.5831188686388953,
            "mae": 0.4045790908071003,
            "precision": 0.762114537444934,
            "recall": 0.7119341563786008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6471245706344928,
            "auditor_fn_violation": 0.07443722822012296,
            "auditor_fp_violation": 0.09300171882408725,
            "ave_precision_score": 0.5908782118296325,
            "fpr": 0.28618421052631576,
            "logloss": 0.6760080042826614,
            "mae": 0.4634632495698609,
            "precision": 0.5830670926517572,
            "recall": 0.7799145299145299
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6467484060419788,
            "auditor_fn_violation": 0.0733693810898348,
            "auditor_fp_violation": 0.08694259701685284,
            "ave_precision_score": 0.5970436003219095,
            "fpr": 0.2864983534577388,
            "logloss": 0.6836561857621721,
            "mae": 0.4685602233582611,
            "precision": 0.5953488372093023,
            "recall": 0.7901234567901234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 9271,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6482137501874343,
            "auditor_fn_violation": 0.12645261658419554,
            "auditor_fp_violation": 0.11820373004583531,
            "ave_precision_score": 0.5117937888405725,
            "fpr": 0.27521929824561403,
            "logloss": 0.6948838462595878,
            "mae": 0.4996946632469955,
            "precision": 0.5107212475633528,
            "recall": 0.5598290598290598
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6804104293833076,
            "auditor_fn_violation": 0.12919371377719957,
            "auditor_fp_violation": 0.11441337896300123,
            "ave_precision_score": 0.548926527159022,
            "fpr": 0.23929747530186607,
            "logloss": 0.6897200854343768,
            "mae": 0.49714884891468136,
            "precision": 0.5604838709677419,
            "recall": 0.5720164609053497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.4431085910732676,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4433327593158481,
            "fpr": 0.4868421052631579,
            "logloss": 0.6929944262219021,
            "mae": 0.4996653540354026,
            "precision": 0.5131578947368421,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.46653288172645324,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.46680355106121546,
            "fpr": 0.4665203073545554,
            "logloss": 0.6916339629329274,
            "mae": 0.49898437349254554,
            "precision": 0.5334796926454446,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8405575784339018,
            "auditor_fn_violation": 0.009081196581196585,
            "auditor_fp_violation": 0.009794333807491704,
            "ave_precision_score": 0.83842366712715,
            "fpr": 0.09868421052631579,
            "logloss": 0.5108271309062719,
            "mae": 0.31928647882631866,
            "precision": 0.7926267281105991,
            "recall": 0.7350427350427351
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8573995926743543,
            "auditor_fn_violation": 0.006649410723078253,
            "auditor_fp_violation": 0.013198166203912962,
            "ave_precision_score": 0.8566200185713888,
            "fpr": 0.0889132821075741,
            "logloss": 0.4885134934705892,
            "mae": 0.3124453058173935,
            "precision": 0.8154897494305239,
            "recall": 0.7366255144032922
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.6403586473999905,
            "auditor_fn_violation": 0.008905476833108422,
            "auditor_fp_violation": 0.013772818871503091,
            "ave_precision_score": 0.6369176942429441,
            "fpr": 0.14144736842105263,
            "logloss": 0.6644843435548408,
            "mae": 0.43213674344383834,
            "precision": 0.6913875598086124,
            "recall": 0.6175213675213675
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7094198437790092,
            "auditor_fn_violation": 0.018073568140649494,
            "auditor_fp_violation": 0.020993090979531222,
            "ave_precision_score": 0.687035251191139,
            "fpr": 0.12733260153677278,
            "logloss": 0.6294271490125987,
            "mae": 0.4145096331245944,
            "precision": 0.7333333333333333,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5404905814975187,
            "auditor_fn_violation": 0.005102901484480437,
            "auditor_fp_violation": 0.009942508297771456,
            "ave_precision_score": 0.536408130873279,
            "fpr": 0.08552631578947369,
            "logloss": 3.2127532352982295,
            "mae": 0.5013632175957168,
            "precision": 0.559322033898305,
            "recall": 0.21153846153846154
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5561712204805701,
            "auditor_fn_violation": 0.012819991597891345,
            "auditor_fp_violation": 0.006717892425905598,
            "ave_precision_score": 0.5529124477767198,
            "fpr": 0.07574094401756312,
            "logloss": 3.2954603239683653,
            "mae": 0.5116018451267182,
            "precision": 0.5740740740740741,
            "recall": 0.19135802469135801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7216019137474858,
            "auditor_fn_violation": 0.05135233918128655,
            "auditor_fp_violation": 0.015350877192982462,
            "ave_precision_score": 0.7144613059382449,
            "fpr": 0.08114035087719298,
            "logloss": 2.855299345706795,
            "mae": 0.34200993567258015,
            "precision": 0.7867435158501441,
            "recall": 0.5833333333333334
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7189143501522915,
            "auditor_fn_violation": 0.05525064032199049,
            "auditor_fp_violation": 0.015256666881900952,
            "ave_precision_score": 0.7133225136307297,
            "fpr": 0.07574094401756312,
            "logloss": 3.0864530257448637,
            "mae": 0.3694751594864715,
            "precision": 0.7896341463414634,
            "recall": 0.5329218106995884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8296559343514694,
            "auditor_fn_violation": 0.008907819763082928,
            "auditor_fp_violation": 0.01939110162794373,
            "ave_precision_score": 0.8304017422649173,
            "fpr": 0.15899122807017543,
            "logloss": 0.5368943624704356,
            "mae": 0.341205305179628,
            "precision": 0.7284644194756554,
            "recall": 0.8311965811965812
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.84226479152037,
            "auditor_fn_violation": 0.005176783076526949,
            "auditor_fp_violation": 0.0170775489119907,
            "ave_precision_score": 0.843059202812444,
            "fpr": 0.1394072447859495,
            "logloss": 0.5286740493431558,
            "mae": 0.3396596559982759,
            "precision": 0.7590132827324478,
            "recall": 0.823045267489712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7409762484188301,
            "auditor_fn_violation": 0.006011958314589914,
            "auditor_fp_violation": 0.009497984826932197,
            "ave_precision_score": 0.7414519911756673,
            "fpr": 0.046052631578947366,
            "logloss": 5.796465250575655,
            "mae": 0.41486428624811833,
            "precision": 0.8116591928251121,
            "recall": 0.38675213675213677
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7407985054480122,
            "auditor_fn_violation": 0.005366508110745221,
            "auditor_fp_violation": 0.004842771356621684,
            "ave_precision_score": 0.7413566498935615,
            "fpr": 0.052689352360043906,
            "logloss": 6.350421776390659,
            "mae": 0.42583534457540523,
            "precision": 0.7974683544303798,
            "recall": 0.3888888888888889
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7964398092565053,
            "auditor_fn_violation": 0.013654595891438005,
            "auditor_fp_violation": 0.006336929034297457,
            "ave_precision_score": 0.7638911819505168,
            "fpr": 0.10307017543859649,
            "logloss": 2.316726874490615,
            "mae": 0.2727063707721868,
            "precision": 0.7788235294117647,
            "recall": 0.7072649572649573
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8061868482121881,
            "auditor_fn_violation": 0.010814326950441116,
            "auditor_fp_violation": 0.01565700264738168,
            "ave_precision_score": 0.7684913484709799,
            "fpr": 0.10098792535675083,
            "logloss": 2.4996711958465085,
            "mae": 0.26348621879408946,
            "precision": 0.7951002227171492,
            "recall": 0.7345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8447597549376041,
            "auditor_fn_violation": 0.0003936122357174993,
            "auditor_fp_violation": 0.006697486960644859,
            "ave_precision_score": 0.8368260694720489,
            "fpr": 0.19736842105263158,
            "logloss": 0.5322849782919473,
            "mae": 0.33956123049485315,
            "precision": 0.6954314720812182,
            "recall": 0.8782051282051282
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8678963821840598,
            "auditor_fn_violation": 0.008029434483880148,
            "auditor_fp_violation": 0.0062349066959385396,
            "ave_precision_score": 0.8582179257532571,
            "fpr": 0.17453347969264543,
            "logloss": 0.49717922570912637,
            "mae": 0.32142240355357643,
            "precision": 0.7295918367346939,
            "recall": 0.8827160493827161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8460916551486526,
            "auditor_fn_violation": 0.009784075573549263,
            "auditor_fp_violation": 0.013177651335546074,
            "ave_precision_score": 0.8463267862312887,
            "fpr": 0.12280701754385964,
            "logloss": 0.5280794912145812,
            "mae": 0.33818389114329483,
            "precision": 0.7627118644067796,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.848771871587549,
            "auditor_fn_violation": 0.005005127093186614,
            "auditor_fp_violation": 0.01540646994253245,
            "ave_precision_score": 0.8490223519563388,
            "fpr": 0.11525795828759605,
            "logloss": 0.5153953721535316,
            "mae": 0.34185761462027925,
            "precision": 0.777542372881356,
            "recall": 0.7551440329218106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8200244652547208,
            "auditor_fn_violation": 0.007225596041385518,
            "auditor_fp_violation": 0.00731488067014384,
            "ave_precision_score": 0.819641129193929,
            "fpr": 0.19956140350877194,
            "logloss": 0.5371109968275068,
            "mae": 0.33919705348620355,
            "precision": 0.6872852233676976,
            "recall": 0.8547008547008547
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8165178318446416,
            "auditor_fn_violation": 0.005551715882243998,
            "auditor_fp_violation": 0.023813521017627688,
            "ave_precision_score": 0.818921486810391,
            "fpr": 0.18111964873765093,
            "logloss": 0.5236853270163576,
            "mae": 0.3381763352387872,
            "precision": 0.7145328719723183,
            "recall": 0.8497942386831275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8462961837515278,
            "auditor_fn_violation": 0.0325596978557505,
            "auditor_fp_violation": 0.01814396633475581,
            "ave_precision_score": 0.8462322830282002,
            "fpr": 0.08223684210526316,
            "logloss": 0.6012051202409353,
            "mae": 0.314679218543285,
            "precision": 0.8125,
            "recall": 0.6944444444444444
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8265345259749389,
            "auditor_fn_violation": 0.03532951172907265,
            "auditor_fp_violation": 0.012433654032414284,
            "ave_precision_score": 0.8269639248961528,
            "fpr": 0.07354555433589462,
            "logloss": 0.6034130712315781,
            "mae": 0.332516985542765,
            "precision": 0.825974025974026,
            "recall": 0.654320987654321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.697144344299203,
            "auditor_fn_violation": 0.009320175438596498,
            "auditor_fp_violation": 0.016269559032716933,
            "ave_precision_score": 0.6790541912443764,
            "fpr": 0.20394736842105263,
            "logloss": 1.8148632061167895,
            "mae": 0.36899695508493513,
            "precision": 0.6770833333333334,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7027356873376196,
            "auditor_fn_violation": 0.003654465540061351,
            "auditor_fp_violation": 0.011651062181184214,
            "ave_precision_score": 0.6855786784340017,
            "fpr": 0.1712403951701427,
            "logloss": 1.807412742637118,
            "mae": 0.36626560860247026,
            "precision": 0.7184115523465704,
            "recall": 0.8189300411522634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6683727686410981,
            "auditor_fn_violation": 0.01754385964912281,
            "auditor_fp_violation": 0.008771929824561422,
            "ave_precision_score": 0.5896173575066302,
            "fpr": 0.3881578947368421,
            "logloss": 0.6720663253137222,
            "mae": 0.4762624324413768,
            "precision": 0.5478927203065134,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7063882136033433,
            "auditor_fn_violation": 0.019677196406065783,
            "auditor_fp_violation": 0.024665848776393103,
            "ave_precision_score": 0.6264265522516063,
            "fpr": 0.3567508232711306,
            "logloss": 0.654938556684637,
            "mae": 0.46822629847720215,
            "precision": 0.5822622107969152,
            "recall": 0.9320987654320988
        }
    }
]