[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.049250658334881,
            "mae": 0.4102714245469032,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831304342262318,
            "mae": 0.44649667406513976,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.054347442067967,
            "mae": 0.41017745740777045,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.833520339783675,
            "mae": 0.4462816048184518,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7634489124500038,
            "auditor_fn_violation": 0.008601204216682062,
            "auditor_fp_violation": 0.01835180055401662,
            "ave_precision_score": 0.7639301882511984,
            "fpr": 0.08771929824561403,
            "logloss": 0.6064987069879992,
            "mae": 0.4077860323973654,
            "precision": 0.7746478873239436,
            "recall": 0.6030701754385965
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7829521566782109,
            "auditor_fn_violation": 0.007860200406455688,
            "auditor_fp_violation": 0.0040665208389259085,
            "ave_precision_score": 0.7832713622578593,
            "fpr": 0.09549945115257959,
            "logloss": 0.6015659333126087,
            "mae": 0.4011025083967935,
            "precision": 0.7780612244897959,
            "recall": 0.6124497991967871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8397109826574197,
            "auditor_fn_violation": 0.005431959833795016,
            "auditor_fp_violation": 0.015509579870729456,
            "ave_precision_score": 0.8401014343234048,
            "fpr": 0.1425438596491228,
            "logloss": 0.5886447136972348,
            "mae": 0.26273193855859733,
            "precision": 0.7415506958250497,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8181365918292547,
            "auditor_fn_violation": 0.014362609604168597,
            "auditor_fp_violation": 0.019832927124225568,
            "ave_precision_score": 0.8184658228914488,
            "fpr": 0.15916575192096596,
            "logloss": 0.6997004054667929,
            "mae": 0.29935084399561573,
            "precision": 0.7248576850094877,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6010651249378354,
            "auditor_fn_violation": 0.016678208679593718,
            "auditor_fp_violation": 0.028600146198830417,
            "ave_precision_score": 0.6018967170592302,
            "fpr": 0.08442982456140351,
            "logloss": 1.2726339613253619,
            "mae": 0.47191298614550187,
            "precision": 0.6091370558375635,
            "recall": 0.2631578947368421
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6751129595768867,
            "auditor_fn_violation": 0.021160382473913213,
            "auditor_fp_violation": 0.024040314371297274,
            "ave_precision_score": 0.675743327929327,
            "fpr": 0.07574094401756312,
            "logloss": 1.3089348718569107,
            "mae": 0.48623055084705613,
            "precision": 0.6820276497695853,
            "recall": 0.2971887550200803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.0511564658474875,
            "mae": 0.4102520110992421,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.832120714524689,
            "mae": 0.4464159777631286,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.05658555139438,
            "mae": 0.4101132583955564,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.834520043443006,
            "mae": 0.44619234341772274,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5951719006139031,
            "auditor_fn_violation": 0.015235457063711913,
            "auditor_fp_violation": 0.02829716835949523,
            "ave_precision_score": 0.5960253482570184,
            "fpr": 0.07456140350877193,
            "logloss": 1.239394632231692,
            "mae": 0.4763034570465894,
            "precision": 0.6304347826086957,
            "recall": 0.2543859649122807
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.661200292826537,
            "auditor_fn_violation": 0.02171584251385346,
            "auditor_fp_violation": 0.018761810850966,
            "ave_precision_score": 0.6619331133616724,
            "fpr": 0.07354555433589462,
            "logloss": 1.2723180536763001,
            "mae": 0.49040925219751136,
            "precision": 0.6824644549763034,
            "recall": 0.2891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.052989441791666,
            "mae": 0.4102129583296023,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.832920415958056,
            "mae": 0.4463379844066275,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.053914603584725,
            "mae": 0.41028942006207153,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.833477869469781,
            "mae": 0.4464158469629111,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8488100778042574,
            "auditor_fn_violation": 0.021020891043397973,
            "auditor_fp_violation": 0.015783702677746998,
            "ave_precision_score": 0.8486303084090927,
            "fpr": 0.08552631578947369,
            "logloss": 0.49713199812693115,
            "mae": 0.33324173381838035,
            "precision": 0.805,
            "recall": 0.706140350877193
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7908971476781801,
            "auditor_fn_violation": 0.021028130083451266,
            "auditor_fp_violation": 0.022480152454663612,
            "ave_precision_score": 0.7912687857884784,
            "fpr": 0.10208562019758508,
            "logloss": 0.5688983314630243,
            "mae": 0.36112339640267266,
            "precision": 0.7816901408450704,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7636918064411069,
            "auditor_fn_violation": 0.04171716297322253,
            "auditor_fp_violation": 0.07544629116651276,
            "ave_precision_score": 0.7532908883104513,
            "fpr": 0.25219298245614036,
            "logloss": 0.6064647749642674,
            "mae": 0.4090520314741553,
            "precision": 0.6013864818024264,
            "recall": 0.7609649122807017
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7837468760979281,
            "auditor_fn_violation": 0.04090786857639119,
            "auditor_fp_violation": 0.05700836959092926,
            "ave_precision_score": 0.7736401802412929,
            "fpr": 0.2491767288693743,
            "logloss": 0.6017175270799359,
            "mae": 0.40215565846531637,
            "precision": 0.6278688524590164,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7456534732418647,
            "auditor_fn_violation": 0.003118748076331179,
            "auditor_fp_violation": 0.008218875038473404,
            "ave_precision_score": 0.5086183375737677,
            "fpr": 0.47149122807017546,
            "logloss": 16.125430606328766,
            "mae": 0.48389777610601303,
            "precision": 0.5074455899198167,
            "recall": 0.9714912280701754
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7749765410315611,
            "auditor_fn_violation": 0.0020190531610525526,
            "auditor_fp_violation": 0.0022804410979074953,
            "ave_precision_score": 0.5597291065930459,
            "fpr": 0.42151481888035125,
            "logloss": 14.544025485706292,
            "mae": 0.43389250151608566,
            "precision": 0.5606407322654462,
            "recall": 0.9839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.008293417205293935,
            "auditor_fp_violation": 0.022660818713450298,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.17543859649122806,
            "logloss": 5.020020549552728,
            "mae": 0.39623358579385176,
            "precision": 0.6728016359918201,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.015138490294878754,
            "auditor_fp_violation": 0.020130607081061975,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.17672886937431395,
            "logloss": 5.799952537736405,
            "mae": 0.4307180828405657,
            "precision": 0.6867704280155642,
            "recall": 0.7088353413654619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6912524096828997,
            "auditor_fn_violation": 0.00812269159741459,
            "auditor_fp_violation": 0.007858187134502924,
            "ave_precision_score": 0.6498066235752433,
            "fpr": 0.041666666666666664,
            "logloss": 5.0634888987121505,
            "mae": 0.3924769432480006,
            "precision": 0.7840909090909091,
            "recall": 0.3026315789473684
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6793061695085776,
            "auditor_fn_violation": 0.00657514801246699,
            "auditor_fp_violation": 0.014323190065994584,
            "ave_precision_score": 0.6454155859561077,
            "fpr": 0.04939626783754116,
            "logloss": 5.819886753771829,
            "mae": 0.43398647870803014,
            "precision": 0.7352941176470589,
            "recall": 0.25100401606425704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.0498571325975,
            "mae": 0.41026863505606326,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6892854254883825,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6452905219508788,
            "fpr": 0.04061470911086718,
            "logloss": 5.831562244446943,
            "mae": 0.4464713569922714,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7185546079939226,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.7212639980646365,
            "fpr": 0.46600877192982454,
            "logloss": 2.2927775945474966,
            "mae": 0.48178040091634583,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7595061706047981,
            "auditor_fn_violation": 0.0024114019194230274,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.7605035999422595,
            "fpr": 0.42041712403951703,
            "logloss": 2.0944946949320413,
            "mae": 0.43235751822116475,
            "precision": 0.5602755453501722,
            "recall": 0.9799196787148594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8166128894922018,
            "auditor_fn_violation": 0.008954678362573104,
            "auditor_fp_violation": 0.023026315789473686,
            "ave_precision_score": 0.817525421770535,
            "fpr": 0.17105263157894737,
            "logloss": 0.6780909928588786,
            "mae": 0.27338289774735397,
            "precision": 0.7089552238805971,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8092199075075692,
            "auditor_fn_violation": 0.011871856250468393,
            "auditor_fp_violation": 0.02208413179780089,
            "ave_precision_score": 0.8097412042311247,
            "fpr": 0.1778265642151482,
            "logloss": 0.7788421472989918,
            "mae": 0.3027385323865534,
            "precision": 0.7101967799642218,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.765090721510985,
            "auditor_fn_violation": 0.008601204216682062,
            "auditor_fp_violation": 0.01835180055401662,
            "ave_precision_score": 0.7655700018468089,
            "fpr": 0.08771929824561403,
            "logloss": 0.6024062398727653,
            "mae": 0.40502159611174937,
            "precision": 0.7746478873239436,
            "recall": 0.6030701754385965
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7833069561691475,
            "auditor_fn_violation": 0.007860200406455688,
            "auditor_fp_violation": 0.0040665208389259085,
            "ave_precision_score": 0.7836290142401647,
            "fpr": 0.09549945115257959,
            "logloss": 0.6006711099134276,
            "mae": 0.4000613291458555,
            "precision": 0.7780612244897959,
            "recall": 0.6124497991967871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.047673516817883,
            "mae": 0.41027223688076464,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.830686717922349,
            "mae": 0.4465843221718603,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 6126,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.44694873789563905,
            "auditor_fn_violation": 0.012147968605724837,
            "auditor_fp_violation": 0.015350877192982462,
            "ave_precision_score": 0.44845278169354263,
            "fpr": 0.2236842105263158,
            "logloss": 1.0768469945381256,
            "mae": 0.5293423256606044,
            "precision": 0.47692307692307695,
            "recall": 0.40789473684210525
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5067815004763001,
            "auditor_fn_violation": 0.017179585521008317,
            "auditor_fp_violation": 0.015141809947294702,
            "ave_precision_score": 0.5083165325766041,
            "fpr": 0.18660812294182216,
            "logloss": 1.0543276644185495,
            "mae": 0.5238477671074218,
            "precision": 0.5303867403314917,
            "recall": 0.3855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 6126,
        "test": {
            "accuracy": 0.4375,
            "auc_prc": 0.4048841395942454,
            "auditor_fn_violation": 0.019041916743613427,
            "auditor_fp_violation": 0.020958371806709754,
            "ave_precision_score": 0.40390732226023235,
            "fpr": 0.2149122807017544,
            "logloss": 3.3549253160722667,
            "mae": 0.5837453381911596,
            "precision": 0.41492537313432837,
            "recall": 0.3048245614035088
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.4791963148679544,
            "auditor_fn_violation": 0.023362384775104807,
            "auditor_fp_violation": 0.022450916030331464,
            "ave_precision_score": 0.4784238912039268,
            "fpr": 0.15916575192096596,
            "logloss": 3.382474392020813,
            "mae": 0.5609886115472565,
            "precision": 0.5292207792207793,
            "recall": 0.3273092369477912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5921869075287212,
            "auditor_fn_violation": 0.019378558787319176,
            "auditor_fp_violation": 0.03087488457987073,
            "ave_precision_score": 0.5930607166877325,
            "fpr": 0.07675438596491228,
            "logloss": 1.2791945616116995,
            "mae": 0.4774155489418231,
            "precision": 0.6216216216216216,
            "recall": 0.25219298245614036
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6577392937952227,
            "auditor_fn_violation": 0.029168264716384746,
            "auditor_fp_violation": 0.021685453284180704,
            "ave_precision_score": 0.6584894494608533,
            "fpr": 0.07135016465422613,
            "logloss": 1.3150976218657937,
            "mae": 0.4912843644027583,
            "precision": 0.6844660194174758,
            "recall": 0.28313253012048195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7685163726495005,
            "auditor_fn_violation": 0.027301669744536784,
            "auditor_fp_violation": 0.016774392120652508,
            "ave_precision_score": 0.7241255208735898,
            "fpr": 0.12280701754385964,
            "logloss": 4.258837952445676,
            "mae": 0.3189958933667231,
            "precision": 0.7213930348258707,
            "recall": 0.6359649122807017
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7701749927549542,
            "auditor_fn_violation": 0.03499398251623398,
            "auditor_fp_violation": 0.02363897800091963,
            "ave_precision_score": 0.7274277980507151,
            "fpr": 0.13391877058177826,
            "logloss": 4.58705757337577,
            "mae": 0.3455389710536183,
            "precision": 0.7227272727272728,
            "recall": 0.6385542168674698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.664682958455219,
            "auditor_fn_violation": 0.00686749769159742,
            "auditor_fp_violation": 0.008490593259464451,
            "ave_precision_score": 0.6577389960194862,
            "fpr": 0.03399122807017544,
            "logloss": 0.6432092820502734,
            "mae": 0.4461482455137006,
            "precision": 0.8228571428571428,
            "recall": 0.3157894736842105
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6615680091745514,
            "auditor_fn_violation": 0.011422198122897749,
            "auditor_fp_violation": 0.013151075235951234,
            "ave_precision_score": 0.6546267939843751,
            "fpr": 0.042810098792535674,
            "logloss": 0.6693431845639396,
            "mae": 0.45657188488675526,
            "precision": 0.7821229050279329,
            "recall": 0.28112449799196787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7993421052631579,
            "auc_prc": 0.8636918787972709,
            "auditor_fn_violation": 0.008310249307479227,
            "auditor_fp_violation": 0.014514081255771005,
            "ave_precision_score": 0.8639801610898771,
            "fpr": 0.08881578947368421,
            "logloss": 0.7208716366838128,
            "mae": 0.2575542504096386,
            "precision": 0.8137931034482758,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8398516232738064,
            "auditor_fn_violation": 0.009718346492446187,
            "auditor_fp_violation": 0.014817551422883617,
            "ave_precision_score": 0.8400698467842376,
            "fpr": 0.11855104281009879,
            "logloss": 0.7166348327134706,
            "mae": 0.3027170963080717,
            "precision": 0.7697228144989339,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8124377398400501,
            "auditor_fn_violation": 0.004674515235457069,
            "auditor_fp_violation": 0.015860649430594037,
            "ave_precision_score": 0.8131013294812722,
            "fpr": 0.13706140350877194,
            "logloss": 0.6673619270137384,
            "mae": 0.2752370725134165,
            "precision": 0.7422680412371134,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8007251635085103,
            "auditor_fn_violation": 0.0062511296558351945,
            "auditor_fp_violation": 0.02007479208915515,
            "ave_precision_score": 0.8011664335434289,
            "fpr": 0.1602634467618002,
            "logloss": 0.7804010130545898,
            "mae": 0.30945414709482305,
            "precision": 0.7203065134099617,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7697113195337671,
            "auditor_fn_violation": 0.014716066481994462,
            "auditor_fp_violation": 0.021804786088027085,
            "ave_precision_score": 0.7700514172205223,
            "fpr": 0.10307017543859649,
            "logloss": 0.6015196822807851,
            "mae": 0.40653588475757524,
            "precision": 0.7513227513227513,
            "recall": 0.6228070175438597
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7868255960094367,
            "auditor_fn_violation": 0.008212873447687568,
            "auditor_fp_violation": 0.007941675991314127,
            "ave_precision_score": 0.7870876150042967,
            "fpr": 0.10428100987925357,
            "logloss": 0.6001224704917955,
            "mae": 0.4011355707203125,
            "precision": 0.7677261613691931,
            "recall": 0.6305220883534136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7605961042270111,
            "auditor_fn_violation": 0.006458718067097572,
            "auditor_fp_violation": 0.0122225107725454,
            "ave_precision_score": 0.7527104659177615,
            "fpr": 0.07785087719298246,
            "logloss": 0.6073483310433372,
            "mae": 0.40671326587662887,
            "precision": 0.7874251497005988,
            "recall": 0.5767543859649122
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7803209363827479,
            "auditor_fn_violation": 0.011115813418327538,
            "auditor_fp_violation": 0.012058696108631924,
            "ave_precision_score": 0.7725835280476099,
            "fpr": 0.07903402854006586,
            "logloss": 0.6032978025741421,
            "mae": 0.4004502992762169,
            "precision": 0.8016528925619835,
            "recall": 0.5843373493975904
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.675072397166181,
            "auditor_fn_violation": 0.005107340720221624,
            "auditor_fp_violation": 0.011869036626654356,
            "ave_precision_score": 0.6740472686026324,
            "fpr": 0.03508771929824561,
            "logloss": 0.6479785167022549,
            "mae": 0.4526027741335463,
            "precision": 0.8160919540229885,
            "recall": 0.31140350877192985
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6937198159446863,
            "auditor_fn_violation": 0.00700496828146837,
            "auditor_fp_violation": 0.01074837272720024,
            "ave_precision_score": 0.6907498411876084,
            "fpr": 0.042810098792535674,
            "logloss": 0.6622867395702695,
            "mae": 0.4577500011146265,
            "precision": 0.7891891891891892,
            "recall": 0.2931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5908903876340295,
            "auditor_fn_violation": 0.023062384579870726,
            "auditor_fp_violation": 0.032959660664819944,
            "ave_precision_score": 0.591762037504391,
            "fpr": 0.0800438596491228,
            "logloss": 1.299954521796504,
            "mae": 0.4780490256278171,
            "precision": 0.6157894736842106,
            "recall": 0.2565789473684211
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6549997842819234,
            "auditor_fn_violation": 0.02517424252443364,
            "auditor_fp_violation": 0.023014381662914658,
            "ave_precision_score": 0.6557583270928647,
            "fpr": 0.07683863885839737,
            "logloss": 1.3397367071622592,
            "mae": 0.49241485702524085,
            "precision": 0.6682464454976303,
            "recall": 0.28313253012048195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 6126,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5526024996864745,
            "auditor_fn_violation": 0.00898353339489074,
            "auditor_fp_violation": 0.0028999307479224377,
            "ave_precision_score": 0.548558084172684,
            "fpr": 0.04276315789473684,
            "logloss": 0.6904119208230352,
            "mae": 0.48915448588760274,
            "precision": 0.5894736842105263,
            "recall": 0.12280701754385964
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.614162455278081,
            "auditor_fn_violation": 0.013159112850964787,
            "auditor_fp_violation": 0.008167593815698896,
            "ave_precision_score": 0.6040333453901471,
            "fpr": 0.030735455543358946,
            "logloss": 0.680764915182221,
            "mae": 0.4881184698786877,
            "precision": 0.6705882352941176,
            "recall": 0.1144578313253012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.768538289539542,
            "auditor_fn_violation": 0.027910030009233616,
            "auditor_fp_violation": 0.016774392120652508,
            "ave_precision_score": 0.7241474147356368,
            "fpr": 0.12280701754385964,
            "logloss": 4.258683690326184,
            "mae": 0.3189807218684903,
            "precision": 0.7220843672456576,
            "recall": 0.6381578947368421
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7701852724471787,
            "auditor_fn_violation": 0.035124030700188234,
            "auditor_fp_violation": 0.02363897800091963,
            "ave_precision_score": 0.727438073285382,
            "fpr": 0.13391877058177826,
            "logloss": 4.586889863510982,
            "mae": 0.34552870462791363,
            "precision": 0.7233560090702947,
            "recall": 0.6405622489959839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.769519029466893,
            "auditor_fn_violation": 0.017918975069252076,
            "auditor_fp_violation": 0.006290397045244694,
            "ave_precision_score": 0.724423578061926,
            "fpr": 0.12719298245614036,
            "logloss": 4.28019039307649,
            "mae": 0.31676152641807437,
            "precision": 0.7211538461538461,
            "recall": 0.6578947368421053
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7704426331802309,
            "auditor_fn_violation": 0.01771520770237923,
            "auditor_fp_violation": 0.01545543704467592,
            "ave_precision_score": 0.7270962345178877,
            "fpr": 0.13391877058177826,
            "logloss": 4.595273515223426,
            "mae": 0.34363732027105,
            "precision": 0.7282850779510023,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8122470983818405,
            "auditor_fn_violation": 0.004674515235457069,
            "auditor_fp_violation": 0.015860649430594037,
            "ave_precision_score": 0.8129110530774041,
            "fpr": 0.13706140350877194,
            "logloss": 0.6703581899164989,
            "mae": 0.27513725145807205,
            "precision": 0.7422680412371134,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8008261916785993,
            "auditor_fn_violation": 0.005726528507002763,
            "auditor_fp_violation": 0.02007479208915515,
            "ave_precision_score": 0.8012662991339186,
            "fpr": 0.1602634467618002,
            "logloss": 0.7839001121755925,
            "mae": 0.3094369092155718,
            "precision": 0.7197696737044146,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8299563591129278,
            "auditor_fn_violation": 0.00585276238842721,
            "auditor_fp_violation": 0.016447368421052634,
            "ave_precision_score": 0.8307494696379913,
            "fpr": 0.125,
            "logloss": 0.6278602849244316,
            "mae": 0.2657576238361327,
            "precision": 0.7605042016806722,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8155042149151144,
            "auditor_fn_violation": 0.014014344975952114,
            "auditor_fp_violation": 0.01824352878325976,
            "ave_precision_score": 0.815862177495304,
            "fpr": 0.15477497255762898,
            "logloss": 0.7506128791922869,
            "mae": 0.3057433001979819,
            "precision": 0.7240704500978473,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6017425594731716,
            "auditor_fn_violation": 0.004073368728839647,
            "auditor_fp_violation": 0.0018467220683287167,
            "ave_precision_score": 0.59847924578598,
            "fpr": 0.04824561403508772,
            "logloss": 0.6697789592714726,
            "mae": 0.4765205749620994,
            "precision": 0.674074074074074,
            "recall": 0.19956140350877194
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6276449158338124,
            "auditor_fn_violation": 0.002962453546347852,
            "auditor_fp_violation": 0.0057569177366754995,
            "ave_precision_score": 0.6246994986867225,
            "fpr": 0.043907793633369926,
            "logloss": 0.6781391418335198,
            "mae": 0.480255236544541,
            "precision": 0.6875,
            "recall": 0.17670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5376914905850576,
            "auditor_fn_violation": 0.01117411126500462,
            "auditor_fp_violation": 0.02123009002770083,
            "ave_precision_score": 0.540831143976226,
            "fpr": 0.10197368421052631,
            "logloss": 8.252541645796702,
            "mae": 0.4921677837805495,
            "precision": 0.5485436893203883,
            "recall": 0.24780701754385964
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6149341634345138,
            "auditor_fn_violation": 0.010346545347140478,
            "auditor_fp_violation": 0.011330443357085712,
            "ave_precision_score": 0.61615815234561,
            "fpr": 0.10208562019758508,
            "logloss": 8.090851172250266,
            "mae": 0.4923282405789434,
            "precision": 0.5956521739130435,
            "recall": 0.2751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8684024133390406,
            "auditor_fn_violation": 0.01395862188365651,
            "auditor_fp_violation": 0.01817867036011081,
            "ave_precision_score": 0.863866587351454,
            "fpr": 0.14912280701754385,
            "logloss": 0.4814648097340749,
            "mae": 0.3276097915347731,
            "precision": 0.743879472693032,
            "recall": 0.8662280701754386
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8368633602180227,
            "auditor_fn_violation": 0.026344676180021953,
            "auditor_fp_violation": 0.016566421169297508,
            "ave_precision_score": 0.8329875997086993,
            "fpr": 0.15697036223929747,
            "logloss": 0.5257399261249688,
            "mae": 0.3392418215192372,
            "precision": 0.7404718693284936,
            "recall": 0.8192771084337349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7271045547206614,
            "auditor_fn_violation": 0.010938461834410584,
            "auditor_fp_violation": 0.011611745921822104,
            "ave_precision_score": 0.703621068741938,
            "fpr": 0.07785087719298246,
            "logloss": 0.6521187194305387,
            "mae": 0.42910690942223656,
            "precision": 0.7633333333333333,
            "recall": 0.5021929824561403
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7701543442477599,
            "auditor_fn_violation": 0.012083460075207534,
            "auditor_fp_violation": 0.01027793208112842,
            "ave_precision_score": 0.7506166974620787,
            "fpr": 0.07354555433589462,
            "logloss": 0.6351921457714311,
            "mae": 0.4202631108062066,
            "precision": 0.790625,
            "recall": 0.5080321285140562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8453711390263866,
            "auditor_fn_violation": 0.002923976608187138,
            "auditor_fp_violation": 0.008021698984302862,
            "ave_precision_score": 0.8386731022583168,
            "fpr": 0.07894736842105263,
            "logloss": 0.510327362932034,
            "mae": 0.3397335519017488,
            "precision": 0.8085106382978723,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7847085895295034,
            "auditor_fn_violation": 0.0025833300270235683,
            "auditor_fp_violation": 0.01291718384129406,
            "ave_precision_score": 0.7884639455888962,
            "fpr": 0.09001097694840834,
            "logloss": 0.5783177741276919,
            "mae": 0.36621166483123924,
            "precision": 0.7939698492462312,
            "recall": 0.6345381526104418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8161118865667769,
            "auditor_fn_violation": 0.008954678362573104,
            "auditor_fp_violation": 0.023026315789473686,
            "ave_precision_score": 0.8170260109751738,
            "fpr": 0.17105263157894737,
            "logloss": 0.6810794542479205,
            "mae": 0.2734774532928021,
            "precision": 0.7089552238805971,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8089427884367786,
            "auditor_fn_violation": 0.009535397352307146,
            "auditor_fp_violation": 0.02208413179780089,
            "ave_precision_score": 0.8094626912972773,
            "fpr": 0.1778265642151482,
            "logloss": 0.7820180597221014,
            "mae": 0.3028794327809854,
            "precision": 0.7096774193548387,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8699642737725357,
            "auditor_fn_violation": 0.01459343259464451,
            "auditor_fp_violation": 0.014860341643582643,
            "ave_precision_score": 0.8692632456785246,
            "fpr": 0.12719298245614036,
            "logloss": 0.4672756026349249,
            "mae": 0.3239194781421439,
            "precision": 0.7684630738522954,
            "recall": 0.8442982456140351
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8402134934635541,
            "auditor_fn_violation": 0.025216122448079917,
            "auditor_fp_violation": 0.01937843361869856,
            "ave_precision_score": 0.838646555027185,
            "fpr": 0.1437980241492865,
            "logloss": 0.5147323535767115,
            "mae": 0.3392665483769025,
            "precision": 0.7532956685499058,
            "recall": 0.8032128514056225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6018255061118436,
            "auditor_fn_violation": 0.016678208679593718,
            "auditor_fp_violation": 0.028600146198830417,
            "ave_precision_score": 0.6026542609998702,
            "fpr": 0.08442982456140351,
            "logloss": 1.2726444977451576,
            "mae": 0.4716533036691161,
            "precision": 0.6091370558375635,
            "recall": 0.2631578947368421
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6760461182931757,
            "auditor_fn_violation": 0.021160382473913213,
            "auditor_fp_violation": 0.024040314371297274,
            "ave_precision_score": 0.6766712581249941,
            "fpr": 0.07574094401756312,
            "logloss": 1.309015131562887,
            "mae": 0.485995145917269,
            "precision": 0.6820276497695853,
            "recall": 0.2971887550200803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8034862391215682,
            "auditor_fn_violation": 0.004674515235457063,
            "auditor_fp_violation": 0.022256848261003395,
            "ave_precision_score": 0.7805051246384764,
            "fpr": 0.10964912280701754,
            "logloss": 5.004920232277565,
            "mae": 0.27937952672407507,
            "precision": 0.7572815533980582,
            "recall": 0.6842105263157895
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7975774382249765,
            "auditor_fn_violation": 0.025582020728357996,
            "auditor_fp_violation": 0.025302796331094533,
            "ave_precision_score": 0.7776934626385938,
            "fpr": 0.12733260153677278,
            "logloss": 5.8848980844769025,
            "mae": 0.3310695233310643,
            "precision": 0.7339449541284404,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8461018267650016,
            "auditor_fn_violation": 0.00506405817174515,
            "auditor_fp_violation": 0.020660203139427524,
            "ave_precision_score": 0.8464861909307232,
            "fpr": 0.13925438596491227,
            "logloss": 0.5749254454569472,
            "mae": 0.2589955353366241,
            "precision": 0.7465069860279441,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8236784212781585,
            "auditor_fn_violation": 0.012343556443116044,
            "auditor_fp_violation": 0.019532589310631697,
            "ave_precision_score": 0.8239729743978662,
            "fpr": 0.1602634467618002,
            "logloss": 0.6869843529591958,
            "mae": 0.2980373666561606,
            "precision": 0.7255639097744361,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8134708185016715,
            "auditor_fn_violation": 0.006732840874115113,
            "auditor_fp_violation": 0.024671052631578955,
            "ave_precision_score": 0.8143898393079239,
            "fpr": 0.17653508771929824,
            "logloss": 0.6955309303634621,
            "mae": 0.27521284227598825,
            "precision": 0.7034990791896869,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8066939143040238,
            "auditor_fn_violation": 0.012508871931193495,
            "auditor_fp_violation": 0.02234460176003275,
            "ave_precision_score": 0.8072216385588357,
            "fpr": 0.18441273326015367,
            "logloss": 0.7941827389399897,
            "mae": 0.3038231866306519,
            "precision": 0.7047451669595782,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.052007127201902,
            "mae": 0.41023557958307494,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.832490272736007,
            "mae": 0.44637960832234796,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.7456618782483423,
            "auditor_fn_violation": 0.003118748076331179,
            "auditor_fp_violation": 0.007617728531855961,
            "ave_precision_score": 0.508608198332376,
            "fpr": 0.47039473684210525,
            "logloss": 16.12536594975689,
            "mae": 0.48388394489557596,
            "precision": 0.5080275229357798,
            "recall": 0.9714912280701754
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7749500699120144,
            "auditor_fn_violation": 0.0020190531610525526,
            "auditor_fp_violation": 0.0022804410979074953,
            "ave_precision_score": 0.5596554793510278,
            "fpr": 0.42151481888035125,
            "logloss": 14.544090700635795,
            "mae": 0.43391613978749444,
            "precision": 0.5606407322654462,
            "recall": 0.9839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 6126,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.44147374738369016,
            "auditor_fn_violation": 0.004061345798707296,
            "auditor_fp_violation": 0.015350877192982459,
            "ave_precision_score": 0.4429341842044053,
            "fpr": 0.25,
            "logloss": 1.1452071626975007,
            "mae": 0.5347623232940494,
            "precision": 0.46853146853146854,
            "recall": 0.4407894736842105
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5005508907146333,
            "auditor_fn_violation": 0.0106419090191722,
            "auditor_fp_violation": 0.016848153985589098,
            "ave_precision_score": 0.5020433662336405,
            "fpr": 0.2030735455543359,
            "logloss": 1.109277944119689,
            "mae": 0.525366971096991,
            "precision": 0.5292620865139949,
            "recall": 0.41767068273092367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5579962510326911,
            "auditor_fn_violation": 0.014389042782394588,
            "auditor_fp_violation": 0.00638417590027701,
            "ave_precision_score": 0.5537904783467354,
            "fpr": 0.047149122807017545,
            "logloss": 0.6932726180376952,
            "mae": 0.486481700353978,
            "precision": 0.5981308411214953,
            "recall": 0.14035087719298245
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.6139232213710886,
            "auditor_fn_violation": 0.018638770229105234,
            "auditor_fp_violation": 0.0016106611950255558,
            "ave_precision_score": 0.6078005258313979,
            "fpr": 0.03293084522502744,
            "logloss": 0.6836228548425308,
            "mae": 0.4851493747776086,
            "precision": 0.6907216494845361,
            "recall": 0.13453815261044177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8280261522947224,
            "auditor_fn_violation": 0.003722299168975069,
            "auditor_fp_violation": 0.006922803170206221,
            "ave_precision_score": 0.8283116566844317,
            "fpr": 0.0581140350877193,
            "logloss": 0.8174562009148426,
            "mae": 0.3191379781856613,
            "precision": 0.8403614457831325,
            "recall": 0.6118421052631579
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7659447900140431,
            "auditor_fn_violation": 0.010053385881616484,
            "auditor_fp_violation": 0.009940384272929995,
            "ave_precision_score": 0.7663921788597975,
            "fpr": 0.09769484083424808,
            "logloss": 1.012881940395816,
            "mae": 0.37954560561621054,
            "precision": 0.7554945054945055,
            "recall": 0.5522088353413654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 6126,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8273618646791008,
            "auditor_fn_violation": 0.0054776469682979384,
            "auditor_fp_violation": 0.022999865343182515,
            "ave_precision_score": 0.8276531841806225,
            "fpr": 0.23793859649122806,
            "logloss": 0.8464468184623113,
            "mae": 0.32566665482632356,
            "precision": 0.6377295492487479,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7687344518319413,
            "auditor_fn_violation": 0.009438412265968376,
            "auditor_fp_violation": 0.028141387348070267,
            "ave_precision_score": 0.7691785094027117,
            "fpr": 0.23161361141602635,
            "logloss": 0.9751107126698924,
            "mae": 0.35642378976675093,
            "precision": 0.6529605263157895,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.7456618782483423,
            "auditor_fn_violation": 0.003118748076331179,
            "auditor_fp_violation": 0.007617728531855961,
            "ave_precision_score": 0.508608198332376,
            "fpr": 0.47039473684210525,
            "logloss": 16.125365940023137,
            "mae": 0.4838839477548997,
            "precision": 0.5080275229357798,
            "recall": 0.9714912280701754
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7749500699120144,
            "auditor_fn_violation": 0.0020190531610525526,
            "auditor_fp_violation": 0.0022804410979074953,
            "ave_precision_score": 0.5596554793510278,
            "fpr": 0.42151481888035125,
            "logloss": 14.544090693774965,
            "mae": 0.4339161444737542,
            "precision": 0.5606407322654462,
            "recall": 0.9839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6549791133323877,
            "auditor_fn_violation": 0.03377481532779319,
            "auditor_fp_violation": 0.03432306094182826,
            "ave_precision_score": 0.6558703277840808,
            "fpr": 0.08991228070175439,
            "logloss": 0.8971542393597837,
            "mae": 0.434652185250381,
            "precision": 0.652542372881356,
            "recall": 0.33771929824561403
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7163599318128278,
            "auditor_fn_violation": 0.048126644889106375,
            "auditor_fp_violation": 0.02301703951967213,
            "ave_precision_score": 0.7169401513080348,
            "fpr": 0.08122941822173436,
            "logloss": 0.9232824574727764,
            "mae": 0.44186919351636017,
            "precision": 0.720754716981132,
            "recall": 0.38353413654618473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8720792844756082,
            "auditor_fn_violation": 0.008964296706678978,
            "auditor_fp_violation": 0.005554593721144971,
            "ave_precision_score": 0.8688575644739517,
            "fpr": 0.08552631578947369,
            "logloss": 0.4637400645647776,
            "mae": 0.3224407171650806,
            "precision": 0.8151658767772512,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8419962440679475,
            "auditor_fn_violation": 0.01891209183605994,
            "auditor_fp_violation": 0.00844401091847556,
            "ave_precision_score": 0.8405529186277916,
            "fpr": 0.10318331503841932,
            "logloss": 0.5134346350612246,
            "mae": 0.34090995492104903,
            "precision": 0.7960954446854663,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6136171311888726,
            "auditor_fn_violation": 0.004818790397045261,
            "auditor_fp_violation": 0.004674515235457065,
            "ave_precision_score": 0.6058583577860386,
            "fpr": 0.051535087719298246,
            "logloss": 0.6663547005099868,
            "mae": 0.4715660501990402,
            "precision": 0.6845637583892618,
            "recall": 0.2236842105263158
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6396920200063483,
            "auditor_fn_violation": 0.0006348114742174029,
            "auditor_fp_violation": 0.005703760601526142,
            "ave_precision_score": 0.6329700813101886,
            "fpr": 0.04720087815587267,
            "logloss": 0.6738164624414689,
            "mae": 0.4731955305150783,
            "precision": 0.7114093959731543,
            "recall": 0.21285140562248997
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6178029860105447,
            "auditor_fn_violation": 0.005588257925515552,
            "auditor_fp_violation": 0.00432825484764543,
            "ave_precision_score": 0.6097890003362986,
            "fpr": 0.05263157894736842,
            "logloss": 0.6651764365866658,
            "mae": 0.4701043894808543,
            "precision": 0.6883116883116883,
            "recall": 0.2324561403508772
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6395131183157834,
            "auditor_fn_violation": 0.0035553850969189827,
            "auditor_fp_violation": 0.00699016327214061,
            "ave_precision_score": 0.6328400991757626,
            "fpr": 0.04939626783754116,
            "logloss": 0.675071444889237,
            "mae": 0.47265557812283515,
            "precision": 0.7077922077922078,
            "recall": 0.21887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 6126,
        "test": {
            "accuracy": 0.43969298245614036,
            "auc_prc": 0.40518014999389906,
            "auditor_fn_violation": 0.022458833487226854,
            "auditor_fp_violation": 0.021872114496768236,
            "ave_precision_score": 0.40420406561366207,
            "fpr": 0.2138157894736842,
            "logloss": 3.3475684233247787,
            "mae": 0.5832874570482748,
            "precision": 0.417910447761194,
            "recall": 0.30701754385964913
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.4795991091081165,
            "auditor_fn_violation": 0.023362384775104807,
            "auditor_fp_violation": 0.022450916030331464,
            "ave_precision_score": 0.47882905327686054,
            "fpr": 0.15916575192096596,
            "logloss": 3.3750648556430214,
            "mae": 0.5606359235234499,
            "precision": 0.5292207792207793,
            "recall": 0.3273092369477912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5309565824920739,
            "auditor_fn_violation": 0.01580774853801171,
            "auditor_fp_violation": 0.024942770852570028,
            "ave_precision_score": 0.5339184368580484,
            "fpr": 0.11074561403508772,
            "logloss": 8.24819592400311,
            "mae": 0.4921707662477879,
            "precision": 0.5409090909090909,
            "recall": 0.26096491228070173
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.6089303456921622,
            "auditor_fn_violation": 0.015204616490109731,
            "auditor_fp_violation": 0.013709225155019497,
            "ave_precision_score": 0.6099998633530017,
            "fpr": 0.10647639956092206,
            "logloss": 8.084739973113626,
            "mae": 0.49296435243824677,
            "precision": 0.5941422594142259,
            "recall": 0.285140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6920184795220898,
            "auditor_fn_violation": 0.026359072022160666,
            "auditor_fp_violation": 0.03546764389042782,
            "ave_precision_score": 0.6925408257183139,
            "fpr": 0.1074561403508772,
            "logloss": 1.0623663520251025,
            "mae": 0.4076439318178464,
            "precision": 0.6585365853658537,
            "recall": 0.4144736842105263
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.750914216606015,
            "auditor_fn_violation": 0.03284267696471948,
            "auditor_fp_violation": 0.028460330158966415,
            "ave_precision_score": 0.7511537271151909,
            "fpr": 0.09769484083424808,
            "logloss": 1.1008368890968545,
            "mae": 0.40431953907245444,
            "precision": 0.72782874617737,
            "recall": 0.4779116465863454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8694838195312447,
            "auditor_fn_violation": 0.01568751923668821,
            "auditor_fp_violation": 0.011796899045860265,
            "ave_precision_score": 0.8648877858084085,
            "fpr": 0.08442982456140351,
            "logloss": 0.46575387424977616,
            "mae": 0.32184003238778625,
            "precision": 0.8166666666666667,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8366022425523538,
            "auditor_fn_violation": 0.02980307619060215,
            "auditor_fp_violation": 0.014280664357875106,
            "ave_precision_score": 0.8326979652965487,
            "fpr": 0.10318331503841932,
            "logloss": 0.5200631803474104,
            "mae": 0.3413080443126179,
            "precision": 0.796976241900648,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7061736428982305,
            "auditor_fn_violation": 0.028066328100954142,
            "auditor_fp_violation": 0.03640543244075101,
            "ave_precision_score": 0.7042206985434796,
            "fpr": 0.12938596491228072,
            "logloss": 1.1336991920981,
            "mae": 0.3751877355912059,
            "precision": 0.6740331491712708,
            "recall": 0.5350877192982456
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7618192889030169,
            "auditor_fn_violation": 0.03980356111603384,
            "auditor_fp_violation": 0.03371225511172301,
            "ave_precision_score": 0.7613000054162383,
            "fpr": 0.11525795828759605,
            "logloss": 1.1180107012454228,
            "mae": 0.3749974803218787,
            "precision": 0.7361809045226131,
            "recall": 0.5883534136546185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6197552106440436,
            "auditor_fn_violation": 0.005588257925515552,
            "auditor_fp_violation": 0.004674515235457065,
            "ave_precision_score": 0.6116558112387002,
            "fpr": 0.051535087719298246,
            "logloss": 0.6635204429646937,
            "mae": 0.469641418081888,
            "precision": 0.6928104575163399,
            "recall": 0.2324561403508772
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6395468519642263,
            "auditor_fn_violation": 0.002239473811822494,
            "auditor_fp_violation": 0.00699016327214061,
            "ave_precision_score": 0.6328999928196277,
            "fpr": 0.04939626783754116,
            "logloss": 0.6750348591674675,
            "mae": 0.4726436301722354,
            "precision": 0.7077922077922078,
            "recall": 0.21887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7994817423506375,
            "auditor_fn_violation": 0.00857956294244383,
            "auditor_fp_violation": 0.02103531855955679,
            "ave_precision_score": 0.7764996570130096,
            "fpr": 0.11074561403508772,
            "logloss": 5.013461516640987,
            "mae": 0.27987063702112136,
            "precision": 0.7560386473429952,
            "recall": 0.6864035087719298
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7958291329519788,
            "auditor_fn_violation": 0.025582020728357996,
            "auditor_fp_violation": 0.02596991837721898,
            "ave_precision_score": 0.7759577844960862,
            "fpr": 0.13172338090010977,
            "logloss": 5.889676443506777,
            "mae": 0.33108329675876547,
            "precision": 0.7272727272727273,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7084265600929132,
            "auditor_fn_violation": 0.005042416897506924,
            "auditor_fp_violation": 0.005436769005847953,
            "ave_precision_score": 0.6611687440763988,
            "fpr": 0.03837719298245614,
            "logloss": 5.043777702275425,
            "mae": 0.3950004808833463,
            "precision": 0.7784810126582279,
            "recall": 0.26973684210526316
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7076539924452463,
            "auditor_fn_violation": 0.0036920459003963227,
            "auditor_fp_violation": 0.006253936950321999,
            "ave_precision_score": 0.6684967389711166,
            "fpr": 0.042810098792535674,
            "logloss": 5.819834044552277,
            "mae": 0.4324146557137223,
            "precision": 0.7253521126760564,
            "recall": 0.20682730923694778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6136171311888726,
            "auditor_fn_violation": 0.004818790397045261,
            "auditor_fp_violation": 0.004674515235457065,
            "ave_precision_score": 0.6058583577860386,
            "fpr": 0.051535087719298246,
            "logloss": 0.666354678744797,
            "mae": 0.4715660064105402,
            "precision": 0.6845637583892618,
            "recall": 0.2236842105263158
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6396920200063483,
            "auditor_fn_violation": 0.0006348114742174029,
            "auditor_fp_violation": 0.005703760601526142,
            "ave_precision_score": 0.6329700813101886,
            "fpr": 0.04720087815587267,
            "logloss": 0.6738165751911076,
            "mae": 0.4731955540363404,
            "precision": 0.7114093959731543,
            "recall": 0.21285140562248997
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.864299401819329,
            "auditor_fn_violation": 0.005314135118498002,
            "auditor_fp_violation": 0.021410433979686064,
            "ave_precision_score": 0.8645494435377632,
            "fpr": 0.11074561403508772,
            "logloss": 0.7210145531789933,
            "mae": 0.2585183712314392,
            "precision": 0.7855626326963907,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8404149647061554,
            "auditor_fn_violation": 0.011578696784944388,
            "auditor_fp_violation": 0.017547170312803163,
            "ave_precision_score": 0.8406230343925987,
            "fpr": 0.14050493962678376,
            "logloss": 0.7088795283128435,
            "mae": 0.30075031532030416,
            "precision": 0.7485265225933202,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.629416087008645,
            "auditor_fn_violation": 0.005482456140350882,
            "auditor_fp_violation": 0.0032317636195752547,
            "ave_precision_score": 0.6206707201167242,
            "fpr": 0.05263157894736842,
            "logloss": 0.6595735978928515,
            "mae": 0.46630490058216084,
            "precision": 0.7037037037037037,
            "recall": 0.25
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6482033779310497,
            "auditor_fn_violation": 0.0009037246681567196,
            "auditor_fp_violation": 0.00827656594275508,
            "ave_precision_score": 0.6413158958802921,
            "fpr": 0.05159165751920966,
            "logloss": 0.6712113639710453,
            "mae": 0.46937775615148825,
            "precision": 0.7116564417177914,
            "recall": 0.23293172690763053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6384996227059409,
            "auditor_fn_violation": 0.012850107725453986,
            "auditor_fp_violation": 0.00207275315481687,
            "ave_precision_score": 0.62919688105612,
            "fpr": 0.05043859649122807,
            "logloss": 0.6532363666876042,
            "mae": 0.4639849990867732,
            "precision": 0.7195121951219512,
            "recall": 0.25877192982456143
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.657415215268101,
            "auditor_fn_violation": 6.612619523099059e-05,
            "auditor_fp_violation": 0.00811709453730701,
            "ave_precision_score": 0.6496053016331748,
            "fpr": 0.050493962678375415,
            "logloss": 0.6660942237924817,
            "mae": 0.4675672355585381,
            "precision": 0.7228915662650602,
            "recall": 0.24096385542168675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5579962510326911,
            "auditor_fn_violation": 0.014389042782394588,
            "auditor_fp_violation": 0.00638417590027701,
            "ave_precision_score": 0.5537904783467354,
            "fpr": 0.047149122807017545,
            "logloss": 0.6932725935013676,
            "mae": 0.48648174531888544,
            "precision": 0.5981308411214953,
            "recall": 0.14035087719298245
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.6139232213710886,
            "auditor_fn_violation": 0.018638770229105234,
            "auditor_fp_violation": 0.0016106611950255558,
            "ave_precision_score": 0.6078005258313979,
            "fpr": 0.03293084522502744,
            "logloss": 0.6836226595635445,
            "mae": 0.4851493435358766,
            "precision": 0.6907216494845361,
            "recall": 0.13453815261044177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 6126,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8411132490274124,
            "auditor_fn_violation": 0.004107032933210225,
            "auditor_fp_violation": 0.008815212373037862,
            "ave_precision_score": 0.8370209284883972,
            "fpr": 0.09100877192982457,
            "logloss": 0.5100738127117033,
            "mae": 0.34176700091879947,
            "precision": 0.7860824742268041,
            "recall": 0.668859649122807
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7969008674162649,
            "auditor_fn_violation": 0.007439196963485118,
            "auditor_fp_violation": 0.014352426490326734,
            "ave_precision_score": 0.7970177413190189,
            "fpr": 0.09549945115257959,
            "logloss": 0.570402549418953,
            "mae": 0.36358641546002857,
            "precision": 0.7898550724637681,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8700476911772288,
            "auditor_fn_violation": 0.016101108033241,
            "auditor_fp_violation": 0.016735918744228997,
            "ave_precision_score": 0.8702414700116838,
            "fpr": 0.11403508771929824,
            "logloss": 0.46952760751664413,
            "mae": 0.32496307829901444,
            "precision": 0.7787234042553192,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8446787637799466,
            "auditor_fn_violation": 0.0246474371690935,
            "auditor_fp_violation": 0.01850399874549161,
            "ave_precision_score": 0.8452221136687473,
            "fpr": 0.132821075740944,
            "logloss": 0.5111418859766595,
            "mae": 0.33737607866231223,
            "precision": 0.7650485436893204,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7456534732418647,
            "auditor_fn_violation": 0.0022122191443521085,
            "auditor_fp_violation": 0.008218875038473404,
            "ave_precision_score": 0.5086183375737677,
            "fpr": 0.47149122807017546,
            "logloss": 16.125360242944538,
            "mae": 0.4838717373480138,
            "precision": 0.5085714285714286,
            "recall": 0.9758771929824561
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7749765410315611,
            "auditor_fn_violation": 0.0006899166369098788,
            "auditor_fp_violation": 0.0022804410979074953,
            "ave_precision_score": 0.5597291065930459,
            "fpr": 0.42151481888035125,
            "logloss": 14.543991267438258,
            "mae": 0.4338829309876873,
            "precision": 0.5611428571428572,
            "recall": 0.9859437751004017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8088418221179875,
            "auditor_fn_violation": 0.0028855032317636193,
            "auditor_fp_violation": 0.017341874422899355,
            "ave_precision_score": 0.8095143676296706,
            "fpr": 0.14144736842105263,
            "logloss": 0.6812856814400378,
            "mae": 0.2760161105959628,
            "precision": 0.7361963190184049,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7994185237956403,
            "auditor_fn_violation": 0.004877909001538542,
            "auditor_fp_violation": 0.018129240942688633,
            "ave_precision_score": 0.7998688801495886,
            "fpr": 0.15916575192096596,
            "logloss": 0.7915584394206557,
            "mae": 0.30971964594241097,
            "precision": 0.7222222222222222,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8503726281406877,
            "auditor_fn_violation": 0.027457967836257317,
            "auditor_fp_violation": 0.015302785472453066,
            "ave_precision_score": 0.8501730389646962,
            "fpr": 0.09100877192982457,
            "logloss": 0.49345658811968296,
            "mae": 0.33521522832789313,
            "precision": 0.7955665024630542,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8007917817711128,
            "auditor_fn_violation": 0.02579582875960483,
            "auditor_fp_violation": 0.022868199541253926,
            "ave_precision_score": 0.8011105088214439,
            "fpr": 0.10867178924259056,
            "logloss": 0.5534184682558705,
            "mae": 0.35694316953306143,
            "precision": 0.7780269058295964,
            "recall": 0.6967871485943775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.801129466979936,
            "auditor_fn_violation": 0.010104070483225607,
            "auditor_fp_violation": 0.021049746075715605,
            "ave_precision_score": 0.7781970904593125,
            "fpr": 0.10197368421052631,
            "logloss": 4.996703803717938,
            "mae": 0.27774901376494354,
            "precision": 0.7698019801980198,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7981386098673029,
            "auditor_fn_violation": 0.024784097972570848,
            "auditor_fp_violation": 0.02416789149565574,
            "ave_precision_score": 0.7782416074508995,
            "fpr": 0.12733260153677278,
            "logloss": 5.874835637792527,
            "mae": 0.3311358561249356,
            "precision": 0.7327188940092166,
            "recall": 0.6385542168674698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8490236924960438,
            "auditor_fn_violation": 0.026510560941828257,
            "auditor_fp_violation": 0.015504770698676519,
            "ave_precision_score": 0.8489199881015265,
            "fpr": 0.07675438596491228,
            "logloss": 0.49856849309983986,
            "mae": 0.33161563782650455,
            "precision": 0.8162729658792651,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7914459150636808,
            "auditor_fn_violation": 0.02360043907793634,
            "auditor_fp_violation": 0.02342634946032219,
            "ave_precision_score": 0.7919065321252914,
            "fpr": 0.09549945115257959,
            "logloss": 0.5719548860018532,
            "mae": 0.36079334429824067,
            "precision": 0.7867647058823529,
            "recall": 0.6445783132530121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6454894633548779,
            "auditor_fn_violation": 0.00729070483225607,
            "auditor_fp_violation": 0.004044513696522006,
            "ave_precision_score": 0.6457388883110984,
            "fpr": 0.04057017543859649,
            "logloss": 0.6525043256587884,
            "mae": 0.46266812027284976,
            "precision": 0.7516778523489933,
            "recall": 0.24561403508771928
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6510182250444978,
            "auditor_fn_violation": 0.0039014455186277535,
            "auditor_fp_violation": 0.007144318964073749,
            "ave_precision_score": 0.6505830207931531,
            "fpr": 0.038419319429198684,
            "logloss": 0.665456971435849,
            "mae": 0.467288679663096,
            "precision": 0.7651006711409396,
            "recall": 0.2289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 6126,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8397178650423884,
            "auditor_fn_violation": 0.004107032933210225,
            "auditor_fp_violation": 0.008815212373037862,
            "ave_precision_score": 0.8308815928506657,
            "fpr": 0.09100877192982457,
            "logloss": 0.5097907006870885,
            "mae": 0.34112934811089773,
            "precision": 0.7860824742268041,
            "recall": 0.668859649122807
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.794863875160682,
            "auditor_fn_violation": 0.008067395818179418,
            "auditor_fp_violation": 0.014352426490326734,
            "ave_precision_score": 0.7910553680856749,
            "fpr": 0.09549945115257959,
            "logloss": 0.5710771388520222,
            "mae": 0.363376461108482,
            "precision": 0.7883211678832117,
            "recall": 0.6506024096385542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.035040813473491,
            "mae": 0.40384788137223376,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.8156411687932765,
            "mae": 0.4392206322168676,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.049035238836733,
            "mae": 0.4102714296936858,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831213204859647,
            "mae": 0.44650551332436855,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 6126,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6333662141086874,
            "auditor_fn_violation": 0.0052636388119421335,
            "auditor_fp_violation": 0.0013850415512465385,
            "ave_precision_score": 0.604645887294782,
            "fpr": 0.019736842105263157,
            "logloss": 5.692944142750503,
            "mae": 0.47593581240027816,
            "precision": 0.660377358490566,
            "recall": 0.07675438596491228
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0.6442120024258088,
            "auditor_fn_violation": 0.004179175538597879,
            "auditor_fp_violation": 0.009618783605276376,
            "ave_precision_score": 0.6266638188621452,
            "fpr": 0.02305159165751921,
            "logloss": 6.470323901016879,
            "mae": 0.5089806660224656,
            "precision": 0.5882352941176471,
            "recall": 0.060240963855421686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.048779701401796,
            "mae": 0.4102706594490691,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831105413846742,
            "mae": 0.4465158495369125,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.683667848623702,
            "auditor_fn_violation": 0.008478570329332115,
            "auditor_fp_violation": 0.01177285318559557,
            "ave_precision_score": 0.6845371989477729,
            "fpr": 0.04824561403508772,
            "logloss": 0.6377596563660219,
            "mae": 0.44426077751344756,
            "precision": 0.8018018018018018,
            "recall": 0.39035087719298245
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6955066145175008,
            "auditor_fn_violation": 0.011356071927666788,
            "auditor_fp_violation": 0.00799749098322095,
            "ave_precision_score": 0.6959392808484114,
            "fpr": 0.06476399560922064,
            "logloss": 0.6510076789727154,
            "mae": 0.4486544461006914,
            "precision": 0.757201646090535,
            "recall": 0.36947791164658633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.05008531153614,
            "mae": 0.41026665649393146,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831659755671339,
            "mae": 0.4464617092837094,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7890154318846224,
            "auditor_fn_violation": 0.011734379809172062,
            "auditor_fp_violation": 0.02002779701446599,
            "ave_precision_score": 0.7660919776644715,
            "fpr": 0.11732456140350878,
            "logloss": 5.030730751647376,
            "mae": 0.2834387047379144,
            "precision": 0.7494145199063232,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7791163961532139,
            "auditor_fn_violation": 0.012923262754640962,
            "auditor_fp_violation": 0.015410253479798965,
            "ave_precision_score": 0.75944513664092,
            "fpr": 0.141602634467618,
            "logloss": 5.865192737416777,
            "mae": 0.3255406849617214,
            "precision": 0.7219827586206896,
            "recall": 0.6726907630522089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.048255654618537,
            "mae": 0.4102663915571675,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.8308860632760116,
            "mae": 0.4465368151435737,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7717198887871749,
            "auditor_fn_violation": 0.007206544321329637,
            "auditor_fp_violation": 0.013129039704524472,
            "ave_precision_score": 0.7238089502141891,
            "fpr": 0.09210526315789473,
            "logloss": 4.991461640495796,
            "mae": 0.3789843246177362,
            "precision": 0.7771883289124668,
            "recall": 0.6425438596491229
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7215600678944885,
            "auditor_fn_violation": 0.014155414192444869,
            "auditor_fp_violation": 0.01371454086853443,
            "ave_precision_score": 0.6927318503120738,
            "fpr": 0.10208562019758508,
            "logloss": 5.780083223169469,
            "mae": 0.4173584787500153,
            "precision": 0.7627551020408163,
            "recall": 0.6004016064257028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8122142589088189,
            "auditor_fn_violation": 0.004674515235457069,
            "auditor_fp_violation": 0.015860649430594037,
            "ave_precision_score": 0.8128782567710688,
            "fpr": 0.13706140350877194,
            "logloss": 0.6704369310154242,
            "mae": 0.27514809646579175,
            "precision": 0.7422680412371134,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8008127463678071,
            "auditor_fn_violation": 0.005726528507002763,
            "auditor_fp_violation": 0.02007479208915515,
            "ave_precision_score": 0.8012499440083014,
            "fpr": 0.1602634467618002,
            "logloss": 0.7839646897583743,
            "mae": 0.3094415286068507,
            "precision": 0.7197696737044146,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.048309542723511,
            "mae": 0.4102840390742609,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.83095089693261,
            "mae": 0.44656056692388263,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8385455099381746,
            "auditor_fn_violation": 0.024555632502308408,
            "auditor_fp_violation": 0.03208198676515852,
            "ave_precision_score": 0.8390946550197771,
            "fpr": 0.13925438596491227,
            "logloss": 1.4501668233635685,
            "mae": 0.2694729697897636,
            "precision": 0.742393509127789,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8304749376882667,
            "auditor_fn_violation": 0.036481821908931004,
            "auditor_fp_violation": 0.02925502932944932,
            "ave_precision_score": 0.8307089663131055,
            "fpr": 0.14928649835345773,
            "logloss": 1.584899389318536,
            "mae": 0.30376846414468456,
            "precision": 0.7369439071566731,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8642254427191025,
            "auditor_fn_violation": 0.0060884118190212425,
            "auditor_fp_violation": 0.023382194521391203,
            "ave_precision_score": 0.8644744937445072,
            "fpr": 0.10964912280701754,
            "logloss": 0.721349016030792,
            "mae": 0.2584263643768372,
            "precision": 0.7867803837953091,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8402827284842047,
            "auditor_fn_violation": 0.011578696784944388,
            "auditor_fp_violation": 0.01634050334491273,
            "ave_precision_score": 0.8404914966878863,
            "fpr": 0.1394072447859495,
            "logloss": 0.7094787544113641,
            "mae": 0.30074400066016177,
            "precision": 0.75,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.048429635196849,
            "mae": 0.41026811294355675,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.830958390051803,
            "mae": 0.4465297309172664,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.049172005203962,
            "mae": 0.4102714947392151,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831271042244119,
            "mae": 0.44649991639261055,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 6126,
        "test": {
            "accuracy": 0.43640350877192985,
            "auc_prc": 0.4047128120818471,
            "auditor_fn_violation": 0.019041916743613427,
            "auditor_fp_violation": 0.023319675284702985,
            "ave_precision_score": 0.4037347663158894,
            "fpr": 0.21600877192982457,
            "logloss": 3.3568623053638285,
            "mae": 0.5839486974761783,
            "precision": 0.41369047619047616,
            "recall": 0.3048245614035088
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.4790927650992076,
            "auditor_fn_violation": 0.023362384775104807,
            "auditor_fp_violation": 0.022450916030331464,
            "ave_precision_score": 0.4783209895723163,
            "fpr": 0.15916575192096596,
            "logloss": 3.3846454623308606,
            "mae": 0.561128806660056,
            "precision": 0.5292207792207793,
            "recall": 0.3273092369477912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.048951357760047,
            "mae": 0.41027127093586485,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.831177776839631,
            "mae": 0.44650892154380073,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6961671561732392,
            "auditor_fn_violation": 0.007492690058479533,
            "auditor_fp_violation": 0.010522468451831333,
            "ave_precision_score": 0.6344644343975494,
            "fpr": 0.03728070175438596,
            "logloss": 5.051114563430465,
            "mae": 0.410252733172424,
            "precision": 0.7166666666666667,
            "recall": 0.18859649122807018
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6894476384000818,
            "auditor_fn_violation": 0.008111479948333406,
            "auditor_fp_violation": 0.01090252841913338,
            "ave_precision_score": 0.6456252396644299,
            "fpr": 0.04061470911086718,
            "logloss": 5.83210259947376,
            "mae": 0.446417781879101,
            "precision": 0.6810344827586207,
            "recall": 0.15863453815261044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6654533217573496,
            "auditor_fn_violation": 0.06949013157894737,
            "auditor_fp_violation": 0.0819482917820868,
            "ave_precision_score": 0.6627717377725983,
            "fpr": 0.23026315789473684,
            "logloss": 0.6251455451236463,
            "mae": 0.4402969674648423,
            "precision": 0.5757575757575758,
            "recall": 0.625
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7065382563904615,
            "auditor_fn_violation": 0.07671961170698162,
            "auditor_fp_violation": 0.06977671345380512,
            "ave_precision_score": 0.7019601705461782,
            "fpr": 0.21624588364434688,
            "logloss": 0.6290933480292643,
            "mae": 0.4380432862285463,
            "precision": 0.6129666011787819,
            "recall": 0.6265060240963856
        }
    }
]