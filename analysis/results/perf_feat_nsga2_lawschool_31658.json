[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5514245661822887,
            "auditor_fn_violation": 0.004536816888216446,
            "auditor_fp_violation": 0.005590815273477812,
            "ave_precision_score": 0.5215879963956873,
            "fpr": 0.019736842105263157,
            "logloss": 0.7355852164135288,
            "mae": 0.5032674755835742,
            "precision": 0.5714285714285714,
            "recall": 0.049281314168377825
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6133416444129518,
            "auditor_fn_violation": 0.00782254481862181,
            "auditor_fp_violation": 0.006964428753671345,
            "ave_precision_score": 0.5254322428629924,
            "fpr": 0.020856201975850714,
            "logloss": 0.7053640182541023,
            "mae": 0.4922682441092218,
            "precision": 0.6935483870967742,
            "recall": 0.09207708779443255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6937125739851744,
            "mae": 0.5002672380784101,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.25631174533479695,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6999938693176032,
            "mae": 0.5006510751438455,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5292390603295535,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5201172047349881,
            "fpr": 0.015350877192982455,
            "logloss": 0.7744560100849327,
            "mae": 0.505335245020034,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6583973584707625,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0015254002630511962,
            "ave_precision_score": 0.5207968311637352,
            "fpr": 0.007683863885839737,
            "logloss": 0.7049516817601855,
            "mae": 0.4926826219789021,
            "precision": 0.8055555555555556,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6014852086141844,
            "auditor_fn_violation": 0.02013536150437696,
            "auditor_fp_violation": 0.011369969040247677,
            "ave_precision_score": 0.5806977691771563,
            "fpr": 0.04057017543859649,
            "logloss": 0.7270417020192631,
            "mae": 0.49152825094510616,
            "precision": 0.6372549019607843,
            "recall": 0.13347022587268995
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6090088245339649,
            "auditor_fn_violation": 0.017250497723517253,
            "auditor_fp_violation": 0.015031496919532044,
            "ave_precision_score": 0.5784854559599765,
            "fpr": 0.05378704720087816,
            "logloss": 0.689278724577544,
            "mae": 0.48294331750929104,
            "precision": 0.6201550387596899,
            "recall": 0.17130620985010706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5447668520328584,
            "auditor_fn_violation": 0.002204240066284817,
            "auditor_fp_violation": 0.0022084623323013423,
            "ave_precision_score": 0.5374813086353558,
            "fpr": 0.007675438596491228,
            "logloss": 0.7578217408692758,
            "mae": 0.4965530594733617,
            "precision": 0.5625,
            "recall": 0.018480492813141684
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.649892560022864,
            "auditor_fn_violation": 0.0016500680476780438,
            "auditor_fp_violation": 0.0010581382699933741,
            "ave_precision_score": 0.5271941136217452,
            "fpr": 0.0043907793633369925,
            "logloss": 0.703202616316527,
            "mae": 0.4903016522044673,
            "precision": 0.8,
            "recall": 0.034261241970021415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5292390603295535,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5201172047349881,
            "fpr": 0.015350877192982455,
            "logloss": 0.7751302441128233,
            "mae": 0.5053770974147738,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.6171928318272636,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0025217313911057057,
            "ave_precision_score": 0.5193675799486168,
            "fpr": 0.008781558726673985,
            "logloss": 0.7188240198106559,
            "mae": 0.49325448477438333,
            "precision": 0.7837837837837838,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5859525133818047,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.004958720330237359,
            "ave_precision_score": 0.5371956873881226,
            "fpr": 0.01206140350877193,
            "logloss": 0.718144089484837,
            "mae": 0.4974301353162318,
            "precision": 0.6206896551724138,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6857301349637466,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.532243384029665,
            "fpr": 0.006586169045005488,
            "logloss": 0.6918754005315298,
            "mae": 0.4880464358335007,
            "precision": 0.8285714285714286,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.7774193111669649,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010371517027863775,
            "ave_precision_score": 0.7391475081524204,
            "fpr": 0.0021929824561403508,
            "logloss": 0.8811698381847841,
            "mae": 0.5041660637218963,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.8339151398406451,
            "auditor_fn_violation": 0.0005053627211549575,
            "auditor_fp_violation": 0.0011866971252262142,
            "ave_precision_score": 0.8014861037247355,
            "fpr": 0.0021953896816684962,
            "logloss": 0.8442780948661002,
            "mae": 0.49008203422779506,
            "precision": 0.3333333333333333,
            "recall": 0.0021413276231263384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7824517003223999,
            "auditor_fn_violation": 0.013025054937137508,
            "auditor_fp_violation": 0.017285861713106303,
            "ave_precision_score": 0.7346089372692156,
            "fpr": 0.10964912280701754,
            "logloss": 4.637970164392926,
            "mae": 0.3090980726230025,
            "precision": 0.7518610421836228,
            "recall": 0.62217659137577
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7657841225851315,
            "auditor_fn_violation": 0.011143835632537843,
            "auditor_fp_violation": 0.014989468063013628,
            "ave_precision_score": 0.711884199620529,
            "fpr": 0.13062568605927552,
            "logloss": 4.803242679194016,
            "mae": 0.31404380697261014,
            "precision": 0.72,
            "recall": 0.6552462526766595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5807123325751851,
            "auditor_fn_violation": 0.016807611945675295,
            "auditor_fp_violation": 0.009881320949432407,
            "ave_precision_score": 0.5492458999950098,
            "fpr": 0.041666666666666664,
            "logloss": 0.7738179219220779,
            "mae": 0.4938931763846722,
            "precision": 0.6448598130841121,
            "recall": 0.14168377823408623
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6265882123510453,
            "auditor_fn_violation": 0.014168960386614245,
            "auditor_fp_violation": 0.018482807725398287,
            "ave_precision_score": 0.5512373335767043,
            "fpr": 0.042810098792535674,
            "logloss": 0.6888295270346366,
            "mae": 0.4835186090766782,
            "precision": 0.6666666666666666,
            "recall": 0.1670235546038544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7832476261417338,
            "auditor_fn_violation": 0.010814060304766024,
            "auditor_fp_violation": 0.01618937048503613,
            "ave_precision_score": 0.735400764531045,
            "fpr": 0.10964912280701754,
            "logloss": 4.633574012237979,
            "mae": 0.30804891069570894,
            "precision": 0.7536945812807881,
            "recall": 0.6283367556468172
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7661614010412184,
            "auditor_fn_violation": 0.00966535585762405,
            "auditor_fp_violation": 0.016584092325036347,
            "ave_precision_score": 0.7122110146425437,
            "fpr": 0.13062568605927552,
            "logloss": 4.811125550617979,
            "mae": 0.31388617792688567,
            "precision": 0.7226107226107226,
            "recall": 0.6638115631691649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5292390603295535,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5201172047349881,
            "fpr": 0.015350877192982455,
            "logloss": 0.7495460340097313,
            "mae": 0.5048189606321486,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.668377474714262,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.5207968311637352,
            "fpr": 0.006586169045005488,
            "logloss": 0.7044798059303479,
            "mae": 0.4924671487017861,
            "precision": 0.8285714285714286,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6926528587507103,
            "auditor_fn_violation": 0.022247289167477213,
            "auditor_fp_violation": 0.016767285861713107,
            "ave_precision_score": 0.6939381172474186,
            "fpr": 0.14692982456140352,
            "logloss": 1.1035669654998266,
            "mae": 0.3662132954641326,
            "precision": 0.7148936170212766,
            "recall": 0.6899383983572895
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7200450578421289,
            "auditor_fn_violation": 0.015311315188852878,
            "auditor_fp_violation": 0.018561920867080042,
            "ave_precision_score": 0.7205079679459134,
            "fpr": 0.1525795828759605,
            "logloss": 0.9485662837930764,
            "mae": 0.3470841264502776,
            "precision": 0.7225548902195609,
            "recall": 0.7751605995717344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7059988064109171,
            "auditor_fn_violation": 0.019072643106740162,
            "auditor_fp_violation": 0.019254385964912284,
            "ave_precision_score": 0.710150253683713,
            "fpr": 0.16557017543859648,
            "logloss": 0.8535071959826378,
            "mae": 0.35570741926354654,
            "precision": 0.7021696252465484,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7493672381229508,
            "auditor_fn_violation": 0.009533726497695315,
            "auditor_fp_violation": 0.014270032930845233,
            "ave_precision_score": 0.7526634534764961,
            "fpr": 0.16245883644346873,
            "logloss": 0.672636044665209,
            "mae": 0.32683613178498877,
            "precision": 0.7159309021113244,
            "recall": 0.7987152034261242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 31658,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6229282203148767,
            "auditor_fn_violation": 0.02074102093014878,
            "auditor_fp_violation": 0.012706398348813208,
            "ave_precision_score": 0.6243874573786524,
            "fpr": 0.13706140350877194,
            "logloss": 0.9767595605630993,
            "mae": 0.4242067706436541,
            "precision": 0.6882793017456359,
            "recall": 0.5667351129363449
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6124960826051105,
            "auditor_fn_violation": 0.03392276647306182,
            "auditor_fp_violation": 0.007866813025978782,
            "ave_precision_score": 0.6138505904990399,
            "fpr": 0.14709110867178923,
            "logloss": 0.8401692219498216,
            "mae": 0.421742279588681,
            "precision": 0.6501305483028721,
            "recall": 0.5331905781584583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6012604002644953,
            "auditor_fn_violation": 0.012973269930473002,
            "auditor_fp_violation": 0.02800567595459236,
            "ave_precision_score": 0.5992004246643685,
            "fpr": 0.1513157894736842,
            "logloss": 1.7632776715801326,
            "mae": 0.41653012949805707,
            "precision": 0.6827586206896552,
            "recall": 0.6098562628336756
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.6109024092425421,
            "auditor_fn_violation": 0.009632448517641867,
            "auditor_fp_violation": 0.01943958228261192,
            "ave_precision_score": 0.6096547380801411,
            "fpr": 0.16136114160263446,
            "logloss": 1.4868762235464865,
            "mae": 0.3946846213059466,
            "precision": 0.671875,
            "recall": 0.6445396145610278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5292390603295535,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5201172047349881,
            "fpr": 0.015350877192982455,
            "logloss": 0.7495460340097313,
            "mae": 0.5048189606321486,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.668377474714262,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.5207968311637352,
            "fpr": 0.006586169045005488,
            "logloss": 0.7044798059303479,
            "mae": 0.4924671487017861,
            "precision": 0.8285714285714286,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 31658,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6224428037859203,
            "auditor_fn_violation": 0.01923925573687813,
            "auditor_fp_violation": 0.013859649122807018,
            "ave_precision_score": 0.6239023858448896,
            "fpr": 0.13815789473684212,
            "logloss": 0.9786942714555027,
            "mae": 0.42489126488677803,
            "precision": 0.6873449131513648,
            "recall": 0.5687885010266941
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6119245821679079,
            "auditor_fn_violation": 0.027982991606277787,
            "auditor_fp_violation": 0.004694870501676216,
            "ave_precision_score": 0.6132781648237926,
            "fpr": 0.14818880351262348,
            "logloss": 0.8418868711297827,
            "mae": 0.42204210246943863,
            "precision": 0.6511627906976745,
            "recall": 0.5396145610278372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6660459371943455,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6332971674036484,
            "fpr": 0.46600877192982454,
            "logloss": 0.8520427434768574,
            "mae": 0.47470624699142944,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7249885144672183,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6964692274753073,
            "fpr": 0.48737650933040616,
            "logloss": 0.8485960125383102,
            "mae": 0.4784218917562985,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5738303753300266,
            "auditor_fn_violation": 0.010627183976368028,
            "auditor_fp_violation": 0.026942724458204344,
            "ave_precision_score": 0.5692883994259355,
            "fpr": 0.13267543859649122,
            "logloss": 1.8395484237469635,
            "mae": 0.46139985761371,
            "precision": 0.5953177257525084,
            "recall": 0.3655030800821355
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5702886371377918,
            "auditor_fn_violation": 0.004179232177737243,
            "auditor_fp_violation": 0.0185421425816596,
            "ave_precision_score": 0.5666250871636718,
            "fpr": 0.14050493962678376,
            "logloss": 1.599304921976478,
            "mae": 0.4445696354911969,
            "precision": 0.6144578313253012,
            "recall": 0.43683083511777304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.530286337616767,
            "auditor_fn_violation": 0.003496613710868562,
            "auditor_fp_violation": 0.008181114551083593,
            "ave_precision_score": 0.5369241933538156,
            "fpr": 0.023026315789473683,
            "logloss": 0.779776779438077,
            "mae": 0.49725594836066095,
            "precision": 0.5434782608695652,
            "recall": 0.0513347022587269
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5842515569584928,
            "auditor_fn_violation": 0.00940914871061991,
            "auditor_fp_violation": 0.009518299858585261,
            "ave_precision_score": 0.5389720839576903,
            "fpr": 0.025246981339187707,
            "logloss": 0.7075136545175982,
            "mae": 0.4858900753161593,
            "precision": 0.6666666666666666,
            "recall": 0.09850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7831407334152085,
            "auditor_fn_violation": 0.01366448719334271,
            "auditor_fp_violation": 0.018356553147574825,
            "ave_precision_score": 0.7489231362072153,
            "fpr": 0.13157894736842105,
            "logloss": 4.008444193660618,
            "mae": 0.3095561026161726,
            "precision": 0.7285067873303167,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7649690621745433,
            "auditor_fn_violation": 0.013409741042739589,
            "auditor_fp_violation": 0.01808229744563444,
            "ave_precision_score": 0.7260302785836887,
            "fpr": 0.1525795828759605,
            "logloss": 4.133000791629622,
            "mae": 0.31478152028687245,
            "precision": 0.7029914529914529,
            "recall": 0.7044967880085653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6196332460249848,
            "auditor_fn_violation": 0.018334143881263736,
            "auditor_fp_violation": 0.021362229102167184,
            "ave_precision_score": 0.6215545394752278,
            "fpr": 0.16557017543859648,
            "logloss": 0.9664986826245224,
            "mae": 0.4095800883191311,
            "precision": 0.6841004184100419,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6032829019868095,
            "auditor_fn_violation": 0.014319393940818496,
            "auditor_fp_violation": 0.013590154369517712,
            "ave_precision_score": 0.6049526402663352,
            "fpr": 0.18331503841931943,
            "logloss": 0.8559966997935455,
            "mae": 0.41363199531024114,
            "precision": 0.6469344608879493,
            "recall": 0.6552462526766595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7510598522029235,
            "auditor_fn_violation": 0.005962030332504773,
            "auditor_fp_violation": 0.00040763673890608894,
            "ave_precision_score": 0.7523163841148608,
            "fpr": 0.006578947368421052,
            "logloss": 1.0796568691174426,
            "mae": 0.46870100507323026,
            "precision": 0.8723404255319149,
            "recall": 0.08418891170431211
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.81990075379736,
            "auditor_fn_violation": 0.007806091148630728,
            "auditor_fp_violation": 0.0005735702771926704,
            "ave_precision_score": 0.821210377270871,
            "fpr": 0.0043907793633369925,
            "logloss": 0.8800868151143724,
            "mae": 0.4332845928489759,
            "precision": 0.9420289855072463,
            "recall": 0.139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6806857770669944,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6824982672406267,
            "fpr": 0.46600877192982454,
            "logloss": 0.860189904163715,
            "mae": 0.473384334722109,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7326911556483973,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7346265743186132,
            "fpr": 0.48737650933040616,
            "logloss": 0.859143282373311,
            "mae": 0.47836190874307005,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.601160216470795,
            "auditor_fn_violation": 0.014481789689830327,
            "auditor_fp_violation": 0.02800567595459236,
            "ave_precision_score": 0.599067166687198,
            "fpr": 0.1513157894736842,
            "logloss": 1.7666065491972107,
            "mae": 0.416656105139603,
            "precision": 0.677570093457944,
            "recall": 0.5954825462012321
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6107556534233654,
            "auditor_fn_violation": 0.004790368491692081,
            "auditor_fp_violation": 0.01943958228261192,
            "ave_precision_score": 0.6095758395615232,
            "fpr": 0.16136114160263446,
            "logloss": 1.4892615511395368,
            "mae": 0.39473050281749417,
            "precision": 0.6643835616438356,
            "recall": 0.6231263383297645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5508277786960456,
            "auditor_fn_violation": 0.0013306495190748995,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5352677086180847,
            "fpr": 0.015350877192982455,
            "logloss": 0.7333426716773738,
            "mae": 0.4984763489480604,
            "precision": 0.5882352941176471,
            "recall": 0.04106776180698152
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6930916589065491,
            "auditor_fn_violation": 0.004261500527692714,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.5343599692919025,
            "fpr": 0.006586169045005488,
            "logloss": 0.6905640399585368,
            "mae": 0.48721469861877476,
            "precision": 0.8421052631578947,
            "recall": 0.06852248394004283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7619554993864226,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013003095975232198,
            "ave_precision_score": 0.7598260952758913,
            "fpr": 0.003289473684210526,
            "logloss": 3.080688852596549,
            "mae": 0.5349370255104674,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.8324085444722004,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.8307560351982834,
            "fpr": 0.0010976948408342481,
            "logloss": 2.891307110907669,
            "mae": 0.5107320739361023,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.836318089432502,
            "auditor_fn_violation": 0.01600156705933212,
            "auditor_fp_violation": 0.020423116615067093,
            "ave_precision_score": 0.8366924639545131,
            "fpr": 0.11842105263157894,
            "logloss": 0.6830533290692411,
            "mae": 0.2861851402557935,
            "precision": 0.7657266811279827,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8398063259660763,
            "auditor_fn_violation": 0.018214212680138307,
            "auditor_fp_violation": 0.018215800872222392,
            "ave_precision_score": 0.8400359280052052,
            "fpr": 0.12952799121844127,
            "logloss": 0.637982569454703,
            "mae": 0.27749023192730915,
            "precision": 0.7489361702127659,
            "recall": 0.7537473233404711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6694118973117241,
            "auditor_fn_violation": 0.0029765121221946036,
            "auditor_fp_violation": 0.0034984520123839116,
            "ave_precision_score": 0.6656055691868494,
            "fpr": 0.44298245614035087,
            "logloss": 0.7158503423734308,
            "mae": 0.42889256583814567,
            "precision": 0.5429864253393665,
            "recall": 0.9856262833675564
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7002304317454487,
            "auditor_fn_violation": 0.0005523732068437864,
            "auditor_fp_violation": 0.010353932417598733,
            "ave_precision_score": 0.6645246438033369,
            "fpr": 0.4522502744237102,
            "logloss": 0.7022004498717386,
            "mae": 0.42678520137513015,
            "precision": 0.530751708428246,
            "recall": 0.9978586723768736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5990058333693211,
            "auditor_fn_violation": 0.0034763500126085336,
            "auditor_fp_violation": 0.005608875128998969,
            "ave_precision_score": 0.5381243740038042,
            "fpr": 0.013157894736842105,
            "logloss": 0.7179626374084446,
            "mae": 0.49716396211532127,
            "precision": 0.6470588235294118,
            "recall": 0.045174537987679675
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.658494728777493,
            "auditor_fn_violation": 0.005544886786997832,
            "auditor_fp_violation": 0.003268361665727198,
            "ave_precision_score": 0.534582491481868,
            "fpr": 0.010976948408342482,
            "logloss": 0.692010538049526,
            "mae": 0.4879622785895899,
            "precision": 0.7674418604651163,
            "recall": 0.07066381156316917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5258921987005989,
            "auditor_fn_violation": 0.003496613710868562,
            "auditor_fp_violation": 0.008181114551083593,
            "ave_precision_score": 0.5362211311272287,
            "fpr": 0.023026315789473683,
            "logloss": 0.7524691124515489,
            "mae": 0.49886995790694255,
            "precision": 0.5434782608695652,
            "recall": 0.0513347022587269
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5656732891832229,
            "auditor_fn_violation": 0.00940914871061991,
            "auditor_fp_violation": 0.009518299858585261,
            "ave_precision_score": 0.5303472921423202,
            "fpr": 0.025246981339187707,
            "logloss": 0.7026825124964762,
            "mae": 0.4917139075787198,
            "precision": 0.6666666666666666,
            "recall": 0.09850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7450261076160234,
            "auditor_fn_violation": 0.0032602038978349567,
            "auditor_fp_violation": 0.0007507739938080497,
            "ave_precision_score": 0.7463238596039979,
            "fpr": 0.007675438596491228,
            "logloss": 0.9502753891862803,
            "mae": 0.4707103663618399,
            "precision": 0.8571428571428571,
            "recall": 0.08624229979466119
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.8152905529625064,
            "auditor_fn_violation": 0.007806091148630728,
            "auditor_fp_violation": 0.0005735702771926704,
            "ave_precision_score": 0.8166095232414388,
            "fpr": 0.0043907793633369925,
            "logloss": 0.8486214709466438,
            "mae": 0.4368224730901727,
            "precision": 0.9420289855072463,
            "recall": 0.139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7821739130149206,
            "auditor_fn_violation": 0.011730429770524875,
            "auditor_fp_violation": 0.018539731682146544,
            "ave_precision_score": 0.7459193266928906,
            "fpr": 0.11403508771929824,
            "logloss": 3.9187705394856978,
            "mae": 0.3056254012055125,
            "precision": 0.7523809523809524,
            "recall": 0.648870636550308
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7653898395800167,
            "auditor_fn_violation": 0.01324520434282867,
            "auditor_fp_violation": 0.015842406621769962,
            "ave_precision_score": 0.7240799829935722,
            "fpr": 0.13721185510428102,
            "logloss": 4.0746222934562555,
            "mae": 0.3110116334852665,
            "precision": 0.7228381374722838,
            "recall": 0.6980728051391863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6806857770669944,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6824982672406267,
            "fpr": 0.46600877192982454,
            "logloss": 0.8601912056146017,
            "mae": 0.4733842818491292,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7326911556483973,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7346265743186132,
            "fpr": 0.48737650933040616,
            "logloss": 0.8591440592811579,
            "mae": 0.4783618704678591,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8368466320245377,
            "auditor_fn_violation": 0.014956860837926448,
            "auditor_fp_violation": 0.02100877192982456,
            "ave_precision_score": 0.8372204205389915,
            "fpr": 0.1162280701754386,
            "logloss": 0.6813133440015183,
            "mae": 0.28648791786321615,
            "precision": 0.7690631808278867,
            "recall": 0.7248459958932238
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8427613315097369,
            "auditor_fn_violation": 0.017692396288992267,
            "auditor_fp_violation": 0.018334470584745008,
            "ave_precision_score": 0.8429820182993728,
            "fpr": 0.12733260153677278,
            "logloss": 0.6315536036397033,
            "mae": 0.276892647256743,
            "precision": 0.7516059957173448,
            "recall": 0.7516059957173448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5516568398711196,
            "auditor_fn_violation": 0.025757412010519117,
            "auditor_fp_violation": 0.019347265221878227,
            "ave_precision_score": 0.5662265836990971,
            "fpr": 0.03618421052631579,
            "logloss": 0.6964542872066845,
            "mae": 0.5007213802452672,
            "precision": 0.611764705882353,
            "recall": 0.10677618069815195
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.524242604552759,
            "auditor_fn_violation": 0.023164416823172405,
            "auditor_fp_violation": 0.025358234194677663,
            "ave_precision_score": 0.5400730702056628,
            "fpr": 0.04500548847420417,
            "logloss": 0.6958202736833302,
            "mae": 0.5003959801534659,
            "precision": 0.5232558139534884,
            "recall": 0.09635974304068523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8382548336564402,
            "auditor_fn_violation": 0.014270146619114524,
            "auditor_fp_violation": 0.02100877192982456,
            "ave_precision_score": 0.8386262094142014,
            "fpr": 0.1162280701754386,
            "logloss": 0.6647821694604459,
            "mae": 0.2853239996008736,
            "precision": 0.7705627705627706,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.838801880043706,
            "auditor_fn_violation": 0.017673592094716733,
            "auditor_fp_violation": 0.017830124306523875,
            "ave_precision_score": 0.8390304626908679,
            "fpr": 0.12843029637760703,
            "logloss": 0.63014943785573,
            "mae": 0.279595709879759,
            "precision": 0.7505330490405118,
            "recall": 0.7537473233404711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6988454316652681,
            "auditor_fn_violation": 0.019820148420332143,
            "auditor_fp_violation": 0.019032507739938087,
            "ave_precision_score": 0.7001355222994909,
            "fpr": 0.17653508771929824,
            "logloss": 0.9064358259021817,
            "mae": 0.3558646143910511,
            "precision": 0.6927480916030534,
            "recall": 0.7453798767967146
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7526462010116701,
            "auditor_fn_violation": 0.006821221473449653,
            "auditor_fp_violation": 0.015862184907190397,
            "ave_precision_score": 0.7538262667631999,
            "fpr": 0.17233809001097694,
            "logloss": 0.7191846312952985,
            "mae": 0.32384616665656407,
            "precision": 0.704331450094162,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6808697283762207,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6827683684106118,
            "fpr": 0.46600877192982454,
            "logloss": 0.8684309806919758,
            "mae": 0.47319586568495686,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7336655987996363,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.735678108446387,
            "fpr": 0.48737650933040616,
            "logloss": 0.8674868138113869,
            "mae": 0.47853194535367444,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.44340362315954,
            "mae": 0.5339912280701754,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.705388119015684,
            "mae": 0.5126234906695939,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6837964932574503,
            "auditor_fn_violation": 0.021074246190424733,
            "auditor_fp_violation": 0.018810629514963883,
            "ave_precision_score": 0.6881864731836511,
            "fpr": 0.17763157894736842,
            "logloss": 0.9745768562857848,
            "mae": 0.35813481558323335,
            "precision": 0.6902485659655831,
            "recall": 0.7412731006160165
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7244724663486508,
            "auditor_fn_violation": 0.00958778855623747,
            "auditor_fp_violation": 0.01577812719415354,
            "ave_precision_score": 0.7270944983263471,
            "fpr": 0.17892425905598244,
            "logloss": 0.7853911530209033,
            "mae": 0.33191903720626736,
            "precision": 0.6970260223048327,
            "recall": 0.8029978586723768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006449948400412798,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0010964912280701754,
            "logloss": 0.7019911558183632,
            "mae": 0.5010123351882947,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.25631174533479695,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000580987134225334,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6939569598022988,
            "mae": 0.5003324501731655,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6925156117515338,
            "auditor_fn_violation": 0.021533556684318604,
            "auditor_fp_violation": 0.016767285861713107,
            "ave_precision_score": 0.6938011833192905,
            "fpr": 0.14692982456140352,
            "logloss": 1.1044741164474097,
            "mae": 0.36622281550822977,
            "precision": 0.7154989384288747,
            "recall": 0.6919917864476386
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.723901836274606,
            "auditor_fn_violation": 0.014070238366667688,
            "auditor_fp_violation": 0.017711454594001252,
            "ave_precision_score": 0.7243661916908561,
            "fpr": 0.15148188803512624,
            "logloss": 0.9394072785357842,
            "mae": 0.3464513602667956,
            "precision": 0.7245508982035929,
            "recall": 0.7773019271948608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6036498306935285,
            "auditor_fn_violation": 0.03329550776324797,
            "auditor_fp_violation": 0.038888028895768846,
            "ave_precision_score": 0.5969578615312567,
            "fpr": 0.21162280701754385,
            "logloss": 0.7189833413407912,
            "mae": 0.4792376018880883,
            "precision": 0.5613636363636364,
            "recall": 0.5071868583162218
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6147937793742655,
            "auditor_fn_violation": 0.022219506060826885,
            "auditor_fp_violation": 0.04061470911086718,
            "ave_precision_score": 0.6078213584534905,
            "fpr": 0.21075740944017562,
            "logloss": 0.6888816494774769,
            "mae": 0.46918762622994026,
            "precision": 0.5460992907801419,
            "recall": 0.49464668094218417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6660459371943455,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6332971674036484,
            "fpr": 0.46600877192982454,
            "logloss": 0.8520397379095322,
            "mae": 0.474706396721957,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7249885144672183,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6964692274753073,
            "fpr": 0.48737650933040616,
            "logloss": 0.8485934730610335,
            "mae": 0.4784220113581543,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6784940795090918,
            "auditor_fn_violation": 0.02044156850030621,
            "auditor_fp_violation": 0.01852683178534572,
            "ave_precision_score": 0.6856885073515788,
            "fpr": 0.18201754385964913,
            "logloss": 1.047198290732421,
            "mae": 0.35215074437654376,
            "precision": 0.6937269372693727,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7106671112993735,
            "auditor_fn_violation": 0.009825191508966076,
            "auditor_fp_violation": 0.015476508341491875,
            "ave_precision_score": 0.7147787370886102,
            "fpr": 0.19319429198682767,
            "logloss": 0.8497963982055878,
            "mae": 0.3333228323459161,
            "precision": 0.6845878136200717,
            "recall": 0.8179871520342612
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6936475727767389,
            "mae": 0.5002379416112315,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.25631174533479695,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.0010976948408342481,
            "logloss": 0.701473369084309,
            "mae": 0.5006407177409016,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5243429302900368,
            "auditor_fn_violation": 0.003496613710868562,
            "auditor_fp_violation": 0.008181114551083593,
            "ave_precision_score": 0.5332400695214324,
            "fpr": 0.023026315789473683,
            "logloss": 0.7369898403288225,
            "mae": 0.5022614725228203,
            "precision": 0.5434782608695652,
            "recall": 0.0513347022587269
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5613864159928588,
            "auditor_fn_violation": 0.00940914871061991,
            "auditor_fp_violation": 0.009518299858585261,
            "ave_precision_score": 0.5244767147049031,
            "fpr": 0.025246981339187707,
            "logloss": 0.7099718540215098,
            "mae": 0.4969566335040835,
            "precision": 0.6666666666666666,
            "recall": 0.09850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7832418165341672,
            "auditor_fn_violation": 0.010814060304766024,
            "auditor_fp_violation": 0.01618937048503613,
            "ave_precision_score": 0.7353990634910148,
            "fpr": 0.10964912280701754,
            "logloss": 4.633574611009903,
            "mae": 0.308049025454452,
            "precision": 0.7536945812807881,
            "recall": 0.6283367556468172
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7661555175761458,
            "auditor_fn_violation": 0.00966535585762405,
            "auditor_fp_violation": 0.016584092325036347,
            "ave_precision_score": 0.7122164891247743,
            "fpr": 0.13062568605927552,
            "logloss": 4.81112525042521,
            "mae": 0.3138861247202743,
            "precision": 0.7226107226107226,
            "recall": 0.6638115631691649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5308480233815094,
            "auditor_fn_violation": 0.003496613710868562,
            "auditor_fp_violation": 0.008181114551083593,
            "ave_precision_score": 0.5380451333431931,
            "fpr": 0.023026315789473683,
            "logloss": 0.7783186511382147,
            "mae": 0.49619087988348504,
            "precision": 0.5434782608695652,
            "recall": 0.0513347022587269
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5845082861914761,
            "auditor_fn_violation": 0.00940914871061991,
            "auditor_fp_violation": 0.009518299858585261,
            "ave_precision_score": 0.5394855424236569,
            "fpr": 0.025246981339187707,
            "logloss": 0.7067838112928946,
            "mae": 0.4853569585295732,
            "precision": 0.6666666666666666,
            "recall": 0.09850107066381156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 31658,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6013918261050593,
            "auditor_fn_violation": 0.01397069418927196,
            "auditor_fp_violation": 0.02942982456140351,
            "ave_precision_score": 0.5994545919627279,
            "fpr": 0.14912280701754385,
            "logloss": 1.7631155405992296,
            "mae": 0.4180486786707733,
            "precision": 0.6784869976359338,
            "recall": 0.5893223819301848
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6089123444425828,
            "auditor_fn_violation": 0.005138246085789444,
            "auditor_fp_violation": 0.017597729452833735,
            "ave_precision_score": 0.6080212577632174,
            "fpr": 0.1602634467618002,
            "logloss": 1.4874679587955126,
            "mae": 0.3971690983988584,
            "precision": 0.6651376146788991,
            "recall": 0.6209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7275076429211478,
            "auditor_fn_violation": 0.02549623545516769,
            "auditor_fp_violation": 0.009223426212590308,
            "ave_precision_score": 0.7287492149358695,
            "fpr": 0.19188596491228072,
            "logloss": 0.9983495829658687,
            "mae": 0.3520473706886259,
            "precision": 0.6823956442831216,
            "recall": 0.7720739219712526
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.741007182515511,
            "auditor_fn_violation": 0.016453669991091515,
            "auditor_fp_violation": 0.0070435418953530985,
            "ave_precision_score": 0.7422607419674692,
            "fpr": 0.2030735455543359,
            "logloss": 0.7963701525078842,
            "mae": 0.3346922036545007,
            "precision": 0.6804835924006909,
            "recall": 0.8436830835117773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.776216447199195,
            "auditor_fn_violation": 0.0032714615079793893,
            "auditor_fp_violation": 0.00040763673890608894,
            "ave_precision_score": 0.7774815657064325,
            "fpr": 0.006578947368421052,
            "logloss": 0.9549192244767967,
            "mae": 0.47372872503869146,
            "precision": 0.8333333333333334,
            "recall": 0.061601642710472276
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.8390354242295286,
            "auditor_fn_violation": 0.009719417916166198,
            "auditor_fp_violation": 0.0013350342658794909,
            "ave_precision_score": 0.8404125356605704,
            "fpr": 0.003293084522502744,
            "logloss": 0.780755285470538,
            "mae": 0.44563574954458335,
            "precision": 0.9423076923076923,
            "recall": 0.10492505353319058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7619554993864226,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013003095975232198,
            "ave_precision_score": 0.7598260952758913,
            "fpr": 0.003289473684210526,
            "logloss": 3.1269536186941296,
            "mae": 0.5350506069279298,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.8324085444722004,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.8307560351982834,
            "fpr": 0.0010976948408342481,
            "logloss": 2.935143893085881,
            "mae": 0.5108917905787697,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7416435477159328,
            "auditor_fn_violation": 0.025791184840952486,
            "auditor_fp_violation": 0.013810629514963887,
            "ave_precision_score": 0.7428804988691489,
            "fpr": 0.17324561403508773,
            "logloss": 0.8823585143032163,
            "mae": 0.3411998628884799,
            "precision": 0.7057728119180633,
            "recall": 0.7782340862422998
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7638269219363294,
            "auditor_fn_violation": 0.015607481248692526,
            "auditor_fp_violation": 0.011481294686563628,
            "ave_precision_score": 0.7650415719477791,
            "fpr": 0.1800219538968167,
            "logloss": 0.7171124079820617,
            "mae": 0.32067757986722,
            "precision": 0.7071428571428572,
            "recall": 0.8479657387580299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 31658,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6887989310532348,
            "auditor_fn_violation": 0.026077128138621713,
            "auditor_fp_violation": 0.02795149638802889,
            "ave_precision_score": 0.6862676649629281,
            "fpr": 0.18969298245614036,
            "logloss": 0.681815951511986,
            "mae": 0.4161645589830324,
            "precision": 0.6808118081180812,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6925810485686525,
            "auditor_fn_violation": 0.016072885057011967,
            "auditor_fp_violation": 0.03274542379921085,
            "ave_precision_score": 0.6882046556638194,
            "fpr": 0.1986827661909989,
            "logloss": 0.6764771246384089,
            "mae": 0.4141286327467831,
            "precision": 0.6629422718808193,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7794954502853799,
            "auditor_fn_violation": 0.011410713642422281,
            "auditor_fp_violation": 0.018237874097007223,
            "ave_precision_score": 0.7318264883575762,
            "fpr": 0.1337719298245614,
            "logloss": 4.627325271084106,
            "mae": 0.30722912994817597,
            "precision": 0.7282850779510023,
            "recall": 0.6714579055441479
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7623302131780635,
            "auditor_fn_violation": 0.014547394796409343,
            "auditor_fp_violation": 0.01869295200799043,
            "ave_precision_score": 0.7085708117291499,
            "fpr": 0.15916575192096596,
            "logloss": 4.81268808029425,
            "mae": 0.3157846399036218,
            "precision": 0.6991701244813278,
            "recall": 0.721627408993576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8325917970029617,
            "auditor_fn_violation": 0.01333351345509565,
            "auditor_fp_violation": 0.016731166150670797,
            "ave_precision_score": 0.8329210297721183,
            "fpr": 0.11293859649122807,
            "logloss": 0.7093627458835082,
            "mae": 0.28915609708138845,
            "precision": 0.7685393258426966,
            "recall": 0.702258726899384
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8356943780286044,
            "auditor_fn_violation": 0.01532306781027509,
            "auditor_fp_violation": 0.014220587217294132,
            "ave_precision_score": 0.8359533494010661,
            "fpr": 0.12733260153677278,
            "logloss": 0.6453761185726035,
            "mae": 0.2803723560243253,
            "precision": 0.7483731019522777,
            "recall": 0.7387580299785867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.783137610984102,
            "auditor_fn_violation": 0.01366448719334271,
            "auditor_fp_violation": 0.018356553147574825,
            "ave_precision_score": 0.7489215525869485,
            "fpr": 0.13157894736842105,
            "logloss": 4.008438073819135,
            "mae": 0.3095568843324711,
            "precision": 0.7285067873303167,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7649694216095495,
            "auditor_fn_violation": 0.013409741042739589,
            "auditor_fp_violation": 0.01808229744563444,
            "ave_precision_score": 0.7260268189411165,
            "fpr": 0.1525795828759605,
            "logloss": 4.132989701966966,
            "mae": 0.3147810074255185,
            "precision": 0.7029914529914529,
            "recall": 0.7044967880085653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6808613231756502,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6827599341165835,
            "fpr": 0.46600877192982454,
            "logloss": 0.8695884146522205,
            "mae": 0.47314926452542605,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7337296739809355,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7357420698431651,
            "fpr": 0.48737650933040616,
            "logloss": 0.868735703237677,
            "mae": 0.47853127746759994,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7337913029727244,
            "auditor_fn_violation": 0.027218649807269717,
            "auditor_fp_violation": 0.014256965944272448,
            "ave_precision_score": 0.7350289979076355,
            "fpr": 0.1875,
            "logloss": 0.9225210607661881,
            "mae": 0.35134388753554857,
            "precision": 0.6868131868131868,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7458919158125469,
            "auditor_fn_violation": 0.016453669991091515,
            "auditor_fp_violation": 0.006966901039348909,
            "ave_precision_score": 0.7471556601034786,
            "fpr": 0.19209659714599342,
            "logloss": 0.751590886084632,
            "mae": 0.3323124951673758,
            "precision": 0.6924428822495606,
            "recall": 0.8436830835117773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6807964920962093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.682690243658783,
            "fpr": 0.46600877192982454,
            "logloss": 0.8569800428859552,
            "mae": 0.47344298007195457,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7338377198541804,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7358459318163628,
            "fpr": 0.48737650933040616,
            "logloss": 0.855576723615315,
            "mae": 0.4782737370510918,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7511050479089222,
            "auditor_fn_violation": 0.005962030332504773,
            "auditor_fp_violation": 0.00040763673890608894,
            "ave_precision_score": 0.752365706086102,
            "fpr": 0.006578947368421052,
            "logloss": 1.0794751915745189,
            "mae": 0.46870290343314513,
            "precision": 0.8723404255319149,
            "recall": 0.08418891170431211
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.8199384135921679,
            "auditor_fn_violation": 0.007806091148630728,
            "auditor_fp_violation": 0.0005735702771926704,
            "ave_precision_score": 0.8212436173646602,
            "fpr": 0.0043907793633369925,
            "logloss": 0.8801137050770966,
            "mae": 0.433287989231861,
            "precision": 0.9420289855072463,
            "recall": 0.139186295503212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6909394366290673,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6921676774650833,
            "fpr": 0.46600877192982454,
            "logloss": 0.819753731227293,
            "mae": 0.4697650727211383,
            "precision": 0.5339912280701754,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7444701320799519,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7453389666408263,
            "fpr": 0.48737650933040616,
            "logloss": 0.8170445473999414,
            "mae": 0.47240562156317134,
            "precision": 0.5126234906695939,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6939258381348121,
            "auditor_fn_violation": 0.018023433841276703,
            "auditor_fp_violation": 0.03477812177502581,
            "ave_precision_score": 0.6908159372703809,
            "fpr": 0.26864035087719296,
            "logloss": 0.6902081322296981,
            "mae": 0.4210190812515712,
            "precision": 0.6224961479198767,
            "recall": 0.8295687885010267
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6980310395313096,
            "auditor_fn_violation": 0.01864905967276001,
            "auditor_fp_violation": 0.035108928906953066,
            "ave_precision_score": 0.6933176671510504,
            "fpr": 0.2645444566410538,
            "logloss": 0.6826733403832446,
            "mae": 0.4181093404262891,
            "precision": 0.6144,
            "recall": 0.8222698072805139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7321484797695736,
            "auditor_fn_violation": 0.01940361684498721,
            "auditor_fp_violation": 0.011075851393188868,
            "ave_precision_score": 0.6213645548352194,
            "fpr": 0.2675438596491228,
            "logloss": 7.1290819506216145,
            "mae": 0.3599953461419941,
            "precision": 0.6303030303030303,
            "recall": 0.8542094455852156
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7392556951390776,
            "auditor_fn_violation": 0.010485688832894179,
            "auditor_fp_violation": 0.011983168679107222,
            "ave_precision_score": 0.6157156490740383,
            "fpr": 0.2843029637760702,
            "logloss": 7.598274900052475,
            "mae": 0.3569406704604458,
            "precision": 0.6168639053254438,
            "recall": 0.892933618843683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.709545368727398,
            "auditor_fn_violation": 0.018223819301848052,
            "auditor_fp_violation": 0.012229102167182678,
            "ave_precision_score": 0.6280969530187458,
            "fpr": 0.26206140350877194,
            "logloss": 5.914557796527062,
            "mae": 0.3505876346339598,
            "precision": 0.6339969372128637,
            "recall": 0.8501026694045175
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7150576709584588,
            "auditor_fn_violation": 0.008426629559723297,
            "auditor_fp_violation": 0.014663126353576418,
            "ave_precision_score": 0.6196516018570885,
            "fpr": 0.27991218441273324,
            "logloss": 6.467686031210266,
            "mae": 0.3485812260331302,
            "precision": 0.6182634730538922,
            "recall": 0.8843683083511777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5487306864678472,
            "auditor_fn_violation": 0.025757412010519117,
            "auditor_fp_violation": 0.02,
            "ave_precision_score": 0.5651924201791034,
            "fpr": 0.03728070175438596,
            "logloss": 0.6981634637419437,
            "mae": 0.5011574763543251,
            "precision": 0.6046511627906976,
            "recall": 0.10677618069815195
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.524242604552759,
            "auditor_fn_violation": 0.023164416823172405,
            "auditor_fp_violation": 0.025358234194677663,
            "ave_precision_score": 0.5400730702056628,
            "fpr": 0.04500548847420417,
            "logloss": 0.6958202736833302,
            "mae": 0.5003959801534659,
            "precision": 0.5232558139534884,
            "recall": 0.09635974304068523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7826468433275408,
            "auditor_fn_violation": 0.013025054937137508,
            "auditor_fp_violation": 0.016581527347781226,
            "ave_precision_score": 0.7348771599360855,
            "fpr": 0.11074561403508772,
            "logloss": 4.662308808584017,
            "mae": 0.3088934701511609,
            "precision": 0.75,
            "recall": 0.62217659137577
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.76474867679192,
            "auditor_fn_violation": 0.012241530473372083,
            "auditor_fp_violation": 0.014675487781964182,
            "ave_precision_score": 0.7108538806249389,
            "fpr": 0.13611416026344675,
            "logloss": 4.8470414124695935,
            "mae": 0.3153088041515705,
            "precision": 0.7116279069767442,
            "recall": 0.6552462526766595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7367804624704217,
            "auditor_fn_violation": 0.017820796858676467,
            "auditor_fp_violation": 0.00824561403508772,
            "ave_precision_score": 0.6347401620597076,
            "fpr": 0.2730263157894737,
            "logloss": 6.751559066064556,
            "mae": 0.36314888072570783,
            "precision": 0.6261261261261262,
            "recall": 0.8562628336755647
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7453123757188524,
            "auditor_fn_violation": 0.011000453651186896,
            "auditor_fp_violation": 0.01265315809772452,
            "ave_precision_score": 0.630231086433882,
            "fpr": 0.283205268935236,
            "logloss": 7.231378420078382,
            "mae": 0.357437109541463,
            "precision": 0.6183431952662722,
            "recall": 0.8950749464668094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7851388288532837,
            "auditor_fn_violation": 0.008976818329190535,
            "auditor_fp_violation": 0.014388544891640868,
            "ave_precision_score": 0.7515092177149365,
            "fpr": 0.11403508771929824,
            "logloss": 3.881175745770805,
            "mae": 0.30497800477947,
            "precision": 0.7547169811320755,
            "recall": 0.6570841889117043
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7677183443698071,
            "auditor_fn_violation": 0.009973274538885907,
            "auditor_fp_violation": 0.016260222901276686,
            "ave_precision_score": 0.7293609737100551,
            "fpr": 0.1437980241492865,
            "logloss": 4.01894925376519,
            "mae": 0.3057780406274612,
            "precision": 0.7164502164502164,
            "recall": 0.708779443254818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.5487306864678472,
            "auditor_fn_violation": 0.025757412010519117,
            "auditor_fp_violation": 0.02,
            "ave_precision_score": 0.5651924201791034,
            "fpr": 0.03728070175438596,
            "logloss": 0.6981634637419437,
            "mae": 0.5011574763543251,
            "precision": 0.6046511627906976,
            "recall": 0.10677618069815195
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.524242604552759,
            "auditor_fn_violation": 0.023164416823172405,
            "auditor_fp_violation": 0.025358234194677663,
            "ave_precision_score": 0.5400730702056628,
            "fpr": 0.04500548847420417,
            "logloss": 0.6958202736833302,
            "mae": 0.5003959801534659,
            "precision": 0.5232558139534884,
            "recall": 0.09635974304068523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7164546878853211,
            "auditor_fn_violation": 0.032788915306747365,
            "auditor_fp_violation": 0.004605263157894734,
            "ave_precision_score": 0.7176853576521787,
            "fpr": 0.20285087719298245,
            "logloss": 0.957429603601006,
            "mae": 0.3633555705855563,
            "precision": 0.6696428571428571,
            "recall": 0.7700205338809035
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7372588693761797,
            "auditor_fn_violation": 0.02007582791341609,
            "auditor_fp_violation": 0.012274898389058658,
            "ave_precision_score": 0.7379640783034487,
            "fpr": 0.2074643249176729,
            "logloss": 0.828851145437931,
            "mae": 0.35121175321045883,
            "precision": 0.6735751295336787,
            "recall": 0.8351177730192719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6856812810692248,
            "auditor_fn_violation": 0.0288712669764761,
            "auditor_fp_violation": 0.02920020639834881,
            "ave_precision_score": 0.6831247827307257,
            "fpr": 0.1875,
            "logloss": 0.6723954090138587,
            "mae": 0.42645988522964307,
            "precision": 0.6797752808988764,
            "recall": 0.7453798767967146
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6856079632678076,
            "auditor_fn_violation": 0.016072885057011967,
            "auditor_fp_violation": 0.031299136677841406,
            "ave_precision_score": 0.6815528023331752,
            "fpr": 0.1942919868276619,
            "logloss": 0.6609934954365526,
            "mae": 0.42189660125904144,
            "precision": 0.6679174484052532,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5304256608560781,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5218878149556208,
            "fpr": 0.015350877192982455,
            "logloss": 1.2246198206098557,
            "mae": 0.5135656129997609,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6702683647301816,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.5216881519137129,
            "fpr": 0.006586169045005488,
            "logloss": 1.1466602189565993,
            "mae": 0.49977090593861223,
            "precision": 0.8285714285714286,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7059988064109171,
            "auditor_fn_violation": 0.019072643106740162,
            "auditor_fp_violation": 0.019254385964912284,
            "ave_precision_score": 0.710150253683713,
            "fpr": 0.16557017543859648,
            "logloss": 0.8535071254530747,
            "mae": 0.3557074129616161,
            "precision": 0.7021696252465484,
            "recall": 0.731006160164271
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7493672381229508,
            "auditor_fn_violation": 0.009533726497695315,
            "auditor_fp_violation": 0.014270032930845233,
            "ave_precision_score": 0.7526634534764961,
            "fpr": 0.16245883644346873,
            "logloss": 0.6726358847000028,
            "mae": 0.3268361262757705,
            "precision": 0.7159309021113244,
            "recall": 0.7987152034261242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7619554993864226,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013003095975232198,
            "ave_precision_score": 0.7598260952758913,
            "fpr": 0.003289473684210526,
            "logloss": 2.280752672361656,
            "mae": 0.5284632281539693,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.8324071503785726,
            "auditor_fn_violation": 0.000550022682559349,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.8307546412051527,
            "fpr": 0.0010976948408342481,
            "logloss": 2.1228270200835424,
            "mae": 0.5019163610648604,
            "precision": 0.5,
            "recall": 0.0021413276231263384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6848978277255592,
            "auditor_fn_violation": 0.026077128138621713,
            "auditor_fp_violation": 0.030513415892672868,
            "ave_precision_score": 0.6820613918568619,
            "fpr": 0.19078947368421054,
            "logloss": 0.6831429186016965,
            "mae": 0.41781243105616606,
            "precision": 0.6795580110497238,
            "recall": 0.757700205338809
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.69193618163469,
            "auditor_fn_violation": 0.016072885057011967,
            "auditor_fp_violation": 0.03177381552793189,
            "ave_precision_score": 0.6870651477706257,
            "fpr": 0.19758507135016465,
            "logloss": 0.677254861228612,
            "mae": 0.41570139754381596,
            "precision": 0.664179104477612,
            "recall": 0.7623126338329764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7136634209764017,
            "auditor_fn_violation": 0.017082297633200048,
            "auditor_fp_violation": 0.013648090815273477,
            "ave_precision_score": 0.6308983067366739,
            "fpr": 0.2631578947368421,
            "logloss": 5.962391110216282,
            "mae": 0.3507701438139971,
            "precision": 0.6335877862595419,
            "recall": 0.8521560574948666
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7158912501314628,
            "auditor_fn_violation": 0.008426629559723297,
            "auditor_fp_violation": 0.014663126353576418,
            "ave_precision_score": 0.6187796371305724,
            "fpr": 0.27991218441273324,
            "logloss": 6.547947107060737,
            "mae": 0.34889387373884845,
            "precision": 0.6182634730538922,
            "recall": 0.8843683083511777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7832476261417338,
            "auditor_fn_violation": 0.010814060304766024,
            "auditor_fp_violation": 0.01618937048503613,
            "ave_precision_score": 0.735400764531045,
            "fpr": 0.10964912280701754,
            "logloss": 4.633574091753054,
            "mae": 0.30804891589052164,
            "precision": 0.7536945812807881,
            "recall": 0.6283367556468172
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7661614010412184,
            "auditor_fn_violation": 0.00966535585762405,
            "auditor_fp_violation": 0.016584092325036347,
            "ave_precision_score": 0.7122110146425437,
            "fpr": 0.13062568605927552,
            "logloss": 4.81112561174915,
            "mae": 0.31388617740886354,
            "precision": 0.7226107226107226,
            "recall": 0.6638115631691649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7831377187812725,
            "auditor_fn_violation": 0.01366448719334271,
            "auditor_fp_violation": 0.018356553147574825,
            "ave_precision_score": 0.7489220031239622,
            "fpr": 0.13157894736842105,
            "logloss": 4.0084850631669005,
            "mae": 0.30955657975612305,
            "precision": 0.7285067873303167,
            "recall": 0.6611909650924025
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7649720259575914,
            "auditor_fn_violation": 0.013409741042739589,
            "auditor_fp_violation": 0.01808229744563444,
            "ave_precision_score": 0.7260302267320959,
            "fpr": 0.1525795828759605,
            "logloss": 4.1330356861580295,
            "mae": 0.3147811022061014,
            "precision": 0.7029914529914529,
            "recall": 0.7044967880085653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 31658,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7136219312544813,
            "auditor_fn_violation": 0.0179446305702655,
            "auditor_fp_violation": 0.01963622291021673,
            "ave_precision_score": 0.7149495178348684,
            "fpr": 0.16666666666666666,
            "logloss": 0.8293102128869453,
            "mae": 0.35208102063139746,
            "precision": 0.703125,
            "recall": 0.7392197125256673
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7563738847809038,
            "auditor_fn_violation": 0.011106227243986775,
            "auditor_fp_violation": 0.012734743525083813,
            "ave_precision_score": 0.7575517912400848,
            "fpr": 0.16794731064763996,
            "logloss": 0.6501895033973064,
            "mae": 0.3243266195307311,
            "precision": 0.711864406779661,
            "recall": 0.8094218415417559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6035137526237799,
            "auditor_fn_violation": 0.02212345545588819,
            "auditor_fp_violation": 0.03153508771929825,
            "ave_precision_score": 0.5978511387938844,
            "fpr": 0.1962719298245614,
            "logloss": 0.723708959920968,
            "mae": 0.479904138710397,
            "precision": 0.5665859564164649,
            "recall": 0.4804928131416838
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6208144346334902,
            "auditor_fn_violation": 0.01698723900365977,
            "auditor_fp_violation": 0.037974308007238874,
            "ave_precision_score": 0.6147349610682308,
            "fpr": 0.18660812294182216,
            "logloss": 0.6870082601580424,
            "mae": 0.46657380310843677,
            "precision": 0.5641025641025641,
            "recall": 0.47109207708779444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7851444658634874,
            "auditor_fn_violation": 0.014650653841997189,
            "auditor_fp_violation": 0.017605779153766772,
            "ave_precision_score": 0.7517152719784688,
            "fpr": 0.12280701754385964,
            "logloss": 3.8546257851107186,
            "mae": 0.30457992382394233,
            "precision": 0.7431192660550459,
            "recall": 0.6652977412731006
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.768171453847206,
            "auditor_fn_violation": 0.011559878430884013,
            "auditor_fp_violation": 0.022159096527922004,
            "ave_precision_score": 0.7299716307563984,
            "fpr": 0.1525795828759605,
            "logloss": 3.9939425649540286,
            "mae": 0.30484155868990487,
            "precision": 0.707983193277311,
            "recall": 0.721627408993576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 31658,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.7715223682390825,
            "auditor_fn_violation": 0.0032714615079793893,
            "auditor_fp_violation": 0.000980392156862745,
            "ave_precision_score": 0.7728860877124648,
            "fpr": 0.005482456140350877,
            "logloss": 0.9369137566872894,
            "mae": 0.4715981193663797,
            "precision": 0.8571428571428571,
            "recall": 0.061601642710472276
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8280251309326249,
            "auditor_fn_violation": 0.008558258919652059,
            "auditor_fp_violation": 0.0013350342658794909,
            "ave_precision_score": 0.8292732529963207,
            "fpr": 0.003293084522502744,
            "logloss": 0.7724315233410102,
            "mae": 0.44514481149365964,
            "precision": 0.9444444444444444,
            "recall": 0.10920770877944326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6379390609047018,
            "auditor_fn_violation": 0.015510735257033757,
            "auditor_fp_violation": 0.025995872033023736,
            "ave_precision_score": 0.6393832058864756,
            "fpr": 0.21162280701754385,
            "logloss": 0.980542686473398,
            "mae": 0.39506554307197866,
            "precision": 0.6571936056838366,
            "recall": 0.7597535934291582
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6432161731623219,
            "auditor_fn_violation": 0.0019650383017932173,
            "auditor_fp_violation": 0.024386625923398714,
            "ave_precision_score": 0.6445471412852136,
            "fpr": 0.2305159165751921,
            "logloss": 0.7948824980403808,
            "mae": 0.3870813240602058,
            "precision": 0.6404109589041096,
            "recall": 0.8008565310492506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 31658,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.785302132795068,
            "auditor_fn_violation": 0.010395277207392199,
            "auditor_fp_violation": 0.015804953560371513,
            "ave_precision_score": 0.7516430862898343,
            "fpr": 0.12390350877192982,
            "logloss": 3.8397893205779705,
            "mae": 0.3046480648135261,
            "precision": 0.7460674157303371,
            "recall": 0.6817248459958932
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.767937674781553,
            "auditor_fn_violation": 0.012399015600429676,
            "auditor_fp_violation": 0.02091553683211203,
            "ave_precision_score": 0.729552447450501,
            "fpr": 0.15806805708013172,
            "logloss": 3.978977198429634,
            "mae": 0.30563844260274964,
            "precision": 0.7012448132780082,
            "recall": 0.7237687366167024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 31658,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7863350098438734,
            "auditor_fn_violation": 0.008260834324003036,
            "auditor_fp_violation": 0.014780701754385976,
            "ave_precision_score": 0.7537341756180302,
            "fpr": 0.1118421052631579,
            "logloss": 3.8035107346978227,
            "mae": 0.30700988702610843,
            "precision": 0.7553956834532374,
            "recall": 0.6468172484599589
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7679384256828304,
            "auditor_fn_violation": 0.011266062895328806,
            "auditor_fp_violation": 0.014972162063270735,
            "ave_precision_score": 0.729835721543559,
            "fpr": 0.14050493962678376,
            "logloss": 3.9551896261321193,
            "mae": 0.30746790963106263,
            "precision": 0.7199124726477024,
            "recall": 0.7044967880085653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 31658,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5807123325751851,
            "auditor_fn_violation": 0.016807611945675295,
            "auditor_fp_violation": 0.009881320949432407,
            "ave_precision_score": 0.5492458999950098,
            "fpr": 0.041666666666666664,
            "logloss": 0.7738179198134348,
            "mae": 0.4938931763847021,
            "precision": 0.6448598130841121,
            "recall": 0.14168377823408623
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6265882123510453,
            "auditor_fn_violation": 0.014168960386614245,
            "auditor_fp_violation": 0.018482807725398287,
            "ave_precision_score": 0.5512373335767043,
            "fpr": 0.042810098792535674,
            "logloss": 0.6888295270346726,
            "mae": 0.4835186090767141,
            "precision": 0.6666666666666666,
            "recall": 0.1670235546038544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.280885444697374,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010371517027863775,
            "ave_precision_score": 0.5472216102531471,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6943755008718094,
            "mae": 0.4995420099677224,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.26835025429033826,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011866971252262142,
            "ave_precision_score": 0.5211512929968833,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6952908328155081,
            "mae": 0.5000714083272723,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8410230101541494,
            "auditor_fn_violation": 0.014414244028963583,
            "auditor_fp_violation": 0.01790505675954593,
            "ave_precision_score": 0.841338331545893,
            "fpr": 0.1206140350877193,
            "logloss": 0.6946387941493588,
            "mae": 0.2775586393874255,
            "precision": 0.7708333333333334,
            "recall": 0.7597535934291582
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.850374504216286,
            "auditor_fn_violation": 0.018228315825844953,
            "auditor_fp_violation": 0.015456730056071444,
            "ave_precision_score": 0.8505932245979957,
            "fpr": 0.13172338090010977,
            "logloss": 0.6273838620614374,
            "mae": 0.2673768700557823,
            "precision": 0.7535934291581109,
            "recall": 0.7858672376873662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7618707876736672,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013003095975232198,
            "ave_precision_score": 0.7597425255343,
            "fpr": 0.003289473684210526,
            "logloss": 3.126915683676905,
            "mae": 0.5350504895846818,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.8324738645072287,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.8308195949293884,
            "fpr": 0.0010976948408342481,
            "logloss": 2.935107692351593,
            "mae": 0.5108916322309899,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8326321195784158,
            "auditor_fn_violation": 0.01333351345509565,
            "auditor_fp_violation": 0.016731166150670797,
            "ave_precision_score": 0.8329615048856132,
            "fpr": 0.11293859649122807,
            "logloss": 0.707961367100124,
            "mae": 0.28924116570314806,
            "precision": 0.7685393258426966,
            "recall": 0.702258726899384
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8358378094708313,
            "auditor_fn_violation": 0.016409010029687133,
            "auditor_fp_violation": 0.014220587217294132,
            "ave_precision_score": 0.8360966265130612,
            "fpr": 0.12733260153677278,
            "logloss": 0.6435624542563924,
            "mae": 0.2803476422827333,
            "precision": 0.7478260869565218,
            "recall": 0.7366167023554604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 31658,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5499815271734327,
            "auditor_fn_violation": 0.0024991894520695933,
            "auditor_fp_violation": 0.003596491228070176,
            "ave_precision_score": 0.5240385619640467,
            "fpr": 0.015350877192982455,
            "logloss": 1.2109121240492933,
            "mae": 0.512865127515599,
            "precision": 0.5625,
            "recall": 0.03696098562628337
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6702683647301816,
            "auditor_fn_violation": 0.004639934937487799,
            "auditor_fp_violation": 0.0021805559676031684,
            "ave_precision_score": 0.5216881519137129,
            "fpr": 0.006586169045005488,
            "logloss": 1.1466600514210494,
            "mae": 0.49977090593857854,
            "precision": 0.8285714285714286,
            "recall": 0.06209850107066381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 31658,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7852596524434343,
            "auditor_fn_violation": 0.00947890774163335,
            "auditor_fp_violation": 0.015804953560371513,
            "ave_precision_score": 0.751613004107785,
            "fpr": 0.12390350877192982,
            "logloss": 3.8378987899844033,
            "mae": 0.3045161892830128,
            "precision": 0.7454954954954955,
            "recall": 0.6796714579055442
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7676604116998487,
            "auditor_fn_violation": 0.01354137040266832,
            "auditor_fp_violation": 0.02091553683211203,
            "ave_precision_score": 0.729284103040766,
            "fpr": 0.15806805708013172,
            "logloss": 3.977027856708145,
            "mae": 0.3057419783039192,
            "precision": 0.7,
            "recall": 0.7194860813704497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6937125739851744,
            "mae": 0.5002672380784101,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.25631174533479695,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005636811344824518,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6999938693176032,
            "mae": 0.5006510751438455,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 31658,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.2669956140350877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0010371517027863775,
            "ave_precision_score": 0.5339912280701754,
            "fpr": 0.0021929824561403508,
            "logloss": 0.7073274479925995,
            "mae": 0.5016394197417978,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.25631174533479695,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000580987134225334,
            "ave_precision_score": 0.5126234906695939,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6943595159689007,
            "mae": 0.5004587895129567,
            "precision": 0.0,
            "recall": 0.0
        }
    }
]