[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5313217867214532,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5328559219383431,
            "fpr": 0.29605263157894735,
            "logloss": 0.6995208716271447,
            "mae": 0.49873804416519735,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5532004501591639,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.08889561805266412,
            "ave_precision_score": 0.555285968764818,
            "fpr": 0.2810098792535675,
            "logloss": 0.6876547576612891,
            "mae": 0.4953735335009289,
            "precision": 0.569023569023569,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5276122432771607,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09317143665615653,
            "ave_precision_score": 0.5291681665953107,
            "fpr": 0.2949561403508772,
            "logloss": 0.70116670505858,
            "mae": 0.4986470705924531,
            "precision": 0.5494137353433836,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5551330310688454,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.0881966261655122,
            "ave_precision_score": 0.5571966609084131,
            "fpr": 0.28210757409440174,
            "logloss": 0.6876104020410945,
            "mae": 0.4951653695459816,
            "precision": 0.5680672268907563,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5276122432771607,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09317143665615653,
            "ave_precision_score": 0.5291681665953107,
            "fpr": 0.2949561403508772,
            "logloss": 0.7011666951824681,
            "mae": 0.4986470705924531,
            "precision": 0.5494137353433836,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5551330310688454,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.0881966261655122,
            "ave_precision_score": 0.5571966609084131,
            "fpr": 0.28210757409440174,
            "logloss": 0.6876104015431846,
            "mae": 0.49516537036382796,
            "precision": 0.5680672268907563,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5704620638808047,
            "auditor_fn_violation": 0.0007661675108272774,
            "auditor_fp_violation": 0.0016219985447489752,
            "ave_precision_score": 0.5720090382727336,
            "fpr": 0.4725877192982456,
            "logloss": 0.7976527074771154,
            "mae": 0.48502212132635786,
            "precision": 0.5232300884955752,
            "recall": 0.9895397489539749
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5793756246245336,
            "auditor_fn_violation": 0.0023706518831462333,
            "auditor_fp_violation": 0.0018774366932889244,
            "ave_precision_score": 0.5809625996126822,
            "fpr": 0.47420417124039516,
            "logloss": 0.7877503361985285,
            "mae": 0.48283746246448855,
            "precision": 0.5221238938053098,
            "recall": 0.9915966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6231306261609066,
            "auditor_fn_violation": 0.09371100345004771,
            "auditor_fp_violation": 0.09619057724957555,
            "ave_precision_score": 0.6197668046217928,
            "fpr": 0.2993421052631579,
            "logloss": 0.6895761903365871,
            "mae": 0.49693422758004124,
            "precision": 0.5495049504950495,
            "recall": 0.696652719665272
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6342957114509424,
            "auditor_fn_violation": 0.0805329815790202,
            "auditor_fp_violation": 0.0903011721362151,
            "ave_precision_score": 0.6294247627917154,
            "fpr": 0.2843029637760702,
            "logloss": 0.6860630351361436,
            "mae": 0.49518269820611116,
            "precision": 0.5690515806988353,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6948412862420901,
            "auditor_fn_violation": 0.09203185788739632,
            "auditor_fp_violation": 0.023865106314172532,
            "ave_precision_score": 0.6955918800645337,
            "fpr": 0.05921052631578947,
            "logloss": 0.6595722054723349,
            "mae": 0.472329447617787,
            "precision": 0.7831325301204819,
            "recall": 0.40794979079497906
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6971204118757536,
            "auditor_fn_violation": 0.08381914785672777,
            "auditor_fp_violation": 0.022698310559319684,
            "ave_precision_score": 0.6980185218314965,
            "fpr": 0.054884742041712405,
            "logloss": 0.661206624463821,
            "mae": 0.4739893581779545,
            "precision": 0.7991967871485943,
            "recall": 0.4180672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6920270493342501,
            "mae": 0.4980639774483024,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6912474861745832,
            "mae": 0.4977423694602221,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.602578873884268,
            "auditor_fn_violation": 0.06211462232988328,
            "auditor_fp_violation": 0.061716791979949885,
            "ave_precision_score": 0.6049414959497446,
            "fpr": 0.3399122807017544,
            "logloss": 0.6843826598722044,
            "mae": 0.48573334856579703,
            "precision": 0.5539568345323741,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5866291093628766,
            "auditor_fn_violation": 0.06897028844468633,
            "auditor_fp_violation": 0.06830185346404735,
            "ave_precision_score": 0.5875983900591935,
            "fpr": 0.3150384193194292,
            "logloss": 0.6856872281639457,
            "mae": 0.48627764506737825,
            "precision": 0.5625,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6947870254977415,
            "auditor_fn_violation": 0.09203185788739632,
            "auditor_fp_violation": 0.023865106314172532,
            "ave_precision_score": 0.6955376018914858,
            "fpr": 0.05921052631578947,
            "logloss": 0.6595691760870881,
            "mae": 0.4723275498601428,
            "precision": 0.7831325301204819,
            "recall": 0.40794979079497906
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6970454129899224,
            "auditor_fn_violation": 0.08381914785672777,
            "auditor_fp_violation": 0.022698310559319684,
            "ave_precision_score": 0.6979439030265577,
            "fpr": 0.054884742041712405,
            "logloss": 0.6612088454648803,
            "mae": 0.4739898200321669,
            "precision": 0.7991967871485943,
            "recall": 0.4180672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.548448719219983,
            "auditor_fn_violation": 0.08348931953314248,
            "auditor_fp_violation": 0.08394979383943732,
            "ave_precision_score": 0.550015775476395,
            "fpr": 0.31798245614035087,
            "logloss": 0.7055827517639508,
            "mae": 0.49639905839923193,
            "precision": 0.5404120443740095,
            "recall": 0.7133891213389121
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5663998174598694,
            "auditor_fn_violation": 0.07499377357968436,
            "auditor_fp_violation": 0.08324816735430311,
            "ave_precision_score": 0.5679813159399215,
            "fpr": 0.29198682766191,
            "logloss": 0.6968238967894884,
            "mae": 0.4945202970184165,
            "precision": 0.5667752442996743,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5445542303486136,
            "auditor_fn_violation": 0.09114181898260294,
            "auditor_fp_violation": 0.09313101301641201,
            "ave_precision_score": 0.5459652749586046,
            "fpr": 0.2916666666666667,
            "logloss": 0.7022237264552953,
            "mae": 0.4985059419031083,
            "precision": 0.5506756756756757,
            "recall": 0.6820083682008368
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5700051496710565,
            "auditor_fn_violation": 0.07722606056692712,
            "auditor_fp_violation": 0.08302862838613626,
            "ave_precision_score": 0.5720917010563684,
            "fpr": 0.27771679473106475,
            "logloss": 0.6861471827172559,
            "mae": 0.49407139272479145,
            "precision": 0.571912013536379,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6025788766023767,
            "auditor_fn_violation": 0.06211462232988328,
            "auditor_fp_violation": 0.061716791979949885,
            "ave_precision_score": 0.6049399357552951,
            "fpr": 0.3399122807017544,
            "logloss": 0.6844206087875079,
            "mae": 0.48575592562229486,
            "precision": 0.5539568345323741,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5866291093628766,
            "auditor_fn_violation": 0.06897028844468633,
            "auditor_fp_violation": 0.06830185346404735,
            "ave_precision_score": 0.5875983900591935,
            "fpr": 0.3150384193194292,
            "logloss": 0.6857188182457912,
            "mae": 0.486299803208572,
            "precision": 0.5625,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5244170649874709,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5259725177008998,
            "fpr": 0.29605263157894735,
            "logloss": 0.699576714407192,
            "mae": 0.4987493880182962,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5511981568641462,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.08749763427836027,
            "ave_precision_score": 0.5532657797793048,
            "fpr": 0.283205268935236,
            "logloss": 0.6876640298821052,
            "mae": 0.4953708589469562,
            "precision": 0.5671140939597316,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5281415798479626,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5296928245193246,
            "fpr": 0.29605263157894735,
            "logloss": 0.7015856145731402,
            "mae": 0.4985748581157327,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5552845603786937,
            "auditor_fn_violation": 0.07867889197391362,
            "auditor_fp_violation": 0.08749763427836027,
            "ave_precision_score": 0.5573747638614783,
            "fpr": 0.283205268935236,
            "logloss": 0.6881223500548014,
            "mae": 0.4951730441428827,
            "precision": 0.5678391959798995,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 30132,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7297775485581726,
            "auditor_fn_violation": 0.015004496072818037,
            "auditor_fp_violation": 0.012604596167838954,
            "ave_precision_score": 0.7308096602581913,
            "fpr": 0.08662280701754387,
            "logloss": 0.7384987895148503,
            "mae": 0.39535093597461174,
            "precision": 0.7312925170068028,
            "recall": 0.4497907949790795
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7336940334992279,
            "auditor_fn_violation": 0.016523074652473515,
            "auditor_fp_violation": 0.0072170281489332185,
            "ave_precision_score": 0.734153565249741,
            "fpr": 0.07683863885839737,
            "logloss": 0.7592509725206212,
            "mae": 0.4044291475817406,
            "precision": 0.7526501766784452,
            "recall": 0.4474789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7570627785131749,
            "auditor_fn_violation": 0.01754385964912281,
            "auditor_fp_violation": 0.012238256932654215,
            "ave_precision_score": 0.6370292920639761,
            "fpr": 0.1074561403508772,
            "logloss": 4.123731392519052,
            "mae": 0.40580367826317487,
            "precision": 0.7277777777777777,
            "recall": 0.5481171548117155
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.767236676366639,
            "auditor_fn_violation": 0.018420979807949527,
            "auditor_fp_violation": 0.020977326923804846,
            "ave_precision_score": 0.6432386638427852,
            "fpr": 0.12843029637760703,
            "logloss": 4.806956999666343,
            "mae": 0.39740928313996476,
            "precision": 0.7160194174757282,
            "recall": 0.6197478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6672743210346253,
            "auditor_fn_violation": 0.013474454965866564,
            "auditor_fp_violation": 0.03696741854636592,
            "ave_precision_score": 0.6490342322484636,
            "fpr": 0.16666666666666666,
            "logloss": 2.5486840185181214,
            "mae": 0.3334066014392126,
            "precision": 0.7001972386587771,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6555577254857583,
            "auditor_fn_violation": 0.02038576132977889,
            "auditor_fp_violation": 0.03547446913206405,
            "ave_precision_score": 0.6366113186889504,
            "fpr": 0.18880351262349068,
            "logloss": 2.8432016653140515,
            "mae": 0.3227482978235834,
            "precision": 0.684981684981685,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6764354522021118,
            "auditor_fn_violation": 0.049280169566174856,
            "auditor_fp_violation": 0.011505578462284746,
            "ave_precision_score": 0.6776236470518342,
            "fpr": 0.025219298245614034,
            "logloss": 5.525648190146206,
            "mae": 0.4486777171454078,
            "precision": 0.8114754098360656,
            "recall": 0.20711297071129708
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7110612496068026,
            "auditor_fn_violation": 0.04474720733518436,
            "auditor_fp_violation": 0.009084371096559294,
            "ave_precision_score": 0.7115044637466251,
            "fpr": 0.019758507135016465,
            "logloss": 5.082027900117518,
            "mae": 0.43896445667919565,
            "precision": 0.8448275862068966,
            "recall": 0.20588235294117646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6542209627601432,
            "auditor_fn_violation": 0.014433311311752182,
            "auditor_fp_violation": 0.041424124828199536,
            "ave_precision_score": 0.6336680289646228,
            "fpr": 0.18859649122807018,
            "logloss": 2.9205767364219692,
            "mae": 0.3398488597762297,
            "precision": 0.6772983114446529,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6452352829438777,
            "auditor_fn_violation": 0.02486878395705154,
            "auditor_fp_violation": 0.039183920663159094,
            "ave_precision_score": 0.624858928144332,
            "fpr": 0.2074643249176729,
            "logloss": 3.0945586959614966,
            "mae": 0.33109000593828897,
            "precision": 0.671304347826087,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7076518747209143,
            "auditor_fn_violation": 0.10173970491081259,
            "auditor_fp_violation": 0.09322701916080524,
            "ave_precision_score": 0.5539907234972783,
            "fpr": 0.26973684210526316,
            "logloss": 0.6925918709271297,
            "mae": 0.49041462550756704,
            "precision": 0.5691768826619965,
            "recall": 0.6799163179916318
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7019366254609734,
            "auditor_fn_violation": 0.10747262681142711,
            "auditor_fp_violation": 0.09569880262942075,
            "ave_precision_score": 0.5517511679750556,
            "fpr": 0.26125137211855104,
            "logloss": 0.6955500979740952,
            "mae": 0.4915216175673691,
            "precision": 0.5688405797101449,
            "recall": 0.6596638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.665329908248826,
            "auditor_fn_violation": 0.016704286867797125,
            "auditor_fp_violation": 0.04398849947449268,
            "ave_precision_score": 0.6476709672043914,
            "fpr": 0.14144736842105263,
            "logloss": 2.5367407214320146,
            "mae": 0.339530324626976,
            "precision": 0.7061503416856492,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6553155428641089,
            "auditor_fn_violation": 0.026370043077604263,
            "auditor_fp_violation": 0.04356712971724895,
            "ave_precision_score": 0.6376269059536056,
            "fpr": 0.16136114160263446,
            "logloss": 2.7400289388721926,
            "mae": 0.322529280699092,
            "precision": 0.7036290322580645,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6623893253945767,
            "auditor_fn_violation": 0.018488952506789988,
            "auditor_fp_violation": 0.045097623089983024,
            "ave_precision_score": 0.6444909122970719,
            "fpr": 0.17763157894736842,
            "logloss": 2.5256532215087897,
            "mae": 0.33276493136384855,
            "precision": 0.6914285714285714,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6536107604961771,
            "auditor_fn_violation": 0.023360606591703647,
            "auditor_fp_violation": 0.03830576479049169,
            "ave_precision_score": 0.6348755304330431,
            "fpr": 0.18551042810098792,
            "logloss": 2.7830244158495288,
            "mae": 0.3216360811593654,
            "precision": 0.6960431654676259,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6702903968493036,
            "auditor_fn_violation": 0.013612089848051099,
            "auditor_fp_violation": 0.03916545395747433,
            "ave_precision_score": 0.652064965452644,
            "fpr": 0.18640350877192982,
            "logloss": 2.5047813061021746,
            "mae": 0.3335312322620943,
            "precision": 0.6840148698884758,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.657409466170353,
            "auditor_fn_violation": 0.018416367644752744,
            "auditor_fp_violation": 0.040039365608085103,
            "ave_precision_score": 0.6389482185286947,
            "fpr": 0.19978046103183314,
            "logloss": 2.773959342892423,
            "mae": 0.32587977676898755,
            "precision": 0.680140597539543,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7158502636078707,
            "auditor_fn_violation": 0.015350877192982467,
            "auditor_fp_violation": 0.015492359932088287,
            "ave_precision_score": 0.6219259103194886,
            "fpr": 0.11513157894736842,
            "logloss": 4.375289799485576,
            "mae": 0.403712191537284,
            "precision": 0.7214854111405835,
            "recall": 0.5690376569037657
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7445513857645475,
            "auditor_fn_violation": 0.019546347627964474,
            "auditor_fp_violation": 0.02236269351603013,
            "ave_precision_score": 0.6378503290826201,
            "fpr": 0.1350164654226125,
            "logloss": 5.022155562920938,
            "mae": 0.3952043879895781,
            "precision": 0.711943793911007,
            "recall": 0.6386554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6471283193025171,
            "auditor_fn_violation": 0.01256147691404243,
            "auditor_fp_violation": 0.040653549195569565,
            "ave_precision_score": 0.6247092622075192,
            "fpr": 0.20285087719298245,
            "logloss": 3.372003527424272,
            "mae": 0.34261545781361047,
            "precision": 0.6708185053380783,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6435794858377458,
            "auditor_fn_violation": 0.02241511313636322,
            "auditor_fp_violation": 0.0379121087096408,
            "ave_precision_score": 0.6205818277230893,
            "fpr": 0.21734357848518113,
            "logloss": 3.4362357860096355,
            "mae": 0.3347399272312338,
            "precision": 0.6666666666666666,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 3.4603725770353884,
            "mae": 0.5220554261202642,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 3.422145370067457,
            "mae": 0.5199409506186645,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7619764569937716,
            "auditor_fn_violation": 0.08522351904866769,
            "auditor_fp_violation": 0.018041575713477243,
            "ave_precision_score": 0.762262573890925,
            "fpr": 0.04057017543859649,
            "logloss": 0.678882622070628,
            "mae": 0.47347399022168757,
            "precision": 0.8271028037383178,
            "recall": 0.3702928870292887
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.751796911225055,
            "auditor_fn_violation": 0.07967050706122185,
            "auditor_fp_violation": 0.014625837465460464,
            "ave_precision_score": 0.7512991849583054,
            "fpr": 0.036223929747530186,
            "logloss": 0.7031721728191058,
            "mae": 0.479965464711909,
            "precision": 0.8421052631578947,
            "recall": 0.3697478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.602578873884268,
            "auditor_fn_violation": 0.06211462232988328,
            "auditor_fp_violation": 0.061716791979949885,
            "ave_precision_score": 0.6049414959497446,
            "fpr": 0.3399122807017544,
            "logloss": 0.6844044847451289,
            "mae": 0.4857463378851351,
            "precision": 0.5539568345323741,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.586627904218999,
            "auditor_fn_violation": 0.06897028844468633,
            "auditor_fp_violation": 0.06830185346404735,
            "ave_precision_score": 0.5875960743593115,
            "fpr": 0.3150384193194292,
            "logloss": 0.6857053943585664,
            "mae": 0.48629039077805897,
            "precision": 0.5625,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6671157261605212,
            "auditor_fn_violation": 0.012361906334874845,
            "auditor_fp_violation": 0.03608820438192256,
            "ave_precision_score": 0.6471561531231308,
            "fpr": 0.24780701754385964,
            "logloss": 2.708267423846236,
            "mae": 0.3428748870334733,
            "precision": 0.6474258970358814,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6540881998599583,
            "auditor_fn_violation": 0.015644457563486428,
            "auditor_fp_violation": 0.0307455492890218,
            "ave_precision_score": 0.6356948470179722,
            "fpr": 0.2678375411635565,
            "logloss": 2.925867936422918,
            "mae": 0.3439779738996651,
            "precision": 0.6369047619047619,
            "recall": 0.8991596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 30132,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6505807925781769,
            "auditor_fn_violation": 0.01522700579901637,
            "auditor_fp_violation": 0.039526740237691003,
            "ave_precision_score": 0.6303205284095567,
            "fpr": 0.19407894736842105,
            "logloss": 2.970725640549914,
            "mae": 0.3442240958664851,
            "precision": 0.6660377358490566,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.645419998514895,
            "auditor_fn_violation": 0.028120359010783247,
            "auditor_fp_violation": 0.03940093619491024,
            "ave_precision_score": 0.6251782643710287,
            "fpr": 0.19978046103183314,
            "logloss": 3.0708861029236014,
            "mae": 0.3308230095654399,
            "precision": 0.675,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 30132,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6570582311288081,
            "auditor_fn_violation": 0.01349739411289731,
            "auditor_fp_violation": 0.036583393968792954,
            "ave_precision_score": 0.6388742227203028,
            "fpr": 0.18859649122807018,
            "logloss": 2.6935393826915615,
            "mae": 0.34007501229379505,
            "precision": 0.6760828625235404,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6500109442614161,
            "auditor_fn_violation": 0.021626433229713405,
            "auditor_fp_violation": 0.039575053307594275,
            "ave_precision_score": 0.6305615178128594,
            "fpr": 0.20197585071350166,
            "logloss": 2.940489469726922,
            "mae": 0.32635827667278877,
            "precision": 0.6794425087108014,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6542143705569688,
            "auditor_fn_violation": 0.014433311311752182,
            "auditor_fp_violation": 0.041424124828199536,
            "ave_precision_score": 0.6336614458401744,
            "fpr": 0.18859649122807018,
            "logloss": 2.9207172337560743,
            "mae": 0.33982437660520504,
            "precision": 0.6772983114446529,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6452257748891748,
            "auditor_fn_violation": 0.02486878395705154,
            "auditor_fp_violation": 0.039183920663159094,
            "ave_precision_score": 0.6248394602483767,
            "fpr": 0.2074643249176729,
            "logloss": 3.095004403750554,
            "mae": 0.33106349708090504,
            "precision": 0.671304347826087,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6691849223631435,
            "auditor_fn_violation": 0.012917033693019163,
            "auditor_fp_violation": 0.038008327269787374,
            "ave_precision_score": 0.6509572130376943,
            "fpr": 0.19736842105263158,
            "logloss": 2.519398824565354,
            "mae": 0.333843365697535,
            "precision": 0.6768402154398564,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6582126626875828,
            "auditor_fn_violation": 0.018467101439917352,
            "auditor_fp_violation": 0.038949241076497984,
            "ave_precision_score": 0.6397494677638067,
            "fpr": 0.2074643249176729,
            "logloss": 2.7856692221204953,
            "mae": 0.3254341308193432,
            "precision": 0.6746987951807228,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6675554552377824,
            "auditor_fn_violation": 0.012900976290097633,
            "auditor_fp_violation": 0.03794769181017058,
            "ave_precision_score": 0.6493283181780696,
            "fpr": 0.19517543859649122,
            "logloss": 2.539428726911158,
            "mae": 0.33579360479452214,
            "precision": 0.6751824817518248,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6575126681890362,
            "auditor_fn_violation": 0.018503998745491614,
            "auditor_fp_violation": 0.038949241076497984,
            "ave_precision_score": 0.638726213422401,
            "fpr": 0.2074643249176729,
            "logloss": 2.8461736890768665,
            "mae": 0.32537083518829896,
            "precision": 0.6741379310344827,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6650323154986805,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6471388714221096,
            "fpr": 0.17982456140350878,
            "logloss": 2.484093934832384,
            "mae": 0.33019846345099013,
            "precision": 0.6893939393939394,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6554061590220267,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.03817454609687473,
            "ave_precision_score": 0.6373415772329492,
            "fpr": 0.18990120746432493,
            "logloss": 2.677565985642166,
            "mae": 0.32064452793299,
            "precision": 0.6921708185053381,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6033254899829277,
            "auditor_fn_violation": 0.10137267855832048,
            "auditor_fp_violation": 0.08564758670870729,
            "ave_precision_score": 0.6048525141067493,
            "fpr": 0.24780701754385964,
            "logloss": 0.6761057468890984,
            "mae": 0.4854300307730834,
            "precision": 0.5890909090909091,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5758720589843049,
            "auditor_fn_violation": 0.10603363189403094,
            "auditor_fp_violation": 0.0906266954338418,
            "ave_precision_score": 0.5789297382601706,
            "fpr": 0.24478594950603733,
            "logloss": 0.6804149033122002,
            "mae": 0.48742028074717286,
            "precision": 0.5816135084427767,
            "recall": 0.6512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5244170649874709,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5259725177008998,
            "fpr": 0.29605263157894735,
            "logloss": 0.6995767103050169,
            "mae": 0.49874938792945295,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5511981568641462,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.08749763427836027,
            "ave_precision_score": 0.5532657797793048,
            "fpr": 0.283205268935236,
            "logloss": 0.6876640289548963,
            "mae": 0.4953708588815285,
            "precision": 0.5671140939597316,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.5692336605181453,
            "auditor_fn_violation": 0.10137267855832048,
            "auditor_fp_violation": 0.08564758670870729,
            "ave_precision_score": 0.57132182088767,
            "fpr": 0.24780701754385964,
            "logloss": 0.6767438979986999,
            "mae": 0.48555607260449934,
            "precision": 0.5890909090909091,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5845804057550541,
            "auditor_fn_violation": 0.10603363189403094,
            "auditor_fp_violation": 0.0906266954338418,
            "ave_precision_score": 0.5858847018811035,
            "fpr": 0.24478594950603733,
            "logloss": 0.6799978380182586,
            "mae": 0.48709620579537394,
            "precision": 0.5816135084427767,
            "recall": 0.6512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 30132,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.47691599866376944,
            "auditor_fn_violation": 0.09336691624458637,
            "auditor_fp_violation": 0.0954048427520414,
            "ave_precision_score": 0.4730831292555415,
            "fpr": 0.29385964912280704,
            "logloss": 0.6921019371938718,
            "mae": 0.4979969721875693,
            "precision": 0.5518394648829431,
            "recall": 0.6903765690376569
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5183352613572637,
            "auditor_fn_violation": 0.08037616803032958,
            "auditor_fp_violation": 0.08512812748400773,
            "ave_precision_score": 0.5073185687586176,
            "fpr": 0.27991218441273324,
            "logloss": 0.6875645887066754,
            "mae": 0.49572638243142386,
            "precision": 0.5699831365935919,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5244170649874709,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5259725177008998,
            "fpr": 0.29605263157894735,
            "logloss": 0.6995767129149477,
            "mae": 0.4987493878559275,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5511981568641462,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.08749763427836027,
            "ave_precision_score": 0.5532657797793048,
            "fpr": 0.283205268935236,
            "logloss": 0.6876640291954315,
            "mae": 0.4953708587506731,
            "precision": 0.5671140939597316,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7925555174552301,
            "auditor_fn_violation": 0.012001761726491965,
            "auditor_fp_violation": 0.019294708545557444,
            "ave_precision_score": 0.7929235363128507,
            "fpr": 0.06469298245614036,
            "logloss": 0.6369699294884327,
            "mae": 0.3752885634026474,
            "precision": 0.8013468013468014,
            "recall": 0.497907949790795
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7908589158014729,
            "auditor_fn_violation": 0.014611333007407138,
            "auditor_fp_violation": 0.011711268405314355,
            "ave_precision_score": 0.7911619319582901,
            "fpr": 0.0570801317233809,
            "logloss": 0.6528382223962524,
            "mae": 0.3843368898456636,
            "precision": 0.8225255972696246,
            "recall": 0.5063025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 30132,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6648205461366281,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04148223381033229,
            "ave_precision_score": 0.6469272404894238,
            "fpr": 0.18092105263157895,
            "logloss": 2.491769811371169,
            "mae": 0.3302919115285521,
            "precision": 0.6880907372400756,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6549163033233034,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.038419319429198684,
            "ave_precision_score": 0.6366655231345305,
            "fpr": 0.19099890230515917,
            "logloss": 2.703573271124373,
            "mae": 0.3207874522256066,
            "precision": 0.6909413854351687,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 30132,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6555416777643908,
            "auditor_fn_violation": 0.013373522718931219,
            "auditor_fp_violation": 0.03802348613469157,
            "ave_precision_score": 0.6347479669084136,
            "fpr": 0.22039473684210525,
            "logloss": 2.9673568990257757,
            "mae": 0.34292787805390196,
            "precision": 0.6587436332767402,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6493948416262149,
            "auditor_fn_violation": 0.017791419531588706,
            "auditor_fp_violation": 0.029837112179365865,
            "ave_precision_score": 0.6280435041759778,
            "fpr": 0.23819978046103182,
            "logloss": 3.14405768464111,
            "mae": 0.33697914897995357,
            "precision": 0.6522435897435898,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6654081214248276,
            "auditor_fn_violation": 0.016704286867797125,
            "auditor_fp_violation": 0.04398849947449268,
            "ave_precision_score": 0.647749131676539,
            "fpr": 0.14144736842105263,
            "logloss": 2.534614081219547,
            "mae": 0.3394641475279287,
            "precision": 0.7061503416856492,
            "recall": 0.6485355648535565
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6545058000644363,
            "auditor_fn_violation": 0.026370043077604263,
            "auditor_fp_violation": 0.04356712971724895,
            "ave_precision_score": 0.6372036634214839,
            "fpr": 0.16136114160263446,
            "logloss": 2.7383824667994956,
            "mae": 0.3224781407021631,
            "precision": 0.7036290322580645,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6468453386451625,
            "auditor_fn_violation": 0.013240475666152832,
            "auditor_fp_violation": 0.041353383458646614,
            "ave_precision_score": 0.6244263595285892,
            "fpr": 0.20394736842105263,
            "logloss": 3.391260953168522,
            "mae": 0.3425366538019345,
            "precision": 0.6702127659574468,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6436198458289032,
            "auditor_fn_violation": 0.02241511313636322,
            "auditor_fp_violation": 0.03440705552821834,
            "ave_precision_score": 0.6206132590217445,
            "fpr": 0.2217343578485181,
            "logloss": 3.4478187918491834,
            "mae": 0.3350936756513154,
            "precision": 0.6622073578595318,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7933691940518184,
            "auditor_fn_violation": 0.012061403508771927,
            "auditor_fp_violation": 0.019294708545557444,
            "ave_precision_score": 0.79373462409556,
            "fpr": 0.06469298245614036,
            "logloss": 0.6328492208345968,
            "mae": 0.37439425075845384,
            "precision": 0.802013422818792,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7907634760314548,
            "auditor_fn_violation": 0.014445295132322969,
            "auditor_fp_violation": 0.011711268405314355,
            "ave_precision_score": 0.7910661464124541,
            "fpr": 0.0570801317233809,
            "logloss": 0.6498564707112716,
            "mae": 0.3839009152863351,
            "precision": 0.8243243243243243,
            "recall": 0.5126050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5244170649874709,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09396475058614279,
            "ave_precision_score": 0.5259725177008998,
            "fpr": 0.29605263157894735,
            "logloss": 0.6995767159463282,
            "mae": 0.49874938796927926,
            "precision": 0.5484949832775919,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5511981568641462,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.08749763427836027,
            "ave_precision_score": 0.5532657797793048,
            "fpr": 0.283205268935236,
            "logloss": 0.6876640300087435,
            "mae": 0.49537085878338694,
            "precision": 0.5671140939597316,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5704620638808047,
            "auditor_fn_violation": 0.0007661675108272774,
            "auditor_fp_violation": 0.0016219985447489752,
            "ave_precision_score": 0.5720090382727336,
            "fpr": 0.4725877192982456,
            "logloss": 0.7976496286319891,
            "mae": 0.48502227625370625,
            "precision": 0.5232300884955752,
            "recall": 0.9895397489539749
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5793727362743443,
            "auditor_fn_violation": 0.0023706518831462333,
            "auditor_fp_violation": 0.0018774366932889244,
            "ave_precision_score": 0.5809625996126822,
            "fpr": 0.47420417124039516,
            "logloss": 0.7877472950928918,
            "mae": 0.48283762006348757,
            "precision": 0.5221238938053098,
            "recall": 0.9915966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6093329945982708,
            "auditor_fn_violation": 0.06084379358437936,
            "auditor_fp_violation": 0.06100685180693673,
            "ave_precision_score": 0.6101111647917676,
            "fpr": 0.34100877192982454,
            "logloss": 0.6834912717716292,
            "mae": 0.48519179855653066,
            "precision": 0.5563480741797432,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5880691764373598,
            "auditor_fn_violation": 0.06878580191681503,
            "auditor_fp_violation": 0.06736061168098717,
            "ave_precision_score": 0.5893286054489597,
            "fpr": 0.3194291986827662,
            "logloss": 0.6849451455259653,
            "mae": 0.4857498900034556,
            "precision": 0.5610859728506787,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6689325777467422,
            "auditor_fn_violation": 0.011586563165235264,
            "auditor_fp_violation": 0.03608820438192256,
            "ave_precision_score": 0.6486738168334862,
            "fpr": 0.24780701754385964,
            "logloss": 2.7053526377181125,
            "mae": 0.34275664319283666,
            "precision": 0.6485225505443235,
            "recall": 0.8723849372384938
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6545385659644025,
            "auditor_fn_violation": 0.012835650176645853,
            "auditor_fp_violation": 0.03114677567911983,
            "ave_precision_score": 0.6361293224377327,
            "fpr": 0.2678375411635565,
            "logloss": 2.928606533062829,
            "mae": 0.34355563089554875,
            "precision": 0.6385185185185185,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.654057533909895,
            "auditor_fn_violation": 0.011478749174190707,
            "auditor_fp_violation": 0.03654297032904843,
            "ave_precision_score": 0.6330306422622377,
            "fpr": 0.22587719298245615,
            "logloss": 3.051276880199582,
            "mae": 0.3515674995375581,
            "precision": 0.6583747927031509,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6496330809245636,
            "auditor_fn_violation": 0.018248023688070186,
            "auditor_fp_violation": 0.032317650176009696,
            "ave_precision_score": 0.6279267614956014,
            "fpr": 0.2557628979143798,
            "logloss": 3.212142477291475,
            "mae": 0.34732747230138483,
            "precision": 0.6381987577639752,
            "recall": 0.8634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 30132,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.7127217676886004,
            "auditor_fn_violation": 0.007001027673786983,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7131568581629995,
            "fpr": 0.0,
            "logloss": 4.679448036363131,
            "mae": 0.4937237301669364,
            "precision": 1.0,
            "recall": 0.029288702928870293
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.7311219863986878,
            "auditor_fn_violation": 0.00458910238079865,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7315159953958332,
            "fpr": 0.0,
            "logloss": 4.371865754162487,
            "mae": 0.49193190231175227,
            "precision": 1.0,
            "recall": 0.02100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6641938473915989,
            "auditor_fn_violation": 0.020053402334287606,
            "auditor_fp_violation": 0.043844490257902824,
            "ave_precision_score": 0.6465505023155196,
            "fpr": 0.14473684210526316,
            "logloss": 2.593792093286848,
            "mae": 0.34065569834537895,
            "precision": 0.7027027027027027,
            "recall": 0.6527196652719666
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.654019987636248,
            "auditor_fn_violation": 0.02746773791843852,
            "auditor_fp_violation": 0.040160490556039215,
            "ave_precision_score": 0.6357740545002681,
            "fpr": 0.16465422612513722,
            "logloss": 2.8209154033291344,
            "mae": 0.32404071237113957,
            "precision": 0.6993987975951904,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6668608065587245,
            "auditor_fn_violation": 0.01580048447478529,
            "auditor_fp_violation": 0.04312697065243755,
            "ave_precision_score": 0.6492501928208422,
            "fpr": 0.17543859649122806,
            "logloss": 2.422857315969167,
            "mae": 0.3287398958865383,
            "precision": 0.6958174904942965,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6568970634000567,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.03855810843206279,
            "ave_precision_score": 0.6393623634252528,
            "fpr": 0.18660812294182216,
            "logloss": 2.602817761993942,
            "mae": 0.3196776733346015,
            "precision": 0.6958855098389982,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 30132,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6554066602243344,
            "auditor_fn_violation": 0.015935825442266755,
            "auditor_fp_violation": 0.04238923922710001,
            "ave_precision_score": 0.6346134648147901,
            "fpr": 0.19517543859649122,
            "logloss": 2.989623373810343,
            "mae": 0.3364118625869227,
            "precision": 0.6721915285451197,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.645546567355626,
            "auditor_fn_violation": 0.02322685385899696,
            "auditor_fp_violation": 0.039183920663159094,
            "ave_precision_score": 0.6248002546599645,
            "fpr": 0.2074643249176729,
            "logloss": 3.139615045567862,
            "mae": 0.32892549923754116,
            "precision": 0.6735751295336787,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.60034332122877,
            "auditor_fn_violation": 0.06433054393305439,
            "auditor_fp_violation": 0.062358517260894177,
            "ave_precision_score": 0.602606845776584,
            "fpr": 0.33771929824561403,
            "logloss": 0.6843045456084568,
            "mae": 0.48584089736993374,
            "precision": 0.553623188405797,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5865192112192339,
            "auditor_fn_violation": 0.07160844579324596,
            "auditor_fp_violation": 0.06961404040021703,
            "ave_precision_score": 0.5875355749549156,
            "fpr": 0.31174533479692645,
            "logloss": 0.6855927504655343,
            "mae": 0.4863727233739637,
            "precision": 0.5617283950617284,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6525133359199103,
            "auditor_fn_violation": 0.016323497027086544,
            "auditor_fp_violation": 0.04188394373029348,
            "ave_precision_score": 0.6324908361978517,
            "fpr": 0.19298245614035087,
            "logloss": 2.933800815127541,
            "mae": 0.3420418796771344,
            "precision": 0.667296786389414,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6461593236082177,
            "auditor_fn_violation": 0.02402245201044194,
            "auditor_fp_violation": 0.04063742003860859,
            "ave_precision_score": 0.625912173509463,
            "fpr": 0.20417124039517015,
            "logloss": 3.0563396835474412,
            "mae": 0.32967098637454395,
            "precision": 0.6707964601769911,
            "recall": 0.7962184873949579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6303519403740925,
            "auditor_fn_violation": 0.09041235410702489,
            "auditor_fp_violation": 0.09437403993855607,
            "ave_precision_score": 0.6322310730467988,
            "fpr": 0.30043859649122806,
            "logloss": 0.7048946504779703,
            "mae": 0.4992556735289103,
            "precision": 0.5440931780366056,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.645037547582539,
            "auditor_fn_violation": 0.07903402854006587,
            "auditor_fp_violation": 0.08608703332197788,
            "ave_precision_score": 0.6463746894623454,
            "fpr": 0.278814489571899,
            "logloss": 0.6887194428902573,
            "mae": 0.4941775600756105,
            "precision": 0.5723905723905723,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6631133810722256,
            "auditor_fn_violation": 0.030096160904352943,
            "auditor_fp_violation": 0.04680299539170507,
            "ave_precision_score": 0.6452489528964482,
            "fpr": 0.12390350877192982,
            "logloss": 2.806274610939394,
            "mae": 0.3587528396112985,
            "precision": 0.6954177897574124,
            "recall": 0.5397489539748954
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6524331176619228,
            "auditor_fn_violation": 0.023540480956378163,
            "auditor_fp_violation": 0.04405162950906546,
            "ave_precision_score": 0.6343586822218918,
            "fpr": 0.13830954994511527,
            "logloss": 2.9313654411580443,
            "mae": 0.3393689409516066,
            "precision": 0.7014218009478673,
            "recall": 0.6218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.665676084422587,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6477949271707786,
            "fpr": 0.17982456140350878,
            "logloss": 2.465189589423422,
            "mae": 0.3298085634383193,
            "precision": 0.6893939393939394,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6559357654606888,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.038240155443683206,
            "ave_precision_score": 0.6378601840330671,
            "fpr": 0.19319429198682767,
            "logloss": 2.6623087687930878,
            "mae": 0.3202707607443151,
            "precision": 0.6884955752212389,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6542189956836885,
            "auditor_fn_violation": 0.014433311311752182,
            "auditor_fp_violation": 0.041424124828199536,
            "ave_precision_score": 0.6336660635164946,
            "fpr": 0.18859649122807018,
            "logloss": 2.9205931722458045,
            "mae": 0.339822206056085,
            "precision": 0.6772983114446529,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.645238925146957,
            "auditor_fn_violation": 0.02486878395705154,
            "auditor_fp_violation": 0.039183920663159094,
            "ave_precision_score": 0.6248580892502968,
            "fpr": 0.2074643249176729,
            "logloss": 3.094574035566551,
            "mae": 0.33106169011477454,
            "precision": 0.671304347826087,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7583795577350163,
            "auditor_fn_violation": 0.017043786243852315,
            "auditor_fp_violation": 0.013084626889805164,
            "ave_precision_score": 0.6387169671710947,
            "fpr": 0.10416666666666667,
            "logloss": 4.0147847181282685,
            "mae": 0.4058609931288581,
            "precision": 0.7323943661971831,
            "recall": 0.5439330543933054
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7655548687298543,
            "auditor_fn_violation": 0.019435655711241694,
            "auditor_fp_violation": 0.02056348335162825,
            "ave_precision_score": 0.6418131850294848,
            "fpr": 0.12733260153677278,
            "logloss": 4.773353814324278,
            "mae": 0.3992946710924155,
            "precision": 0.7156862745098039,
            "recall": 0.6134453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.664815827923868,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6469224946922197,
            "fpr": 0.17982456140350878,
            "logloss": 2.491181663683769,
            "mae": 0.3304180131881677,
            "precision": 0.6893939393939394,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6548867952883894,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.038419319429198684,
            "ave_precision_score": 0.6366413185116917,
            "fpr": 0.19099890230515917,
            "logloss": 2.70079677228838,
            "mae": 0.3209119052769651,
            "precision": 0.6909413854351687,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5211737573017726,
            "auditor_fn_violation": 0.0023489686559494973,
            "auditor_fp_violation": 0.0019479141401891882,
            "ave_precision_score": 0.5577275407650635,
            "fpr": 0.47039473684210525,
            "logloss": 0.7467626232309713,
            "mae": 0.484231184906604,
            "precision": 0.5249169435215947,
            "recall": 0.9916317991631799
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5202007057048533,
            "auditor_fn_violation": 0.0002213838334455626,
            "auditor_fp_violation": 0.0025284832885423543,
            "ave_precision_score": 0.5709365006347322,
            "fpr": 0.4676180021953897,
            "logloss": 0.743440267792253,
            "mae": 0.4832427645619431,
            "precision": 0.5256124721603563,
            "recall": 0.9915966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.571750089243894,
            "auditor_fn_violation": 0.10137267855832048,
            "auditor_fp_violation": 0.08564758670870729,
            "ave_precision_score": 0.5738354729937026,
            "fpr": 0.24780701754385964,
            "logloss": 0.6764495033768767,
            "mae": 0.4849091487070709,
            "precision": 0.5890909090909091,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5907779292844455,
            "auditor_fn_violation": 0.10603363189403094,
            "auditor_fp_violation": 0.0906266954338418,
            "ave_precision_score": 0.5919442670029778,
            "fpr": 0.24478594950603733,
            "logloss": 0.6793836425268746,
            "mae": 0.4863573301145981,
            "precision": 0.5816135084427767,
            "recall": 0.6512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6685486368451824,
            "auditor_fn_violation": 0.01249724730235631,
            "auditor_fp_violation": 0.03843782844207293,
            "ave_precision_score": 0.6503105295390689,
            "fpr": 0.19078947368421054,
            "logloss": 2.5309627008675095,
            "mae": 0.33364411343927275,
            "precision": 0.6807339449541284,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6576220559122967,
            "auditor_fn_violation": 0.01822726895368466,
            "auditor_fp_violation": 0.03982739694916537,
            "ave_precision_score": 0.6389937768890085,
            "fpr": 0.20636663007683864,
            "logloss": 2.811618527900727,
            "mae": 0.3247390123107396,
            "precision": 0.6747404844290658,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6488099899336466,
            "auditor_fn_violation": 0.013685495118549513,
            "auditor_fp_violation": 0.039683381841701025,
            "ave_precision_score": 0.6265767769445949,
            "fpr": 0.19846491228070176,
            "logloss": 3.334118893177022,
            "mae": 0.33921887297794895,
            "precision": 0.6726943942133815,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6455181293012574,
            "auditor_fn_violation": 0.022272136077262958,
            "auditor_fp_violation": 0.03711217936586043,
            "ave_precision_score": 0.6226871759682906,
            "fpr": 0.21514818880351264,
            "logloss": 3.3995677417560617,
            "mae": 0.3309515728812552,
            "precision": 0.6683587140439933,
            "recall": 0.8298319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.667066848848838,
            "auditor_fn_violation": 0.011804485062027456,
            "auditor_fp_violation": 0.03630800792303339,
            "ave_precision_score": 0.6494102789431198,
            "fpr": 0.19188596491228072,
            "logloss": 2.488798771396838,
            "mae": 0.3352972715081303,
            "precision": 0.6788990825688074,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6546816335681334,
            "auditor_fn_violation": 0.018605466335820827,
            "auditor_fp_violation": 0.041497911856366,
            "ave_precision_score": 0.6362801914550275,
            "fpr": 0.2030735455543359,
            "logloss": 2.7763622775802994,
            "mae": 0.3281381985050757,
            "precision": 0.6748681898066784,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.7140171316556234,
            "auditor_fn_violation": 0.004500660647434491,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7144485976570825,
            "fpr": 0.0,
            "logloss": 4.91376820927882,
            "mae": 0.4967079427990293,
            "precision": 1.0,
            "recall": 0.01882845188284519
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.7328903468983012,
            "auditor_fn_violation": 0.004130192142718788,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7332779662625359,
            "fpr": 0.0,
            "logloss": 4.592376243439868,
            "mae": 0.4949646871188353,
            "precision": 1.0,
            "recall": 0.018907563025210083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6663868015366483,
            "auditor_fn_violation": 0.01113924979813551,
            "auditor_fp_violation": 0.03606293960708223,
            "ave_precision_score": 0.6484442774687161,
            "fpr": 0.17763157894736842,
            "logloss": 2.5152138367016352,
            "mae": 0.33448845734467736,
            "precision": 0.6920152091254753,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6568758073460548,
            "auditor_fn_violation": 0.018799177190085694,
            "auditor_fp_violation": 0.03880035832797103,
            "ave_precision_score": 0.6384678959565457,
            "fpr": 0.19538968166849616,
            "logloss": 2.790145884470633,
            "mae": 0.322236824089621,
            "precision": 0.6815742397137746,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.646548591343848,
            "auditor_fn_violation": 0.01256147691404243,
            "auditor_fp_violation": 0.040653549195569565,
            "ave_precision_score": 0.6241140645014817,
            "fpr": 0.20285087719298245,
            "logloss": 3.384357443137205,
            "mae": 0.34272840188254644,
            "precision": 0.6708185053380783,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6433239533751005,
            "auditor_fn_violation": 0.02241511313636322,
            "auditor_fp_violation": 0.0379121087096408,
            "ave_precision_score": 0.620317571101046,
            "fpr": 0.21734357848518113,
            "logloss": 3.4427571117869435,
            "mae": 0.33497983459857117,
            "precision": 0.6666666666666666,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6655841498656019,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6476901956626886,
            "fpr": 0.17982456140350878,
            "logloss": 2.466180879210663,
            "mae": 0.3300337504576462,
            "precision": 0.6893939393939394,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6558287260732683,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.038240155443683206,
            "ave_precision_score": 0.6377532019542017,
            "fpr": 0.19319429198682767,
            "logloss": 2.6632751648127706,
            "mae": 0.32037606698013754,
            "precision": 0.6884955752212389,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 30132,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5647008646044245,
            "auditor_fn_violation": 0.08965765616971298,
            "auditor_fp_violation": 0.09324470450319347,
            "ave_precision_score": 0.5662486542872236,
            "fpr": 0.29714912280701755,
            "logloss": 0.7063497238807325,
            "mae": 0.49665672719073717,
            "precision": 0.5513245033112583,
            "recall": 0.696652719665272
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5696474276921273,
            "auditor_fn_violation": 0.0790778440904353,
            "auditor_fp_violation": 0.08799222781583961,
            "ave_precision_score": 0.5712333348846322,
            "fpr": 0.2810098792535675,
            "logloss": 0.6973054805263655,
            "mae": 0.49484857848132874,
            "precision": 0.5711892797319933,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.7124995688764689,
            "auditor_fn_violation": 0.008918740365558257,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7129286484807855,
            "fpr": 0.0,
            "logloss": 4.62217343962114,
            "mae": 0.49206332206378045,
            "precision": 1.0,
            "recall": 0.03765690376569038
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.7303427701177381,
            "auditor_fn_violation": 0.005965833095038238,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7307352909729974,
            "fpr": 0.0,
            "logloss": 4.316057251062094,
            "mae": 0.49032052577080865,
            "precision": 1.0,
            "recall": 0.0273109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6681176995614314,
            "auditor_fn_violation": 0.013380404463040448,
            "auditor_fp_violation": 0.03630800792303339,
            "ave_precision_score": 0.6504565605362664,
            "fpr": 0.19188596491228072,
            "logloss": 2.460011184652414,
            "mae": 0.33465923878620946,
            "precision": 0.6794871794871795,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6550514410638759,
            "auditor_fn_violation": 0.0200675220692009,
            "auditor_fp_violation": 0.040301802995319026,
            "ave_precision_score": 0.6373449083993472,
            "fpr": 0.20636663007683864,
            "logloss": 2.712607652070488,
            "mae": 0.3280177932052964,
            "precision": 0.6730434782608695,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6685682321052191,
            "auditor_fn_violation": 0.013667143800924908,
            "auditor_fp_violation": 0.03838729889239227,
            "ave_precision_score": 0.6503360967625634,
            "fpr": 0.19407894736842105,
            "logloss": 2.526232573214546,
            "mae": 0.33365811937864315,
            "precision": 0.6775956284153005,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6573849911700618,
            "auditor_fn_violation": 0.021405049396267837,
            "auditor_fp_violation": 0.03982739694916537,
            "ave_precision_score": 0.6389142876771958,
            "fpr": 0.20636663007683864,
            "logloss": 2.7899687170448213,
            "mae": 0.3249256534931514,
            "precision": 0.6753022452504318,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6671660582715374,
            "auditor_fn_violation": 0.013474454965866564,
            "auditor_fp_violation": 0.03696741854636592,
            "ave_precision_score": 0.6489262121093289,
            "fpr": 0.16666666666666666,
            "logloss": 2.550867604878432,
            "mae": 0.33344510235884267,
            "precision": 0.7001972386587771,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6555221823372672,
            "auditor_fn_violation": 0.02038576132977889,
            "auditor_fp_violation": 0.03547446913206405,
            "ave_precision_score": 0.6365810133351192,
            "fpr": 0.18880351262349068,
            "logloss": 2.8447282111302012,
            "mae": 0.3227839728442007,
            "precision": 0.684981684981685,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 3.379141233970287,
            "mae": 0.5215220478908557,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 3.3845123849614898,
            "mae": 0.5196879192732846,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7618810059852339,
            "auditor_fn_violation": 0.08522351904866769,
            "auditor_fp_violation": 0.018041575713477243,
            "ave_precision_score": 0.7632552002214728,
            "fpr": 0.04057017543859649,
            "logloss": 0.6788805478938914,
            "mae": 0.47347305067243023,
            "precision": 0.8271028037383178,
            "recall": 0.3702928870292887
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7517432566231417,
            "auditor_fn_violation": 0.07967050706122185,
            "auditor_fp_violation": 0.014625837465460464,
            "ave_precision_score": 0.752454503801028,
            "fpr": 0.036223929747530186,
            "logloss": 0.7031700509892741,
            "mae": 0.47996452057368144,
            "precision": 0.8421052631578947,
            "recall": 0.3697478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.626688611380007,
            "auditor_fn_violation": 0.09004532775453279,
            "auditor_fp_violation": 0.09509408602150538,
            "ave_precision_score": 0.6290016856136811,
            "fpr": 0.2993421052631579,
            "logloss": 0.7108811911787644,
            "mae": 0.4994730260897134,
            "precision": 0.5442404006677797,
            "recall": 0.6820083682008368
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6434853979920574,
            "auditor_fn_violation": 0.07903402854006587,
            "auditor_fp_violation": 0.0792232862712442,
            "ave_precision_score": 0.646398253716205,
            "fpr": 0.27991218441273324,
            "logloss": 0.6888683611012955,
            "mae": 0.49383026485778103,
            "precision": 0.5714285714285714,
            "recall": 0.7142857142857143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7158502703200877,
            "auditor_fn_violation": 0.015350877192982467,
            "auditor_fp_violation": 0.015492359932088287,
            "ave_precision_score": 0.6219259170374637,
            "fpr": 0.11513157894736842,
            "logloss": 4.375288909467478,
            "mae": 0.40371158627564446,
            "precision": 0.7214854111405835,
            "recall": 0.5690376569037657
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7445500760976923,
            "auditor_fn_violation": 0.019546347627964474,
            "auditor_fp_violation": 0.02236269351603013,
            "ave_precision_score": 0.6378503524486264,
            "fpr": 0.1350164654226125,
            "logloss": 5.022154545214749,
            "mae": 0.3952037345630277,
            "precision": 0.711943793911007,
            "recall": 0.6386554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6657867387063987,
            "auditor_fn_violation": 0.015972528077515962,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6478776858449398,
            "fpr": 0.17982456140350878,
            "logloss": 2.464294924875918,
            "mae": 0.32961661059387937,
            "precision": 0.6911487758945386,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6559221026646712,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.03899970980481219,
            "ave_precision_score": 0.6378464537435489,
            "fpr": 0.19538968166849616,
            "logloss": 2.6601734642372916,
            "mae": 0.32050217516101515,
            "precision": 0.6860670194003528,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6648511134221703,
            "auditor_fn_violation": 0.0134515158188358,
            "auditor_fp_violation": 0.04014067426631095,
            "ave_precision_score": 0.6458394514526367,
            "fpr": 0.21271929824561403,
            "logloss": 2.6691210814882367,
            "mae": 0.3375601314428207,
            "precision": 0.6666666666666666,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6550719670033982,
            "auditor_fn_violation": 0.01850399874549161,
            "auditor_fp_violation": 0.03461145387789093,
            "ave_precision_score": 0.635594950838246,
            "fpr": 0.23380900109769484,
            "logloss": 2.921758021198857,
            "mae": 0.3334616176060785,
            "precision": 0.6570048309178744,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7386685218463289,
            "auditor_fn_violation": 0.00711113557953461,
            "auditor_fp_violation": 0.0071448783248443835,
            "ave_precision_score": 0.672685741923207,
            "fpr": 0.4407894736842105,
            "logloss": 7.60363629819056,
            "mae": 0.47359097894762603,
            "precision": 0.5270588235294118,
            "recall": 0.9372384937238494
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7487638122423717,
            "auditor_fn_violation": 0.008009021391212907,
            "auditor_fp_violation": 0.008670527524382719,
            "ave_precision_score": 0.6783351867883506,
            "fpr": 0.43578485181119647,
            "logloss": 7.702472604316958,
            "mae": 0.4634418350409546,
            "precision": 0.5318396226415094,
            "recall": 0.9474789915966386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.7127089299228101,
            "auditor_fn_violation": 0.007535509799603611,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7131261897655969,
            "fpr": 0.0,
            "logloss": 4.676435217270851,
            "mae": 0.49365321733476075,
            "precision": 1.0,
            "recall": 0.03138075313807531
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.7309850512466196,
            "auditor_fn_violation": 0.005506922856958376,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7313743309887446,
            "fpr": 0.0,
            "logloss": 4.3675040191116725,
            "mae": 0.49180572490143176,
            "precision": 1.0,
            "recall": 0.025210084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6688412140398168,
            "auditor_fn_violation": 0.012263268002642592,
            "auditor_fp_violation": 0.03708616298811546,
            "ave_precision_score": 0.6506256285381621,
            "fpr": 0.1962719298245614,
            "logloss": 2.5176901440621946,
            "mae": 0.3346808045391644,
            "precision": 0.6774774774774774,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6582467296209644,
            "auditor_fn_violation": 0.01803817026261657,
            "auditor_fp_violation": 0.03902494416896932,
            "ave_precision_score": 0.6397894646497124,
            "fpr": 0.20856201975850713,
            "logloss": 2.789840032546218,
            "mae": 0.3252640197133433,
            "precision": 0.6740994854202401,
            "recall": 0.8256302521008403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6698694827638194,
            "auditor_fn_violation": 0.012208214049768776,
            "auditor_fp_violation": 0.03879658824480556,
            "ave_precision_score": 0.6516427912923136,
            "fpr": 0.18859649122807018,
            "logloss": 2.5061417854667916,
            "mae": 0.33376811123660993,
            "precision": 0.6820702402957486,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6566247347524534,
            "auditor_fn_violation": 0.019085131308286214,
            "auditor_fp_violation": 0.0411976229228964,
            "ave_precision_score": 0.6381519895498393,
            "fpr": 0.20087815587266739,
            "logloss": 2.775915323486287,
            "mae": 0.32629734388059645,
            "precision": 0.6795096322241682,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5276122432771607,
            "auditor_fn_violation": 0.090779380459517,
            "auditor_fp_violation": 0.09317143665615653,
            "ave_precision_score": 0.5291681665953107,
            "fpr": 0.2949561403508772,
            "logloss": 0.7011666954513439,
            "mae": 0.49864707028405464,
            "precision": 0.5494137353433836,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5551330310688454,
            "auditor_fn_violation": 0.07832375540776136,
            "auditor_fp_violation": 0.0881966261655122,
            "ave_precision_score": 0.5571966609084131,
            "fpr": 0.28210757409440174,
            "logloss": 0.6876104014475639,
            "mae": 0.4951653702329726,
            "precision": 0.5680672268907563,
            "recall": 0.7100840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7024484285053019,
            "auditor_fn_violation": 0.0483327827938046,
            "auditor_fp_violation": 0.010292869269949066,
            "ave_precision_score": 0.702910334217515,
            "fpr": 0.023026315789473683,
            "logloss": 6.413011626577332,
            "mae": 0.44438469838025846,
            "precision": 0.8235294117647058,
            "recall": 0.20502092050209206
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7187767789135457,
            "auditor_fn_violation": 0.04155097823981404,
            "auditor_fp_violation": 0.007229645331011772,
            "ave_precision_score": 0.719216724413448,
            "fpr": 0.01646542261251372,
            "logloss": 5.899842832714127,
            "mae": 0.4388931687300806,
            "precision": 0.8584905660377359,
            "recall": 0.19117647058823528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7019594852717225,
            "auditor_fn_violation": 0.09371100345004771,
            "auditor_fp_violation": 0.09619057724957555,
            "ave_precision_score": 0.5452906995433756,
            "fpr": 0.2993421052631579,
            "logloss": 0.689099659453325,
            "mae": 0.49680070154238165,
            "precision": 0.5495049504950495,
            "recall": 0.696652719665272
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7168818362993868,
            "auditor_fn_violation": 0.0805329815790202,
            "auditor_fp_violation": 0.0903011721362151,
            "ave_precision_score": 0.559835471344075,
            "fpr": 0.2843029637760702,
            "logloss": 0.6856296709060227,
            "mae": 0.49504794685822284,
            "precision": 0.5690515806988353,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6651020410403774,
            "auditor_fn_violation": 0.016892387873449315,
            "auditor_fp_violation": 0.04186878486538928,
            "ave_precision_score": 0.6472085432561275,
            "fpr": 0.17982456140350878,
            "logloss": 2.483018467137878,
            "mae": 0.33015769674469736,
            "precision": 0.6893939393939394,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6554416552943862,
            "auditor_fn_violation": 0.02452287171729284,
            "auditor_fp_violation": 0.038419319429198684,
            "ave_precision_score": 0.6373609602745373,
            "fpr": 0.19099890230515917,
            "logloss": 2.6784354835726942,
            "mae": 0.32064916037917035,
            "precision": 0.6909413854351687,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6920270788009351,
            "mae": 0.498063993721939,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6912475105538971,
            "mae": 0.4977423838870324,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6631862332400319,
            "auditor_fn_violation": 0.030096160904352943,
            "auditor_fp_violation": 0.04680299539170507,
            "ave_precision_score": 0.6453217622603109,
            "fpr": 0.12390350877192982,
            "logloss": 2.804109634542381,
            "mae": 0.35861650138242546,
            "precision": 0.6954177897574124,
            "recall": 0.5397489539748954
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6526071934139046,
            "auditor_fn_violation": 0.023540480956378163,
            "auditor_fp_violation": 0.04405162950906546,
            "ave_precision_score": 0.6345326326413093,
            "fpr": 0.13830954994511527,
            "logloss": 2.9298446466262895,
            "mae": 0.33922709729194,
            "precision": 0.7014218009478673,
            "recall": 0.6218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.657520202825181,
            "auditor_fn_violation": 0.012598179549291637,
            "auditor_fp_violation": 0.03957979626485569,
            "ave_precision_score": 0.6367135782041023,
            "fpr": 0.21600877192982457,
            "logloss": 2.972724284893627,
            "mae": 0.3420232015080719,
            "precision": 0.6620926243567753,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6527738739129489,
            "auditor_fn_violation": 0.018347185196801008,
            "auditor_fp_violation": 0.031033221040412843,
            "ave_precision_score": 0.6310666431936534,
            "fpr": 0.2349066959385291,
            "logloss": 3.1557218963917264,
            "mae": 0.33732168559454523,
            "precision": 0.6559485530546624,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 30132,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.7108983178548054,
            "auditor_fn_violation": 0.002000293621081999,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7113282112778498,
            "fpr": 0.0,
            "logloss": 4.598306886890403,
            "mae": 0.49845558633318315,
            "precision": 1.0,
            "recall": 0.008368200836820083
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.7272472652797041,
            "auditor_fn_violation": 0.002642769511756404,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7276624706240835,
            "fpr": 0.0,
            "logloss": 4.309249578073612,
            "mae": 0.4968504184044833,
            "precision": 1.0,
            "recall": 0.012605042016806723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6702949865951188,
            "auditor_fn_violation": 0.013612089848051099,
            "auditor_fp_violation": 0.03916545395747433,
            "ave_precision_score": 0.6520695532558395,
            "fpr": 0.18640350877192982,
            "logloss": 2.504339054208166,
            "mae": 0.3335357526475871,
            "precision": 0.6840148698884758,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6574092611511386,
            "auditor_fn_violation": 0.018416367644752744,
            "auditor_fp_violation": 0.040039365608085103,
            "ave_precision_score": 0.6389440646582344,
            "fpr": 0.19978046103183314,
            "logloss": 2.7734523823547175,
            "mae": 0.32589319903902464,
            "precision": 0.680140597539543,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6475161528412456,
            "auditor_fn_violation": 0.0111208984805109,
            "auditor_fp_violation": 0.03947368421052632,
            "ave_precision_score": 0.6256079293277061,
            "fpr": 0.20394736842105263,
            "logloss": 3.313393170413376,
            "mae": 0.3428076307579094,
            "precision": 0.6690391459074733,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6443900732928343,
            "auditor_fn_violation": 0.02241511313636322,
            "auditor_fp_violation": 0.033321977869462636,
            "ave_precision_score": 0.6215567130947648,
            "fpr": 0.21953896816684962,
            "logloss": 3.3871109177214205,
            "mae": 0.3344600705206381,
            "precision": 0.6644295302013423,
            "recall": 0.8319327731092437
        }
    }
]