[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8250141146505389,
            "auditor_fn_violation": 0.014165296052631582,
            "auditor_fp_violation": 0.026843729694606883,
            "ave_precision_score": 0.8253184362417626,
            "fpr": 0.1787280701754386,
            "logloss": 1.041646603809103,
            "mae": 0.27356835461185125,
            "precision": 0.7109929078014184,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8532153746218106,
            "auditor_fn_violation": 0.01584478502318128,
            "auditor_fp_violation": 0.028921872762850197,
            "ave_precision_score": 0.8534126239688171,
            "fpr": 0.1668496158068057,
            "logloss": 0.9887153474118675,
            "mae": 0.2555690761960897,
            "precision": 0.7231329690346083,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.80902919198487,
            "auditor_fn_violation": 0.011821546052631584,
            "auditor_fp_violation": 0.02251868096166343,
            "ave_precision_score": 0.8092067532765028,
            "fpr": 0.16228070175438597,
            "logloss": 1.1476645765461073,
            "mae": 0.2747445678538481,
            "precision": 0.720226843100189,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8427885313330195,
            "auditor_fn_violation": 0.01604394484662378,
            "auditor_fp_violation": 0.021551994815464187,
            "ave_precision_score": 0.8429902955945151,
            "fpr": 0.14709110867178923,
            "logloss": 0.9917620224126433,
            "mae": 0.255027771144412,
            "precision": 0.7377690802348337,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8045911697894349,
            "auditor_fn_violation": 0.017256030701754386,
            "auditor_fp_violation": 0.01919621101364523,
            "ave_precision_score": 0.8047094714791575,
            "fpr": 0.12609649122807018,
            "logloss": 1.118773883712207,
            "mae": 0.2775400487493445,
            "precision": 0.760914760914761,
            "recall": 0.7625
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8375893537072583,
            "auditor_fn_violation": 0.022440217315788744,
            "auditor_fp_violation": 0.018374457118312412,
            "ave_precision_score": 0.8378330209732803,
            "fpr": 0.1251372118551043,
            "logloss": 0.9813515110279993,
            "mae": 0.26073708010009833,
            "precision": 0.7548387096774194,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7922781594042012,
            "auditor_fn_violation": 0.011300712719298256,
            "auditor_fp_violation": 0.01935103963612736,
            "ave_precision_score": 0.7526297004688179,
            "fpr": 0.14912280701754385,
            "logloss": 2.5942574147451873,
            "mae": 0.2765451659334008,
            "precision": 0.7369439071566731,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8075651833336854,
            "auditor_fn_violation": 0.019682085342300155,
            "auditor_fp_violation": 0.021042081651415325,
            "ave_precision_score": 0.7758054519709426,
            "fpr": 0.13611416026344675,
            "logloss": 2.2207493233564155,
            "mae": 0.2604993481788717,
            "precision": 0.751503006012024,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7918661203673254,
            "auditor_fn_violation": 0.012545687134502926,
            "auditor_fp_violation": 0.022193794671864848,
            "ave_precision_score": 0.7869975624493262,
            "fpr": 0.12609649122807018,
            "logloss": 1.1923300939046206,
            "mae": 0.28017124140409816,
            "precision": 0.7542735042735043,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8215585546621743,
            "auditor_fn_violation": 0.013931924393373079,
            "auditor_fp_violation": 0.014486055256501398,
            "ave_precision_score": 0.8190045523844786,
            "fpr": 0.10757409440175632,
            "logloss": 0.9749993790904621,
            "mae": 0.2603443180297142,
            "precision": 0.7841409691629956,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8338250206596384,
            "auditor_fn_violation": 0.007689144736842108,
            "auditor_fp_violation": 0.019371345029239772,
            "ave_precision_score": 0.8316499762213647,
            "fpr": 0.16666666666666666,
            "logloss": 1.203472218099439,
            "mae": 0.25541705925307656,
            "precision": 0.7275985663082437,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8656141980694834,
            "auditor_fn_violation": 0.011565164631068006,
            "auditor_fp_violation": 0.019346557583765175,
            "ave_precision_score": 0.8657961641082674,
            "fpr": 0.150384193194292,
            "logloss": 0.9434270367190385,
            "mae": 0.23596068671081533,
            "precision": 0.7434456928838952,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8300665489456132,
            "auditor_fn_violation": 0.015040204678362576,
            "auditor_fp_violation": 0.02297555230669266,
            "ave_precision_score": 0.8306158767250926,
            "fpr": 0.16228070175438597,
            "logloss": 1.0947021109000696,
            "mae": 0.2698602312039534,
            "precision": 0.7238805970149254,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8599981043932134,
            "auditor_fn_violation": 0.020860833599651706,
            "auditor_fp_violation": 0.02639742581768218,
            "ave_precision_score": 0.8601821920320434,
            "fpr": 0.14489571899012074,
            "logloss": 0.9722431023380943,
            "mae": 0.24629660638051207,
            "precision": 0.7431906614785992,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7972817568887207,
            "auditor_fn_violation": 0.010293311403508774,
            "auditor_fp_violation": 0.024275097465886943,
            "ave_precision_score": 0.797692553949976,
            "fpr": 0.18092105263157895,
            "logloss": 1.0464437528298596,
            "mae": 0.28405491503542596,
            "precision": 0.7043010752688172,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8349277656988008,
            "auditor_fn_violation": 0.019452819964151234,
            "auditor_fp_violation": 0.024387915811578294,
            "ave_precision_score": 0.835180298802828,
            "fpr": 0.16465422612513722,
            "logloss": 0.933691626278532,
            "mae": 0.2672887954663669,
            "precision": 0.7217068645640075,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7536431336098062,
            "auditor_fn_violation": 0.01703673245614035,
            "auditor_fp_violation": 0.004426575698505523,
            "ave_precision_score": 0.7549592963926881,
            "fpr": 0.027412280701754384,
            "logloss": 2.6790359321959496,
            "mae": 0.40537622595339246,
            "precision": 0.8466257668711656,
            "recall": 0.2875
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7862625464866805,
            "auditor_fn_violation": 0.0008614820269838656,
            "auditor_fp_violation": 0.0051518812781488395,
            "ave_precision_score": 0.7873781763882468,
            "fpr": 0.014270032930845226,
            "logloss": 2.4737524179817383,
            "mae": 0.4139314442832496,
            "precision": 0.8943089430894309,
            "recall": 0.2320675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.790511999801279,
            "auditor_fn_violation": 0.010587993421052632,
            "auditor_fp_violation": 0.02112014701104614,
            "ave_precision_score": 0.7518242832322557,
            "fpr": 0.15899122807017543,
            "logloss": 2.549780094446239,
            "mae": 0.27662240644055774,
            "precision": 0.7314814814814815,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.808115601412351,
            "auditor_fn_violation": 0.018836813998619778,
            "auditor_fp_violation": 0.021878540191456065,
            "ave_precision_score": 0.7771051801143284,
            "fpr": 0.14928649835345773,
            "logloss": 2.1702957397141045,
            "mae": 0.2605867424677678,
            "precision": 0.7404580152671756,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7944433159531494,
            "auditor_fn_violation": 0.002997076023391813,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.7430838237801006,
            "fpr": 0.34868421052631576,
            "logloss": 3.4618539984430305,
            "mae": 0.35619731691853657,
            "precision": 0.5974683544303797,
            "recall": 0.9833333333333333
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.8052073940565169,
            "auditor_fn_violation": 0.0053773152329475195,
            "auditor_fp_violation": 0.018060471179858685,
            "ave_precision_score": 0.7598000685400984,
            "fpr": 0.33479692645444564,
            "logloss": 3.1223413518938012,
            "mae": 0.3483629806561919,
            "precision": 0.6018276762402088,
            "recall": 0.9725738396624473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7951472440851727,
            "auditor_fn_violation": 0.009087171052631583,
            "auditor_fp_violation": 0.027579800194931774,
            "ave_precision_score": 0.7954575871417874,
            "fpr": 0.17324561403508773,
            "logloss": 1.1627949008348986,
            "mae": 0.2881582813747914,
            "precision": 0.7079482439926063,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8321897130195797,
            "auditor_fn_violation": 0.008364712584585036,
            "auditor_fp_violation": 0.02605832100415215,
            "ave_precision_score": 0.8324476263922204,
            "fpr": 0.1668496158068057,
            "logloss": 0.9887909897811471,
            "mae": 0.26996466001674263,
            "precision": 0.7164179104477612,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.795664518181546,
            "auditor_fn_violation": 0.016735197368421054,
            "auditor_fp_violation": 0.02928545321637427,
            "ave_precision_score": 0.795553789865793,
            "fpr": 0.16447368421052633,
            "logloss": 2.463493664474178,
            "mae": 0.2993990190154703,
            "precision": 0.7041420118343196,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7862639250458026,
            "auditor_fn_violation": 0.028692909447123074,
            "auditor_fp_violation": 0.036653462511334896,
            "ave_precision_score": 0.7857256640487666,
            "fpr": 0.145993413830955,
            "logloss": 2.766198273339983,
            "mae": 0.2879417373619445,
            "precision": 0.7234927234927235,
            "recall": 0.7341772151898734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7530019326112521,
            "auditor_fn_violation": 0.015021929824561405,
            "auditor_fp_violation": 0.023879142300194937,
            "ave_precision_score": 0.753561636393264,
            "fpr": 0.14912280701754385,
            "logloss": 1.284123400078304,
            "mae": 0.31769067971091974,
            "precision": 0.711864406779661,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7708294197354639,
            "auditor_fn_violation": 0.023588860018433876,
            "auditor_fp_violation": 0.025533336515057514,
            "ave_precision_score": 0.7717377416954933,
            "fpr": 0.14709110867178923,
            "logloss": 1.2459318520809326,
            "mae": 0.3092882884477657,
            "precision": 0.7154989384288747,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8269624806316589,
            "auditor_fn_violation": 0.009708516081871347,
            "auditor_fp_violation": 0.022401924951267062,
            "ave_precision_score": 0.8271770654874991,
            "fpr": 0.22039473684210525,
            "logloss": 1.2226112847608301,
            "mae": 0.28466462274185783,
            "precision": 0.6789137380191693,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8539959729497915,
            "auditor_fn_violation": 0.014459929506685749,
            "auditor_fp_violation": 0.032873071812351974,
            "ave_precision_score": 0.854184433243424,
            "fpr": 0.21075740944017562,
            "logloss": 1.1618676640070738,
            "mae": 0.26982641382931105,
            "precision": 0.6883116883116883,
            "recall": 0.8945147679324894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8012206218417959,
            "auditor_fn_violation": 0.015570175438596498,
            "auditor_fp_violation": 0.016949926900584795,
            "ave_precision_score": 0.8016832944949357,
            "fpr": 0.125,
            "logloss": 1.1210423961564955,
            "mae": 0.2877043582638192,
            "precision": 0.75,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.831911289028388,
            "auditor_fn_violation": 0.01124095096499883,
            "auditor_fp_violation": 0.0160760800488311,
            "ave_precision_score": 0.832133829185654,
            "fpr": 0.1141602634467618,
            "logloss": 0.9826946928146711,
            "mae": 0.26675372389986063,
            "precision": 0.7699115044247787,
            "recall": 0.7341772151898734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8085622128793122,
            "auditor_fn_violation": 0.01137609649122807,
            "auditor_fp_violation": 0.014084328297595844,
            "ave_precision_score": 0.8090240808345663,
            "fpr": 0.11951754385964912,
            "logloss": 0.9950419204663585,
            "mae": 0.28496703731750533,
            "precision": 0.7572383073496659,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8361125549508128,
            "auditor_fn_violation": 0.019851139611036236,
            "auditor_fp_violation": 0.015844986398129146,
            "ave_precision_score": 0.8363579818976357,
            "fpr": 0.10428100987925357,
            "logloss": 0.8907800953194213,
            "mae": 0.26485297771096133,
            "precision": 0.7835990888382688,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8073824330379176,
            "auditor_fn_violation": 0.0006030701754385966,
            "auditor_fp_violation": 0.00232496751137103,
            "ave_precision_score": 0.6830608690083784,
            "fpr": 0.44298245614035087,
            "logloss": 9.449567357015392,
            "mae": 0.4489588654423386,
            "precision": 0.5398633257403189,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.8172629118933714,
            "auditor_fn_violation": 0.00021305469484546582,
            "auditor_fp_violation": 0.0072292122469587525,
            "ave_precision_score": 0.6973509701896257,
            "fpr": 0.4522502744237102,
            "logloss": 9.097379451219757,
            "mae": 0.45441872087226126,
            "precision": 0.5323496027241771,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7649237837279761,
            "auditor_fn_violation": 0.0005802266081871344,
            "auditor_fp_violation": 0.0032666301169590804,
            "ave_precision_score": 0.5375743024923495,
            "fpr": 0.45723684210526316,
            "logloss": 15.437355437515427,
            "mae": 0.45824469734584217,
            "precision": 0.5345982142857143,
            "recall": 0.9979166666666667
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7609468655361356,
            "auditor_fn_violation": 0.0017507537967736111,
            "auditor_fp_violation": 0.005046382002828399,
            "ave_precision_score": 0.5288689307355118,
            "fpr": 0.4610318331503842,
            "logloss": 15.808596189874912,
            "mae": 0.46628014891995223,
            "precision": 0.5286195286195287,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8072954664491498,
            "auditor_fn_violation": 0.011225328947368421,
            "auditor_fp_violation": 0.028224496426250814,
            "ave_precision_score": 0.8073973273357857,
            "fpr": 0.22807017543859648,
            "logloss": 1.2808407832219917,
            "mae": 0.2956334717516586,
            "precision": 0.6693163751987281,
            "recall": 0.8770833333333333
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8359826695565767,
            "auditor_fn_violation": 0.0138022389269454,
            "auditor_fp_violation": 0.026050785341629266,
            "ave_precision_score": 0.8362314060738031,
            "fpr": 0.2217343578485181,
            "logloss": 1.1573064405729423,
            "mae": 0.2774210023687845,
            "precision": 0.6788553259141494,
            "recall": 0.9008438818565401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 10197,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7921308569640805,
            "auditor_fn_violation": 0.002713815789473685,
            "auditor_fp_violation": 0.01779006254061081,
            "ave_precision_score": 0.7407773821573191,
            "fpr": 0.3432017543859649,
            "logloss": 3.392131201059741,
            "mae": 0.35231702941905896,
            "precision": 0.5992317541613317,
            "recall": 0.975
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.80662542568225,
            "auditor_fn_violation": 0.004233304154103388,
            "auditor_fp_violation": 0.01748524894061145,
            "ave_precision_score": 0.7618720745929763,
            "fpr": 0.3424807903402854,
            "logloss": 3.0283035506109304,
            "mae": 0.34701811135573385,
            "precision": 0.5963777490297542,
            "recall": 0.9725738396624473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7624390511195708,
            "auditor_fn_violation": 0.0015739217836257308,
            "auditor_fp_violation": 0.0035839018843404915,
            "ave_precision_score": 0.5374102000863632,
            "fpr": 0.44627192982456143,
            "logloss": 15.274376344170298,
            "mae": 0.45310540600531,
            "precision": 0.5375,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.75867930895746,
            "auditor_fn_violation": 0.00021305469484546582,
            "auditor_fp_violation": 0.0073949968224623274,
            "ave_precision_score": 0.5311996321946987,
            "fpr": 0.4544456641053787,
            "logloss": 15.435398854187126,
            "mae": 0.4589032618675492,
            "precision": 0.5311438278595696,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.805148325476382,
            "auditor_fn_violation": 0.016036184210526324,
            "auditor_fp_violation": 0.016861090805718,
            "ave_precision_score": 0.8056423212238579,
            "fpr": 0.12609649122807018,
            "logloss": 1.0936970284386764,
            "mae": 0.27831605933295905,
            "precision": 0.7568710359408034,
            "recall": 0.7458333333333333
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8347625090748625,
            "auditor_fn_violation": 0.02662257360808126,
            "auditor_fp_violation": 0.02259694001863821,
            "ave_precision_score": 0.8350199475357858,
            "fpr": 0.12843029637760703,
            "logloss": 0.9663884682247593,
            "mae": 0.2618311413606787,
            "precision": 0.7515923566878981,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 10197,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8367228607814393,
            "auditor_fn_violation": 0.016447368421052634,
            "auditor_fp_violation": 0.03133122157244964,
            "ave_precision_score": 0.8380210251105694,
            "fpr": 0.17982456140350878,
            "logloss": 0.7596777850639768,
            "mae": 0.28916597634600816,
            "precision": 0.7172413793103448,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8524747473580745,
            "auditor_fn_violation": 0.03385485417332462,
            "auditor_fp_violation": 0.03126797569497648,
            "ave_precision_score": 0.8527482054914933,
            "fpr": 0.13721185510428102,
            "logloss": 0.7772930037551468,
            "mae": 0.2889309186154591,
            "precision": 0.7529644268774703,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7950334883067306,
            "auditor_fn_violation": 0.016068165204678363,
            "auditor_fp_violation": 0.017645386614684858,
            "ave_precision_score": 0.7955166370598422,
            "fpr": 0.12938596491228072,
            "logloss": 1.0698851693298557,
            "mae": 0.2911802652007802,
            "precision": 0.7456896551724138,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8242859564277641,
            "auditor_fn_violation": 0.01142158429323737,
            "auditor_fp_violation": 0.015870105273205447,
            "ave_precision_score": 0.8245565457531259,
            "fpr": 0.12403951701427003,
            "logloss": 0.9809573787944069,
            "mae": 0.2753198989840983,
            "precision": 0.7564655172413793,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 10197,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8489368260740306,
            "auditor_fn_violation": 0.01906067251461989,
            "auditor_fp_violation": 0.02192982456140351,
            "ave_precision_score": 0.8495867066922237,
            "fpr": 0.11842105263157894,
            "logloss": 0.7137750877480115,
            "mae": 0.2720051010598378,
            "precision": 0.777319587628866,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8651993186916741,
            "auditor_fn_violation": 0.030665981186344126,
            "auditor_fp_violation": 0.020728095712961598,
            "ave_precision_score": 0.8653373343631428,
            "fpr": 0.10537870472008781,
            "logloss": 0.7418537916069019,
            "mae": 0.2615007984513236,
            "precision": 0.7922077922077922,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7830619696997512,
            "auditor_fn_violation": 0.008347039473684209,
            "auditor_fp_violation": 0.021604938271604947,
            "ave_precision_score": 0.731717063476548,
            "fpr": 0.17543859649122806,
            "logloss": 3.179073080699716,
            "mae": 0.29603487198278344,
            "precision": 0.700374531835206,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7878095736248066,
            "auditor_fn_violation": 0.016590476455140415,
            "auditor_fp_violation": 0.023337946833389012,
            "ave_precision_score": 0.7385688984845494,
            "fpr": 0.1668496158068057,
            "logloss": 3.0242757095159014,
            "mae": 0.28338876475451363,
            "precision": 0.7137476459510358,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 10197,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7803604759650065,
            "auditor_fn_violation": 0.014985380116959069,
            "auditor_fp_violation": 0.02002111760883691,
            "ave_precision_score": 0.7808092380917528,
            "fpr": 0.10087719298245613,
            "logloss": 2.296801460005817,
            "mae": 0.32920245291525896,
            "precision": 0.7610389610389611,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7760210251135085,
            "auditor_fn_violation": 0.021296206236944615,
            "auditor_fp_violation": 0.025666466552961894,
            "ave_precision_score": 0.7765855717504707,
            "fpr": 0.1119648737650933,
            "logloss": 2.6552083377912576,
            "mae": 0.3234122119523085,
            "precision": 0.7371134020618557,
            "recall": 0.6033755274261603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7337603470082028,
            "auditor_fn_violation": 0.014510233918128659,
            "auditor_fp_violation": 0.02421925763482782,
            "ave_precision_score": 0.7345796939051404,
            "fpr": 0.12938596491228072,
            "logloss": 1.1696997911811473,
            "mae": 0.3351394455447755,
            "precision": 0.7121951219512195,
            "recall": 0.6083333333333333
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7582186859862482,
            "auditor_fn_violation": 0.02692362915514551,
            "auditor_fp_violation": 0.02462654512480313,
            "ave_precision_score": 0.7591655614860826,
            "fpr": 0.12733260153677278,
            "logloss": 1.108885552496759,
            "mae": 0.32390976074754346,
            "precision": 0.7276995305164319,
            "recall": 0.6540084388185654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8067001616927798,
            "auditor_fn_violation": 0.010635964912280705,
            "auditor_fp_violation": 0.024206566764132555,
            "ave_precision_score": 0.8066289403614604,
            "fpr": 0.26206140350877194,
            "logloss": 1.6514340487345647,
            "mae": 0.31054464509047786,
            "precision": 0.6469719350073855,
            "recall": 0.9125
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8355351601350064,
            "auditor_fn_violation": 0.010689787732681201,
            "auditor_fp_violation": 0.03436010921686884,
            "ave_precision_score": 0.8357532519820381,
            "fpr": 0.25466520307354557,
            "logloss": 1.5786222635720755,
            "mae": 0.2980795188031188,
            "precision": 0.6516516516516516,
            "recall": 0.9156118143459916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 10197,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8102620131222261,
            "auditor_fn_violation": 0.013925438596491228,
            "auditor_fp_violation": 0.02764071637426901,
            "ave_precision_score": 0.8107942794800553,
            "fpr": 0.13815789473684212,
            "logloss": 1.0478887715954623,
            "mae": 0.2755931459245893,
            "precision": 0.7469879518072289,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8419243927727795,
            "auditor_fn_violation": 0.023426753185399267,
            "auditor_fp_violation": 0.02521935057660378,
            "ave_precision_score": 0.842159217446344,
            "fpr": 0.1350164654226125,
            "logloss": 0.927584632191965,
            "mae": 0.2581018992630308,
            "precision": 0.75,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.823998661817678,
            "auditor_fn_violation": 0.014802631578947368,
            "auditor_fp_violation": 0.02672697368421053,
            "ave_precision_score": 0.824353639826402,
            "fpr": 0.17763157894736842,
            "logloss": 1.057294116686683,
            "mae": 0.2738810423278423,
            "precision": 0.7117437722419929,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8522002420490912,
            "auditor_fn_violation": 0.016340368769887034,
            "auditor_fp_violation": 0.028826421037560255,
            "ave_precision_score": 0.8524028610235708,
            "fpr": 0.16355653128430298,
            "logloss": 1.0022355477031746,
            "mae": 0.2556129953751443,
            "precision": 0.726605504587156,
            "recall": 0.8354430379746836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7948756062875362,
            "auditor_fn_violation": 0.01783625730994152,
            "auditor_fp_violation": 0.021706465237166996,
            "ave_precision_score": 0.7541011076222827,
            "fpr": 0.1524122807017544,
            "logloss": 2.6380510477354115,
            "mae": 0.27646778706196273,
            "precision": 0.7362428842504743,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8088963694060969,
            "auditor_fn_violation": 0.025601300559963316,
            "auditor_fp_violation": 0.02103203410138482,
            "ave_precision_score": 0.7767477599810557,
            "fpr": 0.1437980241492865,
            "logloss": 2.2706349465786215,
            "mae": 0.26060272961850206,
            "precision": 0.7431372549019608,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8237766118696324,
            "auditor_fn_violation": 0.01386604532163743,
            "auditor_fp_violation": 0.024122807017543862,
            "ave_precision_score": 0.8241095150887768,
            "fpr": 0.21271929824561403,
            "logloss": 1.1815269301509155,
            "mae": 0.28335868029676026,
            "precision": 0.6814449917898193,
            "recall": 0.8645833333333334
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8514707067944677,
            "auditor_fn_violation": 0.01730837814429361,
            "auditor_fp_violation": 0.030185352179188014,
            "ave_precision_score": 0.8516829898162216,
            "fpr": 0.19758507135016465,
            "logloss": 1.109166932521922,
            "mae": 0.2656915171144912,
            "precision": 0.7004991680532446,
            "recall": 0.8881856540084389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8203422609163323,
            "auditor_fn_violation": 0.01632401315789474,
            "auditor_fp_violation": 0.016772254710851208,
            "ave_precision_score": 0.8209260241440643,
            "fpr": 0.12280701754385964,
            "logloss": 0.9040948426235899,
            "mae": 0.2804913616853234,
            "precision": 0.7554585152838428,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8543396487421244,
            "auditor_fn_violation": 0.02470276554257157,
            "auditor_fp_violation": 0.015513417247122003,
            "ave_precision_score": 0.8545209871054887,
            "fpr": 0.11306256860592755,
            "logloss": 0.8054951070849282,
            "mae": 0.26517039501336254,
            "precision": 0.7711111111111111,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7957569168048261,
            "auditor_fn_violation": 0.005487024853801169,
            "auditor_fp_violation": 0.020467836257309947,
            "ave_precision_score": 0.7548605318464288,
            "fpr": 0.15789473684210525,
            "logloss": 2.643898711924176,
            "mae": 0.27737309545278926,
            "precision": 0.7343173431734318,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8103353245363725,
            "auditor_fn_violation": 0.018063332823854722,
            "auditor_fp_violation": 0.01903005975780381,
            "ave_precision_score": 0.7780919472449431,
            "fpr": 0.15587266739846323,
            "logloss": 2.2537630826148707,
            "mae": 0.2627522551073327,
            "precision": 0.7310606060606061,
            "recall": 0.8143459915611815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.37819136088369837,
            "auditor_fn_violation": 0.0011604532163742862,
            "auditor_fp_violation": 0.002528021442495127,
            "ave_precision_score": 0.5256201856923607,
            "fpr": 0.0043859649122807015,
            "logloss": 17.92018288406326,
            "mae": 0.5265291965265746,
            "precision": 0.5,
            "recall": 0.008333333333333333
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.387947178614967,
            "auditor_fn_violation": 0.0012412751786648986,
            "auditor_fp_violation": 0.0005174488265717508,
            "ave_precision_score": 0.5215758557595338,
            "fpr": 0.0010976948408342481,
            "logloss": 17.741679019273285,
            "mae": 0.518963119145368,
            "precision": 0.6666666666666666,
            "recall": 0.004219409282700422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7874151394982554,
            "auditor_fn_violation": 0.007360197368421056,
            "auditor_fp_violation": 0.024643132716049388,
            "ave_precision_score": 0.7584828490394865,
            "fpr": 0.1524122807017544,
            "logloss": 2.2038582096755057,
            "mae": 0.277987232781028,
            "precision": 0.7311411992263056,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.805625305108523,
            "auditor_fn_violation": 0.013612342351104877,
            "auditor_fp_violation": 0.018751240244456898,
            "ave_precision_score": 0.7821090426078348,
            "fpr": 0.13721185510428102,
            "logloss": 1.8792660776274421,
            "mae": 0.2602170329903451,
            "precision": 0.748995983935743,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8169780062994413,
            "auditor_fn_violation": 0.01729029605263158,
            "auditor_fp_violation": 0.016810327322936976,
            "ave_precision_score": 0.8172936208352506,
            "fpr": 0.11951754385964912,
            "logloss": 0.9605783260657278,
            "mae": 0.27689975623589286,
            "precision": 0.7630434782608696,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8458055320672223,
            "auditor_fn_violation": 0.021222100256128796,
            "auditor_fp_violation": 0.014611649631882887,
            "ave_precision_score": 0.8460275926560861,
            "fpr": 0.10318331503841932,
            "logloss": 0.9102452103495556,
            "mae": 0.2627267538843086,
            "precision": 0.7906458797327395,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.789974174191109,
            "auditor_fn_violation": 0.010268183479532168,
            "auditor_fp_violation": 0.024140574236517224,
            "ave_precision_score": 0.75979229438045,
            "fpr": 0.14364035087719298,
            "logloss": 2.2692224124904876,
            "mae": 0.2797749674538533,
            "precision": 0.7390438247011952,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8076986717206244,
            "auditor_fn_violation": 0.011136739429476577,
            "auditor_fp_violation": 0.019193332445799755,
            "ave_precision_score": 0.7821876948148352,
            "fpr": 0.13391877058177826,
            "logloss": 1.9593672947828886,
            "mae": 0.2619221543439857,
            "precision": 0.7515274949083504,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7952438123654639,
            "auditor_fn_violation": 0.020317068713450296,
            "auditor_fp_violation": 0.013632533300844707,
            "ave_precision_score": 0.7958203790504703,
            "fpr": 0.07785087719298246,
            "logloss": 1.3016113133275558,
            "mae": 0.31656176155720017,
            "precision": 0.7867867867867868,
            "recall": 0.5458333333333333
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8313786949967296,
            "auditor_fn_violation": 0.025724038590689516,
            "auditor_fp_violation": 0.008326907087792981,
            "ave_precision_score": 0.8316397046201058,
            "fpr": 0.0570801317233809,
            "logloss": 1.1975609103265794,
            "mae": 0.3022976228447513,
            "precision": 0.834920634920635,
            "recall": 0.5548523206751055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8029943235851433,
            "auditor_fn_violation": 0.012728435672514622,
            "auditor_fp_violation": 0.017498172514619888,
            "ave_precision_score": 0.8034604810116018,
            "fpr": 0.125,
            "logloss": 1.0844723992149718,
            "mae": 0.28769783466827753,
            "precision": 0.7472283813747228,
            "recall": 0.7020833333333333
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8340995838193493,
            "auditor_fn_violation": 0.018920183227037566,
            "auditor_fp_violation": 0.017218988864802682,
            "ave_precision_score": 0.8343453157416423,
            "fpr": 0.11086717892425905,
            "logloss": 0.949956349037927,
            "mae": 0.2664001381945714,
            "precision": 0.7745535714285714,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7845675376304235,
            "auditor_fn_violation": 0.010599415204678365,
            "auditor_fp_violation": 0.018241857537361923,
            "ave_precision_score": 0.7847063862986389,
            "fpr": 0.12390350877192982,
            "logloss": 1.1444471194205348,
            "mae": 0.3063231223286321,
            "precision": 0.7390300230946882,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8106335985439693,
            "auditor_fn_violation": 0.020877044282955167,
            "auditor_fp_violation": 0.020507049612290173,
            "ave_precision_score": 0.810952634998581,
            "fpr": 0.12403951701427003,
            "logloss": 1.033042293270212,
            "mae": 0.2882477583124484,
            "precision": 0.744343891402715,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.815055542708196,
            "auditor_fn_violation": 0.01312134502923977,
            "auditor_fp_violation": 0.022881639863547756,
            "ave_precision_score": 0.8149218650397506,
            "fpr": 0.20065789473684212,
            "logloss": 1.2380700885085782,
            "mae": 0.2821894514530969,
            "precision": 0.692436974789916,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8501012223447477,
            "auditor_fn_violation": 0.011852325306729288,
            "auditor_fp_violation": 0.029358941189177777,
            "ave_precision_score": 0.8501980086875002,
            "fpr": 0.19099890230515917,
            "logloss": 1.0699852312137421,
            "mae": 0.2656778441095894,
            "precision": 0.7040816326530612,
            "recall": 0.8734177215189873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8081244907778815,
            "auditor_fn_violation": 0.014683845029239763,
            "auditor_fp_violation": 0.019549017218973362,
            "ave_precision_score": 0.8086448911416135,
            "fpr": 0.14364035087719298,
            "logloss": 1.0744904153078652,
            "mae": 0.2778976147058514,
            "precision": 0.7405940594059406,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8396436301103054,
            "auditor_fn_violation": 0.024464236916820675,
            "auditor_fp_violation": 0.023368089483480573,
            "ave_precision_score": 0.839874860238384,
            "fpr": 0.14050493962678376,
            "logloss": 0.9471626702205681,
            "mae": 0.26090031607831987,
            "precision": 0.7419354838709677,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8070550645745723,
            "auditor_fn_violation": 0.015709521198830415,
            "auditor_fp_violation": 0.022952708739441205,
            "ave_precision_score": 0.8074310823073475,
            "fpr": 0.14364035087719298,
            "logloss": 1.0965640495715043,
            "mae": 0.27907845672400866,
            "precision": 0.7369477911646586,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8385848275691059,
            "auditor_fn_violation": 0.018975762712649433,
            "auditor_fp_violation": 0.02103705787640007,
            "ave_precision_score": 0.8388190965624551,
            "fpr": 0.12952799121844127,
            "logloss": 0.9582441681876093,
            "mae": 0.2621621142687921,
            "precision": 0.7541666666666667,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7946142268000038,
            "auditor_fn_violation": 0.01624177631578948,
            "auditor_fp_violation": 0.018366228070175437,
            "ave_precision_score": 0.7952409319077033,
            "fpr": 0.11842105263157894,
            "logloss": 1.0529580774324028,
            "mae": 0.29393343747130446,
            "precision": 0.7539863325740319,
            "recall": 0.6895833333333333
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8284747622969931,
            "auditor_fn_violation": 0.018758076394002975,
            "auditor_fp_violation": 0.018618110206552508,
            "ave_precision_score": 0.8287399616388371,
            "fpr": 0.11306256860592755,
            "logloss": 0.9540514992814918,
            "mae": 0.2737686552954107,
            "precision": 0.765375854214123,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8054127080427778,
            "auditor_fn_violation": 0.014866593567251467,
            "auditor_fp_violation": 0.015899122807017545,
            "ave_precision_score": 0.8047662429325754,
            "fpr": 0.11842105263157894,
            "logloss": 1.2477772879077005,
            "mae": 0.2726141648007104,
            "precision": 0.7672413793103449,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8404017713330856,
            "auditor_fn_violation": 0.01626626278907122,
            "auditor_fp_violation": 0.01939428344641014,
            "ave_precision_score": 0.8406421485034844,
            "fpr": 0.10867178924259056,
            "logloss": 1.0627034414363807,
            "mae": 0.2537406705200364,
            "precision": 0.7819383259911894,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7994889754615404,
            "auditor_fn_violation": 0.0075292397660818725,
            "auditor_fp_violation": 0.027374208089668627,
            "ave_precision_score": 0.7977152678602867,
            "fpr": 0.29714912280701755,
            "logloss": 1.8979194636690653,
            "mae": 0.33186157348344675,
            "precision": 0.6230876216968011,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8279393488536337,
            "auditor_fn_violation": 0.011268740707804748,
            "auditor_fp_violation": 0.024571283599635275,
            "ave_precision_score": 0.8279844414166285,
            "fpr": 0.2843029637760702,
            "logloss": 1.7207246495277873,
            "mae": 0.3150992270215932,
            "precision": 0.6331444759206799,
            "recall": 0.9430379746835443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8272432779329371,
            "auditor_fn_violation": 0.009708516081871347,
            "auditor_fp_violation": 0.023069464749837565,
            "ave_precision_score": 0.8274596992417098,
            "fpr": 0.21820175438596492,
            "logloss": 1.220392114397331,
            "mae": 0.2841468196325981,
            "precision": 0.6810897435897436,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8543034864171137,
            "auditor_fn_violation": 0.014459929506685749,
            "auditor_fp_violation": 0.032873071812351974,
            "ave_precision_score": 0.8544817767568733,
            "fpr": 0.21075740944017562,
            "logloss": 1.1637601368417407,
            "mae": 0.2694713124539442,
            "precision": 0.6883116883116883,
            "recall": 0.8945147679324894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 10197,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8256496212833646,
            "auditor_fn_violation": 0.013863760964912281,
            "auditor_fp_violation": 0.021011005523066933,
            "ave_precision_score": 0.8269603693555247,
            "fpr": 0.11074561403508772,
            "logloss": 0.8603633392310388,
            "mae": 0.2776382044955046,
            "precision": 0.7745535714285714,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8530953398064525,
            "auditor_fn_violation": 0.022810747219867818,
            "auditor_fp_violation": 0.024561236049604755,
            "ave_precision_score": 0.8532887599212797,
            "fpr": 0.11086717892425905,
            "logloss": 0.7816937849311616,
            "mae": 0.2642605169812548,
            "precision": 0.7730337078651686,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7945744362739373,
            "auditor_fn_violation": 0.015535910087719297,
            "auditor_fp_violation": 0.02357456140350877,
            "ave_precision_score": 0.7951201069955421,
            "fpr": 0.18969298245614036,
            "logloss": 1.066599146512164,
            "mae": 0.2876883578335168,
            "precision": 0.6964912280701754,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8327078474362107,
            "auditor_fn_violation": 0.016886900378403666,
            "auditor_fp_violation": 0.02876362384986951,
            "ave_precision_score": 0.8329653752883227,
            "fpr": 0.1734357848518112,
            "logloss": 0.9577432771912054,
            "mae": 0.268347880520103,
            "precision": 0.7153153153153153,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7954350164652739,
            "auditor_fn_violation": 0.011017452485380129,
            "auditor_fp_violation": 0.01827485380116959,
            "ave_precision_score": 0.7958737710699971,
            "fpr": 0.13157894736842105,
            "logloss": 0.9584169837409646,
            "mae": 0.293094836787134,
            "precision": 0.744136460554371,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8277402065705888,
            "auditor_fn_violation": 0.017049007211438264,
            "auditor_fp_violation": 0.018829108757193423,
            "ave_precision_score": 0.8280057429256369,
            "fpr": 0.12843029637760703,
            "logloss": 0.859237227660927,
            "mae": 0.27286248955621056,
            "precision": 0.7505330490405118,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7886341924444723,
            "auditor_fn_violation": 0.011483461257309943,
            "auditor_fp_violation": 0.024579678362573097,
            "ave_precision_score": 0.7883444998684861,
            "fpr": 0.19078947368421054,
            "logloss": 1.1532236456866651,
            "mae": 0.2928282029785023,
            "precision": 0.6920353982300885,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8182514398521088,
            "auditor_fn_violation": 0.020342091733941005,
            "auditor_fp_violation": 0.029464440464498243,
            "ave_precision_score": 0.8185771165734751,
            "fpr": 0.1734357848518112,
            "logloss": 1.0594825170732443,
            "mae": 0.279668685449963,
            "precision": 0.710091743119266,
            "recall": 0.8164556962025317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8255131044251545,
            "auditor_fn_violation": 0.013068804824561403,
            "auditor_fp_violation": 0.027412280701754388,
            "ave_precision_score": 0.8258423832012878,
            "fpr": 0.25,
            "logloss": 1.4209744317574244,
            "mae": 0.3000144936870837,
            "precision": 0.6571428571428571,
            "recall": 0.9104166666666667
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8521618078235149,
            "auditor_fn_violation": 0.01664142431695128,
            "auditor_fp_violation": 0.033918017015525985,
            "ave_precision_score": 0.8523643287277989,
            "fpr": 0.2349066959385291,
            "logloss": 1.3362238769131052,
            "mae": 0.2840578164950266,
            "precision": 0.6697530864197531,
            "recall": 0.9156118143459916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8039425823699012,
            "auditor_fn_violation": 0.01583059210526316,
            "auditor_fp_violation": 0.013685834957764783,
            "ave_precision_score": 0.8045035137775707,
            "fpr": 0.07017543859649122,
            "logloss": 1.3368333904654681,
            "mae": 0.315823318866681,
            "precision": 0.799373040752351,
            "recall": 0.53125
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8354799499465295,
            "auditor_fn_violation": 0.01998082507746392,
            "auditor_fp_violation": 0.009607969716684208,
            "ave_precision_score": 0.8357311511157702,
            "fpr": 0.0570801317233809,
            "logloss": 1.2410354993379575,
            "mae": 0.3058802716871589,
            "precision": 0.8272425249169435,
            "recall": 0.5253164556962026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8233329056471497,
            "auditor_fn_violation": 0.011074561403508775,
            "auditor_fp_violation": 0.023346125730994156,
            "ave_precision_score": 0.823700116887293,
            "fpr": 0.22039473684210525,
            "logloss": 1.2404870586124201,
            "mae": 0.2861745905911776,
            "precision": 0.6778846153846154,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8528448929766158,
            "auditor_fn_violation": 0.015872574765987208,
            "auditor_fp_violation": 0.030115019328974382,
            "ave_precision_score": 0.8530550593750476,
            "fpr": 0.2052689352360044,
            "logloss": 1.1300819791448855,
            "mae": 0.2675311333226779,
            "precision": 0.6929392446633826,
            "recall": 0.890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7762705240736968,
            "auditor_fn_violation": 0.007700566520467837,
            "auditor_fp_violation": 0.020247015107212482,
            "ave_precision_score": 0.7206621557644544,
            "fpr": 0.15899122807017543,
            "logloss": 4.160547182894025,
            "mae": 0.2874269142490273,
            "precision": 0.7232824427480916,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7818032988932523,
            "auditor_fn_violation": 0.00647037844998078,
            "auditor_fp_violation": 0.023272637758190644,
            "ave_precision_score": 0.7286098893041745,
            "fpr": 0.16245883644346873,
            "logloss": 3.903480525050641,
            "mae": 0.2783525266639189,
            "precision": 0.7159309021113244,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7702172171440171,
            "auditor_fn_violation": 0.00390625,
            "auditor_fp_violation": 0.0022640513320337907,
            "ave_precision_score": 0.5688295590813232,
            "fpr": 0.4166666666666667,
            "logloss": 13.605074114964124,
            "mae": 0.434064828387332,
            "precision": 0.5502958579881657,
            "recall": 0.96875
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7683152573869767,
            "auditor_fn_violation": 0.0048817314862417615,
            "auditor_fp_violation": 0.01562645218496535,
            "ave_precision_score": 0.5669646671214401,
            "fpr": 0.4083424807903403,
            "logloss": 13.325120776180828,
            "mae": 0.42336863031785854,
            "precision": 0.5528846153846154,
            "recall": 0.9704641350210971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.3785385831059206,
            "auditor_fn_violation": 0.0011604532163742862,
            "auditor_fp_violation": 0.001857943469785575,
            "ave_precision_score": 0.5259674079145829,
            "fpr": 0.003289473684210526,
            "logloss": 17.920996852246837,
            "mae": 0.5254619399034564,
            "precision": 0.5714285714285714,
            "recall": 0.008333333333333333
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.38817181040605453,
            "auditor_fn_violation": 0.0012412751786648986,
            "auditor_fp_violation": 0.0005174488265717508,
            "ave_precision_score": 0.5218044070956802,
            "fpr": 0.0010976948408342481,
            "logloss": 17.749717061618938,
            "mae": 0.5193081425279643,
            "precision": 0.6666666666666666,
            "recall": 0.004219409282700422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7948436783341682,
            "auditor_fn_violation": 0.006421326754385965,
            "auditor_fp_violation": 0.018386533463287853,
            "ave_precision_score": 0.744085652443041,
            "fpr": 0.3530701754385965,
            "logloss": 3.377435228555495,
            "mae": 0.35620905058289953,
            "precision": 0.5918884664131813,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8023080609703103,
            "auditor_fn_violation": 0.008605557022236426,
            "auditor_fp_violation": 0.0282059848231757,
            "ave_precision_score": 0.7556264071142178,
            "fpr": 0.3336992316136114,
            "logloss": 3.0918305938528867,
            "mae": 0.3458549697840594,
            "precision": 0.5989445910290238,
            "recall": 0.9578059071729957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8031802154605656,
            "auditor_fn_violation": 0.022263340643274863,
            "auditor_fp_violation": 0.013249269005847957,
            "ave_precision_score": 0.8037427452441555,
            "fpr": 0.06907894736842106,
            "logloss": 1.361146812696109,
            "mae": 0.31745239243284046,
            "precision": 0.8012618296529969,
            "recall": 0.5291666666666667
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8355909043944901,
            "auditor_fn_violation": 0.020962729323273456,
            "auditor_fp_violation": 0.010288691231251902,
            "ave_precision_score": 0.8358408405858524,
            "fpr": 0.05598243688254665,
            "logloss": 1.2692836675306631,
            "mae": 0.307813819669751,
            "precision": 0.8271186440677966,
            "recall": 0.5147679324894515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.823682653086692,
            "auditor_fn_violation": 0.017605537280701758,
            "auditor_fp_violation": 0.02602643762183236,
            "ave_precision_score": 0.8240349501808588,
            "fpr": 0.17653508771929824,
            "logloss": 1.037519518454458,
            "mae": 0.27293760101142783,
            "precision": 0.7125,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8518999584925284,
            "auditor_fn_violation": 0.02005724687018022,
            "auditor_fp_violation": 0.03053199265524094,
            "ave_precision_score": 0.852106596695877,
            "fpr": 0.1602634467618002,
            "logloss": 0.9808816170433166,
            "mae": 0.25550686639757336,
            "precision": 0.7311233885819521,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7942355643366605,
            "auditor_fn_violation": 0.008826754385964912,
            "auditor_fp_violation": 0.017470252599090318,
            "ave_precision_score": 0.7434743398643908,
            "fpr": 0.3300438596491228,
            "logloss": 3.3615280306438002,
            "mae": 0.3478521072732276,
            "precision": 0.606020942408377,
            "recall": 0.9645833333333333
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.8050538591989148,
            "auditor_fn_violation": 0.009869990319906256,
            "auditor_fp_violation": 0.03132574910765196,
            "ave_precision_score": 0.7596586352054969,
            "fpr": 0.3194291986827662,
            "logloss": 3.0315180942011293,
            "mae": 0.338450000259737,
            "precision": 0.6083445491251682,
            "recall": 0.9535864978902954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.8098723638818307,
            "auditor_fn_violation": 0.005468750000000001,
            "auditor_fp_violation": 0.02904686484730345,
            "ave_precision_score": 0.8085569738296873,
            "fpr": 0.28728070175438597,
            "logloss": 2.0564866194742977,
            "mae": 0.33076776157302934,
            "precision": 0.6273115220483642,
            "recall": 0.91875
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8296039315957515,
            "auditor_fn_violation": 0.00984451638900082,
            "auditor_fp_violation": 0.017555581790825094,
            "ave_precision_score": 0.8295000896653761,
            "fpr": 0.283205268935236,
            "logloss": 1.951446135279533,
            "mae": 0.32269238207571505,
            "precision": 0.6277056277056277,
            "recall": 0.9177215189873418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8082565171785603,
            "auditor_fn_violation": 0.018996710526315793,
            "auditor_fp_violation": 0.013965034113060437,
            "ave_precision_score": 0.8089565504393886,
            "fpr": 0.12171052631578948,
            "logloss": 1.065997630764921,
            "mae": 0.28204609889055077,
            "precision": 0.7597402597402597,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8386193157205972,
            "auditor_fn_violation": 0.01740795805601486,
            "auditor_fp_violation": 0.02299633013235135,
            "ave_precision_score": 0.8388577983924403,
            "fpr": 0.11745334796926454,
            "logloss": 0.9381106657645977,
            "mae": 0.26428914340896137,
            "precision": 0.7673913043478261,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.548831324139462,
            "auditor_fn_violation": 0.006313961988304102,
            "auditor_fp_violation": 0.010949683235867447,
            "ave_precision_score": 0.5437530011608896,
            "fpr": 0.03289473684210526,
            "logloss": 11.316953975234995,
            "mae": 0.5147102882242597,
            "precision": 0.6103896103896104,
            "recall": 0.09791666666666667
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5303477901880895,
            "auditor_fn_violation": 0.0008499029674813794,
            "auditor_fp_violation": 0.007163903171760356,
            "ave_precision_score": 0.5225152133089644,
            "fpr": 0.048298572996706916,
            "logloss": 11.390398377064109,
            "mae": 0.517433568253715,
            "precision": 0.5164835164835165,
            "recall": 0.09915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7924185063603364,
            "auditor_fn_violation": 0.00044544956140350853,
            "auditor_fp_violation": 0.01360461338531515,
            "ave_precision_score": 0.742331178573965,
            "fpr": 0.34978070175438597,
            "logloss": 3.3308346831718763,
            "mae": 0.35519008015697245,
            "precision": 0.5962025316455696,
            "recall": 0.98125
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8069022956877407,
            "auditor_fn_violation": 0.00435604218482958,
            "auditor_fp_violation": 0.007801922598698341,
            "ave_precision_score": 0.7621658013326544,
            "fpr": 0.3446761800219539,
            "logloss": 2.9911934695508866,
            "mae": 0.3477242332651962,
            "precision": 0.5948387096774194,
            "recall": 0.9725738396624473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.802050073924826,
            "auditor_fn_violation": 0.014635873538011697,
            "auditor_fp_violation": 0.016949926900584795,
            "ave_precision_score": 0.8025167634217862,
            "fpr": 0.125,
            "logloss": 1.1150796844995297,
            "mae": 0.28710801380471007,
            "precision": 0.75054704595186,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8335145983426719,
            "auditor_fn_violation": 0.014793406420356914,
            "auditor_fp_violation": 0.0160760800488311,
            "ave_precision_score": 0.8337642441109738,
            "fpr": 0.1141602634467618,
            "logloss": 0.9753084982746607,
            "mae": 0.2658702913766703,
            "precision": 0.7704194260485652,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 10197,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7988190614331406,
            "auditor_fn_violation": 0.009502923976608188,
            "auditor_fp_violation": 0.021356197205977916,
            "ave_precision_score": 0.7574240095500431,
            "fpr": 0.15570175438596492,
            "logloss": 2.660263252431917,
            "mae": 0.27841429527277123,
            "precision": 0.7320754716981132,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8110666916493817,
            "auditor_fn_violation": 0.020971992570875425,
            "auditor_fp_violation": 0.0234459579962171,
            "ave_precision_score": 0.7770442688897301,
            "fpr": 0.14050493962678376,
            "logloss": 2.3222128129485387,
            "mae": 0.26265948922591675,
            "precision": 0.7480314960629921,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7945754986372867,
            "auditor_fn_violation": 0.004168951023391813,
            "auditor_fp_violation": 0.018762183235867445,
            "ave_precision_score": 0.7438152094143206,
            "fpr": 0.35855263157894735,
            "logloss": 3.3853411612753437,
            "mae": 0.3553821543326736,
            "precision": 0.5881612090680101,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.8062765519622778,
            "auditor_fn_violation": 0.009121983076046631,
            "auditor_fp_violation": 0.03257666908645164,
            "ave_precision_score": 0.7608779789494965,
            "fpr": 0.3413830954994512,
            "logloss": 3.0520900348086175,
            "mae": 0.3467211268797167,
            "precision": 0.5929319371727748,
            "recall": 0.9556962025316456
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 10197,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7933609090172189,
            "auditor_fn_violation": 0.008566337719298246,
            "auditor_fp_violation": 0.020523676088369077,
            "ave_precision_score": 0.7524581403914432,
            "fpr": 0.14692982456140352,
            "logloss": 2.6929511992697575,
            "mae": 0.27818073275243616,
            "precision": 0.7423076923076923,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8068345915192945,
            "auditor_fn_violation": 0.02450360571912907,
            "auditor_fp_violation": 0.02383530055989973,
            "ave_precision_score": 0.7747740096106073,
            "fpr": 0.15367727771679474,
            "logloss": 2.3042408861170376,
            "mae": 0.2633712620298687,
            "precision": 0.7292069632495164,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7975029728349209,
            "auditor_fn_violation": 0.014919133771929827,
            "auditor_fp_violation": 0.019985583170890192,
            "ave_precision_score": 0.7980499210662966,
            "fpr": 0.12609649122807018,
            "logloss": 1.1033311452884977,
            "mae": 0.29088824861301693,
            "precision": 0.7466960352422908,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8301173334575834,
            "auditor_fn_violation": 0.01599299698481291,
            "auditor_fp_violation": 0.017419939865413077,
            "ave_precision_score": 0.8303783819358972,
            "fpr": 0.10757409440175632,
            "logloss": 0.9566821890374382,
            "mae": 0.2687611343435688,
            "precision": 0.7782805429864253,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8183292756680275,
            "auditor_fn_violation": 0.012198464912280708,
            "auditor_fp_violation": 0.021988202566601688,
            "ave_precision_score": 0.8188425557471107,
            "fpr": 0.12390350877192982,
            "logloss": 1.0936869103043245,
            "mae": 0.26977538881694907,
            "precision": 0.7640918580375783,
            "recall": 0.7625
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8509655040784156,
            "auditor_fn_violation": 0.023607386513637824,
            "auditor_fp_violation": 0.024960626163317904,
            "ave_precision_score": 0.8511710210290673,
            "fpr": 0.1141602634467618,
            "logloss": 0.9556364037139434,
            "mae": 0.2530940280833316,
            "precision": 0.7729257641921398,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8132974703125639,
            "auditor_fn_violation": 0.021712810672514626,
            "auditor_fp_violation": 0.016414372157244967,
            "ave_precision_score": 0.8137294758973141,
            "fpr": 0.11293859649122807,
            "logloss": 1.0399478873930075,
            "mae": 0.282391200183826,
            "precision": 0.7648401826484018,
            "recall": 0.6979166666666666
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8482962680454444,
            "auditor_fn_violation": 0.0214999976841881,
            "auditor_fp_violation": 0.01665883795060122,
            "ave_precision_score": 0.8485063576095475,
            "fpr": 0.09110867178924259,
            "logloss": 0.9091339968239817,
            "mae": 0.26151426328400684,
            "precision": 0.8009592326139089,
            "recall": 0.7046413502109705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8145428663545692,
            "auditor_fn_violation": 0.010862116228070175,
            "auditor_fp_violation": 0.029564652371669914,
            "ave_precision_score": 0.8149206946975169,
            "fpr": 0.18859649122807018,
            "logloss": 1.075305730811219,
            "mae": 0.2820712740298563,
            "precision": 0.7019064124783362,
            "recall": 0.84375
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8478082792211001,
            "auditor_fn_violation": 0.010990843279745447,
            "auditor_fp_violation": 0.022807938569279117,
            "ave_precision_score": 0.8480178844195313,
            "fpr": 0.1756311745334797,
            "logloss": 0.9984435377534618,
            "mae": 0.2620603846344692,
            "precision": 0.7153024911032029,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7862118858716045,
            "auditor_fn_violation": 0.009429824561403512,
            "auditor_fp_violation": 0.026011208576998065,
            "ave_precision_score": 0.7489985261255576,
            "fpr": 0.24013157894736842,
            "logloss": 2.696926151407952,
            "mae": 0.30061727650279135,
            "precision": 0.663594470046083,
            "recall": 0.9
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8089299543125097,
            "auditor_fn_violation": 0.010648103118472307,
            "auditor_fp_violation": 0.02594026229129354,
            "ave_precision_score": 0.7794711601575806,
            "fpr": 0.22722283205268934,
            "logloss": 2.2550206345079746,
            "mae": 0.28215746289515364,
            "precision": 0.6765625,
            "recall": 0.9135021097046413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.806168243064627,
            "auditor_fn_violation": 0.004513888888888889,
            "auditor_fp_violation": 0.026955409356725153,
            "ave_precision_score": 0.8041570647222562,
            "fpr": 0.3026315789473684,
            "logloss": 2.207912108673061,
            "mae": 0.34055174159673285,
            "precision": 0.6161335187760779,
            "recall": 0.9229166666666667
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8291978099899494,
            "auditor_fn_violation": 0.006959014760985055,
            "auditor_fp_violation": 0.018801477994609496,
            "ave_precision_score": 0.8291172605849271,
            "fpr": 0.29747530186608123,
            "logloss": 2.0615540846145644,
            "mae": 0.3315855891903781,
            "precision": 0.6183098591549295,
            "recall": 0.9261603375527426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7928368558192447,
            "auditor_fn_violation": 0.009438961988304092,
            "auditor_fp_violation": 0.022891792560103964,
            "ave_precision_score": 0.751155212242996,
            "fpr": 0.15899122807017543,
            "logloss": 2.685182986871367,
            "mae": 0.28259435991538584,
            "precision": 0.7253787878787878,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8084097954074864,
            "auditor_fn_violation": 0.011303477886312165,
            "auditor_fp_violation": 0.019459592521608515,
            "ave_precision_score": 0.7762472791891871,
            "fpr": 0.14818880351262348,
            "logloss": 2.2663203875854747,
            "mae": 0.2668141852904004,
            "precision": 0.7373540856031129,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7867201572418093,
            "auditor_fn_violation": 0.019106359649122818,
            "auditor_fp_violation": 0.015264579272254714,
            "ave_precision_score": 0.7454768382170134,
            "fpr": 0.13706140350877194,
            "logloss": 2.7087070606623214,
            "mae": 0.2924732923078691,
            "precision": 0.7406639004149378,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.801726785674313,
            "auditor_fn_violation": 0.007517125429004159,
            "auditor_fp_violation": 0.01576711788539262,
            "ave_precision_score": 0.7691625411967037,
            "fpr": 0.13062568605927552,
            "logloss": 2.3141396487461408,
            "mae": 0.2753163242419229,
            "precision": 0.75,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.805258202718081,
            "auditor_fn_violation": 0.016650676169590643,
            "auditor_fp_violation": 0.020604897660818716,
            "ave_precision_score": 0.8057260526636298,
            "fpr": 0.12828947368421054,
            "logloss": 1.0693192094722757,
            "mae": 0.2791128825566066,
            "precision": 0.7552301255230126,
            "recall": 0.7520833333333333
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8352262856517303,
            "auditor_fn_violation": 0.027998165876974818,
            "auditor_fp_violation": 0.019585186896990008,
            "ave_precision_score": 0.835477830385283,
            "fpr": 0.12623490669593854,
            "logloss": 0.9503194619825951,
            "mae": 0.2621591919020116,
            "precision": 0.7547974413646056,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8272377526853806,
            "auditor_fn_violation": 0.0466968201754386,
            "auditor_fp_violation": 0.027765086907082525,
            "ave_precision_score": 0.8278885696075897,
            "fpr": 0.07785087719298246,
            "logloss": 0.7929431097990415,
            "mae": 0.3164670378333712,
            "precision": 0.8174807197943444,
            "recall": 0.6625
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8293678091294943,
            "auditor_fn_violation": 0.05095249343467327,
            "auditor_fp_violation": 0.019745947697478318,
            "ave_precision_score": 0.8298151374389863,
            "fpr": 0.06147091108671789,
            "logloss": 0.9008944159753888,
            "mae": 0.3248179028132195,
            "precision": 0.8357771260997068,
            "recall": 0.6012658227848101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7954008655301281,
            "auditor_fn_violation": 0.020086348684210525,
            "auditor_fp_violation": 0.021361273554256016,
            "ave_precision_score": 0.7944120765606275,
            "fpr": 0.12280701754385964,
            "logloss": 1.138046035722775,
            "mae": 0.27198670398000785,
            "precision": 0.7642105263157895,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8339253704141545,
            "auditor_fn_violation": 0.029218598748535253,
            "auditor_fp_violation": 0.01827398161800722,
            "ave_precision_score": 0.8335890416095384,
            "fpr": 0.10976948408342481,
            "logloss": 1.0776117613813592,
            "mae": 0.2557438134844138,
            "precision": 0.7830802603036876,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.800499475368468,
            "auditor_fn_violation": 0.015248081140350877,
            "auditor_fp_violation": 0.017569241390513322,
            "ave_precision_score": 0.8012914919710596,
            "fpr": 0.09429824561403509,
            "logloss": 0.9611770907271155,
            "mae": 0.31905167288736314,
            "precision": 0.7681940700808625,
            "recall": 0.59375
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8121665491336092,
            "auditor_fn_violation": 0.02553877363864998,
            "auditor_fp_violation": 0.023501219521384956,
            "ave_precision_score": 0.8124534316399641,
            "fpr": 0.09549945115257959,
            "logloss": 0.9478832372257643,
            "mae": 0.31366328470683186,
            "precision": 0.7692307692307693,
            "recall": 0.6118143459915611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.804386055565022,
            "auditor_fn_violation": 0.012330957602339184,
            "auditor_fp_violation": 0.03027534113060429,
            "ave_precision_score": 0.8030035974686015,
            "fpr": 0.2850877192982456,
            "logloss": 1.7739900949972913,
            "mae": 0.3258270196059472,
            "precision": 0.6296296296296297,
            "recall": 0.9208333333333333
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8330727314572819,
            "auditor_fn_violation": 0.014760985053749997,
            "auditor_fp_violation": 0.030526968880225682,
            "ave_precision_score": 0.8332674683250768,
            "fpr": 0.2689352360043908,
            "logloss": 1.6104313628367755,
            "mae": 0.3054735823762401,
            "precision": 0.6423357664233577,
            "recall": 0.9282700421940928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.37819136088369837,
            "auditor_fn_violation": 0.0011604532163742862,
            "auditor_fp_violation": 0.002528021442495127,
            "ave_precision_score": 0.5256201856923607,
            "fpr": 0.0043859649122807015,
            "logloss": 17.919913485877046,
            "mae": 0.5265113945999801,
            "precision": 0.5,
            "recall": 0.008333333333333333
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.387947178614967,
            "auditor_fn_violation": 0.0019383345607136507,
            "auditor_fp_violation": 0.0005174488265717508,
            "ave_precision_score": 0.5215758557595338,
            "fpr": 0.0010976948408342481,
            "logloss": 17.741701982351497,
            "mae": 0.5189630187371728,
            "precision": 0.75,
            "recall": 0.006329113924050633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8073112429685436,
            "auditor_fn_violation": 0.022139985380116963,
            "auditor_fp_violation": 0.013053829597141006,
            "ave_precision_score": 0.807835419316495,
            "fpr": 0.08442982456140351,
            "logloss": 1.1435555279320266,
            "mae": 0.2961344476203921,
            "precision": 0.7884615384615384,
            "recall": 0.5979166666666667
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8381902856914705,
            "auditor_fn_violation": 0.02913291370821697,
            "auditor_fp_violation": 0.015314978134019245,
            "ave_precision_score": 0.8384311954856541,
            "fpr": 0.06366630076838639,
            "logloss": 1.0573250034182615,
            "mae": 0.2814330453302797,
            "precision": 0.8361581920903954,
            "recall": 0.6244725738396625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7692308562565242,
            "auditor_fn_violation": 0.0015739217836257308,
            "auditor_fp_violation": 0.0035839018843404915,
            "ave_precision_score": 0.550992196483879,
            "fpr": 0.44627192982456143,
            "logloss": 14.789990241678561,
            "mae": 0.45310261284261183,
            "precision": 0.5375,
            "recall": 0.9854166666666667
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.766260208502409,
            "auditor_fn_violation": 0.00021305469484546582,
            "auditor_fp_violation": 0.006834845908260845,
            "ave_precision_score": 0.5493090809455778,
            "fpr": 0.45554335894621295,
            "logloss": 14.746606087172326,
            "mae": 0.4593496902402015,
            "precision": 0.5305429864253394,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8123157614466981,
            "auditor_fn_violation": 0.01408991228070176,
            "auditor_fp_violation": 0.020155640838206642,
            "ave_precision_score": 0.8120202256884468,
            "fpr": 0.2050438596491228,
            "logloss": 1.2254461506282883,
            "mae": 0.2854033819107452,
            "precision": 0.6888519134775375,
            "recall": 0.8625
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8436003787387494,
            "auditor_fn_violation": 0.010893579179924694,
            "auditor_fp_violation": 0.026018130804030086,
            "ave_precision_score": 0.843818232675463,
            "fpr": 0.1942919868276619,
            "logloss": 1.0816203537896631,
            "mae": 0.26887998037178606,
            "precision": 0.700507614213198,
            "recall": 0.8734177215189873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7926416979758873,
            "auditor_fn_violation": 0.0019371345029239768,
            "auditor_fp_violation": 0.02159478557504874,
            "ave_precision_score": 0.74255593444731,
            "fpr": 0.32346491228070173,
            "logloss": 3.2570413127446534,
            "mae": 0.3395617937799774,
            "precision": 0.6108179419525066,
            "recall": 0.9645833333333333
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.80722956529937,
            "auditor_fn_violation": 0.004170777232790044,
            "auditor_fp_violation": 0.01299901785198453,
            "ave_precision_score": 0.7625307274348301,
            "fpr": 0.3106476399560922,
            "logloss": 2.916999390719359,
            "mae": 0.33047014475575603,
            "precision": 0.6175675675675676,
            "recall": 0.9641350210970464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7899870817616151,
            "auditor_fn_violation": 0.011289290935672514,
            "auditor_fp_violation": 0.026886878654970758,
            "ave_precision_score": 0.7897592239552566,
            "fpr": 0.27960526315789475,
            "logloss": 1.7047356368613542,
            "mae": 0.32156236611874556,
            "precision": 0.6341463414634146,
            "recall": 0.9208333333333333
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8252780932664507,
            "auditor_fn_violation": 0.011921799663744112,
            "auditor_fp_violation": 0.032780131974569644,
            "ave_precision_score": 0.8255939993893561,
            "fpr": 0.265642151481888,
            "logloss": 1.5751534268298197,
            "mae": 0.30271169034842377,
            "precision": 0.6461988304093568,
            "recall": 0.9324894514767933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8003096078870147,
            "auditor_fn_violation": 0.012152777777777787,
            "auditor_fp_violation": 0.014574195906432748,
            "ave_precision_score": 0.8017480131840518,
            "fpr": 0.08223684210526316,
            "logloss": 1.1663803402841488,
            "mae": 0.30477543579876565,
            "precision": 0.7893258426966292,
            "recall": 0.5854166666666667
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8395866497213738,
            "auditor_fn_violation": 0.025872250552321143,
            "auditor_fp_violation": 0.009630576704252878,
            "ave_precision_score": 0.83982402282915,
            "fpr": 0.06037321624588365,
            "logloss": 1.10039432854956,
            "mae": 0.29032561500091136,
            "precision": 0.8348348348348348,
            "recall": 0.5864978902953587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7975091448617666,
            "auditor_fn_violation": 0.02234100877192983,
            "auditor_fp_violation": 0.011558845029239768,
            "ave_precision_score": 0.7981487367904316,
            "fpr": 0.05592105263157895,
            "logloss": 1.5720706885354572,
            "mae": 0.33690667734633256,
            "precision": 0.8152173913043478,
            "recall": 0.46875
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8177029250989974,
            "auditor_fn_violation": 0.01925829176450973,
            "auditor_fp_violation": 0.006530907519837633,
            "ave_precision_score": 0.8180023418970539,
            "fpr": 0.04500548847420417,
            "logloss": 1.4929840593837473,
            "mae": 0.33598782751278206,
            "precision": 0.8366533864541833,
            "recall": 0.4430379746835443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8172712403557593,
            "auditor_fn_violation": 0.017537006578947377,
            "auditor_fp_violation": 0.011378634665367123,
            "ave_precision_score": 0.8177760471666702,
            "fpr": 0.07785087719298246,
            "logloss": 1.1005023271382128,
            "mae": 0.29965934100315145,
            "precision": 0.7959770114942529,
            "recall": 0.5770833333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8442218261442971,
            "auditor_fn_violation": 0.02055746224068697,
            "auditor_fp_violation": 0.006864988558352404,
            "ave_precision_score": 0.8444486154996756,
            "fpr": 0.059275521405049394,
            "logloss": 1.0726724114995978,
            "mae": 0.29149223821111847,
            "precision": 0.8348623853211009,
            "recall": 0.5759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7443596351394015,
            "auditor_fn_violation": 0.020045230263157906,
            "auditor_fp_violation": 0.021122685185185196,
            "ave_precision_score": 0.7449620509711079,
            "fpr": 0.13925438596491227,
            "logloss": 1.236421674026272,
            "mae": 0.3312077303705613,
            "precision": 0.7046511627906977,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7635679355777172,
            "auditor_fn_violation": 0.0070238574941988985,
            "auditor_fp_violation": 0.018218720092839365,
            "ave_precision_score": 0.7641075306430389,
            "fpr": 0.14818880351262348,
            "logloss": 1.1154492604611725,
            "mae": 0.31639458794603453,
            "precision": 0.7039473684210527,
            "recall": 0.6772151898734177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8014258122086595,
            "auditor_fn_violation": 0.014820906432748547,
            "auditor_fp_violation": 0.020955165692007803,
            "ave_precision_score": 0.8018840054373471,
            "fpr": 0.13157894736842105,
            "logloss": 1.0872893296292085,
            "mae": 0.2850446250879424,
            "precision": 0.7478991596638656,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8340510668316143,
            "auditor_fn_violation": 0.013255707318428775,
            "auditor_fp_violation": 0.01894967935755965,
            "ave_precision_score": 0.8342973346885183,
            "fpr": 0.12623490669593854,
            "logloss": 0.9448609639059857,
            "mae": 0.2650048166799706,
            "precision": 0.7563559322033898,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7914366063301439,
            "auditor_fn_violation": 0.021427266081871354,
            "auditor_fp_violation": 0.033021645549057836,
            "ave_precision_score": 0.7918527622032505,
            "fpr": 0.15899122807017543,
            "logloss": 1.1370431160999532,
            "mae": 0.2908412757347084,
            "precision": 0.7184466019417476,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8180479772889304,
            "auditor_fn_violation": 0.020251775069821728,
            "auditor_fp_violation": 0.027246443795261074,
            "ave_precision_score": 0.8183687816700059,
            "fpr": 0.15477497255762898,
            "logloss": 1.0398692038346526,
            "mae": 0.27842384203692483,
            "precision": 0.7235294117647059,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8121484308299848,
            "auditor_fn_violation": 0.01758497807017544,
            "auditor_fp_violation": 0.025006091617933726,
            "ave_precision_score": 0.8125880519292668,
            "fpr": 0.13486842105263158,
            "logloss": 0.997847715119764,
            "mae": 0.274712676492035,
            "precision": 0.7510121457489879,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8438660476694333,
            "auditor_fn_violation": 0.02413076000314951,
            "auditor_fp_violation": 0.021928777941608666,
            "ave_precision_score": 0.8440892905105255,
            "fpr": 0.13172338090010977,
            "logloss": 0.8872188304482275,
            "mae": 0.25796677514629485,
            "precision": 0.7540983606557377,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.809531359420792,
            "auditor_fn_violation": 0.010407529239766088,
            "auditor_fp_violation": 0.025777696556205324,
            "ave_precision_score": 0.8092936279380585,
            "fpr": 0.21271929824561403,
            "logloss": 1.2679952981344926,
            "mae": 0.29052962855460973,
            "precision": 0.6830065359477124,
            "recall": 0.8708333333333333
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8403845116637715,
            "auditor_fn_violation": 0.01722037729207483,
            "auditor_fp_violation": 0.03633947657288117,
            "ave_precision_score": 0.8406127036283524,
            "fpr": 0.20417124039517015,
            "logloss": 1.1318004973755131,
            "mae": 0.2696925810737936,
            "precision": 0.6910299003322259,
            "recall": 0.8776371308016878
        }
    }
]