[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 20300,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5582902716085624,
            "auditor_fn_violation": 0.019841801550719983,
            "auditor_fp_violation": 0.008417718881526861,
            "ave_precision_score": 0.559652054960869,
            "fpr": 0.19407894736842105,
            "logloss": 0.6942407578090475,
            "mae": 0.5002430158814317,
            "precision": 0.5267379679144385,
            "recall": 0.40122199592668023
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5286513422185073,
            "auditor_fn_violation": 0.01865844146299252,
            "auditor_fp_violation": 0.006946350164654229,
            "ave_precision_score": 0.530285948537194,
            "fpr": 0.19209659714599342,
            "logloss": 0.6924398361244507,
            "mae": 0.49934064563359704,
            "precision": 0.5308310991957105,
            "recall": 0.42764578833693306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944573702936074,
            "mae": 0.500604600073737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933415913311788,
            "mae": 0.500047322391286,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5577705172288288,
            "auditor_fn_violation": 0.018854736127487757,
            "auditor_fp_violation": 0.008417718881526861,
            "ave_precision_score": 0.5591327111029577,
            "fpr": 0.19407894736842105,
            "logloss": 0.6943063356778828,
            "mae": 0.5002764572895932,
            "precision": 0.5254691689008043,
            "recall": 0.39918533604887985
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5301046201702674,
            "auditor_fn_violation": 0.019142091025692705,
            "auditor_fp_violation": 0.006946350164654229,
            "ave_precision_score": 0.5317369506045638,
            "fpr": 0.19209659714599342,
            "logloss": 0.6924342720685704,
            "mae": 0.49933756300699045,
            "precision": 0.5308310991957105,
            "recall": 0.42764578833693306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6603429811445122,
            "auditor_fn_violation": 0.00483930038946654,
            "auditor_fp_violation": 0.012564070508813613,
            "ave_precision_score": 0.6006237555655054,
            "fpr": 0.27850877192982454,
            "logloss": 0.6869853093256831,
            "mae": 0.4886036322435789,
            "precision": 0.5528169014084507,
            "recall": 0.639511201629328
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6163486213812723,
            "auditor_fn_violation": 0.016479647599651964,
            "auditor_fp_violation": 0.014223478908577706,
            "ave_precision_score": 0.5561493855053108,
            "fpr": 0.31284302963776073,
            "logloss": 0.6963158309786035,
            "mae": 0.49312270387729096,
            "precision": 0.500875656742557,
            "recall": 0.6177105831533477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.46246403089356125,
            "auditor_fn_violation": 0.0020009290027512825,
            "auditor_fp_violation": 4.427636787931818e-05,
            "ave_precision_score": 0.5508408560237492,
            "fpr": 0.007675438596491228,
            "logloss": 0.6922487760793196,
            "mae": 0.49888049409185586,
            "precision": 0.36363636363636365,
            "recall": 0.008146639511201629
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.314967850016018,
            "auditor_fn_violation": 0.0006211577717031851,
            "auditor_fp_violation": 0.0036410145836600284,
            "ave_precision_score": 0.5232038492148132,
            "fpr": 0.010976948408342482,
            "logloss": 0.6913677901641574,
            "mae": 0.4981863444382744,
            "precision": 0.09090909090909091,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944573702936074,
            "mae": 0.500604600073737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933415913311788,
            "mae": 0.500047322391286,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944573702936074,
            "mae": 0.500604600073737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933415913311788,
            "mae": 0.500047322391286,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6815349559078243,
            "auditor_fn_violation": 0.05330823239361133,
            "auditor_fp_violation": 0.020111888986123268,
            "ave_precision_score": 0.584219559897311,
            "fpr": 0.04276315789473684,
            "logloss": 0.6829937926481408,
            "mae": 0.48845621371609077,
            "precision": 0.7364864864864865,
            "recall": 0.2219959266802444
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6453362303024325,
            "auditor_fn_violation": 0.04920185967998521,
            "auditor_fp_violation": 0.02378175474360985,
            "ave_precision_score": 0.5492721186204821,
            "fpr": 0.050493962678375415,
            "logloss": 0.6840522524280689,
            "mae": 0.48859431741004716,
            "precision": 0.6933333333333334,
            "recall": 0.22462203023758098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5142511809763932,
            "auditor_fn_violation": 0.018854736127487757,
            "auditor_fp_violation": 0.007782222777847237,
            "ave_precision_score": 0.5180226429631553,
            "fpr": 0.19736842105263158,
            "logloss": 0.6935438192321971,
            "mae": 0.49974375796553333,
            "precision": 0.5212765957446809,
            "recall": 0.39918533604887985
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5340584880726589,
            "auditor_fn_violation": 0.019142091025692705,
            "auditor_fp_violation": 0.002548220166222363,
            "ave_precision_score": 0.5367916324414426,
            "fpr": 0.19319429198682767,
            "logloss": 0.6920882408066427,
            "mae": 0.49901892756787664,
            "precision": 0.5294117647058824,
            "recall": 0.42764578833693306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6778103483022178,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5556193484837921,
            "fpr": 0.43640350877192985,
            "logloss": 0.7166146862677176,
            "mae": 0.48128381985844226,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6600992190899073,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5252167507745756,
            "fpr": 0.4643249176728869,
            "logloss": 0.7363688099366898,
            "mae": 0.49060842777580904,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.3830694842060952,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5424895012515493,
            "fpr": 0.43640350877192985,
            "logloss": 0.7193876146272381,
            "mae": 0.48315825140136376,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.3095539813395018,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5158396743437459,
            "fpr": 0.4643249176728869,
            "logloss": 0.7382401137359138,
            "mae": 0.49230075248902505,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5786918985693794,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5806621483045161,
            "fpr": 0.43640350877192985,
            "logloss": 0.7189511070831649,
            "mae": 0.4817319861694909,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5670844851640893,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5684993791871886,
            "fpr": 0.4643249176728869,
            "logloss": 0.734946318117631,
            "mae": 0.4897260545833705,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7703596432217374,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5480799278179543,
            "fpr": 0.43640350877192985,
            "logloss": 0.7147260129959747,
            "mae": 0.4818859438885722,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7556682022235499,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5186119998738685,
            "fpr": 0.4643249176728869,
            "logloss": 0.7335481222495621,
            "mae": 0.490935664734385,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.37383432339648726,
            "auditor_fn_violation": 0.0009468681888019446,
            "auditor_fp_violation": 0.00393799224903113,
            "ave_precision_score": 0.5364154115764856,
            "fpr": 0.009868421052631578,
            "logloss": 0.7086796162523294,
            "mae": 0.5043264151665202,
            "precision": 0.18181818181818182,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4003502838716644,
            "auditor_fn_violation": 0.0020104648488713777,
            "auditor_fp_violation": 0.005606084365689196,
            "ave_precision_score": 0.5048921647009409,
            "fpr": 0.012074643249176729,
            "logloss": 0.7069671262028512,
            "mae": 0.502702043948922,
            "precision": 0.26666666666666666,
            "recall": 0.008639308855291577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7374684749760255,
            "auditor_fn_violation": 0.010064940865401795,
            "auditor_fp_violation": 0.026753344168021005,
            "ave_precision_score": 0.7384048332102163,
            "fpr": 0.2949561403508772,
            "logloss": 0.8775321070491606,
            "mae": 0.3870133568588675,
            "precision": 0.611271676300578,
            "recall": 0.8615071283095723
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7770455007901963,
            "auditor_fn_violation": 0.009049462651110854,
            "auditor_fp_violation": 0.03233299357064451,
            "ave_precision_score": 0.7774072240134465,
            "fpr": 0.305159165751921,
            "logloss": 0.8457990906796955,
            "mae": 0.37899550462844983,
            "precision": 0.6005747126436781,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6942372017242211,
            "mae": 0.5005021727268111,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.7557095542126115,
            "auditor_fn_violation": 0.0019630482250772414,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5114191084252229,
            "fpr": 0.0,
            "logloss": 0.6913667214966949,
            "mae": 0.49867521270569803,
            "precision": 1.0,
            "recall": 0.0064794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5786918985693794,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5806621483045161,
            "fpr": 0.43640350877192985,
            "logloss": 0.7189511125267357,
            "mae": 0.48173198581003307,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5670844851640893,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5684993791871886,
            "fpr": 0.4643249176728869,
            "logloss": 0.7349463246103501,
            "mae": 0.4897260545833705,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7912916353085694,
            "auditor_fn_violation": 0.01581091220924001,
            "auditor_fp_violation": 0.01805434012584907,
            "ave_precision_score": 0.7658989001742291,
            "fpr": 0.24890350877192982,
            "logloss": 2.027225063837946,
            "mae": 0.3205461458497315,
            "precision": 0.6616989567809239,
            "recall": 0.9042769857433809
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8102044206387795,
            "auditor_fn_violation": 0.008276571683266438,
            "auditor_fp_violation": 0.023825858554179107,
            "ave_precision_score": 0.7807341743751353,
            "fpr": 0.2524698133918771,
            "logloss": 2.063787234969697,
            "mae": 0.31001685904727433,
            "precision": 0.6530920060331825,
            "recall": 0.9352051835853131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8259139402723212,
            "auditor_fn_violation": 0.003934862614785436,
            "auditor_fp_violation": 0.011733237488019336,
            "ave_precision_score": 0.8263229815472104,
            "fpr": 0.09868421052631579,
            "logloss": 0.6696337112400498,
            "mae": 0.3189588510790121,
            "precision": 0.7761194029850746,
            "recall": 0.6354378818737271
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.828570522598973,
            "auditor_fn_violation": 0.00523716609806232,
            "auditor_fp_violation": 0.006049572683079821,
            "ave_precision_score": 0.8288522468521894,
            "fpr": 0.10867178924259056,
            "logloss": 0.6158723487572543,
            "mae": 0.29705420067489063,
            "precision": 0.7670588235294118,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7653340859214341,
            "auditor_fn_violation": 0.007550380533819274,
            "auditor_fp_violation": 0.01649424928116015,
            "ave_precision_score": 0.7217821399236997,
            "fpr": 0.35855263157894735,
            "logloss": 3.255968073791867,
            "mae": 0.3865786161367667,
            "precision": 0.5881612090680101,
            "recall": 0.9511201629327902
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7857849784658817,
            "auditor_fn_violation": 0.005441057580377105,
            "auditor_fp_violation": 0.029912184412733273,
            "ave_precision_score": 0.7402604677243118,
            "fpr": 0.36882546652030734,
            "logloss": 3.1468846669846577,
            "mae": 0.3839313080288985,
            "precision": 0.5730622617534943,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5555254173854276,
            "auditor_fn_violation": 0.0005538285632615145,
            "auditor_fp_violation": 0.0007266533316664726,
            "ave_precision_score": 0.5569352796788903,
            "fpr": 0.45723684210526316,
            "logloss": 0.6935925414709714,
            "mae": 0.5001068335483995,
            "precision": 0.5402425578831312,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5189770326475375,
            "auditor_fn_violation": 0.0005405495112531504,
            "auditor_fp_violation": 0.004586796299200249,
            "ave_precision_score": 0.5204259006602974,
            "fpr": 0.4818880351262349,
            "logloss": 0.6923903706281231,
            "mae": 0.49948493051869153,
            "precision": 0.5127635960044395,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7402930304821408,
            "auditor_fn_violation": 0.01927457390931504,
            "auditor_fp_violation": 0.023179980830937204,
            "ave_precision_score": 0.7416070594176732,
            "fpr": 0.1875,
            "logloss": 3.898326297612875,
            "mae": 0.4007793271802252,
            "precision": 0.6452282157676349,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6686557182844912,
            "auditor_fn_violation": 0.011337314749177919,
            "auditor_fp_violation": 0.030980476713188026,
            "ave_precision_score": 0.670560603806813,
            "fpr": 0.18880351262349068,
            "logloss": 4.574866147615692,
            "mae": 0.4267096190391062,
            "precision": 0.6073059360730594,
            "recall": 0.5745140388768899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.37383432339648726,
            "auditor_fn_violation": 0.0009468681888019446,
            "auditor_fp_violation": 0.00393799224903113,
            "ave_precision_score": 0.5364154115764856,
            "fpr": 0.009868421052631578,
            "logloss": 0.7086796162523294,
            "mae": 0.5043264151665202,
            "precision": 0.18181818181818182,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4003502838716644,
            "auditor_fn_violation": 0.0020104648488713777,
            "auditor_fp_violation": 0.005606084365689196,
            "ave_precision_score": 0.5048921647009409,
            "fpr": 0.012074643249176729,
            "logloss": 0.7069671262028512,
            "mae": 0.502702043948922,
            "precision": 0.26666666666666666,
            "recall": 0.008639308855291577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8268582494530407,
            "auditor_fn_violation": 0.004734340944009723,
            "auditor_fp_violation": 0.011733237488019336,
            "ave_precision_score": 0.8272668176148255,
            "fpr": 0.09868421052631579,
            "logloss": 0.6660431450806459,
            "mae": 0.3181640973986217,
            "precision": 0.7761194029850746,
            "recall": 0.6354378818737271
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8294750641164745,
            "auditor_fn_violation": 0.008082163525710478,
            "auditor_fp_violation": 0.004995981652814806,
            "ave_precision_score": 0.8297560931497309,
            "fpr": 0.10647639956092206,
            "logloss": 0.6125146586867471,
            "mae": 0.29617696689491896,
            "precision": 0.7706855791962175,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944882330513201,
            "mae": 0.5006179168428245,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.693351453595482,
            "mae": 0.5000501567197291,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7725281682402646,
            "auditor_fn_violation": 0.024252331439596958,
            "auditor_fp_violation": 0.02209130307955164,
            "ave_precision_score": 0.7708347007126305,
            "fpr": 0.2565789473684211,
            "logloss": 2.9351203463098283,
            "mae": 0.3545664664383795,
            "precision": 0.6332288401253918,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7913898651498594,
            "auditor_fn_violation": 0.014331674541777603,
            "auditor_fp_violation": 0.04836227850086248,
            "ave_precision_score": 0.789655153963378,
            "fpr": 0.2491767288693743,
            "logloss": 2.725937458257437,
            "mae": 0.3345679585177429,
            "precision": 0.6296900489396411,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 20300,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.4887717438662763,
            "auditor_fn_violation": 0.01305516847107586,
            "auditor_fp_violation": 0.01817414676834604,
            "ave_precision_score": 0.4902633525457925,
            "fpr": 0.2807017543859649,
            "logloss": 0.6936787787138626,
            "mae": 0.5002553680617559,
            "precision": 0.5019455252918288,
            "recall": 0.5254582484725051
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.49860599552917495,
            "auditor_fn_violation": 0.0023850561768450455,
            "auditor_fp_violation": 0.021748079034028537,
            "ave_precision_score": 0.49994482795706896,
            "fpr": 0.29198682766191,
            "logloss": 0.691230589004746,
            "mae": 0.4986523535392941,
            "precision": 0.5074074074074074,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 20300,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5495964502053259,
            "auditor_fn_violation": 0.008081877300175077,
            "auditor_fp_violation": 0.0024195732799933345,
            "ave_precision_score": 0.5513321166147032,
            "fpr": 0.03618421052631579,
            "logloss": 0.6950032918981227,
            "mae": 0.5007863183293426,
            "precision": 0.6071428571428571,
            "recall": 0.10386965376782077
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5111944349137296,
            "auditor_fn_violation": 0.008103501006417841,
            "auditor_fp_violation": 0.0024796142386702223,
            "ave_precision_score": 0.513396821592339,
            "fpr": 0.03951701427003293,
            "logloss": 0.6940937721492875,
            "mae": 0.500345390662142,
            "precision": 0.5813953488372093,
            "recall": 0.1079913606911447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.37383432339648726,
            "auditor_fn_violation": 0.0009468681888019446,
            "auditor_fp_violation": 0.00393799224903113,
            "ave_precision_score": 0.5364154115764856,
            "fpr": 0.009868421052631578,
            "logloss": 0.7064258341920342,
            "mae": 0.5043471197091174,
            "precision": 0.18181818181818182,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4003502838716644,
            "auditor_fn_violation": 0.0020104648488713777,
            "auditor_fp_violation": 0.005606084365689196,
            "ave_precision_score": 0.5048921647009409,
            "fpr": 0.012074643249176729,
            "logloss": 0.7038233874472344,
            "mae": 0.502613411842141,
            "precision": 0.26666666666666666,
            "recall": 0.008639308855291577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.787405291871679,
            "auditor_fn_violation": 0.012148497516704182,
            "auditor_fp_violation": 0.011287869316997967,
            "ave_precision_score": 0.7667966189889397,
            "fpr": 0.15679824561403508,
            "logloss": 2.465034877391791,
            "mae": 0.2823346038856385,
            "precision": 0.7332089552238806,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.796096789820994,
            "auditor_fn_violation": 0.00996460349033768,
            "auditor_fp_violation": 0.02075819350791909,
            "ave_precision_score": 0.772660397981997,
            "fpr": 0.15916575192096596,
            "logloss": 2.5378874492262504,
            "mae": 0.2742771104935017,
            "precision": 0.7269303201506592,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.786793741391625,
            "auditor_fn_violation": 0.011270857898309932,
            "auditor_fp_violation": 0.011287869316997967,
            "ave_precision_score": 0.7662026075381678,
            "fpr": 0.15679824561403508,
            "logloss": 2.4734181996176723,
            "mae": 0.28289547865674275,
            "precision": 0.7337057728119181,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.796586731929561,
            "auditor_fn_violation": 0.00996460349033768,
            "auditor_fp_violation": 0.01998147639956092,
            "ave_precision_score": 0.7738648063362367,
            "fpr": 0.16136114160263446,
            "logloss": 2.5294379480610645,
            "mae": 0.27485172346746234,
            "precision": 0.724202626641651,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.506375105563326,
            "auditor_fn_violation": 0.016929735234215895,
            "auditor_fp_violation": 0.004495353585864903,
            "ave_precision_score": 0.5152553210054884,
            "fpr": 0.22039473684210525,
            "logloss": 0.6958314481149994,
            "mae": 0.5012024904421547,
            "precision": 0.5037037037037037,
            "recall": 0.4154786150712831
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5361639155223694,
            "auditor_fn_violation": 0.0007325868376194148,
            "auditor_fp_violation": 0.008267014270032937,
            "ave_precision_score": 0.5287322403036481,
            "fpr": 0.22283205268935236,
            "logloss": 0.69095181374511,
            "mae": 0.4983951171653593,
            "precision": 0.5223529411764706,
            "recall": 0.4794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8065930479957591,
            "auditor_fn_violation": 0.008041680065744811,
            "auditor_fp_violation": 0.01720267116722925,
            "ave_precision_score": 0.806665511536152,
            "fpr": 0.2883771929824561,
            "logloss": 1.6352201352291695,
            "mae": 0.31805051392595923,
            "precision": 0.640218878248974,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7884777718293463,
            "auditor_fn_violation": 0.004312541934076669,
            "auditor_fp_violation": 0.025393994041085177,
            "ave_precision_score": 0.7883528783439699,
            "fpr": 0.29088913282107576,
            "logloss": 1.843817108737874,
            "mae": 0.3209492360989043,
            "precision": 0.6257062146892656,
            "recall": 0.9568034557235421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5722094283374245,
            "auditor_fn_violation": 0.005562850609211425,
            "auditor_fp_violation": 0.01058986539984165,
            "ave_precision_score": 0.5740583235994094,
            "fpr": 0.30701754385964913,
            "logloss": 0.6939838416163929,
            "mae": 0.5002635969666013,
            "precision": 0.5087719298245614,
            "recall": 0.5906313645621182
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5624232931594665,
            "auditor_fn_violation": 0.0006377535900311285,
            "auditor_fp_violation": 0.011459640112905782,
            "ave_precision_score": 0.563726883564593,
            "fpr": 0.3062568605927552,
            "logloss": 0.6903875672075909,
            "mae": 0.4980678064370391,
            "precision": 0.49547920433996384,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7539850428845815,
            "auditor_fn_violation": 0.034449029906742416,
            "auditor_fp_violation": 0.05580385048131018,
            "ave_precision_score": 0.7545868863629887,
            "fpr": 0.28618421052631576,
            "logloss": 0.8952106419384704,
            "mae": 0.37977354461355517,
            "precision": 0.612184249628529,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7887279440772643,
            "auditor_fn_violation": 0.031980141917955014,
            "auditor_fp_violation": 0.06499676572055826,
            "ave_precision_score": 0.789097345209729,
            "fpr": 0.28210757409440174,
            "logloss": 0.8365432595175742,
            "mae": 0.36139902372198834,
            "precision": 0.60882800608828,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7703596432217374,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5480799278179543,
            "fpr": 0.43640350877192985,
            "logloss": 0.7147256199621003,
            "mae": 0.4818860278709939,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7556682022235499,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5186119998738685,
            "fpr": 0.4643249176728869,
            "logloss": 0.7335476350724732,
            "mae": 0.4909357069352587,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7202100867997907,
            "auditor_fn_violation": 0.009006413692071322,
            "auditor_fp_violation": 0.02462026503312914,
            "ave_precision_score": 0.7212024098626156,
            "fpr": 0.3081140350877193,
            "logloss": 0.9392907381226118,
            "mae": 0.3915376090979471,
            "precision": 0.6036671368124118,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7621166770197045,
            "auditor_fn_violation": 0.006737902241146725,
            "auditor_fp_violation": 0.03205856986043593,
            "ave_precision_score": 0.7625705980713489,
            "fpr": 0.31174533479692645,
            "logloss": 0.9025210424393438,
            "mae": 0.38255490378617757,
            "precision": 0.5994358251057827,
            "recall": 0.91792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.787425765194546,
            "auditor_fn_violation": 0.012148497516704182,
            "auditor_fp_violation": 0.011287869316997967,
            "ave_precision_score": 0.7668123354220437,
            "fpr": 0.15679824561403508,
            "logloss": 2.4653360384862713,
            "mae": 0.2823266389431715,
            "precision": 0.7332089552238806,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7961032391083454,
            "auditor_fn_violation": 0.00996460349033768,
            "auditor_fp_violation": 0.02075819350791909,
            "ave_precision_score": 0.7726623052276304,
            "fpr": 0.15916575192096596,
            "logloss": 2.538235946635689,
            "mae": 0.27428276445087263,
            "precision": 0.7269303201506592,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7500907195367281,
            "auditor_fn_violation": 0.013660360167220496,
            "auditor_fp_violation": 0.002625328166020773,
            "ave_precision_score": 0.7205337051580143,
            "fpr": 0.3125,
            "logloss": 2.599199336539561,
            "mae": 0.36970208638919294,
            "precision": 0.611716621253406,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7762842935853969,
            "auditor_fn_violation": 0.0057279281543316275,
            "auditor_fp_violation": 0.01577936333699231,
            "ave_precision_score": 0.7405000185458807,
            "fpr": 0.33479692645444564,
            "logloss": 2.64354076957303,
            "mae": 0.3694207463630398,
            "precision": 0.5855978260869565,
            "recall": 0.9308855291576674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6709087562796008,
            "auditor_fn_violation": 0.00514524600707472,
            "auditor_fp_violation": 0.011787931824811457,
            "ave_precision_score": 0.5953489765773197,
            "fpr": 0.28618421052631576,
            "logloss": 0.6864510616665789,
            "mae": 0.48754972572389405,
            "precision": 0.555366269165247,
            "recall": 0.6639511201629328
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6195955906093918,
            "auditor_fn_violation": 0.011733243557858954,
            "auditor_fp_violation": 0.010925493962678376,
            "ave_precision_score": 0.5471568263419421,
            "fpr": 0.3194291986827662,
            "logloss": 0.6969896193104008,
            "mae": 0.49259507315873313,
            "precision": 0.5051020408163265,
            "recall": 0.6414686825053996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8282169692080701,
            "auditor_fn_violation": 0.005473523421588598,
            "auditor_fp_violation": 0.010826874192607411,
            "ave_precision_score": 0.8287647716972117,
            "fpr": 0.1162280701754386,
            "logloss": 0.6526180322419868,
            "mae": 0.3073662670815478,
            "precision": 0.7596371882086168,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8353057230098757,
            "auditor_fn_violation": 0.009013900183265259,
            "auditor_fp_violation": 0.006353398933667875,
            "ave_precision_score": 0.8355537501421411,
            "fpr": 0.12403951701427003,
            "logloss": 0.6089110384059832,
            "mae": 0.28725599702512666,
            "precision": 0.7538126361655774,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7769156645473614,
            "auditor_fn_violation": 0.021353664201236293,
            "auditor_fp_violation": 0.016374442638663177,
            "ave_precision_score": 0.7740587529154487,
            "fpr": 0.24780701754385964,
            "logloss": 2.9495349852601405,
            "mae": 0.3466790321615843,
            "precision": 0.6424050632911392,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7980331477272888,
            "auditor_fn_violation": 0.013231608869753652,
            "auditor_fp_violation": 0.04406705739375882,
            "ave_precision_score": 0.7961830732377353,
            "fpr": 0.24478594950603733,
            "logloss": 2.70413283954681,
            "mae": 0.32807077967714215,
            "precision": 0.6338259441707718,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8032711846223319,
            "auditor_fn_violation": 0.005766069961053346,
            "auditor_fp_violation": 0.015181585198149786,
            "ave_precision_score": 0.8034915328927689,
            "fpr": 0.29714912280701755,
            "logloss": 1.6461646277590685,
            "mae": 0.3217283799166373,
            "precision": 0.6342780026990553,
            "recall": 0.9572301425661914
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7785374703208845,
            "auditor_fn_violation": 0.002508339398709793,
            "auditor_fp_violation": 0.027363964246510917,
            "ave_precision_score": 0.778467968140726,
            "fpr": 0.29857299670691545,
            "logloss": 1.8395028892980607,
            "mae": 0.3229200642557208,
            "precision": 0.6206415620641562,
            "recall": 0.9611231101511879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7703596432217374,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.5480799278179543,
            "fpr": 0.43640350877192985,
            "logloss": 0.714725559619861,
            "mae": 0.4818860409421879,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7556682022235499,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5186119998738685,
            "fpr": 0.4643249176728869,
            "logloss": 0.7335475603065901,
            "mae": 0.49093571360888516,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8261257557495627,
            "auditor_fn_violation": 0.006712938149855286,
            "auditor_fp_violation": 0.013824644747260076,
            "ave_precision_score": 0.8265924856236968,
            "fpr": 0.1206140350877193,
            "logloss": 0.6736054743216864,
            "mae": 0.30675883988097913,
            "precision": 0.7555555555555555,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8313521965305984,
            "auditor_fn_violation": 0.009978828477475924,
            "auditor_fp_violation": 0.007865179551513257,
            "ave_precision_score": 0.8315998898894043,
            "fpr": 0.13391877058177826,
            "logloss": 0.643823325436899,
            "mae": 0.28814366653764945,
            "precision": 0.7387580299785867,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7503988627855928,
            "auditor_fn_violation": 0.013660360167220496,
            "auditor_fp_violation": 0.0014480976788765444,
            "ave_precision_score": 0.7208390088955914,
            "fpr": 0.31140350877192985,
            "logloss": 2.5973078659297713,
            "mae": 0.36943374948972824,
            "precision": 0.6125511596180082,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7766640074592361,
            "auditor_fn_violation": 0.00573504064790075,
            "auditor_fp_violation": 0.01687705817782659,
            "ave_precision_score": 0.7408870412831929,
            "fpr": 0.33479692645444564,
            "logloss": 2.6416537016312347,
            "mae": 0.3692995766617366,
            "precision": 0.5861601085481682,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7266022817938058,
            "auditor_fn_violation": 0.008910386965376781,
            "auditor_fp_violation": 0.02514897695545277,
            "ave_precision_score": 0.7273340433147955,
            "fpr": 0.3048245614035088,
            "logloss": 0.9379757486762258,
            "mae": 0.3885353619997132,
            "precision": 0.607898448519041,
            "recall": 0.8778004073319755
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7634063670883864,
            "auditor_fn_violation": 0.007143314374586587,
            "auditor_fp_violation": 0.02983377763838796,
            "ave_precision_score": 0.7638511577979462,
            "fpr": 0.3106476399560922,
            "logloss": 0.9104125319052568,
            "mae": 0.3815771113581747,
            "precision": 0.5980113636363636,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8349466450249465,
            "auditor_fn_violation": 0.00717967270518455,
            "auditor_fp_violation": 0.009113118306454974,
            "ave_precision_score": 0.8353477239349779,
            "fpr": 0.08552631578947369,
            "logloss": 0.6425638245554232,
            "mae": 0.3150483019147774,
            "precision": 0.7994858611825193,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8357472911721755,
            "auditor_fn_violation": 0.00526798690352851,
            "auditor_fp_violation": 0.0001715148188803515,
            "ave_precision_score": 0.8360290916904721,
            "fpr": 0.09769484083424808,
            "logloss": 0.5910539696073511,
            "mae": 0.2948016262405325,
            "precision": 0.7813267813267813,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7535775383989688,
            "auditor_fn_violation": 0.012186461571443886,
            "auditor_fp_violation": 0.01387413009959579,
            "ave_precision_score": 0.7240276892656886,
            "fpr": 0.3201754385964912,
            "logloss": 2.601702614080344,
            "mae": 0.3707651697847101,
            "precision": 0.6069986541049798,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7797285525998567,
            "auditor_fn_violation": 0.005858323869765502,
            "auditor_fp_violation": 0.01209179473106477,
            "ave_precision_score": 0.744074470356019,
            "fpr": 0.34577387486278816,
            "logloss": 2.652333957703728,
            "mae": 0.37098839010265844,
            "precision": 0.5816733067729084,
            "recall": 0.9460043196544277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8331483524854431,
            "auditor_fn_violation": 0.006185907742880628,
            "auditor_fp_violation": 0.00874328041005126,
            "ave_precision_score": 0.8334784819950194,
            "fpr": 0.08771929824561403,
            "logloss": 0.6528802736176228,
            "mae": 0.3166765939594402,
            "precision": 0.7948717948717948,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8335279474138408,
            "auditor_fn_violation": 0.007674380561080915,
            "auditor_fp_violation": 0.0024257095813078272,
            "ave_precision_score": 0.8338095156088693,
            "fpr": 0.09879253567508232,
            "logloss": 0.597780878478376,
            "mae": 0.2954674537825245,
            "precision": 0.7794117647058824,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7853487043256051,
            "auditor_fn_violation": 0.009953281880873263,
            "auditor_fp_violation": 0.011207130057923917,
            "ave_precision_score": 0.7633789413784492,
            "fpr": 0.15789473684210525,
            "logloss": 2.542613851246668,
            "mae": 0.28291964361957844,
            "precision": 0.7333333333333333,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7957863058724155,
            "auditor_fn_violation": 0.00996460349033768,
            "auditor_fp_violation": 0.01941547749725576,
            "ave_precision_score": 0.771490111541836,
            "fpr": 0.16245883644346873,
            "logloss": 2.601097509337916,
            "mae": 0.2751985893008821,
            "precision": 0.7228464419475655,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7482347890882199,
            "auditor_fn_violation": 0.006920623861078358,
            "auditor_fp_violation": 0.00011720215026879421,
            "ave_precision_score": 0.719378851110046,
            "fpr": 0.3508771929824561,
            "logloss": 2.7992333244501766,
            "mae": 0.38509875782709285,
            "precision": 0.5928753180661578,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7723963375098247,
            "auditor_fn_violation": 0.003949804762051527,
            "auditor_fp_violation": 0.018224674611886482,
            "ave_precision_score": 0.7375233608735092,
            "fpr": 0.3633369923161361,
            "logloss": 2.8602888191985545,
            "mae": 0.3889440404745504,
            "precision": 0.5729032258064516,
            "recall": 0.958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7502482226528691,
            "auditor_fn_violation": 0.013660360167220496,
            "auditor_fp_violation": 0.001005334000083365,
            "ave_precision_score": 0.7206883565510174,
            "fpr": 0.3125,
            "logloss": 2.600903733322625,
            "mae": 0.36962482449956024,
            "precision": 0.611716621253406,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7765642826895747,
            "auditor_fn_violation": 0.00573504064790075,
            "auditor_fp_violation": 0.01687705817782659,
            "ave_precision_score": 0.740782038466927,
            "fpr": 0.33479692645444564,
            "logloss": 2.645188081903331,
            "mae": 0.3696303702836563,
            "precision": 0.5861601085481682,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7482553492510406,
            "auditor_fn_violation": 0.006920623861078358,
            "auditor_fp_violation": 0.00011720215026879421,
            "ave_precision_score": 0.7193581206559135,
            "fpr": 0.3508771929824561,
            "logloss": 2.805180161722371,
            "mae": 0.3852374963295133,
            "precision": 0.5928753180661578,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7719943194991195,
            "auditor_fn_violation": 0.003949804762051527,
            "auditor_fp_violation": 0.018224674611886482,
            "ave_precision_score": 0.7371256386327549,
            "fpr": 0.3633369923161361,
            "logloss": 2.86658705667336,
            "mae": 0.38921013212766353,
            "precision": 0.5729032258064516,
            "recall": 0.958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7201927912890667,
            "auditor_fn_violation": 0.009006413692071322,
            "auditor_fp_violation": 0.02462026503312914,
            "ave_precision_score": 0.7211851543438575,
            "fpr": 0.3081140350877193,
            "logloss": 0.939453763086605,
            "mae": 0.39155063010127233,
            "precision": 0.6036671368124118,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.762113772201671,
            "auditor_fn_violation": 0.006737902241146725,
            "auditor_fp_violation": 0.03205856986043593,
            "ave_precision_score": 0.762567694935691,
            "fpr": 0.31174533479692645,
            "logloss": 0.9026800775153464,
            "mae": 0.38256662509467504,
            "precision": 0.5994358251057827,
            "recall": 0.91792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8030924151195722,
            "auditor_fn_violation": 0.017141887304820098,
            "auditor_fp_violation": 0.02287525524023837,
            "ave_precision_score": 0.802334792068475,
            "fpr": 0.24561403508771928,
            "logloss": 1.1513001169329362,
            "mae": 0.31403481983473125,
            "precision": 0.6631578947368421,
            "recall": 0.8981670061099797
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8283917348506753,
            "auditor_fn_violation": 0.0068493313070629456,
            "auditor_fp_violation": 0.03210757409440176,
            "ave_precision_score": 0.828366661641154,
            "fpr": 0.2535675082327113,
            "logloss": 1.087345347263387,
            "mae": 0.30545516776247267,
            "precision": 0.6505295007564297,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.8072428629903601,
            "auditor_fn_violation": 0.015743916818522885,
            "auditor_fp_violation": 0.04064049672875777,
            "ave_precision_score": 0.8084991206549048,
            "fpr": 0.2598684210526316,
            "logloss": 0.7128221321240574,
            "mae": 0.35599102389811343,
            "precision": 0.6419939577039275,
            "recall": 0.8655804480651731
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.826528773313666,
            "auditor_fn_violation": 0.011090748305448409,
            "auditor_fp_violation": 0.05100850713501647,
            "ave_precision_score": 0.826877453878474,
            "fpr": 0.2535675082327113,
            "logloss": 0.6833886451142669,
            "mae": 0.3366204828039756,
            "precision": 0.642967542503864,
            "recall": 0.8984881209503239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6709087562796008,
            "auditor_fn_violation": 0.00514524600707472,
            "auditor_fp_violation": 0.011787931824811457,
            "ave_precision_score": 0.5953489765773197,
            "fpr": 0.28618421052631576,
            "logloss": 0.6864510616665789,
            "mae": 0.48754972572389405,
            "precision": 0.555366269165247,
            "recall": 0.6639511201629328
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6195955906093918,
            "auditor_fn_violation": 0.011733243557858954,
            "auditor_fp_violation": 0.010925493962678376,
            "ave_precision_score": 0.5471568263419421,
            "fpr": 0.3194291986827662,
            "logloss": 0.6969896193104008,
            "mae": 0.49259507315873313,
            "precision": 0.5051020408163265,
            "recall": 0.6414686825053996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7482855164245414,
            "auditor_fn_violation": 0.004727641404938008,
            "auditor_fp_violation": 0.01630151685627372,
            "ave_precision_score": 0.7023985221501621,
            "fpr": 0.4232456140350877,
            "logloss": 3.926008588531243,
            "mae": 0.42062829611615216,
            "precision": 0.5558112773302647,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7700805561189532,
            "auditor_fn_violation": 0.004324396090025202,
            "auditor_fp_violation": 0.022100909518582408,
            "ave_precision_score": 0.7225941139487271,
            "fpr": 0.429198682766191,
            "logloss": 3.817985089321307,
            "mae": 0.42439508840925255,
            "precision": 0.5389150943396226,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6926494131263183,
            "auditor_fn_violation": 0.007132775931682567,
            "auditor_fp_violation": 5.990332124848546e-05,
            "ave_precision_score": 0.6484573141288792,
            "fpr": 0.3541666666666667,
            "logloss": 4.083559478482613,
            "mae": 0.38893763667338616,
            "precision": 0.5916561314791403,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7255389338097239,
            "auditor_fn_violation": 0.003949804762051527,
            "auditor_fp_violation": 0.01307923004547593,
            "ave_precision_score": 0.6761264117495127,
            "fpr": 0.3699231613611416,
            "logloss": 4.019351806661309,
            "mae": 0.3965787844586469,
            "precision": 0.5685019206145967,
            "recall": 0.958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7996162309792909,
            "auditor_fn_violation": 0.02092042734126559,
            "auditor_fp_violation": 0.04697983081218486,
            "ave_precision_score": 0.8008862966059065,
            "fpr": 0.2576754385964912,
            "logloss": 0.6976162088103482,
            "mae": 0.35941978865402663,
            "precision": 0.6384615384615384,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8216437982581147,
            "auditor_fn_violation": 0.016382443520873983,
            "auditor_fp_violation": 0.0570801317233809,
            "ave_precision_score": 0.8219887091179856,
            "fpr": 0.24588364434687157,
            "logloss": 0.6620930214590726,
            "mae": 0.339555549443496,
            "precision": 0.6455696202531646,
            "recall": 0.8812095032397408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.600910994083536,
            "auditor_fn_violation": 0.014147193339764892,
            "auditor_fp_violation": 0.012483331249739552,
            "ave_precision_score": 0.6025378531536741,
            "fpr": 0.10635964912280702,
            "logloss": 0.6896779803434249,
            "mae": 0.497668994819386,
            "precision": 0.6135458167330677,
            "recall": 0.3136456211812627
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5522207009999163,
            "auditor_fn_violation": 0.009305512419599192,
            "auditor_fp_violation": 0.007313881919397837,
            "ave_precision_score": 0.5534283957716293,
            "fpr": 0.13721185510428102,
            "logloss": 0.6894891736010048,
            "mae": 0.4971919547517004,
            "precision": 0.5437956204379562,
            "recall": 0.32181425485961124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.37642937942316673,
            "auditor_fn_violation": 0.0009468681888019446,
            "auditor_fp_violation": 0.00393799224903113,
            "ave_precision_score": 0.5385183228880335,
            "fpr": 0.009868421052631578,
            "logloss": 0.7057837860459191,
            "mae": 0.5038387090490576,
            "precision": 0.18181818181818182,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4016562196272534,
            "auditor_fn_violation": 0.0020104648488713777,
            "auditor_fp_violation": 0.005606084365689196,
            "ave_precision_score": 0.5044505834970849,
            "fpr": 0.012074643249176729,
            "logloss": 0.704451759124508,
            "mae": 0.5026905987121402,
            "precision": 0.26666666666666666,
            "recall": 0.008639308855291577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7872326520374323,
            "auditor_fn_violation": 0.00994434916211098,
            "auditor_fp_violation": 0.009376172021502685,
            "ave_precision_score": 0.7665915890993139,
            "fpr": 0.16228070175438597,
            "logloss": 2.46961031523419,
            "mae": 0.2831025442008278,
            "precision": 0.7274401473296501,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7957916670230577,
            "auditor_fn_violation": 0.008866908649503428,
            "auditor_fp_violation": 0.02138299749098323,
            "ave_precision_score": 0.7723655064315667,
            "fpr": 0.16355653128430298,
            "logloss": 2.5426078683841555,
            "mae": 0.2752569719267225,
            "precision": 0.7214953271028037,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7860091708136374,
            "auditor_fn_violation": 0.021029853146103547,
            "auditor_fp_violation": 0.019713401675209404,
            "ave_precision_score": 0.7835367535170334,
            "fpr": 0.2412280701754386,
            "logloss": 2.8738430410492537,
            "mae": 0.3396596446211189,
            "precision": 0.6463022508038585,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8007904806405381,
            "auditor_fn_violation": 0.013615683522486152,
            "auditor_fp_violation": 0.0437828328367571,
            "ave_precision_score": 0.7988115295732195,
            "fpr": 0.23161361141602635,
            "logloss": 2.665386715462726,
            "mae": 0.31980603123032353,
            "precision": 0.6459731543624161,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.7512565072449163,
            "auditor_fn_violation": 0.007094811876942867,
            "auditor_fp_violation": 0.0023075801141809586,
            "ave_precision_score": 0.5399777997868557,
            "fpr": 0.42105263157894735,
            "logloss": 0.695201333582578,
            "mae": 0.500260031112192,
            "precision": 0.5401197604790419,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.728418930932873,
            "auditor_fn_violation": 0.0016358735208976912,
            "auditor_fp_violation": 0.004478986984475466,
            "ave_precision_score": 0.5101047661575745,
            "fpr": 0.44127332601536773,
            "logloss": 0.6938673813852287,
            "mae": 0.4990224778717619,
            "precision": 0.5067484662576687,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7141102102289838,
            "auditor_fn_violation": 0.006190374102261765,
            "auditor_fp_violation": 0.006448722757011311,
            "ave_precision_score": 0.714538360916857,
            "fpr": 0.3782894736842105,
            "logloss": 2.007534505482161,
            "mae": 0.4024475157008662,
            "precision": 0.5772058823529411,
            "recall": 0.9592668024439919
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7568403873202912,
            "auditor_fn_violation": 0.004869687263657767,
            "auditor_fp_violation": 0.009261800219538967,
            "ave_precision_score": 0.757134555877157,
            "fpr": 0.3918770581778266,
            "logloss": 1.9745595084360514,
            "mae": 0.40900328364940136,
            "precision": 0.5559701492537313,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.3610378560500493,
            "auditor_fn_violation": 0.0009468681888019446,
            "auditor_fp_violation": 0.00393799224903113,
            "ave_precision_score": 0.5369248141182432,
            "fpr": 0.009868421052631578,
            "logloss": 0.7048028037373625,
            "mae": 0.5041782050475216,
            "precision": 0.18181818181818182,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.3895739537324391,
            "auditor_fn_violation": 0.0020104648488713777,
            "auditor_fp_violation": 0.005606084365689196,
            "ave_precision_score": 0.5061457476376644,
            "fpr": 0.012074643249176729,
            "logloss": 0.7017807749537754,
            "mae": 0.5024256159262128,
            "precision": 0.26666666666666666,
            "recall": 0.008639308855291577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.752269790340163,
            "auditor_fn_violation": 0.01026146067817201,
            "auditor_fp_violation": 0.012350502146101606,
            "ave_precision_score": 0.7227897885396131,
            "fpr": 0.31359649122807015,
            "logloss": 2.588106938967667,
            "mae": 0.3662667510661777,
            "precision": 0.6119402985074627,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7800888779629805,
            "auditor_fn_violation": 0.005215828617354959,
            "auditor_fp_violation": 0.01802865767602323,
            "ave_precision_score": 0.7451684336458342,
            "fpr": 0.33699231613611413,
            "logloss": 2.603380186658059,
            "mae": 0.36451045298533347,
            "precision": 0.5862533692722371,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6815349559078243,
            "auditor_fn_violation": 0.05330823239361133,
            "auditor_fp_violation": 0.020111888986123268,
            "ave_precision_score": 0.584219559897311,
            "fpr": 0.04276315789473684,
            "logloss": 0.6829937926481408,
            "mae": 0.48845621371609077,
            "precision": 0.7364864864864865,
            "recall": 0.2219959266802444
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6453362303024325,
            "auditor_fn_violation": 0.04920185967998521,
            "auditor_fp_violation": 0.02378175474360985,
            "ave_precision_score": 0.5492721186204821,
            "fpr": 0.050493962678375415,
            "logloss": 0.6840522524280689,
            "mae": 0.48859431741004716,
            "precision": 0.6933333333333334,
            "recall": 0.22462203023758098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7873547457316058,
            "auditor_fn_violation": 0.012190927930825032,
            "auditor_fp_violation": 0.015340459224069684,
            "ave_precision_score": 0.765979281603359,
            "fpr": 0.15679824561403508,
            "logloss": 2.5065274256994488,
            "mae": 0.2796223286872013,
            "precision": 0.7356746765249538,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7969861656367213,
            "auditor_fn_violation": 0.009599495487122831,
            "auditor_fp_violation": 0.018758820762113854,
            "ave_precision_score": 0.7726821610366761,
            "fpr": 0.16245883644346873,
            "logloss": 2.5710884419288274,
            "mae": 0.27187386442342976,
            "precision": 0.7228464419475655,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 20300,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7337712743013481,
            "auditor_fn_violation": 0.009357022903490908,
            "auditor_fp_violation": 0.02220069175313581,
            "ave_precision_score": 0.7347148394220222,
            "fpr": 0.30372807017543857,
            "logloss": 0.9191256549621827,
            "mae": 0.38983760376715126,
            "precision": 0.609308885754584,
            "recall": 0.879837067209776
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.774346050873077,
            "auditor_fn_violation": 0.008084534356900186,
            "auditor_fp_violation": 0.029946487376509335,
            "ave_precision_score": 0.7747075853833816,
            "fpr": 0.31833150384193193,
            "logloss": 0.892246224377466,
            "mae": 0.38431732063605956,
            "precision": 0.5932678821879382,
            "recall": 0.9136069114470843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7857139871663983,
            "auditor_fn_violation": 0.01888376746346518,
            "auditor_fp_violation": 0.01726517898070594,
            "ave_precision_score": 0.7832973881614564,
            "fpr": 0.24013157894736842,
            "logloss": 2.867883795948351,
            "mae": 0.33942270134940317,
            "precision": 0.646774193548387,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8007622728104362,
            "auditor_fn_violation": 0.013615683522486152,
            "auditor_fp_violation": 0.0420897365532382,
            "ave_precision_score": 0.7989965639051682,
            "fpr": 0.2305159165751921,
            "logloss": 2.6579057007793994,
            "mae": 0.3198694543653901,
            "precision": 0.6470588235294118,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.786809359701322,
            "auditor_fn_violation": 0.011297656054596778,
            "auditor_fp_violation": 0.016629682877026295,
            "ave_precision_score": 0.7680292705926283,
            "fpr": 0.15350877192982457,
            "logloss": 2.3200289212041536,
            "mae": 0.27868162796324575,
            "precision": 0.7388059701492538,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7977336079662778,
            "auditor_fn_violation": 0.009265208289374176,
            "auditor_fp_violation": 0.017612121687313784,
            "ave_precision_score": 0.7760279378821782,
            "fpr": 0.16245883644346873,
            "logloss": 2.3695060963425307,
            "mae": 0.27107355198005734,
            "precision": 0.7238805970149254,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7329769819712626,
            "auditor_fn_violation": 0.02248141994497446,
            "auditor_fp_violation": 0.028519189898737342,
            "ave_precision_score": 0.7343212450201113,
            "fpr": 0.18640350877192982,
            "logloss": 4.025044499538111,
            "mae": 0.4055037106646607,
            "precision": 0.6450939457202505,
            "recall": 0.6293279022403259
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6606296682698986,
            "auditor_fn_violation": 0.013091729829560948,
            "auditor_fp_violation": 0.032283989336678705,
            "ave_precision_score": 0.6626646943837226,
            "fpr": 0.19758507135016465,
            "logloss": 4.749131054542696,
            "mae": 0.4312875329107008,
            "precision": 0.5909090909090909,
            "recall": 0.5615550755939525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7508837259149264,
            "auditor_fn_violation": 0.0032403437310179737,
            "auditor_fp_violation": 0.0025237529691211507,
            "ave_precision_score": 0.542708522326001,
            "fpr": 0.41228070175438597,
            "logloss": 0.7586403586353017,
            "mae": 0.4981736091145298,
            "precision": 0.543134872417983,
            "recall": 0.9103869653767821
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7380074076933222,
            "auditor_fn_violation": 0.005358078488737368,
            "auditor_fp_violation": 0.004184961580680579,
            "ave_precision_score": 0.5128147490897899,
            "fpr": 0.4456641053787047,
            "logloss": 0.7424677215887499,
            "mae": 0.4962378274465366,
            "precision": 0.513189448441247,
            "recall": 0.9244060475161987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7876221884190007,
            "auditor_fn_violation": 0.011983242219601955,
            "auditor_fp_violation": 0.013702233612534908,
            "ave_precision_score": 0.7699718333286351,
            "fpr": 0.14473684210526316,
            "logloss": 2.2445875489386906,
            "mae": 0.27840313559051266,
            "precision": 0.7436893203883496,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7974635513979008,
            "auditor_fn_violation": 0.01134679807393674,
            "auditor_fp_violation": 0.020581778265642156,
            "ave_precision_score": 0.780208372709233,
            "fpr": 0.14489571899012074,
            "logloss": 2.2127198958442973,
            "mae": 0.26815347034666887,
            "precision": 0.7431906614785992,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.803192395012283,
            "auditor_fn_violation": 0.014517901168399617,
            "auditor_fp_violation": 0.04291942742842856,
            "ave_precision_score": 0.8044559715740023,
            "fpr": 0.26973684210526316,
            "logloss": 0.724691543767813,
            "mae": 0.35964904613195503,
            "precision": 0.6350148367952523,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8240439615662605,
            "auditor_fn_violation": 0.009976457646286211,
            "auditor_fp_violation": 0.05145444566410539,
            "ave_precision_score": 0.8244007642895597,
            "fpr": 0.2678375411635565,
            "logloss": 0.696074139412127,
            "mae": 0.3416198517648763,
            "precision": 0.6319758672699849,
            "recall": 0.9049676025917927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 20300,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7340660332652725,
            "auditor_fn_violation": 0.010953746382248901,
            "auditor_fp_violation": 0.024404092178188938,
            "ave_precision_score": 0.7348090868404986,
            "fpr": 0.31798245614035087,
            "logloss": 0.8796047911287035,
            "mae": 0.3899776104357953,
            "precision": 0.598893499308437,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7763745768209697,
            "auditor_fn_violation": 0.004855462276519525,
            "auditor_fp_violation": 0.03124509957660342,
            "ave_precision_score": 0.7768116728390265,
            "fpr": 0.32930845225027444,
            "logloss": 0.845940758184817,
            "mae": 0.3805607534029023,
            "precision": 0.5867768595041323,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7501672180542163,
            "auditor_fn_violation": 0.013660360167220496,
            "auditor_fp_violation": 0.005459015710297135,
            "ave_precision_score": 0.7205787480783113,
            "fpr": 0.3168859649122807,
            "logloss": 2.6105318948430853,
            "mae": 0.3705288012523006,
            "precision": 0.6084010840108401,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7759506030899824,
            "auditor_fn_violation": 0.00573504064790075,
            "auditor_fp_violation": 0.018523600439077942,
            "ave_precision_score": 0.7402183466221941,
            "fpr": 0.3380900109769484,
            "logloss": 2.655781121986279,
            "mae": 0.3705577510505537,
            "precision": 0.5837837837837838,
            "recall": 0.9330453563714903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.765274885153255,
            "auditor_fn_violation": 0.007550380533819274,
            "auditor_fp_violation": 0.01649424928116015,
            "ave_precision_score": 0.7217256084490262,
            "fpr": 0.35855263157894735,
            "logloss": 3.260325779066171,
            "mae": 0.3868696276550876,
            "precision": 0.5881612090680101,
            "recall": 0.9511201629327902
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7856769967197907,
            "auditor_fn_violation": 0.005441057580377105,
            "auditor_fp_violation": 0.028902697193037476,
            "ave_precision_score": 0.7401525853931735,
            "fpr": 0.37102085620197583,
            "logloss": 3.151283597154897,
            "mae": 0.38437525416866486,
            "precision": 0.5716096324461344,
            "recall": 0.9740820734341252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.755605823798702,
            "auditor_fn_violation": 0.012345017329474402,
            "auditor_fp_violation": 0.01367358419802475,
            "ave_precision_score": 0.7260289863952972,
            "fpr": 0.3168859649122807,
            "logloss": 2.5919072802493646,
            "mae": 0.36982096217562094,
            "precision": 0.6099865047233468,
            "recall": 0.9205702647657841
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.780524323688457,
            "auditor_fn_violation": 0.006306410964620087,
            "auditor_fp_violation": 0.012853810569233199,
            "ave_precision_score": 0.7448704156369611,
            "fpr": 0.3446761800219539,
            "logloss": 2.642265218250833,
            "mae": 0.3703542703558317,
            "precision": 0.5813333333333334,
            "recall": 0.9416846652267818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7512012615216561,
            "auditor_fn_violation": 0.013660360167220496,
            "auditor_fp_violation": 0.0012058799016543933,
            "ave_precision_score": 0.7215768474398748,
            "fpr": 0.3125,
            "logloss": 2.600983666527815,
            "mae": 0.36995406360760524,
            "precision": 0.611716621253406,
            "recall": 0.9144602851323829
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7768683121662927,
            "auditor_fn_violation": 0.006379906731500998,
            "auditor_fp_violation": 0.013858397365532384,
            "ave_precision_score": 0.7419068171425989,
            "fpr": 0.33260153677277715,
            "logloss": 2.6246621652314452,
            "mae": 0.3712748637384647,
            "precision": 0.5866302864938608,
            "recall": 0.9287257019438445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8312474375055092,
            "auditor_fn_violation": 0.01073489477257298,
            "auditor_fp_violation": 0.014392424053006624,
            "ave_precision_score": 0.8317893577563124,
            "fpr": 0.11513157894736842,
            "logloss": 0.635446346547749,
            "mae": 0.3049263175222669,
            "precision": 0.7651006711409396,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8388701586373137,
            "auditor_fn_violation": 0.010642661210593823,
            "auditor_fp_violation": 0.009124588364434687,
            "ave_precision_score": 0.8391120922351414,
            "fpr": 0.12952799121844127,
            "logloss": 0.5909202637355663,
            "mae": 0.2842766105775581,
            "precision": 0.7467811158798283,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8162260743847183,
            "auditor_fn_violation": 0.016221817272305,
            "auditor_fp_violation": 0.024966662499479104,
            "ave_precision_score": 0.8168042783856948,
            "fpr": 0.21271929824561403,
            "logloss": 0.997904695046999,
            "mae": 0.29024835060278226,
            "precision": 0.6964006259780907,
            "recall": 0.9063136456211812
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8402533426630501,
            "auditor_fn_violation": 0.008181738435678165,
            "auditor_fp_violation": 0.03479300611572841,
            "ave_precision_score": 0.8404831948604811,
            "fpr": 0.21734357848518113,
            "logloss": 0.9448338917587517,
            "mae": 0.27919812389095183,
            "precision": 0.6826923076923077,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7072177567507685,
            "auditor_fn_violation": 0.005748204523528782,
            "auditor_fp_violation": 0.006287244238863195,
            "ave_precision_score": 0.6621045040104745,
            "fpr": 0.38706140350877194,
            "logloss": 4.2178626103974,
            "mae": 0.3965209656648368,
            "precision": 0.5710814094775213,
            "recall": 0.9572301425661914
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7354788935095368,
            "auditor_fn_violation": 0.004068346321536869,
            "auditor_fp_violation": 0.01275825231299986,
            "ave_precision_score": 0.6859154491343266,
            "fpr": 0.39846322722283206,
            "logloss": 4.176157677426292,
            "mae": 0.4067695703984484,
            "precision": 0.5529556650246306,
            "recall": 0.9697624190064795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8259641736401112,
            "auditor_fn_violation": 0.007923321542144566,
            "auditor_fp_violation": 0.01275159394924366,
            "ave_precision_score": 0.8264311808170334,
            "fpr": 0.11951754385964912,
            "logloss": 0.6778803128469404,
            "mae": 0.3076669196530538,
            "precision": 0.7545045045045045,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8317449384337542,
            "auditor_fn_violation": 0.008845571168796069,
            "auditor_fp_violation": 0.006125529245726835,
            "ave_precision_score": 0.8319921123469434,
            "fpr": 0.12623490669593854,
            "logloss": 0.6435799495465042,
            "mae": 0.2878676331314892,
            "precision": 0.7478070175438597,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8363581707328444,
            "auditor_fn_violation": 0.005540518812305715,
            "auditor_fp_violation": 0.00946993374171772,
            "ave_precision_score": 0.8367627962474603,
            "fpr": 0.10307017543859649,
            "logloss": 0.6279493220430192,
            "mae": 0.30524899802667116,
            "precision": 0.7793427230046949,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8397133581683989,
            "auditor_fn_violation": 0.00450695009163263,
            "auditor_fp_violation": 0.010506507762270665,
            "ave_precision_score": 0.8399768276066607,
            "fpr": 0.10537870472008781,
            "logloss": 0.5890397444718874,
            "mae": 0.2861386627241835,
            "precision": 0.7803203661327232,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944573702936074,
            "mae": 0.500604600073737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933415913311788,
            "mae": 0.500047322391286,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7761698259203722,
            "auditor_fn_violation": 0.010779558366384395,
            "auditor_fp_violation": 0.02200275034379297,
            "ave_precision_score": 0.7466364318103991,
            "fpr": 0.28728070175438597,
            "logloss": 2.3228098802570085,
            "mae": 0.3435195165428715,
            "precision": 0.6335664335664336,
            "recall": 0.9226069246435845
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.8027552497833095,
            "auditor_fn_violation": 0.006109631975874423,
            "auditor_fp_violation": 0.030806511682609405,
            "ave_precision_score": 0.7692270926900153,
            "fpr": 0.29088913282107576,
            "logloss": 2.3072579168465306,
            "mae": 0.33388798692839733,
            "precision": 0.6214285714285714,
            "recall": 0.9395248380129589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 20300,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7530780183098337,
            "auditor_fn_violation": 0.008602208168078038,
            "auditor_fp_violation": 0.0033806309121973714,
            "ave_precision_score": 0.7211738700034737,
            "fpr": 0.34649122807017546,
            "logloss": 2.9032113802681008,
            "mae": 0.38233142367078055,
            "precision": 0.5953905249679897,
            "recall": 0.9470468431771895
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7768996943303621,
            "auditor_fn_violation": 0.00575637812860811,
            "auditor_fp_violation": 0.020856201975850742,
            "ave_precision_score": 0.7410411869339153,
            "fpr": 0.3600439077936334,
            "logloss": 2.890920683805113,
            "mae": 0.3842592974811635,
            "precision": 0.574025974025974,
            "recall": 0.9546436285097192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8031992136077082,
            "auditor_fn_violation": 0.014517901168399617,
            "auditor_fp_violation": 0.04291942742842856,
            "ave_precision_score": 0.8044627694842549,
            "fpr": 0.26973684210526316,
            "logloss": 0.7246974537642947,
            "mae": 0.3596480812336443,
            "precision": 0.6350148367952523,
            "recall": 0.8716904276985743
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8240529771510403,
            "auditor_fn_violation": 0.009976457646286211,
            "auditor_fp_violation": 0.05145444566410539,
            "ave_precision_score": 0.8244097745474839,
            "fpr": 0.2678375411635565,
            "logloss": 0.696081981412011,
            "mae": 0.34161947376956564,
            "precision": 0.6319758672699849,
            "recall": 0.9049676025917927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7998690160465667,
            "auditor_fn_violation": 0.011206095687283384,
            "auditor_fp_violation": 0.035512251531441434,
            "ave_precision_score": 0.8011386897192823,
            "fpr": 0.2807017543859649,
            "logloss": 0.7399546731713667,
            "mae": 0.3636164221263658,
            "precision": 0.6289855072463768,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8234180411029173,
            "auditor_fn_violation": 0.006040877871372925,
            "auditor_fp_violation": 0.04923945428885058,
            "ave_precision_score": 0.8237378334696884,
            "fpr": 0.2810098792535675,
            "logloss": 0.7181653638159409,
            "mae": 0.35137293118478485,
            "precision": 0.6240822320117474,
            "recall": 0.91792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7623357612265607,
            "auditor_fn_violation": 0.013577732518669384,
            "auditor_fp_violation": 0.007519169062799524,
            "ave_precision_score": 0.7610116775325495,
            "fpr": 0.2741228070175439,
            "logloss": 2.9382676352165618,
            "mae": 0.3595490109563322,
            "precision": 0.622356495468278,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7933971702119714,
            "auditor_fn_violation": 0.009215420834390333,
            "auditor_fp_violation": 0.029823976791594795,
            "ave_precision_score": 0.7922939100963168,
            "fpr": 0.27442371020856204,
            "logloss": 2.7128244739720713,
            "mae": 0.345415891593736,
            "precision": 0.6141975308641975,
            "recall": 0.8596112311015118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8254605829717713,
            "auditor_fn_violation": 0.0071752063458034076,
            "auditor_fp_violation": 0.013212589073634205,
            "ave_precision_score": 0.825925653301246,
            "fpr": 0.12171052631578948,
            "logloss": 0.6716500111905477,
            "mae": 0.307944154997376,
            "precision": 0.754424778761062,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8315569136977043,
            "auditor_fn_violation": 0.011012510876188084,
            "auditor_fp_violation": 0.007370236788458529,
            "ave_precision_score": 0.8317998320526423,
            "fpr": 0.13172338090010977,
            "logloss": 0.6410658730768207,
            "mae": 0.2894757604374425,
            "precision": 0.7419354838709677,
            "recall": 0.7451403887688985
        }
    }
]