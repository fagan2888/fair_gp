[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8088464792780374,
            "auditor_fn_violation": 0.020746887966804982,
            "auditor_fp_violation": 0.01447368421052632,
            "ave_precision_score": 0.8081060699065723,
            "fpr": 0.14583333333333334,
            "logloss": 1.022585823153848,
            "mae": 0.28200045037010857,
            "precision": 0.7345309381237525,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8162774867705591,
            "auditor_fn_violation": 0.013179314963999333,
            "auditor_fp_violation": 0.021798869299300635,
            "ave_precision_score": 0.8146168455476261,
            "fpr": 0.14709110867178923,
            "logloss": 0.871838758454961,
            "mae": 0.25763447259340955,
            "precision": 0.7387914230019493,
            "recall": 0.8029661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5188070689108033,
            "auditor_fn_violation": 0.0019290966004222323,
            "auditor_fp_violation": 0.0017135862913096698,
            "ave_precision_score": 0.5329938388029675,
            "fpr": 0.003289473684210526,
            "logloss": 18.013133070707976,
            "mae": 0.5268508675439675,
            "precision": 0.5714285714285714,
            "recall": 0.008298755186721992
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5142566605890342,
            "auditor_fn_violation": 0.001486074159519245,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5232167110085769,
            "fpr": 0.0,
            "logloss": 17.70827371744306,
            "mae": 0.5146064777158402,
            "precision": 1.0,
            "recall": 0.006355932203389831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8001606121952174,
            "auditor_fn_violation": 0.023979489699352118,
            "auditor_fp_violation": 0.007473990208078339,
            "ave_precision_score": 0.8005351867983781,
            "fpr": 0.10855263157894737,
            "logloss": 1.2766035940260065,
            "mae": 0.2976949450731381,
            "precision": 0.7620192307692307,
            "recall": 0.6576763485477178
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8095120662608671,
            "auditor_fn_violation": 0.012300228841466823,
            "auditor_fp_violation": 0.02163133956277239,
            "ave_precision_score": 0.8115490637774141,
            "fpr": 0.09659714599341383,
            "logloss": 1.035442202388509,
            "mae": 0.2701612954233319,
            "precision": 0.7879518072289157,
            "recall": 0.6927966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7184568811260679,
            "auditor_fn_violation": 0.07202491446458471,
            "auditor_fp_violation": 0.0785138718890249,
            "ave_precision_score": 0.7029112912108507,
            "fpr": 0.2631578947368421,
            "logloss": 4.054992904360451,
            "mae": 0.38976356252967254,
            "precision": 0.6072013093289689,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7183005343497492,
            "auditor_fn_violation": 0.0598290200747921,
            "auditor_fp_violation": 0.09291899312127905,
            "ave_precision_score": 0.6957824698809485,
            "fpr": 0.2711306256860593,
            "logloss": 3.820268834840213,
            "mae": 0.36343899272052416,
            "precision": 0.6122448979591837,
            "recall": 0.826271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5498822884277825,
            "auditor_fn_violation": 0.01399050010919416,
            "auditor_fp_violation": 0.03799469604243167,
            "ave_precision_score": 0.5140706160017843,
            "fpr": 0.23793859649122806,
            "logloss": 8.138677436901942,
            "mae": 0.48118457840844375,
            "precision": 0.5598377281947262,
            "recall": 0.5726141078838174
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5416844835430837,
            "auditor_fn_violation": 0.029628458203873567,
            "auditor_fp_violation": 0.04453040414673604,
            "ave_precision_score": 0.5080204268085511,
            "fpr": 0.21295279912184412,
            "logloss": 7.71896600834655,
            "mae": 0.4722909032231836,
            "precision": 0.5726872246696035,
            "recall": 0.5508474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8032618710128512,
            "auditor_fn_violation": 0.016881870131760943,
            "auditor_fp_violation": 0.018959098327213385,
            "ave_precision_score": 0.8032186882679812,
            "fpr": 0.14802631578947367,
            "logloss": 1.0623298255540938,
            "mae": 0.2855675972393581,
            "precision": 0.733201581027668,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8295300869850316,
            "auditor_fn_violation": 0.006116392863123037,
            "auditor_fp_violation": 0.02346916577692541,
            "ave_precision_score": 0.8298574302594387,
            "fpr": 0.145993413830955,
            "logloss": 0.8719972082216036,
            "mae": 0.25993181787897823,
            "precision": 0.7397260273972602,
            "recall": 0.8008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7934497645553727,
            "auditor_fn_violation": 0.017725849894445662,
            "auditor_fp_violation": 0.008960628314973487,
            "ave_precision_score": 0.7931241453524751,
            "fpr": 0.13815789473684212,
            "logloss": 1.0086437555291998,
            "mae": 0.29644073899946083,
            "precision": 0.7358490566037735,
            "recall": 0.7282157676348547
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8044374651564454,
            "auditor_fn_violation": 0.015935180189398872,
            "auditor_fp_violation": 0.021521320034306096,
            "ave_precision_score": 0.8029156045495227,
            "fpr": 0.12623490669593854,
            "logloss": 0.9039513601300408,
            "mae": 0.2697248005745662,
            "precision": 0.7568710359408034,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8410330851647433,
            "auditor_fn_violation": 0.01830821867947878,
            "auditor_fp_violation": 0.006599347205222365,
            "ave_precision_score": 0.8438255207982311,
            "fpr": 0.13596491228070176,
            "logloss": 1.0580891941700385,
            "mae": 0.25951259873618626,
            "precision": 0.753968253968254,
            "recall": 0.7883817427385892
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8686179150151041,
            "auditor_fn_violation": 0.0059745297586931865,
            "auditor_fp_violation": 0.015475246856317003,
            "ave_precision_score": 0.8688188999244499,
            "fpr": 0.1207464324917673,
            "logloss": 0.8076881904578198,
            "mae": 0.22850570724832284,
            "precision": 0.778672032193159,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7699245599595467,
            "auditor_fn_violation": 0.018017034286962223,
            "auditor_fp_violation": 0.011230110159118734,
            "ave_precision_score": 0.767101305253248,
            "fpr": 0.13048245614035087,
            "logloss": 1.313141103482251,
            "mae": 0.293040654436574,
            "precision": 0.7478813559322034,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8220797371606295,
            "auditor_fn_violation": 0.013251409328545648,
            "auditor_fp_violation": 0.025929602504444548,
            "ave_precision_score": 0.8215711416435696,
            "fpr": 0.1207464324917673,
            "logloss": 0.901438819016259,
            "mae": 0.26177381352685564,
            "precision": 0.7624190064794817,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7822331797874519,
            "auditor_fn_violation": 0.016110686467205357,
            "auditor_fp_violation": 0.0057578539371685045,
            "ave_precision_score": 0.7812991657977151,
            "fpr": 0.10526315789473684,
            "logloss": 1.2771454143241827,
            "mae": 0.30489520864726716,
            "precision": 0.7623762376237624,
            "recall": 0.6390041493775933
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7906301411705536,
            "auditor_fn_violation": 0.009042028688905853,
            "auditor_fp_violation": 0.01331486338825142,
            "ave_precision_score": 0.7888163878261054,
            "fpr": 0.10428100987925357,
            "logloss": 1.1384604477735063,
            "mae": 0.28819318842851377,
            "precision": 0.7654320987654321,
            "recall": 0.6567796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8361974518030142,
            "auditor_fn_violation": 0.043077091067918766,
            "auditor_fp_violation": 0.03419012647898817,
            "ave_precision_score": 0.8365851037194282,
            "fpr": 0.14364035087719298,
            "logloss": 0.6271094019187202,
            "mae": 0.3065038694413855,
            "precision": 0.7385229540918163,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8652327270666593,
            "auditor_fn_violation": 0.038530949413012335,
            "auditor_fp_violation": 0.03834180567050652,
            "ave_precision_score": 0.865401299734957,
            "fpr": 0.13172338090010977,
            "logloss": 0.5232681001567089,
            "mae": 0.2813598727382985,
            "precision": 0.765625,
            "recall": 0.8305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8173414644938555,
            "auditor_fn_violation": 0.016838647448496766,
            "auditor_fp_violation": 0.009939820481436157,
            "ave_precision_score": 0.817723408036923,
            "fpr": 0.12719298245614036,
            "logloss": 0.9354570719896079,
            "mae": 0.2861625185686073,
            "precision": 0.7547568710359408,
            "recall": 0.7406639004149378
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8419215937459046,
            "auditor_fn_violation": 0.00795363634672273,
            "auditor_fp_violation": 0.022624015762797905,
            "ave_precision_score": 0.8422177456936392,
            "fpr": 0.1207464324917673,
            "logloss": 0.7494546153918741,
            "mae": 0.26131587071559365,
            "precision": 0.7639484978540773,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8390366092989437,
            "auditor_fn_violation": 0.036611887602824494,
            "auditor_fp_violation": 0.007224092207262342,
            "ave_precision_score": 0.8393755525130961,
            "fpr": 0.0537280701754386,
            "logloss": 1.0145393046675202,
            "mae": 0.3206845252260905,
            "precision": 0.8558823529411764,
            "recall": 0.6037344398340249
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8575759023457944,
            "auditor_fn_violation": 0.017344508735046237,
            "auditor_fp_violation": 0.011622062916167622,
            "ave_precision_score": 0.8578004513493533,
            "fpr": 0.043907793633369926,
            "logloss": 0.7208333201811197,
            "mae": 0.30713190219708086,
            "precision": 0.8776758409785933,
            "recall": 0.6080508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7017011968283589,
            "auditor_fn_violation": 0.07684310620950718,
            "auditor_fp_violation": 0.05796868625050999,
            "ave_precision_score": 0.6959112392122857,
            "fpr": 0.16337719298245615,
            "logloss": 4.177054646064992,
            "mae": 0.3619155557476311,
            "precision": 0.6718061674008811,
            "recall": 0.6327800829875518
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6914852573501837,
            "auditor_fn_violation": 0.06820592011014158,
            "auditor_fp_violation": 0.05757772004530805,
            "ave_precision_score": 0.6815176714376807,
            "fpr": 0.16465422612513722,
            "logloss": 3.4966784827317126,
            "mae": 0.3230288755794703,
            "precision": 0.6887966804979253,
            "recall": 0.7033898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7603842550993846,
            "auditor_fn_violation": 0.02322877993739537,
            "auditor_fp_violation": 0.028784169726642193,
            "ave_precision_score": 0.7607569225245907,
            "fpr": 0.12390350877192982,
            "logloss": 4.0990609240250775,
            "mae": 0.36220016617890105,
            "precision": 0.7026315789473684,
            "recall": 0.553941908713693
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7428494291577181,
            "auditor_fn_violation": 0.026177231204301484,
            "auditor_fp_violation": 0.028187503281832525,
            "ave_precision_score": 0.7432377906638007,
            "fpr": 0.11745334796926454,
            "logloss": 3.918172433085979,
            "mae": 0.35831778542806403,
            "precision": 0.699438202247191,
            "recall": 0.527542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8627601202102005,
            "auditor_fn_violation": 0.015287180607119462,
            "auditor_fp_violation": 0.004901060791513672,
            "ave_precision_score": 0.8625806161005797,
            "fpr": 0.10307017543859649,
            "logloss": 0.9614426498381875,
            "mae": 0.23676770669486347,
            "precision": 0.7974137931034483,
            "recall": 0.7676348547717843
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8852182574601619,
            "auditor_fn_violation": 0.0019488734674133494,
            "auditor_fp_violation": 0.014760119921286037,
            "ave_precision_score": 0.8853632838607686,
            "fpr": 0.09989023051591657,
            "logloss": 0.7366453990954486,
            "mae": 0.216643123505321,
            "precision": 0.8059701492537313,
            "recall": 0.8008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 22727,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8225479901308457,
            "auditor_fn_violation": 0.04724011792967897,
            "auditor_fp_violation": 0.03306813545491636,
            "ave_precision_score": 0.823181723856139,
            "fpr": 0.13596491228070176,
            "logloss": 0.6785842226943372,
            "mae": 0.30454889726978873,
            "precision": 0.75,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8257180106728585,
            "auditor_fn_violation": 0.04068215222608793,
            "auditor_fp_violation": 0.03823678702969777,
            "ave_precision_score": 0.8265370078914593,
            "fpr": 0.1350164654226125,
            "logloss": 0.5855833988474541,
            "mae": 0.2918179236919043,
            "precision": 0.7578740157480315,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 22727,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8161179617709036,
            "auditor_fn_violation": 0.023317500181990244,
            "auditor_fp_violation": 0.014866381068951452,
            "ave_precision_score": 0.8159110799617315,
            "fpr": 0.1206140350877193,
            "logloss": 1.1227649295557962,
            "mae": 0.27593933149363054,
            "precision": 0.7649572649572649,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8312836418840545,
            "auditor_fn_violation": 0.01712124876741893,
            "auditor_fp_violation": 0.019308427245836136,
            "ave_precision_score": 0.8314064193408202,
            "fpr": 0.11306256860592755,
            "logloss": 0.9132823737781035,
            "mae": 0.25389663519443373,
            "precision": 0.7765726681127982,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6933988543685929,
            "auditor_fn_violation": 0.08215949625100095,
            "auditor_fp_violation": 0.06216340269277846,
            "ave_precision_score": 0.6862141442916656,
            "fpr": 0.17982456140350878,
            "logloss": 4.274768725104107,
            "mae": 0.36197577607013104,
            "precision": 0.6611570247933884,
            "recall": 0.6639004149377593
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6881853466228056,
            "auditor_fn_violation": 0.06595704106122906,
            "auditor_fp_violation": 0.06508155197547565,
            "ave_precision_score": 0.6765478484187561,
            "fpr": 0.18331503841931943,
            "logloss": 3.611755772267829,
            "mae": 0.3238473081511849,
            "precision": 0.6763565891472868,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6995998623801882,
            "auditor_fn_violation": 0.07845599475868094,
            "auditor_fp_violation": 0.05796868625050999,
            "ave_precision_score": 0.6939183115402957,
            "fpr": 0.16337719298245615,
            "logloss": 4.251047173201808,
            "mae": 0.36329650164002397,
            "precision": 0.6703539823008849,
            "recall": 0.6286307053941909
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6894255311618418,
            "auditor_fn_violation": 0.06867569629202404,
            "auditor_fp_violation": 0.0580127972715157,
            "ave_precision_score": 0.6794502374158621,
            "fpr": 0.16575192096597147,
            "logloss": 3.5618938295314493,
            "mae": 0.3248715205570878,
            "precision": 0.6860706860706861,
            "recall": 0.6991525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8156776584287391,
            "auditor_fn_violation": 0.01764395428405038,
            "auditor_fp_violation": 0.012239902080783356,
            "ave_precision_score": 0.8160561497339053,
            "fpr": 0.1206140350877193,
            "logloss": 0.9802037787559671,
            "mae": 0.28711449362492597,
            "precision": 0.7603485838779956,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8396307531122363,
            "auditor_fn_violation": 0.009921114811438356,
            "auditor_fp_violation": 0.024414333544204095,
            "ave_precision_score": 0.8399503181166661,
            "fpr": 0.10976948408342481,
            "logloss": 0.7735343334894698,
            "mae": 0.26234889366703235,
            "precision": 0.7752808988764045,
            "recall": 0.7309322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8129015095809191,
            "auditor_fn_violation": 0.01752566062459052,
            "auditor_fp_violation": 0.012714198286413713,
            "ave_precision_score": 0.812814635505928,
            "fpr": 0.12171052631578948,
            "logloss": 0.9791867978105808,
            "mae": 0.2908048917951337,
            "precision": 0.7533333333333333,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8245878158029661,
            "auditor_fn_violation": 0.009330406147091113,
            "auditor_fp_violation": 0.013099825218976369,
            "ave_precision_score": 0.8236125163258803,
            "fpr": 0.10757409440175632,
            "logloss": 0.8348260697286836,
            "mae": 0.2712485143222922,
            "precision": 0.7757437070938215,
            "recall": 0.7182203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7852331759849865,
            "auditor_fn_violation": 0.00982747324743394,
            "auditor_fp_violation": 0.01957109343125256,
            "ave_precision_score": 0.7863574599103249,
            "fpr": 0.15899122807017543,
            "logloss": 1.2181784764944983,
            "mae": 0.28295161534688734,
            "precision": 0.722753346080306,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7962859344360631,
            "auditor_fn_violation": 0.008900165584475997,
            "auditor_fp_violation": 0.019233413930972748,
            "ave_precision_score": 0.7972913112092136,
            "fpr": 0.15367727771679474,
            "logloss": 1.0532077940871434,
            "mae": 0.2619575479323311,
            "precision": 0.7333333333333333,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8415275053020226,
            "auditor_fn_violation": 0.0345053505132125,
            "auditor_fp_violation": 0.01874745002039984,
            "ave_precision_score": 0.8418640099010324,
            "fpr": 0.08552631578947369,
            "logloss": 0.9244064230704075,
            "mae": 0.31017953186156855,
            "precision": 0.8120481927710843,
            "recall": 0.6991701244813278
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.859594601297022,
            "auditor_fn_violation": 0.023842304042865917,
            "auditor_fp_violation": 0.017305571738983668,
            "ave_precision_score": 0.8598233500990596,
            "fpr": 0.0801317233809001,
            "logloss": 0.6449020877819257,
            "mae": 0.2950718103129394,
            "precision": 0.821078431372549,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8228168989487026,
            "auditor_fn_violation": 0.05350740700298463,
            "auditor_fp_violation": 0.02083333333333334,
            "ave_precision_score": 0.8235078110761589,
            "fpr": 0.08771929824561403,
            "logloss": 0.7886099553208278,
            "mae": 0.30753820465853265,
            "precision": 0.80440097799511,
            "recall": 0.6825726141078838
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8315015618745936,
            "auditor_fn_violation": 0.03904723808815048,
            "auditor_fp_violation": 0.028425045445566594,
            "ave_precision_score": 0.8322926658106439,
            "fpr": 0.08781558726673985,
            "logloss": 0.62198451287636,
            "mae": 0.29207584116978363,
            "precision": 0.814385150812065,
            "recall": 0.7436440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.805439953515007,
            "auditor_fn_violation": 0.01914082405183083,
            "auditor_fp_violation": 0.010276417788657696,
            "ave_precision_score": 0.8050993943926954,
            "fpr": 0.1206140350877193,
            "logloss": 1.109745668938559,
            "mae": 0.28328220393558406,
            "precision": 0.7608695652173914,
            "recall": 0.7261410788381742
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.813691505864553,
            "auditor_fn_violation": 0.016911942547768333,
            "auditor_fp_violation": 0.021871382170335237,
            "ave_precision_score": 0.8127004912481122,
            "fpr": 0.11306256860592755,
            "logloss": 0.9680867399699715,
            "mae": 0.26413586328728356,
            "precision": 0.7695749440715883,
            "recall": 0.7288135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7864498485599402,
            "auditor_fn_violation": 0.04665092451044624,
            "auditor_fp_violation": 0.02728478172174623,
            "ave_precision_score": 0.7871101508654779,
            "fpr": 0.10416666666666667,
            "logloss": 0.9398409132245064,
            "mae": 0.33328969049752116,
            "precision": 0.76010101010101,
            "recall": 0.6244813278008299
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7817487473622345,
            "auditor_fn_violation": 0.03779605201957246,
            "auditor_fp_violation": 0.027962463337242362,
            "ave_precision_score": 0.7826119886072991,
            "fpr": 0.09549945115257959,
            "logloss": 0.7654933424804105,
            "mae": 0.32310581378028297,
            "precision": 0.7786259541984732,
            "recall": 0.6483050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6931091402047649,
            "auditor_fn_violation": 0.08149523185557254,
            "auditor_fp_violation": 0.06116891064871481,
            "ave_precision_score": 0.6860674794570307,
            "fpr": 0.17763157894736842,
            "logloss": 4.233720536162228,
            "mae": 0.3617370356969463,
            "precision": 0.6625,
            "recall": 0.6597510373443983
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.685738212899197,
            "auditor_fn_violation": 0.0667547303205641,
            "auditor_fp_violation": 0.061465910199060336,
            "ave_precision_score": 0.6748993237347515,
            "fpr": 0.1778265642151482,
            "logloss": 3.6100928803852055,
            "mae": 0.3248850334483137,
            "precision": 0.6772908366533864,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7977811246337951,
            "auditor_fn_violation": 0.028940998762466336,
            "auditor_fp_violation": 0.027185332517339865,
            "ave_precision_score": 0.7976998496873018,
            "fpr": 0.15460526315789475,
            "logloss": 1.2076064502028605,
            "mae": 0.2912577168247954,
            "precision": 0.7229862475442044,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8163186136224758,
            "auditor_fn_violation": 0.02380509404826137,
            "auditor_fp_violation": 0.036273938624105787,
            "ave_precision_score": 0.8161199546614422,
            "fpr": 0.14818880351262348,
            "logloss": 0.9682997987693542,
            "mae": 0.2601124333870442,
            "precision": 0.7347740667976425,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7213398272253673,
            "auditor_fn_violation": 0.036359376137439045,
            "auditor_fp_violation": 0.026971134230926157,
            "ave_precision_score": 0.7218493829232884,
            "fpr": 0.09539473684210527,
            "logloss": 3.062334104925867,
            "mae": 0.3760664662437714,
            "precision": 0.7363636363636363,
            "recall": 0.504149377593361
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7200449408907539,
            "auditor_fn_violation": 0.03796117137063016,
            "auditor_fp_violation": 0.0288051129075411,
            "ave_precision_score": 0.7205864563567058,
            "fpr": 0.09440175631174534,
            "logloss": 2.555462248428101,
            "mae": 0.3702286854746258,
            "precision": 0.7252396166134185,
            "recall": 0.4809322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8140289119829947,
            "auditor_fn_violation": 0.018785943073451262,
            "auditor_fp_violation": 0.005036209710322318,
            "ave_precision_score": 0.8146360083730495,
            "fpr": 0.11513157894736842,
            "logloss": 0.9099877706748681,
            "mae": 0.2864490631271567,
            "precision": 0.7671840354767184,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8300056771360098,
            "auditor_fn_violation": 0.005800107908984353,
            "auditor_fp_violation": 0.017200553098174927,
            "ave_precision_score": 0.8304244346333653,
            "fpr": 0.10647639956092206,
            "logloss": 0.7535537331011216,
            "mae": 0.2690609034544358,
            "precision": 0.7770114942528735,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8222369845437183,
            "auditor_fn_violation": 0.04798855281356921,
            "auditor_fp_violation": 0.03434567523459812,
            "ave_precision_score": 0.8228720210294789,
            "fpr": 0.13925438596491227,
            "logloss": 0.6804332103880193,
            "mae": 0.30490773024286105,
            "precision": 0.7449799196787149,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8253073752768683,
            "auditor_fn_violation": 0.04167519395709687,
            "auditor_fp_violation": 0.03823678702969777,
            "ave_precision_score": 0.8261263823631028,
            "fpr": 0.1350164654226125,
            "logloss": 0.5874980652742915,
            "mae": 0.2922399691180415,
            "precision": 0.757396449704142,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7704632074685276,
            "auditor_fn_violation": 0.01893153526970955,
            "auditor_fp_violation": 0.011857405140758876,
            "ave_precision_score": 0.7677604783370604,
            "fpr": 0.13157894736842105,
            "logloss": 1.2586896862866088,
            "mae": 0.2947258090706947,
            "precision": 0.7430406852248393,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8220655182552314,
            "auditor_fn_violation": 0.014865392844518046,
            "auditor_fp_violation": 0.028405041894936357,
            "ave_precision_score": 0.8215322895300338,
            "fpr": 0.11855104281009879,
            "logloss": 0.8537342544103805,
            "mae": 0.26377071252282,
            "precision": 0.7636761487964989,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5145062061037164,
            "auditor_fn_violation": 0.0013035051321249357,
            "auditor_fp_violation": 0.0011117911056711545,
            "ave_precision_score": 0.5293754827468521,
            "fpr": 0.0021929824561403508,
            "logloss": 18.04842080396305,
            "mae": 0.5256391021539136,
            "precision": 0.7142857142857143,
            "recall": 0.01037344398340249
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5131241948908906,
            "auditor_fn_violation": 9.302498651146689e-06,
            "auditor_fp_violation": 0.0005575989738178526,
            "ave_precision_score": 0.5221876553185043,
            "fpr": 0.0010976948408342481,
            "logloss": 17.713319241835872,
            "mae": 0.5152503274655216,
            "precision": 0.8,
            "recall": 0.00847457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.813129181806242,
            "auditor_fn_violation": 0.0190498289291694,
            "auditor_fp_violation": 0.009664422684618527,
            "ave_precision_score": 0.8134912133145659,
            "fpr": 0.12280701754385964,
            "logloss": 1.0006009445475545,
            "mae": 0.28208310958745925,
            "precision": 0.7586206896551724,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.830390410454294,
            "auditor_fn_violation": 0.007646653891235191,
            "auditor_fp_violation": 0.022924069022251452,
            "ave_precision_score": 0.8307005959499534,
            "fpr": 0.1119648737650933,
            "logloss": 0.8314038768162016,
            "mae": 0.26349122967407185,
            "precision": 0.775330396475771,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8042477684422983,
            "auditor_fn_violation": 0.025101004586154184,
            "auditor_fp_violation": 0.012296001631986955,
            "ave_precision_score": 0.8053926824555895,
            "fpr": 0.10635964912280702,
            "logloss": 0.6346370657570758,
            "mae": 0.3048843860859018,
            "precision": 0.789587852494577,
            "recall": 0.7551867219917012
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8305821875793264,
            "auditor_fn_violation": 0.017591024949301388,
            "auditor_fp_violation": 0.01653043415206199,
            "ave_precision_score": 0.831873133432655,
            "fpr": 0.09220636663007684,
            "logloss": 0.49606522265017367,
            "mae": 0.28910415850616605,
            "precision": 0.8133333333333334,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7610559369889236,
            "auditor_fn_violation": 0.0010600931790056053,
            "auditor_fp_violation": 0.0014585883312933452,
            "ave_precision_score": 0.528956796987973,
            "fpr": 0.4692982456140351,
            "logloss": 16.061209540832525,
            "mae": 0.4710582886260159,
            "precision": 0.5286343612334802,
            "recall": 0.995850622406639
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.7566095716601952,
            "auditor_fn_violation": 0.000916296117137063,
            "auditor_fp_violation": 0.0006201100695373386,
            "ave_precision_score": 0.5183201892004379,
            "fpr": 0.47859495060373214,
            "logloss": 16.471645041853964,
            "mae": 0.48090817470974506,
            "precision": 0.5187637969094923,
            "recall": 0.9957627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.741024794383272,
            "auditor_fn_violation": 0.063298482201354,
            "auditor_fp_violation": 0.05512290901672788,
            "ave_precision_score": 0.7249611455103266,
            "fpr": 0.1787280701754386,
            "logloss": 4.536832141181572,
            "mae": 0.338426740399408,
            "precision": 0.6726907630522089,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7559869758298254,
            "auditor_fn_violation": 0.051231185696478075,
            "auditor_fp_violation": 0.056465022541501125,
            "ave_precision_score": 0.7344034579252607,
            "fpr": 0.17233809001097694,
            "logloss": 3.817937096359834,
            "mae": 0.3015576312593651,
            "precision": 0.6945525291828794,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7812051605742913,
            "auditor_fn_violation": 0.015496469389240737,
            "auditor_fp_violation": 0.008175234598123214,
            "ave_precision_score": 0.7802046745445668,
            "fpr": 0.10855263157894737,
            "logloss": 1.2429607863013137,
            "mae": 0.3028120189397091,
            "precision": 0.7614457831325301,
            "recall": 0.6556016597510373
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7904321303848124,
            "auditor_fn_violation": 0.00870713873746489,
            "auditor_fp_violation": 0.010031780641063786,
            "ave_precision_score": 0.7886671372087144,
            "fpr": 0.10757409440175632,
            "logloss": 1.1113609129467823,
            "mae": 0.28638487730255685,
            "precision": 0.7632850241545893,
            "recall": 0.6694915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 22727,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.5947142315191523,
            "auditor_fn_violation": 0.03780847346582224,
            "auditor_fp_violation": 0.03425897592819258,
            "ave_precision_score": 0.5599425709673731,
            "fpr": 0.27960526315789475,
            "logloss": 4.089430548688604,
            "mae": 0.39656752227110387,
            "precision": 0.6076923076923076,
            "recall": 0.8195020746887967
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.5770334789987193,
            "auditor_fn_violation": 0.030777316787289066,
            "auditor_fp_violation": 0.038511835850863554,
            "ave_precision_score": 0.5388917971898943,
            "fpr": 0.29418221734357847,
            "logloss": 4.5090640871796035,
            "mae": 0.4058443856169265,
            "precision": 0.5982008995502249,
            "recall": 0.8453389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6103638765816211,
            "auditor_fn_violation": 0.008191835917594818,
            "auditor_fp_violation": 0.01970624235006121,
            "ave_precision_score": 0.5691796819457875,
            "fpr": 0.24561403508771928,
            "logloss": 6.6051550568201565,
            "mae": 0.43247206960686374,
            "precision": 0.5813084112149532,
            "recall": 0.6452282157676349
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.615959946239584,
            "auditor_fn_violation": 0.01002111667193809,
            "auditor_fp_violation": 0.020658666913377133,
            "ave_precision_score": 0.5714507004366758,
            "fpr": 0.2535675082327113,
            "logloss": 6.863855684018235,
            "mae": 0.44557247215984896,
            "precision": 0.5625,
            "recall": 0.6292372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8621754537773103,
            "auditor_fn_violation": 0.01106728179369586,
            "auditor_fp_violation": 0.0029069767441860456,
            "ave_precision_score": 0.8624184423769361,
            "fpr": 0.10964912280701754,
            "logloss": 0.9896309337465311,
            "mae": 0.23735972389848864,
            "precision": 0.7885835095137421,
            "recall": 0.7738589211618258
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8869084839101216,
            "auditor_fn_violation": 0.005507079201473515,
            "auditor_fp_violation": 0.012992306134338848,
            "ave_precision_score": 0.8870476821784915,
            "fpr": 0.10098792535675083,
            "logloss": 0.7433744969553097,
            "mae": 0.21436543232605648,
            "precision": 0.8050847457627118,
            "recall": 0.8050847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7536976448551956,
            "auditor_fn_violation": 0.02311731091213511,
            "auditor_fp_violation": 0.008611281109751125,
            "ave_precision_score": 0.7508179395003851,
            "fpr": 0.12171052631578948,
            "logloss": 1.1798512654811535,
            "mae": 0.31817934019829514,
            "precision": 0.7394366197183099,
            "recall": 0.6535269709543569
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8047593949464926,
            "auditor_fn_violation": 0.013195594336638826,
            "auditor_fp_violation": 0.025059448052029237,
            "ave_precision_score": 0.8042952097783571,
            "fpr": 0.10537870472008781,
            "logloss": 0.8250171511917216,
            "mae": 0.2939785927581893,
            "precision": 0.7681159420289855,
            "recall": 0.673728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7816064136930108,
            "auditor_fn_violation": 0.011506333260537233,
            "auditor_fp_violation": 0.018793349653202777,
            "ave_precision_score": 0.7829626052561758,
            "fpr": 0.15460526315789475,
            "logloss": 1.2680213783448104,
            "mae": 0.28444183252223143,
            "precision": 0.7267441860465116,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.794811771524432,
            "auditor_fn_violation": 0.002472139016539842,
            "auditor_fp_violation": 0.017483103250827022,
            "ave_precision_score": 0.7953076353791149,
            "fpr": 0.15587266739846323,
            "logloss": 1.0889503380145753,
            "mae": 0.2629507033493864,
            "precision": 0.7253384912959381,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8036147014223569,
            "auditor_fn_violation": 0.01860850258426149,
            "auditor_fp_violation": 0.011408608731130154,
            "ave_precision_score": 0.8033413062081535,
            "fpr": 0.11403508771929824,
            "logloss": 1.1328736357255842,
            "mae": 0.2893526158898039,
            "precision": 0.7609195402298851,
            "recall": 0.6867219917012448
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.81307421593715,
            "auditor_fn_violation": 0.011525795828759603,
            "auditor_fp_violation": 0.024141785166867127,
            "ave_precision_score": 0.8121113025547477,
            "fpr": 0.09769484083424808,
            "logloss": 0.9908202883194145,
            "mae": 0.2695239855565788,
            "precision": 0.7900943396226415,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8436421442572302,
            "auditor_fn_violation": 0.034195967096163654,
            "auditor_fp_violation": 0.010850163198694413,
            "ave_precision_score": 0.843905989341355,
            "fpr": 0.07785087719298246,
            "logloss": 0.9526448537891976,
            "mae": 0.3113050464619307,
            "precision": 0.8211586901763224,
            "recall": 0.6763485477178424
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8543104545051943,
            "auditor_fn_violation": 0.017293344992464984,
            "auditor_fp_violation": 0.015625273486043773,
            "ave_precision_score": 0.8545211992777871,
            "fpr": 0.06695938529088913,
            "logloss": 0.6725838010139301,
            "mae": 0.29701161224758404,
            "precision": 0.8390501319261213,
            "recall": 0.673728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8129495675724884,
            "auditor_fn_violation": 0.016415520128121135,
            "auditor_fp_violation": 0.010562015503875971,
            "ave_precision_score": 0.8133227699270861,
            "fpr": 0.12719298245614036,
            "logloss": 0.994210960609102,
            "mae": 0.27892661779029293,
            "precision": 0.7563025210084033,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8252042740360194,
            "auditor_fn_violation": 0.008288526298163689,
            "auditor_fp_violation": 0.022994081449457283,
            "ave_precision_score": 0.8254821745838246,
            "fpr": 0.1163556531284303,
            "logloss": 0.8515951024710999,
            "mae": 0.26344217743205606,
            "precision": 0.771551724137931,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8162104448878409,
            "auditor_fn_violation": 0.013346709616364569,
            "auditor_fp_violation": 0.008751529987760104,
            "ave_precision_score": 0.8162243776633752,
            "fpr": 0.11842105263157894,
            "logloss": 1.0391590546027807,
            "mae": 0.2754576371508692,
            "precision": 0.7677419354838709,
            "recall": 0.7406639004149378
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8334762471270157,
            "auditor_fn_violation": 0.007907123853467044,
            "auditor_fp_violation": 0.01936343701006929,
            "ave_precision_score": 0.8336760968217403,
            "fpr": 0.11525795828759605,
            "logloss": 0.8614875146786177,
            "mae": 0.2585711608172445,
            "precision": 0.7692307692307693,
            "recall": 0.7415254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7642717693800016,
            "auditor_fn_violation": 0.011747470335590014,
            "auditor_fp_violation": 0.01348174214606283,
            "ave_precision_score": 0.7646678224103018,
            "fpr": 0.09758771929824561,
            "logloss": 3.39234548103976,
            "mae": 0.36290506835317615,
            "precision": 0.7435158501440923,
            "recall": 0.5352697095435685
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7448244415604597,
            "auditor_fn_violation": 0.008781558726673985,
            "auditor_fp_violation": 0.016973012709755982,
            "ave_precision_score": 0.7452064745493772,
            "fpr": 0.10208562019758508,
            "logloss": 3.2689399435525135,
            "mae": 0.3684462660303429,
            "precision": 0.7173252279635258,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.750659761263318,
            "auditor_fn_violation": 0.011069556671762393,
            "auditor_fp_violation": 0.007216442268461857,
            "ave_precision_score": 0.7401345002083984,
            "fpr": 0.24013157894736842,
            "logloss": 2.0758702023417825,
            "mae": 0.3461056635415695,
            "precision": 0.6368159203980099,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7780245210724492,
            "auditor_fn_violation": 0.011162998381365235,
            "auditor_fp_violation": 0.004140734980459034,
            "ave_precision_score": 0.768242598797251,
            "fpr": 0.23710208562019758,
            "logloss": 1.8503778467373881,
            "mae": 0.33228162802444366,
            "precision": 0.64,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8146620436445285,
            "auditor_fn_violation": 0.02428659823833443,
            "auditor_fp_violation": 0.01822470420236639,
            "ave_precision_score": 0.8154303406917001,
            "fpr": 0.13267543859649122,
            "logloss": 1.0406827587909768,
            "mae": 0.28616889807140733,
            "precision": 0.7479166666666667,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.839991783622762,
            "auditor_fn_violation": 0.015758432715027262,
            "auditor_fp_violation": 0.02717732397500557,
            "ave_precision_score": 0.8402922757508496,
            "fpr": 0.12952799121844127,
            "logloss": 0.8119869653384887,
            "mae": 0.2587028755981545,
            "precision": 0.7531380753138075,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6409426861522902,
            "auditor_fn_violation": 0.020856082113998694,
            "auditor_fp_violation": 0.01665391676866585,
            "ave_precision_score": 0.637026764130477,
            "fpr": 0.06469298245614036,
            "logloss": 10.490148378276086,
            "mae": 0.4571466202927127,
            "precision": 0.6844919786096256,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6371070336864906,
            "auditor_fn_violation": 0.01153974957673632,
            "auditor_fp_violation": 0.015345223777220458,
            "ave_precision_score": 0.6335715168279026,
            "fpr": 0.05378704720087816,
            "logloss": 10.014272727144364,
            "mae": 0.4429778142002771,
            "precision": 0.72,
            "recall": 0.2669491525423729
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7319664276616911,
            "auditor_fn_violation": 0.012006806435175082,
            "auditor_fp_violation": 0.015605875152998777,
            "ave_precision_score": 0.7304913270085889,
            "fpr": 0.10416666666666667,
            "logloss": 3.6388171751502307,
            "mae": 0.3648587807701881,
            "precision": 0.7338935574229691,
            "recall": 0.5435684647302904
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.734710709636593,
            "auditor_fn_violation": 0.0011883942026828527,
            "auditor_fp_violation": 0.00867904052969402,
            "ave_precision_score": 0.7345567240672677,
            "fpr": 0.10867178924259056,
            "logloss": 3.3464664013208933,
            "mae": 0.3714812050841696,
            "precision": 0.7018072289156626,
            "recall": 0.4936440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8225376828934003,
            "auditor_fn_violation": 0.04097510373443984,
            "auditor_fp_violation": 0.04306915544675643,
            "ave_precision_score": 0.8231732359457383,
            "fpr": 0.17543859649122806,
            "logloss": 0.695416514909238,
            "mae": 0.30898918139638437,
            "precision": 0.7090909090909091,
            "recall": 0.8091286307053942
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8272663609752768,
            "auditor_fn_violation": 0.03854025191166348,
            "auditor_fp_violation": 0.043135156490277035,
            "ave_precision_score": 0.8280824013576478,
            "fpr": 0.17453347969264543,
            "logloss": 0.6091662411925154,
            "mae": 0.2969560420617352,
            "precision": 0.7145421903052065,
            "recall": 0.8432203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8348583708869248,
            "auditor_fn_violation": 0.042940598383926616,
            "auditor_fp_violation": 0.039218686250510004,
            "ave_precision_score": 0.8353210356080725,
            "fpr": 0.1425438596491228,
            "logloss": 0.6346959767282605,
            "mae": 0.30441272191360996,
            "precision": 0.7373737373737373,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.864658507595665,
            "auditor_fn_violation": 0.03792163575136282,
            "auditor_fp_violation": 0.036368955489599404,
            "ave_precision_score": 0.8648310076843568,
            "fpr": 0.132821075740944,
            "logloss": 0.5226461304120966,
            "mae": 0.2795958384064395,
            "precision": 0.7618110236220472,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7697771266899925,
            "auditor_fn_violation": 0.01783504404163937,
            "auditor_fp_violation": 0.011857405140758876,
            "ave_precision_score": 0.7671842594486408,
            "fpr": 0.13157894736842105,
            "logloss": 1.2541372936272854,
            "mae": 0.29521347957653227,
            "precision": 0.7430406852248393,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8214158262512586,
            "auditor_fn_violation": 0.014865392844518046,
            "auditor_fp_violation": 0.027854944252604843,
            "ave_precision_score": 0.8209131777519938,
            "fpr": 0.11964873765093303,
            "logloss": 0.8676565698019484,
            "mae": 0.2637836681634315,
            "precision": 0.7620087336244541,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7501791547608836,
            "auditor_fn_violation": 0.011504058382470699,
            "auditor_fp_violation": 0.01463178294573646,
            "ave_precision_score": 0.7383681198821657,
            "fpr": 0.24232456140350878,
            "logloss": 2.2407476151870926,
            "mae": 0.3472034758142472,
            "precision": 0.632890365448505,
            "recall": 0.7904564315352697
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7770095421103138,
            "auditor_fn_violation": 0.010521125974436734,
            "auditor_fp_violation": 0.009379164801752313,
            "ave_precision_score": 0.7672173501224306,
            "fpr": 0.2283205268935236,
            "logloss": 1.9516077748651464,
            "mae": 0.32970453049460036,
            "precision": 0.6480541455160744,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7091179195762984,
            "auditor_fn_violation": 0.0799665137948606,
            "auditor_fp_violation": 0.059496124031007756,
            "ave_precision_score": 0.7030887853361066,
            "fpr": 0.17324561403508773,
            "logloss": 4.175937531550259,
            "mae": 0.3549436747187835,
            "precision": 0.6694560669456067,
            "recall": 0.6639004149377593
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7020053027080029,
            "auditor_fn_violation": 0.06339885393216618,
            "auditor_fp_violation": 0.059753106176346306,
            "ave_precision_score": 0.6911687936207711,
            "fpr": 0.17014270032930845,
            "logloss": 3.492787624663663,
            "mae": 0.3133500912207481,
            "precision": 0.69,
            "recall": 0.7309322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7096892750501357,
            "auditor_fn_violation": 0.0689788527334935,
            "auditor_fp_violation": 0.07570889432884538,
            "ave_precision_score": 0.6920561180302353,
            "fpr": 0.27631578947368424,
            "logloss": 4.196926741818,
            "mae": 0.3935554981625548,
            "precision": 0.6,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7063235516657265,
            "auditor_fn_violation": 0.05938715138886305,
            "auditor_fp_violation": 0.0867779030777963,
            "ave_precision_score": 0.6811905583935101,
            "fpr": 0.287596048298573,
            "logloss": 4.022758268395701,
            "mae": 0.37434012795011123,
            "precision": 0.599388379204893,
            "recall": 0.8305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8194868344308981,
            "auditor_fn_violation": 0.01686139622916212,
            "auditor_fp_violation": 0.009501223990208082,
            "ave_precision_score": 0.8200838110826882,
            "fpr": 0.10855263157894737,
            "logloss": 0.907110157317691,
            "mae": 0.28729742358558163,
            "precision": 0.775,
            "recall": 0.7074688796680498
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8340921857232803,
            "auditor_fn_violation": 0.0052582373625555895,
            "auditor_fp_violation": 0.015055172293082024,
            "ave_precision_score": 0.8345230099129466,
            "fpr": 0.10208562019758508,
            "logloss": 0.7522444596560705,
            "mae": 0.26954742779330193,
            "precision": 0.7827102803738317,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.838309428391685,
            "auditor_fn_violation": 0.0191453738079639,
            "auditor_fp_violation": 0.006629946960424322,
            "ave_precision_score": 0.8385766405421162,
            "fpr": 0.10964912280701754,
            "logloss": 0.8790313659920902,
            "mae": 0.2861167325714907,
            "precision": 0.7737556561085973,
            "recall": 0.7095435684647303
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8509552347956642,
            "auditor_fn_violation": 0.00995134793205455,
            "auditor_fp_violation": 0.020343610990950896,
            "ave_precision_score": 0.8516779190073982,
            "fpr": 0.09001097694840834,
            "logloss": 0.6897391418587722,
            "mae": 0.2627423889480059,
            "precision": 0.8070588235294117,
            "recall": 0.7266949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8059500076619814,
            "auditor_fn_violation": 0.023872570430224938,
            "auditor_fp_violation": 0.01926764585883314,
            "ave_precision_score": 0.8051884363541539,
            "fpr": 0.14364035087719298,
            "logloss": 1.0838512434304393,
            "mae": 0.28551575036949584,
            "precision": 0.7364185110663984,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8116647933970108,
            "auditor_fn_violation": 0.019721297140411917,
            "auditor_fp_violation": 0.027434869689369864,
            "ave_precision_score": 0.8100535088215267,
            "fpr": 0.1350164654226125,
            "logloss": 0.9117097008436361,
            "mae": 0.2589442434789387,
            "precision": 0.7484662576687117,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7243086382111168,
            "auditor_fn_violation": 0.07058719152653417,
            "auditor_fp_violation": 0.07699918400652794,
            "ave_precision_score": 0.7122752029976083,
            "fpr": 0.24561403508771928,
            "logloss": 3.522273280685724,
            "mae": 0.3729489009525192,
            "precision": 0.6196943972835314,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.72781979842925,
            "auditor_fn_violation": 0.06005693129174497,
            "auditor_fp_violation": 0.0863253227447872,
            "ave_precision_score": 0.711105349112596,
            "fpr": 0.24698133918770582,
            "logloss": 3.2130378280564007,
            "mae": 0.3466543393321899,
            "precision": 0.6305418719211823,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7758975840042172,
            "auditor_fn_violation": 0.016392771347455783,
            "auditor_fp_violation": 0.010174418604651164,
            "ave_precision_score": 0.773823341751029,
            "fpr": 0.13267543859649122,
            "logloss": 1.1516231986329497,
            "mae": 0.29349406455084914,
            "precision": 0.7425531914893617,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8190673698608326,
            "auditor_fn_violation": 0.009921114811438356,
            "auditor_fp_violation": 0.018308249714324293,
            "ave_precision_score": 0.81859696769957,
            "fpr": 0.11745334796926454,
            "logloss": 0.8354398456316778,
            "mae": 0.2693110522358293,
            "precision": 0.7632743362831859,
            "recall": 0.7309322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6938545889608079,
            "auditor_fn_violation": 0.08226869039819466,
            "auditor_fp_violation": 0.06116891064871481,
            "ave_precision_score": 0.686752643844398,
            "fpr": 0.17763157894736842,
            "logloss": 4.25423061791214,
            "mae": 0.36259837339115675,
            "precision": 0.660377358490566,
            "recall": 0.6535269709543569
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6859939403998114,
            "auditor_fn_violation": 0.06742683584810881,
            "auditor_fp_violation": 0.06256360503989458,
            "ave_precision_score": 0.675172572748266,
            "fpr": 0.1778265642151482,
            "logloss": 3.579473512821059,
            "mae": 0.32453786422938335,
            "precision": 0.6779324055666004,
            "recall": 0.722457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7930221333913694,
            "auditor_fn_violation": 0.020132670888840357,
            "auditor_fp_violation": 0.011793655650754796,
            "ave_precision_score": 0.7946518271317677,
            "fpr": 0.12171052631578948,
            "logloss": 1.2032027928012297,
            "mae": 0.28994309734683316,
            "precision": 0.7571115973741794,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8140380268523204,
            "auditor_fn_violation": 0.012279298219501758,
            "auditor_fp_violation": 0.0206611673572059,
            "ave_precision_score": 0.8147388507739921,
            "fpr": 0.11745334796926454,
            "logloss": 0.9805892835778736,
            "mae": 0.2679610662666926,
            "precision": 0.7627494456762749,
            "recall": 0.7288135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7392542464452037,
            "auditor_fn_violation": 0.0803941908713693,
            "auditor_fp_violation": 0.06952009383924929,
            "ave_precision_score": 0.7250056854641753,
            "fpr": 0.20723684210526316,
            "logloss": 4.027598009471955,
            "mae": 0.35544600927998515,
            "precision": 0.65,
            "recall": 0.7282157676348547
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7402937674626175,
            "auditor_fn_violation": 0.06021972501813987,
            "auditor_fp_violation": 0.07539338232536275,
            "ave_precision_score": 0.7204335399444013,
            "fpr": 0.2217343578485181,
            "logloss": 3.557536139265403,
            "mae": 0.32480616236182713,
            "precision": 0.648695652173913,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7785788410614716,
            "auditor_fn_violation": 0.017662153308582663,
            "auditor_fp_violation": 0.015508975928192581,
            "ave_precision_score": 0.7789782132528533,
            "fpr": 0.14912280701754385,
            "logloss": 0.9163152779075715,
            "mae": 0.3093643334267177,
            "precision": 0.7224489795918367,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7919485833324669,
            "auditor_fn_violation": 0.012632793168244994,
            "auditor_fp_violation": 0.025021941394597548,
            "ave_precision_score": 0.7926415564878906,
            "fpr": 0.14709110867178923,
            "logloss": 0.7948657511700666,
            "mae": 0.2910865293018277,
            "precision": 0.726530612244898,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7794689730756763,
            "auditor_fn_violation": 0.022989917740409118,
            "auditor_fp_violation": 0.021215830273357817,
            "ave_precision_score": 0.7769143684169721,
            "fpr": 0.16447368421052633,
            "logloss": 1.1741046181672052,
            "mae": 0.2893797397829673,
            "precision": 0.715370018975332,
            "recall": 0.7821576763485477
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8302249660488381,
            "auditor_fn_violation": 0.016330536382072228,
            "auditor_fp_violation": 0.03408104938626608,
            "ave_precision_score": 0.8297479722009128,
            "fpr": 0.14709110867178923,
            "logloss": 0.8069369824294891,
            "mae": 0.25410230411907847,
            "precision": 0.7418111753371869,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7867602860501886,
            "auditor_fn_violation": 0.02869303705321395,
            "auditor_fp_violation": 0.028401672786617715,
            "ave_precision_score": 0.7853169522998893,
            "fpr": 0.17434210526315788,
            "logloss": 1.314671994406916,
            "mae": 0.2944100990481407,
            "precision": 0.7044609665427509,
            "recall": 0.7863070539419087
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8089886007507568,
            "auditor_fn_violation": 0.02525860946250163,
            "auditor_fp_violation": 0.03787672311835351,
            "ave_precision_score": 0.8059922881846042,
            "fpr": 0.16575192096597147,
            "logloss": 1.1254113552704679,
            "mae": 0.26665151993183306,
            "precision": 0.7182835820895522,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6961062359040968,
            "auditor_fn_violation": 0.08103343160806581,
            "auditor_fp_violation": 0.05865973072215423,
            "ave_precision_score": 0.6891708567385703,
            "fpr": 0.17105263157894737,
            "logloss": 4.373459648668059,
            "mae": 0.36544711438819183,
            "precision": 0.6630669546436285,
            "recall": 0.6369294605809128
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.6902382640784148,
            "auditor_fn_violation": 0.06991060298796258,
            "auditor_fp_violation": 0.059968144345621366,
            "ave_precision_score": 0.6798464255322381,
            "fpr": 0.1668496158068057,
            "logloss": 3.6228779546639376,
            "mae": 0.3232273997627279,
            "precision": 0.6878850102669405,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7046954425506551,
            "auditor_fn_violation": 0.08039874062750237,
            "auditor_fp_violation": 0.05991432068543452,
            "ave_precision_score": 0.697573113770102,
            "fpr": 0.17434210526315788,
            "logloss": 4.286368306784807,
            "mae": 0.35677387766070795,
            "precision": 0.6666666666666666,
            "recall": 0.6597510373443983
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.700282837839001,
            "auditor_fn_violation": 0.06376165137956055,
            "auditor_fp_violation": 0.060883306786954694,
            "ave_precision_score": 0.6886159466824501,
            "fpr": 0.1734357848518112,
            "logloss": 3.622499538652915,
            "mae": 0.31391140473644785,
            "precision": 0.6883629191321499,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8188849458599416,
            "auditor_fn_violation": 0.01789874062750237,
            "auditor_fp_violation": 0.006818645450836392,
            "ave_precision_score": 0.8195509529743141,
            "fpr": 0.12280701754385964,
            "logloss": 0.9770624968688321,
            "mae": 0.2742063386248281,
            "precision": 0.7632135306553911,
            "recall": 0.7489626556016598
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8374399218457471,
            "auditor_fn_violation": 0.009786228580996861,
            "auditor_fp_violation": 0.021533822253449988,
            "ave_precision_score": 0.8377181127866509,
            "fpr": 0.1141602634467618,
            "logloss": 0.8115581370632868,
            "mae": 0.2576830253886829,
            "precision": 0.7719298245614035,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 22727,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7045570358269584,
            "auditor_fn_violation": 0.07973447623207397,
            "auditor_fp_violation": 0.05667074663402694,
            "ave_precision_score": 0.7036479425951503,
            "fpr": 0.1600877192982456,
            "logloss": 3.8164670877782028,
            "mae": 0.3716563525074547,
            "precision": 0.6666666666666666,
            "recall": 0.6058091286307054
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6906367279593941,
            "auditor_fn_violation": 0.06928035870434798,
            "auditor_fp_violation": 0.05405459469055758,
            "ave_precision_score": 0.686768062888482,
            "fpr": 0.15477497255762898,
            "logloss": 3.0847974289205804,
            "mae": 0.3333258390896536,
            "precision": 0.6873614190687362,
            "recall": 0.6567796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7741849451451273,
            "auditor_fn_violation": 0.010286998616874142,
            "auditor_fp_violation": 0.012846797225622214,
            "ave_precision_score": 0.7670714482919105,
            "fpr": 0.22807017543859648,
            "logloss": 1.9523914578765749,
            "mae": 0.32862627551345175,
            "precision": 0.6556291390728477,
            "recall": 0.8215767634854771
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7847063054730268,
            "auditor_fn_violation": 0.0021419003144244548,
            "auditor_fp_violation": 0.01880083714859388,
            "ave_precision_score": 0.7762490954847268,
            "fpr": 0.23380900109769484,
            "logloss": 1.8793994239897842,
            "mae": 0.31472240086961173,
            "precision": 0.6530944625407166,
            "recall": 0.8495762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.80610272566385,
            "auditor_fn_violation": 0.019113525515032394,
            "auditor_fp_violation": 0.006349449204406371,
            "ave_precision_score": 0.8059011602261312,
            "fpr": 0.12280701754385964,
            "logloss": 1.0613143393392364,
            "mae": 0.2843722998672634,
            "precision": 0.7591397849462366,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.821558579026131,
            "auditor_fn_violation": 0.009246683659230872,
            "auditor_fp_violation": 0.01977350979798915,
            "ave_precision_score": 0.8205261290666068,
            "fpr": 0.1141602634467618,
            "logloss": 0.91264868028122,
            "mae": 0.2586699380641962,
            "precision": 0.7719298245614035,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8130801631051103,
            "auditor_fn_violation": 0.011881688141515613,
            "auditor_fp_violation": 0.024303855569155455,
            "ave_precision_score": 0.813272641283221,
            "fpr": 0.22916666666666666,
            "logloss": 1.3092378911626021,
            "mae": 0.2968307719300191,
            "precision": 0.6713836477987422,
            "recall": 0.8858921161825726
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8345739194788253,
            "auditor_fn_violation": 0.005572196692031481,
            "auditor_fp_violation": 0.030527918705570242,
            "ave_precision_score": 0.8348368699849498,
            "fpr": 0.21514818880351264,
            "logloss": 1.1048251226526358,
            "mae": 0.2684715813659947,
            "precision": 0.684887459807074,
            "recall": 0.902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8173945228522839,
            "auditor_fn_violation": 0.016401870859721918,
            "auditor_fp_violation": 0.007389840881272959,
            "ave_precision_score": 0.8175238891038383,
            "fpr": 0.11842105263157894,
            "logloss": 1.028091785159822,
            "mae": 0.27514462466363776,
            "precision": 0.7692307692307693,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8338398701850647,
            "auditor_fn_violation": 0.007458278293549644,
            "auditor_fp_violation": 0.022053914569836148,
            "ave_precision_score": 0.8340971247793177,
            "fpr": 0.1141602634467618,
            "logloss": 0.8540423636939791,
            "mae": 0.2577923153665005,
            "precision": 0.7724288840262582,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7610583381009932,
            "auditor_fn_violation": 0.002447768799592342,
            "auditor_fp_violation": 0.0028559771521827876,
            "ave_precision_score": 0.528959197954929,
            "fpr": 0.46600877192982454,
            "logloss": 16.127849626152873,
            "mae": 0.4706533491331883,
            "precision": 0.5293466223698782,
            "recall": 0.991701244813278
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7566156410879352,
            "auditor_fn_violation": 0.000916296117137063,
            "auditor_fp_violation": 0.0004550807768378895,
            "ave_precision_score": 0.5183262583817463,
            "fpr": 0.47639956092206365,
            "logloss": 16.47135521293969,
            "mae": 0.47861492047938314,
            "precision": 0.5199115044247787,
            "recall": 0.9957627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8428109606219695,
            "auditor_fn_violation": 0.034236914901361284,
            "auditor_fp_violation": 0.011474908200734399,
            "ave_precision_score": 0.8430852838144123,
            "fpr": 0.07675438596491228,
            "logloss": 0.963646599440207,
            "mae": 0.3116052939419425,
            "precision": 0.8209718670076727,
            "recall": 0.6659751037344398
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8540191635220289,
            "auditor_fn_violation": 0.01703054940557034,
            "auditor_fp_violation": 0.014710111044710438,
            "ave_precision_score": 0.8542309912134519,
            "fpr": 0.06695938529088913,
            "logloss": 0.6792264616713045,
            "mae": 0.29703291834122303,
            "precision": 0.8394736842105263,
            "recall": 0.6758474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7794685165483326,
            "auditor_fn_violation": 0.02056489772148213,
            "auditor_fp_violation": 0.010786413708690335,
            "ave_precision_score": 0.7799646309697201,
            "fpr": 0.1206140350877193,
            "logloss": 1.2637195083726107,
            "mae": 0.29235957297361276,
            "precision": 0.7516930022573364,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.797806335765506,
            "auditor_fn_violation": 0.012642095666896138,
            "auditor_fp_violation": 0.022701529521490064,
            "ave_precision_score": 0.7980927175022532,
            "fpr": 0.10647639956092206,
            "logloss": 1.0611931966568013,
            "mae": 0.26462747695290856,
            "precision": 0.7780320366132724,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7537100963352177,
            "auditor_fn_violation": 0.014286234257843781,
            "auditor_fp_violation": 0.015590575275397795,
            "ave_precision_score": 0.7407406530892411,
            "fpr": 0.24342105263157895,
            "logloss": 2.225741902003548,
            "mae": 0.34723641329218674,
            "precision": 0.6336633663366337,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7803462069243214,
            "auditor_fn_violation": 0.014353755418705465,
            "auditor_fp_violation": 0.013832455260808804,
            "ave_precision_score": 0.7694212164353087,
            "fpr": 0.22941822173435786,
            "logloss": 1.9322840171427889,
            "mae": 0.32581308411927007,
            "precision": 0.6510851419031719,
            "recall": 0.826271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7856257043597347,
            "auditor_fn_violation": 0.03162762975904492,
            "auditor_fp_violation": 0.024184006527947777,
            "ave_precision_score": 0.779683597987149,
            "fpr": 0.14035087719298245,
            "logloss": 1.1798541931369158,
            "mae": 0.29806535477983537,
            "precision": 0.7434869739478958,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8059266842514987,
            "auditor_fn_violation": 0.024539991441701246,
            "auditor_fp_violation": 0.04097977390986902,
            "ave_precision_score": 0.7989469698887293,
            "fpr": 0.14709110867178923,
            "logloss": 1.0672625107315121,
            "mae": 0.2868162903188753,
            "precision": 0.728744939271255,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6934046461787493,
            "auditor_fn_violation": 0.08029182135837519,
            "auditor_fp_violation": 0.06216340269277846,
            "ave_precision_score": 0.6862262703610896,
            "fpr": 0.18311403508771928,
            "logloss": 4.220584719005655,
            "mae": 0.36100924281679797,
            "precision": 0.6577868852459017,
            "recall": 0.6659751037344398
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.693404169910247,
            "auditor_fn_violation": 0.0655919179891719,
            "auditor_fp_violation": 0.06424390329283448,
            "ave_precision_score": 0.6804790609594887,
            "fpr": 0.18221734357848518,
            "logloss": 3.6147434259121316,
            "mae": 0.31952374306006853,
            "precision": 0.6770428015564203,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8206575865913852,
            "auditor_fn_violation": 0.015846800611487227,
            "auditor_fp_violation": 0.011826805385556917,
            "ave_precision_score": 0.8209954483978918,
            "fpr": 0.12828947368421054,
            "logloss": 1.017973222781078,
            "mae": 0.27962593115495804,
            "precision": 0.755741127348643,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8405990585102654,
            "auditor_fn_violation": 0.007851308861560219,
            "auditor_fp_violation": 0.02085370153202194,
            "ave_precision_score": 0.8409174349629098,
            "fpr": 0.1251372118551043,
            "logloss": 0.8123813852559709,
            "mae": 0.2549230766331496,
            "precision": 0.7615062761506276,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 22727,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8376163728794546,
            "auditor_fn_violation": 0.03486478124772512,
            "auditor_fp_violation": 0.017752957976336192,
            "ave_precision_score": 0.8379103384846271,
            "fpr": 0.08552631578947369,
            "logloss": 0.9419008087409079,
            "mae": 0.31612465754685,
            "precision": 0.8125,
            "recall": 0.7012448132780082
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8521471792251754,
            "auditor_fn_violation": 0.0209631807103388,
            "auditor_fp_violation": 0.015200198035151241,
            "ave_precision_score": 0.8523845825639839,
            "fpr": 0.08122941822173436,
            "logloss": 0.6648523363185629,
            "mae": 0.305077538490929,
            "precision": 0.8186274509803921,
            "recall": 0.7076271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7894053365441992,
            "auditor_fn_violation": 0.010714675693382839,
            "auditor_fp_violation": 0.022057323541411673,
            "ave_precision_score": 0.7898698865131113,
            "fpr": 0.19188596491228072,
            "logloss": 1.2029479374381782,
            "mae": 0.2870821672864137,
            "precision": 0.6951219512195121,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8021552732295856,
            "auditor_fn_violation": 0.009004818694301293,
            "auditor_fp_violation": 0.022924069022251463,
            "ave_precision_score": 0.8024899933160725,
            "fpr": 0.17233809001097694,
            "logloss": 1.0435211400109143,
            "mae": 0.2612749504655545,
            "precision": 0.7211367673179396,
            "recall": 0.8601694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7222257968244532,
            "auditor_fn_violation": 0.08358356992065227,
            "auditor_fp_violation": 0.07428600571195432,
            "ave_precision_score": 0.7047158600295045,
            "fpr": 0.21820175438596492,
            "logloss": 4.475906643591234,
            "mae": 0.36552233780841964,
            "precision": 0.6401446654611211,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7189815217195287,
            "auditor_fn_violation": 0.06425235818340806,
            "auditor_fp_violation": 0.08120941467110412,
            "ave_precision_score": 0.6942082725036628,
            "fpr": 0.22941822173435786,
            "logloss": 4.144988849224312,
            "mae": 0.3374324192527488,
            "precision": 0.6439522998296422,
            "recall": 0.8008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7113930688248065,
            "auditor_fn_violation": 0.078970117201718,
            "auditor_fp_violation": 0.059077927376581005,
            "ave_precision_score": 0.7056911499343766,
            "fpr": 0.17214912280701755,
            "logloss": 4.027730740286667,
            "mae": 0.35377234869778523,
            "precision": 0.6687763713080169,
            "recall": 0.6576763485477178
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7027767029663875,
            "auditor_fn_violation": 0.0641291000762805,
            "auditor_fp_violation": 0.05931802895013866,
            "ave_precision_score": 0.6921284319321133,
            "fpr": 0.1690450054884742,
            "logloss": 3.3835656193745494,
            "mae": 0.3100407701530395,
            "precision": 0.6926147704590818,
            "recall": 0.7351694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6930676491197463,
            "auditor_fn_violation": 0.08260992210817501,
            "auditor_fp_violation": 0.060332517339861294,
            "ave_precision_score": 0.6861841951630985,
            "fpr": 0.17543859649122806,
            "logloss": 4.317933790177303,
            "mae": 0.3613913762667033,
            "precision": 0.6638655462184874,
            "recall": 0.6556016597510373
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6848407711757936,
            "auditor_fn_violation": 0.06633146663193734,
            "auditor_fp_violation": 0.06298367960312956,
            "ave_precision_score": 0.6730191388695732,
            "fpr": 0.17892425905598244,
            "logloss": 3.6923337278136334,
            "mae": 0.3281922122582757,
            "precision": 0.6746506986027944,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8180411021565845,
            "auditor_fn_violation": 0.020210016743102573,
            "auditor_fp_violation": 0.007606589147286828,
            "ave_precision_score": 0.8183717017206081,
            "fpr": 0.11951754385964912,
            "logloss": 1.0658664323148077,
            "mae": 0.27390925663112187,
            "precision": 0.7685774946921444,
            "recall": 0.7510373443983402
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8339261461586209,
            "auditor_fn_violation": 0.011437422091573796,
            "auditor_fp_violation": 0.021371293404579314,
            "ave_precision_score": 0.8340665232095259,
            "fpr": 0.1119648737650933,
            "logloss": 0.8694706436844328,
            "mae": 0.2541734396892871,
            "precision": 0.7782608695652173,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7320543107413835,
            "auditor_fn_violation": 0.07234567227196623,
            "auditor_fp_violation": 0.06186760505915955,
            "ave_precision_score": 0.7261334957750524,
            "fpr": 0.1875,
            "logloss": 3.945515535346767,
            "mae": 0.34453754875187836,
            "precision": 0.6666666666666666,
            "recall": 0.7095435684647303
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7252154262005772,
            "auditor_fn_violation": 0.06082671305512661,
            "auditor_fp_violation": 0.06190098742526799,
            "ave_precision_score": 0.7142678319459859,
            "fpr": 0.18111964873765093,
            "logloss": 3.4338147643939947,
            "mae": 0.30684232133877004,
            "precision": 0.6851145038167938,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8615138070162802,
            "auditor_fn_violation": 0.013144245468442893,
            "auditor_fp_violation": 0.007624439004487969,
            "ave_precision_score": 0.861476347722095,
            "fpr": 0.10964912280701754,
            "logloss": 0.9993392959438958,
            "mae": 0.23862802984118583,
            "precision": 0.788135593220339,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8857910045949022,
            "auditor_fn_violation": 0.0030628476808870863,
            "auditor_fp_violation": 0.013019811016455425,
            "ave_precision_score": 0.8859469865712887,
            "fpr": 0.10208562019758508,
            "logloss": 0.7483161618419946,
            "mae": 0.21518178379111386,
            "precision": 0.8029661016949152,
            "recall": 0.8029661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7465266699842505,
            "auditor_fn_violation": 0.0477974630559802,
            "auditor_fp_violation": 0.061760505915952675,
            "ave_precision_score": 0.7169651511047541,
            "fpr": 0.22478070175438597,
            "logloss": 5.204003965927235,
            "mae": 0.3421998998773879,
            "precision": 0.646551724137931,
            "recall": 0.7780082987551867
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7632671146935744,
            "auditor_fn_violation": 0.03978678673091593,
            "auditor_fp_violation": 0.0655041269825394,
            "ave_precision_score": 0.7258061317928195,
            "fpr": 0.2239297475301866,
            "logloss": 4.5773739991531865,
            "mae": 0.313352020622411,
            "precision": 0.6565656565656566,
            "recall": 0.826271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7794935559066467,
            "auditor_fn_violation": 0.02157039382689088,
            "auditor_fp_violation": 0.021215830273357817,
            "ave_precision_score": 0.7769347448460233,
            "fpr": 0.16447368421052633,
            "logloss": 1.1843881483218337,
            "mae": 0.2890826789109795,
            "precision": 0.7164461247637051,
            "recall": 0.7863070539419087
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8293193392740223,
            "auditor_fn_violation": 0.015804945208282947,
            "auditor_fp_violation": 0.03269330306129338,
            "ave_precision_score": 0.8287723213362539,
            "fpr": 0.15148188803512624,
            "logloss": 0.8171623019082668,
            "mae": 0.254442794530371,
            "precision": 0.7366412213740458,
            "recall": 0.8177966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8076234711762245,
            "auditor_fn_violation": 0.028292658513503686,
            "auditor_fp_violation": 0.025285597715218284,
            "ave_precision_score": 0.8079247135623314,
            "fpr": 0.13486842105263158,
            "logloss": 1.2364671065866006,
            "mae": 0.2871888672170481,
            "precision": 0.74375,
            "recall": 0.7406639004149378
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8295994844646548,
            "auditor_fn_violation": 0.019698040893784068,
            "auditor_fp_violation": 0.03385100855401834,
            "ave_precision_score": 0.8299577489217232,
            "fpr": 0.12843029637760703,
            "logloss": 0.9368015976501002,
            "mae": 0.25779546043660206,
            "precision": 0.7536842105263157,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6459410736329891,
            "auditor_fn_violation": 0.020658167722210092,
            "auditor_fp_violation": 0.01591187270501836,
            "ave_precision_score": 0.6421124860268864,
            "fpr": 0.06030701754385965,
            "logloss": 10.037770439823186,
            "mae": 0.45284696312733563,
            "precision": 0.6978021978021978,
            "recall": 0.26348547717842324
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.64734572725968,
            "auditor_fn_violation": 0.009707157342462214,
            "auditor_fp_violation": 0.013217346078929012,
            "ave_precision_score": 0.6437319994411517,
            "fpr": 0.048298572996706916,
            "logloss": 9.620280914879345,
            "mae": 0.4394090468368299,
            "precision": 0.7396449704142012,
            "recall": 0.2648305084745763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.807895526827114,
            "auditor_fn_violation": 0.01761210599111888,
            "auditor_fp_violation": 0.01649071807425541,
            "ave_precision_score": 0.8080082147585628,
            "fpr": 0.15021929824561403,
            "logloss": 0.9875927122809723,
            "mae": 0.284631054271547,
            "precision": 0.730844793713163,
            "recall": 0.7717842323651453
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8336682618561085,
            "auditor_fn_violation": 0.003037265809596459,
            "auditor_fp_violation": 0.023639195957282425,
            "ave_precision_score": 0.8339678999919579,
            "fpr": 0.14489571899012074,
            "logloss": 0.8132463001824928,
            "mae": 0.25931695684138256,
            "precision": 0.7411764705882353,
            "recall": 0.8008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8123669492364912,
            "auditor_fn_violation": 0.02484849312076872,
            "auditor_fp_violation": 0.027203182374541005,
            "ave_precision_score": 0.8122502910590151,
            "fpr": 0.15570175438596492,
            "logloss": 1.0437297166173205,
            "mae": 0.2886264116884497,
            "precision": 0.7221135029354208,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8229137292983487,
            "auditor_fn_violation": 0.025272563210478334,
            "auditor_fp_violation": 0.03437860220189085,
            "ave_precision_score": 0.8221247852630453,
            "fpr": 0.14489571899012074,
            "logloss": 0.8644100472057326,
            "mae": 0.2562387382881615,
            "precision": 0.7396449704142012,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7524000309252024,
            "auditor_fn_violation": 0.03662781174929024,
            "auditor_fp_violation": 0.015644124847001225,
            "ave_precision_score": 0.7529535565652928,
            "fpr": 0.07346491228070176,
            "logloss": 1.8752930361513074,
            "mae": 0.3825229861348766,
            "precision": 0.7673611111111112,
            "recall": 0.45850622406639
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7584000587209578,
            "auditor_fn_violation": 0.032140132839680736,
            "auditor_fp_violation": 0.015177694040692224,
            "ave_precision_score": 0.7588971046664537,
            "fpr": 0.06915477497255763,
            "logloss": 1.4986099919310056,
            "mae": 0.3753841258720735,
            "precision": 0.7758007117437722,
            "recall": 0.461864406779661
        }
    }
]