[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8474028727359126,
            "auditor_fn_violation": 0.013987059591126581,
            "auditor_fp_violation": 0.014461899491719953,
            "ave_precision_score": 0.8477154194741964,
            "fpr": 0.11951754385964912,
            "logloss": 0.6177711409883154,
            "mae": 0.2728094606045498,
            "precision": 0.7738589211618258,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8522539022636244,
            "auditor_fn_violation": 0.013896349580773994,
            "auditor_fp_violation": 0.016901015803320967,
            "ave_precision_score": 0.8525168540842731,
            "fpr": 0.12403951701427003,
            "logloss": 0.6005409697289951,
            "mae": 0.2646940533840964,
            "precision": 0.7674897119341564,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7169921483259242,
            "auditor_fn_violation": 0.02027149485283457,
            "auditor_fp_violation": 0.022022052795540255,
            "ave_precision_score": 0.6793924691879641,
            "fpr": 0.18421052631578946,
            "logloss": 3.1583807705490785,
            "mae": 0.2924332460856798,
            "precision": 0.7026548672566372,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7474826492445421,
            "auditor_fn_violation": 0.019903309433169074,
            "auditor_fp_violation": 0.021553151081142297,
            "ave_precision_score": 0.7111990484705601,
            "fpr": 0.19319429198682767,
            "logloss": 2.830104625932324,
            "mae": 0.2943656268464847,
            "precision": 0.6906854130052724,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8491672618950991,
            "auditor_fn_violation": 0.005641039582427145,
            "auditor_fp_violation": 0.006466223971142813,
            "ave_precision_score": 0.8494806046358521,
            "fpr": 0.09320175438596491,
            "logloss": 0.6096989488168174,
            "mae": 0.2790444381627627,
            "precision": 0.802784222737819,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8427933055726777,
            "auditor_fn_violation": 0.014611018987785229,
            "auditor_fp_violation": 0.013217141961065439,
            "ave_precision_score": 0.8432628594417969,
            "fpr": 0.09879253567508232,
            "logloss": 0.6094107152407597,
            "mae": 0.277297027134419,
            "precision": 0.7926267281105991,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8361926892530926,
            "auditor_fn_violation": 0.01472560533565319,
            "auditor_fp_violation": 0.011682242990654207,
            "ave_precision_score": 0.8367635133094488,
            "fpr": 0.09539473684210527,
            "logloss": 0.6687858898958214,
            "mae": 0.284279253881336,
            "precision": 0.7972027972027972,
            "recall": 0.7066115702479339
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.838623222762211,
            "auditor_fn_violation": 0.011962538244155363,
            "auditor_fp_violation": 0.014476628558485229,
            "ave_precision_score": 0.8388804571777897,
            "fpr": 0.10647639956092206,
            "logloss": 0.652200737497979,
            "mae": 0.27734250663279525,
            "precision": 0.7790432801822323,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7787878695682808,
            "auditor_fn_violation": 0.01371293678410903,
            "auditor_fp_violation": 0.01596317019183473,
            "ave_precision_score": 0.7729222347104715,
            "fpr": 0.13486842105263158,
            "logloss": 2.309551415440032,
            "mae": 0.3087387520825311,
            "precision": 0.7278761061946902,
            "recall": 0.6797520661157025
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.773932417124382,
            "auditor_fn_violation": 0.009664385641217275,
            "auditor_fp_violation": 0.01630363085592818,
            "ave_precision_score": 0.7647206588155999,
            "fpr": 0.14270032930845225,
            "logloss": 2.365904310985207,
            "mae": 0.29084467014888016,
            "precision": 0.7245762711864406,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8550846299808909,
            "auditor_fn_violation": 0.009868421052631584,
            "auditor_fp_violation": 0.010001639613051323,
            "ave_precision_score": 0.8554352155454554,
            "fpr": 0.10526315789473684,
            "logloss": 0.6310179586839422,
            "mae": 0.2697251268641627,
            "precision": 0.7908496732026143,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8532796597467422,
            "auditor_fn_violation": 0.014582992736529882,
            "auditor_fp_violation": 0.013008057229477961,
            "ave_precision_score": 0.8535924799606653,
            "fpr": 0.11306256860592755,
            "logloss": 0.6016752573138522,
            "mae": 0.2679303804871047,
            "precision": 0.7784946236559139,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8344392301859276,
            "auditor_fn_violation": 0.014739198202116869,
            "auditor_fp_violation": 0.013157894736842108,
            "ave_precision_score": 0.8349235189557488,
            "fpr": 0.11403508771929824,
            "logloss": 0.73133239339543,
            "mae": 0.27554769521752054,
            "precision": 0.7748917748917749,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8367265212295144,
            "auditor_fn_violation": 0.0171567368101455,
            "auditor_fp_violation": 0.017212153796754705,
            "ave_precision_score": 0.8370005402781755,
            "fpr": 0.11964873765093303,
            "logloss": 0.7322391291855055,
            "mae": 0.2706826320317686,
            "precision": 0.7665952890792291,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8135658984328523,
            "auditor_fn_violation": 0.015525318979266355,
            "auditor_fp_violation": 0.015115182816855222,
            "ave_precision_score": 0.8163723490479919,
            "fpr": 0.14473684210526316,
            "logloss": 0.737670410647245,
            "mae": 0.2816201981204059,
            "precision": 0.7386138613861386,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8217327426033332,
            "auditor_fn_violation": 0.014211644907396603,
            "auditor_fp_violation": 0.020637160828473364,
            "ave_precision_score": 0.8214925502922673,
            "fpr": 0.15916575192096596,
            "logloss": 0.7318969861133748,
            "mae": 0.27892979950530167,
            "precision": 0.7211538461538461,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8655245680727146,
            "auditor_fn_violation": 0.016293315934464266,
            "auditor_fp_violation": 0.02699725364813904,
            "ave_precision_score": 0.865708170884229,
            "fpr": 0.12938596491228072,
            "logloss": 0.4857718353728679,
            "mae": 0.30155072533615024,
            "precision": 0.7686274509803922,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8588174543889224,
            "auditor_fn_violation": 0.020314361118247425,
            "auditor_fp_violation": 0.026083320265537613,
            "ave_precision_score": 0.8595777092535848,
            "fpr": 0.1251372118551043,
            "logloss": 0.4852132629011374,
            "mae": 0.3026696338744894,
            "precision": 0.7696969696969697,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8183884990110935,
            "auditor_fn_violation": 0.010964912280701754,
            "auditor_fp_violation": 0.011549024430234468,
            "ave_precision_score": 0.8192074031319645,
            "fpr": 0.125,
            "logloss": 0.8311327010322832,
            "mae": 0.2757375306931704,
            "precision": 0.7610062893081762,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8197893886675602,
            "auditor_fn_violation": 0.013858981245766872,
            "auditor_fp_violation": 0.01801862347573497,
            "ave_precision_score": 0.8201307408027921,
            "fpr": 0.13391877058177826,
            "logloss": 0.8285011643742485,
            "mae": 0.27040483651396996,
            "precision": 0.7479338842975206,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7949106926882201,
            "auditor_fn_violation": 0.016361280266782657,
            "auditor_fp_violation": 0.023359362190523036,
            "ave_precision_score": 0.7963266674243715,
            "fpr": 0.1524122807017544,
            "logloss": 0.8038888998880511,
            "mae": 0.2939285318284728,
            "precision": 0.7225548902195609,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8028383248531618,
            "auditor_fn_violation": 0.014853913165331533,
            "auditor_fp_violation": 0.022312327785120642,
            "ave_precision_score": 0.8031862763516915,
            "fpr": 0.15806805708013172,
            "logloss": 0.7937788589785874,
            "mae": 0.28949136826250105,
            "precision": 0.7165354330708661,
            "recall": 0.774468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8219469978060305,
            "auditor_fn_violation": 0.020454998550094246,
            "auditor_fp_violation": 0.011579767174946716,
            "ave_precision_score": 0.8235220539713777,
            "fpr": 0.06359649122807018,
            "logloss": 1.4145148063855022,
            "mae": 0.3314075344427964,
            "precision": 0.8318840579710145,
            "recall": 0.5929752066115702
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8413399928739766,
            "auditor_fn_violation": 0.01258845785552468,
            "auditor_fp_violation": 0.010282488406998367,
            "ave_precision_score": 0.8404301123539608,
            "fpr": 0.06256860592755215,
            "logloss": 1.2648876829382996,
            "mae": 0.3241315033212344,
            "precision": 0.8357348703170029,
            "recall": 0.6170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7898788302253332,
            "auditor_fn_violation": 0.008148923444976083,
            "auditor_fp_violation": 0.020966551893753075,
            "ave_precision_score": 0.7910501784049877,
            "fpr": 0.17324561403508773,
            "logloss": 1.0631550958004503,
            "mae": 0.2886712104745141,
            "precision": 0.7090239410681399,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7905575030886481,
            "auditor_fn_violation": 0.007945442230889607,
            "auditor_fp_violation": 0.021495901690350486,
            "ave_precision_score": 0.7909067714776876,
            "fpr": 0.18331503841931943,
            "logloss": 1.1106731660000446,
            "mae": 0.2913614397827644,
            "precision": 0.6930147058823529,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8541045905616352,
            "auditor_fn_violation": 0.012793152820066694,
            "auditor_fp_violation": 0.008669454008853912,
            "ave_precision_score": 0.8545482645305489,
            "fpr": 0.08333333333333333,
            "logloss": 0.6145721369987127,
            "mae": 0.27925785815909737,
            "precision": 0.8141809290953546,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8526856092608722,
            "auditor_fn_violation": 0.018782259382955375,
            "auditor_fp_violation": 0.013508367122919425,
            "ave_precision_score": 0.853138775808808,
            "fpr": 0.0867178924259056,
            "logloss": 0.5901314272999544,
            "mae": 0.2697733419297079,
            "precision": 0.8096385542168675,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8154332202802905,
            "auditor_fn_violation": 0.01315336378135422,
            "auditor_fp_violation": 0.012922200360714878,
            "ave_precision_score": 0.8165202332884768,
            "fpr": 0.12280701754385964,
            "logloss": 0.7905935757694837,
            "mae": 0.28146690120124923,
            "precision": 0.7622080679405521,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8204309913877986,
            "auditor_fn_violation": 0.011705630940981386,
            "auditor_fp_violation": 0.017996221540207743,
            "ave_precision_score": 0.8205700145440115,
            "fpr": 0.12733260153677278,
            "logloss": 0.7758128898537043,
            "mae": 0.2727454531401172,
            "precision": 0.7531914893617021,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8361164281863319,
            "auditor_fn_violation": 0.0079654197477164,
            "auditor_fp_violation": 0.009286870798491557,
            "ave_precision_score": 0.8383771716155776,
            "fpr": 0.0800438596491228,
            "logloss": 0.5292442099613419,
            "mae": 0.32450481502159517,
            "precision": 0.8266033254156769,
            "recall": 0.71900826446281
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8399684518259084,
            "auditor_fn_violation": 0.005827124740173306,
            "auditor_fp_violation": 0.009924057438562693,
            "ave_precision_score": 0.8385701907847423,
            "fpr": 0.07903402854006586,
            "logloss": 0.5133098353027032,
            "mae": 0.3209709218804419,
            "precision": 0.8230958230958231,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 8233,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8133335829978442,
            "auditor_fn_violation": 0.025359757865738734,
            "auditor_fp_violation": 0.024660805050008196,
            "ave_precision_score": 0.8145225470157728,
            "fpr": 0.13048245614035087,
            "logloss": 1.4844335809431515,
            "mae": 0.285461918384582,
            "precision": 0.750524109014675,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8287018586460467,
            "auditor_fn_violation": 0.020326038722937156,
            "auditor_fp_violation": 0.02646415316950052,
            "ave_precision_score": 0.8288577201282713,
            "fpr": 0.1350164654226125,
            "logloss": 1.290695524194878,
            "mae": 0.27536649777950006,
            "precision": 0.7458677685950413,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8085983111878011,
            "auditor_fn_violation": 0.04956865303755256,
            "auditor_fp_violation": 0.04262993933431711,
            "ave_precision_score": 0.8091709660610737,
            "fpr": 0.15789473684210525,
            "logloss": 0.6806437555337804,
            "mae": 0.3246750521649578,
            "precision": 0.7209302325581395,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.821698101506852,
            "auditor_fn_violation": 0.044669173459140066,
            "auditor_fp_violation": 0.043731067253099554,
            "ave_precision_score": 0.8220359206319358,
            "fpr": 0.16575192096597147,
            "logloss": 0.6251067416162307,
            "mae": 0.31808534928427235,
            "precision": 0.7079303675048356,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8567521538914478,
            "auditor_fn_violation": 0.012242641728287663,
            "auditor_fp_violation": 0.01542261026397771,
            "ave_precision_score": 0.8570200338938456,
            "fpr": 0.12280701754385964,
            "logloss": 0.5547484961271955,
            "mae": 0.2704001068602297,
            "precision": 0.7732793522267206,
            "recall": 0.7892561983471075
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8530979699065842,
            "auditor_fn_violation": 0.01619683770465002,
            "auditor_fp_violation": 0.015031698738771032,
            "ave_precision_score": 0.8535454383937986,
            "fpr": 0.1251372118551043,
            "logloss": 0.5525620241042232,
            "mae": 0.2712036500290716,
            "precision": 0.7668711656441718,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7260851170712439,
            "auditor_fn_violation": 0.01307633753806003,
            "auditor_fp_violation": 0.011520843580914906,
            "ave_precision_score": 0.7179922337663728,
            "fpr": 0.14802631578947367,
            "logloss": 1.5124545959268014,
            "mae": 0.29589934900987164,
            "precision": 0.7337278106508875,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7169264165378828,
            "auditor_fn_violation": 0.010435107550739193,
            "auditor_fp_violation": 0.016293674440138302,
            "ave_precision_score": 0.7121427202199565,
            "fpr": 0.1525795828759605,
            "logloss": 1.5322218468919735,
            "mae": 0.29140642738404915,
            "precision": 0.7279843444227005,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8457308611970612,
            "auditor_fn_violation": 0.013031027983181094,
            "auditor_fp_violation": 0.012584030168880152,
            "ave_precision_score": 0.8456713645030658,
            "fpr": 0.12280701754385964,
            "logloss": 0.608023729563627,
            "mae": 0.274969949986718,
            "precision": 0.7714285714285715,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.849058531698619,
            "auditor_fn_violation": 0.016115094471821943,
            "auditor_fp_violation": 0.019255708137627538,
            "ave_precision_score": 0.8490318590185133,
            "fpr": 0.12952799121844127,
            "logloss": 0.5941006852052289,
            "mae": 0.2712974919200415,
            "precision": 0.7581967213114754,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8131574501624127,
            "auditor_fn_violation": 0.009940916340437873,
            "auditor_fp_violation": 0.011777033120183637,
            "ave_precision_score": 0.8136014640537279,
            "fpr": 0.12390350877192982,
            "logloss": 0.8352198022641328,
            "mae": 0.27883411906847005,
            "precision": 0.7610993657505285,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8155990096003304,
            "auditor_fn_violation": 0.004393114884274941,
            "auditor_fp_violation": 0.01744612956781688,
            "ave_precision_score": 0.8159002140507229,
            "fpr": 0.13721185510428102,
            "logloss": 0.8370335076884552,
            "mae": 0.2748227350005684,
            "precision": 0.7417355371900827,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8463272276740981,
            "auditor_fn_violation": 0.004734848484848484,
            "auditor_fp_violation": 0.009325299229381872,
            "ave_precision_score": 0.8466163352741262,
            "fpr": 0.11403508771929824,
            "logloss": 0.6185636829423792,
            "mae": 0.27452523235862164,
            "precision": 0.776824034334764,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8367986024217515,
            "auditor_fn_violation": 0.014608683466847286,
            "auditor_fp_violation": 0.01954942240342899,
            "ave_precision_score": 0.8373540494752734,
            "fpr": 0.11525795828759605,
            "logloss": 0.6247435109002146,
            "mae": 0.27691439845568827,
            "precision": 0.7717391304347826,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8640531387735834,
            "auditor_fn_violation": 0.014852472089314199,
            "auditor_fp_violation": 0.009151090342679127,
            "ave_precision_score": 0.8642688726226475,
            "fpr": 0.07456140350877193,
            "logloss": 0.497040460901207,
            "mae": 0.30264388888041904,
            "precision": 0.8320987654320988,
            "recall": 0.6962809917355371
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8656307936248633,
            "auditor_fn_violation": 0.009435504589298644,
            "auditor_fp_violation": 0.009276890412220505,
            "ave_precision_score": 0.8659200644431342,
            "fpr": 0.06695938529088913,
            "logloss": 0.48718332051916824,
            "mae": 0.30022107301848305,
            "precision": 0.8439897698209718,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8154016387524565,
            "auditor_fn_violation": 0.01315336378135422,
            "auditor_fp_violation": 0.012922200360714878,
            "ave_precision_score": 0.8164887068232324,
            "fpr": 0.12280701754385964,
            "logloss": 0.790597518381497,
            "mae": 0.2814721626280315,
            "precision": 0.7622080679405521,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8203318105904228,
            "auditor_fn_violation": 0.011705630940981386,
            "auditor_fp_violation": 0.017996221540207743,
            "ave_precision_score": 0.8204721297264574,
            "fpr": 0.12733260153677278,
            "logloss": 0.7758004419544947,
            "mae": 0.27275387138505514,
            "precision": 0.7531914893617021,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.811304749758471,
            "auditor_fn_violation": 0.05211958097723648,
            "auditor_fp_violation": 0.032474585997704544,
            "ave_precision_score": 0.8116007586917251,
            "fpr": 0.1162280701754386,
            "logloss": 0.6267237628012187,
            "mae": 0.3379757040617484,
            "precision": 0.7654867256637168,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8326627646233109,
            "auditor_fn_violation": 0.048828736249620475,
            "auditor_fp_violation": 0.035098854763273776,
            "ave_precision_score": 0.8326967093812668,
            "fpr": 0.11745334796926454,
            "logloss": 0.5803239153637357,
            "mae": 0.32999537872331136,
            "precision": 0.76431718061674,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8155959699864187,
            "auditor_fn_violation": 0.012351384659997102,
            "auditor_fp_violation": 0.014964030988686672,
            "ave_precision_score": 0.818425501986196,
            "fpr": 0.14583333333333334,
            "logloss": 0.7142208777635073,
            "mae": 0.281314422181181,
            "precision": 0.7397260273972602,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8256079327143672,
            "auditor_fn_violation": 0.009001097694840835,
            "auditor_fp_violation": 0.020756637817951916,
            "ave_precision_score": 0.8252283760868547,
            "fpr": 0.15916575192096596,
            "logloss": 0.7079955110102512,
            "mae": 0.278577901287301,
            "precision": 0.7216890595009597,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.754411275161518,
            "auditor_fn_violation": 0.03418152820066696,
            "auditor_fp_violation": 0.013598540744384324,
            "ave_precision_score": 0.7552136464881014,
            "fpr": 0.05482456140350877,
            "logloss": 1.457357446555544,
            "mae": 0.38380909567464344,
            "precision": 0.782608695652174,
            "recall": 0.371900826446281
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7383860909171609,
            "auditor_fn_violation": 0.045411869117406654,
            "auditor_fp_violation": 0.015290565549307905,
            "ave_precision_score": 0.739641282919741,
            "fpr": 0.06037321624588365,
            "logloss": 1.454305689125635,
            "mae": 0.381423946925015,
            "precision": 0.7669491525423728,
            "recall": 0.3851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8282219067364887,
            "auditor_fn_violation": 0.00903472524285922,
            "auditor_fp_violation": 0.011825709132644704,
            "ave_precision_score": 0.8284650374128175,
            "fpr": 0.12280701754385964,
            "logloss": 0.7593431850939877,
            "mae": 0.2798581212074735,
            "precision": 0.7627118644067796,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8298262583025466,
            "auditor_fn_violation": 0.012027932830417828,
            "auditor_fp_violation": 0.014046013575572931,
            "ave_precision_score": 0.8300760609493402,
            "fpr": 0.12843029637760703,
            "logloss": 0.7570357279892904,
            "mae": 0.2739896607464152,
            "precision": 0.7536842105263157,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8480081738805441,
            "auditor_fn_violation": 0.012063668986515884,
            "auditor_fp_violation": 0.012030660764059684,
            "ave_precision_score": 0.8484648587523147,
            "fpr": 0.11074561403508772,
            "logloss": 0.6120775586296495,
            "mae": 0.274481178572384,
            "precision": 0.7804347826086957,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8452565938859448,
            "auditor_fn_violation": 0.017633183081486325,
            "auditor_fp_violation": 0.013774701245298705,
            "ave_precision_score": 0.8457168898861644,
            "fpr": 0.10318331503841932,
            "logloss": 0.6049842685076915,
            "mae": 0.2713613271820905,
            "precision": 0.7911111111111111,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 8233,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8295562981227084,
            "auditor_fn_violation": 0.031073292735972164,
            "auditor_fp_violation": 0.012440564026889655,
            "ave_precision_score": 0.8307536753126439,
            "fpr": 0.08552631578947369,
            "logloss": 0.5445258495239645,
            "mae": 0.30380596685975897,
            "precision": 0.8133971291866029,
            "recall": 0.7024793388429752
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.853498148534745,
            "auditor_fn_violation": 0.017245486605787425,
            "auditor_fp_violation": 0.011708744968898647,
            "ave_precision_score": 0.8538797969992109,
            "fpr": 0.08562019758507135,
            "logloss": 0.5019927649781998,
            "mae": 0.29230103927841317,
            "precision": 0.8142857142857143,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8390927081294848,
            "auditor_fn_violation": 0.00906870740901842,
            "auditor_fp_violation": 0.016078455484505667,
            "ave_precision_score": 0.8395154337807992,
            "fpr": 0.125,
            "logloss": 0.6811075726569177,
            "mae": 0.27332072036058197,
            "precision": 0.7639751552795031,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8365271563580723,
            "auditor_fn_violation": 0.013756218324497282,
            "auditor_fp_violation": 0.013510856226866893,
            "ave_precision_score": 0.8368437533347943,
            "fpr": 0.1394072447859495,
            "logloss": 0.691539720456829,
            "mae": 0.27157438371875403,
            "precision": 0.742393509127789,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8533228454749142,
            "auditor_fn_violation": 0.013493185442946212,
            "auditor_fp_violation": 0.014761641252664371,
            "ave_precision_score": 0.8537737897274651,
            "fpr": 0.11513157894736842,
            "logloss": 0.6085323490141241,
            "mae": 0.2683770811421462,
            "precision": 0.7835051546391752,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8545982722693031,
            "auditor_fn_violation": 0.016736343041315365,
            "auditor_fp_violation": 0.019492173012637188,
            "ave_precision_score": 0.855044045816687,
            "fpr": 0.12623490669593854,
            "logloss": 0.567889646370569,
            "mae": 0.2650171093064313,
            "precision": 0.764344262295082,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8046888709825586,
            "auditor_fn_violation": 0.011277548209366396,
            "auditor_fp_violation": 0.017666830627971804,
            "ave_precision_score": 0.8053927654499747,
            "fpr": 0.1425438596491228,
            "logloss": 0.8946441013110246,
            "mae": 0.28766502260364707,
            "precision": 0.7379032258064516,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8048934194337227,
            "auditor_fn_violation": 0.012448326599247961,
            "auditor_fp_violation": 0.017764734873093043,
            "ave_precision_score": 0.8052759046442768,
            "fpr": 0.15477497255762898,
            "logloss": 0.9107286238541666,
            "mae": 0.28476852501097716,
            "precision": 0.7213438735177866,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7207844469679093,
            "auditor_fn_violation": 0.021367986080904747,
            "auditor_fp_violation": 0.024840137727496322,
            "ave_precision_score": 0.6816117013399027,
            "fpr": 0.17982456140350878,
            "logloss": 3.288909727046549,
            "mae": 0.29294058367348547,
            "precision": 0.7076648841354723,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7476808712594938,
            "auditor_fn_violation": 0.01992199360067263,
            "auditor_fp_violation": 0.02113000341007242,
            "ave_precision_score": 0.7101726086549125,
            "fpr": 0.19538968166849616,
            "logloss": 3.003383341250457,
            "mae": 0.29468701200342495,
            "precision": 0.6882661996497373,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8512412118778477,
            "auditor_fn_violation": 0.015507195157314779,
            "auditor_fp_violation": 0.013065666502705364,
            "ave_precision_score": 0.8519526699882998,
            "fpr": 0.11074561403508772,
            "logloss": 0.5779013936216202,
            "mae": 0.27046893207455097,
            "precision": 0.7860169491525424,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8530158971957622,
            "auditor_fn_violation": 0.014363453768363033,
            "auditor_fp_violation": 0.012166740095233122,
            "ave_precision_score": 0.853332973197213,
            "fpr": 0.11306256860592755,
            "logloss": 0.5722203637857397,
            "mae": 0.2680789498085229,
            "precision": 0.7799145299145299,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.871965970753104,
            "auditor_fn_violation": 0.00603749818761781,
            "auditor_fp_violation": 0.011162178225938681,
            "ave_precision_score": 0.8721341919095699,
            "fpr": 0.08223684210526316,
            "logloss": 0.48727123319655014,
            "mae": 0.2954092847975788,
            "precision": 0.8271889400921659,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8612101154348613,
            "auditor_fn_violation": 0.004488871242730697,
            "auditor_fp_violation": 0.010962013784657663,
            "ave_precision_score": 0.8614743666250692,
            "fpr": 0.07574094401756312,
            "logloss": 0.47539952907946736,
            "mae": 0.29476096683501807,
            "precision": 0.8317073170731707,
            "recall": 0.725531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.809240788456312,
            "auditor_fn_violation": 0.02691387559808613,
            "auditor_fp_violation": 0.016721491228070175,
            "ave_precision_score": 0.8096974356101394,
            "fpr": 0.11732456140350878,
            "logloss": 0.5482516137134569,
            "mae": 0.3363681021234873,
            "precision": 0.7668845315904139,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8174279087279175,
            "auditor_fn_violation": 0.018462293014456878,
            "auditor_fp_violation": 0.0191013836928844,
            "ave_precision_score": 0.8177856100423204,
            "fpr": 0.1119648737650933,
            "logloss": 0.5208188246436763,
            "mae": 0.3301465394101632,
            "precision": 0.7728285077951003,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8142025784472016,
            "auditor_fn_violation": 0.012364977526460789,
            "auditor_fp_violation": 0.010150229545827194,
            "ave_precision_score": 0.8149798405835815,
            "fpr": 0.125,
            "logloss": 0.8648478164104109,
            "mae": 0.281951109506994,
            "precision": 0.7584745762711864,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8161550567064916,
            "auditor_fn_violation": 0.01277763505149824,
            "auditor_fp_violation": 0.013904134650567156,
            "ave_precision_score": 0.8164512860843538,
            "fpr": 0.1350164654226125,
            "logloss": 0.8729921967583331,
            "mae": 0.2767633608726277,
            "precision": 0.7448132780082988,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7154285749577276,
            "auditor_fn_violation": 0.019693798028128175,
            "auditor_fp_violation": 0.021079275291031326,
            "ave_precision_score": 0.6776225534342946,
            "fpr": 0.18421052631578946,
            "logloss": 3.1322589350282968,
            "mae": 0.29180233923522164,
            "precision": 0.7047451669595782,
            "recall": 0.8285123966942148
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7454946101104432,
            "auditor_fn_violation": 0.020143868089777427,
            "auditor_fp_violation": 0.020072134232397676,
            "ave_precision_score": 0.7088773214752618,
            "fpr": 0.19758507135016465,
            "logloss": 2.795614250785401,
            "mae": 0.29473437485561355,
            "precision": 0.6869565217391305,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8179918074773644,
            "auditor_fn_violation": 0.011182398144120639,
            "auditor_fp_violation": 0.014397852106902772,
            "ave_precision_score": 0.8190826864797025,
            "fpr": 0.14144736842105263,
            "logloss": 0.7324525813881001,
            "mae": 0.2798570060515228,
            "precision": 0.7425149700598802,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8228686443660118,
            "auditor_fn_violation": 0.00947287292430577,
            "auditor_fp_violation": 0.019362739607368746,
            "ave_precision_score": 0.8230213117753703,
            "fpr": 0.15148188803512624,
            "logloss": 0.7304187647967909,
            "mae": 0.2776151778887,
            "precision": 0.7294117647058823,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8193023617913471,
            "auditor_fn_violation": 0.024947440916340435,
            "auditor_fp_violation": 0.02342597147073291,
            "ave_precision_score": 0.8206098124543054,
            "fpr": 0.12609649122807018,
            "logloss": 0.7629857571467743,
            "mae": 0.28212313518010446,
            "precision": 0.7578947368421053,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8324258053156708,
            "auditor_fn_violation": 0.02357941938949483,
            "auditor_fp_violation": 0.02173734477325508,
            "ave_precision_score": 0.8326629107920728,
            "fpr": 0.13172338090010977,
            "logloss": 0.7217351656866824,
            "mae": 0.27120096699850177,
            "precision": 0.7530864197530864,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8263927624566896,
            "auditor_fn_violation": 0.014521712338697985,
            "auditor_fp_violation": 0.014753955566486307,
            "ave_precision_score": 0.8266406314907593,
            "fpr": 0.12609649122807018,
            "logloss": 0.7772743266478,
            "mae": 0.2794580317006428,
            "precision": 0.7563559322033898,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8292882263889891,
            "auditor_fn_violation": 0.013242403718149333,
            "auditor_fp_violation": 0.014919689061134883,
            "ave_precision_score": 0.8295353766942895,
            "fpr": 0.12843029637760703,
            "logloss": 0.7743971625004396,
            "mae": 0.2730256649700328,
            "precision": 0.7526427061310782,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8289384911108518,
            "auditor_fn_violation": 0.005138103523270989,
            "auditor_fp_violation": 0.008946138711264142,
            "ave_precision_score": 0.8291289588757239,
            "fpr": 0.11951754385964912,
            "logloss": 1.0328847379191792,
            "mae": 0.2817716690223334,
            "precision": 0.7695560253699789,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8316853089267047,
            "auditor_fn_violation": 0.012586122334586733,
            "auditor_fp_violation": 0.018158013296793295,
            "ave_precision_score": 0.8317831793231445,
            "fpr": 0.12623490669593854,
            "logloss": 0.7949542451852266,
            "mae": 0.2762182105763143,
            "precision": 0.7542735042735043,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 8233,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7481508558970703,
            "auditor_fn_violation": 0.008083224590401629,
            "auditor_fp_violation": 0.01295294310542712,
            "ave_precision_score": 0.7431953116591214,
            "fpr": 0.14035087719298245,
            "logloss": 1.2618460455962772,
            "mae": 0.28467211290908334,
            "precision": 0.75,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7465794141373432,
            "auditor_fn_violation": 0.013085923815307002,
            "auditor_fp_violation": 0.018503998745491614,
            "ave_precision_score": 0.7461702569516035,
            "fpr": 0.14050493962678376,
            "logloss": 1.169847549217579,
            "mae": 0.2852428952115538,
            "precision": 0.7382413087934561,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8318103650111468,
            "auditor_fn_violation": 0.01958732057416268,
            "auditor_fp_violation": 0.009176709296606007,
            "ave_precision_score": 0.8329014546737894,
            "fpr": 0.07346491228070176,
            "logloss": 0.5323307393675865,
            "mae": 0.31526021733078413,
            "precision": 0.8312342569269522,
            "recall": 0.6818181818181818
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8606464641006732,
            "auditor_fn_violation": 0.01002639138659878,
            "auditor_fp_violation": 0.010820134859651878,
            "ave_precision_score": 0.8608248826300451,
            "fpr": 0.07683863885839737,
            "logloss": 0.4977008090183432,
            "mae": 0.30500403217333405,
            "precision": 0.821882951653944,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8496229686853667,
            "auditor_fn_violation": 0.011411211396259247,
            "auditor_fp_violation": 0.013168142318412854,
            "ave_precision_score": 0.8500299939631728,
            "fpr": 0.11951754385964912,
            "logloss": 0.6083877169145737,
            "mae": 0.2679760198417119,
            "precision": 0.7738589211618258,
            "recall": 0.7706611570247934
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8498409604264103,
            "auditor_fn_violation": 0.015358385687927691,
            "auditor_fp_violation": 0.01358304024134352,
            "ave_precision_score": 0.8501278470872238,
            "fpr": 0.1207464324917673,
            "logloss": 0.6047134692590301,
            "mae": 0.2661953428696586,
            "precision": 0.7698744769874477,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7169602422137724,
            "auditor_fn_violation": 0.02013556618819777,
            "auditor_fp_violation": 0.023095486965076243,
            "ave_precision_score": 0.6793276149825638,
            "fpr": 0.18311403508771928,
            "logloss": 3.155628282952641,
            "mae": 0.29213959910333964,
            "precision": 0.7039007092198581,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7470741895462297,
            "auditor_fn_violation": 0.01992199360067263,
            "auditor_fp_violation": 0.020455456240308048,
            "ave_precision_score": 0.7102830220410938,
            "fpr": 0.19538968166849616,
            "logloss": 2.846450168183161,
            "mae": 0.29427542310086,
            "precision": 0.6882661996497373,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8235051436487282,
            "auditor_fn_violation": 0.015971618094823847,
            "auditor_fp_violation": 0.01668818658796524,
            "ave_precision_score": 0.8241360298354694,
            "fpr": 0.12828947368421054,
            "logloss": 0.7516275932988766,
            "mae": 0.2797851950896913,
            "precision": 0.7536842105263157,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8280105959178881,
            "auditor_fn_violation": 0.018434266763201534,
            "auditor_fp_violation": 0.014929645476924764,
            "ave_precision_score": 0.8280730805157783,
            "fpr": 0.132821075740944,
            "logloss": 0.7402521447711304,
            "mae": 0.27091905488666373,
            "precision": 0.75,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8150857634186667,
            "auditor_fn_violation": 0.012605118167319128,
            "auditor_fp_violation": 0.014397852106902772,
            "ave_precision_score": 0.8175504023067061,
            "fpr": 0.14144736842105263,
            "logloss": 0.7325045442816196,
            "mae": 0.2806555425958037,
            "precision": 0.7445544554455445,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8244980596126992,
            "auditor_fn_violation": 0.009610668659644536,
            "auditor_fp_violation": 0.019357761399473813,
            "ave_precision_score": 0.8241181095372421,
            "fpr": 0.15367727771679474,
            "logloss": 0.7245375179969603,
            "mae": 0.27791084907167235,
            "precision": 0.7281553398058253,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8224795148212504,
            "auditor_fn_violation": 0.012605118167319128,
            "auditor_fp_violation": 0.018414904082636498,
            "ave_precision_score": 0.8245856775331935,
            "fpr": 0.14035087719298245,
            "logloss": 0.6707962219576491,
            "mae": 0.2805636953004721,
            "precision": 0.746031746031746,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8312255248803869,
            "auditor_fn_violation": 0.015367727771679473,
            "auditor_fp_violation": 0.022897267212776077,
            "ave_precision_score": 0.8315286571419158,
            "fpr": 0.150384193194292,
            "logloss": 0.6624121411599276,
            "mae": 0.2779334462946701,
            "precision": 0.732943469785575,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8191292979503947,
            "auditor_fn_violation": 0.013053682760620558,
            "auditor_fp_violation": 0.01604002705361535,
            "ave_precision_score": 0.8221434890527676,
            "fpr": 0.12390350877192982,
            "logloss": 0.7026038503493138,
            "mae": 0.2820364033608916,
            "precision": 0.7621052631578947,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8283020193092818,
            "auditor_fn_violation": 0.01592825279678633,
            "auditor_fp_violation": 0.018309848637588964,
            "ave_precision_score": 0.8280057964851466,
            "fpr": 0.13172338090010977,
            "logloss": 0.6917923038422389,
            "mae": 0.2779049946556594,
            "precision": 0.7484276729559748,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7349053663681874,
            "auditor_fn_violation": 0.009959040162389445,
            "auditor_fp_violation": 0.007829152320052478,
            "ave_precision_score": 0.7267867435272968,
            "fpr": 0.14473684210526316,
            "logloss": 1.4832980014768316,
            "mae": 0.29105376099497293,
            "precision": 0.7436893203883496,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7235434273385822,
            "auditor_fn_violation": 0.010435107550739193,
            "auditor_fp_violation": 0.015086459025615367,
            "ave_precision_score": 0.7187956438164995,
            "fpr": 0.14928649835345773,
            "logloss": 1.4947035452681137,
            "mae": 0.2887906747728446,
            "precision": 0.7322834645669292,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8101705976220641,
            "auditor_fn_violation": 0.015042772219805718,
            "auditor_fp_violation": 0.012806915068043946,
            "ave_precision_score": 0.8118122649125183,
            "fpr": 0.12609649122807018,
            "logloss": 0.8741017486677694,
            "mae": 0.28278161289739534,
            "precision": 0.7558386411889597,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8151990887687024,
            "auditor_fn_violation": 0.013034542354672208,
            "auditor_fp_violation": 0.014872396086132956,
            "ave_precision_score": 0.8155251121163762,
            "fpr": 0.13611416026344675,
            "logloss": 0.8808674590227603,
            "mae": 0.27701119540411556,
            "precision": 0.7453798767967146,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7009448714697558,
            "auditor_fn_violation": 0.012299278671886333,
            "auditor_fp_violation": 0.014477270864076078,
            "ave_precision_score": 0.6787761737368485,
            "fpr": 0.18969298245614036,
            "logloss": 2.414121763061848,
            "mae": 0.2987334617642963,
            "precision": 0.6986062717770035,
            "recall": 0.8285123966942148
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7340209521696192,
            "auditor_fn_violation": 0.01195786720227947,
            "auditor_fp_violation": 0.00738517141214335,
            "ave_precision_score": 0.7170317249079111,
            "fpr": 0.19099890230515917,
            "logloss": 1.93422378326197,
            "mae": 0.2912514711119854,
            "precision": 0.6958041958041958,
            "recall": 0.8468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7335002982330052,
            "auditor_fn_violation": 0.010013411628244165,
            "auditor_fp_violation": 0.011631005082800464,
            "ave_precision_score": 0.7254090414562206,
            "fpr": 0.15789473684210525,
            "logloss": 1.4851852433513462,
            "mae": 0.2916300194246546,
            "precision": 0.7288135593220338,
            "recall": 0.7995867768595041
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7207096937829729,
            "auditor_fn_violation": 0.00780998201648878,
            "auditor_fp_violation": 0.015223359742726221,
            "ave_precision_score": 0.7159789846089993,
            "fpr": 0.1602634467618002,
            "logloss": 1.4938235960718014,
            "mae": 0.28953076436007524,
            "precision": 0.7192307692307692,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7166989254793334,
            "auditor_fn_violation": 0.01784290271132376,
            "auditor_fp_violation": 0.024993851451057553,
            "ave_precision_score": 0.6785476792201879,
            "fpr": 0.18421052631578946,
            "logloss": 3.1762409539400913,
            "mae": 0.2932723062240901,
            "precision": 0.7021276595744681,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7472615600910142,
            "auditor_fn_violation": 0.019342784408062218,
            "auditor_fp_violation": 0.020477858175835282,
            "ave_precision_score": 0.7104579059150806,
            "fpr": 0.1964873765093304,
            "logloss": 2.840531732664418,
            "mae": 0.29407277814617133,
            "precision": 0.6865148861646234,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8192011637345455,
            "auditor_fn_violation": 0.011118964767290133,
            "auditor_fp_violation": 0.014397852106902772,
            "ave_precision_score": 0.8222191483850793,
            "fpr": 0.14144736842105263,
            "logloss": 0.6941653627456967,
            "mae": 0.27995001928276475,
            "precision": 0.7455621301775148,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8285395941167464,
            "auditor_fn_violation": 0.010537870472008782,
            "auditor_fp_violation": 0.01957182433895622,
            "ave_precision_score": 0.8282425682146799,
            "fpr": 0.15148188803512624,
            "logloss": 0.6873773492044596,
            "mae": 0.27765172713738445,
            "precision": 0.7315175097276264,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8264247466479389,
            "auditor_fn_violation": 0.00998622589531681,
            "auditor_fp_violation": 0.01610919822921791,
            "ave_precision_score": 0.8274588594169067,
            "fpr": 0.14035087719298245,
            "logloss": 0.6580192716282154,
            "mae": 0.2793274268661319,
            "precision": 0.7480314960629921,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8341703469953028,
            "auditor_fn_violation": 0.011458065721559196,
            "auditor_fp_violation": 0.017899146486256415,
            "ave_precision_score": 0.8342493786837993,
            "fpr": 0.14818880351262348,
            "logloss": 0.6525599041085417,
            "mae": 0.27740393109219036,
            "precision": 0.734251968503937,
            "recall": 0.7936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8629059435839813,
            "auditor_fn_violation": 0.03149920255183414,
            "auditor_fp_violation": 0.019829070339399905,
            "ave_precision_score": 0.8631059473283477,
            "fpr": 0.11513157894736842,
            "logloss": 0.5049293023692214,
            "mae": 0.3035491329562654,
            "precision": 0.7817047817047817,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8428996378485079,
            "auditor_fn_violation": 0.02393908961393839,
            "auditor_fp_violation": 0.026055940122115442,
            "ave_precision_score": 0.8437024937472274,
            "fpr": 0.11964873765093303,
            "logloss": 0.5119479346325331,
            "mae": 0.3088977699056595,
            "precision": 0.7650862068965517,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8314999740494509,
            "auditor_fn_violation": 0.00989560678555894,
            "auditor_fp_violation": 0.013478131660928023,
            "ave_precision_score": 0.8322547118057503,
            "fpr": 0.12390350877192982,
            "logloss": 0.6964671224355174,
            "mae": 0.2692574896095948,
            "precision": 0.77079107505071,
            "recall": 0.7851239669421488
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8349015117394994,
            "auditor_fn_violation": 0.01598664082023496,
            "auditor_fp_violation": 0.01665957272041638,
            "ave_precision_score": 0.8351900014195885,
            "fpr": 0.12952799121844127,
            "logloss": 0.6991108993703319,
            "mae": 0.2663203721478849,
            "precision": 0.7606490872210954,
            "recall": 0.7978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8520797747771587,
            "auditor_fn_violation": 0.015029179353342035,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.852536787935574,
            "fpr": 0.1074561403508772,
            "logloss": 0.5886323967504045,
            "mae": 0.27042674734564376,
            "precision": 0.7901498929336188,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8544486334718547,
            "auditor_fn_violation": 0.014853913165331528,
            "auditor_fp_violation": 0.01249281271235169,
            "ave_precision_score": 0.8547472122945986,
            "fpr": 0.11525795828759605,
            "logloss": 0.5804791469546132,
            "mae": 0.26688839588028385,
            "precision": 0.7770700636942676,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7037601440160277,
            "auditor_fn_violation": 0.015751866753661015,
            "auditor_fp_violation": 0.014771888834235126,
            "ave_precision_score": 0.6948062843695363,
            "fpr": 0.12828947368421054,
            "logloss": 1.391330088276042,
            "mae": 0.3498598012679794,
            "precision": 0.743421052631579,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7285506952204737,
            "auditor_fn_violation": 0.008148632552490835,
            "auditor_fp_violation": 0.013139979738693875,
            "ave_precision_score": 0.7235003270742513,
            "fpr": 0.12733260153677278,
            "logloss": 1.0707967311047202,
            "mae": 0.3366494988705697,
            "precision": 0.7439293598233996,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8196779309517145,
            "auditor_fn_violation": 0.024938379005364657,
            "auditor_fp_violation": 0.023510514018691593,
            "ave_precision_score": 0.8210270033773343,
            "fpr": 0.13486842105263158,
            "logloss": 0.7669074745740513,
            "mae": 0.27954434584094046,
            "precision": 0.7515151515151515,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8351231329312768,
            "auditor_fn_violation": 0.023210407081299487,
            "auditor_fp_violation": 0.022215252731169307,
            "ave_precision_score": 0.8353532033849639,
            "fpr": 0.13611416026344675,
            "logloss": 0.7218298781355932,
            "mae": 0.2693652222788587,
            "precision": 0.7479674796747967,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8179195732937304,
            "auditor_fn_violation": 0.026503824126431787,
            "auditor_fp_violation": 0.022652279062141335,
            "ave_precision_score": 0.819304134692963,
            "fpr": 0.12828947368421054,
            "logloss": 0.7666433068366603,
            "mae": 0.28055137307571637,
            "precision": 0.7592592592592593,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8348206062065382,
            "auditor_fn_violation": 0.025293691757946612,
            "auditor_fp_violation": 0.022553770868025225,
            "ave_precision_score": 0.8350714923357053,
            "fpr": 0.132821075740944,
            "logloss": 0.7170004633185731,
            "mae": 0.2703384670194382,
            "precision": 0.7510288065843621,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7296396295742855,
            "auditor_fn_violation": 0.009859359141655795,
            "auditor_fp_violation": 0.015274020331201846,
            "ave_precision_score": 0.721543925691726,
            "fpr": 0.14692982456140352,
            "logloss": 1.4987418131332715,
            "mae": 0.2909833479518415,
            "precision": 0.7413127413127413,
            "recall": 0.7933884297520661
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7224891163356039,
            "auditor_fn_violation": 0.008071560361538641,
            "auditor_fp_violation": 0.014148066837419211,
            "ave_precision_score": 0.7177010038162585,
            "fpr": 0.150384193194292,
            "logloss": 1.5193419103529213,
            "mae": 0.28853260917966383,
            "precision": 0.7318982387475538,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8017525112173605,
            "auditor_fn_violation": 0.016345421922575043,
            "auditor_fp_violation": 0.01754385964912281,
            "ave_precision_score": 0.8021429398913038,
            "fpr": 0.15350877192982457,
            "logloss": 0.9078556154644462,
            "mae": 0.2801951756934508,
            "precision": 0.7312859884836852,
            "recall": 0.7871900826446281
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.821866476929466,
            "auditor_fn_violation": 0.010252936917579468,
            "auditor_fp_violation": 0.017065296663853986,
            "ave_precision_score": 0.8221028080763706,
            "fpr": 0.16355653128430298,
            "logloss": 0.8747684939745375,
            "mae": 0.2731859392896546,
            "precision": 0.718336483931947,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7845083735748937,
            "auditor_fn_violation": 0.0164360410323329,
            "auditor_fp_violation": 0.021115141826528943,
            "ave_precision_score": 0.760070482566251,
            "fpr": 0.15021929824561403,
            "logloss": 3.714213521705896,
            "mae": 0.3133277150859873,
            "precision": 0.7072649572649573,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7788290126882,
            "auditor_fn_violation": 0.015052432445056873,
            "auditor_fp_violation": 0.014103262966364744,
            "ave_precision_score": 0.7487828536904455,
            "fpr": 0.1602634467618002,
            "logloss": 3.7528052228623285,
            "mae": 0.29601589760119196,
            "precision": 0.7014314928425358,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.812394804160387,
            "auditor_fn_violation": 0.011132557633753808,
            "auditor_fp_violation": 0.011938432529922936,
            "ave_precision_score": 0.8137552687646863,
            "fpr": 0.12609649122807018,
            "logloss": 0.8374664976787259,
            "mae": 0.2773477522041102,
            "precision": 0.7604166666666666,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8190741222885047,
            "auditor_fn_violation": 0.01105402059929467,
            "auditor_fp_violation": 0.01913125294025404,
            "ave_precision_score": 0.8193952387976386,
            "fpr": 0.13830954994511527,
            "logloss": 0.8252559946956217,
            "mae": 0.26974264829839834,
            "precision": 0.7423312883435583,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7361790939297581,
            "auditor_fn_violation": 0.008547647527910693,
            "auditor_fp_violation": 0.010019572880800139,
            "ave_precision_score": 0.7280811932687031,
            "fpr": 0.14802631578947367,
            "logloss": 1.4815032777345936,
            "mae": 0.2916111724824617,
            "precision": 0.736328125,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7206607186486217,
            "auditor_fn_violation": 0.010642968914216311,
            "auditor_fp_violation": 0.01728682691517881,
            "ave_precision_score": 0.7166665169135945,
            "fpr": 0.14709110867178923,
            "logloss": 1.4744039729231964,
            "mae": 0.2906470936273388,
            "precision": 0.7303822937625755,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8518846049027473,
            "auditor_fn_violation": 0.01325757575757576,
            "auditor_fp_violation": 0.013419208066896214,
            "ave_precision_score": 0.8522864765602619,
            "fpr": 0.1162280701754386,
            "logloss": 0.5969901945319389,
            "mae": 0.2692033864579628,
            "precision": 0.7805383022774327,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8509696315362888,
            "auditor_fn_violation": 0.012452997641123856,
            "auditor_fp_violation": 0.01270189744393916,
            "ave_precision_score": 0.8513681971458185,
            "fpr": 0.11525795828759605,
            "logloss": 0.5925326540644568,
            "mae": 0.2678712683475299,
            "precision": 0.7794117647058824,
            "recall": 0.7893617021276595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8538409662183803,
            "auditor_fn_violation": 0.011164274322169059,
            "auditor_fp_violation": 0.011057140514838495,
            "ave_precision_score": 0.8541758625410117,
            "fpr": 0.10526315789473684,
            "logloss": 0.5952665897646715,
            "mae": 0.27018358188112407,
            "precision": 0.7903930131004366,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8514658550083897,
            "auditor_fn_violation": 0.013753882803559339,
            "auditor_fp_violation": 0.013846885259775338,
            "ave_precision_score": 0.8517578852428411,
            "fpr": 0.11086717892425905,
            "logloss": 0.5907810169249379,
            "mae": 0.26919659214130365,
            "precision": 0.7813852813852814,
            "recall": 0.7680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8088785311108587,
            "auditor_fn_violation": 0.047756270842395254,
            "auditor_fp_violation": 0.028396048532546316,
            "ave_precision_score": 0.8096703248360857,
            "fpr": 0.10087719298245613,
            "logloss": 0.6262114708789164,
            "mae": 0.3399766693208943,
            "precision": 0.784037558685446,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8313361586242793,
            "auditor_fn_violation": 0.045077889623280486,
            "auditor_fp_violation": 0.028375785001157436,
            "ave_precision_score": 0.8315147620014101,
            "fpr": 0.10208562019758508,
            "logloss": 0.5820848027056384,
            "mae": 0.3316485844344521,
            "precision": 0.7816901408450704,
            "recall": 0.7085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8196645646777642,
            "auditor_fn_violation": 0.024938379005364657,
            "auditor_fp_violation": 0.023510514018691593,
            "ave_precision_score": 0.8210136657104692,
            "fpr": 0.13486842105263158,
            "logloss": 0.7669619735704367,
            "mae": 0.2795498620854268,
            "precision": 0.7515151515151515,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8352058451834163,
            "auditor_fn_violation": 0.023210407081299487,
            "auditor_fp_violation": 0.022215252731169307,
            "ave_precision_score": 0.8354542660547668,
            "fpr": 0.13611416026344675,
            "logloss": 0.7218612058840582,
            "mae": 0.2693676818024262,
            "precision": 0.7479674796747967,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8242824126890338,
            "auditor_fn_violation": 0.01583568943018705,
            "auditor_fp_violation": 0.010934169535989505,
            "ave_precision_score": 0.8245426896648924,
            "fpr": 0.12390350877192982,
            "logloss": 0.7932844043514283,
            "mae": 0.2791020740345422,
            "precision": 0.7600849256900213,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8259227211653846,
            "auditor_fn_violation": 0.011047014036480845,
            "auditor_fp_violation": 0.015367727771679478,
            "ave_precision_score": 0.8262235023006778,
            "fpr": 0.12843029637760703,
            "logloss": 0.7893677125450028,
            "mae": 0.2733679276885116,
            "precision": 0.7526427061310782,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8308475068825453,
            "auditor_fn_violation": 0.011828059301145426,
            "auditor_fp_violation": 0.013101533038202984,
            "ave_precision_score": 0.8311274088215355,
            "fpr": 0.10307017543859649,
            "logloss": 0.6367428968750242,
            "mae": 0.2936837916518295,
            "precision": 0.785876993166287,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8296963625387118,
            "auditor_fn_violation": 0.012829016512133038,
            "auditor_fp_violation": 0.01507401350587802,
            "ave_precision_score": 0.8299715252743346,
            "fpr": 0.10647639956092206,
            "logloss": 0.6287563055460368,
            "mae": 0.2865238531525328,
            "precision": 0.7764976958525346,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.814811741977358,
            "auditor_fn_violation": 0.012188270262432951,
            "auditor_fp_violation": 0.012922200360714878,
            "ave_precision_score": 0.815977065849362,
            "fpr": 0.12280701754385964,
            "logloss": 0.7881347334671734,
            "mae": 0.2815619405545781,
            "precision": 0.7627118644067796,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8201661110324816,
            "auditor_fn_violation": 0.011093724455239746,
            "auditor_fp_violation": 0.01926566455341742,
            "ave_precision_score": 0.8203912509974275,
            "fpr": 0.12843029637760703,
            "logloss": 0.773627608675008,
            "mae": 0.27286001086917394,
            "precision": 0.7521186440677966,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8164778643837686,
            "auditor_fn_violation": 0.015747335798173123,
            "auditor_fp_violation": 0.014264633546483035,
            "ave_precision_score": 0.8178196662262287,
            "fpr": 0.11842105263157894,
            "logloss": 0.770684017215222,
            "mae": 0.2852374354466109,
            "precision": 0.7647058823529411,
            "recall": 0.7252066115702479
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8147600033450002,
            "auditor_fn_violation": 0.014690426699675362,
            "auditor_fp_violation": 0.019467281973162477,
            "ave_precision_score": 0.8150792676754102,
            "fpr": 0.11855104281009879,
            "logloss": 0.7602197493912942,
            "mae": 0.27658456241123125,
            "precision": 0.7641921397379913,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8515522100252905,
            "auditor_fn_violation": 0.011952660577062492,
            "auditor_fp_violation": 0.022905906706017384,
            "ave_precision_score": 0.8519233347016472,
            "fpr": 0.14583333333333334,
            "logloss": 0.5729653836742099,
            "mae": 0.2734730414248611,
            "precision": 0.7476280834914611,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8475503277442763,
            "auditor_fn_violation": 0.01918630450521989,
            "auditor_fp_violation": 0.024731736822061437,
            "ave_precision_score": 0.8480338957760281,
            "fpr": 0.15806805708013172,
            "logloss": 0.578347606376439,
            "mae": 0.2752410347432147,
            "precision": 0.7277882797731569,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7266662944814181,
            "auditor_fn_violation": 0.009968102073365239,
            "auditor_fp_violation": 0.014669413018527627,
            "ave_precision_score": 0.7178620396430196,
            "fpr": 0.15021929824561403,
            "logloss": 1.5453959702482227,
            "mae": 0.29534210162182917,
            "precision": 0.7375478927203065,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7239411093151661,
            "auditor_fn_violation": 0.009337412709904947,
            "auditor_fp_violation": 0.014862439670343076,
            "ave_precision_score": 0.7173780792233373,
            "fpr": 0.15367727771679474,
            "logloss": 1.4927124005937111,
            "mae": 0.29189104410728606,
            "precision": 0.7265625,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8102456161248728,
            "auditor_fn_violation": 0.006141710163839352,
            "auditor_fp_violation": 0.008351778980160684,
            "ave_precision_score": 0.8146481609974603,
            "fpr": 0.07675438596491228,
            "logloss": 0.5177029597174215,
            "mae": 0.31118601222724146,
            "precision": 0.8288508557457213,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.824104965987386,
            "auditor_fn_violation": 0.0009575635845575368,
            "auditor_fp_violation": 0.011641539162316958,
            "ave_precision_score": 0.8203755845274037,
            "fpr": 0.08232711306256861,
            "logloss": 0.520520778245363,
            "mae": 0.31605263746933426,
            "precision": 0.8120300751879699,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8118172417522931,
            "auditor_fn_violation": 0.008404922430042046,
            "auditor_fp_violation": 0.008356902770946058,
            "ave_precision_score": 0.8125763003288304,
            "fpr": 0.05921052631578947,
            "logloss": 1.1368341732286755,
            "mae": 0.3147428806528904,
            "precision": 0.850415512465374,
            "recall": 0.6342975206611571
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8302291936376054,
            "auditor_fn_violation": 0.00018684167503562417,
            "auditor_fp_violation": 0.005249520225214127,
            "ave_precision_score": 0.8309732229307096,
            "fpr": 0.06256860592755215,
            "logloss": 0.9642484684265877,
            "mae": 0.3088264230093929,
            "precision": 0.8403361344537815,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.808497943414096,
            "auditor_fn_violation": 0.00942438741481804,
            "auditor_fp_violation": 0.01102639777012626,
            "ave_precision_score": 0.808807331120304,
            "fpr": 0.125,
            "logloss": 0.9602474955295921,
            "mae": 0.28200294488802324,
            "precision": 0.7564102564102564,
            "recall": 0.731404958677686
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8073655001713667,
            "auditor_fn_violation": 0.007992152649648506,
            "auditor_fp_violation": 0.01763281236387713,
            "ave_precision_score": 0.8077290128772932,
            "fpr": 0.13062568605927552,
            "logloss": 0.9852276451892938,
            "mae": 0.27914549538688666,
            "precision": 0.7473460721868365,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8157093650977897,
            "auditor_fn_violation": 0.008447966507177036,
            "auditor_fp_violation": 0.011777033120183637,
            "ave_precision_score": 0.8170119407877275,
            "fpr": 0.12390350877192982,
            "logloss": 0.8790344507084479,
            "mae": 0.2839632088584699,
            "precision": 0.7554112554112554,
            "recall": 0.7210743801652892
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8150005447112479,
            "auditor_fn_violation": 0.010264614522269193,
            "auditor_fp_violation": 0.015437422682208636,
            "ave_precision_score": 0.8153334518968243,
            "fpr": 0.13062568605927552,
            "logloss": 0.9022971906642006,
            "mae": 0.2810117736136096,
            "precision": 0.7435344827586207,
            "recall": 0.7340425531914894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.82157572642004,
            "auditor_fn_violation": 0.010258083224590403,
            "auditor_fp_violation": 0.011549024430234468,
            "ave_precision_score": 0.8223814597912694,
            "fpr": 0.125,
            "logloss": 0.7996236242781345,
            "mae": 0.27536711005247055,
            "precision": 0.7615062761506276,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.823066068136854,
            "auditor_fn_violation": 0.011560828642828792,
            "auditor_fp_violation": 0.01801862347573497,
            "ave_precision_score": 0.823403608905841,
            "fpr": 0.13391877058177826,
            "logloss": 0.7946940844063419,
            "mae": 0.2701665991836552,
            "precision": 0.7494866529774127,
            "recall": 0.776595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8319184459175311,
            "auditor_fn_violation": 0.009292989705669132,
            "auditor_fp_violation": 0.012189498278406296,
            "ave_precision_score": 0.8331004701023028,
            "fpr": 0.09320175438596491,
            "logloss": 0.6972031464928821,
            "mae": 0.282210460880918,
            "precision": 0.7995283018867925,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8394846507803875,
            "auditor_fn_violation": 0.01016885816381345,
            "auditor_fp_violation": 0.015228337950621156,
            "ave_precision_score": 0.8396814826261606,
            "fpr": 0.09989023051591657,
            "logloss": 0.6716812455614345,
            "mae": 0.27317011815853726,
            "precision": 0.7868852459016393,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8477045959736432,
            "auditor_fn_violation": 0.018823854574452663,
            "auditor_fp_violation": 0.0071015740285292695,
            "ave_precision_score": 0.8472645362721931,
            "fpr": 0.07785087719298246,
            "logloss": 0.5115718199392801,
            "mae": 0.3039469317606601,
            "precision": 0.8293269230769231,
            "recall": 0.7128099173553719
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8659828510136537,
            "auditor_fn_violation": 0.007352219912651517,
            "auditor_fp_violation": 0.009924057438562691,
            "ave_precision_score": 0.8658213425375474,
            "fpr": 0.07903402854006586,
            "logloss": 0.4914765600191036,
            "mae": 0.30107681048394036,
            "precision": 0.8248175182481752,
            "recall": 0.7212765957446808
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8511010465213582,
            "auditor_fn_violation": 0.010575250108742936,
            "auditor_fp_violation": 0.022470384489260538,
            "ave_precision_score": 0.8514507634282451,
            "fpr": 0.14802631578947367,
            "logloss": 0.5807276176662964,
            "mae": 0.27307107600567937,
            "precision": 0.7448015122873346,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8452601311290597,
            "auditor_fn_violation": 0.016091739262442492,
            "auditor_fp_violation": 0.022685693377241134,
            "ave_precision_score": 0.8458141665665817,
            "fpr": 0.16136114160263446,
            "logloss": 0.5906446699384567,
            "mae": 0.2762907584831231,
            "precision": 0.7236842105263158,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.852166479918316,
            "auditor_fn_violation": 0.013717467739596928,
            "auditor_fp_violation": 0.025408878504672897,
            "ave_precision_score": 0.8525706232661635,
            "fpr": 0.14364035087719298,
            "logloss": 0.5729127994566913,
            "mae": 0.273444045301908,
            "precision": 0.7509505703422054,
            "recall": 0.8161157024793388
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8500641954933484,
            "auditor_fn_violation": 0.018688838545437566,
            "auditor_fp_violation": 0.023069015385151513,
            "ave_precision_score": 0.8504348341297165,
            "fpr": 0.15367727771679474,
            "logloss": 0.5759219579187207,
            "mae": 0.2739851629215217,
            "precision": 0.732824427480916,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8002663083218042,
            "auditor_fn_violation": 0.013633645063070904,
            "auditor_fp_violation": 0.013050295130349238,
            "ave_precision_score": 0.8007837969937344,
            "fpr": 0.1118421052631579,
            "logloss": 1.1240027786712896,
            "mae": 0.2896444008236154,
            "precision": 0.7681818181818182,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.800703892496354,
            "auditor_fn_violation": 0.018842982927341947,
            "auditor_fp_violation": 0.017968841396785572,
            "ave_precision_score": 0.801068964322358,
            "fpr": 0.1163556531284303,
            "logloss": 1.1108198208416573,
            "mae": 0.27676186931341124,
            "precision": 0.7612612612612613,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8178732499059165,
            "auditor_fn_violation": 0.010135747426417293,
            "auditor_fp_violation": 0.011777033120183637,
            "ave_precision_score": 0.8185022355621482,
            "fpr": 0.12390350877192982,
            "logloss": 0.8760714011110425,
            "mae": 0.2819904965869252,
            "precision": 0.7575107296137339,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8154780809603323,
            "auditor_fn_violation": 0.010607936100147142,
            "auditor_fp_violation": 0.019860560396862736,
            "ave_precision_score": 0.8158271092718236,
            "fpr": 0.1394072447859495,
            "logloss": 0.8983290844518796,
            "mae": 0.27770920460264165,
            "precision": 0.735966735966736,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.818997965140855,
            "auditor_fn_violation": 0.01328476149050312,
            "auditor_fp_violation": 0.016534472864404008,
            "ave_precision_score": 0.8196344416637142,
            "fpr": 0.14692982456140352,
            "logloss": 0.7229825613284968,
            "mae": 0.28536472757565734,
            "precision": 0.732,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.822143369728406,
            "auditor_fn_violation": 0.012027932830417828,
            "auditor_fp_violation": 0.014820124903236087,
            "ave_precision_score": 0.8224428893728642,
            "fpr": 0.15697036223929747,
            "logloss": 0.7325181304683689,
            "mae": 0.2830837532496292,
            "precision": 0.7212475633528265,
            "recall": 0.7872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 8233,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8575200162319316,
            "auditor_fn_violation": 0.010167464114832533,
            "auditor_fp_violation": 0.013590855058206267,
            "ave_precision_score": 0.8575458653230073,
            "fpr": 0.13267543859649122,
            "logloss": 0.5383255614924535,
            "mae": 0.281185749997875,
            "precision": 0.7599206349206349,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8433117742982547,
            "auditor_fn_violation": 0.008071560361538641,
            "auditor_fp_violation": 0.014414400959798485,
            "ave_precision_score": 0.8433991217489161,
            "fpr": 0.150384193194292,
            "logloss": 0.5318822738198,
            "mae": 0.2845871814745903,
            "precision": 0.7318982387475538,
            "recall": 0.7957446808510639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7947928795000069,
            "auditor_fn_violation": 0.012586994345367551,
            "auditor_fp_violation": 0.013782997212657813,
            "ave_precision_score": 0.7961068787371771,
            "fpr": 0.11842105263157894,
            "logloss": 0.917588921121081,
            "mae": 0.2946972324215646,
            "precision": 0.757847533632287,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7964529635157543,
            "auditor_fn_violation": 0.014456874605880845,
            "auditor_fp_violation": 0.018078361970474247,
            "ave_precision_score": 0.7966576870090036,
            "fpr": 0.11855104281009879,
            "logloss": 0.8977115916781718,
            "mae": 0.28368281836564796,
            "precision": 0.76,
            "recall": 0.7276595744680852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8342867589770139,
            "auditor_fn_violation": 0.012455596636218645,
            "auditor_fp_violation": 0.014400414002295461,
            "ave_precision_score": 0.8346326582691196,
            "fpr": 0.11951754385964912,
            "logloss": 0.7326285587717507,
            "mae": 0.27105350443652876,
            "precision": 0.7685774946921444,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8256976845075923,
            "auditor_fn_violation": 0.01589789102459304,
            "auditor_fp_violation": 0.018526400681018844,
            "ave_precision_score": 0.8260508355808085,
            "fpr": 0.13172338090010977,
            "logloss": 0.7527114744901758,
            "mae": 0.2733678501130775,
            "precision": 0.7484276729559748,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 8233,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7382595130293299,
            "auditor_fn_violation": 0.026284072785268963,
            "auditor_fp_violation": 0.028314067879980337,
            "ave_precision_score": 0.7374205085992559,
            "fpr": 0.16228070175438597,
            "logloss": 0.8607452183576947,
            "mae": 0.3214361655164363,
            "precision": 0.7289377289377289,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7898069806760084,
            "auditor_fn_violation": 0.01708200014013126,
            "auditor_fp_violation": 0.029553131168310726,
            "ave_precision_score": 0.7888389783877544,
            "fpr": 0.1734357848518112,
            "logloss": 0.6847416194064807,
            "mae": 0.31187985266602786,
            "precision": 0.7132486388384754,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8190863849222941,
            "auditor_fn_violation": 0.024938379005364657,
            "auditor_fp_violation": 0.024291892113461225,
            "ave_precision_score": 0.8204424491585445,
            "fpr": 0.13486842105263158,
            "logloss": 0.771796310769056,
            "mae": 0.27961750676401415,
            "precision": 0.7515151515151515,
            "recall": 0.768595041322314
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8345931553860672,
            "auditor_fn_violation": 0.02357474834761894,
            "auditor_fp_violation": 0.022215252731169307,
            "ave_precision_score": 0.8348442294131732,
            "fpr": 0.13611416026344675,
            "logloss": 0.7259985608219272,
            "mae": 0.26940092724316383,
            "precision": 0.7484787018255578,
            "recall": 0.7851063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8301417422992144,
            "auditor_fn_violation": 0.010416666666666666,
            "auditor_fp_violation": 0.014879488440727994,
            "ave_precision_score": 0.8305020365659797,
            "fpr": 0.12280701754385964,
            "logloss": 0.7433018140132718,
            "mae": 0.27749382262963956,
            "precision": 0.7642105263157895,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8295730940878703,
            "auditor_fn_violation": 0.01184109115538221,
            "auditor_fp_violation": 0.01574109336379997,
            "ave_precision_score": 0.8298709289108867,
            "fpr": 0.1350164654226125,
            "logloss": 0.7486833461711506,
            "mae": 0.27346741698481575,
            "precision": 0.7453416149068323,
            "recall": 0.7659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8421868060604514,
            "auditor_fn_violation": 0.011839386689865164,
            "auditor_fp_violation": 0.011730919003115264,
            "ave_precision_score": 0.8429163272875602,
            "fpr": 0.11951754385964912,
            "logloss": 0.6427579409832913,
            "mae": 0.27179668685676106,
            "precision": 0.7705263157894737,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8428618915297651,
            "auditor_fn_violation": 0.013648784361351798,
            "auditor_fp_violation": 0.013363999093966166,
            "ave_precision_score": 0.8431490646820256,
            "fpr": 0.11964873765093303,
            "logloss": 0.6393786560233227,
            "mae": 0.26998260261907875,
            "precision": 0.7665952890792291,
            "recall": 0.7617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8156796498316868,
            "auditor_fn_violation": 0.016436041032332906,
            "auditor_fp_violation": 0.014390166420724708,
            "ave_precision_score": 0.8161589392739745,
            "fpr": 0.12390350877192982,
            "logloss": 0.8098899092913541,
            "mae": 0.27974382824739524,
            "precision": 0.7635983263598326,
            "recall": 0.7541322314049587
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8163325254953677,
            "auditor_fn_violation": 0.012693556297732209,
            "auditor_fp_violation": 0.014932134580872228,
            "ave_precision_score": 0.816648841862383,
            "fpr": 0.14928649835345773,
            "logloss": 0.8154146336565127,
            "mae": 0.2786940130904919,
            "precision": 0.7285429141716567,
            "recall": 0.776595744680851
        }
    }
]