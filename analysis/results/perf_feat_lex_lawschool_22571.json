[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7310770948262624,
            "auditor_fn_violation": 0.022741628411800295,
            "auditor_fp_violation": 0.03456956831218859,
            "ave_precision_score": 0.7229305487183679,
            "fpr": 0.15021929824561403,
            "logloss": 2.667481465558055,
            "mae": 0.31386390829514416,
            "precision": 0.7151767151767152,
            "recall": 0.6977687626774848
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7423905655095788,
            "auditor_fn_violation": 0.011207916737108036,
            "auditor_fp_violation": 0.02722283205268936,
            "ave_precision_score": 0.7366808166447887,
            "fpr": 0.13830954994511527,
            "logloss": 2.5791971115125016,
            "mae": 0.3040570388428478,
            "precision": 0.72,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6712623853860324,
            "auditor_fn_violation": 0.014438987936372383,
            "auditor_fp_violation": 0.010629945986685093,
            "ave_precision_score": 0.6670355746383585,
            "fpr": 0.049342105263157895,
            "logloss": 7.750121700449736,
            "mae": 0.441927476836443,
            "precision": 0.7704081632653061,
            "recall": 0.30628803245436104
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6518685485551299,
            "auditor_fn_violation": 0.014031921251705479,
            "auditor_fp_violation": 0.012574704232223443,
            "ave_precision_score": 0.6513178546521557,
            "fpr": 0.05159165751920966,
            "logloss": 7.364981507797229,
            "mae": 0.4184875212450009,
            "precision": 0.7417582417582418,
            "recall": 0.2928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 22571,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6118338904470396,
            "auditor_fn_violation": 0.024220668303619092,
            "auditor_fp_violation": 0.02286144956663736,
            "ave_precision_score": 0.6085036361126197,
            "fpr": 0.09539473684210527,
            "logloss": 6.0838906182145,
            "mae": 0.4583746540560696,
            "precision": 0.6679389312977099,
            "recall": 0.35496957403651114
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6106291333142709,
            "auditor_fn_violation": 0.015182000661950482,
            "auditor_fp_violation": 0.020319551164776194,
            "ave_precision_score": 0.6087802604882379,
            "fpr": 0.08781558726673985,
            "logloss": 5.897328796230957,
            "mae": 0.42659009201127335,
            "precision": 0.6825396825396826,
            "recall": 0.37310195227765725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8334274922409018,
            "auditor_fn_violation": 0.010907085157111848,
            "auditor_fp_violation": 0.024046916216555716,
            "ave_precision_score": 0.8339003491812637,
            "fpr": 0.14035087719298245,
            "logloss": 0.8694555296464952,
            "mae": 0.275111979772416,
            "precision": 0.7470355731225297,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8224162000842944,
            "auditor_fn_violation": 0.021427670005786117,
            "auditor_fp_violation": 0.026081229418221736,
            "ave_precision_score": 0.8227117024979,
            "fpr": 0.14489571899012074,
            "logloss": 0.8354838752230977,
            "mae": 0.2669528745761272,
            "precision": 0.7354709418837675,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7973417514412496,
            "auditor_fn_violation": 0.005764919397886198,
            "auditor_fp_violation": 0.017816019763011347,
            "ave_precision_score": 0.7980378110716015,
            "fpr": 0.07785087719298246,
            "logloss": 1.8972410453343853,
            "mae": 0.3547377446420389,
            "precision": 0.8070652173913043,
            "recall": 0.6024340770791075
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8013288035974782,
            "auditor_fn_violation": 0.008629167252024547,
            "auditor_fp_violation": 0.018402244176119038,
            "ave_precision_score": 0.8018286786938247,
            "fpr": 0.08342480790340286,
            "logloss": 2.0708583418030067,
            "mae": 0.33954314374134437,
            "precision": 0.7865168539325843,
            "recall": 0.6073752711496746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7543205740612414,
            "auditor_fn_violation": 0.009563716593715526,
            "auditor_fp_violation": 0.00489626512582172,
            "ave_precision_score": 0.5359965475256999,
            "fpr": 0.4407894736842105,
            "logloss": 16.084759699651578,
            "mae": 0.4680381584764869,
            "precision": 0.5379310344827586,
            "recall": 0.949290060851927
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.7293469056969097,
            "auditor_fn_violation": 0.008831562179293335,
            "auditor_fp_violation": 0.0015172582022197811,
            "ave_precision_score": 0.4959063964581275,
            "fpr": 0.47859495060373214,
            "logloss": 17.563040359051442,
            "mae": 0.5118325994460995,
            "precision": 0.497116493656286,
            "recall": 0.9349240780911063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7820139374185902,
            "auditor_fn_violation": 0.0069303583502366446,
            "auditor_fp_violation": 0.0073352384541305535,
            "ave_precision_score": 0.782575892671064,
            "fpr": 0.05482456140350877,
            "logloss": 3.372836600038353,
            "mae": 0.3483231816220137,
            "precision": 0.8269896193771626,
            "recall": 0.4847870182555781
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7473109208105647,
            "auditor_fn_violation": 0.020418076486233575,
            "auditor_fp_violation": 0.007976582510062207,
            "ave_precision_score": 0.747982943888255,
            "fpr": 0.06366630076838639,
            "logloss": 3.51104375030319,
            "mae": 0.35809298754702346,
            "precision": 0.7786259541984732,
            "recall": 0.44251626898047725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8025541673122955,
            "auditor_fn_violation": 0.012959948044553582,
            "auditor_fp_violation": 0.013976992002679732,
            "ave_precision_score": 0.8029788007014333,
            "fpr": 0.10307017543859649,
            "logloss": 2.1913790646728173,
            "mae": 0.3105164789647781,
            "precision": 0.7712895377128953,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.779258830094119,
            "auditor_fn_violation": 0.008152943893745044,
            "auditor_fp_violation": 0.019173069886571536,
            "ave_precision_score": 0.779937898792624,
            "fpr": 0.11525795828759605,
            "logloss": 2.3508073931801534,
            "mae": 0.3081236211331334,
            "precision": 0.7388059701492538,
            "recall": 0.6442516268980477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7977751363485353,
            "auditor_fn_violation": 0.013162342977118264,
            "auditor_fp_violation": 0.007774881715027428,
            "ave_precision_score": 0.7869377542167862,
            "fpr": 0.08114035087719298,
            "logloss": 1.8960197105370684,
            "mae": 0.28725228094294725,
            "precision": 0.8154613466334164,
            "recall": 0.6632860040567952
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7934839630811943,
            "auditor_fn_violation": 0.019927566427205695,
            "auditor_fp_violation": 0.013648005854372487,
            "ave_precision_score": 0.7835312004507824,
            "fpr": 0.09330406147091108,
            "logloss": 1.5989953900300917,
            "mae": 0.2800045516223552,
            "precision": 0.7853535353535354,
            "recall": 0.6746203904555315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8157393117875651,
            "auditor_fn_violation": 0.022132219493968194,
            "auditor_fp_violation": 0.02119185194489805,
            "ave_precision_score": 0.8160814456931362,
            "fpr": 0.13486842105263158,
            "logloss": 0.8428833619766798,
            "mae": 0.29766233235914663,
            "precision": 0.7453416149068323,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7490438926898219,
            "auditor_fn_violation": 0.02180626757561832,
            "auditor_fp_violation": 0.018294914013904134,
            "ave_precision_score": 0.7503242031618511,
            "fpr": 0.13172338090010977,
            "logloss": 1.0001493006976396,
            "mae": 0.2916926094002715,
            "precision": 0.7345132743362832,
            "recall": 0.720173535791757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7707646386938134,
            "auditor_fn_violation": 0.025937689050211744,
            "auditor_fp_violation": 0.028474751915588497,
            "ave_precision_score": 0.7627074285483884,
            "fpr": 0.13486842105263158,
            "logloss": 1.5682910966153114,
            "mae": 0.2871490599073473,
            "precision": 0.7469135802469136,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7892722301660404,
            "auditor_fn_violation": 0.024385017060701814,
            "auditor_fp_violation": 0.02327113062568606,
            "ave_precision_score": 0.7826346444427067,
            "fpr": 0.1207464324917673,
            "logloss": 1.3428302347441596,
            "mae": 0.2684794476771853,
            "precision": 0.755011135857461,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 22571,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7394312236463418,
            "auditor_fn_violation": 0.014519056261343019,
            "auditor_fp_violation": 0.019210840346690124,
            "ave_precision_score": 0.7382557601959527,
            "fpr": 0.12609649122807018,
            "logloss": 3.1734525826340643,
            "mae": 0.334457809194813,
            "precision": 0.7268408551068883,
            "recall": 0.6206896551724138
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7224491043741926,
            "auditor_fn_violation": 0.0077005317033795265,
            "auditor_fp_violation": 0.026037321624588366,
            "ave_precision_score": 0.7231466759221262,
            "fpr": 0.14489571899012074,
            "logloss": 3.0589682850580577,
            "mae": 0.332595186154544,
            "precision": 0.6937354988399071,
            "recall": 0.648590021691974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8087051121079399,
            "auditor_fn_violation": 0.01156542471798157,
            "auditor_fp_violation": 0.014707113846669178,
            "ave_precision_score": 0.8091146415902708,
            "fpr": 0.09539473684210527,
            "logloss": 2.1368377000024523,
            "mae": 0.3113256941613578,
            "precision": 0.7825,
            "recall": 0.6348884381338742
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7915559873847121,
            "auditor_fn_violation": 0.0016382083524814832,
            "auditor_fp_violation": 0.021383095499451155,
            "ave_precision_score": 0.7921608898954373,
            "fpr": 0.11086717892425905,
            "logloss": 2.2900483513624366,
            "mae": 0.30932316646286073,
            "precision": 0.7443037974683544,
            "recall": 0.6377440347071583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7909598776591455,
            "auditor_fn_violation": 0.009270132735489843,
            "auditor_fp_violation": 0.01602080978101579,
            "ave_precision_score": 0.7919001688995153,
            "fpr": 0.10197368421052631,
            "logloss": 2.792401281914746,
            "mae": 0.3185966378049644,
            "precision": 0.7686567164179104,
            "recall": 0.6267748478701826
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.766093973388078,
            "auditor_fn_violation": 0.008000552419095612,
            "auditor_fp_violation": 0.016131235516526406,
            "ave_precision_score": 0.7671684658046222,
            "fpr": 0.11745334796926454,
            "logloss": 2.7451147583338606,
            "mae": 0.3166787199199239,
            "precision": 0.7331670822942643,
            "recall": 0.6377440347071583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8126134914900821,
            "auditor_fn_violation": 0.01089596455642148,
            "auditor_fp_violation": 0.010433676673784701,
            "ave_precision_score": 0.8130441826251723,
            "fpr": 0.08223684210526316,
            "logloss": 2.248662292640019,
            "mae": 0.3068643649084501,
            "precision": 0.7989276139410187,
            "recall": 0.6044624746450304
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7788715798858932,
            "auditor_fn_violation": 0.014498620142819385,
            "auditor_fp_violation": 0.01607025246981339,
            "ave_precision_score": 0.7795590783808155,
            "fpr": 0.0889132821075741,
            "logloss": 2.3183978527226063,
            "mae": 0.31370187363256474,
            "precision": 0.7685714285714286,
            "recall": 0.5835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7959647917422714,
            "auditor_fn_violation": 0.015277481228426032,
            "auditor_fp_violation": 0.021411673575346485,
            "ave_precision_score": 0.7964686882588142,
            "fpr": 0.09978070175438597,
            "logloss": 2.17912370597194,
            "mae": 0.3143021398756425,
            "precision": 0.7725,
            "recall": 0.6267748478701826
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7695452436624982,
            "auditor_fn_violation": 0.0002928773653418996,
            "auditor_fp_violation": 0.017563117453347977,
            "ave_precision_score": 0.7701471656945806,
            "fpr": 0.10976948408342481,
            "logloss": 2.301202214073318,
            "mae": 0.31121348286933814,
            "precision": 0.7435897435897436,
            "recall": 0.6290672451193059
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7943289303228471,
            "auditor_fn_violation": 0.012328297925340737,
            "auditor_fp_violation": 0.016449985345224637,
            "ave_precision_score": 0.7932626719455846,
            "fpr": 0.13267543859649122,
            "logloss": 1.0183868707408348,
            "mae": 0.26839519728720496,
            "precision": 0.7655038759689923,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8070168898134913,
            "auditor_fn_violation": 0.014196218310311908,
            "auditor_fp_violation": 0.02334431028174168,
            "ave_precision_score": 0.8063410350542536,
            "fpr": 0.13172338090010977,
            "logloss": 0.8680733934095839,
            "mae": 0.2601101506529564,
            "precision": 0.7560975609756098,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7786059287628818,
            "auditor_fn_violation": 0.007864488808227465,
            "auditor_fp_violation": 0.017114684084913952,
            "ave_precision_score": 0.7791315497315896,
            "fpr": 0.1074561403508772,
            "logloss": 2.732740698726759,
            "mae": 0.32730854207598015,
            "precision": 0.7556109725685786,
            "recall": 0.6146044624746451
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7547986909006635,
            "auditor_fn_violation": 0.0052217891235347225,
            "auditor_fp_violation": 0.019670691547749728,
            "ave_precision_score": 0.7555686550957931,
            "fpr": 0.11855104281009879,
            "logloss": 2.7841154023256807,
            "mae": 0.3236023906198589,
            "precision": 0.7265822784810126,
            "recall": 0.6225596529284165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6313591119418394,
            "auditor_fn_violation": 0.011316323262517355,
            "auditor_fp_violation": 0.01608361596114391,
            "ave_precision_score": 0.6247491973343532,
            "fpr": 0.2708333333333333,
            "logloss": 3.4277419634038515,
            "mae": 0.39118983403472923,
            "precision": 0.6158631415241057,
            "recall": 0.8032454361054767
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6017759391444735,
            "auditor_fn_violation": 0.012067499898802536,
            "auditor_fp_violation": 0.023044273691913655,
            "ave_precision_score": 0.5960613970952799,
            "fpr": 0.3106476399560922,
            "logloss": 3.67392437083033,
            "mae": 0.4198817433256714,
            "precision": 0.5646153846153846,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.793148266960222,
            "auditor_fn_violation": 0.004276983025515106,
            "auditor_fp_violation": 0.014385232173512539,
            "ave_precision_score": 0.7940132651546892,
            "fpr": 0.09758771929824561,
            "logloss": 2.915963250543562,
            "mae": 0.32061671699428235,
            "precision": 0.7717948717948718,
            "recall": 0.6105476673427992
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7664694166387644,
            "auditor_fn_violation": 0.012319898278690674,
            "auditor_fp_violation": 0.01764117575314063,
            "ave_precision_score": 0.7675481050854038,
            "fpr": 0.1141602634467618,
            "logloss": 2.8411291254495534,
            "mae": 0.31984669912946206,
            "precision": 0.7298701298701299,
            "recall": 0.6095444685466378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8397359649483647,
            "auditor_fn_violation": 0.01580237358101135,
            "auditor_fp_violation": 0.021081941129673824,
            "ave_precision_score": 0.8401918238696247,
            "fpr": 0.13267543859649122,
            "logloss": 0.8936441044258986,
            "mae": 0.26668428224755447,
            "precision": 0.7575150300601202,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8312965499706766,
            "auditor_fn_violation": 0.023268273285536382,
            "auditor_fp_violation": 0.025295767776558127,
            "ave_precision_score": 0.8315557122271686,
            "fpr": 0.14270032930845225,
            "logloss": 0.8453976373041646,
            "mae": 0.2658500274376922,
            "precision": 0.7352342158859471,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8032088792536786,
            "auditor_fn_violation": 0.016089285078822818,
            "auditor_fp_violation": 0.021050538039609767,
            "ave_precision_score": 0.8020399449766782,
            "fpr": 0.12938596491228072,
            "logloss": 1.0487345881889203,
            "mae": 0.2761310037375454,
            "precision": 0.7586912065439673,
            "recall": 0.7525354969574036
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8049745868846097,
            "auditor_fn_violation": 0.01135078374459189,
            "auditor_fp_violation": 0.026300768386388586,
            "ave_precision_score": 0.8053685123778135,
            "fpr": 0.1251372118551043,
            "logloss": 0.885224537663434,
            "mae": 0.264422808272593,
            "precision": 0.7574468085106383,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7958397079803132,
            "auditor_fn_violation": 0.012548485819010002,
            "auditor_fp_violation": 0.018556609303688815,
            "ave_precision_score": 0.7941061716755664,
            "fpr": 0.12171052631578948,
            "logloss": 1.113511827024991,
            "mae": 0.28078366619126593,
            "precision": 0.76875,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.793949571364798,
            "auditor_fn_violation": 0.013189005907550762,
            "auditor_fp_violation": 0.02541529454811563,
            "ave_precision_score": 0.7939668034986835,
            "fpr": 0.13062568605927552,
            "logloss": 0.9348210281870519,
            "mae": 0.2714074787529037,
            "precision": 0.7457264957264957,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7345554817155152,
            "auditor_fn_violation": 0.01781520230596776,
            "auditor_fp_violation": 0.026930766654105435,
            "ave_precision_score": 0.7269507329698814,
            "fpr": 0.14692982456140352,
            "logloss": 2.65040012820964,
            "mae": 0.3153714867737731,
            "precision": 0.7202505219206681,
            "recall": 0.6997971602434077
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7432527258687116,
            "auditor_fn_violation": 0.011717475730467108,
            "auditor_fp_violation": 0.02425905598243688,
            "ave_precision_score": 0.7375890963775646,
            "fpr": 0.14818880351262348,
            "logloss": 2.57537371076412,
            "mae": 0.3061263487532582,
            "precision": 0.7071583514099783,
            "recall": 0.7071583514099783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6549937542395874,
            "auditor_fn_violation": 0.006921461869684383,
            "auditor_fp_violation": 0.0032449859732864386,
            "ave_precision_score": 0.6568758292475753,
            "fpr": 0.007675438596491228,
            "logloss": 4.4614125567428955,
            "mae": 0.5044763086455537,
            "precision": 0.8627450980392157,
            "recall": 0.08924949290060852
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6240823579605959,
            "auditor_fn_violation": 0.005943267511328171,
            "auditor_fp_violation": 0.003654104159043786,
            "ave_precision_score": 0.6251088768683883,
            "fpr": 0.007683863885839737,
            "logloss": 4.324472118003194,
            "mae": 0.473408242259551,
            "precision": 0.8372093023255814,
            "recall": 0.07809110629067245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.798222772688784,
            "auditor_fn_violation": 0.015922476068467317,
            "auditor_fp_violation": 0.023172863543105975,
            "ave_precision_score": 0.7979805566581466,
            "fpr": 0.13157894736842105,
            "logloss": 1.0548657287779024,
            "mae": 0.27818129500241967,
            "precision": 0.7560975609756098,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8065136841981477,
            "auditor_fn_violation": 0.009910208085796401,
            "auditor_fp_violation": 0.02685693377241127,
            "ave_precision_score": 0.8064551328901862,
            "fpr": 0.132821075740944,
            "logloss": 0.9088436790615202,
            "mae": 0.2683029701928287,
            "precision": 0.7473903966597077,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7849334670315974,
            "auditor_fn_violation": 0.013106739973666418,
            "auditor_fp_violation": 0.027901645521919358,
            "ave_precision_score": 0.7861793597676912,
            "fpr": 0.10307017543859649,
            "logloss": 2.6018787703573953,
            "mae": 0.36169180044341026,
            "precision": 0.7712895377128953,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7920813088123158,
            "auditor_fn_violation": 0.011307923642346738,
            "auditor_fp_violation": 0.029027930235394562,
            "ave_precision_score": 0.7931538835384387,
            "fpr": 0.12623490669593854,
            "logloss": 2.6081972887068807,
            "mae": 0.350374935448358,
            "precision": 0.720873786407767,
            "recall": 0.6442516268980477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6068620160113585,
            "auditor_fn_violation": 0.01703676025764208,
            "auditor_fp_violation": 0.025737449231671063,
            "ave_precision_score": 0.6049660620361715,
            "fpr": 0.08223684210526316,
            "logloss": 7.198141454351283,
            "mae": 0.472135982816138,
            "precision": 0.668141592920354,
            "recall": 0.30628803245436104
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5929223655026485,
            "auditor_fn_violation": 0.011707951263301522,
            "auditor_fp_violation": 0.011952677155750702,
            "ave_precision_score": 0.5931233480483705,
            "fpr": 0.08122941822173436,
            "logloss": 7.002799903805224,
            "mae": 0.44631851780631726,
            "precision": 0.6605504587155964,
            "recall": 0.3123644251626898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7423491058069904,
            "auditor_fn_violation": 0.01821999217109712,
            "auditor_fp_violation": 0.038403362224176195,
            "ave_precision_score": 0.7308574809805117,
            "fpr": 0.17324561403508773,
            "logloss": 1.7811280129463691,
            "mae": 0.2897852704740224,
            "precision": 0.7148014440433214,
            "recall": 0.8032454361054767
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.777826950972906,
            "auditor_fn_violation": 0.018170302235154336,
            "auditor_fp_violation": 0.033301622149042566,
            "ave_precision_score": 0.7677773330126523,
            "fpr": 0.1668496158068057,
            "logloss": 1.5396552800778964,
            "mae": 0.27193450976549555,
            "precision": 0.7132075471698113,
            "recall": 0.8199566160520607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8082591215366272,
            "auditor_fn_violation": 0.009007686559197182,
            "auditor_fp_violation": 0.00893156219905372,
            "ave_precision_score": 0.7919729214867478,
            "fpr": 0.11403508771929824,
            "logloss": 1.290017944473177,
            "mae": 0.3074922943855391,
            "precision": 0.7907444668008048,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.7908723562777971,
            "auditor_fn_violation": 0.00311211964635654,
            "auditor_fp_violation": 0.012001463593121117,
            "ave_precision_score": 0.7719978711860763,
            "fpr": 0.11306256860592755,
            "logloss": 1.4630470453822524,
            "mae": 0.3016917221789973,
            "precision": 0.7784946236559139,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7567166615201846,
            "auditor_fn_violation": 0.006200846944948578,
            "auditor_fp_violation": 0.004587468073525118,
            "ave_precision_score": 0.536835555266505,
            "fpr": 0.4440789473684211,
            "logloss": 15.866277885869893,
            "mae": 0.4632180623916611,
            "precision": 0.5402951191827469,
            "recall": 0.9655172413793104
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.7345997484897824,
            "auditor_fn_violation": 0.010067361794028635,
            "auditor_fp_violation": 0.0024588364434687186,
            "ave_precision_score": 0.4996377332535439,
            "fpr": 0.4796926454445664,
            "logloss": 17.24523366175109,
            "mae": 0.5069812006213973,
            "precision": 0.49942726231386025,
            "recall": 0.9457700650759219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7911398577433685,
            "auditor_fn_violation": 0.008614017294758195,
            "auditor_fp_violation": 0.023060335803709756,
            "ave_precision_score": 0.7910767190768113,
            "fpr": 0.1337719298245614,
            "logloss": 1.315241288772717,
            "mae": 0.2839913026806381,
            "precision": 0.7479338842975206,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7874048109292855,
            "auditor_fn_violation": 0.0057242047665195936,
            "auditor_fp_violation": 0.02644224905476278,
            "ave_precision_score": 0.7873900522786093,
            "fpr": 0.14270032930845225,
            "logloss": 1.4747596903146158,
            "mae": 0.2895834965104657,
            "precision": 0.7257383966244726,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.85180903569281,
            "auditor_fn_violation": 0.017946425394114097,
            "auditor_fp_violation": 0.0023971025415567586,
            "ave_precision_score": 0.8512462428553063,
            "fpr": 0.0668859649122807,
            "logloss": 2.285942289938075,
            "mae": 0.2600950786672818,
            "precision": 0.8407310704960835,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8386642547767937,
            "auditor_fn_violation": 0.011857961621159556,
            "auditor_fp_violation": 0.011047688742529576,
            "ave_precision_score": 0.8391433320086841,
            "fpr": 0.0801317233809001,
            "logloss": 2.343222824003304,
            "mae": 0.2522864284384078,
            "precision": 0.8078947368421052,
            "recall": 0.665943600867679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7111503278060767,
            "auditor_fn_violation": 0.015232998825664573,
            "auditor_fp_violation": 0.023322028220910274,
            "ave_precision_score": 0.7118172783785579,
            "fpr": 0.13157894736842105,
            "logloss": 4.291256646866225,
            "mae": 0.360404451958799,
            "precision": 0.708029197080292,
            "recall": 0.59026369168357
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.657844523360559,
            "auditor_fn_violation": 0.02495648509063722,
            "auditor_fp_violation": 0.02221734357848518,
            "ave_precision_score": 0.6590532515102681,
            "fpr": 0.14928649835345773,
            "logloss": 4.854702224916369,
            "mae": 0.3893980509940547,
            "precision": 0.6521739130434783,
            "recall": 0.5531453362255966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7770306191873256,
            "auditor_fn_violation": 0.017401515960286114,
            "auditor_fp_violation": 0.02572959845915505,
            "ave_precision_score": 0.7770095733419097,
            "fpr": 0.14364035087719298,
            "logloss": 2.225691000340255,
            "mae": 0.3056784550026073,
            "precision": 0.7298969072164948,
            "recall": 0.718052738336714
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7526664012500446,
            "auditor_fn_violation": 0.009436365844308296,
            "auditor_fp_violation": 0.027961946578851076,
            "ave_precision_score": 0.7534788162685527,
            "fpr": 0.16575192096597147,
            "logloss": 2.3647395156377833,
            "mae": 0.3120409947153135,
            "precision": 0.688659793814433,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.821292865065602,
            "auditor_fn_violation": 0.02242580335219387,
            "auditor_fp_violation": 0.019260561905958214,
            "ave_precision_score": 0.8220338802489584,
            "fpr": 0.12171052631578948,
            "logloss": 0.9849246614537269,
            "mae": 0.285564198577232,
            "precision": 0.7607758620689655,
            "recall": 0.716024340770791
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8045165630657052,
            "auditor_fn_violation": 0.01823935462210486,
            "auditor_fp_violation": 0.012684473716306868,
            "ave_precision_score": 0.8049195986577747,
            "fpr": 0.12733260153677278,
            "logloss": 0.9987583771730822,
            "mae": 0.282975873130207,
            "precision": 0.7422222222222222,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.703795295453117,
            "auditor_fn_violation": 0.018769349845201243,
            "auditor_fp_violation": 0.024397584055604406,
            "ave_precision_score": 0.7022703850636718,
            "fpr": 0.09100877192982457,
            "logloss": 6.037847903180677,
            "mae": 0.41552924583153694,
            "precision": 0.7097902097902098,
            "recall": 0.4117647058823529
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6782885031045046,
            "auditor_fn_violation": 0.006571882344257115,
            "auditor_fp_violation": 0.019804854250518356,
            "ave_precision_score": 0.6774644878918245,
            "fpr": 0.0867178924259056,
            "logloss": 5.989146694554481,
            "mae": 0.39025593123125374,
            "precision": 0.7116788321167883,
            "recall": 0.4229934924078091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7961646959666882,
            "auditor_fn_violation": 0.01771734101989253,
            "auditor_fp_violation": 0.02800370556462757,
            "ave_precision_score": 0.7936770548143421,
            "fpr": 0.14802631578947367,
            "logloss": 1.121347119692938,
            "mae": 0.27158396628557757,
            "precision": 0.7413793103448276,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7934293350695143,
            "auditor_fn_violation": 0.016853544649511516,
            "auditor_fp_violation": 0.018563239419441394,
            "ave_precision_score": 0.7912179485847173,
            "fpr": 0.14928649835345773,
            "logloss": 1.093165739150436,
            "mae": 0.26880095877578386,
            "precision": 0.7301587301587301,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7322785828624409,
            "auditor_fn_violation": 0.02977874452866446,
            "auditor_fp_violation": 0.04435686471548801,
            "ave_precision_score": 0.6895817575296913,
            "fpr": 0.17982456140350878,
            "logloss": 3.3470152536290594,
            "mae": 0.2952959702602464,
            "precision": 0.7087033747779752,
            "recall": 0.8093306288032455
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7381930561707499,
            "auditor_fn_violation": 0.02875198525612483,
            "auditor_fp_violation": 0.0389071838029028,
            "ave_precision_score": 0.6914368477244685,
            "fpr": 0.18880351262349068,
            "logloss": 3.2403386295886123,
            "mae": 0.2901918005986232,
            "precision": 0.6872727272727273,
            "recall": 0.8199566160520607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7734107071809802,
            "auditor_fn_violation": 0.020982349382584253,
            "auditor_fp_violation": 0.02628700330779215,
            "ave_precision_score": 0.773636698035338,
            "fpr": 0.125,
            "logloss": 2.333739941514081,
            "mae": 0.3130497592598543,
            "precision": 0.7449664429530202,
            "recall": 0.6754563894523327
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7483931609068892,
            "auditor_fn_violation": 0.0030764028944855683,
            "auditor_fp_violation": 0.02801317233809002,
            "ave_precision_score": 0.7496979762555421,
            "fpr": 0.13830954994511527,
            "logloss": 2.4522360747961898,
            "mae": 0.3114276402607781,
            "precision": 0.7129840546697038,
            "recall": 0.6789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8027072190830793,
            "auditor_fn_violation": 0.009078858403615534,
            "auditor_fp_violation": 0.01320761629611021,
            "ave_precision_score": 0.8009585661945992,
            "fpr": 0.1611842105263158,
            "logloss": 1.0327876582124453,
            "mae": 0.27601783377823813,
            "precision": 0.7272727272727273,
            "recall": 0.795131845841785
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8000428037728893,
            "auditor_fn_violation": 0.008012458003052595,
            "auditor_fp_violation": 0.030601292840590315,
            "ave_precision_score": 0.7999475645085992,
            "fpr": 0.17014270032930845,
            "logloss": 0.9863323169164145,
            "mae": 0.2742294367779659,
            "precision": 0.7113594040968343,
            "recall": 0.8286334056399133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7689523588213133,
            "auditor_fn_violation": 0.003109319953026583,
            "auditor_fp_violation": 0.0018161453753716124,
            "ave_precision_score": 0.5434917149608606,
            "fpr": 0.44846491228070173,
            "logloss": 15.717091043625945,
            "mae": 0.45511694237759776,
            "precision": 0.5435267857142857,
            "recall": 0.9878296146044625
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.742770918431234,
            "auditor_fn_violation": 0.005150355619792796,
            "auditor_fp_violation": 0.004742041712403956,
            "ave_precision_score": 0.5029281436518737,
            "fpr": 0.4840834248079034,
            "logloss": 17.265008469192693,
            "mae": 0.5018318081461599,
            "precision": 0.5022573363431151,
            "recall": 0.96529284164859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8003114020799117,
            "auditor_fn_violation": 0.01039776164549305,
            "auditor_fp_violation": 0.027260499099778096,
            "ave_precision_score": 0.7988414926084372,
            "fpr": 0.14802631578947367,
            "logloss": 1.0626170733328164,
            "mae": 0.2720401230389199,
            "precision": 0.7428571428571429,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8027767496330678,
            "auditor_fn_violation": 0.014989130201847273,
            "auditor_fp_violation": 0.02736919136480059,
            "ave_precision_score": 0.8028564228793532,
            "fpr": 0.1668496158068057,
            "logloss": 0.9829238360128583,
            "mae": 0.2703734316362015,
            "precision": 0.7099236641221374,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7701794518595937,
            "auditor_fn_violation": 0.017908615351766844,
            "auditor_fp_violation": 0.023319411296738268,
            "ave_precision_score": 0.7713517551058725,
            "fpr": 0.14912280701754385,
            "logloss": 1.28877771426031,
            "mae": 0.28088904510287166,
            "precision": 0.734375,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7309018785420867,
            "auditor_fn_violation": 0.01646304149572233,
            "auditor_fp_violation": 0.01732894255397,
            "ave_precision_score": 0.7300936305934127,
            "fpr": 0.15148188803512624,
            "logloss": 1.4509256706813,
            "mae": 0.27776125320705825,
            "precision": 0.7261904761904762,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 22571,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8035893022810544,
            "auditor_fn_violation": 0.010813672111312761,
            "auditor_fp_violation": 0.02137765356111042,
            "ave_precision_score": 0.8024012345743432,
            "fpr": 0.12828947368421054,
            "logloss": 1.1386877122642711,
            "mae": 0.2793323365138303,
            "precision": 0.7572614107883817,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8051141619464577,
            "auditor_fn_violation": 0.014910553347731158,
            "auditor_fp_violation": 0.02693743139407245,
            "ave_precision_score": 0.805611824227091,
            "fpr": 0.12184412733260154,
            "logloss": 1.0105867101842125,
            "mae": 0.26377036963582967,
            "precision": 0.7597402597402597,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.786795076704419,
            "auditor_fn_violation": 0.013391427351339809,
            "auditor_fp_violation": 0.013312293262990412,
            "ave_precision_score": 0.7878194899684418,
            "fpr": 0.08991228070175439,
            "logloss": 3.214435092163433,
            "mae": 0.3275331744426099,
            "precision": 0.7771739130434783,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7603424793440663,
            "auditor_fn_violation": 0.014512906843567775,
            "auditor_fp_violation": 0.01975850713501647,
            "ave_precision_score": 0.7616389310119213,
            "fpr": 0.09879253567508232,
            "logloss": 3.112788717150273,
            "mae": 0.32632527047824983,
            "precision": 0.7486033519553073,
            "recall": 0.5813449023861171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.696893156139347,
            "auditor_fn_violation": 0.01405199103234761,
            "auditor_fp_violation": 0.01936523887283842,
            "ave_precision_score": 0.6946570515184589,
            "fpr": 0.20065789473684212,
            "logloss": 2.465661034443526,
            "mae": 0.3493028476396793,
            "precision": 0.6737967914438503,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6759667656914223,
            "auditor_fn_violation": 0.006702843767783968,
            "auditor_fp_violation": 0.01964629832906454,
            "ave_precision_score": 0.6746554828805735,
            "fpr": 0.2283205268935236,
            "logloss": 2.5587224695869875,
            "mae": 0.36293996110001064,
            "precision": 0.631858407079646,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7471378525886307,
            "auditor_fn_violation": 0.01411649051635173,
            "auditor_fp_violation": 0.022102541556755853,
            "ave_precision_score": 0.745625608382978,
            "fpr": 0.13596491228070176,
            "logloss": 2.8360624285068776,
            "mae": 0.3242700513875145,
            "precision": 0.7238307349665924,
            "recall": 0.6592292089249493
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7314406318276585,
            "auditor_fn_violation": 0.006676651483078604,
            "auditor_fp_violation": 0.02371020856201976,
            "ave_precision_score": 0.7311427119048874,
            "fpr": 0.14818880351262348,
            "logloss": 2.861350386625985,
            "mae": 0.32620326790044174,
            "precision": 0.6938775510204082,
            "recall": 0.6637744034707158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7376311835277265,
            "auditor_fn_violation": 0.03128669798227821,
            "auditor_fp_violation": 0.03128271155215007,
            "ave_precision_score": 0.7271132555205255,
            "fpr": 0.14692982456140352,
            "logloss": 1.5726627654521828,
            "mae": 0.29473305323015164,
            "precision": 0.7387914230019493,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7642339415834787,
            "auditor_fn_violation": 0.026632791311781055,
            "auditor_fp_violation": 0.02984754238321747,
            "ave_precision_score": 0.7558727914701135,
            "fpr": 0.14928649835345773,
            "logloss": 1.4181944790674297,
            "mae": 0.283801462991945,
            "precision": 0.7274549098196392,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6764732787785774,
            "auditor_fn_violation": 0.013504857478381557,
            "auditor_fp_violation": 0.011017250764141857,
            "ave_precision_score": 0.6741849725973483,
            "fpr": 0.046052631578947366,
            "logloss": 7.259524303482222,
            "mae": 0.43365828019943486,
            "precision": 0.79,
            "recall": 0.3204868154158215
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6546664494044219,
            "auditor_fn_violation": 0.010195942100764108,
            "auditor_fp_violation": 0.009440175631174535,
            "ave_precision_score": 0.6544995587168678,
            "fpr": 0.04939626783754116,
            "logloss": 7.051356976995401,
            "mae": 0.4115527421553161,
            "precision": 0.7606382978723404,
            "recall": 0.31019522776572667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7635272363543764,
            "auditor_fn_violation": 0.026856250667236046,
            "auditor_fp_violation": 0.03533632709458611,
            "ave_precision_score": 0.7533120575867385,
            "fpr": 0.13815789473684212,
            "logloss": 1.7217336201117355,
            "mae": 0.2877700896342079,
            "precision": 0.7454545454545455,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7881512054687172,
            "auditor_fn_violation": 0.021489579042362456,
            "auditor_fp_violation": 0.027774118794975003,
            "ave_precision_score": 0.779808035823204,
            "fpr": 0.13062568605927552,
            "logloss": 1.4478038690414992,
            "mae": 0.26532590254602323,
            "precision": 0.7484143763213531,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7950910365816487,
            "auditor_fn_violation": 0.016647539233479235,
            "auditor_fp_violation": 0.013464074864966712,
            "ave_precision_score": 0.7955998305130337,
            "fpr": 0.10197368421052631,
            "logloss": 2.3534969902300347,
            "mae": 0.32100344825879157,
            "precision": 0.7651515151515151,
            "recall": 0.6146044624746451
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7689141297660762,
            "auditor_fn_violation": 0.01512723497574833,
            "auditor_fp_violation": 0.016882546652030737,
            "ave_precision_score": 0.7695893388895403,
            "fpr": 0.11086717892425905,
            "logloss": 2.510984382847983,
            "mae": 0.3146683439110312,
            "precision": 0.7449494949494949,
            "recall": 0.6399132321041214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 22571,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7808124545389701,
            "auditor_fn_violation": 0.009932920536635708,
            "auditor_fp_violation": 0.006681007411129257,
            "ave_precision_score": 0.7813595908690485,
            "fpr": 0.03728070175438596,
            "logloss": 4.115323588319045,
            "mae": 0.3698762345898141,
            "precision": 0.8559322033898306,
            "recall": 0.40973630831643004
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7457287168500807,
            "auditor_fn_violation": 0.011874629438699335,
            "auditor_fp_violation": 0.007639956092206367,
            "ave_precision_score": 0.7464001710042435,
            "fpr": 0.03951701427003293,
            "logloss": 4.225040561925547,
            "mae": 0.3682664196757998,
            "precision": 0.824390243902439,
            "recall": 0.3665943600867679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6661953340710405,
            "auditor_fn_violation": 0.004661755809401801,
            "auditor_fp_violation": 0.01032638278273249,
            "ave_precision_score": 0.6552561889763602,
            "fpr": 0.3048245614035088,
            "logloss": 2.3596929357990803,
            "mae": 0.34841077468504084,
            "precision": 0.6263440860215054,
            "recall": 0.9452332657200812
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6472726618711695,
            "auditor_fn_violation": 0.005290841510485248,
            "auditor_fp_violation": 0.009425539699963431,
            "ave_precision_score": 0.636720748738894,
            "fpr": 0.3545554335894621,
            "logloss": 2.4796159821556882,
            "mae": 0.3864060320838937,
            "precision": 0.5716180371352785,
            "recall": 0.9349240780911063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7935300271995133,
            "auditor_fn_violation": 0.011972438703249001,
            "auditor_fp_violation": 0.02405476698907173,
            "ave_precision_score": 0.7917720961116751,
            "fpr": 0.12828947368421054,
            "logloss": 1.147563929080168,
            "mae": 0.281497380525825,
            "precision": 0.7567567567567568,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7926608408059361,
            "auditor_fn_violation": 0.01603444047327078,
            "auditor_fp_violation": 0.028261983168679113,
            "ave_precision_score": 0.7926603448817369,
            "fpr": 0.13391877058177826,
            "logloss": 0.9579856143072357,
            "mae": 0.2725302336885558,
            "precision": 0.7426160337552743,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6896487918643738,
            "auditor_fn_violation": 0.013042240489662299,
            "auditor_fp_violation": 0.01495833856718168,
            "ave_precision_score": 0.6873789787406046,
            "fpr": 0.06578947368421052,
            "logloss": 6.371338068812933,
            "mae": 0.42160290548635243,
            "precision": 0.75,
            "recall": 0.36511156186612576
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6787534179183194,
            "auditor_fn_violation": 0.011979398577520846,
            "auditor_fp_violation": 0.010298816928893768,
            "ave_precision_score": 0.6781550942530877,
            "fpr": 0.05817782656421515,
            "logloss": 6.20366484417563,
            "mae": 0.39042484770209024,
            "precision": 0.771551724137931,
            "recall": 0.3882863340563991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7612973251424457,
            "auditor_fn_violation": 0.006200846944948578,
            "auditor_fp_violation": 0.003412469120294772,
            "ave_precision_score": 0.5533360185990951,
            "fpr": 0.4451754385964912,
            "logloss": 15.088443353873663,
            "mae": 0.463186144841845,
            "precision": 0.5396825396825397,
            "recall": 0.9655172413793104
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.74144623320714,
            "auditor_fn_violation": 0.00946255812901367,
            "auditor_fp_violation": 0.0032589340163434516,
            "ave_precision_score": 0.5153743351256758,
            "fpr": 0.47859495060373214,
            "logloss": 16.52372841113552,
            "mae": 0.5051548138867532,
            "precision": 0.5005727376861397,
            "recall": 0.9479392624728851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8024507983277099,
            "auditor_fn_violation": 0.015544375644994836,
            "auditor_fp_violation": 0.014202047481472174,
            "ave_precision_score": 0.8028804078770787,
            "fpr": 0.10307017543859649,
            "logloss": 2.2088133233141183,
            "mae": 0.31107932905520486,
            "precision": 0.7712895377128953,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7794931798722998,
            "auditor_fn_violation": 0.007152874841358097,
            "auditor_fp_violation": 0.021822173435784863,
            "ave_precision_score": 0.7801481662973966,
            "fpr": 0.1163556531284303,
            "logloss": 2.3666367687892342,
            "mae": 0.3089869689608068,
            "precision": 0.7376237623762376,
            "recall": 0.6464208242950108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8060910914020041,
            "auditor_fn_violation": 0.012577399380804957,
            "auditor_fp_violation": 0.01586379433069548,
            "ave_precision_score": 0.8065957886090751,
            "fpr": 0.13925438596491227,
            "logloss": 0.9611038837731557,
            "mae": 0.30023228721853107,
            "precision": 0.7326315789473684,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7918417483275277,
            "auditor_fn_violation": 0.010081648494777027,
            "auditor_fp_violation": 0.02112940602512502,
            "ave_precision_score": 0.7922142305259333,
            "fpr": 0.14050493962678376,
            "logloss": 0.9214975522858035,
            "mae": 0.28623276220955957,
            "precision": 0.7293868921775899,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7305878528373928,
            "auditor_fn_violation": 0.013814010177573752,
            "auditor_fp_violation": 0.031248691537913997,
            "ave_precision_score": 0.7216861022743455,
            "fpr": 0.16337719298245615,
            "logloss": 2.448054049155588,
            "mae": 0.32645647763552593,
            "precision": 0.707843137254902,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7340731171759466,
            "auditor_fn_violation": 0.011193630036359663,
            "auditor_fp_violation": 0.03189413343090621,
            "ave_precision_score": 0.7281389340349305,
            "fpr": 0.17014270032930845,
            "logloss": 2.5420365466989203,
            "mae": 0.32204964804927483,
            "precision": 0.69,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7997692936174228,
            "auditor_fn_violation": 0.006207519305362797,
            "auditor_fp_violation": 0.006715027425365323,
            "ave_precision_score": 0.800380233612694,
            "fpr": 0.044956140350877194,
            "logloss": 2.3252228193892894,
            "mae": 0.3407706383527966,
            "precision": 0.8673139158576052,
            "recall": 0.5436105476673428
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.786441266190752,
            "auditor_fn_violation": 0.004274104640558515,
            "auditor_fp_violation": 0.006893523600439082,
            "ave_precision_score": 0.7881415215214324,
            "fpr": 0.059275521405049394,
            "logloss": 2.2711160182049754,
            "mae": 0.32608706809587396,
            "precision": 0.8217821782178217,
            "recall": 0.5401301518438177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8064565346345307,
            "auditor_fn_violation": 0.010422226967011852,
            "auditor_fp_violation": 0.01333584558053846,
            "ave_precision_score": 0.806923326750728,
            "fpr": 0.08552631578947369,
            "logloss": 2.167529984996399,
            "mae": 0.31102258957051654,
            "precision": 0.7947368421052632,
            "recall": 0.6125760649087221
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7744638019099394,
            "auditor_fn_violation": 0.01365808591545607,
            "auditor_fp_violation": 0.014284668862056352,
            "ave_precision_score": 0.7751503604275183,
            "fpr": 0.09220636663007684,
            "logloss": 2.2147530942077274,
            "mae": 0.3160488858971677,
            "precision": 0.7633802816901408,
            "recall": 0.5878524945770065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8019641903420063,
            "auditor_fn_violation": 0.014917173766058153,
            "auditor_fp_violation": 0.014079052045387935,
            "ave_precision_score": 0.8023940902139373,
            "fpr": 0.10197368421052631,
            "logloss": 2.2172441814302792,
            "mae": 0.31104257662192814,
            "precision": 0.7731707317073171,
            "recall": 0.6430020283975659
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7790020301796898,
            "auditor_fn_violation": 0.007371937586166668,
            "auditor_fp_violation": 0.02246615440907428,
            "ave_precision_score": 0.779660336471162,
            "fpr": 0.11525795828759605,
            "logloss": 2.3754219673859818,
            "mae": 0.30915706844471375,
            "precision": 0.7388059701492538,
            "recall": 0.6442516268980477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6826181933317119,
            "auditor_fn_violation": 0.002958079783637597,
            "auditor_fp_violation": 0.010281895071808404,
            "ave_precision_score": 0.6814082812238149,
            "fpr": 0.08771929824561403,
            "logloss": 6.09735676426325,
            "mae": 0.4198859807027396,
            "precision": 0.7090909090909091,
            "recall": 0.39553752535496955
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6658347071265418,
            "auditor_fn_violation": 0.0023977846089373034,
            "auditor_fp_violation": 0.014296865471398957,
            "ave_precision_score": 0.6652086324663762,
            "fpr": 0.07793633369923161,
            "logloss": 6.008034936630524,
            "mae": 0.39615751348119915,
            "precision": 0.7269230769230769,
            "recall": 0.40997830802603036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7709199674813578,
            "auditor_fn_violation": 0.009114444325824702,
            "auditor_fp_violation": 0.0009263911568898398,
            "ave_precision_score": 0.7712476495225893,
            "fpr": 0.046052631578947366,
            "logloss": 3.491859829386059,
            "mae": 0.3607859323741367,
            "precision": 0.8299595141700404,
            "recall": 0.4158215010141988
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7623701651897068,
            "auditor_fn_violation": 0.014172407142397939,
            "auditor_fp_violation": 0.00894255396999634,
            "ave_precision_score": 0.7640552681559936,
            "fpr": 0.052689352360043906,
            "logloss": 3.294081385791234,
            "mae": 0.3397508822559968,
            "precision": 0.8095238095238095,
            "recall": 0.44251626898047725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7312951758169812,
            "auditor_fn_violation": 0.01906293370342693,
            "auditor_fp_violation": 0.03423983586651593,
            "ave_precision_score": 0.7231364411241726,
            "fpr": 0.1425438596491228,
            "logloss": 2.6566919368535546,
            "mae": 0.3146966157856467,
            "precision": 0.721627408993576,
            "recall": 0.6835699797160243
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7429246787907384,
            "auditor_fn_violation": 0.008981572537151377,
            "auditor_fp_violation": 0.0283790706183681,
            "ave_precision_score": 0.7371226571074107,
            "fpr": 0.1350164654226125,
            "logloss": 2.5611886491266644,
            "mae": 0.3044229056342257,
            "precision": 0.7248322147651006,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 22571,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8039451750908557,
            "auditor_fn_violation": 0.013753958933845773,
            "auditor_fp_violation": 0.031840116400787176,
            "ave_precision_score": 0.8035368954010351,
            "fpr": 0.19188596491228072,
            "logloss": 1.239109351413095,
            "mae": 0.2715895389239919,
            "precision": 0.7126436781609196,
            "recall": 0.8803245436105477
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7972157610148178,
            "auditor_fn_violation": 0.016965457138707198,
            "auditor_fp_violation": 0.02545188437614343,
            "ave_precision_score": 0.7971259076389293,
            "fpr": 0.2239297475301866,
            "logloss": 1.2008781526581824,
            "mae": 0.2831390286816358,
            "precision": 0.6661211129296236,
            "recall": 0.8828633405639913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8471876011926344,
            "auditor_fn_violation": 0.008696309739866908,
            "auditor_fp_violation": 0.01642643302767659,
            "ave_precision_score": 0.8475966430948328,
            "fpr": 0.13267543859649122,
            "logloss": 0.7530562929532376,
            "mae": 0.2638230658056312,
            "precision": 0.763671875,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8456606562980792,
            "auditor_fn_violation": 0.012984229863490581,
            "auditor_fp_violation": 0.020139041346505675,
            "ave_precision_score": 0.8458809022355339,
            "fpr": 0.141602634467618,
            "logloss": 0.7044012369986471,
            "mae": 0.2622649454996256,
            "precision": 0.7425149700598802,
            "recall": 0.806941431670282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7528695633514564,
            "auditor_fn_violation": 0.009772783886694423,
            "auditor_fp_violation": 0.00489626512582172,
            "ave_precision_score": 0.5349847272203343,
            "fpr": 0.4407894736842105,
            "logloss": 16.11225304000064,
            "mae": 0.46934417819294755,
            "precision": 0.5373993095512083,
            "recall": 0.947261663286004
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.7279689654115007,
            "auditor_fn_violation": 0.009493512647301838,
            "auditor_fp_violation": 0.0012074643249176927,
            "ave_precision_score": 0.4953486145137775,
            "fpr": 0.4774972557628979,
            "logloss": 17.55721859935931,
            "mae": 0.5131149058443301,
            "precision": 0.4965277777777778,
            "recall": 0.93058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8011184305446409,
            "auditor_fn_violation": 0.011320771502793493,
            "auditor_fp_violation": 0.012461792907088726,
            "ave_precision_score": 0.8015426310869875,
            "fpr": 0.10855263157894737,
            "logloss": 2.1787457263213,
            "mae": 0.3129151815394254,
            "precision": 0.7637231503579952,
            "recall": 0.6490872210953347
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7740735975815659,
            "auditor_fn_violation": 0.005007488612308947,
            "auditor_fp_violation": 0.02173435784851811,
            "ave_precision_score": 0.7747591922509744,
            "fpr": 0.12184412733260154,
            "logloss": 2.3546859845914794,
            "mae": 0.3114984623308062,
            "precision": 0.7279411764705882,
            "recall": 0.6442516268980477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7367430411087774,
            "auditor_fn_violation": 0.016133767481584287,
            "auditor_fp_violation": 0.02639691412301638,
            "ave_precision_score": 0.7327656422918265,
            "fpr": 0.12828947368421054,
            "logloss": 2.663993453558216,
            "mae": 0.31894002822422013,
            "precision": 0.7334851936218679,
            "recall": 0.6531440162271805
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7412585355373353,
            "auditor_fn_violation": 0.0011881772789073518,
            "auditor_fp_violation": 0.02108549823149165,
            "ave_precision_score": 0.7368469411851817,
            "fpr": 0.12403951701427003,
            "logloss": 2.63631497461456,
            "mae": 0.30961365672413094,
            "precision": 0.7290167865707434,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6470637671404064,
            "auditor_fn_violation": 0.011113928329952671,
            "auditor_fp_violation": 0.022788175689821222,
            "ave_precision_score": 0.6436715927322244,
            "fpr": 0.24451754385964913,
            "logloss": 3.0475186640987157,
            "mae": 0.38244170296784064,
            "precision": 0.6320132013201321,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6243690727825086,
            "auditor_fn_violation": 0.011419836131542422,
            "auditor_fp_violation": 0.025095743383339426,
            "ave_precision_score": 0.6228956943528042,
            "fpr": 0.287596048298573,
            "logloss": 3.1894682995631487,
            "mae": 0.40827676134989294,
            "precision": 0.5753646677471637,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7871695640098937,
            "auditor_fn_violation": 0.012448400412796703,
            "auditor_fp_violation": 0.02486601348239334,
            "ave_precision_score": 0.7879262286744534,
            "fpr": 0.13048245614035087,
            "logloss": 2.021259279791129,
            "mae": 0.3010690485253206,
            "precision": 0.7451820128479657,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.77732643245033,
            "auditor_fn_violation": 0.006038512182984067,
            "auditor_fp_violation": 0.016636175143310162,
            "ave_precision_score": 0.7784436494741016,
            "fpr": 0.14270032930845225,
            "logloss": 2.1066604792217287,
            "mae": 0.30368201572350967,
            "precision": 0.721627408993576,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 22571,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7926187939040903,
            "auditor_fn_violation": 0.012212643678160922,
            "auditor_fp_violation": 0.019647866683414988,
            "ave_precision_score": 0.7931637295638656,
            "fpr": 0.11403508771929824,
            "logloss": 2.4588486979663258,
            "mae": 0.3211629517013702,
            "precision": 0.7463414634146341,
            "recall": 0.6206896551724138
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7655822756864283,
            "auditor_fn_violation": 0.005324177145564817,
            "auditor_fp_violation": 0.021697768020490307,
            "ave_precision_score": 0.7663008655470852,
            "fpr": 0.11525795828759605,
            "logloss": 2.541711418567786,
            "mae": 0.31712642163182936,
            "precision": 0.7355163727959698,
            "recall": 0.6334056399132321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7360652815197476,
            "auditor_fn_violation": 0.018711522721611338,
            "auditor_fp_violation": 0.023937005401331497,
            "ave_precision_score": 0.7302087724193959,
            "fpr": 0.12171052631578948,
            "logloss": 2.612889625710924,
            "mae": 0.3225880684387117,
            "precision": 0.7400468384074942,
            "recall": 0.640973630831643
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7434080769755096,
            "auditor_fn_violation": 0.007783870791078435,
            "auditor_fp_violation": 0.021205025003049154,
            "ave_precision_score": 0.7378645685956593,
            "fpr": 0.11745334796926454,
            "logloss": 2.546320644740386,
            "mae": 0.3077318351565658,
            "precision": 0.7383863080684596,
            "recall": 0.6550976138828634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.788357089362964,
            "auditor_fn_violation": 0.012063627628910006,
            "auditor_fp_violation": 0.01615427291378806,
            "ave_precision_score": 0.7860714415485311,
            "fpr": 0.13706140350877194,
            "logloss": 1.2092794039407246,
            "mae": 0.2849206576811556,
            "precision": 0.7479838709677419,
            "recall": 0.7525354969574036
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7842354396007731,
            "auditor_fn_violation": 0.005490855320962642,
            "auditor_fp_violation": 0.023534577387486287,
            "ave_precision_score": 0.7823426841281511,
            "fpr": 0.15148188803512624,
            "logloss": 1.075806532018226,
            "mae": 0.2773688997583899,
            "precision": 0.7234468937875751,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7962474529461201,
            "auditor_fn_violation": 0.010491174691292127,
            "auditor_fp_violation": 0.011260624712138342,
            "ave_precision_score": 0.7967986986859754,
            "fpr": 0.06140350877192982,
            "logloss": 2.92315469230952,
            "mae": 0.3312726667780145,
            "precision": 0.8244514106583072,
            "recall": 0.5334685598377282
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7647544364991332,
            "auditor_fn_violation": 0.014793878624952687,
            "auditor_fp_violation": 0.014348091230637886,
            "ave_precision_score": 0.7653848172926737,
            "fpr": 0.07464324917672886,
            "logloss": 2.9118285591700603,
            "mae": 0.3286298861972521,
            "precision": 0.7813504823151125,
            "recall": 0.527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7799631859156932,
            "auditor_fn_violation": 0.013044464609800362,
            "auditor_fp_violation": 0.02655131264916468,
            "ave_precision_score": 0.7805466501761595,
            "fpr": 0.12171052631578948,
            "logloss": 2.4031988492679024,
            "mae": 0.3155842370033133,
            "precision": 0.7459954233409611,
            "recall": 0.6612576064908722
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.758331611702409,
            "auditor_fn_violation": 0.006867140826390394,
            "auditor_fp_violation": 0.02586169045005489,
            "ave_precision_score": 0.7590072109714734,
            "fpr": 0.13830954994511527,
            "logloss": 2.58679323049597,
            "mae": 0.3188094085831373,
            "precision": 0.7069767441860465,
            "recall": 0.6594360086767896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8356580322118441,
            "auditor_fn_violation": 0.012804259634888439,
            "auditor_fp_violation": 0.024313842482100237,
            "ave_precision_score": 0.8361715339495489,
            "fpr": 0.13706140350877194,
            "logloss": 0.8893396153530669,
            "mae": 0.27287007523741674,
            "precision": 0.75,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8254013873882448,
            "auditor_fn_violation": 0.01052691733476836,
            "auditor_fp_violation": 0.018831564824978657,
            "ave_precision_score": 0.8256865967157789,
            "fpr": 0.132821075740944,
            "logloss": 0.8446344543890281,
            "mae": 0.2654874994190248,
            "precision": 0.7479166666666667,
            "recall": 0.7787418655097614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7141638128639749,
            "auditor_fn_violation": 0.013104515853528351,
            "auditor_fp_violation": 0.01654419461541683,
            "ave_precision_score": 0.7148003334735523,
            "fpr": 0.1524122807017544,
            "logloss": 4.35200885491204,
            "mae": 0.36718213334702693,
            "precision": 0.682648401826484,
            "recall": 0.6064908722109533
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6606477132168772,
            "auditor_fn_violation": 0.02438263594391041,
            "auditor_fp_violation": 0.01842175875106721,
            "ave_precision_score": 0.6621784651018234,
            "fpr": 0.17892425905598244,
            "logloss": 4.933810077864845,
            "mae": 0.4020046576980633,
            "precision": 0.6164705882352941,
            "recall": 0.5683297180043384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7866052623801251,
            "auditor_fn_violation": 0.012866534998754495,
            "auditor_fp_violation": 0.014275321358288323,
            "ave_precision_score": 0.7870896077151918,
            "fpr": 0.08442982456140351,
            "logloss": 2.6143909562403014,
            "mae": 0.3317474841692736,
            "precision": 0.7855153203342619,
            "recall": 0.5720081135902637
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7610544623343808,
            "auditor_fn_violation": 0.012210366906286393,
            "auditor_fp_violation": 0.018548603488230276,
            "ave_precision_score": 0.7617833466599941,
            "fpr": 0.09440175631174534,
            "logloss": 2.648782556510725,
            "mae": 0.32086364744698825,
            "precision": 0.7577464788732394,
            "recall": 0.5835140997830802
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7985208325302158,
            "auditor_fn_violation": 0.008442760044126548,
            "auditor_fp_violation": 0.01423345057153624,
            "ave_precision_score": 0.7991914187232074,
            "fpr": 0.09539473684210527,
            "logloss": 2.7632382788914893,
            "mae": 0.31648375811960955,
            "precision": 0.7780612244897959,
            "recall": 0.6186612576064908
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7694398981497697,
            "auditor_fn_violation": 0.006921906512592543,
            "auditor_fp_violation": 0.017104524942066112,
            "ave_precision_score": 0.770412857742861,
            "fpr": 0.11086717892425905,
            "logloss": 2.725963557424876,
            "mae": 0.3164212471537326,
            "precision": 0.7410256410256411,
            "recall": 0.6268980477223427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7975705489738568,
            "auditor_fn_violation": 0.018073200241984284,
            "auditor_fp_violation": 0.01836033999078843,
            "ave_precision_score": 0.7980188764306713,
            "fpr": 0.09978070175438597,
            "logloss": 2.3094625878659167,
            "mae": 0.31619826125122386,
            "precision": 0.7707808564231738,
            "recall": 0.6206896551724138
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.776002327455139,
            "auditor_fn_violation": 0.001183415045324557,
            "auditor_fp_violation": 0.021470911086717892,
            "ave_precision_score": 0.7766289132919817,
            "fpr": 0.10647639956092206,
            "logloss": 2.391931910660398,
            "mae": 0.31178782888050627,
            "precision": 0.75,
            "recall": 0.631236442516269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.801426085933226,
            "auditor_fn_violation": 0.015479876160990712,
            "auditor_fp_violation": 0.013055834694133905,
            "ave_precision_score": 0.8019012624906632,
            "fpr": 0.07785087719298246,
            "logloss": 2.2740352441519285,
            "mae": 0.31863691846013514,
            "precision": 0.8033240997229917,
            "recall": 0.5882352941176471
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7660296430836664,
            "auditor_fn_violation": 0.017305956839877044,
            "auditor_fp_violation": 0.017221612391755094,
            "ave_precision_score": 0.766728184355538,
            "fpr": 0.08781558726673985,
            "logloss": 2.3364107703135364,
            "mae": 0.32470693663744954,
            "precision": 0.7604790419161677,
            "recall": 0.5509761388286334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7927823341794775,
            "auditor_fn_violation": 0.019147450268673708,
            "auditor_fp_violation": 0.0005233848344010402,
            "ave_precision_score": 0.7916038634183037,
            "fpr": 0.0756578947368421,
            "logloss": 1.2939312100144627,
            "mae": 0.30918099831866236,
            "precision": 0.8050847457627118,
            "recall": 0.5780933062880325
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8026286922514001,
            "auditor_fn_violation": 0.0052956037440680444,
            "auditor_fp_violation": 0.01874862788144896,
            "ave_precision_score": 0.8032942417315222,
            "fpr": 0.07903402854006586,
            "logloss": 1.0655402203882454,
            "mae": 0.2889101800834216,
            "precision": 0.791907514450867,
            "recall": 0.5943600867678959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.626264776460735,
            "auditor_fn_violation": 0.012526244617629268,
            "auditor_fp_violation": 0.009473265502658793,
            "ave_precision_score": 0.6185232071247511,
            "fpr": 0.27521929824561403,
            "logloss": 3.5937054099233574,
            "mae": 0.4092759096395514,
            "precision": 0.5977564102564102,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5933815608789591,
            "auditor_fn_violation": 0.0003309752340042521,
            "auditor_fp_violation": 0.01707525307964386,
            "ave_precision_score": 0.5862172299988635,
            "fpr": 0.30735455543358947,
            "logloss": 3.867583144714593,
            "mae": 0.42842593627990994,
            "precision": 0.5562599049128367,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6489311751705745,
            "auditor_fn_violation": 0.011801181452617346,
            "auditor_fp_violation": 0.02168645061340703,
            "ave_precision_score": 0.6446120571722606,
            "fpr": 0.1699561403508772,
            "logloss": 4.742439472200787,
            "mae": 0.38171933530064567,
            "precision": 0.6600877192982456,
            "recall": 0.6105476673427992
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5733351084351678,
            "auditor_fn_violation": 0.020129961354474483,
            "auditor_fp_violation": 0.026059275521405054,
            "ave_precision_score": 0.5705895819904641,
            "fpr": 0.1877058177826564,
            "logloss": 5.39738717661439,
            "mae": 0.4174570687299088,
            "precision": 0.6104783599088838,
            "recall": 0.5813449023861171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7854537709228324,
            "auditor_fn_violation": 0.014899380804953562,
            "auditor_fp_violation": 0.013155277812670101,
            "ave_precision_score": 0.7859557403084775,
            "fpr": 0.08442982456140351,
            "logloss": 2.639240005030634,
            "mae": 0.33050127879120134,
            "precision": 0.7878787878787878,
            "recall": 0.5801217038539553
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7620315127117072,
            "auditor_fn_violation": 0.010365001392953321,
            "auditor_fp_violation": 0.021302597877789983,
            "ave_precision_score": 0.7627127161400727,
            "fpr": 0.09549945115257959,
            "logloss": 2.6487224202178825,
            "mae": 0.3210776251755343,
            "precision": 0.7569832402234636,
            "recall": 0.5878524945770065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8646509770769347,
            "auditor_fn_violation": 0.014761485356393017,
            "auditor_fp_violation": 0.007400661558430683,
            "ave_precision_score": 0.864904220074106,
            "fpr": 0.0712719298245614,
            "logloss": 0.5968209967090075,
            "mae": 0.2825747663770471,
            "precision": 0.8399014778325123,
            "recall": 0.691683569979716
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8597569995292227,
            "auditor_fn_violation": 0.008157706127327845,
            "auditor_fp_violation": 0.015862910110989142,
            "ave_precision_score": 0.8599824993976404,
            "fpr": 0.07793633369923161,
            "logloss": 0.5552158086906738,
            "mae": 0.27102076800911035,
            "precision": 0.8202531645569621,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8028674820012759,
            "auditor_fn_violation": 0.015889114266396213,
            "auditor_fp_violation": 0.01939925888707449,
            "ave_precision_score": 0.8033005017106363,
            "fpr": 0.11074561403508772,
            "logloss": 2.20673573606257,
            "mae": 0.311199969902103,
            "precision": 0.7566265060240964,
            "recall": 0.6369168356997972
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7780876791949893,
            "auditor_fn_violation": 0.0014643868267094616,
            "auditor_fp_violation": 0.02156360531772168,
            "ave_precision_score": 0.7786889092182264,
            "fpr": 0.1163556531284303,
            "logloss": 2.3816307986254435,
            "mae": 0.3107031511955834,
            "precision": 0.7376237623762376,
            "recall": 0.6464208242950108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 22571,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.748941428708175,
            "auditor_fn_violation": 0.012710846589089364,
            "auditor_fp_violation": 0.021139513461457943,
            "ave_precision_score": 0.7477439541872415,
            "fpr": 0.1118421052631579,
            "logloss": 2.8588249037517075,
            "mae": 0.3298217198091712,
            "precision": 0.7487684729064039,
            "recall": 0.6166328600405679
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7347097797275922,
            "auditor_fn_violation": 0.0028168611642232426,
            "auditor_fp_violation": 0.024661544090742775,
            "ave_precision_score": 0.7351525275332451,
            "fpr": 0.11525795828759605,
            "logloss": 2.754162049165606,
            "mae": 0.3234073966395996,
            "precision": 0.732824427480916,
            "recall": 0.6247288503253796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8321279980515653,
            "auditor_fn_violation": 0.013173463577808618,
            "auditor_fp_violation": 0.031007934514089522,
            "ave_precision_score": 0.832690862252349,
            "fpr": 0.14364035087719298,
            "logloss": 0.9755703754684251,
            "mae": 0.269725216535713,
            "precision": 0.744140625,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8217844239883858,
            "auditor_fn_violation": 0.012365139497727225,
            "auditor_fp_violation": 0.025271374557872917,
            "ave_precision_score": 0.8220610067238157,
            "fpr": 0.15916575192096596,
            "logloss": 0.9968730290889055,
            "mae": 0.26843098486864725,
            "precision": 0.7178988326848249,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7900899797918817,
            "auditor_fn_violation": 0.011518718195082031,
            "auditor_fp_violation": 0.011415023238286645,
            "ave_precision_score": 0.7908216705949509,
            "fpr": 0.08223684210526316,
            "logloss": 3.2122888458267647,
            "mae": 0.32352451941177357,
            "precision": 0.7893258426966292,
            "recall": 0.5699797160243407
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7677513175895011,
            "auditor_fn_violation": 0.0014524812427524811,
            "auditor_fp_violation": 0.01773386998414441,
            "ave_precision_score": 0.7687110180179126,
            "fpr": 0.08781558726673985,
            "logloss": 3.113074059713004,
            "mae": 0.32080862396353893,
            "precision": 0.7687861271676301,
            "recall": 0.5770065075921909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8000716578105733,
            "auditor_fn_violation": 0.015951389630262266,
            "auditor_fp_violation": 0.018297533810660304,
            "ave_precision_score": 0.800573937243344,
            "fpr": 0.10964912280701754,
            "logloss": 2.2603804291914287,
            "mae": 0.31499377861637445,
            "precision": 0.7578692493946732,
            "recall": 0.6348884381338742
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.774433537282141,
            "auditor_fn_violation": 0.01293660752766262,
            "auditor_fp_violation": 0.018119282839370657,
            "ave_precision_score": 0.7750911951351649,
            "fpr": 0.11745334796926454,
            "logloss": 2.3635139946356527,
            "mae": 0.31248253169186246,
            "precision": 0.7377450980392157,
            "recall": 0.6529284164859002
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7989084306167165,
            "auditor_fn_violation": 0.014060887512899904,
            "auditor_fp_violation": 0.019679269773479047,
            "ave_precision_score": 0.7993642491680157,
            "fpr": 0.11951754385964912,
            "logloss": 2.284966283973807,
            "mae": 0.3136285684761105,
            "precision": 0.7453271028037384,
            "recall": 0.6470588235294118
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7725850994309372,
            "auditor_fn_violation": 0.004026468494253183,
            "auditor_fp_violation": 0.02331503841931943,
            "ave_precision_score": 0.7732012841856637,
            "fpr": 0.12403951701427003,
            "logloss": 2.462169740600187,
            "mae": 0.31338815333809017,
            "precision": 0.727710843373494,
            "recall": 0.6550976138828634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6161449067254418,
            "auditor_fn_violation": 0.014859346642468243,
            "auditor_fp_violation": 0.011485680190930794,
            "ave_precision_score": 0.6039566692726024,
            "fpr": 0.29714912280701755,
            "logloss": 3.8373174028404238,
            "mae": 0.3957552992969259,
            "precision": 0.6008836524300442,
            "recall": 0.8275862068965517
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.5846020838662513,
            "auditor_fn_violation": 0.010981710641925282,
            "auditor_fp_violation": 0.015223807781436755,
            "ave_precision_score": 0.5719657756812413,
            "fpr": 0.34796926454445665,
            "logloss": 4.230683598954619,
            "mae": 0.4307244775653308,
            "precision": 0.5451936872309899,
            "recall": 0.824295010845987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7912979160251061,
            "auditor_fn_violation": 0.00404789865129355,
            "auditor_fp_violation": 0.012294309760080394,
            "ave_precision_score": 0.7921677087905663,
            "fpr": 0.09100877192982457,
            "logloss": 2.939638667909058,
            "mae": 0.3222220160537046,
            "precision": 0.783289817232376,
            "recall": 0.6085192697768763
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.763673082021979,
            "auditor_fn_violation": 0.010717406678080157,
            "auditor_fp_violation": 0.017724112696670333,
            "ave_precision_score": 0.7647577878181926,
            "fpr": 0.1119648737650933,
            "logloss": 2.8616596431957095,
            "mae": 0.32099412598653004,
            "precision": 0.7329842931937173,
            "recall": 0.6073752711496746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8390913138216507,
            "auditor_fn_violation": 0.021645137183730123,
            "auditor_fp_violation": 0.01610193443034795,
            "ave_precision_score": 0.8394411153773268,
            "fpr": 0.12171052631578948,
            "logloss": 0.8674116526781909,
            "mae": 0.27034116086915294,
            "precision": 0.7677824267782427,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8303216913681084,
            "auditor_fn_violation": 0.01661305185358037,
            "auditor_fp_violation": 0.021026954506647155,
            "ave_precision_score": 0.8306376018979416,
            "fpr": 0.12623490669593854,
            "logloss": 0.8734002547980226,
            "mae": 0.26150298035245223,
            "precision": 0.7537473233404711,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 22571,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7857280914291846,
            "auditor_fn_violation": 0.014418970855129718,
            "auditor_fp_violation": 0.013723150357995229,
            "ave_precision_score": 0.7778201564420473,
            "fpr": 0.13267543859649122,
            "logloss": 1.3315316646097715,
            "mae": 0.2702399893291897,
            "precision": 0.7613412228796844,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7486894231625904,
            "auditor_fn_violation": 0.02271823530672356,
            "auditor_fp_violation": 0.01748749847542384,
            "ave_precision_score": 0.7382754261158079,
            "fpr": 0.1437980241492865,
            "logloss": 1.494933556331963,
            "mae": 0.26630817110025834,
            "precision": 0.741106719367589,
            "recall": 0.8134490238611713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7434532420559541,
            "auditor_fn_violation": 0.014172093519803568,
            "auditor_fp_violation": 0.01831323535569234,
            "ave_precision_score": 0.7422489387951792,
            "fpr": 0.12390350877192982,
            "logloss": 3.088086315905425,
            "mae": 0.3307725984337449,
            "precision": 0.7309523809523809,
            "recall": 0.6227180527383367
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7284195871498405,
            "auditor_fn_violation": 0.005655152379569068,
            "auditor_fp_violation": 0.02482010001219661,
            "ave_precision_score": 0.7291094470187858,
            "fpr": 0.13721185510428102,
            "logloss": 2.980516265023629,
            "mae": 0.3283803296176466,
            "precision": 0.7058823529411765,
            "recall": 0.6507592190889371
        }
    }
]