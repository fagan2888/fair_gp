[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8011807427192827,
            "auditor_fn_violation": 0.021388157894736845,
            "auditor_fp_violation": 0.00741462272185318,
            "ave_precision_score": 0.8017380244519791,
            "fpr": 0.06030701754385965,
            "logloss": 1.1551810728806218,
            "mae": 0.34834445314806123,
            "precision": 0.8129251700680272,
            "recall": 0.478
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8217320082355943,
            "auditor_fn_violation": 0.008339095828276046,
            "auditor_fp_violation": 0.005490876162247463,
            "ave_precision_score": 0.8220341641598863,
            "fpr": 0.04610318331503842,
            "logloss": 0.8961986427430546,
            "mae": 0.30991436004114975,
            "precision": 0.8426966292134831,
            "recall": 0.4955947136563877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7532276430526792,
            "auditor_fn_violation": 0.012078947368421059,
            "auditor_fp_violation": 0.023404232669051273,
            "ave_precision_score": 0.7513611339067416,
            "fpr": 0.1611842105263158,
            "logloss": 1.4334560826918539,
            "mae": 0.3104291546747111,
            "precision": 0.7162162162162162,
            "recall": 0.742
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7256374229387478,
            "auditor_fn_violation": 3.1431790596577636e-05,
            "auditor_fp_violation": 0.021627230518318538,
            "ave_precision_score": 0.7220175302091016,
            "fpr": 0.14709110867178923,
            "logloss": 1.5025416166460226,
            "mae": 0.27194604434330594,
            "precision": 0.7270875763747454,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.76429776046033,
            "auditor_fn_violation": 0.007214912280701756,
            "auditor_fp_violation": 0.021589167092488502,
            "ave_precision_score": 0.7457334073379349,
            "fpr": 0.15679824561403508,
            "logloss": 2.7617752578968684,
            "mae": 0.31289085950835555,
            "precision": 0.718503937007874,
            "recall": 0.73
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7518669248093368,
            "auditor_fn_violation": 0.004320662292006173,
            "auditor_fp_violation": 0.022388651228481465,
            "ave_precision_score": 0.72880436181437,
            "fpr": 0.14818880351262348,
            "logloss": 2.4830699820063207,
            "mae": 0.2755619780262711,
            "precision": 0.7233606557377049,
            "recall": 0.7775330396475771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.803407436140933,
            "auditor_fn_violation": 0.010570175438596495,
            "auditor_fp_violation": 0.01798032703117017,
            "ave_precision_score": 0.8038149920996864,
            "fpr": 0.13157894736842105,
            "logloss": 1.1217942819617184,
            "mae": 0.29064794451587855,
            "precision": 0.7551020408163265,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8193700984444164,
            "auditor_fn_violation": 0.008745291275985629,
            "auditor_fp_violation": 0.015420570849356397,
            "ave_precision_score": 0.8199493351949799,
            "fpr": 0.1207464324917673,
            "logloss": 0.8783556452827905,
            "mae": 0.25213581216272424,
            "precision": 0.7634408602150538,
            "recall": 0.7819383259911894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8232228347376634,
            "auditor_fn_violation": 0.013938596491228075,
            "auditor_fp_violation": 0.01681996252767842,
            "ave_precision_score": 0.8234919002469026,
            "fpr": 0.13157894736842105,
            "logloss": 0.9895127435122764,
            "mae": 0.2922181950454458,
            "precision": 0.7520661157024794,
            "recall": 0.728
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8405071852928347,
            "auditor_fn_violation": 0.004850167072056173,
            "auditor_fp_violation": 0.016842530030480852,
            "ave_precision_score": 0.8408543402372688,
            "fpr": 0.11306256860592755,
            "logloss": 0.7322646193543652,
            "mae": 0.2547650397436875,
            "precision": 0.7706013363028953,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7992712493983194,
            "auditor_fn_violation": 0.013688596491228073,
            "auditor_fp_violation": 0.00797883665474366,
            "ave_precision_score": 0.7998306240718059,
            "fpr": 0.07236842105263158,
            "logloss": 1.0615274459690915,
            "mae": 0.3298823642820911,
            "precision": 0.8041543026706232,
            "recall": 0.542
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8192909118757759,
            "auditor_fn_violation": 0.0032640705619520673,
            "auditor_fp_violation": 0.00361734886279295,
            "ave_precision_score": 0.8196065639207519,
            "fpr": 0.059275521405049394,
            "logloss": 0.8118467943243026,
            "mae": 0.29241681830409433,
            "precision": 0.8280254777070064,
            "recall": 0.5726872246696035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.785772337909842,
            "auditor_fn_violation": 0.015298245614035089,
            "auditor_fp_violation": 0.016324944643161306,
            "ave_precision_score": 0.7331472744908125,
            "fpr": 0.1162280701754386,
            "logloss": 5.05937191816163,
            "mae": 0.30122539310282437,
            "precision": 0.7633928571428571,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7965429895431281,
            "auditor_fn_violation": 0.011620091200549331,
            "auditor_fp_violation": 0.01192091793229841,
            "ave_precision_score": 0.7424821104628755,
            "fpr": 0.09769484083424808,
            "logloss": 4.363933198904948,
            "mae": 0.2539922471414903,
            "precision": 0.789598108747045,
            "recall": 0.73568281938326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8080517611346464,
            "auditor_fn_violation": 0.01906140350877194,
            "auditor_fp_violation": 0.008859755578266059,
            "ave_precision_score": 0.8085651200040103,
            "fpr": 0.10197368421052631,
            "logloss": 1.0649653210596062,
            "mae": 0.2960000219744726,
            "precision": 0.7811764705882352,
            "recall": 0.664
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8265640319736431,
            "auditor_fn_violation": 0.011141360851463038,
            "auditor_fp_violation": 0.0055245035753146,
            "ave_precision_score": 0.8269045258185815,
            "fpr": 0.09220636663007684,
            "logloss": 0.787751648993189,
            "mae": 0.2545002221351047,
            "precision": 0.7951219512195122,
            "recall": 0.7180616740088106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8084103408238352,
            "auditor_fn_violation": 0.019508771929824566,
            "auditor_fp_violation": 0.014033490887412707,
            "ave_precision_score": 0.8089319155602179,
            "fpr": 0.10635964912280702,
            "logloss": 0.9017612220503569,
            "mae": 0.2928985693662096,
            "precision": 0.780045351473923,
            "recall": 0.688
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.827245794711401,
            "auditor_fn_violation": 0.004366601062878098,
            "auditor_fp_violation": 0.008164255501084487,
            "ave_precision_score": 0.8275470177477067,
            "fpr": 0.09659714599341383,
            "logloss": 0.6769565899201057,
            "mae": 0.259210923536273,
            "precision": 0.7889688249400479,
            "recall": 0.724669603524229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8231541924422763,
            "auditor_fn_violation": 0.012903508771929825,
            "auditor_fp_violation": 0.029339124510304893,
            "ave_precision_score": 0.8236895156686794,
            "fpr": 0.18859649122807018,
            "logloss": 1.1084948243179116,
            "mae": 0.2842388363640075,
            "precision": 0.7089678510998308,
            "recall": 0.838
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8402848468038626,
            "auditor_fn_violation": 0.009985638089527411,
            "auditor_fp_violation": 0.02339987557857166,
            "ave_precision_score": 0.8405060667222863,
            "fpr": 0.18331503841931943,
            "logloss": 0.9207427755933979,
            "mae": 0.2621537303892436,
            "precision": 0.7012522361359571,
            "recall": 0.8634361233480177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 16695,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8397304015806908,
            "auditor_fn_violation": 0.028017543859649125,
            "auditor_fp_violation": 0.010057379492420374,
            "ave_precision_score": 0.8401171523698419,
            "fpr": 0.08662280701754387,
            "logloss": 0.6343480687892821,
            "mae": 0.30975830293077505,
            "precision": 0.8232662192393736,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8782569156655692,
            "auditor_fn_violation": 0.026535684753647294,
            "auditor_fp_violation": 0.010921703372589336,
            "ave_precision_score": 0.878501922020563,
            "fpr": 0.07464324917672886,
            "logloss": 0.5386035861535458,
            "mae": 0.27621360723259003,
            "precision": 0.8295739348370927,
            "recall": 0.7290748898678414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8069400611149743,
            "auditor_fn_violation": 0.015247807017543866,
            "auditor_fp_violation": 0.012181165900187365,
            "ave_precision_score": 0.8072857005894931,
            "fpr": 0.10416666666666667,
            "logloss": 1.136218597521951,
            "mae": 0.29074080052600143,
            "precision": 0.7821100917431193,
            "recall": 0.682
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8199359916246206,
            "auditor_fn_violation": 0.009659231033332206,
            "auditor_fp_violation": 0.007229893809433451,
            "ave_precision_score": 0.8201790789642802,
            "fpr": 0.09110867178924259,
            "logloss": 0.8581104649368826,
            "mae": 0.2505855917322331,
            "precision": 0.8014354066985646,
            "recall": 0.737885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8269337136345305,
            "auditor_fn_violation": 0.009188596491228076,
            "auditor_fp_violation": 0.015095384091296201,
            "ave_precision_score": 0.8272107390397402,
            "fpr": 0.14473684210526316,
            "logloss": 0.845619287339485,
            "mae": 0.28701504771528596,
            "precision": 0.7471264367816092,
            "recall": 0.78
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8401390196899214,
            "auditor_fn_violation": 0.004291648331455485,
            "auditor_fp_violation": 0.019006694257158438,
            "ave_precision_score": 0.8404923559027274,
            "fpr": 0.13830954994511527,
            "logloss": 0.6781406846203951,
            "mae": 0.2513011293249032,
            "precision": 0.7464788732394366,
            "recall": 0.8171806167400881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8014567499487585,
            "auditor_fn_violation": 0.017605263157894735,
            "auditor_fp_violation": 0.011188468744677224,
            "ave_precision_score": 0.8018140915032554,
            "fpr": 0.11403508771929824,
            "logloss": 1.0986990814461426,
            "mae": 0.29390237490910504,
            "precision": 0.7714285714285715,
            "recall": 0.702
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8166293473755268,
            "auditor_fn_violation": 0.012838677543678102,
            "auditor_fp_violation": 0.008260333824133433,
            "ave_precision_score": 0.8169989759323043,
            "fpr": 0.10537870472008781,
            "logloss": 0.8428551651365757,
            "mae": 0.2557540876920119,
            "precision": 0.7777777777777778,
            "recall": 0.7400881057268722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8028399319280184,
            "auditor_fn_violation": 0.01949561403508772,
            "auditor_fp_violation": 0.006078606710952139,
            "ave_precision_score": 0.8033821846457285,
            "fpr": 0.0625,
            "logloss": 1.1526998164855735,
            "mae": 0.3350822937259343,
            "precision": 0.819047619047619,
            "recall": 0.516
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8228563948221853,
            "auditor_fn_violation": 0.005788285129861652,
            "auditor_fp_violation": 0.004318720621050281,
            "ave_precision_score": 0.8231791162277928,
            "fpr": 0.05159165751920966,
            "logloss": 0.8712116112387296,
            "mae": 0.29564843610457175,
            "precision": 0.8412162162162162,
            "recall": 0.5484581497797357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8060921976083009,
            "auditor_fn_violation": 0.01376096491228071,
            "auditor_fp_violation": 0.012923692726963046,
            "ave_precision_score": 0.8065687442257733,
            "fpr": 0.11732456140350878,
            "logloss": 1.087987383318846,
            "mae": 0.2916178858716775,
            "precision": 0.7703862660944206,
            "recall": 0.718
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8225417998972442,
            "auditor_fn_violation": 0.012084314569360294,
            "auditor_fp_violation": 0.009451705029940412,
            "ave_precision_score": 0.8228952545054441,
            "fpr": 0.1141602634467618,
            "logloss": 0.8174642062467053,
            "mae": 0.25438686190123155,
            "precision": 0.7657657657657657,
            "recall": 0.748898678414097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.739753605812197,
            "auditor_fn_violation": 0.007462719298245614,
            "auditor_fp_violation": 0.022690981093510473,
            "ave_precision_score": 0.7374118440383333,
            "fpr": 0.16557017543859648,
            "logloss": 1.5609925732292016,
            "mae": 0.31170323277720124,
            "precision": 0.7150943396226415,
            "recall": 0.758
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7179397951945284,
            "auditor_fn_violation": 0.0014724584979472644,
            "auditor_fp_violation": 0.024523991958244357,
            "ave_precision_score": 0.7130750424236114,
            "fpr": 0.1602634467618002,
            "logloss": 1.575233783771034,
            "mae": 0.27379054223081295,
            "precision": 0.7120315581854043,
            "recall": 0.7951541850220264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8141105743017379,
            "auditor_fn_violation": 0.011605263157894738,
            "auditor_fp_violation": 0.017799352750809072,
            "ave_precision_score": 0.8144555389163961,
            "fpr": 0.1337719298245614,
            "logloss": 1.0876670537986408,
            "mae": 0.2899987490207211,
            "precision": 0.7530364372469636,
            "recall": 0.744
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8276744023242372,
            "auditor_fn_violation": 0.010116200912005496,
            "auditor_fp_violation": 0.017099539544636784,
            "ave_precision_score": 0.8281005098877352,
            "fpr": 0.12184412733260154,
            "logloss": 0.8403128272935568,
            "mae": 0.25391806174765036,
            "precision": 0.7612903225806451,
            "recall": 0.7797356828193832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8016090994268443,
            "auditor_fn_violation": 0.022438596491228077,
            "auditor_fp_violation": 0.01130556974961676,
            "ave_precision_score": 0.8022690361140764,
            "fpr": 0.09210526315789473,
            "logloss": 0.984117440790584,
            "mae": 0.3035599215591829,
            "precision": 0.7915632754342432,
            "recall": 0.638
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8202458953924572,
            "auditor_fn_violation": 0.00287721775460959,
            "auditor_fp_violation": 0.008500529631755807,
            "ave_precision_score": 0.8205599629616878,
            "fpr": 0.07574094401756312,
            "logloss": 0.7560005145798827,
            "mae": 0.26943574148600946,
            "precision": 0.8125,
            "recall": 0.6585903083700441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 16695,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8008126949687612,
            "auditor_fn_violation": 0.022041666666666668,
            "auditor_fp_violation": 0.012766670924885029,
            "ave_precision_score": 0.8013860241062183,
            "fpr": 0.09539473684210527,
            "logloss": 0.9975205376770618,
            "mae": 0.30407383200648885,
            "precision": 0.7857142857142857,
            "recall": 0.638
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8180418333426124,
            "auditor_fn_violation": 0.009141815403511652,
            "auditor_fp_violation": 0.011010575821409614,
            "ave_precision_score": 0.8183653731442627,
            "fpr": 0.07683863885839737,
            "logloss": 0.7649143105754405,
            "mae": 0.2702457250152789,
            "precision": 0.8102981029810298,
            "recall": 0.6585903083700441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7447208838470472,
            "auditor_fn_violation": 0.024377192982456167,
            "auditor_fp_violation": 0.009272270482030318,
            "ave_precision_score": 0.7454283710742461,
            "fpr": 0.05263157894736842,
            "logloss": 0.831512954146258,
            "mae": 0.41767856049154467,
            "precision": 0.7903930131004366,
            "recall": 0.362
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7647733749212958,
            "auditor_fn_violation": 0.022108637939621947,
            "auditor_fp_violation": 0.009511753981846002,
            "ave_precision_score": 0.765146440246159,
            "fpr": 0.042810098792535674,
            "logloss": 0.737976725916454,
            "mae": 0.3844119633909795,
            "precision": 0.8235294117647058,
            "recall": 0.4008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8124368793434797,
            "auditor_fn_violation": 0.011478070175438594,
            "auditor_fp_violation": 0.01409736416283427,
            "ave_precision_score": 0.8127411067389659,
            "fpr": 0.10635964912280702,
            "logloss": 1.1565530045701677,
            "mae": 0.2896963683689357,
            "precision": 0.781038374717833,
            "recall": 0.692
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8296058244636851,
            "auditor_fn_violation": 0.0073888886202411125,
            "auditor_fp_violation": 0.008615823619414547,
            "ave_precision_score": 0.829939802652731,
            "fpr": 0.09330406147091108,
            "logloss": 0.8550582024307307,
            "mae": 0.25254367290239343,
            "precision": 0.7936893203883495,
            "recall": 0.7202643171806168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8195778929674087,
            "auditor_fn_violation": 0.013030701754385976,
            "auditor_fp_violation": 0.014254385964912285,
            "ave_precision_score": 0.8211998553713866,
            "fpr": 0.11293859649122807,
            "logloss": 1.1929315316083464,
            "mae": 0.2831625521253791,
            "precision": 0.778969957081545,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8301909593456347,
            "auditor_fn_violation": 0.008491419121167139,
            "auditor_fp_violation": 0.013165132215782317,
            "ave_precision_score": 0.8315517447883379,
            "fpr": 0.10647639956092206,
            "logloss": 0.8597912910077338,
            "mae": 0.24518014002831048,
            "precision": 0.7790432801822323,
            "recall": 0.7533039647577092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7993739765861323,
            "auditor_fn_violation": 0.015719298245614043,
            "auditor_fp_violation": 0.01524442173394652,
            "ave_precision_score": 0.7999306438486546,
            "fpr": 0.13157894736842105,
            "logloss": 1.019550862402454,
            "mae": 0.29254274521902635,
            "precision": 0.7540983606557377,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8244562146076808,
            "auditor_fn_violation": 0.006494291503261655,
            "auditor_fp_violation": 0.0071121978636984875,
            "ave_precision_score": 0.8247823863864954,
            "fpr": 0.11525795828759605,
            "logloss": 0.750432794739193,
            "mae": 0.25175436396723383,
            "precision": 0.7737068965517241,
            "recall": 0.7907488986784141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8548439995213539,
            "auditor_fn_violation": 0.004710526315789476,
            "auditor_fp_violation": 0.006541687957758474,
            "ave_precision_score": 0.8551761254995638,
            "fpr": 0.09429824561403509,
            "logloss": 0.49591723180093955,
            "mae": 0.30401637677124727,
            "precision": 0.8177966101694916,
            "recall": 0.772
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8823037964046379,
            "auditor_fn_violation": 0.010121036572097277,
            "auditor_fp_violation": 0.007189060522137649,
            "ave_precision_score": 0.8824849403743319,
            "fpr": 0.0867178924259056,
            "logloss": 0.4433588602130676,
            "mae": 0.2818287885813022,
            "precision": 0.8145539906103286,
            "recall": 0.76431718061674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8184334932364021,
            "auditor_fn_violation": 0.017026315789473688,
            "auditor_fp_violation": 0.01619453670584228,
            "ave_precision_score": 0.8188225085826879,
            "fpr": 0.13706140350877194,
            "logloss": 1.0016624827556582,
            "mae": 0.29051470304003746,
            "precision": 0.7438524590163934,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8371559952673311,
            "auditor_fn_violation": 0.01060218475122947,
            "auditor_fp_violation": 0.010628664487290045,
            "ave_precision_score": 0.837547804617635,
            "fpr": 0.13062568605927552,
            "logloss": 0.7911972019948059,
            "mae": 0.2548791891582199,
            "precision": 0.7489451476793249,
            "recall": 0.7819383259911894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.817342862691397,
            "auditor_fn_violation": 0.015026315789473686,
            "auditor_fp_violation": 0.018536556804632946,
            "ave_precision_score": 0.8176810341684879,
            "fpr": 0.14144736842105263,
            "logloss": 1.1146798484594904,
            "mae": 0.29156310535694846,
            "precision": 0.7425149700598802,
            "recall": 0.744
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8358284750043542,
            "auditor_fn_violation": 0.0077249669966198715,
            "auditor_fp_violation": 0.018927429640643055,
            "ave_precision_score": 0.8361554890943355,
            "fpr": 0.13172338090010977,
            "logloss": 0.8172460847190316,
            "mae": 0.25603443277903143,
            "precision": 0.7484276729559748,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8018127163519235,
            "auditor_fn_violation": 0.013447368421052631,
            "auditor_fp_violation": 0.01628236245954693,
            "ave_precision_score": 0.8013678635137443,
            "fpr": 0.1425438596491228,
            "logloss": 1.5583830422355005,
            "mae": 0.29590911045697854,
            "precision": 0.7394789579158316,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8157905997485985,
            "auditor_fn_violation": 0.006257344158764397,
            "auditor_fp_violation": 0.019539928950080106,
            "ave_precision_score": 0.8151321669675601,
            "fpr": 0.12952799121844127,
            "logloss": 1.1459646179347722,
            "mae": 0.25833535595923346,
            "precision": 0.7484008528784648,
            "recall": 0.7731277533039648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8092650280440805,
            "auditor_fn_violation": 0.01214473684210527,
            "auditor_fp_violation": 0.014049459206268104,
            "ave_precision_score": 0.8095649546967076,
            "fpr": 0.13048245614035087,
            "logloss": 1.2348221959841794,
            "mae": 0.29346873390234884,
            "precision": 0.7531120331950207,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8218043638070338,
            "auditor_fn_violation": 0.009511743400532895,
            "auditor_fp_violation": 0.01206743737494806,
            "ave_precision_score": 0.8221941510383364,
            "fpr": 0.11525795828759605,
            "logloss": 0.856563502272472,
            "mae": 0.25534296905872633,
            "precision": 0.7671840354767184,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8146026053455102,
            "auditor_fn_violation": 0.009250000000000003,
            "auditor_fp_violation": 0.018076136944302514,
            "ave_precision_score": 0.8149679010989463,
            "fpr": 0.13267543859649122,
            "logloss": 1.0324679453951087,
            "mae": 0.2812495315989853,
            "precision": 0.7570281124497992,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8318913810929348,
            "auditor_fn_violation": 0.006383071321150695,
            "auditor_fp_violation": 0.011671114292371144,
            "ave_precision_score": 0.8322648039395063,
            "fpr": 0.1251372118551043,
            "logloss": 0.7718956741314129,
            "mae": 0.24377282017836022,
            "precision": 0.7579617834394905,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.47562682915034404,
            "auditor_fn_violation": 0.010081140350877198,
            "auditor_fp_violation": 0.007475834610798845,
            "ave_precision_score": 0.4285296653977534,
            "fpr": 0.3673245614035088,
            "logloss": 10.047763033734162,
            "mae": 0.46242943362484096,
            "precision": 0.5568783068783069,
            "recall": 0.842
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.42693710700702114,
            "auditor_fn_violation": 0.009884089227600016,
            "auditor_fp_violation": 0.014349297547360617,
            "ave_precision_score": 0.3789409793849822,
            "fpr": 0.4061470911086718,
            "logloss": 11.538052472539974,
            "mae": 0.49011169997139997,
            "precision": 0.5144356955380578,
            "recall": 0.8634361233480177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8017549631002941,
            "auditor_fn_violation": 0.02317543859649123,
            "auditor_fp_violation": 0.012604326349855225,
            "ave_precision_score": 0.8021297430910415,
            "fpr": 0.09649122807017543,
            "logloss": 1.0675424616521236,
            "mae": 0.31253277143145886,
            "precision": 0.7777777777777778,
            "recall": 0.616
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8017386482307143,
            "auditor_fn_violation": 0.00906202701199728,
            "auditor_fp_violation": 0.013013808856980212,
            "ave_precision_score": 0.8020745301288243,
            "fpr": 0.09110867178924259,
            "logloss": 0.9444530986795696,
            "mae": 0.2835469995778617,
            "precision": 0.7827225130890052,
            "recall": 0.6585903083700441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8093230256775412,
            "auditor_fn_violation": 0.01825657894736843,
            "auditor_fp_violation": 0.011936318344404702,
            "ave_precision_score": 0.8097892395300164,
            "fpr": 0.10416666666666667,
            "logloss": 1.0712672530175396,
            "mae": 0.2937920320033581,
            "precision": 0.7800925925925926,
            "recall": 0.674
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8271875702286655,
            "auditor_fn_violation": 0.010275777695034268,
            "auditor_fp_violation": 0.008440480679850218,
            "ave_precision_score": 0.8275375677311627,
            "fpr": 0.09549945115257959,
            "logloss": 0.7957563147866602,
            "mae": 0.252363887972508,
            "precision": 0.7928571428571428,
            "recall": 0.7334801762114538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7957677784425858,
            "auditor_fn_violation": 0.015767543859649125,
            "auditor_fp_violation": 0.014701498892863232,
            "ave_precision_score": 0.7961227183622144,
            "fpr": 0.125,
            "logloss": 1.0103758671943326,
            "mae": 0.2990969231664403,
            "precision": 0.7558886509635975,
            "recall": 0.706
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8203137146481267,
            "auditor_fn_violation": 0.005246691199582208,
            "auditor_fp_violation": 0.0027046047938279285,
            "ave_precision_score": 0.8206317538114098,
            "fpr": 0.10757409440175632,
            "logloss": 0.7527664287024839,
            "mae": 0.2612038248846244,
            "precision": 0.7757437070938215,
            "recall": 0.7466960352422908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8062528392150529,
            "auditor_fn_violation": 0.01800438596491229,
            "auditor_fp_violation": 0.0077286663260092,
            "ave_precision_score": 0.8067551007735937,
            "fpr": 0.07894736842105263,
            "logloss": 0.9884782502717189,
            "mae": 0.3143272460912928,
            "precision": 0.8038147138964578,
            "recall": 0.59
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8289910669666067,
            "auditor_fn_violation": 0.010299955995493167,
            "auditor_fp_violation": 0.0038383290058055346,
            "ave_precision_score": 0.8292825187433475,
            "fpr": 0.06915477497255763,
            "logloss": 0.7397829658764482,
            "mae": 0.27530546798860334,
            "precision": 0.8173913043478261,
            "recall": 0.6211453744493393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8586794301132121,
            "auditor_fn_violation": 0.013355263157894743,
            "auditor_fp_violation": 0.018882537046499743,
            "ave_precision_score": 0.8589052149436742,
            "fpr": 0.09539473684210527,
            "logloss": 0.5393489444501463,
            "mae": 0.3108603247053412,
            "precision": 0.8062360801781737,
            "recall": 0.724
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8814538297184448,
            "auditor_fn_violation": 0.010217749773932893,
            "auditor_fp_violation": 0.008329990608343925,
            "ave_precision_score": 0.8818124202136836,
            "fpr": 0.09110867178924259,
            "logloss": 0.4324272859789392,
            "mae": 0.2814274185247107,
            "precision": 0.8078703703703703,
            "recall": 0.7687224669603524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7988951106163203,
            "auditor_fn_violation": 0.028149122807017552,
            "auditor_fp_violation": 0.012183827286663264,
            "ave_precision_score": 0.7992678202017907,
            "fpr": 0.09429824561403509,
            "logloss": 1.072723090857792,
            "mae": 0.3110690947351436,
            "precision": 0.7817258883248731,
            "recall": 0.616
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8126290014427366,
            "auditor_fn_violation": 0.008994327770712345,
            "auditor_fp_violation": 0.009490136359159986,
            "ave_precision_score": 0.812987858459536,
            "fpr": 0.08562019758507135,
            "logloss": 0.8214293244767985,
            "mae": 0.2721215846405757,
            "precision": 0.7936507936507936,
            "recall": 0.6607929515418502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 16695,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8224845371627616,
            "auditor_fn_violation": 0.010000000000000007,
            "auditor_fp_violation": 0.016436722875149037,
            "ave_precision_score": 0.8227895769703377,
            "fpr": 0.12609649122807018,
            "logloss": 0.9044011256044893,
            "mae": 0.28509804313606407,
            "precision": 0.7628865979381443,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8410603847116065,
            "auditor_fn_violation": 0.006300865099590419,
            "auditor_fp_violation": 0.015766452812332618,
            "ave_precision_score": 0.8414745042007316,
            "fpr": 0.11964873765093303,
            "logloss": 0.6739972868911221,
            "mae": 0.2468378775641373,
            "precision": 0.7645788336933045,
            "recall": 0.7797356828193832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8119471745927558,
            "auditor_fn_violation": 0.016877192982456143,
            "auditor_fp_violation": 0.016074774314426856,
            "ave_precision_score": 0.812381184109194,
            "fpr": 0.14035087719298245,
            "logloss": 1.0834993968290139,
            "mae": 0.2895705764074861,
            "precision": 0.7419354838709677,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8325972541365492,
            "auditor_fn_violation": 0.011760325343210977,
            "auditor_fp_violation": 0.010112243500901943,
            "ave_precision_score": 0.8329122619871177,
            "fpr": 0.1350164654226125,
            "logloss": 0.8379481719341153,
            "mae": 0.25441052483962273,
            "precision": 0.7432150313152401,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8398603819870036,
            "auditor_fn_violation": 0.0021447368421052657,
            "auditor_fp_violation": 0.012189150059615055,
            "ave_precision_score": 0.8401867049355329,
            "fpr": 0.08662280701754387,
            "logloss": 0.5621590127882231,
            "mae": 0.3225978423266066,
            "precision": 0.8175519630484989,
            "recall": 0.708
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8531641677270516,
            "auditor_fn_violation": 0.007420320410837686,
            "auditor_fp_violation": 0.015175571125581577,
            "ave_precision_score": 0.8545664332213754,
            "fpr": 0.08122941822173436,
            "logloss": 0.4660160020272719,
            "mae": 0.29185934613988646,
            "precision": 0.8181818181818182,
            "recall": 0.7334801762114538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8044836248610554,
            "auditor_fn_violation": 0.02164912280701756,
            "auditor_fp_violation": 0.009402678419349345,
            "ave_precision_score": 0.8050379689472906,
            "fpr": 0.0668859649122807,
            "logloss": 1.0498834702018196,
            "mae": 0.3301298629141791,
            "precision": 0.8145896656534954,
            "recall": 0.536
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8232109633972835,
            "auditor_fn_violation": 0.0089048680590144,
            "auditor_fp_violation": 0.006321953656620882,
            "ave_precision_score": 0.823509003106437,
            "fpr": 0.05817782656421515,
            "logloss": 0.8158771918092376,
            "mae": 0.29605566807154315,
            "precision": 0.8245033112582781,
            "recall": 0.5484581497797357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6365720763190688,
            "auditor_fn_violation": 0.010964912280701759,
            "auditor_fp_violation": 0.016034853517288374,
            "ave_precision_score": 0.6142274950750579,
            "fpr": 0.19188596491228072,
            "logloss": 3.9739474797153886,
            "mae": 0.31645016770129514,
            "precision": 0.6956521739130435,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.6394213373844532,
            "auditor_fn_violation": 0.007908722080107547,
            "auditor_fp_violation": 0.03380996188092533,
            "ave_precision_score": 0.6155389075000708,
            "fpr": 0.1712403951701427,
            "logloss": 3.412299228378658,
            "mae": 0.2737220747140797,
            "precision": 0.708411214953271,
            "recall": 0.8348017621145375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8014404794092778,
            "auditor_fn_violation": 0.021388157894736845,
            "auditor_fp_violation": 0.00741462272185318,
            "ave_precision_score": 0.8019977530645097,
            "fpr": 0.06030701754385965,
            "logloss": 1.1485697978287595,
            "mae": 0.3486760525963044,
            "precision": 0.8129251700680272,
            "recall": 0.478
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8221739122370446,
            "auditor_fn_violation": 0.008339095828276046,
            "auditor_fp_violation": 0.005490876162247463,
            "ave_precision_score": 0.8224747217707891,
            "fpr": 0.04610318331503842,
            "logloss": 0.8918492049317589,
            "mae": 0.31027778848760557,
            "precision": 0.8426966292134831,
            "recall": 0.4955947136563877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 16695,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7789054303330796,
            "auditor_fn_violation": 0.022675438596491234,
            "auditor_fp_violation": 0.012921031340487141,
            "ave_precision_score": 0.7796791414558617,
            "fpr": 0.11074561403508772,
            "logloss": 1.0425868443113728,
            "mae": 0.31829922612646194,
            "precision": 0.7612293144208038,
            "recall": 0.644
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7927472289749337,
            "auditor_fn_violation": 0.012717786041383591,
            "auditor_fp_violation": 0.013924150967869007,
            "ave_precision_score": 0.7930999158772554,
            "fpr": 0.10757409440175632,
            "logloss": 0.8370028079996376,
            "mae": 0.28493653394124346,
            "precision": 0.7598039215686274,
            "recall": 0.6828193832599119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 16695,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8379640104416224,
            "auditor_fn_violation": 0.0159561403508772,
            "auditor_fp_violation": 0.013131280872083128,
            "ave_precision_score": 0.8382934493398764,
            "fpr": 0.09868421052631579,
            "logloss": 0.5679250704265935,
            "mae": 0.31815357261870014,
            "precision": 0.7982062780269058,
            "recall": 0.712
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8454625793340891,
            "auditor_fn_violation": 0.015527304554708243,
            "auditor_fp_violation": 0.010472537212335497,
            "ave_precision_score": 0.8469476471805285,
            "fpr": 0.08781558726673985,
            "logloss": 0.4740433598337227,
            "mae": 0.28850365637398084,
            "precision": 0.8113207547169812,
            "recall": 0.7577092511013216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8065221069643336,
            "auditor_fn_violation": 0.013675438596491235,
            "auditor_fp_violation": 0.01695303185147335,
            "ave_precision_score": 0.8068821522834803,
            "fpr": 0.12828947368421054,
            "logloss": 1.2258972104043941,
            "mae": 0.29655761718917717,
            "precision": 0.7542016806722689,
            "recall": 0.718
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8220967242251503,
            "auditor_fn_violation": 0.009811554326223302,
            "auditor_fp_violation": 0.017034686676578745,
            "ave_precision_score": 0.8224994767332344,
            "fpr": 0.1163556531284303,
            "logloss": 0.8819479678865964,
            "mae": 0.25818180752700515,
            "precision": 0.7644444444444445,
            "recall": 0.7577092511013216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8475415947378471,
            "auditor_fn_violation": 0.012192982456140351,
            "auditor_fp_violation": 0.006866377107818088,
            "ave_precision_score": 0.8479635430138925,
            "fpr": 0.10526315789473684,
            "logloss": 0.5273630518847331,
            "mae": 0.29613353736599574,
            "precision": 0.7983193277310925,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8276568485966256,
            "auditor_fn_violation": 0.007408231260608236,
            "auditor_fp_violation": 0.010472537212335499,
            "ave_precision_score": 0.829385986007133,
            "fpr": 0.09549945115257959,
            "logloss": 0.4897601551428864,
            "mae": 0.27248512555905907,
            "precision": 0.8036117381489842,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8120580021082715,
            "auditor_fn_violation": 0.011546052631578952,
            "auditor_fp_violation": 0.016553823880088577,
            "ave_precision_score": 0.8124034454836837,
            "fpr": 0.13596491228070176,
            "logloss": 1.1317848660495031,
            "mae": 0.2912840036338713,
            "precision": 0.7494949494949495,
            "recall": 0.742
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8263980883184918,
            "auditor_fn_violation": 0.006368564340875354,
            "auditor_fp_violation": 0.01585292330307667,
            "ave_precision_score": 0.8268294596968376,
            "fpr": 0.12403951701427003,
            "logloss": 0.856777293973606,
            "mae": 0.25347083608040477,
            "precision": 0.7585470085470085,
            "recall": 0.7819383259911894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8027002256033278,
            "auditor_fn_violation": 0.014265350877192981,
            "auditor_fp_violation": 0.008481838698688472,
            "ave_precision_score": 0.8032482286048188,
            "fpr": 0.07346491228070176,
            "logloss": 0.992186306846922,
            "mae": 0.3235352299904243,
            "precision": 0.8096590909090909,
            "recall": 0.57
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8216666020671173,
            "auditor_fn_violation": 0.0051354710174712475,
            "auditor_fp_violation": 0.006038522603626481,
            "ave_precision_score": 0.8219730512318177,
            "fpr": 0.06586169045005488,
            "logloss": 0.7594612111780032,
            "mae": 0.2870140416647059,
            "precision": 0.8165137614678899,
            "recall": 0.5881057268722467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8014634012490007,
            "auditor_fn_violation": 0.021388157894736845,
            "auditor_fp_violation": 0.00741462272185318,
            "ave_precision_score": 0.8020206531058945,
            "fpr": 0.06030701754385965,
            "logloss": 1.147851635031668,
            "mae": 0.3485776752322538,
            "precision": 0.8129251700680272,
            "recall": 0.478
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8221858886181383,
            "auditor_fn_violation": 0.008339095828276046,
            "auditor_fp_violation": 0.005490876162247463,
            "ave_precision_score": 0.8224866891323148,
            "fpr": 0.04610318331503842,
            "logloss": 0.8911926711915037,
            "mae": 0.31017542026643985,
            "precision": 0.8426966292134831,
            "recall": 0.4955947136563877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8133475786391791,
            "auditor_fn_violation": 0.012269736842105259,
            "auditor_fp_violation": 0.020588485777550673,
            "ave_precision_score": 0.8136190281773933,
            "fpr": 0.1524122807017544,
            "logloss": 1.1001922841918528,
            "mae": 0.29112836081448273,
            "precision": 0.7306201550387597,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8322620278910852,
            "auditor_fn_violation": 0.007971585661300696,
            "auditor_fp_violation": 0.018199636343547265,
            "ave_precision_score": 0.8326494774659068,
            "fpr": 0.1394072447859495,
            "logloss": 0.8283915882178763,
            "mae": 0.2542098710759961,
            "precision": 0.741869918699187,
            "recall": 0.8039647577092511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8330142498333195,
            "auditor_fn_violation": 0.011842105263157902,
            "auditor_fp_violation": 0.012700136262987568,
            "ave_precision_score": 0.8333118498714018,
            "fpr": 0.11403508771929824,
            "logloss": 1.0914344935639215,
            "mae": 0.28047689289643146,
            "precision": 0.7758620689655172,
            "recall": 0.72
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8515629226556292,
            "auditor_fn_violation": 0.008890361078739053,
            "auditor_fp_violation": 0.010969742534113817,
            "ave_precision_score": 0.8519985226461418,
            "fpr": 0.10647639956092206,
            "logloss": 0.7848650412957505,
            "mae": 0.23887758429311734,
            "precision": 0.7815315315315315,
            "recall": 0.76431718061674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8353696946295913,
            "auditor_fn_violation": 0.022875,
            "auditor_fp_violation": 0.013927035428376769,
            "ave_precision_score": 0.8356961179985021,
            "fpr": 0.10855263157894737,
            "logloss": 0.5625688759842467,
            "mae": 0.31755915747105556,
            "precision": 0.7884615384615384,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8392058055810939,
            "auditor_fn_violation": 0.015287939380165094,
            "auditor_fp_violation": 0.006415630021593604,
            "ave_precision_score": 0.8407890183112559,
            "fpr": 0.09330406147091108,
            "logloss": 0.47647528927657323,
            "mae": 0.2903017025226542,
            "precision": 0.8032407407407407,
            "recall": 0.76431718061674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8460313270188591,
            "auditor_fn_violation": 0.012828947368421056,
            "auditor_fp_violation": 0.0018496636007494511,
            "ave_precision_score": 0.8463482829348579,
            "fpr": 0.09539473684210527,
            "logloss": 0.537357897902633,
            "mae": 0.3089508722602196,
            "precision": 0.8096280087527352,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8602101758595353,
            "auditor_fn_violation": 0.02020822352355209,
            "auditor_fp_violation": 0.0061177872201418635,
            "ave_precision_score": 0.861591256349785,
            "fpr": 0.09001097694840834,
            "logloss": 0.46215877145479006,
            "mae": 0.28316143170878244,
            "precision": 0.8047619047619048,
            "recall": 0.7444933920704846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8105604269049371,
            "auditor_fn_violation": 0.017668859649122817,
            "auditor_fp_violation": 0.011550417305399425,
            "ave_precision_score": 0.811207509354146,
            "fpr": 0.1118421052631579,
            "logloss": 0.9031516348325763,
            "mae": 0.28411046247725624,
            "precision": 0.7796976241900648,
            "recall": 0.722
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.83201968881304,
            "auditor_fn_violation": 0.0058269704105959035,
            "auditor_fp_violation": 0.009845626154441104,
            "ave_precision_score": 0.8323181884841513,
            "fpr": 0.10428100987925357,
            "logloss": 0.6765674745860969,
            "mae": 0.2497666226546903,
            "precision": 0.782608695652174,
            "recall": 0.7533039647577092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8014369523203819,
            "auditor_fn_violation": 0.016282894736842107,
            "auditor_fp_violation": 0.0067253236245954735,
            "ave_precision_score": 0.8019939004815676,
            "fpr": 0.0712719298245614,
            "logloss": 0.9828508016700137,
            "mae": 0.3258562596639348,
            "precision": 0.8142857142857143,
            "recall": 0.57
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8186473046326023,
            "auditor_fn_violation": 0.0038419319429198705,
            "auditor_fp_violation": 0.004140975723409726,
            "ave_precision_score": 0.8189580153757712,
            "fpr": 0.06586169045005488,
            "logloss": 0.7583956837978906,
            "mae": 0.29046410604423606,
            "precision": 0.8165137614678899,
            "recall": 0.5881057268722467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8074061686529075,
            "auditor_fn_violation": 0.015269736842105268,
            "auditor_fp_violation": 0.013897760177141887,
            "ave_precision_score": 0.8077169227344124,
            "fpr": 0.1118421052631579,
            "logloss": 1.0665728316919276,
            "mae": 0.28914089331192844,
            "precision": 0.7728285077951003,
            "recall": 0.694
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.822630884318435,
            "auditor_fn_violation": 0.01136621904573084,
            "auditor_fp_violation": 0.01229322143411309,
            "ave_precision_score": 0.8229928107718865,
            "fpr": 0.10428100987925357,
            "logloss": 0.8330177051330703,
            "mae": 0.25163607722478554,
            "precision": 0.7800925925925926,
            "recall": 0.7422907488986784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8174386216638736,
            "auditor_fn_violation": 0.013342105263157898,
            "auditor_fp_violation": 0.019284406404360424,
            "ave_precision_score": 0.8177260509113977,
            "fpr": 0.13486842105263158,
            "logloss": 1.045789584222648,
            "mae": 0.28963275750933515,
            "precision": 0.75,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8343909899917481,
            "auditor_fn_violation": 0.010474039758797273,
            "auditor_fp_violation": 0.017579931159881542,
            "ave_precision_score": 0.8347168651161896,
            "fpr": 0.12294182217343579,
            "logloss": 0.8327397684841653,
            "mae": 0.25483332876081716,
            "precision": 0.759656652360515,
            "recall": 0.7797356828193832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8194434500571087,
            "auditor_fn_violation": 0.016666666666666673,
            "auditor_fp_violation": 0.013535811616419691,
            "ave_precision_score": 0.8207309158670799,
            "fpr": 0.11074561403508772,
            "logloss": 1.164862402602458,
            "mae": 0.2853536431693006,
            "precision": 0.7809110629067245,
            "recall": 0.72
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8319116946052227,
            "auditor_fn_violation": 0.008135998104421244,
            "auditor_fp_violation": 0.012187535278759248,
            "ave_precision_score": 0.8333219568817751,
            "fpr": 0.10757409440175632,
            "logloss": 0.8281808632394395,
            "mae": 0.24476858916867775,
            "precision": 0.7767653758542141,
            "recall": 0.751101321585903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.728137627288203,
            "auditor_fn_violation": 0.002741228070175444,
            "auditor_fp_violation": 0.024048288196218705,
            "ave_precision_score": 0.7253858868307644,
            "fpr": 0.16447368421052633,
            "logloss": 1.6229976775627202,
            "mae": 0.31269011559690446,
            "precision": 0.7142857142857143,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7129690911268879,
            "auditor_fn_violation": 0.0017698515935917845,
            "auditor_fp_violation": 0.024276590276393322,
            "ave_precision_score": 0.7074482361582272,
            "fpr": 0.15148188803512624,
            "logloss": 1.6211287555898393,
            "mae": 0.2769087478769899,
            "precision": 0.7212121212121212,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8152918029286211,
            "auditor_fn_violation": 0.011559210526315795,
            "auditor_fp_violation": 0.021259155169477087,
            "ave_precision_score": 0.8155577875363313,
            "fpr": 0.15789473684210525,
            "logloss": 1.1006962925515158,
            "mae": 0.2898391354209046,
            "precision": 0.7267552182163188,
            "recall": 0.766
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8288301402555379,
            "auditor_fn_violation": 0.003626745068835622,
            "auditor_fp_violation": 0.01745743129799413,
            "ave_precision_score": 0.829245491171436,
            "fpr": 0.1437980241492865,
            "logloss": 0.892113707353347,
            "mae": 0.25707321741513917,
            "precision": 0.7364185110663984,
            "recall": 0.8061674008810573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8020564471169533,
            "auditor_fn_violation": 0.015899122807017555,
            "auditor_fp_violation": 0.010214401294498385,
            "ave_precision_score": 0.8026126644907691,
            "fpr": 0.07236842105263158,
            "logloss": 0.9965704658604801,
            "mae": 0.3280881999719004,
            "precision": 0.8064516129032258,
            "recall": 0.55
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8238486528251665,
            "auditor_fn_violation": 0.003162521700024658,
            "auditor_fp_violation": 0.003225829696368483,
            "ave_precision_score": 0.8241447310880987,
            "fpr": 0.06147091108671789,
            "logloss": 0.7643431805895219,
            "mae": 0.2904586288374766,
            "precision": 0.8238993710691824,
            "recall": 0.5770925110132159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8090025173399913,
            "auditor_fn_violation": 0.013135964912280708,
            "auditor_fp_violation": 0.018246465678760006,
            "ave_precision_score": 0.8093372263048949,
            "fpr": 0.14035087719298245,
            "logloss": 1.0861992447792388,
            "mae": 0.29248815723393845,
            "precision": 0.7393075356415478,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8296661292317754,
            "auditor_fn_violation": 0.013109474508817828,
            "auditor_fp_violation": 0.016659981216687846,
            "ave_precision_score": 0.8299457885717554,
            "fpr": 0.12184412733260154,
            "logloss": 0.8164762813520716,
            "mae": 0.2530173819270371,
            "precision": 0.7623126338329764,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8112992798352024,
            "auditor_fn_violation": 0.018872807017543868,
            "auditor_fp_violation": 0.011071367739737693,
            "ave_precision_score": 0.8119444662437633,
            "fpr": 0.1074561403508772,
            "logloss": 0.8999594606114004,
            "mae": 0.28557793153478933,
            "precision": 0.7831858407079646,
            "recall": 0.708
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8334131394218687,
            "auditor_fn_violation": 0.009864746587232897,
            "auditor_fp_violation": 0.009439695239559287,
            "ave_precision_score": 0.8337061635134784,
            "fpr": 0.10318331503841932,
            "logloss": 0.6727119675084898,
            "mae": 0.25044375368840494,
            "precision": 0.7824074074074074,
            "recall": 0.7444933920704846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8030470080025608,
            "auditor_fn_violation": 0.022861842105263167,
            "auditor_fp_violation": 0.014004215636177821,
            "ave_precision_score": 0.8034232512492219,
            "fpr": 0.09758771929824561,
            "logloss": 1.0331935118097904,
            "mae": 0.2997765994613209,
            "precision": 0.785024154589372,
            "recall": 0.65
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.828425439340273,
            "auditor_fn_violation": 0.006208987557846588,
            "auditor_fp_violation": 0.00758778556279079,
            "ave_precision_score": 0.8287242460972284,
            "fpr": 0.08342480790340286,
            "logloss": 0.7586765990009401,
            "mae": 0.25961619502873545,
            "precision": 0.8080808080808081,
            "recall": 0.7048458149779736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8017454805568078,
            "auditor_fn_violation": 0.01342982456140351,
            "auditor_fp_violation": 0.018818663771078187,
            "ave_precision_score": 0.8021222673925739,
            "fpr": 0.13706140350877194,
            "logloss": 1.266546283453599,
            "mae": 0.30030874131123236,
            "precision": 0.7401247401247402,
            "recall": 0.712
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8141459847711754,
            "auditor_fn_violation": 0.007567808043636999,
            "auditor_fp_violation": 0.016880961359700433,
            "ave_precision_score": 0.8143924039378735,
            "fpr": 0.1251372118551043,
            "logloss": 0.9558605352674501,
            "mae": 0.25885153248148984,
            "precision": 0.7521739130434782,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8035654211530608,
            "auditor_fn_violation": 0.01924561403508773,
            "auditor_fp_violation": 0.007494464316130131,
            "ave_precision_score": 0.8041192013093726,
            "fpr": 0.06140350877192982,
            "logloss": 1.1103256204628653,
            "mae": 0.34184857798110674,
            "precision": 0.8163934426229508,
            "recall": 0.498
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8256083138248563,
            "auditor_fn_violation": 0.001948771016987682,
            "auditor_fp_violation": 0.004004064113064971,
            "ave_precision_score": 0.8259042189203699,
            "fpr": 0.04939626783754116,
            "logloss": 0.8514173086915443,
            "mae": 0.30408068190222964,
            "precision": 0.8381294964028777,
            "recall": 0.513215859030837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7311738263678398,
            "auditor_fn_violation": 0.003743421052631577,
            "auditor_fp_violation": 0.023236565321069668,
            "ave_precision_score": 0.7285481449510738,
            "fpr": 0.16557017543859648,
            "logloss": 1.6207954313020254,
            "mae": 0.31284140518178905,
            "precision": 0.7140151515151515,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.712673754661969,
            "auditor_fn_violation": 0.0008268978756945222,
            "auditor_fp_violation": 0.02509085406423317,
            "ave_precision_score": 0.7077599142999509,
            "fpr": 0.15367727771679474,
            "logloss": 1.6233786520763858,
            "mae": 0.2766062658919579,
            "precision": 0.717741935483871,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7945654040434915,
            "auditor_fn_violation": 0.02353070175438597,
            "auditor_fp_violation": 0.011404041049225004,
            "ave_precision_score": 0.7951890373403195,
            "fpr": 0.11513157894736842,
            "logloss": 0.9757816353645056,
            "mae": 0.2956600250076572,
            "precision": 0.7697368421052632,
            "recall": 0.702
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8134468840497264,
            "auditor_fn_violation": 0.01061669173150481,
            "auditor_fp_violation": 0.009530969646455794,
            "ave_precision_score": 0.8137862584704615,
            "fpr": 0.10757409440175632,
            "logloss": 0.7410165505145058,
            "mae": 0.2651903856363267,
            "precision": 0.7715617715617715,
            "recall": 0.7290748898678414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8203158304029687,
            "auditor_fn_violation": 0.0124561403508772,
            "auditor_fp_violation": 0.018797372679271,
            "ave_precision_score": 0.8206829002872984,
            "fpr": 0.15021929824561403,
            "logloss": 1.0019436539213673,
            "mae": 0.29057144457490197,
            "precision": 0.7350096711798839,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8354653806084396,
            "auditor_fn_violation": 0.008800901367041114,
            "auditor_fp_violation": 0.014553463983839623,
            "ave_precision_score": 0.83580552225566,
            "fpr": 0.14050493962678376,
            "logloss": 0.8272617186825626,
            "mae": 0.25648043902230094,
            "precision": 0.7408906882591093,
            "recall": 0.8061674008810573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8055956593603086,
            "auditor_fn_violation": 0.01763157894736843,
            "auditor_fp_violation": 0.007747296031340491,
            "ave_precision_score": 0.8061459203606726,
            "fpr": 0.06469298245614036,
            "logloss": 1.0613843470338469,
            "mae": 0.33442656159136613,
            "precision": 0.8150470219435737,
            "recall": 0.52
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8261600707048298,
            "auditor_fn_violation": 0.006368564340875358,
            "auditor_fp_violation": 0.006612590583843952,
            "ave_precision_score": 0.8264509054741096,
            "fpr": 0.054884742041712405,
            "logloss": 0.8185678053950939,
            "mae": 0.29931293767466494,
            "precision": 0.8287671232876712,
            "recall": 0.5330396475770925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8115333012108964,
            "auditor_fn_violation": 0.01411184210526316,
            "auditor_fp_violation": 0.016064128768523256,
            "ave_precision_score": 0.8119120791549734,
            "fpr": 0.13486842105263158,
            "logloss": 0.9919711106101182,
            "mae": 0.2789547803879663,
            "precision": 0.7578740157480315,
            "recall": 0.77
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8281024672988233,
            "auditor_fn_violation": 0.005602112216328096,
            "auditor_fp_violation": 0.017226843322676648,
            "ave_precision_score": 0.8284882032439655,
            "fpr": 0.13062568605927552,
            "logloss": 0.7670544183682271,
            "mae": 0.24672832129403793,
            "precision": 0.7520833333333333,
            "recall": 0.7951541850220264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7325819878185262,
            "auditor_fn_violation": 0.002741228070175444,
            "auditor_fp_violation": 0.024048288196218705,
            "ave_precision_score": 0.7294625975339956,
            "fpr": 0.16447368421052633,
            "logloss": 1.6117402873598425,
            "mae": 0.31274672796687897,
            "precision": 0.7142857142857143,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7134875339264832,
            "auditor_fn_violation": 0.0019245927165287724,
            "auditor_fp_violation": 0.02509085406423317,
            "ave_precision_score": 0.7086415629896098,
            "fpr": 0.15367727771679474,
            "logloss": 1.6156782555574252,
            "mae": 0.2761047022218869,
            "precision": 0.717741935483871,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8389306467252559,
            "auditor_fn_violation": 0.026717105263157903,
            "auditor_fp_violation": 0.013857839380003406,
            "ave_precision_score": 0.8393218676572907,
            "fpr": 0.08662280701754387,
            "logloss": 0.6399950836574826,
            "mae": 0.31009800098819895,
            "precision": 0.8228699551569507,
            "recall": 0.734
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8788615040316178,
            "auditor_fn_violation": 0.026180263736901407,
            "auditor_fp_violation": 0.010743958474948781,
            "ave_precision_score": 0.8791038314328619,
            "fpr": 0.07683863885839737,
            "logloss": 0.5412012948679696,
            "mae": 0.2761238320424691,
            "precision": 0.825,
            "recall": 0.7268722466960352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.726757780558245,
            "auditor_fn_violation": 0.005396929824561409,
            "auditor_fp_violation": 0.02337761880429228,
            "ave_precision_score": 0.7236237443374514,
            "fpr": 0.16228070175438597,
            "logloss": 1.6573491164043772,
            "mae": 0.31626930700991235,
            "precision": 0.7148362235067437,
            "recall": 0.742
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7119627796929954,
            "auditor_fn_violation": 0.0033220984830534318,
            "auditor_fp_violation": 0.023409483410876557,
            "ave_precision_score": 0.7064838521221148,
            "fpr": 0.15367727771679474,
            "logloss": 1.6318097956100526,
            "mae": 0.2798380785739352,
            "precision": 0.717741935483871,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.801759834321921,
            "auditor_fn_violation": 0.01342982456140351,
            "auditor_fp_violation": 0.018818663771078187,
            "ave_precision_score": 0.8021411706155699,
            "fpr": 0.13706140350877194,
            "logloss": 1.2664730143763725,
            "mae": 0.30030242971691007,
            "precision": 0.7401247401247402,
            "recall": 0.712
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.814194500981091,
            "auditor_fn_violation": 0.007567808043636999,
            "auditor_fp_violation": 0.016880961359700433,
            "ave_precision_score": 0.814440792399566,
            "fpr": 0.1251372118551043,
            "logloss": 0.9557956754453235,
            "mae": 0.25884531732300714,
            "precision": 0.7521739130434782,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8025247190528587,
            "auditor_fn_violation": 0.014265350877192981,
            "auditor_fp_violation": 0.008681442684380859,
            "ave_precision_score": 0.8030739293267793,
            "fpr": 0.07236842105263158,
            "logloss": 0.9839679291784116,
            "mae": 0.3252474329915807,
            "precision": 0.811965811965812,
            "recall": 0.57
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8214821372224781,
            "auditor_fn_violation": 0.001636870941067808,
            "auditor_fp_violation": 0.0057502876344796275,
            "ave_precision_score": 0.8217877224784228,
            "fpr": 0.06476399560922064,
            "logloss": 0.7558061876263323,
            "mae": 0.28874230004872053,
            "precision": 0.8179012345679012,
            "recall": 0.5837004405286343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8061849188943118,
            "auditor_fn_violation": 0.01367324561403509,
            "auditor_fp_violation": 0.0235266564469426,
            "ave_precision_score": 0.8063869479670358,
            "fpr": 0.17214912280701755,
            "logloss": 1.1757186361980196,
            "mae": 0.2858907527044013,
            "precision": 0.7186379928315412,
            "recall": 0.802
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.82028584347082,
            "auditor_fn_violation": 0.00786278330923563,
            "auditor_fp_violation": 0.019306939016686408,
            "ave_precision_score": 0.8207488924454558,
            "fpr": 0.16245883644346873,
            "logloss": 0.9261256970900552,
            "mae": 0.25610050073883306,
            "precision": 0.7223264540337712,
            "recall": 0.8480176211453745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8110172215768158,
            "auditor_fn_violation": 0.012171052631578952,
            "auditor_fp_violation": 0.016553823880088577,
            "ave_precision_score": 0.8113058332155545,
            "fpr": 0.13596491228070176,
            "logloss": 1.164032704539695,
            "mae": 0.2917980196243416,
            "precision": 0.7489878542510121,
            "recall": 0.74
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.825252365319675,
            "auditor_fn_violation": 0.005200752428710287,
            "auditor_fp_violation": 0.01585292330307667,
            "ave_precision_score": 0.8256843753400949,
            "fpr": 0.12403951701427003,
            "logloss": 0.8805743114675196,
            "mae": 0.25385512105651775,
            "precision": 0.7575107296137339,
            "recall": 0.7775330396475771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 16695,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8418600483774076,
            "auditor_fn_violation": 0.017429824561403507,
            "auditor_fp_violation": 0.013815257196389031,
            "ave_precision_score": 0.8421833187041899,
            "fpr": 0.12828947368421054,
            "logloss": 0.552635648497458,
            "mae": 0.3081711952651076,
            "precision": 0.7762906309751434,
            "recall": 0.812
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8469029088904008,
            "auditor_fn_violation": 0.010599766921183577,
            "auditor_fp_violation": 0.007640628640467712,
            "ave_precision_score": 0.8483726805960847,
            "fpr": 0.132821075740944,
            "logloss": 0.4795435921741731,
            "mae": 0.28718044988943886,
            "precision": 0.7565392354124748,
            "recall": 0.8281938325991189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8038248912788861,
            "auditor_fn_violation": 0.01648684210526316,
            "auditor_fp_violation": 0.01168880940214614,
            "ave_precision_score": 0.8044973403093766,
            "fpr": 0.09429824561403509,
            "logloss": 1.0382271326752233,
            "mae": 0.2997639454967682,
            "precision": 0.7917675544794189,
            "recall": 0.654
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8239058072081966,
            "auditor_fn_violation": 0.008140833764513035,
            "auditor_fp_violation": 0.010722340852262768,
            "ave_precision_score": 0.8242356992548894,
            "fpr": 0.08342480790340286,
            "logloss": 0.7656243775623629,
            "mae": 0.26123949877935054,
            "precision": 0.8025974025974026,
            "recall": 0.6806167400881057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 16695,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7952908712831841,
            "auditor_fn_violation": 0.015057017543859654,
            "auditor_fp_violation": 0.015279019758133202,
            "ave_precision_score": 0.7948805167922699,
            "fpr": 0.14144736842105263,
            "logloss": 1.5948466978427487,
            "mae": 0.2999501660763519,
            "precision": 0.736734693877551,
            "recall": 0.722
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8067646884719142,
            "auditor_fn_violation": 0.011223567073023303,
            "auditor_fp_violation": 0.017841744590189935,
            "ave_precision_score": 0.8066962544685028,
            "fpr": 0.13172338090010977,
            "logloss": 1.1593453705855725,
            "mae": 0.26390880855600063,
            "precision": 0.7424892703862661,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8037671965000864,
            "auditor_fn_violation": 0.023357456140350886,
            "auditor_fp_violation": 0.011646227218531762,
            "ave_precision_score": 0.8041211703623419,
            "fpr": 0.09868421052631579,
            "logloss": 1.1388729279032617,
            "mae": 0.2998061910693693,
            "precision": 0.781021897810219,
            "recall": 0.642
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8198136386485134,
            "auditor_fn_violation": 0.01570622397810413,
            "auditor_fp_violation": 0.0060361206455502555,
            "ave_precision_score": 0.8201654288141724,
            "fpr": 0.09001097694840834,
            "logloss": 0.8608823379973335,
            "mae": 0.25904397791070605,
            "precision": 0.7980295566502463,
            "recall": 0.7136563876651982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8099182136249146,
            "auditor_fn_violation": 0.015679824561403512,
            "auditor_fp_violation": 0.014882473173224322,
            "ave_precision_score": 0.8102323157947168,
            "fpr": 0.11403508771929824,
            "logloss": 1.028975872505768,
            "mae": 0.2877430221759703,
            "precision": 0.7709251101321586,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8276850047910118,
            "auditor_fn_violation": 0.010203242793657554,
            "auditor_fp_violation": 0.011803221986563445,
            "ave_precision_score": 0.8280273332417516,
            "fpr": 0.10537870472008781,
            "logloss": 0.7673634387118831,
            "mae": 0.24938476789411773,
            "precision": 0.7798165137614679,
            "recall": 0.748898678414097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7822801012356011,
            "auditor_fn_violation": 0.0254342105263158,
            "auditor_fp_violation": 0.012399399591211042,
            "ave_precision_score": 0.783014138699613,
            "fpr": 0.10197368421052631,
            "logloss": 1.0037823400007369,
            "mae": 0.3205482349468758,
            "precision": 0.7686567164179104,
            "recall": 0.618
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7967781696366562,
            "auditor_fn_violation": 0.013339168363177424,
            "auditor_fp_violation": 0.012367682134476024,
            "ave_precision_score": 0.797138636379167,
            "fpr": 0.09330406147091108,
            "logloss": 0.8077687915615338,
            "mae": 0.2886869888808587,
            "precision": 0.7809278350515464,
            "recall": 0.6674008810572687
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.80685681022785,
            "auditor_fn_violation": 0.015355263157894738,
            "auditor_fp_violation": 0.012141245103048886,
            "ave_precision_score": 0.8072028434818114,
            "fpr": 0.10307017543859649,
            "logloss": 1.1341763719085771,
            "mae": 0.2909075574965718,
            "precision": 0.7844036697247706,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8202266731483945,
            "auditor_fn_violation": 0.008670338544563033,
            "auditor_fp_violation": 0.007337981922863518,
            "ave_precision_score": 0.8205206407492203,
            "fpr": 0.09330406147091108,
            "logloss": 0.8562227773672069,
            "mae": 0.25045332209425547,
            "precision": 0.7966507177033493,
            "recall": 0.7334801762114538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 16695,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8243272851692706,
            "auditor_fn_violation": 0.014377192982456145,
            "auditor_fp_violation": 0.013157894736842108,
            "ave_precision_score": 0.824636729938977,
            "fpr": 0.11293859649122807,
            "logloss": 1.1850470583633304,
            "mae": 0.28566647574077547,
            "precision": 0.7765726681127982,
            "recall": 0.716
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8432016042247317,
            "auditor_fn_violation": 0.01050305371934796,
            "auditor_fp_violation": 0.015552678543548703,
            "ave_precision_score": 0.8434319442044416,
            "fpr": 0.10976948408342481,
            "logloss": 0.8526187578158003,
            "mae": 0.24551952410907982,
            "precision": 0.7727272727272727,
            "recall": 0.748898678414097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8249127556425342,
            "auditor_fn_violation": 0.017258771929824567,
            "auditor_fp_violation": 0.025767543859649127,
            "ave_precision_score": 0.8252431633755919,
            "fpr": 0.13267543859649122,
            "logloss": 0.988071424459565,
            "mae": 0.2844026436361795,
            "precision": 0.7550607287449392,
            "recall": 0.746
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8425903500763124,
            "auditor_fn_violation": 0.009620545752597957,
            "auditor_fp_violation": 0.025616882882926163,
            "ave_precision_score": 0.8430774401740888,
            "fpr": 0.132821075740944,
            "logloss": 0.7662888631064833,
            "mae": 0.25328238676760273,
            "precision": 0.7457983193277311,
            "recall": 0.7819383259911894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8070281735679556,
            "auditor_fn_violation": 0.012903508771929827,
            "auditor_fp_violation": 0.012907724408107654,
            "ave_precision_score": 0.8074699369687663,
            "fpr": 0.10855263157894737,
            "logloss": 1.0479550640283057,
            "mae": 0.2939706305777485,
            "precision": 0.775,
            "recall": 0.682
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8257613290699402,
            "auditor_fn_violation": 0.01428695774116646,
            "auditor_fp_violation": 0.005683032808345365,
            "ave_precision_score": 0.8260989921141078,
            "fpr": 0.09659714599341383,
            "logloss": 0.7814797961612091,
            "mae": 0.2522881817696936,
            "precision": 0.7929411764705883,
            "recall": 0.7422907488986784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8042236723408616,
            "auditor_fn_violation": 0.020991228070175446,
            "auditor_fp_violation": 0.006882345426673484,
            "ave_precision_score": 0.804763346225665,
            "fpr": 0.07236842105263158,
            "logloss": 1.041630598594298,
            "mae": 0.31780697601744595,
            "precision": 0.8156424581005587,
            "recall": 0.584
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8274840485190418,
            "auditor_fn_violation": 0.013152995449643863,
            "auditor_fp_violation": 0.0076118051435530255,
            "ave_precision_score": 0.8277812315298311,
            "fpr": 0.06147091108671789,
            "logloss": 0.7769639340958401,
            "mae": 0.2787608321429087,
            "precision": 0.8303030303030303,
            "recall": 0.6035242290748899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8105460161379519,
            "auditor_fn_violation": 0.012021929824561408,
            "auditor_fp_violation": 0.01178461931527849,
            "ave_precision_score": 0.8108298839515499,
            "fpr": 0.1162280701754386,
            "logloss": 1.055229562302194,
            "mae": 0.2901552973348465,
            "precision": 0.771551724137931,
            "recall": 0.716
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8279396492200533,
            "auditor_fn_violation": 0.007952243020933579,
            "auditor_fp_violation": 0.013474984807615173,
            "ave_precision_score": 0.8282846248603287,
            "fpr": 0.10098792535675083,
            "logloss": 0.7774266228146197,
            "mae": 0.25135664926490703,
            "precision": 0.7865429234338747,
            "recall": 0.7466960352422908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8289717319401001,
            "auditor_fn_violation": 0.020412280701754392,
            "auditor_fp_violation": 0.016266394140691542,
            "ave_precision_score": 0.829441006097452,
            "fpr": 0.13048245614035087,
            "logloss": 0.8726676984873164,
            "mae": 0.28000542161194764,
            "precision": 0.7605633802816901,
            "recall": 0.756
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8527584149949428,
            "auditor_fn_violation": 0.013834823522584954,
            "auditor_fp_violation": 0.019121988244817176,
            "ave_precision_score": 0.8529790124241965,
            "fpr": 0.12184412733260154,
            "logloss": 0.6804651979227472,
            "mae": 0.24279057392115325,
            "precision": 0.7653276955602537,
            "recall": 0.7973568281938326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7233003714200811,
            "auditor_fn_violation": 0.01241228070175439,
            "auditor_fp_violation": 0.004503065917220235,
            "ave_precision_score": 0.7242265574318265,
            "fpr": 0.027412280701754384,
            "logloss": 2.322345592382733,
            "mae": 0.47486630864636326,
            "precision": 0.7787610619469026,
            "recall": 0.176
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7180925670173937,
            "auditor_fn_violation": 0.010503053719347972,
            "auditor_fp_violation": 0.0044075930698705594,
            "ave_precision_score": 0.7187113488697043,
            "fpr": 0.021953896816684963,
            "logloss": 1.8751264862803956,
            "mae": 0.42768558605437945,
            "precision": 0.8214285714285714,
            "recall": 0.2026431718061674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8015851701622962,
            "auditor_fn_violation": 0.020263157894736854,
            "auditor_fp_violation": 0.008870401124169649,
            "ave_precision_score": 0.8030322898137661,
            "fpr": 0.08881578947368421,
            "logloss": 0.8795681727883087,
            "mae": 0.30076589131044434,
            "precision": 0.8029197080291971,
            "recall": 0.66
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8218191121144475,
            "auditor_fn_violation": 0.004688172458981517,
            "auditor_fp_violation": 0.008944891875857201,
            "ave_precision_score": 0.8231832982276459,
            "fpr": 0.0801317233809001,
            "logloss": 0.673568241207388,
            "mae": 0.2694248005493613,
            "precision": 0.8078947368421052,
            "recall": 0.6762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8201704746850709,
            "auditor_fn_violation": 0.014491228070175438,
            "auditor_fp_violation": 0.013980263157894737,
            "ave_precision_score": 0.8205088876742785,
            "fpr": 0.11293859649122807,
            "logloss": 1.0590734483745574,
            "mae": 0.29255565579064796,
            "precision": 0.7736263736263737,
            "recall": 0.704
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8389830783512857,
            "auditor_fn_violation": 0.008655831564287682,
            "auditor_fp_violation": 0.011858467022316596,
            "ave_precision_score": 0.8393038817731316,
            "fpr": 0.10537870472008781,
            "logloss": 0.7767520245582022,
            "mae": 0.25499203521778846,
            "precision": 0.7757009345794392,
            "recall": 0.7312775330396476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8119502604839979,
            "auditor_fn_violation": 0.014293859649122819,
            "auditor_fp_violation": 0.00978325668540283,
            "ave_precision_score": 0.8123980980660158,
            "fpr": 0.09649122807017543,
            "logloss": 1.0293691226735968,
            "mae": 0.2962072304523956,
            "precision": 0.7879518072289157,
            "recall": 0.654
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8324310860021014,
            "auditor_fn_violation": 0.006532976783995902,
            "auditor_fp_violation": 0.011582241843550863,
            "ave_precision_score": 0.8327889724168877,
            "fpr": 0.0801317233809001,
            "logloss": 0.7487987585015541,
            "mae": 0.2537988474783551,
            "precision": 0.8118556701030928,
            "recall": 0.6938325991189427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8198443025962122,
            "auditor_fn_violation": 0.009708333333333334,
            "auditor_fp_violation": 0.019369570771589167,
            "ave_precision_score": 0.8201640844771689,
            "fpr": 0.13925438596491227,
            "logloss": 1.0663530520527755,
            "mae": 0.2905570808506418,
            "precision": 0.7449799196787149,
            "recall": 0.742
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8393579045496822,
            "auditor_fn_violation": 0.004806646131230147,
            "auditor_fp_violation": 0.017133166957703932,
            "ave_precision_score": 0.8396798149985607,
            "fpr": 0.12952799121844127,
            "logloss": 0.8017357035613922,
            "mae": 0.25340933391536336,
            "precision": 0.751578947368421,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 16695,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8000373412573816,
            "auditor_fn_violation": 0.013048245614035095,
            "auditor_fp_violation": 0.00797883665474366,
            "ave_precision_score": 0.8005966258563811,
            "fpr": 0.07236842105263158,
            "logloss": 1.0474579452591992,
            "mae": 0.3276959111127578,
            "precision": 0.8064516129032258,
            "recall": 0.55
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.82059212976198,
            "auditor_fn_violation": 0.003965241275260282,
            "auditor_fp_violation": 0.008553372709432733,
            "ave_precision_score": 0.8208995922319937,
            "fpr": 0.06147091108671789,
            "logloss": 0.799723782681951,
            "mae": 0.290150702767058,
            "precision": 0.8238993710691824,
            "recall": 0.5770925110132159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.817422552425596,
            "auditor_fn_violation": 0.015026315789473686,
            "auditor_fp_violation": 0.018536556804632946,
            "ave_precision_score": 0.8177526059252191,
            "fpr": 0.14144736842105263,
            "logloss": 1.113534823101165,
            "mae": 0.2915333955802847,
            "precision": 0.7425149700598802,
            "recall": 0.744
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8358405537031814,
            "auditor_fn_violation": 0.0077249669966198715,
            "auditor_fp_violation": 0.018927429640643055,
            "ave_precision_score": 0.8361690616558013,
            "fpr": 0.13172338090010977,
            "logloss": 0.8169091466130115,
            "mae": 0.256010679272642,
            "precision": 0.7484276729559748,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7689093204912263,
            "auditor_fn_violation": 0.013087719298245619,
            "auditor_fp_violation": 0.018137348833248173,
            "ave_precision_score": 0.768939372818629,
            "fpr": 0.13048245614035087,
            "logloss": 1.3249734623544513,
            "mae": 0.2982355640214416,
            "precision": 0.7525987525987526,
            "recall": 0.724
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7479104336028001,
            "auditor_fn_violation": 0.0011944080426698651,
            "auditor_fp_violation": 0.021310172052257007,
            "ave_precision_score": 0.7463710791149551,
            "fpr": 0.11525795828759605,
            "logloss": 1.285947909113298,
            "mae": 0.25503914304381653,
            "precision": 0.7692307692307693,
            "recall": 0.7709251101321586
        }
    }
]