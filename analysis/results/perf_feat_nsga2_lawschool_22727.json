[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.6329611268172628,
            "auditor_fn_violation": 0.005614399068209946,
            "auditor_fp_violation": 0.0005813953488372093,
            "ave_precision_score": 0.5599873709228269,
            "fpr": 0.0010964912280701754,
            "logloss": 8.783553217658984,
            "mae": 0.5093749528834569,
            "precision": 0.9473684210526315,
            "recall": 0.03734439834024896
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6370108506262513,
            "auditor_fn_violation": 0.001260488567229148,
            "auditor_fp_violation": 0.0005225927602149382,
            "ave_precision_score": 0.5631373276764832,
            "fpr": 0.0010976948408342481,
            "logloss": 8.443154390769259,
            "mae": 0.49692647697845005,
            "precision": 0.9444444444444444,
            "recall": 0.036016949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6406556368858245,
            "auditor_fn_violation": 0.02279427822668707,
            "auditor_fp_violation": 0.008807629538963687,
            "ave_precision_score": 0.6421949049932021,
            "fpr": 0.02850877192982456,
            "logloss": 3.947170735025753,
            "mae": 0.48138636922734673,
            "precision": 0.7833333333333333,
            "recall": 0.1950207468879668
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6562232164951574,
            "auditor_fn_violation": 0.01663984446222254,
            "auditor_fp_violation": 0.004743341943194918,
            "ave_precision_score": 0.6570520933961386,
            "fpr": 0.024149286498353458,
            "logloss": 3.764850736786025,
            "mae": 0.4656855004502265,
            "precision": 0.8181818181818182,
            "recall": 0.2097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6977904896052527,
            "auditor_fn_violation": 0.012075052777171144,
            "auditor_fp_violation": 0.0113984088127295,
            "ave_precision_score": 0.6960649283365685,
            "fpr": 0.09868421052631579,
            "logloss": 0.7576504525983879,
            "mae": 0.4367186241556498,
            "precision": 0.697986577181208,
            "recall": 0.4315352697095436
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7006988705970358,
            "auditor_fn_violation": 0.014800275353960076,
            "auditor_fp_violation": 0.014917647882499144,
            "ave_precision_score": 0.7006684991972872,
            "fpr": 0.09220636663007684,
            "logloss": 0.753644729775516,
            "mae": 0.432002555316758,
            "precision": 0.711340206185567,
            "recall": 0.4385593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5164886447514495,
            "auditor_fn_violation": 0.00910178714420907,
            "auditor_fp_violation": 0.012686148510811913,
            "ave_precision_score": 0.5185858505145322,
            "fpr": 0.2576754385964912,
            "logloss": 0.6941162913195408,
            "mae": 0.49976739483444316,
            "precision": 0.5144628099173554,
            "recall": 0.516597510373444
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5239753188259808,
            "auditor_fn_violation": 0.007376881430352199,
            "auditor_fp_violation": 0.024291811796593895,
            "ave_precision_score": 0.5268313902993963,
            "fpr": 0.25686059275521406,
            "logloss": 0.6940833694064075,
            "mae": 0.49974641894142663,
            "precision": 0.5104602510460251,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7351491710044341,
            "auditor_fn_violation": 0.004781793695857896,
            "auditor_fp_violation": 0.0005915952672378623,
            "ave_precision_score": 0.5399600081435635,
            "fpr": 0.0010964912280701754,
            "logloss": 0.688727951342678,
            "mae": 0.49502291105556906,
            "precision": 0.9285714285714286,
            "recall": 0.026970954356846474
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.766202627025619,
            "auditor_fn_violation": 0.0011116485888109588,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5324052540512381,
            "fpr": 0.0,
            "logloss": 0.684728795914217,
            "mae": 0.49327990435611796,
            "precision": 1.0,
            "recall": 0.029661016949152543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6632729372724149,
            "auditor_fn_violation": 0.0026661570939797625,
            "auditor_fp_violation": 0.0067625458996328006,
            "ave_precision_score": 0.6638087409318689,
            "fpr": 0.43201754385964913,
            "logloss": 0.66795669260885,
            "mae": 0.4644030727642147,
            "precision": 0.541860465116279,
            "recall": 0.966804979253112
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6633479513489955,
            "auditor_fn_violation": 0.006083834117844053,
            "auditor_fp_violation": 0.008261466410287832,
            "ave_precision_score": 0.6640620836792986,
            "fpr": 0.4270032930845225,
            "logloss": 0.6770209708817884,
            "mae": 0.4661673490616414,
            "precision": 0.5352449223416965,
            "recall": 0.9491525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5915890400591932,
            "auditor_fn_violation": 0.0019723192836864105,
            "auditor_fp_violation": 0.0008975928192574504,
            "ave_precision_score": 0.5600945706125386,
            "fpr": 0.09539473684210527,
            "logloss": 7.110243406324256,
            "mae": 0.4670049811334246,
            "precision": 0.66015625,
            "recall": 0.3506224066390041
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.6082313695384949,
            "auditor_fn_violation": 0.01146998083685278,
            "auditor_fp_violation": 0.005275936478724978,
            "ave_precision_score": 0.5798539468918955,
            "fpr": 0.0889132821075741,
            "logloss": 6.450491264758296,
            "mae": 0.4488585699346596,
            "precision": 0.676,
            "recall": 0.3580508474576271
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7805025930547906,
            "auditor_fn_violation": 0.012309365218024315,
            "auditor_fp_violation": 0.012086903304773562,
            "ave_precision_score": 0.7813625250822711,
            "fpr": 0.1699561403508772,
            "logloss": 0.6146937570236788,
            "mae": 0.34625768594407036,
            "precision": 0.7030651340996169,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7992994599607206,
            "auditor_fn_violation": 0.007348973934398782,
            "auditor_fp_violation": 0.014805127910204063,
            "ave_precision_score": 0.7999086498113137,
            "fpr": 0.16575192096597147,
            "logloss": 0.6031702805876328,
            "mae": 0.3453426180401271,
            "precision": 0.7045009784735812,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7675624751350449,
            "auditor_fn_violation": 0.017370968916066105,
            "auditor_fp_violation": 0.016518767849857202,
            "ave_precision_score": 0.7268283294651143,
            "fpr": 0.15021929824561403,
            "logloss": 4.95054689067,
            "mae": 0.31745104858468653,
            "precision": 0.7091295116772823,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7846388128246188,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.02310160053409481,
            "ave_precision_score": 0.7474751135108165,
            "fpr": 0.150384193194292,
            "logloss": 4.282419743658564,
            "mae": 0.30690243546217916,
            "precision": 0.7097457627118644,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7850388785675211,
            "auditor_fn_violation": 0.019413809419815107,
            "auditor_fp_violation": 0.020744084047327624,
            "ave_precision_score": 0.738703446484321,
            "fpr": 0.14802631578947367,
            "logloss": 3.8704276801712845,
            "mae": 0.30765811124241277,
            "precision": 0.7175732217573222,
            "recall": 0.7116182572614108
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8034414087557046,
            "auditor_fn_violation": 0.01673984632272229,
            "auditor_fp_violation": 0.0306929479982697,
            "ave_precision_score": 0.75928408718884,
            "fpr": 0.14818880351262348,
            "logloss": 3.3493131977531165,
            "mae": 0.2885919446486408,
            "precision": 0.7239263803680982,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7685035261931714,
            "auditor_fn_violation": 0.016247179151197493,
            "auditor_fp_violation": 0.020338637290901677,
            "ave_precision_score": 0.708165609606105,
            "fpr": 0.15460526315789475,
            "logloss": 6.628718306743947,
            "mae": 0.3204831283106941,
            "precision": 0.7044025157232704,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7827038989149545,
            "auditor_fn_violation": 0.007572233902026089,
            "auditor_fp_violation": 0.023099100090266025,
            "ave_precision_score": 0.7231077835373544,
            "fpr": 0.1525795828759605,
            "logloss": 5.955011249470108,
            "mae": 0.31184744136833714,
            "precision": 0.7073684210526315,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.254046296433057,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7604104189799176,
            "auditor_fn_violation": 0.007008899322996299,
            "auditor_fp_violation": 0.00698184414524684,
            "ave_precision_score": 0.7609548568341065,
            "fpr": 0.03728070175438596,
            "logloss": 1.1770303977823813,
            "mae": 0.400545450097245,
            "precision": 0.8291457286432161,
            "recall": 0.34232365145228216
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7520235725993837,
            "auditor_fn_violation": 0.00340936575564196,
            "auditor_fp_violation": 0.006901224967431719,
            "ave_precision_score": 0.7524124951103874,
            "fpr": 0.03951701427003293,
            "logloss": 1.131449649119131,
            "mae": 0.4048382528883279,
            "precision": 0.797752808988764,
            "recall": 0.3008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6678969250673061,
            "auditor_fn_violation": 0.003218952464147922,
            "auditor_fp_violation": 0.0067625458996328006,
            "ave_precision_score": 0.6684117494354512,
            "fpr": 0.43201754385964913,
            "logloss": 0.6665688872036484,
            "mae": 0.46368617825863656,
            "precision": 0.5423925667828107,
            "recall": 0.9688796680497925
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.6690848448515974,
            "auditor_fn_violation": 0.004855904295893877,
            "auditor_fp_violation": 0.008261466410287832,
            "ave_precision_score": 0.6697763727451713,
            "fpr": 0.4270032930845225,
            "logloss": 0.6767517022406038,
            "mae": 0.4654321019199363,
            "precision": 0.5363528009535161,
            "recall": 0.9533898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8038281522993778,
            "auditor_fn_violation": 0.016401870859721918,
            "auditor_fp_violation": 0.014152386780905763,
            "ave_precision_score": 0.8056916220959723,
            "fpr": 0.1337719298245614,
            "logloss": 1.1163182666757163,
            "mae": 0.2876134066014146,
            "precision": 0.7468879668049793,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.83341909568668,
            "auditor_fn_violation": 0.008181547563675605,
            "auditor_fp_violation": 0.02568205856539536,
            "ave_precision_score": 0.8337725665776541,
            "fpr": 0.13172338090010977,
            "logloss": 0.874878078518427,
            "mae": 0.25724220347580307,
            "precision": 0.7551020408163265,
            "recall": 0.7838983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.254046296433057,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7674926865864713,
            "auditor_fn_violation": 0.01815352697095436,
            "auditor_fp_violation": 0.01643716850265198,
            "ave_precision_score": 0.7281732854723555,
            "fpr": 0.14692982456140352,
            "logloss": 4.842979663485249,
            "mae": 0.3174421078519478,
            "precision": 0.7124463519313304,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7864666047466982,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.02310160053409481,
            "ave_precision_score": 0.7521742379976197,
            "fpr": 0.150384193194292,
            "logloss": 4.142275825371319,
            "mae": 0.3074090310917665,
            "precision": 0.7097457627118644,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7111036666390316,
            "auditor_fn_violation": 0.01609703719880616,
            "auditor_fp_violation": 0.014075887392900862,
            "ave_precision_score": 0.6988949223990404,
            "fpr": 0.18640350877192982,
            "logloss": 3.140615819909319,
            "mae": 0.41175396800888936,
            "precision": 0.6073903002309469,
            "recall": 0.5456431535269709
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7295424014513378,
            "auditor_fn_violation": 0.005365216097043677,
            "auditor_fp_violation": 0.01654293637120589,
            "ave_precision_score": 0.7197703323221963,
            "fpr": 0.16465422612513722,
            "logloss": 2.567903254477214,
            "mae": 0.380088649221783,
            "precision": 0.6437054631828979,
            "recall": 0.5741525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6651018149760757,
            "auditor_fn_violation": 0.0034760136856664486,
            "auditor_fp_violation": 0.006966544267645869,
            "ave_precision_score": 0.6667685873931523,
            "fpr": 0.4298245614035088,
            "logloss": 0.6605029615058393,
            "mae": 0.46560271316322316,
            "precision": 0.5425904317386231,
            "recall": 0.9647302904564315
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6844381645044744,
            "auditor_fn_violation": 0.004855904295893877,
            "auditor_fp_violation": 0.007791382970477274,
            "ave_precision_score": 0.6848995016414712,
            "fpr": 0.42590559824368823,
            "logloss": 0.6547373007845705,
            "mae": 0.4638370764242438,
            "precision": 0.5369928400954654,
            "recall": 0.9533898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7319231624592508,
            "auditor_fn_violation": 0.01215694838756644,
            "auditor_fp_violation": 0.005360057119543043,
            "ave_precision_score": 0.7322870698042138,
            "fpr": 0.02631578947368421,
            "logloss": 2.33691343778451,
            "mae": 0.4140604041434868,
            "precision": 0.8333333333333334,
            "recall": 0.24896265560165975
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7201057461475502,
            "auditor_fn_violation": 0.0018860816015181725,
            "auditor_fp_violation": 0.002310410097792358,
            "ave_precision_score": 0.720541352313673,
            "fpr": 0.04061470911086718,
            "logloss": 1.9804997200026344,
            "mae": 0.4032901061112529,
            "precision": 0.7357142857142858,
            "recall": 0.21822033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7811983556958766,
            "auditor_fn_violation": 0.021900251146538565,
            "auditor_fp_violation": 0.008914728682170544,
            "ave_precision_score": 0.7420723801320064,
            "fpr": 0.03399122807017544,
            "logloss": 1.6892327151013002,
            "mae": 0.40619331000274733,
            "precision": 0.8675213675213675,
            "recall": 0.4211618257261411
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7826852699850586,
            "auditor_fn_violation": 0.0031488957934101133,
            "auditor_fp_violation": 0.00901660044657927,
            "ave_precision_score": 0.740810641858848,
            "fpr": 0.038419319429198684,
            "logloss": 1.7727150894150845,
            "mae": 0.41274793444428304,
            "precision": 0.8464912280701754,
            "recall": 0.4088983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8063588084498675,
            "auditor_fn_violation": 0.01620850622406639,
            "auditor_fp_violation": 0.015146878824969403,
            "ave_precision_score": 0.8068153409175001,
            "fpr": 0.13706140350877194,
            "logloss": 1.1297539791085358,
            "mae": 0.28760802504320687,
            "precision": 0.7438524590163934,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8307452388007173,
            "auditor_fn_violation": 0.007395486427654473,
            "auditor_fp_violation": 0.02568205856539536,
            "ave_precision_score": 0.8311794469403703,
            "fpr": 0.13172338090010977,
            "logloss": 0.8959813500377051,
            "mae": 0.2606572501910783,
            "precision": 0.7515527950310559,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7712732738931187,
            "auditor_fn_violation": 0.018012484530829154,
            "auditor_fp_violation": 0.016518767849857202,
            "ave_precision_score": 0.7293595714497437,
            "fpr": 0.15021929824561403,
            "logloss": 4.970817168966755,
            "mae": 0.3171395217534042,
            "precision": 0.7085106382978723,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7869897546961279,
            "auditor_fn_violation": 0.011293233362481163,
            "auditor_fp_violation": 0.022714031740633966,
            "ave_precision_score": 0.747572050832698,
            "fpr": 0.14928649835345773,
            "logloss": 4.333785307697921,
            "mae": 0.3039852498900426,
            "precision": 0.711864406779661,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7076508699133727,
            "auditor_fn_violation": 0.004995632234112263,
            "auditor_fp_violation": 0.001356589147286822,
            "ave_precision_score": 0.5380541602970081,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6923376254476502,
            "mae": 0.4949769616257726,
            "precision": 0.875,
            "recall": 0.029045643153526972
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.7677340508660625,
            "auditor_fn_violation": 0.002160505311726731,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5354681017321252,
            "fpr": 0.0,
            "logloss": 0.6829386447021274,
            "mae": 0.49181971873200686,
            "precision": 1.0,
            "recall": 0.036016949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7289543447137898,
            "auditor_fn_violation": 0.005496105408750088,
            "auditor_fp_violation": 0.0006757445940432479,
            "ave_precision_score": 0.5597989614423333,
            "fpr": 0.005482456140350877,
            "logloss": 0.6789264914478323,
            "mae": 0.4861913806709804,
            "precision": 0.8888888888888888,
            "recall": 0.08298755186721991
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7283864583527134,
            "auditor_fn_violation": 0.011209510874620932,
            "auditor_fp_violation": 0.0016202876010491865,
            "ave_precision_score": 0.5491457980613592,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6782685984697533,
            "mae": 0.4863313672375077,
            "precision": 0.9,
            "recall": 0.07627118644067797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6673366023764292,
            "auditor_fn_violation": 0.015109740117929678,
            "auditor_fp_violation": 0.01554467564259486,
            "ave_precision_score": 0.66794961629333,
            "fpr": 0.09539473684210527,
            "logloss": 4.948065152114344,
            "mae": 0.4684047296121291,
            "precision": 0.6297872340425532,
            "recall": 0.3070539419087137
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6797320522824073,
            "auditor_fn_violation": 0.014916556587099304,
            "auditor_fp_violation": 0.02008106438892903,
            "ave_precision_score": 0.6803149930333192,
            "fpr": 0.09659714599341383,
            "logloss": 4.515723037748985,
            "mae": 0.4580197706305456,
            "precision": 0.6239316239316239,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.557574981676782,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.5586648147243782,
            "fpr": 0.45614035087719296,
            "logloss": 1.6783261772113967,
            "mae": 0.467654719033785,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.557064469203018,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5580057144914825,
            "fpr": 0.4654226125137212,
            "logloss": 1.7037541543862582,
            "mae": 0.47674226073873294,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7727728667088913,
            "auditor_fn_violation": 0.013166994249108247,
            "auditor_fp_violation": 0.0023765809873521012,
            "ave_precision_score": 0.6332582302833669,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6642522708381049,
            "mae": 0.4723749021885165,
            "precision": 0.9384615384615385,
            "recall": 0.12655601659751037
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7931679312024544,
            "auditor_fn_violation": 0.0019023609741576732,
            "auditor_fp_violation": 0.0010201810821420802,
            "ave_precision_score": 0.6424403163634697,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6596515359519717,
            "mae": 0.4716813241414783,
            "precision": 0.9666666666666667,
            "recall": 0.1228813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7697035384411083,
            "auditor_fn_violation": 0.018012484530829154,
            "auditor_fp_violation": 0.016518767849857202,
            "ave_precision_score": 0.7285534481666915,
            "fpr": 0.15021929824561403,
            "logloss": 5.020982147090486,
            "mae": 0.31759336622891216,
            "precision": 0.7085106382978723,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7846711999356302,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.024569361061588434,
            "ave_precision_score": 0.7460777672809635,
            "fpr": 0.14928649835345773,
            "logloss": 4.376900297313089,
            "mae": 0.3064062346956956,
            "precision": 0.7112526539278131,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7697472707080251,
            "auditor_fn_violation": 0.018012484530829154,
            "auditor_fp_violation": 0.01761525907792738,
            "ave_precision_score": 0.7286237522819095,
            "fpr": 0.15021929824561403,
            "logloss": 4.985623369395253,
            "mae": 0.3174810778202863,
            "precision": 0.7085106382978723,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7841603628791332,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.024569361061588434,
            "ave_precision_score": 0.7455140639293091,
            "fpr": 0.14928649835345773,
            "logloss": 4.349307937400168,
            "mae": 0.3061319451902651,
            "precision": 0.7112526539278131,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7701162462488821,
            "auditor_fn_violation": 0.018012484530829154,
            "auditor_fp_violation": 0.02143002855977152,
            "ave_precision_score": 0.7288833204831243,
            "fpr": 0.1513157894736842,
            "logloss": 5.016376140996169,
            "mae": 0.3175904147672136,
            "precision": 0.7070063694267515,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7842918392634937,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.024569361061588434,
            "ave_precision_score": 0.745684125845938,
            "fpr": 0.14928649835345773,
            "logloss": 4.373713070014322,
            "mae": 0.3062626489180569,
            "precision": 0.7112526539278131,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6777471841145679,
            "auditor_fn_violation": 0.004542931498871696,
            "auditor_fp_violation": 0.001356589147286822,
            "ave_precision_score": 0.5339176047436585,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6936381300682285,
            "mae": 0.4967048295626515,
            "precision": 0.8181818181818182,
            "recall": 0.01867219917012448
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.7646712031851755,
            "auditor_fn_violation": 0.0031023833001544323,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.529342406370351,
            "fpr": 0.0,
            "logloss": 0.6854980644592763,
            "mae": 0.4944322643112534,
            "precision": 1.0,
            "recall": 0.023305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0.7110365818884087,
            "auditor_fn_violation": 0.004886438086918545,
            "auditor_fp_violation": 0.001356589147286822,
            "ave_precision_score": 0.5383223039458989,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6919409561165697,
            "mae": 0.4946024694659731,
            "precision": 0.8823529411764706,
            "recall": 0.03112033195020747
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.7677340508660625,
            "auditor_fn_violation": 0.002160505311726731,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5354681017321252,
            "fpr": 0.0,
            "logloss": 0.6831773057916124,
            "mae": 0.491851412176955,
            "precision": 1.0,
            "recall": 0.036016949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 22727,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7134839711325375,
            "auditor_fn_violation": 0.019195421125427683,
            "auditor_fp_violation": 0.015070379436964512,
            "ave_precision_score": 0.7090621579738738,
            "fpr": 0.19188596491228072,
            "logloss": 2.8883903325208298,
            "mae": 0.3976740706059726,
            "precision": 0.6111111111111112,
            "recall": 0.5705394190871369
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.727014346918956,
            "auditor_fn_violation": 0.006837336508586209,
            "auditor_fp_violation": 0.019005873542553814,
            "ave_precision_score": 0.7240381560818228,
            "fpr": 0.17233809001097694,
            "logloss": 2.367122405057718,
            "mae": 0.3636037211314307,
            "precision": 0.6463963963963963,
            "recall": 0.6080508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6651805619237039,
            "auditor_fn_violation": 0.002766251728907331,
            "auditor_fp_violation": 0.006219400244798055,
            "ave_precision_score": 0.6657690759146808,
            "fpr": 0.4309210526315789,
            "logloss": 0.6589334848502113,
            "mae": 0.46623162529839757,
            "precision": 0.5414235705950992,
            "recall": 0.9626556016597511
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6826884946421661,
            "auditor_fn_violation": 0.006083834117844053,
            "auditor_fp_violation": 0.007791382970477274,
            "ave_precision_score": 0.6831569733824958,
            "fpr": 0.42590559824368823,
            "logloss": 0.6574873141581802,
            "mae": 0.46541366360582714,
            "precision": 0.5358851674641149,
            "recall": 0.9491525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6674242815360351,
            "auditor_fn_violation": 0.015109740117929678,
            "auditor_fp_violation": 0.01554467564259486,
            "ave_precision_score": 0.6680371624804544,
            "fpr": 0.09539473684210527,
            "logloss": 4.95928408040696,
            "mae": 0.46840527815998123,
            "precision": 0.6297872340425532,
            "recall": 0.3070539419087137
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6797539777047389,
            "auditor_fn_violation": 0.014916556587099304,
            "auditor_fp_violation": 0.02008106438892903,
            "ave_precision_score": 0.6803369284477893,
            "fpr": 0.09659714599341383,
            "logloss": 4.528985743899837,
            "mae": 0.45802656038882716,
            "precision": 0.6239316239316239,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7527149096217997,
            "auditor_fn_violation": 0.012156948387566426,
            "auditor_fp_violation": 0.003238474092207262,
            "ave_precision_score": 0.7001198422821665,
            "fpr": 0.01425438596491228,
            "logloss": 2.338759053211457,
            "mae": 0.41365696449913575,
            "precision": 0.8907563025210085,
            "recall": 0.21991701244813278
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7479677445441284,
            "auditor_fn_violation": 0.006865244004539639,
            "auditor_fp_violation": 0.0030530419149399027,
            "ave_precision_score": 0.7080416409912462,
            "fpr": 0.015367727771679473,
            "logloss": 1.9836029119874743,
            "mae": 0.3998098064750915,
            "precision": 0.8640776699029126,
            "recall": 0.1885593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.769049143465706,
            "auditor_fn_violation": 0.01734367037926767,
            "auditor_fp_violation": 0.02143002855977152,
            "ave_precision_score": 0.7168043785020489,
            "fpr": 0.1513157894736842,
            "logloss": 5.866948609605595,
            "mae": 0.319075718228942,
            "precision": 0.7088607594936709,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.781783229928343,
            "auditor_fn_violation": 0.008081545703175872,
            "auditor_fp_violation": 0.023926746997592074,
            "ave_precision_score": 0.7295627293654948,
            "fpr": 0.150384193194292,
            "logloss": 5.257563591443498,
            "mae": 0.30847415703186165,
            "precision": 0.7109704641350211,
            "recall": 0.7139830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5614572906009536,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.555834331881314,
            "fpr": 0.45614035087719296,
            "logloss": 0.6930477810461885,
            "mae": 0.49053573180316834,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5641418975011673,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5576753583241834,
            "fpr": 0.4654226125137212,
            "logloss": 0.6885071451864905,
            "mae": 0.49086263995008333,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.782285888562193,
            "auditor_fn_violation": 0.011745195457523476,
            "auditor_fp_violation": 0.01857405140758874,
            "ave_precision_score": 0.7831440906778719,
            "fpr": 0.17324561403508773,
            "logloss": 0.6124476427528961,
            "mae": 0.34619115006685125,
            "precision": 0.7013232514177694,
            "recall": 0.7697095435684648
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8008229599682539,
            "auditor_fn_violation": 0.007867588234199712,
            "auditor_fp_violation": 0.018370760810043782,
            "ave_precision_score": 0.8014271794548444,
            "fpr": 0.1690450054884742,
            "logloss": 0.5994446600248209,
            "mae": 0.3445955700109152,
            "precision": 0.7032755298651252,
            "recall": 0.7733050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 22727,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5498737298234131,
            "auditor_fn_violation": 0.006367383708233234,
            "auditor_fp_violation": 0.007728988168094655,
            "ave_precision_score": 0.5510031847459521,
            "fpr": 0.08662280701754387,
            "logloss": 0.6930843903503362,
            "mae": 0.49590187219151277,
            "precision": 0.5659340659340659,
            "recall": 0.21369294605809128
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.567741225757757,
            "auditor_fn_violation": 0.006995478985655565,
            "auditor_fp_violation": 0.010461856979613883,
            "ave_precision_score": 0.5685669401577795,
            "fpr": 0.09440175631174534,
            "logloss": 0.6846068211046888,
            "mae": 0.4939561542184895,
            "precision": 0.5376344086021505,
            "recall": 0.211864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7928724128516482,
            "auditor_fn_violation": 0.019250018199024537,
            "auditor_fp_violation": 0.01790085679314566,
            "ave_precision_score": 0.7902902060548312,
            "fpr": 0.08771929824561403,
            "logloss": 0.6037674176092933,
            "mae": 0.4111241966306248,
            "precision": 0.7714285714285715,
            "recall": 0.5601659751037344
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.776591984078651,
            "auditor_fn_violation": 0.00550707920147352,
            "auditor_fp_violation": 0.016918002945522835,
            "ave_precision_score": 0.7748016459337312,
            "fpr": 0.09001097694840834,
            "logloss": 0.6104686048462028,
            "mae": 0.41501179127315,
            "precision": 0.760932944606414,
            "recall": 0.5529661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.6316106644602348,
            "auditor_fn_violation": 0.005191271747834321,
            "auditor_fp_violation": 0.0005813953488372093,
            "ave_precision_score": 0.5587269142222933,
            "fpr": 0.0010964912280701754,
            "logloss": 8.716337562990194,
            "mae": 0.5098995199891025,
            "precision": 0.9444444444444444,
            "recall": 0.035269709543568464
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6370108506262513,
            "auditor_fn_violation": 0.001260488567229148,
            "auditor_fp_violation": 0.0005225927602149382,
            "ave_precision_score": 0.5631373276764832,
            "fpr": 0.0010976948408342481,
            "logloss": 8.371624485198273,
            "mae": 0.4969217041135583,
            "precision": 0.9444444444444444,
            "recall": 0.036016949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5399886231652782,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.5411456668398835,
            "fpr": 0.45614035087719296,
            "logloss": 0.6940214683242605,
            "mae": 0.4910301269081078,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5561511405380143,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5569900592053019,
            "fpr": 0.4654226125137212,
            "logloss": 0.6882296511047545,
            "mae": 0.49071187176767217,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7642667413767449,
            "auditor_fn_violation": 0.01922726941835918,
            "auditor_fp_violation": 0.016870665034679728,
            "ave_precision_score": 0.7125955322568557,
            "fpr": 0.1513157894736842,
            "logloss": 5.578708272332173,
            "mae": 0.3175450409975607,
            "precision": 0.7076271186440678,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7772367068194852,
            "auditor_fn_violation": 0.00909784368081267,
            "auditor_fp_violation": 0.024921923641446363,
            "ave_precision_score": 0.7268129521276138,
            "fpr": 0.15477497255762898,
            "logloss": 4.929199110739736,
            "mae": 0.3093908548129178,
            "precision": 0.7044025157232704,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6668920770882742,
            "auditor_fn_violation": 0.03152981000218389,
            "auditor_fp_violation": 0.027585679314565483,
            "ave_precision_score": 0.6684229116731916,
            "fpr": 0.11293859649122807,
            "logloss": 0.6708095492612517,
            "mae": 0.4579816139956707,
            "precision": 0.6589403973509934,
            "recall": 0.41286307053941906
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.663310038880101,
            "auditor_fn_violation": 0.033398295782247116,
            "auditor_fp_violation": 0.016405411960623017,
            "ave_precision_score": 0.6644507716745187,
            "fpr": 0.10867178924259056,
            "logloss": 0.669466838972218,
            "mae": 0.45369435783013556,
            "precision": 0.6847133757961783,
            "recall": 0.4555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5402143365081928,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.5413707792005324,
            "fpr": 0.45614035087719296,
            "logloss": 0.6941782403699326,
            "mae": 0.4910162695471132,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5561890480427039,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5570843655434314,
            "fpr": 0.4654226125137212,
            "logloss": 0.6881949662194494,
            "mae": 0.4906948737464804,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8071695451914878,
            "auditor_fn_violation": 0.0167704011065007,
            "auditor_fp_violation": 0.01468788249694003,
            "ave_precision_score": 0.8079591021591586,
            "fpr": 0.13706140350877194,
            "logloss": 1.042190948033037,
            "mae": 0.2923377433600553,
            "precision": 0.7412008281573499,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8337585684542934,
            "auditor_fn_violation": 0.006609425291633334,
            "auditor_fp_violation": 0.024681881033883517,
            "ave_precision_score": 0.8341428679444605,
            "fpr": 0.13062568605927552,
            "logloss": 0.8297643610790579,
            "mae": 0.25875913733432104,
            "precision": 0.7541322314049587,
            "recall": 0.7733050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7445554806193423,
            "auditor_fn_violation": 0.0008348802504185834,
            "auditor_fp_violation": 0.000420746634026928,
            "ave_precision_score": 0.5723819255012069,
            "fpr": 0.005482456140350877,
            "logloss": 0.6678541451791251,
            "mae": 0.4774039947150046,
            "precision": 0.9137931034482759,
            "recall": 0.10995850622406639
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.7087942092472453,
            "auditor_fn_violation": 0.003109360174142774,
            "auditor_fp_violation": 0.003663150209162127,
            "ave_precision_score": 0.5541410248264382,
            "fpr": 0.008781558726673985,
            "logloss": 0.6781675021387422,
            "mae": 0.4820098201739147,
            "precision": 0.8490566037735849,
            "recall": 0.09533898305084745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6890367590231591,
            "auditor_fn_violation": 0.001774404891897811,
            "auditor_fp_violation": 0.0003059975520195843,
            "ave_precision_score": 0.5607010734716423,
            "fpr": 0.013157894736842105,
            "logloss": 0.6855903452826724,
            "mae": 0.482334440508694,
            "precision": 0.8032786885245902,
            "recall": 0.1016597510373444
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6867261899224703,
            "auditor_fn_violation": 0.0005976855383356109,
            "auditor_fp_violation": 0.0035006213602914514,
            "ave_precision_score": 0.5511536510313813,
            "fpr": 0.012074643249176729,
            "logloss": 0.6851494156242559,
            "mae": 0.4833104515245796,
            "precision": 0.8035714285714286,
            "recall": 0.09533898305084745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6777471841145679,
            "auditor_fn_violation": 0.004542931498871696,
            "auditor_fp_violation": 0.001356589147286822,
            "ave_precision_score": 0.5339176047436585,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6943694650234555,
            "mae": 0.4970433634558791,
            "precision": 0.8181818181818182,
            "recall": 0.01867219917012448
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.7646712031851755,
            "auditor_fn_violation": 0.0019791065880295643,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.529342406370351,
            "fpr": 0.0,
            "logloss": 0.6860910815053183,
            "mae": 0.49461571301377566,
            "precision": 1.0,
            "recall": 0.023305084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7702225712597978,
            "auditor_fn_violation": 0.01815352697095436,
            "auditor_fp_violation": 0.016126070991432068,
            "ave_precision_score": 0.729055948061111,
            "fpr": 0.14912280701754385,
            "logloss": 5.004916397010063,
            "mae": 0.31739532910975093,
            "precision": 0.7094017094017094,
            "recall": 0.6887966804979253
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7846315566654929,
            "auditor_fn_violation": 0.0088699324638598,
            "auditor_fp_violation": 0.024114280284750548,
            "ave_precision_score": 0.7459586314469118,
            "fpr": 0.14818880351262348,
            "logloss": 4.36822496657144,
            "mae": 0.30627570185140723,
            "precision": 0.7127659574468085,
            "recall": 0.7097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8049780762568061,
            "auditor_fn_violation": 0.011642825944529379,
            "auditor_fp_violation": 0.014432884536923705,
            "ave_precision_score": 0.8053114831695809,
            "fpr": 0.16337719298245615,
            "logloss": 0.6054547222418419,
            "mae": 0.34222471150324535,
            "precision": 0.7072691552062869,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7973921116164948,
            "auditor_fn_violation": 0.006134997860425313,
            "auditor_fp_violation": 0.012469713374123911,
            "ave_precision_score": 0.797900307163523,
            "fpr": 0.16575192096597147,
            "logloss": 0.6085451398686225,
            "mae": 0.34281058787367213,
            "precision": 0.7033398821218074,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7026705018650167,
            "auditor_fn_violation": 0.01609703719880616,
            "auditor_fp_violation": 0.015452876376988986,
            "ave_precision_score": 0.6913615553936361,
            "fpr": 0.18311403508771928,
            "logloss": 3.175164847777996,
            "mae": 0.41505008517936404,
            "precision": 0.6116279069767442,
            "recall": 0.5456431535269709
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7206381595282755,
            "auditor_fn_violation": 0.005365216097043677,
            "auditor_fp_violation": 0.018043202668473663,
            "ave_precision_score": 0.7130449397541386,
            "fpr": 0.16245883644346873,
            "logloss": 2.5914571678578344,
            "mae": 0.3830187646537124,
            "precision": 0.6467780429594272,
            "recall": 0.5741525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6402079469464059,
            "auditor_fn_violation": 0.02279427822668707,
            "auditor_fp_violation": 0.008807629538963687,
            "ave_precision_score": 0.6417501995677225,
            "fpr": 0.02850877192982456,
            "logloss": 4.0284692866193685,
            "mae": 0.48141635737513006,
            "precision": 0.7833333333333333,
            "recall": 0.1950207468879668
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6559754983988231,
            "auditor_fn_violation": 0.01663984446222254,
            "auditor_fp_violation": 0.004743341943194918,
            "ave_precision_score": 0.6568059647845887,
            "fpr": 0.024149286498353458,
            "logloss": 3.842368327449444,
            "mae": 0.46573701206977064,
            "precision": 0.8181818181818182,
            "recall": 0.2097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6664561752756144,
            "auditor_fn_violation": 0.015109740117929678,
            "auditor_fp_violation": 0.01453488372093023,
            "ave_precision_score": 0.6670697883686466,
            "fpr": 0.09100877192982457,
            "logloss": 5.234152434253827,
            "mae": 0.46879492032113473,
            "precision": 0.6406926406926406,
            "recall": 0.3070539419087137
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6779302281630328,
            "auditor_fn_violation": 0.014916556587099304,
            "auditor_fp_violation": 0.018983369548094788,
            "ave_precision_score": 0.6785194034218208,
            "fpr": 0.09659714599341383,
            "logloss": 4.793498833028489,
            "mae": 0.4589494276445348,
            "precision": 0.6239316239316239,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8171674695436956,
            "auditor_fn_violation": 0.016486041348183735,
            "auditor_fp_violation": 0.015835373317013464,
            "ave_precision_score": 0.8176174515271564,
            "fpr": 0.1425438596491228,
            "logloss": 1.0392024156459927,
            "mae": 0.2876973169383034,
            "precision": 0.7373737373737373,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8410582864763889,
            "auditor_fn_violation": 0.004925673035777417,
            "auditor_fp_violation": 0.025194472018783335,
            "ave_precision_score": 0.8414286831335747,
            "fpr": 0.132821075740944,
            "logloss": 0.8223943992015016,
            "mae": 0.2578842740771024,
            "precision": 0.7540650406504065,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7748669608728274,
            "auditor_fn_violation": 0.01549646938924076,
            "auditor_fp_violation": 0.003748470012239902,
            "ave_precision_score": 0.7209002068898557,
            "fpr": 0.013157894736842105,
            "logloss": 0.7980454285230076,
            "mae": 0.40728663078041055,
            "precision": 0.9117647058823529,
            "recall": 0.2572614107883817
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.755074811233636,
            "auditor_fn_violation": 0.00046279930789410584,
            "auditor_fp_violation": 0.0024904420534644896,
            "ave_precision_score": 0.7137740348920045,
            "fpr": 0.01646542261251372,
            "logloss": 0.791336860242554,
            "mae": 0.40386725683484054,
            "precision": 0.8706896551724138,
            "recall": 0.21398305084745764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7693441957487465,
            "auditor_fn_violation": 0.01498917158040329,
            "auditor_fp_violation": 0.01788810689514485,
            "ave_precision_score": 0.7068358068816456,
            "fpr": 0.1699561403508772,
            "logloss": 6.818866640735969,
            "mae": 0.3229521127752603,
            "precision": 0.6875,
            "recall": 0.7074688796680498
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7845484986662024,
            "auditor_fn_violation": 0.007009432733632253,
            "auditor_fp_violation": 0.028147496180572062,
            "ave_precision_score": 0.7239705101764797,
            "fpr": 0.17453347969264543,
            "logloss": 6.104231045878195,
            "mae": 0.3155732186077098,
            "precision": 0.682,
            "recall": 0.722457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5315987792553154,
            "auditor_fn_violation": 0.0035897575889932403,
            "auditor_fp_violation": 0.0011423908608731129,
            "ave_precision_score": 0.5373588928490519,
            "fpr": 0.006578947368421052,
            "logloss": 0.6944123286842545,
            "mae": 0.5004966321417637,
            "precision": 0.5,
            "recall": 0.012448132780082987
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5274278291225096,
            "auditor_fn_violation": 0.0021023646951571183,
            "auditor_fp_violation": 0.001565277836816035,
            "ave_precision_score": 0.5335472132036023,
            "fpr": 0.005488474204171241,
            "logloss": 0.693207234612508,
            "mae": 0.4998854503738893,
            "precision": 0.7058823529411765,
            "recall": 0.025423728813559324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 22727,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7876766032543508,
            "auditor_fn_violation": 0.01859485331586227,
            "auditor_fp_violation": 0.018446552427580584,
            "ave_precision_score": 0.7413395671606822,
            "fpr": 0.14473684210526316,
            "logloss": 3.5344165132037726,
            "mae": 0.30277222563012735,
            "precision": 0.7238493723849372,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8043198138562975,
            "auditor_fn_violation": 0.012707213157454093,
            "auditor_fp_violation": 0.02925519279672142,
            "ave_precision_score": 0.7601621475258838,
            "fpr": 0.145993413830955,
            "logloss": 3.0739793098708645,
            "mae": 0.2862629230966777,
            "precision": 0.7263374485596708,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5177421218258198,
            "auditor_fn_violation": 0.0069520273713329145,
            "auditor_fp_violation": 0.013685740514075902,
            "ave_precision_score": 0.5195947034353833,
            "fpr": 0.1787280701754386,
            "logloss": 0.693191853546432,
            "mae": 0.49986244460339085,
            "precision": 0.5177514792899408,
            "recall": 0.3630705394190871
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5258235091312897,
            "auditor_fn_violation": 0.014530502893077078,
            "auditor_fp_violation": 0.011009454178116619,
            "ave_precision_score": 0.5278852551699942,
            "fpr": 0.18221734357848518,
            "logloss": 0.691980932081329,
            "mae": 0.49927761643699703,
            "precision": 0.5029940119760479,
            "recall": 0.3559322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6503849091040979,
            "auditor_fn_violation": 0.023030865545606773,
            "auditor_fp_violation": 0.011627906976744186,
            "ave_precision_score": 0.6455669112243598,
            "fpr": 0.12938596491228072,
            "logloss": 2.9536084827142695,
            "mae": 0.45219029660425086,
            "precision": 0.6118421052631579,
            "recall": 0.38589211618257263
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.666516068698122,
            "auditor_fn_violation": 0.004311708124802333,
            "auditor_fp_violation": 0.013532402001355248,
            "ave_precision_score": 0.6633790662132776,
            "fpr": 0.12184412733260154,
            "logloss": 2.474120483858233,
            "mae": 0.4293248617996161,
            "precision": 0.6198630136986302,
            "recall": 0.3834745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8034842306798026,
            "auditor_fn_violation": 0.014511447186430807,
            "auditor_fp_violation": 0.020450836393308868,
            "ave_precision_score": 0.8047735179590856,
            "fpr": 0.19736842105263158,
            "logloss": 1.0645317202518791,
            "mae": 0.3010662172956882,
            "precision": 0.6836555360281195,
            "recall": 0.8070539419087137
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8317537732224414,
            "auditor_fn_violation": 0.004279149379523342,
            "auditor_fp_violation": 0.024676880146225957,
            "ave_precision_score": 0.8320140307790098,
            "fpr": 0.18990120746432493,
            "logloss": 0.9049062967532902,
            "mae": 0.27828271550599964,
            "precision": 0.6970227670753065,
            "recall": 0.8432203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 22727,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.7271834279682609,
            "auditor_fn_violation": 0.0031438814879522583,
            "auditor_fp_violation": 0.0005558955528355773,
            "ave_precision_score": 0.5494567591177113,
            "fpr": 0.003289473684210526,
            "logloss": 0.6859450314726191,
            "mae": 0.48862050637079957,
            "precision": 0.9,
            "recall": 0.056016597510373446
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7589424824495841,
            "auditor_fn_violation": 0.00867225436752312,
            "auditor_fp_violation": 0.0005801029682768691,
            "ave_precision_score": 0.5475714463202893,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6756183474629008,
            "mae": 0.4848088887075431,
            "precision": 0.96875,
            "recall": 0.06567796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8080455563278685,
            "auditor_fn_violation": 0.018096655019290964,
            "auditor_fp_violation": 0.014835781313749501,
            "ave_precision_score": 0.8092036960051497,
            "fpr": 0.1524122807017544,
            "logloss": 1.0695403579527842,
            "mae": 0.2864881769070259,
            "precision": 0.7263779527559056,
            "recall": 0.7655601659751037
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8365218336686199,
            "auditor_fn_violation": 0.0047303205641035205,
            "auditor_fp_violation": 0.026737245861140357,
            "ave_precision_score": 0.836759213392286,
            "fpr": 0.141602634467618,
            "logloss": 0.8391847083121332,
            "mae": 0.2550303647767921,
            "precision": 0.7430278884462151,
            "recall": 0.7902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7677800021003663,
            "auditor_fn_violation": 0.017370968916066105,
            "auditor_fp_violation": 0.02143002855977152,
            "ave_precision_score": 0.7270598245080546,
            "fpr": 0.1513157894736842,
            "logloss": 4.944598812286512,
            "mae": 0.31736483633130846,
            "precision": 0.7076271186440678,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7846063747998834,
            "auditor_fn_violation": 0.012300228841466818,
            "auditor_fp_violation": 0.02310160053409481,
            "ave_precision_score": 0.7474468658753429,
            "fpr": 0.150384193194292,
            "logloss": 4.281508886788991,
            "mae": 0.3068913496566729,
            "precision": 0.7085106382978723,
            "recall": 0.7055084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5614572906009536,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.555834331881314,
            "fpr": 0.45614035087719296,
            "logloss": 0.6932090481525998,
            "mae": 0.4905264734764371,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5641418975011673,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5576753583241834,
            "fpr": 0.4654226125137212,
            "logloss": 0.6884753772408398,
            "mae": 0.4908485432553108,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8036621838705359,
            "auditor_fn_violation": 0.014511447186430807,
            "auditor_fp_violation": 0.020450836393308868,
            "ave_precision_score": 0.8056281157607087,
            "fpr": 0.19736842105263158,
            "logloss": 1.0580546661940005,
            "mae": 0.30106859038699707,
            "precision": 0.6836555360281195,
            "recall": 0.8070539419087137
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8323501640757194,
            "auditor_fn_violation": 0.004279149379523342,
            "auditor_fp_violation": 0.024676880146225957,
            "ave_precision_score": 0.8326079028442087,
            "fpr": 0.18990120746432493,
            "logloss": 0.9001242452562378,
            "mae": 0.2783250073613018,
            "precision": 0.6970227670753065,
            "recall": 0.8432203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.7037442679803368,
            "auditor_fn_violation": 0.017719025260246067,
            "auditor_fp_violation": 0.011531007751937985,
            "ave_precision_score": 0.7017795942938744,
            "fpr": 0.07456140350877193,
            "logloss": 0.754004129898066,
            "mae": 0.4358754391815685,
            "precision": 0.7433962264150943,
            "recall": 0.4087136929460581
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7024617096494518,
            "auditor_fn_violation": 0.00811177882379207,
            "auditor_fp_violation": 0.016070352487566546,
            "ave_precision_score": 0.7024278065193933,
            "fpr": 0.07793633369923161,
            "logloss": 0.7572297461619034,
            "mae": 0.4326094557801328,
            "precision": 0.7380073800738007,
            "recall": 0.423728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6717406033248547,
            "auditor_fn_violation": 0.0012693819611268838,
            "auditor_fp_violation": 0.011893104855161176,
            "ave_precision_score": 0.6732766338938522,
            "fpr": 0.4144736842105263,
            "logloss": 0.7536013255628456,
            "mae": 0.4539066461944266,
            "precision": 0.5510688836104513,
            "recall": 0.9626556016597511
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6640115679050301,
            "auditor_fn_violation": 0.002662840238888166,
            "auditor_fp_violation": 0.014417559116743242,
            "ave_precision_score": 0.66521245032925,
            "fpr": 0.407244785949506,
            "logloss": 0.7578909081836415,
            "mae": 0.4520598224207808,
            "precision": 0.5475609756097561,
            "recall": 0.951271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7685035261931714,
            "auditor_fn_violation": 0.016247179151197493,
            "auditor_fp_violation": 0.020338637290901677,
            "ave_precision_score": 0.708165609606105,
            "fpr": 0.15460526315789475,
            "logloss": 6.6287336016840595,
            "mae": 0.3204831485439576,
            "precision": 0.7044025157232704,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7827038989149545,
            "auditor_fn_violation": 0.007572233902026089,
            "auditor_fp_violation": 0.023099100090266025,
            "ave_precision_score": 0.7231077835373544,
            "fpr": 0.1525795828759605,
            "logloss": 5.955100731088812,
            "mae": 0.311847546895017,
            "precision": 0.7073684210526315,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7115883477370477,
            "auditor_fn_violation": 0.019195421125427683,
            "auditor_fp_violation": 0.014432884536923714,
            "ave_precision_score": 0.7019774378879999,
            "fpr": 0.19078947368421054,
            "logloss": 2.8709066677040456,
            "mae": 0.3987663745856043,
            "precision": 0.6124721603563474,
            "recall": 0.5705394190871369
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7245723407097473,
            "auditor_fn_violation": 0.004986139277009812,
            "auditor_fp_violation": 0.019005873542553814,
            "ave_precision_score": 0.7181033591726664,
            "fpr": 0.17233809001097694,
            "logloss": 2.353634820994766,
            "mae": 0.36520409481752303,
            "precision": 0.6455981941309256,
            "recall": 0.6059322033898306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7289543447137898,
            "auditor_fn_violation": 0.005496105408750088,
            "auditor_fp_violation": 0.0006757445940432479,
            "ave_precision_score": 0.5597989614423333,
            "fpr": 0.005482456140350877,
            "logloss": 0.6789264914478323,
            "mae": 0.4861913806709804,
            "precision": 0.8888888888888888,
            "recall": 0.08298755186721991
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7283864583527134,
            "auditor_fn_violation": 0.011209510874620932,
            "auditor_fp_violation": 0.0016202876010491865,
            "ave_precision_score": 0.5491457980613592,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6782685984697533,
            "mae": 0.4863313672375077,
            "precision": 0.9,
            "recall": 0.07627118644067797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7683547776167607,
            "auditor_fn_violation": 0.016247179151197493,
            "auditor_fp_violation": 0.020338637290901677,
            "ave_precision_score": 0.7080871712911694,
            "fpr": 0.15460526315789475,
            "logloss": 6.557428376800237,
            "mae": 0.3204077564541004,
            "precision": 0.7044025157232704,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7840325225753023,
            "auditor_fn_violation": 0.007572233902026089,
            "auditor_fp_violation": 0.024574361949245994,
            "ave_precision_score": 0.7250038308113462,
            "fpr": 0.15806805708013172,
            "logloss": 5.873245900384475,
            "mae": 0.31121005997651224,
            "precision": 0.7,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6664853968333512,
            "auditor_fn_violation": 0.015109740117929678,
            "auditor_fp_violation": 0.01453488372093023,
            "ave_precision_score": 0.6670988444495661,
            "fpr": 0.09100877192982457,
            "logloss": 5.238270529267311,
            "mae": 0.4687947680891732,
            "precision": 0.6406926406926406,
            "recall": 0.3070539419087137
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.67788483257952,
            "auditor_fn_violation": 0.014916556587099304,
            "auditor_fp_violation": 0.018983369548094788,
            "ave_precision_score": 0.6784740677138371,
            "fpr": 0.09659714599341383,
            "logloss": 4.79835301656181,
            "mae": 0.4589559604205432,
            "precision": 0.6239316239316239,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 22727,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5917974462325821,
            "auditor_fn_violation": 0.00558255077527845,
            "auditor_fp_violation": 0.0031721746226030224,
            "ave_precision_score": 0.5627388208819514,
            "fpr": 0.08114035087719298,
            "logloss": 7.244428255965269,
            "mae": 0.46710402452510386,
            "precision": 0.6711111111111111,
            "recall": 0.3132780082987552
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6082466957701467,
            "auditor_fn_violation": 0.017232878751232614,
            "auditor_fp_violation": 0.006588669488834272,
            "ave_precision_score": 0.5798907787733971,
            "fpr": 0.06915477497255763,
            "logloss": 6.709574130577104,
            "mae": 0.4479586974860232,
            "precision": 0.7,
            "recall": 0.3114406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.535787113396969,
            "auditor_fn_violation": 0.0035897575889932403,
            "auditor_fp_violation": 0.0011423908608731129,
            "ave_precision_score": 0.5412094913054595,
            "fpr": 0.006578947368421052,
            "logloss": 0.6944066843803138,
            "mae": 0.5004982464015484,
            "precision": 0.5,
            "recall": 0.012448132780082987
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5333482541403297,
            "auditor_fn_violation": 0.0021023646951571183,
            "auditor_fp_violation": 0.001565277836816035,
            "ave_precision_score": 0.539218100316102,
            "fpr": 0.005488474204171241,
            "logloss": 0.6931789231682784,
            "mae": 0.4998740689945535,
            "precision": 0.7058823529411765,
            "recall": 0.025423728813559324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6679138326937903,
            "auditor_fn_violation": 0.015109740117929678,
            "auditor_fp_violation": 0.01554467564259486,
            "ave_precision_score": 0.668524106062353,
            "fpr": 0.09539473684210527,
            "logloss": 4.564654427375884,
            "mae": 0.4687854802961252,
            "precision": 0.6297872340425532,
            "recall": 0.3070539419087137
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6805877228660551,
            "auditor_fn_violation": 0.0144398035312285,
            "auditor_fp_violation": 0.019393442336014644,
            "ave_precision_score": 0.6811645309173429,
            "fpr": 0.09879253567508232,
            "logloss": 4.156828080602442,
            "mae": 0.4578292400510761,
            "precision": 0.620253164556962,
            "recall": 0.3114406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.64036311568845,
            "auditor_fn_violation": 0.02279427822668707,
            "auditor_fp_violation": 0.008807629538963687,
            "ave_precision_score": 0.6419017933202518,
            "fpr": 0.02850877192982456,
            "logloss": 4.024697424332631,
            "mae": 0.481608985369131,
            "precision": 0.7833333333333333,
            "recall": 0.1950207468879668
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.655968454906193,
            "auditor_fn_violation": 0.01663984446222254,
            "auditor_fp_violation": 0.004743341943194918,
            "ave_precision_score": 0.6567955929746259,
            "fpr": 0.024149286498353458,
            "logloss": 3.839647024035509,
            "mae": 0.46605497465153617,
            "precision": 0.8181818181818182,
            "recall": 0.2097457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7927398839610147,
            "auditor_fn_violation": 0.011378940088811249,
            "auditor_fp_violation": 0.012290901672786618,
            "ave_precision_score": 0.7686035588444315,
            "fpr": 0.11513157894736842,
            "logloss": 0.5805832730890137,
            "mae": 0.3885178353572101,
            "precision": 0.7388059701492538,
            "recall": 0.6161825726141079
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7753372629832113,
            "auditor_fn_violation": 0.005014046772963226,
            "auditor_fp_violation": 0.01838826391684524,
            "ave_precision_score": 0.7552760809526354,
            "fpr": 0.1119648737650933,
            "logloss": 0.5848375547605015,
            "mae": 0.38971069222878413,
            "precision": 0.7417721518987341,
            "recall": 0.6207627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7850372541318096,
            "auditor_fn_violation": 0.019413809419815107,
            "auditor_fp_violation": 0.020744084047327624,
            "ave_precision_score": 0.7387018223823225,
            "fpr": 0.14802631578947367,
            "logloss": 3.8704119871088905,
            "mae": 0.30765814707243655,
            "precision": 0.7175732217573222,
            "recall": 0.7116182572614108
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8034414087557046,
            "auditor_fn_violation": 0.01673984632272229,
            "auditor_fp_violation": 0.0306929479982697,
            "ave_precision_score": 0.75928408718884,
            "fpr": 0.14818880351262348,
            "logloss": 3.349300837684241,
            "mae": 0.28859179991273776,
            "precision": 0.7239263803680982,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6618826296568706,
            "auditor_fn_violation": 0.004613452718934267,
            "auditor_fp_violation": 0.006219400244798055,
            "ave_precision_score": 0.6624576213941284,
            "fpr": 0.4309210526315789,
            "logloss": 0.6603896704978199,
            "mae": 0.46687624593706506,
            "precision": 0.5403508771929825,
            "recall": 0.9585062240663901
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.680740462571332,
            "auditor_fn_violation": 0.008381551284675064,
            "auditor_fp_violation": 0.007791382970477274,
            "ave_precision_score": 0.6812205295960477,
            "fpr": 0.42590559824368823,
            "logloss": 0.6587011074767766,
            "mae": 0.46570239373933603,
            "precision": 0.5347721822541966,
            "recall": 0.9449152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.6152589477243684,
            "auditor_fn_violation": 0.012316189852223929,
            "auditor_fp_violation": 0.01035291717666259,
            "ave_precision_score": 0.6107228557618943,
            "fpr": 0.12719298245614036,
            "logloss": 4.404858698761583,
            "mae": 0.5112702560655186,
            "precision": 0.5245901639344263,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6246218672558965,
            "auditor_fn_violation": 0.0007325717687771017,
            "auditor_fp_violation": 0.01662045012989806,
            "ave_precision_score": 0.6229116000250996,
            "fpr": 0.11964873765093303,
            "logloss": 4.063800196811529,
            "mae": 0.4935498376747759,
            "precision": 0.542016806722689,
            "recall": 0.2733050847457627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7850209769433735,
            "auditor_fn_violation": 0.022273331149450404,
            "auditor_fp_violation": 0.007917686658506734,
            "ave_precision_score": 0.7584645589660376,
            "fpr": 0.03399122807017544,
            "logloss": 0.7107704005113654,
            "mae": 0.40939267049952033,
            "precision": 0.8663793103448276,
            "recall": 0.4170124481327801
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7631753941016342,
            "auditor_fn_violation": 0.007935031349420453,
            "auditor_fp_violation": 0.010209312152907142,
            "ave_precision_score": 0.7394048414501216,
            "fpr": 0.04061470911086718,
            "logloss": 0.7206403256348881,
            "mae": 0.41449705942336607,
            "precision": 0.8302752293577982,
            "recall": 0.3834745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8141851409700119,
            "auditor_fn_violation": 0.018476559656402415,
            "auditor_fp_violation": 0.016049571603427175,
            "ave_precision_score": 0.8147063550298569,
            "fpr": 0.14692982456140352,
            "logloss": 0.9979941405137102,
            "mae": 0.2884451840360371,
            "precision": 0.7309236947791165,
            "recall": 0.7551867219917012
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8388605184752993,
            "auditor_fn_violation": 0.005776851662356509,
            "auditor_fp_violation": 0.026077128690342535,
            "ave_precision_score": 0.8392244178046897,
            "fpr": 0.1350164654226125,
            "logloss": 0.7945571981727075,
            "mae": 0.25547493177420705,
            "precision": 0.7515151515151515,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7126675260740956,
            "auditor_fn_violation": 0.007363780301375858,
            "auditor_fp_violation": 0.009399224806201551,
            "ave_precision_score": 0.712134274741977,
            "fpr": 0.08333333333333333,
            "logloss": 4.512938798634026,
            "mae": 0.4086423791411548,
            "precision": 0.7132075471698113,
            "recall": 0.3921161825726141
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7166754554746324,
            "auditor_fn_violation": 0.01394677110271821,
            "auditor_fp_violation": 0.017478102363169462,
            "ave_precision_score": 0.715473841712962,
            "fpr": 0.0845225027442371,
            "logloss": 3.8494084376999664,
            "mae": 0.39092702328090534,
            "precision": 0.7230215827338129,
            "recall": 0.4258474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8041305366261084,
            "auditor_fn_violation": 0.010878466914173398,
            "auditor_fp_violation": 0.014208486332109343,
            "ave_precision_score": 0.8044616764233108,
            "fpr": 0.16557017543859648,
            "logloss": 0.6079680400429301,
            "mae": 0.3427945846740745,
            "precision": 0.703921568627451,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7960139139796685,
            "auditor_fn_violation": 0.0067280321494353375,
            "auditor_fp_violation": 0.013414881141402598,
            "ave_precision_score": 0.7965243554957342,
            "fpr": 0.16465422612513722,
            "logloss": 0.6125051878499188,
            "mae": 0.3439580263768279,
            "precision": 0.7041420118343196,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6926342443344085,
            "auditor_fn_violation": 0.01412244303705322,
            "auditor_fp_violation": 0.014993880048959612,
            "ave_precision_score": 0.6856251549383847,
            "fpr": 0.18421052631578946,
            "logloss": 3.1816812483779358,
            "mae": 0.41625977649311613,
            "precision": 0.6111111111111112,
            "recall": 0.5477178423236515
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7130618034132943,
            "auditor_fn_violation": 0.005365216097043677,
            "auditor_fp_violation": 0.017878173375774204,
            "ave_precision_score": 0.7081572890252927,
            "fpr": 0.16465422612513722,
            "logloss": 2.5986647015642,
            "mae": 0.385194428420214,
            "precision": 0.6437054631828979,
            "recall": 0.5741525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.778523045310514,
            "auditor_fn_violation": 0.025749344835116834,
            "auditor_fp_violation": 0.005796103631170951,
            "ave_precision_score": 0.7767738751308192,
            "fpr": 0.025219298245614034,
            "logloss": 0.6733644951579594,
            "mae": 0.39499389170260546,
            "precision": 0.8935185185185185,
            "recall": 0.4004149377593361
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7643248268334167,
            "auditor_fn_violation": 0.002176784684366218,
            "auditor_fp_violation": 0.007793883414306041,
            "ave_precision_score": 0.7634116897791667,
            "fpr": 0.029637760702524697,
            "logloss": 0.6761260043722117,
            "mae": 0.3977610227190833,
            "precision": 0.864321608040201,
            "recall": 0.3644067796610169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 22727,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7134839711325375,
            "auditor_fn_violation": 0.019195421125427683,
            "auditor_fp_violation": 0.015070379436964512,
            "ave_precision_score": 0.7090621579738738,
            "fpr": 0.19188596491228072,
            "logloss": 2.8888906055961203,
            "mae": 0.39772766126509257,
            "precision": 0.6111111111111112,
            "recall": 0.5705394190871369
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.727014346918956,
            "auditor_fn_violation": 0.006837336508586209,
            "auditor_fp_violation": 0.019005873542553814,
            "ave_precision_score": 0.7240381560818228,
            "fpr": 0.17233809001097694,
            "logloss": 2.3675144651884557,
            "mae": 0.3636623980470654,
            "precision": 0.6463963963963963,
            "recall": 0.6080508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7681179312495618,
            "auditor_fn_violation": 0.016247179151197493,
            "auditor_fp_violation": 0.020338637290901677,
            "ave_precision_score": 0.7078172308542705,
            "fpr": 0.15460526315789475,
            "logloss": 6.614621771829492,
            "mae": 0.3204812643836784,
            "precision": 0.7044025157232704,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7829155386589971,
            "auditor_fn_violation": 0.006976873988353282,
            "auditor_fp_violation": 0.024426835763347997,
            "ave_precision_score": 0.7233194102419169,
            "fpr": 0.15587266739846323,
            "logloss": 5.945257345961301,
            "mae": 0.3117914954348686,
            "precision": 0.7053941908713693,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5575790347651781,
            "auditor_fn_violation": 0.0035670088083278734,
            "auditor_fp_violation": 0.005625254997960021,
            "ave_precision_score": 0.5586747659112448,
            "fpr": 0.45614035087719296,
            "logloss": 0.6930872702615744,
            "mae": 0.4905333319319445,
            "precision": 0.5331088664421998,
            "recall": 0.9854771784232366
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.5570757868039661,
            "auditor_fn_violation": 0.00021628309363895158,
            "auditor_fp_violation": 0.00311055212300183,
            "ave_precision_score": 0.5580224322621676,
            "fpr": 0.4654226125137212,
            "logloss": 0.6883707052050307,
            "mae": 0.49077287286879856,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5912952348986688,
            "auditor_fn_violation": 0.004897812477251228,
            "auditor_fp_violation": 0.00251172990616075,
            "ave_precision_score": 0.5622366533317814,
            "fpr": 0.08223684210526316,
            "logloss": 7.184810359228311,
            "mae": 0.46801313738463063,
            "precision": 0.6710526315789473,
            "recall": 0.31742738589211617
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6069902640125968,
            "auditor_fn_violation": 0.0159630876853523,
            "auditor_fp_violation": 0.006826211652568335,
            "ave_precision_score": 0.5786348151066625,
            "fpr": 0.07025246981339188,
            "logloss": 6.676930501294155,
            "mae": 0.4494726513766748,
            "precision": 0.6981132075471698,
            "recall": 0.3135593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7689869404842389,
            "auditor_fn_violation": 0.017370968916066105,
            "auditor_fp_violation": 0.016518767849857202,
            "ave_precision_score": 0.7203654307470847,
            "fpr": 0.15021929824561403,
            "logloss": 5.352789961405476,
            "mae": 0.31772515235377535,
            "precision": 0.7091295116772823,
            "recall": 0.6929460580912863
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7874492756707994,
            "auditor_fn_violation": 0.009958324806042905,
            "auditor_fp_violation": 0.023691705277686794,
            "ave_precision_score": 0.7434682286821364,
            "fpr": 0.14818880351262348,
            "logloss": 4.615440476872912,
            "mae": 0.30476563438398463,
            "precision": 0.7139830508474576,
            "recall": 0.7139830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7353429606173109,
            "auditor_fn_violation": 0.004454211254276795,
            "auditor_fp_violation": 0.0005915952672378623,
            "ave_precision_score": 0.5401879959234185,
            "fpr": 0.0010964912280701754,
            "logloss": 0.6910354436825941,
            "mae": 0.4958667319856192,
            "precision": 0.9285714285714286,
            "recall": 0.026970954356846474
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.7667131016391001,
            "auditor_fn_violation": 0.002483767139853769,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5334262032782005,
            "fpr": 0.0,
            "logloss": 0.6862927632192943,
            "mae": 0.49363380330323386,
            "precision": 1.0,
            "recall": 0.03177966101694915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 22727,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6401190800234515,
            "auditor_fn_violation": 0.008890223484021258,
            "auditor_fp_violation": 0.0005813953488372093,
            "ave_precision_score": 0.5677759410383887,
            "fpr": 0.0010964912280701754,
            "logloss": 8.976725470986516,
            "mae": 0.5056766842546846,
            "precision": 0.9615384615384616,
            "recall": 0.05186721991701245
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6423460018411655,
            "auditor_fn_violation": 5.1163742581256954e-05,
            "auditor_fp_violation": 0.0005225927602149382,
            "ave_precision_score": 0.5684734875263243,
            "fpr": 0.0010976948408342481,
            "logloss": 8.62908229674107,
            "mae": 0.49429856345555323,
            "precision": 0.9565217391304348,
            "recall": 0.046610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7850807475125127,
            "auditor_fn_violation": 0.019236368930625317,
            "auditor_fp_violation": 0.02081803345573236,
            "ave_precision_score": 0.7387453246196024,
            "fpr": 0.1513157894736842,
            "logloss": 3.824010069238094,
            "mae": 0.3076577247598804,
            "precision": 0.7142857142857143,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.803564593402181,
            "auditor_fn_violation": 0.016735195073396717,
            "auditor_fp_violation": 0.026482200590604833,
            "ave_precision_score": 0.7594072144938205,
            "fpr": 0.1525795828759605,
            "logloss": 3.3108641922323314,
            "mae": 0.28828820475439826,
            "precision": 0.7191919191919192,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6677434540644814,
            "auditor_fn_violation": 0.03495122661425348,
            "auditor_fp_violation": 0.028493472052223582,
            "ave_precision_score": 0.6692602952328979,
            "fpr": 0.1118421052631579,
            "logloss": 0.6730991316423341,
            "mae": 0.4614407584365261,
            "precision": 0.6565656565656566,
            "recall": 0.4045643153526971
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6559321665553,
            "auditor_fn_violation": 0.0355936854639156,
            "auditor_fp_violation": 0.018563294984859813,
            "ave_precision_score": 0.6571726944074628,
            "fpr": 0.1163556531284303,
            "logloss": 0.6776564176574394,
            "mae": 0.45797157054920357,
            "precision": 0.6697819314641744,
            "recall": 0.4555084745762712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8082734565510131,
            "auditor_fn_violation": 0.0167704011065007,
            "auditor_fp_violation": 0.014137086903304784,
            "ave_precision_score": 0.8087566492889353,
            "fpr": 0.1337719298245614,
            "logloss": 1.0484117149743652,
            "mae": 0.29189105131166726,
            "precision": 0.7458333333333333,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8330547306788753,
            "auditor_fn_violation": 0.006804777763307227,
            "auditor_fp_violation": 0.02408677540263397,
            "ave_precision_score": 0.8334652378260797,
            "fpr": 0.13062568605927552,
            "logloss": 0.8319102217796407,
            "mae": 0.25806831398005686,
            "precision": 0.7531120331950207,
            "recall": 0.7690677966101694
        }
    }
]