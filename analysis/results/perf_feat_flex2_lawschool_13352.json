[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6426467481910232,
            "auditor_fn_violation": 0.011231006386258537,
            "auditor_fp_violation": 0.012127091923356788,
            "ave_precision_score": 0.5210024717420989,
            "fpr": 0.3267543859649123,
            "logloss": 9.594521884578606,
            "mae": 0.42859357038290413,
            "precision": 0.5767045454545454,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.638727636417671,
            "auditor_fn_violation": 0.0011484286359988581,
            "auditor_fp_violation": 0.007570309247132754,
            "ave_precision_score": 0.5145826053977897,
            "fpr": 0.34357848518111966,
            "logloss": 9.866496072120004,
            "mae": 0.42406039055626915,
            "precision": 0.5735694822888283,
            "recall": 0.884453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 13352,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5857982498584156,
            "auditor_fn_violation": 0.013639616824488002,
            "auditor_fp_violation": 0.015090650012127093,
            "ave_precision_score": 0.5955766103012451,
            "fpr": 0.10855263157894737,
            "logloss": 6.730422521937956,
            "mae": 0.46543944837005147,
            "precision": 0.6346863468634686,
            "recall": 0.3598326359832636
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6050009924369775,
            "auditor_fn_violation": 0.01426542076764845,
            "auditor_fp_violation": 0.007822652888703836,
            "ave_precision_score": 0.6143795730459418,
            "fpr": 0.10976948408342481,
            "logloss": 6.78081652186713,
            "mae": 0.4629781932641725,
            "precision": 0.6415770609318996,
            "recall": 0.3760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6303215130301316,
            "auditor_fn_violation": 0.015162776187330253,
            "auditor_fp_violation": 0.010035168566577731,
            "ave_precision_score": 0.5126312320580227,
            "fpr": 0.3815789473684211,
            "logloss": 9.280514195067589,
            "mae": 0.4577749605870626,
            "precision": 0.546875,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6256336731565404,
            "auditor_fn_violation": 0.009685542713243367,
            "auditor_fp_violation": 0.007487035845414311,
            "ave_precision_score": 0.5063218876371504,
            "fpr": 0.38529088913282106,
            "logloss": 9.611423735507914,
            "mae": 0.45377056716514996,
            "precision": 0.5447470817120622,
            "recall": 0.8823529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8293536080683777,
            "auditor_fn_violation": 0.015084783087425679,
            "auditor_fp_violation": 0.022652397121836847,
            "ave_precision_score": 0.8296519894493009,
            "fpr": 0.09429824561403509,
            "logloss": 0.9067155559259138,
            "mae": 0.2968524523950026,
            "precision": 0.7957244655581948,
            "recall": 0.700836820083682
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8619982159604916,
            "auditor_fn_violation": 0.01521322030458726,
            "auditor_fp_violation": 0.011143495211779405,
            "ave_precision_score": 0.863158260140664,
            "fpr": 0.08122941822173436,
            "logloss": 0.8773205035190398,
            "mae": 0.268691211448654,
            "precision": 0.8216867469879519,
            "recall": 0.7163865546218487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6420957117764077,
            "auditor_fn_violation": 0.008900389047933643,
            "auditor_fp_violation": 0.005821004123211269,
            "ave_precision_score": 0.5209845767805893,
            "fpr": 0.35526315789473684,
            "logloss": 9.33508816427475,
            "mae": 0.42950299393442837,
            "precision": 0.5668449197860963,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6373341717710153,
            "auditor_fn_violation": 0.014650536394579784,
            "auditor_fp_violation": 0.008339957353924586,
            "ave_precision_score": 0.5150198100350918,
            "fpr": 0.3677277716794731,
            "logloss": 9.607610177595433,
            "mae": 0.4295499436771978,
            "precision": 0.5626631853785901,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6354613676927132,
            "auditor_fn_violation": 0.03387194450561551,
            "auditor_fp_violation": 0.029888228636106403,
            "ave_precision_score": 0.5607987922830604,
            "fpr": 0.2894736842105263,
            "logloss": 8.016794011148303,
            "mae": 0.41618575004935215,
            "precision": 0.5849056603773585,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6402016800327086,
            "auditor_fn_violation": 0.03133503675894068,
            "auditor_fp_violation": 0.03830071791766027,
            "ave_precision_score": 0.5630607380079704,
            "fpr": 0.287596048298573,
            "logloss": 7.897692442345558,
            "mae": 0.40915322750399447,
            "precision": 0.5847860538827259,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7818476057347292,
            "auditor_fn_violation": 0.015428870292887033,
            "auditor_fp_violation": 0.02864520171396233,
            "ave_precision_score": 0.7179617253575243,
            "fpr": 0.1600877192982456,
            "logloss": 4.172689623686649,
            "mae": 0.2992386997645085,
            "precision": 0.7068273092369478,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8088920903016418,
            "auditor_fn_violation": 0.010810910533258307,
            "auditor_fp_violation": 0.01935728074491844,
            "ave_precision_score": 0.7490155121022258,
            "fpr": 0.150384193194292,
            "logloss": 3.8621528700731846,
            "mae": 0.273871044731807,
            "precision": 0.7276341948310139,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6534431468074203,
            "auditor_fn_violation": 0.010295089187403659,
            "auditor_fp_violation": 0.016290726817042613,
            "ave_precision_score": 0.6463730413918822,
            "fpr": 0.06798245614035088,
            "logloss": 8.863751454047119,
            "mae": 0.44019058770234615,
            "precision": 0.7129629629629629,
            "recall": 0.32217573221757323
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.68355200445604,
            "auditor_fn_violation": 0.01212076488114459,
            "auditor_fp_violation": 0.009059136732402186,
            "ave_precision_score": 0.6738713960603213,
            "fpr": 0.07683863885839737,
            "logloss": 8.759187422288665,
            "mae": 0.4284544132042521,
            "precision": 0.7095435684647303,
            "recall": 0.3592436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6375668710577156,
            "auditor_fn_violation": 0.006858804962196285,
            "auditor_fp_violation": 0.013511601584606682,
            "ave_precision_score": 0.5198743991866357,
            "fpr": 0.34539473684210525,
            "logloss": 9.179895422018078,
            "mae": 0.4312856254421109,
            "precision": 0.5702592087312415,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6306822028433392,
            "auditor_fn_violation": 0.006819083286443007,
            "auditor_fp_violation": 0.008100230894432047,
            "ave_precision_score": 0.5113682231005663,
            "fpr": 0.3567508232711306,
            "logloss": 9.496171897761089,
            "mae": 0.433672374780939,
            "precision": 0.5631720430107527,
            "recall": 0.8802521008403361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6660504917902159,
            "auditor_fn_violation": 0.01190082947955663,
            "auditor_fp_violation": 0.011760752688172041,
            "ave_precision_score": 0.6173882068592648,
            "fpr": 0.2225877192982456,
            "logloss": 4.513619294452924,
            "mae": 0.3695391217190306,
            "precision": 0.6553480475382003,
            "recall": 0.8075313807531381
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6943759041477056,
            "auditor_fn_violation": 0.011567305297530651,
            "auditor_fp_violation": 0.008748754053269742,
            "ave_precision_score": 0.6477313159762383,
            "fpr": 0.21624588364434688,
            "logloss": 4.1162418251667265,
            "mae": 0.3324904378305205,
            "precision": 0.6700167504187605,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8117769328558938,
            "auditor_fn_violation": 0.014119044997430821,
            "auditor_fp_violation": 0.01807441992076967,
            "ave_precision_score": 0.8121308712102507,
            "fpr": 0.10087719298245613,
            "logloss": 0.8915478019379908,
            "mae": 0.28858612879985707,
            "precision": 0.7845433255269321,
            "recall": 0.700836820083682
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8479223763680316,
            "auditor_fn_violation": 0.011442776891217525,
            "auditor_fp_violation": 0.005972973995987739,
            "ave_precision_score": 0.8482244291235548,
            "fpr": 0.09989023051591657,
            "logloss": 0.7755889091233428,
            "mae": 0.26441302722982807,
            "precision": 0.7922374429223744,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.537594419246664,
            "auditor_fn_violation": 0.008703112383469139,
            "auditor_fp_violation": 0.012106880103484518,
            "ave_precision_score": 0.44355043005004524,
            "fpr": 0.36293859649122806,
            "logloss": 10.59584336794017,
            "mae": 0.5124932279009231,
            "precision": 0.5181950509461426,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5122565889477271,
            "auditor_fn_violation": 0.0006226420315656452,
            "auditor_fp_violation": 0.010553011090503054,
            "ave_precision_score": 0.42484967358294085,
            "fpr": 0.36882546652030734,
            "logloss": 11.167338661393138,
            "mae": 0.5173578101002022,
            "precision": 0.5137481910274964,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7618286674171012,
            "auditor_fn_violation": 0.03274792630110844,
            "auditor_fp_violation": 0.017660077613388316,
            "ave_precision_score": 0.7616763702036768,
            "fpr": 0.07456140350877193,
            "logloss": 1.689375234981733,
            "mae": 0.37323151823504547,
            "precision": 0.7687074829931972,
            "recall": 0.47280334728033474
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8126024299120586,
            "auditor_fn_violation": 0.02916732005645288,
            "auditor_fp_violation": 0.012485963384937609,
            "ave_precision_score": 0.8124411998161831,
            "fpr": 0.05378704720087816,
            "logloss": 1.5025164664990287,
            "mae": 0.3309516743481156,
            "precision": 0.8419354838709677,
            "recall": 0.5483193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7831889862479134,
            "auditor_fn_violation": 0.03680815532555238,
            "auditor_fp_violation": 0.03070175438596491,
            "ave_precision_score": 0.7788469554744559,
            "fpr": 0.1118421052631579,
            "logloss": 1.5157384372462295,
            "mae": 0.3227718608339497,
            "precision": 0.7702702702702703,
            "recall": 0.7154811715481172
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8312691259453009,
            "auditor_fn_violation": 0.03269101273879475,
            "auditor_fp_violation": 0.023836380382805306,
            "ave_precision_score": 0.8284522589104895,
            "fpr": 0.09440175631174534,
            "logloss": 1.136804532236539,
            "mae": 0.29388955919200843,
            "precision": 0.8054298642533937,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7826645260439802,
            "auditor_fn_violation": 0.028917088746972033,
            "auditor_fp_violation": 0.021439687929501173,
            "ave_precision_score": 0.7787465788948059,
            "fpr": 0.09649122807017543,
            "logloss": 1.1970674963026282,
            "mae": 0.3239927941712698,
            "precision": 0.7919621749408984,
            "recall": 0.700836820083682
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8316851925333097,
            "auditor_fn_violation": 0.025662076026898142,
            "auditor_fp_violation": 0.017797797040009087,
            "ave_precision_score": 0.8293193605141354,
            "fpr": 0.08342480790340286,
            "logloss": 0.8111560564969834,
            "mae": 0.2922087422215291,
            "precision": 0.8248847926267281,
            "recall": 0.7521008403361344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7617881422999997,
            "auditor_fn_violation": 0.022636350289950827,
            "auditor_fp_violation": 0.023582140835960882,
            "ave_precision_score": 0.7577860232175078,
            "fpr": 0.13706140350877194,
            "logloss": 1.4132375610632597,
            "mae": 0.29830470773822054,
            "precision": 0.7362869198312236,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.818671327699756,
            "auditor_fn_violation": 0.01690819027940485,
            "auditor_fp_violation": 0.016028868112595733,
            "ave_precision_score": 0.8180640564392287,
            "fpr": 0.12294182217343579,
            "logloss": 1.0454049317293534,
            "mae": 0.2673770153254613,
            "precision": 0.7606837606837606,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6290911772015816,
            "auditor_fn_violation": 0.014965499522865756,
            "auditor_fp_violation": 0.014095217883418226,
            "ave_precision_score": 0.6378762148374157,
            "fpr": 0.08442982456140351,
            "logloss": 6.335919251292301,
            "mae": 0.44309584019440806,
            "precision": 0.6968503937007874,
            "recall": 0.3702928870292887
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6504784984396751,
            "auditor_fn_violation": 0.0040587036131686655,
            "auditor_fp_violation": 0.011925760500649791,
            "ave_precision_score": 0.6591799131967345,
            "fpr": 0.0867178924259056,
            "logloss": 6.3277652299848395,
            "mae": 0.43381871944474215,
            "precision": 0.7084870848708487,
            "recall": 0.40336134453781514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.765238772919794,
            "auditor_fn_violation": 0.028790923438302883,
            "auditor_fp_violation": 0.01723057644110276,
            "ave_precision_score": 0.7650632565815063,
            "fpr": 0.06798245614035088,
            "logloss": 1.670693839326544,
            "mae": 0.3745615936184593,
            "precision": 0.7839721254355401,
            "recall": 0.4707112970711297
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8166965328683075,
            "auditor_fn_violation": 0.023189956553422684,
            "auditor_fp_violation": 0.009538589651387258,
            "ave_precision_score": 0.816518766194377,
            "fpr": 0.048298572996706916,
            "logloss": 1.484140982808807,
            "mae": 0.33319960398726245,
            "precision": 0.8533333333333334,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6323612272587151,
            "auditor_fn_violation": 0.012708287455039274,
            "auditor_fp_violation": 0.013653084323712508,
            "ave_precision_score": 0.6079652453218197,
            "fpr": 0.2149122807017544,
            "logloss": 3.4677216012136967,
            "mae": 0.3354790201485993,
            "precision": 0.6573426573426573,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.645200637933067,
            "auditor_fn_violation": 0.015213220304587265,
            "auditor_fp_violation": 0.01860529669303658,
            "ave_precision_score": 0.6230242349131843,
            "fpr": 0.1986827661909989,
            "logloss": 3.3591665069287995,
            "mae": 0.3127850566487647,
            "precision": 0.6779359430604982,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7980480386281259,
            "auditor_fn_violation": 0.012419254202451737,
            "auditor_fp_violation": 0.026452219257821975,
            "ave_precision_score": 0.7985036986137345,
            "fpr": 0.1600877192982456,
            "logloss": 0.9895312265994852,
            "mae": 0.2892764000735043,
            "precision": 0.7181467181467182,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8369291159603167,
            "auditor_fn_violation": 0.007587008458707303,
            "auditor_fp_violation": 0.017479844051629514,
            "ave_precision_score": 0.8371641830331884,
            "fpr": 0.14489571899012074,
            "logloss": 0.8419096527120953,
            "mae": 0.26279526212384585,
            "precision": 0.7431906614785992,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6342095010036777,
            "auditor_fn_violation": 0.013637322909784921,
            "auditor_fp_violation": 0.012450481041312973,
            "ave_precision_score": 0.6112581495775834,
            "fpr": 0.19188596491228072,
            "logloss": 3.291273336824198,
            "mae": 0.3322473830367938,
            "precision": 0.6806569343065694,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6455757226981291,
            "auditor_fn_violation": 0.009095185824055205,
            "auditor_fp_violation": 0.020841061357356448,
            "ave_precision_score": 0.6255968803645356,
            "fpr": 0.18441273326015367,
            "logloss": 3.182145369845357,
            "mae": 0.3073835786278286,
            "precision": 0.6934306569343066,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7686085755938081,
            "auditor_fn_violation": 0.008996733465462824,
            "auditor_fp_violation": 0.027167212385803226,
            "ave_precision_score": 0.7687620987237521,
            "fpr": 0.29714912280701755,
            "logloss": 1.3958708394244348,
            "mae": 0.3525873820533314,
            "precision": 0.613960113960114,
            "recall": 0.9016736401673641
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8219982878591225,
            "auditor_fn_violation": 0.0024744255550738434,
            "auditor_fp_violation": 0.026016629445979534,
            "ave_precision_score": 0.8220192406424027,
            "fpr": 0.3018660812294182,
            "logloss": 1.1091413586989423,
            "mae": 0.3365514261369991,
            "precision": 0.6180555555555556,
            "recall": 0.9348739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7961231600047867,
            "auditor_fn_violation": 0.01658500330323718,
            "auditor_fp_violation": 0.025982294445791906,
            "ave_precision_score": 0.7965231995640764,
            "fpr": 0.15679824561403508,
            "logloss": 0.968936184719679,
            "mae": 0.2952697758346806,
            "precision": 0.7201565557729941,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8364122669713023,
            "auditor_fn_violation": 0.013172338090010977,
            "auditor_fp_violation": 0.01772966425678489,
            "ave_precision_score": 0.8367633220312652,
            "fpr": 0.14928649835345773,
            "logloss": 0.8190017226691665,
            "mae": 0.26569927856254566,
            "precision": 0.7333333333333333,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.640311741587613,
            "auditor_fn_violation": 0.005991705204433682,
            "auditor_fp_violation": 0.01262733446519524,
            "ave_precision_score": 0.5226188366614652,
            "fpr": 0.33881578947368424,
            "logloss": 9.111017286681177,
            "mae": 0.4225392105362149,
            "precision": 0.5795918367346938,
            "recall": 0.891213389121339
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6330217736442114,
            "auditor_fn_violation": 0.0018379470339178498,
            "auditor_fp_violation": 0.009442699067590246,
            "ave_precision_score": 0.5137091930862208,
            "fpr": 0.3578485181119649,
            "logloss": 9.4565059510284,
            "mae": 0.424810730205887,
            "precision": 0.5704874835309618,
            "recall": 0.9096638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8509781273430849,
            "auditor_fn_violation": 0.010515304998898923,
            "auditor_fp_violation": 0.014471663028539092,
            "ave_precision_score": 0.8512551588641097,
            "fpr": 0.1206140350877193,
            "logloss": 0.7660811920099823,
            "mae": 0.3113168637807432,
            "precision": 0.780439121756487,
            "recall": 0.8179916317991632
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8829049427463868,
            "auditor_fn_violation": 0.019989115294855593,
            "auditor_fp_violation": 0.009457839686084516,
            "ave_precision_score": 0.8829205576969562,
            "fpr": 0.13391877058177826,
            "logloss": 0.6646987168163916,
            "mae": 0.2939695310415997,
            "precision": 0.7662835249042146,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6136843155212026,
            "auditor_fn_violation": 0.013038611172282173,
            "auditor_fp_violation": 0.013779408197914145,
            "ave_precision_score": 0.6013164186294917,
            "fpr": 0.19517543859649122,
            "logloss": 3.241012858788959,
            "mae": 0.3406100544903606,
            "precision": 0.6703703703703704,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6332428402408143,
            "auditor_fn_violation": 0.010792461880471185,
            "auditor_fp_violation": 0.017653961164313565,
            "ave_precision_score": 0.62277534815228,
            "fpr": 0.1877058177826564,
            "logloss": 3.14569250012596,
            "mae": 0.31634702602863374,
            "precision": 0.6809701492537313,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8046135110124666,
            "auditor_fn_violation": 0.016266149159509656,
            "auditor_fp_violation": 0.02358719379092894,
            "ave_precision_score": 0.8049428668406271,
            "fpr": 0.13267543859649122,
            "logloss": 0.8984159413635819,
            "mae": 0.2952931925053363,
            "precision": 0.7425531914893617,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.844467547189441,
            "auditor_fn_violation": 0.012355985204180466,
            "auditor_fp_violation": 0.012395119673972015,
            "ave_precision_score": 0.8447601514484415,
            "fpr": 0.12403951701427003,
            "logloss": 0.7624089891594844,
            "mae": 0.26391226970258197,
            "precision": 0.7621052631578947,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6297200277895106,
            "auditor_fn_violation": 0.021278352785730016,
            "auditor_fp_violation": 0.009373231465761182,
            "ave_precision_score": 0.6083433704168746,
            "fpr": 0.17434210526315788,
            "logloss": 3.2946058996740044,
            "mae": 0.3385424767947352,
            "precision": 0.68762278978389,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6447894420612612,
            "auditor_fn_violation": 0.012771079891890894,
            "auditor_fp_violation": 0.020843584793772164,
            "ave_precision_score": 0.6255339618436713,
            "fpr": 0.17233809001097694,
            "logloss": 3.137131307070985,
            "mae": 0.3122095177235883,
            "precision": 0.697495183044316,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7732357603162114,
            "auditor_fn_violation": 0.012813807531380759,
            "auditor_fp_violation": 0.026267786401487598,
            "ave_precision_score": 0.7248607007635595,
            "fpr": 0.15460526315789475,
            "logloss": 4.619004667249969,
            "mae": 0.3007675188210464,
            "precision": 0.7207920792079208,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8057279456120364,
            "auditor_fn_violation": 0.008836904685035379,
            "auditor_fp_violation": 0.014711634303594642,
            "ave_precision_score": 0.7655503670591322,
            "fpr": 0.14928649835345773,
            "logloss": 3.902937091812318,
            "mae": 0.27378530172511656,
            "precision": 0.7322834645669292,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6396468345090908,
            "auditor_fn_violation": 0.011175952433384716,
            "auditor_fp_violation": 0.0055178268251273345,
            "ave_precision_score": 0.5188082335948957,
            "fpr": 0.3618421052631579,
            "logloss": 9.40749953628563,
            "mae": 0.4343605989512677,
            "precision": 0.5611702127659575,
            "recall": 0.8828451882845189
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6373121376216164,
            "auditor_fn_violation": 0.015762067725004384,
            "auditor_fp_violation": 0.007683863885839738,
            "ave_precision_score": 0.5154902627626411,
            "fpr": 0.3677277716794731,
            "logloss": 9.594125044370124,
            "mae": 0.4292951154846669,
            "precision": 0.5638020833333334,
            "recall": 0.9096638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8034712661705062,
            "auditor_fn_violation": 0.0163280848564927,
            "auditor_fp_violation": 0.025315304390007277,
            "ave_precision_score": 0.8038018719476139,
            "fpr": 0.14035087719298245,
            "logloss": 0.9012192519609206,
            "mae": 0.296009374449381,
            "precision": 0.7333333333333333,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8437315395322396,
            "auditor_fn_violation": 0.012355985204180466,
            "auditor_fp_violation": 0.01595316502012441,
            "ave_precision_score": 0.8440254881834528,
            "fpr": 0.12733260153677278,
            "logloss": 0.7643919447071482,
            "mae": 0.2646798103916495,
            "precision": 0.7573221757322176,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7951433521045588,
            "auditor_fn_violation": 0.01658500330323718,
            "auditor_fp_violation": 0.024511884550084892,
            "ave_precision_score": 0.7955503485557645,
            "fpr": 0.15679824561403508,
            "logloss": 0.9877678306588727,
            "mae": 0.295224872635116,
            "precision": 0.7201565557729941,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8359176032253004,
            "auditor_fn_violation": 0.013172338090010977,
            "auditor_fp_violation": 0.019039327756538854,
            "ave_precision_score": 0.8362694713805597,
            "fpr": 0.14818880351262348,
            "logloss": 0.8350135812932679,
            "mae": 0.26557513525296994,
            "precision": 0.7347740667976425,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7958591248512621,
            "auditor_fn_violation": 0.01658500330323718,
            "auditor_fp_violation": 0.027715457999838312,
            "ave_precision_score": 0.7962552800220553,
            "fpr": 0.15570175438596492,
            "logloss": 0.9690681950109177,
            "mae": 0.2954544089526551,
            "precision": 0.7215686274509804,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8360250578669857,
            "auditor_fn_violation": 0.013172338090010977,
            "auditor_fp_violation": 0.017752375184526294,
            "ave_precision_score": 0.8363773822097246,
            "fpr": 0.14818880351262348,
            "logloss": 0.8191122537257632,
            "mae": 0.2658592840530883,
            "precision": 0.7347740667976425,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8006626466570381,
            "auditor_fn_violation": 0.016759340820670935,
            "auditor_fp_violation": 0.031217155792707573,
            "ave_precision_score": 0.8010647574085792,
            "fpr": 0.14692982456140352,
            "logloss": 0.9248890087013806,
            "mae": 0.29124403915667585,
            "precision": 0.7248459958932238,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8449206080203797,
            "auditor_fn_violation": 0.01256814471123246,
            "auditor_fp_violation": 0.012899806957114209,
            "ave_precision_score": 0.8452328815882194,
            "fpr": 0.1251372118551043,
            "logloss": 0.7704510443832134,
            "mae": 0.2615591366622817,
            "precision": 0.7610062893081762,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7826720537883328,
            "auditor_fn_violation": 0.028825332158849006,
            "auditor_fp_violation": 0.021439687929501173,
            "ave_precision_score": 0.7787538443985418,
            "fpr": 0.09649122807017543,
            "logloss": 1.196591759084039,
            "mae": 0.3246231067827658,
            "precision": 0.7924528301886793,
            "recall": 0.702928870292887
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8319059352955589,
            "auditor_fn_violation": 0.024728112979549677,
            "auditor_fp_violation": 0.019226062051301465,
            "ave_precision_score": 0.8295386527892159,
            "fpr": 0.08342480790340286,
            "logloss": 0.8111062087698012,
            "mae": 0.2931696822709362,
            "precision": 0.825287356321839,
            "recall": 0.7542016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8127950424400744,
            "auditor_fn_violation": 0.019555622843720182,
            "auditor_fp_violation": 0.012308998302207132,
            "ave_precision_score": 0.8131447193238293,
            "fpr": 0.06907894736842106,
            "logloss": 0.9126602657070744,
            "mae": 0.31721983707204765,
            "precision": 0.8043478260869565,
            "recall": 0.5418410041841004
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.857025435194986,
            "auditor_fn_violation": 0.010658709147764482,
            "auditor_fp_violation": 0.004080396684204553,
            "ave_precision_score": 0.8573006537223584,
            "fpr": 0.06256860592755215,
            "logloss": 0.760590978875725,
            "mae": 0.28248458316356284,
            "precision": 0.8333333333333334,
            "recall": 0.5987394957983193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 13352,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7777663316550179,
            "auditor_fn_violation": 0.01085939220436028,
            "auditor_fp_violation": 0.020608476837254436,
            "ave_precision_score": 0.7441808693668892,
            "fpr": 0.12390350877192982,
            "logloss": 3.6644344558285913,
            "mae": 0.2779164457111664,
            "precision": 0.7595744680851064,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8152458374659102,
            "auditor_fn_violation": 0.00887149590901125,
            "auditor_fp_violation": 0.012501104003431879,
            "ave_precision_score": 0.7918643258718457,
            "fpr": 0.11964873765093303,
            "logloss": 2.8476890282690857,
            "mae": 0.2553874235520669,
            "precision": 0.7690677966101694,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6431412562279314,
            "auditor_fn_violation": 0.007838306540409602,
            "auditor_fp_violation": 0.005727524456302049,
            "ave_precision_score": 0.5214889967663677,
            "fpr": 0.3651315789473684,
            "logloss": 9.425408755030704,
            "mae": 0.42955469999555806,
            "precision": 0.5652741514360313,
            "recall": 0.9058577405857741
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6388643687542608,
            "auditor_fn_violation": 0.012328312224999772,
            "auditor_fp_violation": 0.012223525997703665,
            "ave_precision_score": 0.5154604995941009,
            "fpr": 0.37760702524698136,
            "logloss": 9.746700568064671,
            "mae": 0.4280984880488686,
            "precision": 0.5606641123882503,
            "recall": 0.9222689075630253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6384945932395143,
            "auditor_fn_violation": 0.007198304338251488,
            "auditor_fp_violation": 0.016892028458242385,
            "ave_precision_score": 0.520801985922932,
            "fpr": 0.3519736842105263,
            "logloss": 9.124705800066147,
            "mae": 0.4303572071377155,
            "precision": 0.5691275167785235,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6315712107239607,
            "auditor_fn_violation": 0.005135643719617375,
            "auditor_fp_violation": 0.00965214429009426,
            "ave_precision_score": 0.5122571358952863,
            "fpr": 0.3633369923161361,
            "logloss": 9.436298048397564,
            "mae": 0.4341246364219063,
            "precision": 0.5621693121693122,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8026812170211827,
            "auditor_fn_violation": 0.01823891580415474,
            "auditor_fp_violation": 0.023354757862397935,
            "ave_precision_score": 0.803055157330445,
            "fpr": 0.1206140350877193,
            "logloss": 0.897920750056464,
            "mae": 0.29212066699770106,
            "precision": 0.7560975609756098,
            "recall": 0.7133891213389121
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8454730156179867,
            "auditor_fn_violation": 0.012678836627955244,
            "auditor_fp_violation": 0.01339944736742496,
            "ave_precision_score": 0.8457053939689856,
            "fpr": 0.1119648737650933,
            "logloss": 0.7388541201877981,
            "mae": 0.26087164245748107,
            "precision": 0.7768052516411379,
            "recall": 0.7457983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8030277160712209,
            "auditor_fn_violation": 0.022042226381854223,
            "auditor_fp_violation": 0.018372544263885526,
            "ave_precision_score": 0.7978302524406288,
            "fpr": 0.11842105263157894,
            "logloss": 1.431720925164992,
            "mae": 0.29039247231884746,
            "precision": 0.7716701902748414,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8548487219392804,
            "auditor_fn_violation": 0.012893302216605632,
            "auditor_fp_violation": 0.01565287608665481,
            "ave_precision_score": 0.8520780468771413,
            "fpr": 0.11086717892425905,
            "logloss": 0.8837834455121213,
            "mae": 0.2542000802123406,
            "precision": 0.7938775510204081,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6334660876207661,
            "auditor_fn_violation": 0.025868476106584454,
            "auditor_fp_violation": 0.012167515563101304,
            "ave_precision_score": 0.6030854095068411,
            "fpr": 0.20723684210526316,
            "logloss": 3.5652602725007787,
            "mae": 0.3522662903394147,
            "precision": 0.6563636363636364,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6834604785450152,
            "auditor_fn_violation": 0.018725382578937175,
            "auditor_fp_violation": 0.007093379764563393,
            "ave_precision_score": 0.6547053280678231,
            "fpr": 0.1942919868276619,
            "logloss": 2.982271315350596,
            "mae": 0.30747427019067275,
            "precision": 0.6799276672694394,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 13352,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8383062543381163,
            "auditor_fn_violation": 0.0311743008147985,
            "auditor_fp_violation": 0.028862478777589136,
            "ave_precision_score": 0.8385909017626239,
            "fpr": 0.13815789473684212,
            "logloss": 0.5182480966616524,
            "mae": 0.3182821381720204,
            "precision": 0.749003984063745,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8715925713348349,
            "auditor_fn_violation": 0.03251575053731701,
            "auditor_fp_violation": 0.02635224648926909,
            "ave_precision_score": 0.8719559941846893,
            "fpr": 0.141602634467618,
            "logloss": 0.4789765368382988,
            "mae": 0.2962625196590022,
            "precision": 0.7542857142857143,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7877760170813544,
            "auditor_fn_violation": 0.03059164648021729,
            "auditor_fp_violation": 0.010861326703856415,
            "ave_precision_score": 0.7874353401456631,
            "fpr": 0.0712719298245614,
            "logloss": 1.0701132851589459,
            "mae": 0.3196360431351135,
            "precision": 0.8204419889502762,
            "recall": 0.6213389121338913
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8419816624900844,
            "auditor_fn_violation": 0.03047717440433913,
            "auditor_fp_violation": 0.00807247309385922,
            "ave_precision_score": 0.8414008998617855,
            "fpr": 0.0570801317233809,
            "logloss": 0.7471735237986372,
            "mae": 0.28396515323398136,
            "precision": 0.8638743455497382,
            "recall": 0.6932773109243697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6316367347749074,
            "auditor_fn_violation": 0.014263561623724585,
            "auditor_fp_violation": 0.019580200501253135,
            "ave_precision_score": 0.6091581934326434,
            "fpr": 0.20942982456140352,
            "logloss": 3.3383415204132403,
            "mae": 0.3356839431925183,
            "precision": 0.6619469026548672,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6463948404499766,
            "auditor_fn_violation": 0.011062273427482963,
            "auditor_fp_violation": 0.014476954716933523,
            "ave_precision_score": 0.6265201395394591,
            "fpr": 0.1964873765093304,
            "logloss": 3.1985164021187815,
            "mae": 0.3104025809455192,
            "precision": 0.6803571428571429,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 13352,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6049053821054318,
            "auditor_fn_violation": 0.012185274902738026,
            "auditor_fp_violation": 0.02626525992400356,
            "ave_precision_score": 0.5984094750696703,
            "fpr": 0.14364035087719298,
            "logloss": 8.889966357235169,
            "mae": 0.4508993251396245,
            "precision": 0.608955223880597,
            "recall": 0.42677824267782427
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6309747387574071,
            "auditor_fn_violation": 0.010914684205185928,
            "auditor_fp_violation": 0.014333118841237998,
            "ave_precision_score": 0.6215061528897193,
            "fpr": 0.13721185510428102,
            "logloss": 8.766528917456906,
            "mae": 0.4353650651021598,
            "precision": 0.6301775147928994,
            "recall": 0.4474789915966387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7786186019954753,
            "auditor_fn_violation": 0.016268443074212734,
            "auditor_fp_violation": 0.028349603848330504,
            "ave_precision_score": 0.7737568035581854,
            "fpr": 0.1611842105263158,
            "logloss": 1.2655065491390518,
            "mae": 0.3036782263079658,
            "precision": 0.7302752293577982,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8273061842918297,
            "auditor_fn_violation": 0.01295787250136059,
            "auditor_fp_violation": 0.02009917105113744,
            "ave_precision_score": 0.8233107040371727,
            "fpr": 0.16794731064763996,
            "logloss": 0.9267978971978929,
            "mae": 0.2864606109632815,
            "precision": 0.7306338028169014,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6310835626274172,
            "auditor_fn_violation": 0.01797970344270719,
            "auditor_fp_violation": 0.010398981324278439,
            "ave_precision_score": 0.6091000648563023,
            "fpr": 0.17982456140350878,
            "logloss": 3.3163574823256323,
            "mae": 0.33745594186513705,
            "precision": 0.6852207293666027,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6447588362674566,
            "auditor_fn_violation": 0.009431873737420328,
            "auditor_fp_violation": 0.018289867141072717,
            "ave_precision_score": 0.6248773078381797,
            "fpr": 0.17453347969264543,
            "logloss": 3.1901393238607407,
            "mae": 0.3141182768347444,
            "precision": 0.6948176583493282,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7772787964714025,
            "auditor_fn_violation": 0.013843775233061743,
            "auditor_fp_violation": 0.02126283450561889,
            "ave_precision_score": 0.7565150253518993,
            "fpr": 0.125,
            "logloss": 1.78857103593389,
            "mae": 0.2883955897056072,
            "precision": 0.7579617834394905,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8193774267900503,
            "auditor_fn_violation": 0.013107767805256026,
            "auditor_fp_violation": 0.008705855634202661,
            "ave_precision_score": 0.8052502775695184,
            "fpr": 0.11306256860592755,
            "logloss": 1.3180769208898155,
            "mae": 0.2549051298957886,
            "precision": 0.7827004219409283,
            "recall": 0.7794117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6123081719515222,
            "auditor_fn_violation": 0.012625706525728546,
            "auditor_fp_violation": 0.01400679117147708,
            "ave_precision_score": 0.5999006246182818,
            "fpr": 0.19956140350877194,
            "logloss": 3.2907481771947897,
            "mae": 0.34085121156772474,
            "precision": 0.6648250460405156,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.632180265581753,
            "auditor_fn_violation": 0.01004990360578919,
            "auditor_fp_violation": 0.014307884477080892,
            "ave_precision_score": 0.6209950667793203,
            "fpr": 0.18880351262349068,
            "logloss": 3.164108022913778,
            "mae": 0.3189630296394617,
            "precision": 0.6802973977695167,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6382953171127423,
            "auditor_fn_violation": 0.006335792409895032,
            "auditor_fp_violation": 0.011136712749615973,
            "ave_precision_score": 0.5206027453395126,
            "fpr": 0.3717105263157895,
            "logloss": 9.173978829148503,
            "mae": 0.4319775375464049,
            "precision": 0.5637065637065637,
            "recall": 0.9163179916317992
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6310370604769706,
            "auditor_fn_violation": 0.009399588595042849,
            "auditor_fp_violation": 0.008246590206543286,
            "ave_precision_score": 0.5117224420811537,
            "fpr": 0.37980241492864986,
            "logloss": 9.529231591823757,
            "mae": 0.43448189097230705,
            "precision": 0.5597964376590331,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 13352,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6331514269673557,
            "auditor_fn_violation": 0.019383579240989504,
            "auditor_fp_violation": 0.009454078745250224,
            "ave_precision_score": 0.6117875078195876,
            "fpr": 0.17543859649122806,
            "logloss": 3.2533848424419376,
            "mae": 0.33411823608462304,
            "precision": 0.6917148362235067,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6492554413094539,
            "auditor_fn_violation": 0.012554308221642115,
            "auditor_fp_violation": 0.019377468236244116,
            "ave_precision_score": 0.6287502899921099,
            "fpr": 0.17672886937431395,
            "logloss": 3.1673507582081366,
            "mae": 0.3090320140914733,
            "precision": 0.6956521739130435,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7753155640455546,
            "auditor_fn_violation": 0.013483630624678852,
            "auditor_fp_violation": 0.016796022313849145,
            "ave_precision_score": 0.7526159189391172,
            "fpr": 0.14035087719298245,
            "logloss": 1.982703561175676,
            "mae": 0.290920956786474,
            "precision": 0.7366255144032922,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8127986974546806,
            "auditor_fn_violation": 0.007460173970795783,
            "auditor_fp_violation": 0.011991369847458277,
            "ave_precision_score": 0.7982897124621595,
            "fpr": 0.1251372118551043,
            "logloss": 1.494014736604398,
            "mae": 0.2650945470181521,
            "precision": 0.762993762993763,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7828098715654151,
            "auditor_fn_violation": 0.01564449827497615,
            "auditor_fp_violation": 0.024895909127657864,
            "ave_precision_score": 0.7833165053518782,
            "fpr": 0.14912280701754385,
            "logloss": 1.0255803155355214,
            "mae": 0.30348199157789685,
            "precision": 0.7207392197125256,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8234111090703088,
            "auditor_fn_violation": 0.01060105710780471,
            "auditor_fp_violation": 0.01499678261856997,
            "ave_precision_score": 0.8237823378103097,
            "fpr": 0.1350164654226125,
            "logloss": 0.8761097937194158,
            "mae": 0.27292462174470533,
            "precision": 0.7469135802469136,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6294371276232339,
            "auditor_fn_violation": 0.01673640167364017,
            "auditor_fp_violation": 0.0066875859002344705,
            "ave_precision_score": 0.5117445870819834,
            "fpr": 0.38706140350877194,
            "logloss": 9.311222806366205,
            "mae": 0.4601576978773728,
            "precision": 0.5480153649167734,
            "recall": 0.895397489539749
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6246743523367365,
            "auditor_fn_violation": 0.005806713464749239,
            "auditor_fp_violation": 0.005379966438295685,
            "ave_precision_score": 0.5053599674709958,
            "fpr": 0.3940724478594951,
            "logloss": 9.611779428330792,
            "mae": 0.4569542876002098,
            "precision": 0.5444162436548223,
            "recall": 0.9012605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6558362509294978,
            "auditor_fn_violation": 0.006266974968802761,
            "auditor_fp_violation": 0.000184432856334393,
            "ave_precision_score": 0.5370834735756305,
            "fpr": 0.3475877192982456,
            "logloss": 8.834057789240838,
            "mae": 0.41486833012858004,
            "precision": 0.5739247311827957,
            "recall": 0.893305439330544
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6546028225025087,
            "auditor_fn_violation": 0.011461225544004652,
            "auditor_fp_violation": 0.007242262513090323,
            "ave_precision_score": 0.536851049462749,
            "fpr": 0.34796926454445665,
            "logloss": 8.959580794761408,
            "mae": 0.406204397201596,
            "precision": 0.5756358768406962,
            "recall": 0.9033613445378151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6310680462844954,
            "auditor_fn_violation": 0.013685495118549515,
            "auditor_fp_violation": 0.01609366157328806,
            "ave_precision_score": 0.6081183954313321,
            "fpr": 0.19956140350877194,
            "logloss": 3.4015302767345137,
            "mae": 0.33806057256426586,
            "precision": 0.6678832116788321,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6423143216518739,
            "auditor_fn_violation": 0.011899381047698993,
            "auditor_fp_violation": 0.019821593045409237,
            "ave_precision_score": 0.6224492941055234,
            "fpr": 0.18880351262349068,
            "logloss": 3.2671763223545605,
            "mae": 0.313786334568218,
            "precision": 0.6820702402957486,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8298899908916515,
            "auditor_fn_violation": 0.03277086544813918,
            "auditor_fp_violation": 0.03890017382165091,
            "ave_precision_score": 0.8301896387747558,
            "fpr": 0.19407894736842105,
            "logloss": 0.5738056487818128,
            "mae": 0.3217038035883186,
            "precision": 0.6921739130434783,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8695917728614215,
            "auditor_fn_violation": 0.031863129444972285,
            "auditor_fp_violation": 0.037404897990082904,
            "ave_precision_score": 0.8700707809091597,
            "fpr": 0.1877058177826564,
            "logloss": 0.5230288230431124,
            "mae": 0.2978666844240029,
            "precision": 0.7051724137931035,
            "recall": 0.8592436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.6249603568356874,
            "auditor_fn_violation": 0.019778132569918522,
            "auditor_fp_violation": 0.014653569407389449,
            "ave_precision_score": 0.6025000505356842,
            "fpr": 0.1962719298245614,
            "logloss": 3.346957370460443,
            "mae": 0.3448025155152557,
            "precision": 0.6654205607476635,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6374956019461313,
            "auditor_fn_violation": 0.018144250016142574,
            "auditor_fp_violation": 0.019947764866194786,
            "ave_precision_score": 0.6176917506181645,
            "fpr": 0.1800219538968167,
            "logloss": 3.2295830734798225,
            "mae": 0.3189351163573511,
            "precision": 0.6911487758945386,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7993882082978853,
            "auditor_fn_violation": 0.016020700286280557,
            "auditor_fp_violation": 0.021303258145363418,
            "ave_precision_score": 0.7997709054742516,
            "fpr": 0.13596491228070176,
            "logloss": 0.9485627100373937,
            "mae": 0.2943203960559645,
            "precision": 0.7389473684210527,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8371165879058199,
            "auditor_fn_violation": 0.010861644328422921,
            "auditor_fp_violation": 0.013813290939601555,
            "ave_precision_score": 0.837469774851407,
            "fpr": 0.12294182217343579,
            "logloss": 0.8092374602533645,
            "mae": 0.2646668367803031,
            "precision": 0.7642105263157895,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7722262049037415,
            "auditor_fn_violation": 0.012676172649196217,
            "auditor_fp_violation": 0.021187040181097908,
            "ave_precision_score": 0.7583907429132066,
            "fpr": 0.13815789473684212,
            "logloss": 1.6554574377257831,
            "mae": 0.29109887649873495,
            "precision": 0.7375,
            "recall": 0.7405857740585774
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8171587163537016,
            "auditor_fn_violation": 0.009136695292826244,
            "auditor_fp_violation": 0.014910985780435794,
            "ave_precision_score": 0.8082637889850792,
            "fpr": 0.12294182217343579,
            "logloss": 1.231943774655867,
            "mae": 0.2634625746511162,
            "precision": 0.7656903765690377,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6133704831820561,
            "auditor_fn_violation": 0.015529802539822363,
            "auditor_fp_violation": 0.013663190233648644,
            "ave_precision_score": 0.6010133542059781,
            "fpr": 0.19736842105263158,
            "logloss": 3.2357839481694644,
            "mae": 0.3407281877115207,
            "precision": 0.6678966789667896,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.632807246535561,
            "auditor_fn_violation": 0.011871708068518297,
            "auditor_fp_violation": 0.014651071829617578,
            "ave_precision_score": 0.6223578055891847,
            "fpr": 0.18990120746432493,
            "logloss": 3.139157515021036,
            "mae": 0.3162815206632472,
            "precision": 0.6802218114602587,
            "recall": 0.773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6454827904930818,
            "auditor_fn_violation": 0.012389433311311756,
            "auditor_fp_violation": 0.00899425984315628,
            "ave_precision_score": 0.5232938572380303,
            "fpr": 0.3333333333333333,
            "logloss": 9.366919406388687,
            "mae": 0.4249844318617346,
            "precision": 0.5771905424200278,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6410417655157461,
            "auditor_fn_violation": 0.012455146712911293,
            "auditor_fp_violation": 0.0062984972936144445,
            "ave_precision_score": 0.5163395463660531,
            "fpr": 0.34906695938529086,
            "logloss": 9.732011955054896,
            "mae": 0.42087985857650045,
            "precision": 0.57543391188251,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6721933745191634,
            "auditor_fn_violation": 0.004046465536225512,
            "auditor_fp_violation": 0.016164402942840973,
            "ave_precision_score": 0.6650774317502868,
            "fpr": 0.08442982456140351,
            "logloss": 8.70635293896326,
            "mae": 0.41443750135071594,
            "precision": 0.7137546468401487,
            "recall": 0.401673640167364
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6932486017478778,
            "auditor_fn_violation": 0.010056821850584392,
            "auditor_fp_violation": 0.01563521203174483,
            "ave_precision_score": 0.684180575349149,
            "fpr": 0.0845225027442371,
            "logloss": 8.65564838890732,
            "mae": 0.4056081260579028,
            "precision": 0.7210144927536232,
            "recall": 0.4180672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8054301713924192,
            "auditor_fn_violation": 0.015080195258019527,
            "auditor_fp_violation": 0.02313242784380306,
            "ave_precision_score": 0.8058345384759354,
            "fpr": 0.16337719298245615,
            "logloss": 0.8896713420887435,
            "mae": 0.2829384577085741,
            "precision": 0.7204502814258912,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8439977224250214,
            "auditor_fn_violation": 0.005631451263271503,
            "auditor_fp_violation": 0.017066000479452927,
            "ave_precision_score": 0.844311326475164,
            "fpr": 0.150384193194292,
            "logloss": 0.7620485612942592,
            "mae": 0.26024183200903706,
            "precision": 0.7380497131931166,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6311327829985383,
            "auditor_fn_violation": 0.017764075460618072,
            "auditor_fp_violation": 0.01186686474250142,
            "ave_precision_score": 0.6102087093108848,
            "fpr": 0.17653508771929824,
            "logloss": 3.30812913480114,
            "mae": 0.33535107517394697,
            "precision": 0.6903846153846154,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.647566524787655,
            "auditor_fn_violation": 0.007169607689398486,
            "auditor_fp_violation": 0.015337446534690952,
            "ave_precision_score": 0.6270693509266235,
            "fpr": 0.1778265642151482,
            "logloss": 3.1959796935382423,
            "mae": 0.3099375187568232,
            "precision": 0.6925996204933587,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6432298168689315,
            "auditor_fn_violation": 0.007838306540409602,
            "auditor_fp_violation": 0.004037311019484194,
            "ave_precision_score": 0.5215764754600754,
            "fpr": 0.36622807017543857,
            "logloss": 9.41884513588621,
            "mae": 0.4294368542044443,
            "precision": 0.5645371577574967,
            "recall": 0.9058577405857741
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6389906800897337,
            "auditor_fn_violation": 0.011714894519827688,
            "auditor_fp_violation": 0.012223525997703665,
            "ave_precision_score": 0.515587935288329,
            "fpr": 0.37760702524698136,
            "logloss": 9.738317964058451,
            "mae": 0.4279397928019097,
            "precision": 0.5601023017902813,
            "recall": 0.9201680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6295224722975278,
            "auditor_fn_violation": 0.017846656389928797,
            "auditor_fp_violation": 0.010244866197752446,
            "ave_precision_score": 0.6036435203278868,
            "fpr": 0.21600877192982457,
            "logloss": 3.5258863376029423,
            "mae": 0.3416294711569475,
            "precision": 0.6513274336283186,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.644217238961114,
            "auditor_fn_violation": 0.012817201523858722,
            "auditor_fp_violation": 0.00743404368068436,
            "ave_precision_score": 0.6201225064088702,
            "fpr": 0.20417124039517015,
            "logloss": 3.387447589835501,
            "mae": 0.32036998352082,
            "precision": 0.6702127659574468,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6439083458118255,
            "auditor_fn_violation": 0.006482602950891876,
            "auditor_fp_violation": 0.009527346592287173,
            "ave_precision_score": 0.5219951741942915,
            "fpr": 0.33223684210526316,
            "logloss": 9.589730902152983,
            "mae": 0.42653061104838824,
            "precision": 0.5779944289693594,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6396565863979834,
            "auditor_fn_violation": 0.008716988441919031,
            "auditor_fp_violation": 0.008317246426183192,
            "ave_precision_score": 0.5152303583592333,
            "fpr": 0.34796926454445665,
            "logloss": 9.82854178265984,
            "mae": 0.4230819024499436,
            "precision": 0.5739247311827957,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.666494408719386,
            "auditor_fn_violation": 0.023044667107098293,
            "auditor_fp_violation": 0.02109861346915677,
            "ave_precision_score": 0.6721155982076229,
            "fpr": 0.13048245614035087,
            "logloss": 5.446421357858558,
            "mae": 0.41269844158504715,
            "precision": 0.6703601108033241,
            "recall": 0.5062761506276151
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6957427705362225,
            "auditor_fn_violation": 0.020662491121585847,
            "auditor_fp_violation": 0.01818388281161286,
            "ave_precision_score": 0.7006267507595351,
            "fpr": 0.1119648737650933,
            "logloss": 5.149107909401913,
            "mae": 0.3911735694414391,
            "precision": 0.711864406779661,
            "recall": 0.5294117647058824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6274668942525026,
            "auditor_fn_violation": 0.02416639139690231,
            "auditor_fp_violation": 0.009817891502950935,
            "ave_precision_score": 0.6050262200771281,
            "fpr": 0.17434210526315788,
            "logloss": 3.343503734676254,
            "mae": 0.3444868245052699,
            "precision": 0.6857707509881423,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6415568722328993,
            "auditor_fn_violation": 0.02140504939626784,
            "auditor_fp_violation": 0.02199174836292063,
            "ave_precision_score": 0.6217110935070799,
            "fpr": 0.16465422612513722,
            "logloss": 3.225886623332669,
            "mae": 0.3166536761857228,
            "precision": 0.7041420118343196,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7992328091731761,
            "auditor_fn_violation": 0.013910298759450932,
            "auditor_fp_violation": 0.026214730374322915,
            "ave_precision_score": 0.7997123193207967,
            "fpr": 0.1425438596491228,
            "logloss": 0.8933498770945036,
            "mae": 0.2859425968473004,
            "precision": 0.7379032258064516,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8388358367140105,
            "auditor_fn_violation": 0.01034277596878488,
            "auditor_fp_violation": 0.016586547560467846,
            "ave_precision_score": 0.8391456532685836,
            "fpr": 0.12403951701427003,
            "logloss": 0.7425721994523907,
            "mae": 0.2595628072859903,
            "precision": 0.7655601659751037,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6395205346784669,
            "auditor_fn_violation": 0.007390993173309845,
            "auditor_fp_violation": 0.010105909936130655,
            "ave_precision_score": 0.5218278333458786,
            "fpr": 0.39364035087719296,
            "logloss": 9.146651875341824,
            "mae": 0.43564038664069876,
            "precision": 0.5600490196078431,
            "recall": 0.9560669456066946
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6321147508617222,
            "auditor_fn_violation": 0.009489525777380109,
            "auditor_fp_violation": 0.008488840102451538,
            "ave_precision_score": 0.5128006209636302,
            "fpr": 0.40285400658616904,
            "logloss": 9.470714160557604,
            "mae": 0.43910535824874625,
            "precision": 0.552439024390244,
            "recall": 0.9516806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7974103952938822,
            "auditor_fn_violation": 0.016020700286280557,
            "auditor_fp_violation": 0.021965195246179972,
            "ave_precision_score": 0.7978480189469253,
            "fpr": 0.13815789473684212,
            "logloss": 0.9591975321695536,
            "mae": 0.29474020943606155,
            "precision": 0.7358490566037735,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8364487222376522,
            "auditor_fn_violation": 0.010861644328422921,
            "auditor_fp_violation": 0.012395119673972015,
            "ave_precision_score": 0.8367908567691756,
            "fpr": 0.12403951701427003,
            "logloss": 0.8169692738841556,
            "mae": 0.2648135535837526,
            "precision": 0.7626050420168067,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6505077139223933,
            "auditor_fn_violation": 0.0038124862365117905,
            "auditor_fp_violation": 0.013011359042768211,
            "ave_precision_score": 0.6561026148669253,
            "fpr": 0.10307017543859649,
            "logloss": 5.892772198630139,
            "mae": 0.4321004423160879,
            "precision": 0.6845637583892618,
            "recall": 0.42677824267782427
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6687471832713452,
            "auditor_fn_violation": 0.012316781817007818,
            "auditor_fp_violation": 0.016553742887063606,
            "ave_precision_score": 0.6737533457662286,
            "fpr": 0.11086717892425905,
            "logloss": 5.829938602914752,
            "mae": 0.42319899357999113,
            "precision": 0.6823899371069182,
            "recall": 0.45588235294117646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7756111205179202,
            "auditor_fn_violation": 0.010012937678925351,
            "auditor_fp_violation": 0.017781348532621883,
            "ave_precision_score": 0.753703647963339,
            "fpr": 0.14364035087719298,
            "logloss": 1.9600318080829302,
            "mae": 0.2891786468093047,
            "precision": 0.7304526748971193,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8071157792098209,
            "auditor_fn_violation": 0.003449898071193355,
            "auditor_fp_violation": 0.01651589134082794,
            "ave_precision_score": 0.7911161364607365,
            "fpr": 0.12623490669593854,
            "logloss": 1.555736921811237,
            "mae": 0.2699565919918156,
            "precision": 0.7638603696098563,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8144577104690229,
            "auditor_fn_violation": 0.017206654187770693,
            "auditor_fp_violation": 0.01359497534157976,
            "ave_precision_score": 0.8148099028925732,
            "fpr": 0.0800438596491228,
            "logloss": 0.8550086003646488,
            "mae": 0.30844542709849926,
            "precision": 0.7960893854748603,
            "recall": 0.5962343096234309
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8584028059751119,
            "auditor_fn_violation": 0.011622651255892045,
            "auditor_fp_violation": 0.002717741019720658,
            "ave_precision_score": 0.8586744648833362,
            "fpr": 0.06915477497255763,
            "logloss": 0.7108262747906552,
            "mae": 0.2746454683904449,
            "precision": 0.8301886792452831,
            "recall": 0.6470588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 13352,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.6293876105794123,
            "auditor_fn_violation": 0.021186596197606985,
            "auditor_fp_violation": 0.02280651224836284,
            "ave_precision_score": 0.6059829472038993,
            "fpr": 0.1875,
            "logloss": 3.383829465342306,
            "mae": 0.3423722596781688,
            "precision": 0.6767485822306238,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6411568730058212,
            "auditor_fn_violation": 0.015605254176313773,
            "auditor_fp_violation": 0.019841780536734927,
            "ave_precision_score": 0.620733510041857,
            "fpr": 0.1778265642151482,
            "logloss": 3.2940734860345695,
            "mae": 0.3152968151904892,
            "precision": 0.6937618147448015,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7961231600047867,
            "auditor_fn_violation": 0.01658500330323718,
            "auditor_fp_violation": 0.025982294445791906,
            "ave_precision_score": 0.7965231995640764,
            "fpr": 0.15679824561403508,
            "logloss": 0.9689451493619987,
            "mae": 0.29527199115816066,
            "precision": 0.7201565557729941,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.836408481835418,
            "auditor_fn_violation": 0.013172338090010977,
            "auditor_fp_violation": 0.01772966425678489,
            "ave_precision_score": 0.83675954005115,
            "fpr": 0.14928649835345773,
            "logloss": 0.8190093918095334,
            "mae": 0.2657014667858481,
            "precision": 0.7333333333333333,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7981469332597145,
            "auditor_fn_violation": 0.01484162812889966,
            "auditor_fp_violation": 0.026568437222087488,
            "ave_precision_score": 0.7985026998589706,
            "fpr": 0.15460526315789475,
            "logloss": 0.9498007654171857,
            "mae": 0.2990217923250357,
            "precision": 0.7157258064516129,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.835979643203979,
            "auditor_fn_violation": 0.008802313461059507,
            "auditor_fp_violation": 0.020099171051137444,
            "ave_precision_score": 0.8363246714300334,
            "fpr": 0.1394072447859495,
            "logloss": 0.8123982959175128,
            "mae": 0.26936535808856293,
            "precision": 0.742914979757085,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6385725384189199,
            "auditor_fn_violation": 0.001915418777068196,
            "auditor_fp_violation": 0.0032717883418222978,
            "ave_precision_score": 0.5211304853788519,
            "fpr": 0.34539473684210525,
            "logloss": 9.205306878284027,
            "mae": 0.43068481018047333,
            "precision": 0.5708446866485014,
            "recall": 0.8765690376569037
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6304301296036293,
            "auditor_fn_violation": 0.012010072964421773,
            "auditor_fp_violation": 0.008789129035921127,
            "ave_precision_score": 0.5111161689443182,
            "fpr": 0.3556531284302964,
            "logloss": 9.524917747589216,
            "mae": 0.43518894038818073,
            "precision": 0.5685752330226365,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6255510757393714,
            "auditor_fn_violation": 0.020090104969536816,
            "auditor_fp_violation": 0.020833333333333346,
            "ave_precision_score": 0.6036036239270963,
            "fpr": 0.19188596491228072,
            "logloss": 3.335135219197521,
            "mae": 0.34299068857584347,
            "precision": 0.6716697936210131,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6392737621658489,
            "auditor_fn_violation": 0.014357664031584096,
            "auditor_fp_violation": 0.020654327062593847,
            "ave_precision_score": 0.6194469628237032,
            "fpr": 0.17892425905598244,
            "logloss": 3.2162141575749597,
            "mae": 0.31666637554759197,
            "precision": 0.6958955223880597,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6625880978523883,
            "auditor_fn_violation": 0.02020250678998753,
            "auditor_fp_violation": 0.03139906217155793,
            "ave_precision_score": 0.6530466903763533,
            "fpr": 0.17543859649122806,
            "logloss": 2.2571058537291453,
            "mae": 0.3187721539371959,
            "precision": 0.690522243713733,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6921126494566792,
            "auditor_fn_violation": 0.0029102749771697948,
            "auditor_fp_violation": 0.02634467618002196,
            "ave_precision_score": 0.6839788072511309,
            "fpr": 0.15916575192096596,
            "logloss": 1.991284966168376,
            "mae": 0.2964718449393684,
            "precision": 0.7145669291338582,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7961185341623891,
            "auditor_fn_violation": 0.019287234823460335,
            "auditor_fp_violation": 0.029251556310130166,
            "ave_precision_score": 0.7965380972225449,
            "fpr": 0.14802631578947367,
            "logloss": 0.9886505813793777,
            "mae": 0.29292202518027394,
            "precision": 0.7227926078028748,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8400175935400671,
            "auditor_fn_violation": 0.009851580588327536,
            "auditor_fp_violation": 0.01968280404254514,
            "ave_precision_score": 0.8403478801188552,
            "fpr": 0.12623490669593854,
            "logloss": 0.8253730467435385,
            "mae": 0.26220403318289787,
            "precision": 0.7594142259414226,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 13352,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7782490982836584,
            "auditor_fn_violation": 0.015050374366879544,
            "auditor_fp_violation": 0.022574076319831847,
            "ave_precision_score": 0.7631405331301878,
            "fpr": 0.13706140350877194,
            "logloss": 1.6508578207717206,
            "mae": 0.2818582008327898,
            "precision": 0.7469635627530364,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8240869706494495,
            "auditor_fn_violation": 0.011931666190076472,
            "auditor_fp_violation": 0.006164755163581773,
            "ave_precision_score": 0.8158156696374044,
            "fpr": 0.13391877058177826,
            "logloss": 1.192778411795522,
            "mae": 0.2529802447500916,
            "precision": 0.757455268389662,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 13352,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7804441996583956,
            "auditor_fn_violation": 0.029050135799750427,
            "auditor_fp_violation": 0.019529670951572483,
            "ave_precision_score": 0.7760930635421748,
            "fpr": 0.09649122807017543,
            "logloss": 1.2232627792132786,
            "mae": 0.32226772081993293,
            "precision": 0.7934272300469484,
            "recall": 0.7071129707112971
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8316874156058688,
            "auditor_fn_violation": 0.02854006586169045,
            "auditor_fp_violation": 0.020308616273641448,
            "ave_precision_score": 0.8292514334043707,
            "fpr": 0.0867178924259056,
            "logloss": 0.8184284897290087,
            "mae": 0.2914138443330477,
            "precision": 0.8188073394495413,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8101325601620348,
            "auditor_fn_violation": 0.014529655729281365,
            "auditor_fp_violation": 0.02173275931764896,
            "ave_precision_score": 0.8104750248825636,
            "fpr": 0.13925438596491227,
            "logloss": 0.9123665321861786,
            "mae": 0.28388823599323243,
            "precision": 0.7408163265306122,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.848178591153929,
            "auditor_fn_violation": 0.015169404754217828,
            "auditor_fp_violation": 0.012334557199994958,
            "ave_precision_score": 0.8485556734835311,
            "fpr": 0.12952799121844127,
            "logloss": 0.7709286214591503,
            "mae": 0.2577056389312685,
            "precision": 0.756701030927835,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7778411630548758,
            "auditor_fn_violation": 0.0014956323864053443,
            "auditor_fp_violation": 0.014421133478858433,
            "ave_precision_score": 0.7789335591103691,
            "fpr": 0.3508771929824561,
            "logloss": 0.8570951569038427,
            "mae": 0.3691704554172854,
            "precision": 0.5923566878980892,
            "recall": 0.9728033472803347
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.8400774978978568,
            "auditor_fn_violation": 0.0069643664271416585,
            "auditor_fp_violation": 0.005480903894924107,
            "ave_precision_score": 0.8409956642733185,
            "fpr": 0.3391877058177827,
            "logloss": 0.7995536032840715,
            "mae": 0.3643853090699398,
            "precision": 0.5950196592398427,
            "recall": 0.9537815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7990333100068041,
            "auditor_fn_violation": 0.014862273361227337,
            "auditor_fp_violation": 0.025105606758832572,
            "ave_precision_score": 0.799406863320487,
            "fpr": 0.14364035087719298,
            "logloss": 0.9455647860068757,
            "mae": 0.28588864934055636,
            "precision": 0.7358870967741935,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8414826753049953,
            "auditor_fn_violation": 0.0075685598059201786,
            "auditor_fp_violation": 0.012180627578636586,
            "ave_precision_score": 0.841799892692255,
            "fpr": 0.141602634467618,
            "logloss": 0.7840141927672764,
            "mae": 0.2607496696388463,
            "precision": 0.7414829659318637,
            "recall": 0.7773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6312124885510013,
            "auditor_fn_violation": 0.014059403215150852,
            "auditor_fp_violation": 0.009454078745250224,
            "ave_precision_score": 0.6097478174128101,
            "fpr": 0.17543859649122806,
            "logloss": 3.315112822325833,
            "mae": 0.3362467364320507,
            "precision": 0.6928982725527831,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6482237180779741,
            "auditor_fn_violation": 0.008207344408674565,
            "auditor_fp_violation": 0.015337446534690952,
            "ave_precision_score": 0.6272173320274201,
            "fpr": 0.1778265642151482,
            "logloss": 3.20261145680912,
            "mae": 0.3102743986169196,
            "precision": 0.6937618147448015,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6474161788421147,
            "auditor_fn_violation": 0.008441606107318506,
            "auditor_fp_violation": 0.002228353140916806,
            "ave_precision_score": 0.525226966054188,
            "fpr": 0.35855263157894735,
            "logloss": 9.293077715055952,
            "mae": 0.4257345732223991,
            "precision": 0.5691699604743083,
            "recall": 0.9037656903765691
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6445261651418415,
            "auditor_fn_violation": 0.009353466963075022,
            "auditor_fp_violation": 0.006396911313827179,
            "ave_precision_score": 0.5200681243686835,
            "fpr": 0.3677277716794731,
            "logloss": 9.622246956241549,
            "mae": 0.4213785177811733,
            "precision": 0.567741935483871,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7199263591891176,
            "auditor_fn_violation": 0.016605648535564857,
            "auditor_fp_violation": 0.019271970248201153,
            "ave_precision_score": 0.7088774062450098,
            "fpr": 0.14035087719298245,
            "logloss": 1.8204374931631486,
            "mae": 0.29775246801305405,
            "precision": 0.7360824742268042,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7544376541787914,
            "auditor_fn_violation": 0.013762694979199148,
            "auditor_fp_violation": 0.010101315972090796,
            "ave_precision_score": 0.74351005741843,
            "fpr": 0.13391877058177826,
            "logloss": 1.5694454017063606,
            "mae": 0.2675791372532593,
            "precision": 0.7515274949083504,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 13352,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6479754345018189,
            "auditor_fn_violation": 0.0036037399985318942,
            "auditor_fp_violation": 0.01073247635217076,
            "ave_precision_score": 0.5302811725655698,
            "fpr": 0.3081140350877193,
            "logloss": 9.101497944770696,
            "mae": 0.3849387514231451,
            "precision": 0.5974212034383954,
            "recall": 0.8723849372384938
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6398330125128249,
            "auditor_fn_violation": 0.002596647879788578,
            "auditor_fp_violation": 0.012306799399422134,
            "ave_precision_score": 0.5205175797193945,
            "fpr": 0.3205268935236004,
            "logloss": 9.43819752751353,
            "mae": 0.39470107620495626,
            "precision": 0.5887323943661972,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8149472569634225,
            "auditor_fn_violation": 0.026219445056155033,
            "auditor_fp_violation": 0.017523647829250547,
            "ave_precision_score": 0.8152911323875004,
            "fpr": 0.09100877192982457,
            "logloss": 0.7875848796081346,
            "mae": 0.29676014558407454,
            "precision": 0.7909319899244333,
            "recall": 0.6569037656903766
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.858788925895182,
            "auditor_fn_violation": 0.011638793827080782,
            "auditor_fp_violation": 0.009349331920208941,
            "ave_precision_score": 0.8590662408692573,
            "fpr": 0.08781558726673985,
            "logloss": 0.651988616584787,
            "mae": 0.263899780074711,
            "precision": 0.8062953995157385,
            "recall": 0.6995798319327731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7653924458977264,
            "auditor_fn_violation": 0.010799750422080314,
            "auditor_fp_violation": 0.018928369310372718,
            "ave_precision_score": 0.7341083766435325,
            "fpr": 0.16776315789473684,
            "logloss": 2.303773991022044,
            "mae": 0.3137709660674629,
            "precision": 0.7063339731285988,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8069722661432487,
            "auditor_fn_violation": 0.00754549898993626,
            "auditor_fp_violation": 0.008067426221027803,
            "ave_precision_score": 0.7866137188799476,
            "fpr": 0.15697036223929747,
            "logloss": 1.688740588320342,
            "mae": 0.28574539008854805,
            "precision": 0.7265774378585086,
            "recall": 0.7983193277310925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6437529260114528,
            "auditor_fn_violation": 0.005404463040446306,
            "auditor_fp_violation": 0.008448540706605234,
            "ave_precision_score": 0.5218361904412072,
            "fpr": 0.34978070175438597,
            "logloss": 9.431958298415726,
            "mae": 0.42861229028287934,
            "precision": 0.5723860589812333,
            "recall": 0.893305439330544
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6388863158299337,
            "auditor_fn_violation": 0.01184172900773921,
            "auditor_fp_violation": 0.009601675561780059,
            "ave_precision_score": 0.5147131169702764,
            "fpr": 0.3677277716794731,
            "logloss": 9.794157676700056,
            "mae": 0.4277607988095643,
            "precision": 0.564935064935065,
            "recall": 0.9138655462184874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8030542003264096,
            "auditor_fn_violation": 0.015105428319753367,
            "auditor_fp_violation": 0.025461840084081172,
            "ave_precision_score": 0.8034918994135993,
            "fpr": 0.13267543859649122,
            "logloss": 0.9243235207805665,
            "mae": 0.28745449459399464,
            "precision": 0.7447257383966245,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.841220607658991,
            "auditor_fn_violation": 0.005859753341512237,
            "auditor_fp_violation": 0.008289488625610363,
            "ave_precision_score": 0.8415015210119693,
            "fpr": 0.1207464324917673,
            "logloss": 0.7946679779759009,
            "mae": 0.26355095687860697,
            "precision": 0.7664543524416136,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7856099013097978,
            "auditor_fn_violation": 0.019406518388020263,
            "auditor_fp_violation": 0.024731688091195737,
            "ave_precision_score": 0.7799002729684099,
            "fpr": 0.13706140350877194,
            "logloss": 1.3751221615787117,
            "mae": 0.28201036476504104,
            "precision": 0.7417355371900827,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8312939500150971,
            "auditor_fn_violation": 0.016700642935549632,
            "auditor_fp_violation": 0.016609258488209246,
            "ave_precision_score": 0.8288703010810626,
            "fpr": 0.1251372118551043,
            "logloss": 1.0283183009919692,
            "mae": 0.24973951119837834,
            "precision": 0.7663934426229508,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7850087910159292,
            "auditor_fn_violation": 0.0158280114512222,
            "auditor_fp_violation": 0.020934392432694647,
            "ave_precision_score": 0.7786309924629353,
            "fpr": 0.14473684210526316,
            "logloss": 1.2564908541448327,
            "mae": 0.2816639762991016,
            "precision": 0.736,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8271108648338429,
            "auditor_fn_violation": 0.013661227388869927,
            "auditor_fp_violation": 0.010825542223399827,
            "ave_precision_score": 0.8217130807694412,
            "fpr": 0.13172338090010977,
            "logloss": 1.0500671891642963,
            "mae": 0.24984514473013367,
            "precision": 0.7575757575757576,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7663871107716556,
            "auditor_fn_violation": 0.024182448799823824,
            "auditor_fp_violation": 0.014047214811221604,
            "ave_precision_score": 0.7664919262773058,
            "fpr": 0.09649122807017543,
            "logloss": 1.203266332859362,
            "mae": 0.36219036268913013,
            "precision": 0.7411764705882353,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8233692930004818,
            "auditor_fn_violation": 0.019401064487265817,
            "auditor_fp_violation": 0.013969743997375628,
            "ave_precision_score": 0.823377066707329,
            "fpr": 0.07793633369923161,
            "logloss": 0.8945292389833492,
            "mae": 0.32857777923677817,
            "precision": 0.7911764705882353,
            "recall": 0.5651260504201681
        }
    }
]