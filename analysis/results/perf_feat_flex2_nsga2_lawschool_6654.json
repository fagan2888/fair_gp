[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7501920904435595,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6566651020316545,
            "fpr": 0.14692982456140352,
            "logloss": 0.8103970862920804,
            "mae": 0.4160426036176974,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7755106467226183,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6820475847240072,
            "fpr": 0.13172338090010977,
            "logloss": 0.7640717236524647,
            "mae": 0.4028715764782693,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7477990946447046,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6563796702491582,
            "fpr": 0.48135964912280704,
            "logloss": 0.9280717149569998,
            "mae": 0.43081070613442807,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6862010781980203,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6789959594254137,
            "fpr": 0.47200878155872666,
            "logloss": 0.8985340639809408,
            "mae": 0.4203268548659776,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7096424640389996,
            "auditor_fn_violation": 0.0008322206149623517,
            "auditor_fp_violation": 0.02125294728849459,
            "ave_precision_score": 0.7101545902636592,
            "fpr": 0.20285087719298245,
            "logloss": 0.6446993296682257,
            "mae": 0.4537726077018816,
            "precision": 0.6292585170340681,
            "recall": 0.6638477801268499
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7355885939196932,
            "auditor_fn_violation": 0.0048061233571661715,
            "auditor_fp_violation": 0.019707451561024176,
            "ave_precision_score": 0.7361373943882414,
            "fpr": 0.18441273326015367,
            "logloss": 0.6375954954450412,
            "mae": 0.4483399798005613,
            "precision": 0.6612903225806451,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.4846602847466541,
            "auditor_fn_violation": 0.016132098215941557,
            "auditor_fp_violation": 0.009781001478639646,
            "ave_precision_score": 0.48618019731391493,
            "fpr": 0.27521929824561403,
            "logloss": 0.8027123673736931,
            "mae": 0.506716279835816,
            "precision": 0.502970297029703,
            "recall": 0.5369978858350951
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4871715206441776,
            "auditor_fn_violation": 0.010598118172212583,
            "auditor_fp_violation": 0.013580782681949316,
            "ave_precision_score": 0.4889229118300485,
            "fpr": 0.27991218441273324,
            "logloss": 0.8043010943801974,
            "mae": 0.5065009599524979,
            "precision": 0.510556621880998,
            "recall": 0.553014553014553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.501614463387913,
            "auditor_fn_violation": 0.009625013908979654,
            "auditor_fp_violation": 0.00837979059265476,
            "ave_precision_score": 0.48300691869375145,
            "fpr": 0.0625,
            "logloss": 2.397261932040342,
            "mae": 0.575812762408117,
            "precision": 0.5546875,
            "recall": 0.15010570824524314
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5266163494763255,
            "auditor_fn_violation": 0.0051164902976099545,
            "auditor_fp_violation": 0.01082378168636561,
            "ave_precision_score": 0.50570529367934,
            "fpr": 0.048298572996706916,
            "logloss": 2.476403607654121,
            "mae": 0.5796800434486389,
            "precision": 0.6333333333333333,
            "recall": 0.158004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.7069163770859814,
            "auditor_fn_violation": 0.0008322206149623517,
            "auditor_fp_violation": 0.020621028653638657,
            "ave_precision_score": 0.7074354110499268,
            "fpr": 0.20394736842105263,
            "logloss": 0.646127550558457,
            "mae": 0.454448280243684,
            "precision": 0.628,
            "recall": 0.6638477801268499
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7327688229168146,
            "auditor_fn_violation": 0.004450114219598303,
            "auditor_fp_violation": 0.020503918515303914,
            "ave_precision_score": 0.7333249911406295,
            "fpr": 0.18551042810098792,
            "logloss": 0.638984223440977,
            "mae": 0.4489976248497391,
            "precision": 0.6592741935483871,
            "recall": 0.6798336798336798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 6654,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7116931038919339,
            "auditor_fn_violation": 0.001569396535736807,
            "auditor_fp_violation": 0.024412540462774253,
            "ave_precision_score": 0.7122035564160879,
            "fpr": 0.20394736842105263,
            "logloss": 0.644552928108052,
            "mae": 0.45331202268885373,
            "precision": 0.6345776031434185,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7365499696895376,
            "auditor_fn_violation": 0.008729070199981294,
            "auditor_fp_violation": 0.013580782681949306,
            "ave_precision_score": 0.7370942393828451,
            "fpr": 0.18111964873765093,
            "logloss": 0.6387774320254778,
            "mae": 0.44831234298321354,
            "precision": 0.67,
            "recall": 0.6964656964656964
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7540672125730494,
            "auditor_fn_violation": 0.026053837023849273,
            "auditor_fp_violation": 0.01796846900851217,
            "ave_precision_score": 0.7559283687300999,
            "fpr": 0.10855263157894737,
            "logloss": 0.6022119379049066,
            "mae": 0.3387350860048412,
            "precision": 0.7670588235294118,
            "recall": 0.6892177589852009
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7839561482602724,
            "auditor_fn_violation": 0.02823198103110288,
            "auditor_fp_violation": 0.010785490005871394,
            "ave_precision_score": 0.7851539885441786,
            "fpr": 0.10428100987925357,
            "logloss": 0.5711697492486114,
            "mae": 0.3286220870428587,
            "precision": 0.7850678733031674,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7501920904435595,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6566651020316545,
            "fpr": 0.14692982456140352,
            "logloss": 0.819563375941871,
            "mae": 0.4155591345277795,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7755106467226183,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6820475847240072,
            "fpr": 0.13172338090010977,
            "logloss": 0.7725310597755346,
            "mae": 0.40235941372116624,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7501920904435595,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6566651020316545,
            "fpr": 0.14692982456140352,
            "logloss": 0.8244402794474355,
            "mae": 0.4153079915334258,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7755106467226183,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6820475847240072,
            "fpr": 0.13172338090010977,
            "logloss": 0.7770736730056413,
            "mae": 0.4020907333535761,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6713964155824594,
            "auditor_fn_violation": 0.0021025740884982025,
            "auditor_fp_violation": 0.029447907924709277,
            "ave_precision_score": 0.6269554738996617,
            "fpr": 0.21162280701754385,
            "logloss": 3.8836329314221025,
            "mae": 0.33619715981279896,
            "precision": 0.6712095400340715,
            "recall": 0.8329809725158562
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.686607314881343,
            "auditor_fn_violation": 0.008217877592191536,
            "auditor_fp_violation": 0.030658872182370515,
            "ave_precision_score": 0.6372520972348036,
            "fpr": 0.20965971459934138,
            "logloss": 4.046535233246648,
            "mae": 0.33383554116738823,
            "precision": 0.6723842195540308,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8044518013076192,
            "auditor_fn_violation": 0.02917640295241275,
            "auditor_fp_violation": 0.0234983814890301,
            "ave_precision_score": 0.8049233295421516,
            "fpr": 0.10964912280701754,
            "logloss": 0.5731362015852283,
            "mae": 0.3235025144662311,
            "precision": 0.7701149425287356,
            "recall": 0.7082452431289641
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8077753629882466,
            "auditor_fn_violation": 0.025580169378193532,
            "auditor_fp_violation": 0.013616521583743907,
            "ave_precision_score": 0.8088328498310962,
            "fpr": 0.10318331503841932,
            "logloss": 0.544795411026614,
            "mae": 0.3173490241735713,
            "precision": 0.7819025522041764,
            "recall": 0.7006237006237006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5776412471553896,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.659707697464305,
            "fpr": 0.48135964912280704,
            "logloss": 0.8654883785818029,
            "mae": 0.435325932934096,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5637173623241057,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.673784917678968,
            "fpr": 0.47200878155872666,
            "logloss": 0.8533825993341506,
            "mae": 0.42512085297759356,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7023334439561635,
            "auditor_fn_violation": 0.0018614851081191384,
            "auditor_fp_violation": 0.026647983854853535,
            "ave_precision_score": 0.6457721873203355,
            "fpr": 0.21600877192982457,
            "logloss": 4.1392686013428905,
            "mae": 0.3476167404010643,
            "precision": 0.6677908937605397,
            "recall": 0.8372093023255814
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.708933897388873,
            "auditor_fn_violation": 0.00892761375747106,
            "auditor_fp_violation": 0.03410512342685013,
            "ave_precision_score": 0.6485506601406834,
            "fpr": 0.20856201975850713,
            "logloss": 4.386069868224733,
            "mae": 0.34428719929600915,
            "precision": 0.6746575342465754,
            "recall": 0.8191268191268192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7519625926606299,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6669419675694016,
            "fpr": 0.14692982456140352,
            "logloss": 0.7042125992354583,
            "mae": 0.42361635936979664,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.777218534048539,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6937987549766,
            "fpr": 0.13172338090010977,
            "logloss": 0.6669568544147554,
            "mae": 0.40937403279523293,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8037557361047483,
            "auditor_fn_violation": 0.004293238381365684,
            "auditor_fp_violation": 0.003449326619510052,
            "ave_precision_score": 0.8035209270023664,
            "fpr": 0.0581140350877193,
            "logloss": 0.5639851172467235,
            "mae": 0.3755551208496878,
            "precision": 0.8312101910828026,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8177907086408948,
            "auditor_fn_violation": 0.00714756806963175,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8179032911934145,
            "fpr": 0.050493962678375415,
            "logloss": 0.554672490301149,
            "mae": 0.3716735262525985,
            "precision": 0.85625,
            "recall": 0.5696465696465697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8043194019996711,
            "auditor_fn_violation": 0.004293238381365684,
            "auditor_fp_violation": 0.003449326619510052,
            "ave_precision_score": 0.8040897289121686,
            "fpr": 0.0581140350877193,
            "logloss": 0.5636736220875131,
            "mae": 0.37544509420465483,
            "precision": 0.8312101910828026,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8205061280815401,
            "auditor_fn_violation": 0.00714756806963175,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8205735411412487,
            "fpr": 0.050493962678375415,
            "logloss": 0.5541930277610376,
            "mae": 0.3715044082879497,
            "precision": 0.85625,
            "recall": 0.5696465696465697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.752917703005471,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.666201832843077,
            "fpr": 0.14692982456140352,
            "logloss": 0.8255548124719659,
            "mae": 0.41551840913138893,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7765185364547113,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6904752481864977,
            "fpr": 0.13172338090010977,
            "logloss": 0.777108290207676,
            "mae": 0.4026444750284913,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7532787739015276,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6700975681881864,
            "fpr": 0.14692982456140352,
            "logloss": 0.7218792535698713,
            "mae": 0.42156011683114786,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7760731311308773,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6934942770061989,
            "fpr": 0.13172338090010977,
            "logloss": 0.6824469725445017,
            "mae": 0.40738853714076145,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5495984949693841,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6434834381917419,
            "fpr": 0.48135964912280704,
            "logloss": 0.8311760301179462,
            "mae": 0.4369088662951662,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5397300154414401,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.666013476201481,
            "fpr": 0.47200878155872666,
            "logloss": 0.8220866993161818,
            "mae": 0.4267270829360912,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8043451391380796,
            "auditor_fn_violation": 0.01037146248284559,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8041133306803085,
            "fpr": 0.06469298245614036,
            "logloss": 0.5621323838034976,
            "mae": 0.37485428887272354,
            "precision": 0.8190184049079755,
            "recall": 0.5644820295983086
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8203290350447938,
            "auditor_fn_violation": 0.006373932828378504,
            "auditor_fp_violation": 0.0023128175018507667,
            "ave_precision_score": 0.8204108324160624,
            "fpr": 0.05378704720087816,
            "logloss": 0.5517393964851091,
            "mae": 0.37059243860052393,
            "precision": 0.850609756097561,
            "recall": 0.58004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7552971569249847,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6484699206086652,
            "fpr": 0.14692982456140352,
            "logloss": 0.8071146681607546,
            "mae": 0.415873353418551,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7804492949250881,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6805055748822684,
            "fpr": 0.13172338090010977,
            "logloss": 0.7603699812266081,
            "mae": 0.4028782486326739,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5495984949693841,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6434834381917419,
            "fpr": 0.48135964912280704,
            "logloss": 0.824698478143816,
            "mae": 0.4372120117932035,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5397300154414401,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.666013476201481,
            "fpr": 0.47200878155872666,
            "logloss": 0.8161337023401193,
            "mae": 0.4270189612547731,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7552971569249847,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6484699206086652,
            "fpr": 0.14692982456140352,
            "logloss": 0.785983000381313,
            "mae": 0.41630985692404865,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7804492949250881,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6805055748822684,
            "fpr": 0.13172338090010977,
            "logloss": 0.7409273699303909,
            "mae": 0.40310888579595755,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7309425168008765,
            "auditor_fn_violation": 0.041441804829197744,
            "auditor_fp_violation": 0.019459597170603044,
            "ave_precision_score": 0.7315649252716703,
            "fpr": 0.13267543859649122,
            "logloss": 2.9657500324234336,
            "mae": 0.31204318308525353,
            "precision": 0.7328918322295805,
            "recall": 0.7019027484143763
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7648995185522257,
            "auditor_fn_violation": 0.0429789749218948,
            "auditor_fp_violation": 0.010098792535675086,
            "ave_precision_score": 0.764808967209527,
            "fpr": 0.12843029637760703,
            "logloss": 2.851052847814737,
            "mae": 0.30734616815459365,
            "precision": 0.74,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6602393379494198,
            "auditor_fn_violation": 0.003607062052594493,
            "auditor_fp_violation": 0.01088748351516605,
            "ave_precision_score": 0.6611817078224497,
            "fpr": 0.07346491228070176,
            "logloss": 0.7153158442798004,
            "mae": 0.45885220919431924,
            "precision": 0.6839622641509434,
            "recall": 0.30655391120507397
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6403179550964861,
            "auditor_fn_violation": 0.0013350342658794865,
            "auditor_fp_violation": 0.015811911265412402,
            "ave_precision_score": 0.6410015393648281,
            "fpr": 0.09220636663007684,
            "logloss": 0.7465532489991676,
            "mae": 0.4738374039276998,
            "precision": 0.65,
            "recall": 0.32432432432432434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6319797870090469,
            "auditor_fn_violation": 0.013329438819034914,
            "auditor_fp_violation": 0.015917855572872956,
            "ave_precision_score": 0.6331467260578454,
            "fpr": 0.08442982456140351,
            "logloss": 0.7259370998140313,
            "mae": 0.47283387449500114,
            "precision": 0.6577777777777778,
            "recall": 0.3128964059196617
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6297759965109521,
            "auditor_fn_violation": 0.001752660369564876,
            "auditor_fp_violation": 0.019099890230515917,
            "ave_precision_score": 0.6304659562843961,
            "fpr": 0.09440175631174534,
            "logloss": 0.7429388867809992,
            "mae": 0.47844340175049177,
            "precision": 0.6228070175438597,
            "recall": 0.29521829521829523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6545885241916911,
            "auditor_fn_violation": 0.0010014465338822765,
            "auditor_fp_violation": 0.028983335331495025,
            "ave_precision_score": 0.6152140074298684,
            "fpr": 0.20942982456140352,
            "logloss": 3.745661434145416,
            "mae": 0.3429633560683629,
            "precision": 0.6718213058419243,
            "recall": 0.8266384778012685
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6761237843672341,
            "auditor_fn_violation": 0.00970581321843671,
            "auditor_fp_violation": 0.03024787481173257,
            "ave_precision_score": 0.6302303682066549,
            "fpr": 0.21185510428100987,
            "logloss": 3.904330359040707,
            "mae": 0.3389710037581119,
            "precision": 0.6695205479452054,
            "recall": 0.8128898128898129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8037603777831999,
            "auditor_fn_violation": 0.004293238381365684,
            "auditor_fp_violation": 0.005872097670143471,
            "ave_precision_score": 0.8035219580069752,
            "fpr": 0.05921052631578947,
            "logloss": 0.5649658492017735,
            "mae": 0.375885654559457,
            "precision": 0.8285714285714286,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.81609045572553,
            "auditor_fn_violation": 0.007590297381735367,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.816213059516799,
            "fpr": 0.050493962678375415,
            "logloss": 0.5561549745901296,
            "mae": 0.3721803069016543,
            "precision": 0.8566978193146417,
            "recall": 0.5717255717255717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6744070022856291,
            "auditor_fn_violation": 0.00622195022439823,
            "auditor_fp_violation": 0.008889321823921995,
            "ave_precision_score": 0.6753291318598782,
            "fpr": 0.07456140350877193,
            "logloss": 0.6999602716059216,
            "mae": 0.4537654822387227,
            "precision": 0.7081545064377682,
            "recall": 0.3488372093023256
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6575432836079784,
            "auditor_fn_violation": 0.004164850487572768,
            "auditor_fp_violation": 0.015924233528195438,
            "ave_precision_score": 0.6581841910538706,
            "fpr": 0.09220636663007684,
            "logloss": 0.7301956860458579,
            "mae": 0.4685892818661868,
            "precision": 0.6744186046511628,
            "recall": 0.36174636174636177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6719994263576443,
            "auditor_fn_violation": 0.002285708987055376,
            "auditor_fp_violation": 0.027052611597330457,
            "ave_precision_score": 0.6279126365506928,
            "fpr": 0.2149122807017544,
            "logloss": 3.8581671923919374,
            "mae": 0.33599857445050585,
            "precision": 0.66723259762309,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6849882267348099,
            "auditor_fn_violation": 0.008217877592191536,
            "auditor_fp_violation": 0.030658872182370515,
            "ave_precision_score": 0.6362380484088592,
            "fpr": 0.20965971459934138,
            "logloss": 4.03712264989111,
            "mae": 0.33366664242467475,
            "precision": 0.6723842195540308,
            "recall": 0.814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7532787739015276,
            "auditor_fn_violation": 0.011989540447312796,
            "auditor_fp_violation": 0.01819575990089119,
            "ave_precision_score": 0.6700975681881864,
            "fpr": 0.14692982456140352,
            "logloss": 0.7160728741692444,
            "mae": 0.4221884380503182,
            "precision": 0.6898148148148148,
            "recall": 0.6300211416490487
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7769476847210859,
            "auditor_fn_violation": 0.019977589681212077,
            "auditor_fp_violation": 0.0168993949914482,
            "ave_precision_score": 0.6942470573116948,
            "fpr": 0.13172338090010977,
            "logloss": 0.677337766785316,
            "mae": 0.40800193511563,
            "precision": 0.7266514806378133,
            "recall": 0.6632016632016632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8063786778715722,
            "auditor_fn_violation": 0.010981139423611884,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8061262072158508,
            "fpr": 0.06469298245614036,
            "logloss": 0.559864926249772,
            "mae": 0.3733345067226573,
            "precision": 0.8195718654434251,
            "recall": 0.5665961945031712
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8232360986554474,
            "auditor_fn_violation": 0.0014902177361013841,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8232620033561693,
            "fpr": 0.054884742041712405,
            "logloss": 0.5466690628252211,
            "mae": 0.3680731049615125,
            "precision": 0.8493975903614458,
            "recall": 0.5862785862785863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5064174337289773,
            "auditor_fn_violation": 0.006877990430622013,
            "auditor_fp_violation": 0.004987911121767974,
            "ave_precision_score": 0.492151923246325,
            "fpr": 0.039473684210526314,
            "logloss": 0.8434586278926439,
            "mae": 0.5201194330461716,
            "precision": 0.5443037974683544,
            "recall": 0.09090909090909091
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5265671371752695,
            "auditor_fn_violation": 0.005938049845843487,
            "auditor_fp_violation": 0.005843310443417661,
            "ave_precision_score": 0.5159197408813365,
            "fpr": 0.025246981339187707,
            "logloss": 0.8133957240470407,
            "mae": 0.5194000401232559,
            "precision": 0.6229508196721312,
            "recall": 0.079002079002079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6442997882648371,
            "auditor_fn_violation": 0.005477819813805131,
            "auditor_fp_violation": 0.016032749870119493,
            "ave_precision_score": 0.6454448689099119,
            "fpr": 0.08552631578947369,
            "logloss": 0.7177577886652354,
            "mae": 0.4690646416170638,
            "precision": 0.6708860759493671,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6402589562587553,
            "auditor_fn_violation": 0.010285469121912591,
            "auditor_fp_violation": 0.020034207234574834,
            "ave_precision_score": 0.6409022509059412,
            "fpr": 0.09549945115257959,
            "logloss": 0.73537515520209,
            "mae": 0.4753483066517547,
            "precision": 0.6329113924050633,
            "recall": 0.31185031185031187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8069659420115053,
            "auditor_fn_violation": 0.006833945328437378,
            "auditor_fp_violation": 0.0019382168405067375,
            "ave_precision_score": 0.8067393677677231,
            "fpr": 0.06140350877192982,
            "logloss": 0.5591028566748619,
            "mae": 0.37339514860752643,
            "precision": 0.825,
            "recall": 0.5581395348837209
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8217727642368264,
            "auditor_fn_violation": 0.007156696509056554,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8218626659889992,
            "fpr": 0.050493962678375415,
            "logloss": 0.547127339001596,
            "mae": 0.3682829253089284,
            "precision": 0.8580246913580247,
            "recall": 0.577962577962578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7434537166511184,
            "auditor_fn_violation": 0.00878120247765291,
            "auditor_fp_violation": 0.022062202773448433,
            "ave_precision_score": 0.7409515832009845,
            "fpr": 0.1787280701754386,
            "logloss": 1.6511096704222517,
            "mae": 0.2966954546312823,
            "precision": 0.6947565543071161,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7549727456111923,
            "auditor_fn_violation": 0.02463537589772497,
            "auditor_fp_violation": 0.00829653077374722,
            "ave_precision_score": 0.7539724352063157,
            "fpr": 0.1756311745334797,
            "logloss": 1.7379680615718065,
            "mae": 0.30509080039184283,
            "precision": 0.6963946869070209,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7326846036375373,
            "auditor_fn_violation": 0.03693065910018175,
            "auditor_fp_violation": 0.02127292890540703,
            "ave_precision_score": 0.7328659805325399,
            "fpr": 0.13048245614035087,
            "logloss": 3.0082632317876703,
            "mae": 0.3130910441832705,
            "precision": 0.734375,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7672494054082065,
            "auditor_fn_violation": 0.04521316047111876,
            "auditor_fp_violation": 0.01347611875526511,
            "ave_precision_score": 0.76747491285853,
            "fpr": 0.12184412733260154,
            "logloss": 2.900787029972892,
            "mae": 0.3088593546267519,
            "precision": 0.7454128440366973,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.765050417172078,
            "auditor_fn_violation": 0.03983068135454916,
            "auditor_fp_violation": 0.02386304599768213,
            "ave_precision_score": 0.7661527271830948,
            "fpr": 0.1074561403508772,
            "logloss": 2.3918107962674564,
            "mae": 0.311032843210371,
            "precision": 0.755,
            "recall": 0.638477801268499
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8001842778233633,
            "auditor_fn_violation": 0.052940384444226385,
            "auditor_fp_violation": 0.014060705077476834,
            "ave_precision_score": 0.8007306384298438,
            "fpr": 0.11086717892425905,
            "logloss": 2.426831990204167,
            "mae": 0.30706991333460076,
            "precision": 0.754257907542579,
            "recall": 0.6444906444906445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6968342206965094,
            "auditor_fn_violation": 0.0008739475538741177,
            "auditor_fp_violation": 0.01871528194061463,
            "ave_precision_score": 0.6973732361644176,
            "fpr": 0.20833333333333334,
            "logloss": 0.6510926626840919,
            "mae": 0.4570492959067914,
            "precision": 0.6296296296296297,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7229512154929332,
            "auditor_fn_violation": 0.00653368051831279,
            "auditor_fp_violation": 0.019258162509892023,
            "ave_precision_score": 0.7235530876879172,
            "fpr": 0.18221734357848518,
            "logloss": 0.6447792457032241,
            "mae": 0.45188686162801756,
            "precision": 0.6686626746506986,
            "recall": 0.6964656964656964
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6486143196428539,
            "auditor_fn_violation": 0.0044485553206483446,
            "auditor_fp_violation": 0.015255964512648363,
            "ave_precision_score": 0.6495897618225239,
            "fpr": 0.11951754385964912,
            "logloss": 0.7051501613973841,
            "mae": 0.45786999308405973,
            "precision": 0.6426229508196721,
            "recall": 0.4143763213530655
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6310392135061085,
            "auditor_fn_violation": 0.008927613757471054,
            "auditor_fp_violation": 0.02522655910959079,
            "ave_precision_score": 0.6317422504313701,
            "fpr": 0.1394072447859495,
            "logloss": 0.736755492528989,
            "mae": 0.4727509312832879,
            "precision": 0.6139817629179332,
            "recall": 0.41995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.80255627046793,
            "auditor_fn_violation": 0.02091215088461111,
            "auditor_fp_violation": 0.009161571354354001,
            "ave_precision_score": 0.802987694624522,
            "fpr": 0.11403508771929824,
            "logloss": 0.5791786859660846,
            "mae": 0.323109319332798,
            "precision": 0.7668161434977578,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8086009117311236,
            "auditor_fn_violation": 0.02156822025098645,
            "auditor_fp_violation": 0.01409644397927144,
            "ave_precision_score": 0.8095836373312806,
            "fpr": 0.10318331503841932,
            "logloss": 0.5428660081371425,
            "mae": 0.3149299028493648,
            "precision": 0.7892376681614349,
            "recall": 0.7318087318087318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.626078239101681,
            "auditor_fn_violation": 0.006476948184414527,
            "auditor_fp_violation": 0.021622607201374752,
            "ave_precision_score": 0.602213695940852,
            "fpr": 0.3026315789473684,
            "logloss": 2.7369139282346326,
            "mae": 0.44778943408215255,
            "precision": 0.6085106382978723,
            "recall": 0.9069767441860465
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6370262428131429,
            "auditor_fn_violation": 0.003507602848985945,
            "auditor_fp_violation": 0.022336813621627136,
            "ave_precision_score": 0.6073341743279606,
            "fpr": 0.31833150384193193,
            "logloss": 3.1035298259178785,
            "mae": 0.4530796050150295,
            "precision": 0.6043656207366985,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7723553677297202,
            "auditor_fn_violation": 0.006534902266236418,
            "auditor_fp_violation": 0.028501278823482405,
            "ave_precision_score": 0.7727479069337151,
            "fpr": 0.18969298245614036,
            "logloss": 1.1625876048020756,
            "mae": 0.28785893803684315,
            "precision": 0.6943462897526502,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8071543705798363,
            "auditor_fn_violation": 0.011303290117779693,
            "auditor_fp_violation": 0.012294182217343578,
            "ave_precision_score": 0.8062617450558259,
            "fpr": 0.18331503841931943,
            "logloss": 0.9836785467382674,
            "mae": 0.2788390421210966,
            "precision": 0.708041958041958,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7603423083757628,
            "auditor_fn_violation": 0.0410175809502615,
            "auditor_fp_violation": 0.02526425688366703,
            "ave_precision_score": 0.7636051832213058,
            "fpr": 0.14802631578947367,
            "logloss": 2.508876971761824,
            "mae": 0.3082791744562106,
            "precision": 0.7139830508474576,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7981260345710455,
            "auditor_fn_violation": 0.045297598535798324,
            "auditor_fp_violation": 0.013213182549204814,
            "ave_precision_score": 0.7988452455268278,
            "fpr": 0.13830954994511527,
            "logloss": 2.5473644493822603,
            "mae": 0.30359285016287396,
            "precision": 0.7301927194860813,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6243925332494046,
            "auditor_fn_violation": 0.007870164311412783,
            "auditor_fp_violation": 0.01894756823722176,
            "ave_precision_score": 0.6005280085170388,
            "fpr": 0.3048245614035088,
            "logloss": 2.726912146836676,
            "mae": 0.4465885353969051,
            "precision": 0.6017191977077364,
            "recall": 0.8879492600422833
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.633793632055275,
            "auditor_fn_violation": 0.001531295713513057,
            "auditor_fp_violation": 0.0268603374773441,
            "ave_precision_score": 0.6041029432204146,
            "fpr": 0.3336992316136114,
            "logloss": 3.1013072751575934,
            "mae": 0.45321624265609534,
            "precision": 0.5891891891891892,
            "recall": 0.9064449064449065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7679579456614786,
            "auditor_fn_violation": 0.03840501094173066,
            "auditor_fp_violation": 0.025951124965032178,
            "ave_precision_score": 0.7695852161478309,
            "fpr": 0.1425438596491228,
            "logloss": 2.49220476857462,
            "mae": 0.3049162352771837,
            "precision": 0.7245762711864406,
            "recall": 0.7230443974630021
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8066504343300847,
            "auditor_fn_violation": 0.04569696776063407,
            "auditor_fp_violation": 0.011357312434585048,
            "ave_precision_score": 0.8068282521749065,
            "fpr": 0.1350164654226125,
            "logloss": 2.5170451581711575,
            "mae": 0.29866427034385284,
            "precision": 0.7371794871794872,
            "recall": 0.7172557172557172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.754359191279776,
            "auditor_fn_violation": 0.038595100330106456,
            "auditor_fp_violation": 0.01484883906805739,
            "ave_precision_score": 0.7553824379935143,
            "fpr": 0.1524122807017544,
            "logloss": 2.2539968352587865,
            "mae": 0.31216313815432517,
            "precision": 0.717479674796748,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7905709764689374,
            "auditor_fn_violation": 0.04861350415686311,
            "auditor_fp_violation": 0.013726291067827332,
            "ave_precision_score": 0.7911147254999975,
            "fpr": 0.1394072447859495,
            "logloss": 2.303337865164047,
            "mae": 0.3034794758857396,
            "precision": 0.7331932773109243,
            "recall": 0.7255717255717256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7470281293064842,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6726188747411166,
            "fpr": 0.48135964912280704,
            "logloss": 3.1288000515651087,
            "mae": 0.4239550543328126,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7637280318095034,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6886556979628123,
            "fpr": 0.47200878155872666,
            "logloss": 3.1887619771923363,
            "mae": 0.41131881805204273,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5495984949693841,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6434834381917419,
            "fpr": 0.48135964912280704,
            "logloss": 0.8279825017625606,
            "mae": 0.4370470640429279,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5397300154414401,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.666013476201481,
            "fpr": 0.47200878155872666,
            "logloss": 0.81914249758382,
            "mae": 0.42685696584071336,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6672437507917157,
            "auditor_fn_violation": 0.0008113571455064772,
            "auditor_fp_violation": 0.029492866562762263,
            "ave_precision_score": 0.6239555982391054,
            "fpr": 0.21052631578947367,
            "logloss": 3.8417100678864515,
            "mae": 0.3408399713276722,
            "precision": 0.6706689536878216,
            "recall": 0.8266384778012685
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6846364466843771,
            "auditor_fn_violation": 0.008090079440244102,
            "auditor_fp_violation": 0.03336481760396191,
            "ave_precision_score": 0.6359058544622349,
            "fpr": 0.20856201975850713,
            "logloss": 4.0157561786705855,
            "mae": 0.3378019010252051,
            "precision": 0.671280276816609,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6695970256998238,
            "auditor_fn_violation": 0.0012239902080783405,
            "auditor_fp_violation": 0.027627083083563132,
            "ave_precision_score": 0.626982335606056,
            "fpr": 0.21929824561403508,
            "logloss": 3.816250533187707,
            "mae": 0.3317013025934054,
            "precision": 0.6644295302013423,
            "recall": 0.8372093023255814
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.685306869863847,
            "auditor_fn_violation": 0.010246673254357123,
            "auditor_fp_violation": 0.03147576136624717,
            "ave_precision_score": 0.6366601366560644,
            "fpr": 0.2074643249176729,
            "logloss": 4.0177752755109095,
            "mae": 0.32964649881989183,
            "precision": 0.6763698630136986,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5690113786169463,
            "auditor_fn_violation": 0.013327120655762036,
            "auditor_fp_violation": 0.01722665148063782,
            "ave_precision_score": 0.570290359453697,
            "fpr": 0.2807017543859649,
            "logloss": 0.7762278959477091,
            "mae": 0.4663725889897027,
            "precision": 0.5623931623931624,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5606721777178475,
            "auditor_fn_violation": 0.013443909162899285,
            "auditor_fp_violation": 0.018813979016159096,
            "ave_precision_score": 0.5620163056356633,
            "fpr": 0.29747530186608123,
            "logloss": 0.7980593529263803,
            "mae": 0.47336660907541506,
            "precision": 0.5475792988313857,
            "recall": 0.681912681912682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7706726847854649,
            "auditor_fn_violation": 0.0398747264567338,
            "auditor_fp_violation": 0.02840386844103425,
            "ave_precision_score": 0.7715963830999263,
            "fpr": 0.13596491228070176,
            "logloss": 2.46061131126524,
            "mae": 0.30160793026129296,
            "precision": 0.7274725274725274,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8096522079746208,
            "auditor_fn_violation": 0.04859068305830107,
            "auditor_fp_violation": 0.012452454496719693,
            "ave_precision_score": 0.8103841621182276,
            "fpr": 0.1350164654226125,
            "logloss": 2.558010257605262,
            "mae": 0.30108450802534037,
            "precision": 0.7349137931034483,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7417748009820023,
            "auditor_fn_violation": 0.00944419717369534,
            "auditor_fp_violation": 0.02300883187467531,
            "ave_precision_score": 0.73926089727236,
            "fpr": 0.17324561403508773,
            "logloss": 1.7180765921660146,
            "mae": 0.303541718533669,
            "precision": 0.6932038834951456,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7522978078229152,
            "auditor_fn_violation": 0.02124872487111785,
            "auditor_fp_violation": 0.0079748806575958,
            "ave_precision_score": 0.7512126177018664,
            "fpr": 0.1734357848518112,
            "logloss": 1.8260473129380719,
            "mae": 0.31094648202385655,
            "precision": 0.6955684007707129,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7437332106542172,
            "auditor_fn_violation": 0.03946441155743482,
            "auditor_fp_violation": 0.02254425928146106,
            "ave_precision_score": 0.7418763407775303,
            "fpr": 0.16337719298245615,
            "logloss": 2.434769640971225,
            "mae": 0.31017714153552356,
            "precision": 0.7066929133858267,
            "recall": 0.758985200845666
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7713448162014743,
            "auditor_fn_violation": 0.039001257442530766,
            "auditor_fp_violation": 0.017169989533607332,
            "ave_precision_score": 0.7701361996406537,
            "fpr": 0.14928649835345773,
            "logloss": 2.41330171251226,
            "mae": 0.30245433308067043,
            "precision": 0.7258064516129032,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6273887391949191,
            "auditor_fn_violation": 0.03818942175735322,
            "auditor_fp_violation": 0.008497182592015347,
            "ave_precision_score": 0.6201286608753168,
            "fpr": 0.19298245614035087,
            "logloss": 3.5041833971295473,
            "mae": 0.34633575405612727,
            "precision": 0.6685499058380414,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6294537049279716,
            "auditor_fn_violation": 0.046863125897154446,
            "auditor_fp_violation": 0.014709110867178929,
            "ave_precision_score": 0.6226682515153148,
            "fpr": 0.18221734357848518,
            "logloss": 3.75794274039262,
            "mae": 0.3435453980826246,
            "precision": 0.6782945736434108,
            "recall": 0.7276507276507277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.5847814063646004,
            "auditor_fn_violation": 0.03935545788360967,
            "auditor_fp_violation": 0.006184310434400364,
            "ave_precision_score": 0.5728146464030467,
            "fpr": 0.2642543859649123,
            "logloss": 4.228101138315718,
            "mae": 0.376402365106179,
            "precision": 0.6137820512820513,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.5945946013872259,
            "auditor_fn_violation": 0.04451939907483267,
            "auditor_fp_violation": 0.007877875067010456,
            "ave_precision_score": 0.5808313745830733,
            "fpr": 0.25686059275521406,
            "logloss": 4.407572801309961,
            "mae": 0.3826180313588532,
            "precision": 0.6213592233009708,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8069390425137644,
            "auditor_fn_violation": 0.010981139423611884,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8066829188395104,
            "fpr": 0.06469298245614036,
            "logloss": 0.5593184870042643,
            "mae": 0.37283638134402663,
            "precision": 0.8195718654434251,
            "recall": 0.5665961945031712
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8248918487448988,
            "auditor_fn_violation": 0.0014902177361013841,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8249257968944077,
            "fpr": 0.054884742041712405,
            "logloss": 0.5436808091356505,
            "mae": 0.3665738932943763,
            "precision": 0.8493975903614458,
            "recall": 0.5862785862785863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7434537166511184,
            "auditor_fn_violation": 0.00878120247765291,
            "auditor_fp_violation": 0.022062202773448433,
            "ave_precision_score": 0.7409515832009845,
            "fpr": 0.1787280701754386,
            "logloss": 1.6511040483952235,
            "mae": 0.296695146072104,
            "precision": 0.6947565543071161,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7549804238357625,
            "auditor_fn_violation": 0.02463537589772497,
            "auditor_fp_violation": 0.00829653077374722,
            "ave_precision_score": 0.7539800996246766,
            "fpr": 0.1756311745334797,
            "logloss": 1.7379600072996486,
            "mae": 0.3050904299135141,
            "precision": 0.6963946869070209,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8044836165551423,
            "auditor_fn_violation": 0.004293238381365684,
            "auditor_fp_violation": 0.003449326619510052,
            "ave_precision_score": 0.8042525082682916,
            "fpr": 0.0581140350877193,
            "logloss": 0.5632930757216355,
            "mae": 0.37530692690460565,
            "precision": 0.8312101910828026,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8203724237621295,
            "auditor_fn_violation": 0.00714756806963175,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8204405758611827,
            "fpr": 0.050493962678375415,
            "logloss": 0.5536007677183609,
            "mae": 0.37129171552498436,
            "precision": 0.85625,
            "recall": 0.5696465696465697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8054793707841472,
            "auditor_fn_violation": 0.00952069656170023,
            "auditor_fp_violation": 0.0030621827918315167,
            "ave_precision_score": 0.8053468585152714,
            "fpr": 0.0668859649122807,
            "logloss": 0.5591112797222909,
            "mae": 0.37249878351168153,
            "precision": 0.8162650602409639,
            "recall": 0.572938689217759
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8271970317440576,
            "auditor_fn_violation": 0.0001962614476335791,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8271766159645331,
            "fpr": 0.054884742041712405,
            "logloss": 0.5396540471467502,
            "mae": 0.36445311404576547,
            "precision": 0.8525073746312685,
            "recall": 0.6008316008316008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7433364928773046,
            "auditor_fn_violation": 0.00878120247765291,
            "auditor_fp_violation": 0.022062202773448433,
            "ave_precision_score": 0.740812199720067,
            "fpr": 0.1787280701754386,
            "logloss": 1.651478949451487,
            "mae": 0.2967345581742694,
            "precision": 0.6947565543071161,
            "recall": 0.7843551797040169
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7549295936283977,
            "auditor_fn_violation": 0.02463537589772497,
            "auditor_fp_violation": 0.00829653077374722,
            "ave_precision_score": 0.753920976757503,
            "fpr": 0.1756311745334797,
            "logloss": 1.7382439929076836,
            "mae": 0.305123944460934,
            "precision": 0.6963946869070209,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5416350410697918,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6336939532940905,
            "fpr": 0.48135964912280704,
            "logloss": 0.8185045214952877,
            "mae": 0.4375154354462498,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5339458124513047,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6582020503474159,
            "fpr": 0.47200878155872666,
            "logloss": 0.8104606140601173,
            "mae": 0.42730831275525394,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.804251145826664,
            "auditor_fn_violation": 0.01037146248284559,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8040196743397541,
            "fpr": 0.06469298245614036,
            "logloss": 0.5619860136664346,
            "mae": 0.37479311023561057,
            "precision": 0.8190184049079755,
            "recall": 0.5644820295983086
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8203060777345123,
            "auditor_fn_violation": 0.006373932828378504,
            "auditor_fp_violation": 0.0023128175018507667,
            "ave_precision_score": 0.8203881883176065,
            "fpr": 0.05378704720087816,
            "logloss": 0.5514974513719225,
            "mae": 0.3704976480041194,
            "precision": 0.850609756097561,
            "recall": 0.58004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8059590315982077,
            "auditor_fn_violation": 0.010494325136308,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8057167957395659,
            "fpr": 0.06469298245614036,
            "logloss": 0.5606819963987816,
            "mae": 0.37393450212517854,
            "precision": 0.8201219512195121,
            "recall": 0.5687103594080338
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8233939350618358,
            "auditor_fn_violation": 0.0033798046970385217,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8234356433313319,
            "fpr": 0.054884742041712405,
            "logloss": 0.5469891012936184,
            "mae": 0.3684522470645402,
            "precision": 0.8498498498498499,
            "recall": 0.5883575883575883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6565805705900624,
            "auditor_fn_violation": 0.001017673676792409,
            "auditor_fp_violation": 0.028983335331495025,
            "ave_precision_score": 0.6171881381208741,
            "fpr": 0.20942982456140352,
            "logloss": 3.740951431584469,
            "mae": 0.33977715148253,
            "precision": 0.674061433447099,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6760332289357833,
            "auditor_fn_violation": 0.006451524563489442,
            "auditor_fp_violation": 0.03024787481173257,
            "ave_precision_score": 0.6303219050406806,
            "fpr": 0.21185510428100987,
            "logloss": 3.8999741026555306,
            "mae": 0.3372502810419251,
            "precision": 0.6712095400340715,
            "recall": 0.8191268191268192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7757616034101418,
            "auditor_fn_violation": 0.011182819628352063,
            "auditor_fp_violation": 0.023620768892618802,
            "ave_precision_score": 0.7776528034091545,
            "fpr": 0.17105263157894737,
            "logloss": 1.2058657648300128,
            "mae": 0.2880969399925146,
            "precision": 0.7089552238805971,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.797032369336262,
            "auditor_fn_violation": 0.02456919471189505,
            "auditor_fp_violation": 0.0065861690450055,
            "ave_precision_score": 0.7990241620334264,
            "fpr": 0.18111964873765093,
            "logloss": 1.3315072546872273,
            "mae": 0.29887868272052637,
            "precision": 0.698905109489051,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6992206793383309,
            "auditor_fn_violation": 0.037118430325284675,
            "auditor_fp_violation": 0.018428046197498306,
            "ave_precision_score": 0.6992897250242001,
            "fpr": 0.21162280701754385,
            "logloss": 2.568309650536775,
            "mae": 0.34838408397763887,
            "precision": 0.6571936056838366,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7409259815172704,
            "auditor_fn_violation": 0.04119208290448686,
            "auditor_fp_violation": 0.00048502795292676014,
            "ave_precision_score": 0.7415202964497359,
            "fpr": 0.20856201975850713,
            "logloss": 2.538423138082007,
            "mae": 0.3479556012105698,
            "precision": 0.6594982078853047,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6669261312597421,
            "auditor_fn_violation": 0.0011637179629835712,
            "auditor_fp_violation": 0.028791012268712782,
            "ave_precision_score": 0.6242003625909829,
            "fpr": 0.20942982456140352,
            "logloss": 3.825549439204795,
            "mae": 0.34085925439923587,
            "precision": 0.6712564543889845,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6839541089672047,
            "auditor_fn_violation": 0.008090079440244102,
            "auditor_fp_violation": 0.03297424246292089,
            "ave_precision_score": 0.635408586561861,
            "fpr": 0.20965971459934138,
            "logloss": 4.016362808414476,
            "mae": 0.3376936094082439,
            "precision": 0.6701208981001727,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7575817706924396,
            "auditor_fn_violation": 0.02529347947034606,
            "auditor_fp_violation": 0.019049974023898016,
            "ave_precision_score": 0.7594347921224729,
            "fpr": 0.1206140350877193,
            "logloss": 0.5913037932938732,
            "mae": 0.3355858617797989,
            "precision": 0.7505668934240363,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7819418215225096,
            "auditor_fn_violation": 0.02638118993772123,
            "auditor_fp_violation": 0.017991984274883212,
            "ave_precision_score": 0.7831185871744354,
            "fpr": 0.1119648737650933,
            "logloss": 0.5645444742127684,
            "mae": 0.32695134397420794,
            "precision": 0.7792207792207793,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7527836604072475,
            "auditor_fn_violation": 0.038595100330106456,
            "auditor_fp_violation": 0.016509810973904013,
            "ave_precision_score": 0.7537335993819678,
            "fpr": 0.15350877192982457,
            "logloss": 2.260934217353586,
            "mae": 0.3133940063925913,
            "precision": 0.716024340770791,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7892780066394851,
            "auditor_fn_violation": 0.04861350415686311,
            "auditor_fp_violation": 0.011742782018226839,
            "ave_precision_score": 0.7898388145230024,
            "fpr": 0.14270032930845225,
            "logloss": 2.308696163253016,
            "mae": 0.3052997824993762,
            "precision": 0.7286012526096033,
            "recall": 0.7255717255717256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.645094295591497,
            "auditor_fn_violation": 0.036796205630354954,
            "auditor_fp_violation": 0.007667945490149067,
            "ave_precision_score": 0.6450887000924468,
            "fpr": 0.2324561403508772,
            "logloss": 2.8276219660049335,
            "mae": 0.36384867682047445,
            "precision": 0.6382252559726962,
            "recall": 0.7906976744186046
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6857462052027377,
            "auditor_fn_violation": 0.04052114260676281,
            "auditor_fp_violation": 0.006404921757332861,
            "ave_precision_score": 0.6864528532952028,
            "fpr": 0.22722283205268934,
            "logloss": 2.8251547358969766,
            "mae": 0.36424773378854575,
            "precision": 0.6424870466321243,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6715537318514749,
            "auditor_fn_violation": 0.0006954489818626903,
            "auditor_fp_violation": 0.028883427246932825,
            "ave_precision_score": 0.6281464204759997,
            "fpr": 0.21600877192982457,
            "logloss": 3.8383047128161802,
            "mae": 0.3313585183766503,
            "precision": 0.6683501683501684,
            "recall": 0.8393234672304439
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6880911086548709,
            "auditor_fn_violation": 0.0069535887318543784,
            "auditor_fp_violation": 0.03147576136624717,
            "ave_precision_score": 0.6386698242063731,
            "fpr": 0.2074643249176729,
            "logloss": 4.023556433992209,
            "mae": 0.3297459107477874,
            "precision": 0.6763698630136986,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7273638119518733,
            "auditor_fn_violation": 0.039100459923593345,
            "auditor_fp_violation": 0.02080086320585062,
            "ave_precision_score": 0.7255292777630618,
            "fpr": 0.21052631578947367,
            "logloss": 2.5167901249450266,
            "mae": 0.34189548214323956,
            "precision": 0.6631578947368421,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7574504838050131,
            "auditor_fn_violation": 0.04147278241679998,
            "auditor_fp_violation": 0.0047736961682791805,
            "ave_precision_score": 0.7562590927600535,
            "fpr": 0.19758507135016465,
            "logloss": 2.5012739455385202,
            "mae": 0.3369471987911717,
            "precision": 0.6739130434782609,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6733632311054295,
            "auditor_fn_violation": 0.00968064982752866,
            "auditor_fp_violation": 0.03182072493306159,
            "ave_precision_score": 0.627749318289985,
            "fpr": 0.20833333333333334,
            "logloss": 3.886770228570986,
            "mae": 0.33953864523777666,
            "precision": 0.6678321678321678,
            "recall": 0.8076109936575053
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6895805175399077,
            "auditor_fn_violation": 0.012172773972993517,
            "auditor_fp_violation": 0.03297424246292089,
            "ave_precision_score": 0.6382841327040517,
            "fpr": 0.20965971459934138,
            "logloss": 4.095655840086032,
            "mae": 0.33689370252807704,
            "precision": 0.6684027777777778,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7525680988825303,
            "auditor_fn_violation": 0.026220744779496315,
            "auditor_fp_violation": 0.01613016025256764,
            "ave_precision_score": 0.7544289862915896,
            "fpr": 0.10855263157894737,
            "logloss": 0.6044800717143194,
            "mae": 0.3398460445056723,
            "precision": 0.7659574468085106,
            "recall": 0.6849894291754757
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.784461535007266,
            "auditor_fn_violation": 0.028852714911990443,
            "auditor_fp_violation": 0.011081612335026681,
            "ave_precision_score": 0.7856579364823668,
            "fpr": 0.10208562019758508,
            "logloss": 0.5697132761410623,
            "mae": 0.3277989115796546,
            "precision": 0.7876712328767124,
            "recall": 0.7172557172557172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7714754646284466,
            "auditor_fn_violation": 0.005438411038166237,
            "auditor_fp_violation": 0.028079167166207095,
            "ave_precision_score": 0.7715417820544105,
            "fpr": 0.1875,
            "logloss": 1.1470485331953713,
            "mae": 0.2878353629267565,
            "precision": 0.6968085106382979,
            "recall": 0.8308668076109936
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8073657671241526,
            "auditor_fn_violation": 0.010709941555166583,
            "auditor_fp_violation": 0.010976948408342485,
            "ave_precision_score": 0.8069537573821621,
            "fpr": 0.1756311745334797,
            "logloss": 0.9542029872078378,
            "mae": 0.27897491694936905,
            "precision": 0.7158081705150977,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7721768853074757,
            "auditor_fn_violation": 0.011736860650569341,
            "auditor_fp_violation": 0.024045378252008157,
            "ave_precision_score": 0.7740514497200972,
            "fpr": 0.18201754385964913,
            "logloss": 1.2557416541844746,
            "mae": 0.2943957376136353,
            "precision": 0.6959706959706959,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7835230458835494,
            "auditor_fn_violation": 0.024601144249881902,
            "auditor_fp_violation": 0.010749751104076785,
            "ave_precision_score": 0.7852157149600123,
            "fpr": 0.1942919868276619,
            "logloss": 1.4153882882216045,
            "mae": 0.30910012894783084,
            "precision": 0.6856127886323268,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7652760970342802,
            "auditor_fn_violation": 0.04044035829531547,
            "auditor_fp_violation": 0.02317118251208888,
            "ave_precision_score": 0.7663780868159575,
            "fpr": 0.10855263157894737,
            "logloss": 2.390869448317846,
            "mae": 0.31053240698462625,
            "precision": 0.754950495049505,
            "recall": 0.6448202959830867
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8001940695957113,
            "auditor_fn_violation": 0.05346070549144096,
            "auditor_fp_violation": 0.015296249968090266,
            "ave_precision_score": 0.8007394615550489,
            "fpr": 0.1119648737650933,
            "logloss": 2.426157350906545,
            "mae": 0.30660022935251335,
            "precision": 0.7536231884057971,
            "recall": 0.6486486486486487
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6939551623310348,
            "auditor_fn_violation": 0.022068914357776054,
            "auditor_fp_violation": 0.026415697558246413,
            "ave_precision_score": 0.6945059646544658,
            "fpr": 0.18859649122807018,
            "logloss": 0.6550025589268729,
            "mae": 0.46138218994874797,
            "precision": 0.6177777777777778,
            "recall": 0.587737843551797
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7230466381655057,
            "auditor_fn_violation": 0.019927383264375587,
            "auditor_fp_violation": 0.022673780409976266,
            "ave_precision_score": 0.7235939486517418,
            "fpr": 0.16245883644346873,
            "logloss": 0.6518074320657734,
            "mae": 0.4579413900695972,
            "precision": 0.6666666666666666,
            "recall": 0.6153846153846154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8041904346885289,
            "auditor_fn_violation": 0.004293238381365684,
            "auditor_fp_violation": 0.005872097670143471,
            "ave_precision_score": 0.8039544076777914,
            "fpr": 0.05921052631578947,
            "logloss": 0.5668545797864527,
            "mae": 0.37612139723639476,
            "precision": 0.8285714285714286,
            "recall": 0.5517970401691332
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8168836327670964,
            "auditor_fn_violation": 0.007590297381735367,
            "auditor_fp_violation": 0.006080718862481814,
            "ave_precision_score": 0.8170221293528951,
            "fpr": 0.050493962678375415,
            "logloss": 0.5561913998155267,
            "mae": 0.3714957296864654,
            "precision": 0.8566978193146417,
            "recall": 0.5717255717255717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8065037582415113,
            "auditor_fn_violation": 0.010494325136308,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8062830217980783,
            "fpr": 0.06469298245614036,
            "logloss": 0.5606192186286939,
            "mae": 0.3725990166871302,
            "precision": 0.8201219512195121,
            "recall": 0.5687103594080338
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8251719123961638,
            "auditor_fn_violation": 0.0033798046970385217,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8252446003570377,
            "fpr": 0.054884742041712405,
            "logloss": 0.5461459753646685,
            "mae": 0.3669784207031965,
            "precision": 0.8498498498498499,
            "recall": 0.5883575883575883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6945381966243525,
            "auditor_fn_violation": 0.002485071028522689,
            "auditor_fp_violation": 0.021437777244934664,
            "ave_precision_score": 0.6951376851213732,
            "fpr": 0.19517543859649122,
            "logloss": 0.6553320730800127,
            "mae": 0.4621451802290322,
            "precision": 0.6147186147186147,
            "recall": 0.6004228329809725
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7235779845644953,
            "auditor_fn_violation": 0.004032488115912931,
            "auditor_fp_violation": 0.02719219870829398,
            "ave_precision_score": 0.7240960313953346,
            "fpr": 0.1778265642151482,
            "logloss": 0.6533038282267647,
            "mae": 0.45928217784532793,
            "precision": 0.6493506493506493,
            "recall": 0.6237006237006237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6672651358386854,
            "auditor_fn_violation": 0.0008113571455064772,
            "auditor_fp_violation": 0.029492866562762263,
            "ave_precision_score": 0.6239681736325866,
            "fpr": 0.21052631578947367,
            "logloss": 3.841201673865776,
            "mae": 0.34083441170023115,
            "precision": 0.6706689536878216,
            "recall": 0.8266384778012685
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.6839697494977421,
            "auditor_fn_violation": 0.008090079440244102,
            "auditor_fp_violation": 0.03336481760396191,
            "ave_precision_score": 0.6354543754124863,
            "fpr": 0.20856201975850713,
            "logloss": 4.015324466457725,
            "mae": 0.3377956391848127,
            "precision": 0.671280276816609,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8028868561169213,
            "auditor_fn_violation": 0.02917640295241275,
            "auditor_fp_violation": 0.02306378132118451,
            "ave_precision_score": 0.8033523490781966,
            "fpr": 0.10855263157894737,
            "logloss": 0.5757516493031521,
            "mae": 0.3243229065656921,
            "precision": 0.771889400921659,
            "recall": 0.7082452431289641
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.806169353881258,
            "auditor_fn_violation": 0.02723013480422921,
            "auditor_fp_violation": 0.01356036045235239,
            "ave_precision_score": 0.8072363122869611,
            "fpr": 0.10098792535675083,
            "logloss": 0.5473889187495423,
            "mae": 0.3181619665067563,
            "precision": 0.7855477855477856,
            "recall": 0.7006237006237006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8058883080383994,
            "auditor_fn_violation": 0.010494325136308,
            "auditor_fp_violation": 0.006528993326139952,
            "ave_precision_score": 0.8056466625857752,
            "fpr": 0.06469298245614036,
            "logloss": 0.5605916755388723,
            "mae": 0.3740284815185556,
            "precision": 0.8201219512195121,
            "recall": 0.5687103594080338
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8232429289242722,
            "auditor_fn_violation": 0.0033798046970385217,
            "auditor_fp_violation": 0.00500344625124448,
            "ave_precision_score": 0.8232846583019625,
            "fpr": 0.054884742041712405,
            "logloss": 0.5470565147508091,
            "mae": 0.36858983463009676,
            "precision": 0.8498498498498499,
            "recall": 0.5883575883575883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6381013041159809,
            "auditor_fn_violation": 0.009664422684618526,
            "auditor_fp_violation": 0.014988710386444474,
            "ave_precision_score": 0.6392582036734997,
            "fpr": 0.08662280701754387,
            "logloss": 0.7217003427041921,
            "mae": 0.47089313913466757,
            "precision": 0.6638297872340425,
            "recall": 0.3298097251585624
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6341897346936523,
            "auditor_fn_violation": 0.0018576374229502593,
            "auditor_fp_violation": 0.020478390728307767,
            "ave_precision_score": 0.6348601059166219,
            "fpr": 0.09549945115257959,
            "logloss": 0.7391864869756543,
            "mae": 0.4769446523946674,
            "precision": 0.6297872340425532,
            "recall": 0.3076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7424790713631568,
            "auditor_fn_violation": 0.009404788398056458,
            "auditor_fp_violation": 0.02188486592335052,
            "ave_precision_score": 0.7397504975554628,
            "fpr": 0.17543859649122806,
            "logloss": 1.6670597433438084,
            "mae": 0.2957812630590146,
            "precision": 0.6981132075471698,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.759692831801228,
            "auditor_fn_violation": 0.023727096174955675,
            "auditor_fp_violation": 0.004589896101906929,
            "ave_precision_score": 0.7579904611903387,
            "fpr": 0.17453347969264543,
            "logloss": 1.7066356010186543,
            "mae": 0.30397541735126077,
            "precision": 0.6994328922495274,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8093495497085589,
            "auditor_fn_violation": 0.010494325136308,
            "auditor_fp_violation": 0.005802162010949928,
            "ave_precision_score": 0.8091129677752567,
            "fpr": 0.06359649122807018,
            "logloss": 0.5622889345850475,
            "mae": 0.37274729052819966,
            "precision": 0.8226299694189603,
            "recall": 0.5687103594080338
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8210542928538248,
            "auditor_fn_violation": 0.005723531519360279,
            "auditor_fp_violation": 0.004661373905496135,
            "ave_precision_score": 0.8212805994440975,
            "fpr": 0.05598243688254665,
            "logloss": 0.5502262794870305,
            "mae": 0.3679787858290154,
            "precision": 0.8463855421686747,
            "recall": 0.5841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6788817329938688,
            "auditor_fn_violation": 0.002772523274359264,
            "auditor_fp_violation": 0.027392299084841948,
            "ave_precision_score": 0.6346606781394579,
            "fpr": 0.22587719298245615,
            "logloss": 3.793248235212986,
            "mae": 0.33549306771537724,
            "precision": 0.6622950819672131,
            "recall": 0.854122621564482
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6898878911797071,
            "auditor_fn_violation": 0.0083593684032762,
            "auditor_fp_violation": 0.034628443060271116,
            "ave_precision_score": 0.6399548635364537,
            "fpr": 0.21405049396267836,
            "logloss": 4.030695443763441,
            "mae": 0.33093046907639145,
            "precision": 0.6760797342192691,
            "recall": 0.8461538461538461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7455579461442146,
            "auditor_fn_violation": 0.011055320648343905,
            "auditor_fp_violation": 0.0211855093314151,
            "ave_precision_score": 0.7434636288738627,
            "fpr": 0.17214912280701755,
            "logloss": 1.6007251712133246,
            "mae": 0.29409836246867715,
            "precision": 0.7015209125475285,
            "recall": 0.7801268498942917
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7573287604257722,
            "auditor_fn_violation": 0.02717536416768031,
            "auditor_fp_violation": 0.004314196002348559,
            "ave_precision_score": 0.7564395270455266,
            "fpr": 0.1756311745334797,
            "logloss": 1.681460532830964,
            "mae": 0.30334402975047176,
            "precision": 0.6992481203007519,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8035836096137441,
            "auditor_fn_violation": 0.02670524090352732,
            "auditor_fp_violation": 0.02359579187147824,
            "ave_precision_score": 0.804068448896498,
            "fpr": 0.10964912280701754,
            "logloss": 0.5713050001214129,
            "mae": 0.3236135872134024,
            "precision": 0.7727272727272727,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.806765129436032,
            "auditor_fn_violation": 0.02762037558964014,
            "auditor_fp_violation": 0.013580782681949306,
            "ave_precision_score": 0.8078209429044362,
            "fpr": 0.10428100987925357,
            "logloss": 0.5443469374601402,
            "mae": 0.3174895025413337,
            "precision": 0.7806004618937644,
            "recall": 0.7027027027027027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7490697013950803,
            "auditor_fn_violation": 0.009574014316976374,
            "auditor_fp_violation": 0.01832314270870799,
            "ave_precision_score": 0.7466148159897218,
            "fpr": 0.16557017543859648,
            "logloss": 1.6041846099251087,
            "mae": 0.29334469129342783,
            "precision": 0.7084942084942085,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7621454482577272,
            "auditor_fn_violation": 0.02439575436282352,
            "auditor_fp_violation": 0.007091619227529168,
            "ave_precision_score": 0.7615782805014595,
            "fpr": 0.1690450054884742,
            "logloss": 1.641574904750785,
            "mae": 0.3014966989658622,
            "precision": 0.7055449330783938,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7312920550067121,
            "auditor_fn_violation": 0.03938559400615705,
            "auditor_fp_violation": 0.0203737561443472,
            "ave_precision_score": 0.7319431889129768,
            "fpr": 0.1337719298245614,
            "logloss": 2.974691349295409,
            "mae": 0.31153072765614775,
            "precision": 0.7336244541484717,
            "recall": 0.7103594080338267
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7652177634934741,
            "auditor_fn_violation": 0.04435052294547356,
            "auditor_fp_violation": 0.010537870472008782,
            "ave_precision_score": 0.7653002599661638,
            "fpr": 0.132821075740944,
            "logloss": 2.8635812841648485,
            "mae": 0.30663637085358936,
            "precision": 0.7369565217391304,
            "recall": 0.7047817047817048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7534911968455338,
            "auditor_fn_violation": 0.026053837023849273,
            "auditor_fp_violation": 0.01796846900851217,
            "ave_precision_score": 0.7553347429042229,
            "fpr": 0.10855263157894737,
            "logloss": 0.6029083797005514,
            "mae": 0.33913124463054756,
            "precision": 0.7670588235294118,
            "recall": 0.6892177589852009
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7835239500873954,
            "auditor_fn_violation": 0.02823198103110288,
            "auditor_fp_violation": 0.010251959257651959,
            "ave_precision_score": 0.7847220333571728,
            "fpr": 0.10537870472008781,
            "logloss": 0.5717442262727295,
            "mae": 0.3290047565688257,
            "precision": 0.7832957110609481,
            "recall": 0.7214137214137214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5696777932557973,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6499182125666536,
            "fpr": 0.48135964912280704,
            "logloss": 0.8962521862990998,
            "mae": 0.43186075188088835,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5579331593339704,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6659734918249026,
            "fpr": 0.47200878155872666,
            "logloss": 0.8689645542489,
            "mae": 0.42145378503265546,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.778118937682212,
            "auditor_fn_violation": 0.011458681057824265,
            "auditor_fp_violation": 0.025309215521720024,
            "ave_precision_score": 0.7795936483762741,
            "fpr": 0.1699561403508772,
            "logloss": 1.1697425481647559,
            "mae": 0.28617288762714566,
            "precision": 0.7091932457786116,
            "recall": 0.7991543340380549
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8020736168851189,
            "auditor_fn_violation": 0.026289905543473057,
            "auditor_fp_violation": 0.007903402854006593,
            "ave_precision_score": 0.8035797829960214,
            "fpr": 0.17233809001097694,
            "logloss": 1.284311011418062,
            "mae": 0.2957198411408569,
            "precision": 0.7087198515769945,
            "recall": 0.7941787941787942
        }
    }
]