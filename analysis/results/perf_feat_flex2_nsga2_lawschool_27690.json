[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.98894603901598,
            "mae": 0.5208333333333334,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.16034455890474,
            "mae": 0.5257958287596048,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.98894603901598,
            "mae": 0.5208333333333334,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.16034455890474,
            "mae": 0.5257958287596048,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6309797750047555,
            "auditor_fn_violation": 0.06519852262234534,
            "auditor_fp_violation": 0.09913585451041793,
            "ave_precision_score": 0.6326040161469921,
            "fpr": 0.3092105263157895,
            "logloss": 0.6879451141421494,
            "mae": 0.4971963613571828,
            "precision": 0.573373676248109,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.595370522218972,
            "auditor_fn_violation": 0.09013014215033609,
            "auditor_fp_violation": 0.09369028743342685,
            "ave_precision_score": 0.5974023177142413,
            "fpr": 0.32491767288693746,
            "logloss": 0.6916438149760084,
            "mae": 0.49903355733492505,
            "precision": 0.5474006116207951,
            "recall": 0.7473903966597077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6318049730092669,
            "auditor_fn_violation": 0.06530009233610343,
            "auditor_fp_violation": 0.09450650367337109,
            "ave_precision_score": 0.6331863069339049,
            "fpr": 0.2982456140350877,
            "logloss": 0.6876295658326625,
            "mae": 0.49699810153821056,
            "precision": 0.5789473684210527,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5845384369358698,
            "auditor_fn_violation": 0.08684851582032638,
            "auditor_fp_violation": 0.08929442614953043,
            "ave_precision_score": 0.5861133464143704,
            "fpr": 0.3194291986827662,
            "logloss": 0.6918531021433554,
            "mae": 0.49908994296903014,
            "precision": 0.5453125,
            "recall": 0.7286012526096033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6176359108663645,
            "auditor_fn_violation": 0.06834949215143121,
            "auditor_fp_violation": 0.10223212493476254,
            "ave_precision_score": 0.6189109012854106,
            "fpr": 0.30701754385964913,
            "logloss": 0.687749864570755,
            "mae": 0.49705343843813526,
            "precision": 0.5776772247360482,
            "recall": 0.8063157894736842
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5822660005012233,
            "auditor_fn_violation": 0.08610144166977948,
            "auditor_fp_violation": 0.09374618855958045,
            "ave_precision_score": 0.5838397199672156,
            "fpr": 0.32711306256860595,
            "logloss": 0.6918411154014711,
            "mae": 0.49907669981146224,
            "precision": 0.5422427035330261,
            "recall": 0.7369519832985386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7443972136256631,
            "auditor_fn_violation": 0.004799168975069254,
            "auditor_fp_violation": 0.009394194869324368,
            "ave_precision_score": 0.6549752041684724,
            "fpr": 0.40460526315789475,
            "logloss": 4.946699183817971,
            "mae": 0.4121825854833189,
            "precision": 0.5281329923273658,
            "recall": 0.8694736842105263
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.7450890126439982,
            "auditor_fn_violation": 0.007990943444653495,
            "auditor_fp_violation": 0.0031101353823637175,
            "ave_precision_score": 0.6612447600883322,
            "fpr": 0.4083424807903403,
            "logloss": 4.6212376155140245,
            "mae": 0.4088302886381369,
            "precision": 0.5230769230769231,
            "recall": 0.8517745302713987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7156390446824039,
            "auditor_fn_violation": 0.008222530009233613,
            "auditor_fp_violation": 0.02354570637119116,
            "ave_precision_score": 0.6938021042187409,
            "fpr": 0.35526315789473684,
            "logloss": 0.8330017312015545,
            "mae": 0.4224455036557884,
            "precision": 0.5725593667546174,
            "recall": 0.9136842105263158
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.729746179542022,
            "auditor_fn_violation": 0.012487138178926549,
            "auditor_fp_violation": 0.019006382892222617,
            "ave_precision_score": 0.7071171100177907,
            "fpr": 0.3611416026344676,
            "logloss": 0.8179263310281234,
            "mae": 0.42025620853436374,
            "precision": 0.5716145833333334,
            "recall": 0.9164926931106472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6175323179288699,
            "auditor_fn_violation": 0.06834949215143121,
            "auditor_fp_violation": 0.10153207675940425,
            "ave_precision_score": 0.6188139409542125,
            "fpr": 0.3081140350877193,
            "logloss": 0.6877650053885438,
            "mae": 0.4970629733513322,
            "precision": 0.5768072289156626,
            "recall": 0.8063157894736842
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.5824199041194928,
            "auditor_fn_violation": 0.08610144166977948,
            "auditor_fp_violation": 0.09302201487986339,
            "ave_precision_score": 0.5839934382604013,
            "fpr": 0.32821075740944017,
            "logloss": 0.691837543705971,
            "mae": 0.4990771370321414,
            "precision": 0.5414110429447853,
            "recall": 0.7369519832985386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6285615903659272,
            "auditor_fn_violation": 0.06835641735918745,
            "auditor_fp_violation": 0.09178660323577827,
            "ave_precision_score": 0.6302310007426344,
            "fpr": 0.2883771929824561,
            "logloss": 0.6875821763428487,
            "mae": 0.4969781653857545,
            "precision": 0.5858267716535434,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.59318581835153,
            "auditor_fn_violation": 0.09090242432436768,
            "auditor_fp_violation": 0.08926393462617394,
            "ave_precision_score": 0.5952279843274931,
            "fpr": 0.31284302963776073,
            "logloss": 0.6916882751557739,
            "mae": 0.4990147408159321,
            "precision": 0.5539906103286385,
            "recall": 0.7390396659707724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6298957544728431,
            "auditor_fn_violation": 0.06518005540166205,
            "auditor_fp_violation": 0.09450650367337109,
            "ave_precision_score": 0.6315239845959968,
            "fpr": 0.2982456140350877,
            "logloss": 0.6877140936819276,
            "mae": 0.49705906189455273,
            "precision": 0.5802469135802469,
            "recall": 0.791578947368421
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.593879865818024,
            "auditor_fn_violation": 0.09163804028242153,
            "auditor_fp_violation": 0.09037687522868645,
            "ave_precision_score": 0.595919689952175,
            "fpr": 0.31613611416026344,
            "logloss": 0.6916656426356554,
            "mae": 0.4990201324518897,
            "precision": 0.5527950310559007,
            "recall": 0.7432150313152401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6821396300747342,
            "auditor_fn_violation": 0.026061865189289022,
            "auditor_fp_violation": 0.031805773013770126,
            "ave_precision_score": 0.6829542534646579,
            "fpr": 0.16228070175438597,
            "logloss": 0.6344734294548088,
            "mae": 0.45158716529738485,
            "precision": 0.6775599128540305,
            "recall": 0.6547368421052632
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7009612195639672,
            "auditor_fn_violation": 0.04016783960363821,
            "auditor_fp_violation": 0.02862137659064114,
            "ave_precision_score": 0.7019502169208266,
            "fpr": 0.14709110867178923,
            "logloss": 0.6293759696450489,
            "mae": 0.4480590568252243,
            "precision": 0.6933638443935927,
            "recall": 0.6325678496868476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6301361100705949,
            "auditor_fn_violation": 0.06445521698984304,
            "auditor_fp_violation": 0.09577863422859209,
            "ave_precision_score": 0.6317414565674311,
            "fpr": 0.30153508771929827,
            "logloss": 0.6877612811036002,
            "mae": 0.49708750576042293,
            "precision": 0.5782208588957055,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.594331603814708,
            "auditor_fn_violation": 0.09163804028242153,
            "auditor_fp_violation": 0.09223177623287392,
            "ave_precision_score": 0.5963688119142965,
            "fpr": 0.3216245883644347,
            "logloss": 0.6916597631681698,
            "mae": 0.4990226086617563,
            "precision": 0.5485362095531587,
            "recall": 0.7432150313152401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6298453876896832,
            "auditor_fn_violation": 0.06590489381348107,
            "auditor_fp_violation": 0.09365841663655707,
            "ave_precision_score": 0.6314988239882178,
            "fpr": 0.29605263157894735,
            "logloss": 0.6876653488100025,
            "mae": 0.49702943302690983,
            "precision": 0.5813953488372093,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5938541060719417,
            "auditor_fn_violation": 0.0935286420437749,
            "auditor_fp_violation": 0.09000589502784892,
            "ave_precision_score": 0.5958948417261405,
            "fpr": 0.3150384193194292,
            "logloss": 0.6916725074579954,
            "mae": 0.4990176982793274,
            "precision": 0.5529595015576324,
            "recall": 0.7411273486430062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6015254189158685,
            "auditor_fn_violation": 0.05319482917820868,
            "auditor_fp_violation": 0.0488352603476655,
            "ave_precision_score": 0.6033525469424137,
            "fpr": 0.22587719298245615,
            "logloss": 0.6855138835983215,
            "mae": 0.4956565987514822,
            "precision": 0.6149532710280374,
            "recall": 0.6926315789473684
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5773091236704699,
            "auditor_fn_violation": 0.07074746372909166,
            "auditor_fp_violation": 0.0503770785055088,
            "ave_precision_score": 0.5790422706094999,
            "fpr": 0.2579582875960483,
            "logloss": 0.6900080926666623,
            "mae": 0.49788910994545427,
            "precision": 0.567219152854512,
            "recall": 0.6430062630480167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7550575518482473,
            "auditor_fn_violation": 0.011890581717451523,
            "auditor_fp_violation": 0.018033140631900115,
            "ave_precision_score": 0.5413177091115782,
            "fpr": 0.4100877192982456,
            "logloss": 14.973951159431008,
            "mae": 0.44207680483528394,
            "precision": 0.5466666666666666,
            "recall": 0.9494736842105264
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7581480598117276,
            "auditor_fn_violation": 0.01568855716148489,
            "auditor_fp_violation": 0.026161727039882926,
            "ave_precision_score": 0.5524366937358717,
            "fpr": 0.3951701427003293,
            "logloss": 14.483148723420477,
            "mae": 0.4333518670200657,
            "precision": 0.5533498759305211,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7559680063123273,
            "auditor_fn_violation": 0.012927054478301015,
            "auditor_fp_violation": 0.02031143361837089,
            "ave_precision_score": 0.531686672822407,
            "fpr": 0.43969298245614036,
            "logloss": 15.908540425305734,
            "mae": 0.461599119955249,
            "precision": 0.5315420560747663,
            "recall": 0.9578947368421052
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7575534355709361,
            "auditor_fn_violation": 0.014093576766452245,
            "auditor_fp_violation": 0.0256128796194658,
            "ave_precision_score": 0.5391299837643062,
            "fpr": 0.424807903402854,
            "logloss": 15.585234735756616,
            "mae": 0.4524428124256375,
            "precision": 0.539833531510107,
            "recall": 0.9478079331941545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6819862848216798,
            "auditor_fn_violation": 0.029379039704524473,
            "auditor_fp_violation": 0.031339074230197925,
            "ave_precision_score": 0.68278765980538,
            "fpr": 0.16337719298245615,
            "logloss": 0.6352341277301854,
            "mae": 0.451701929465982,
            "precision": 0.6725274725274726,
            "recall": 0.6442105263157895
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7011527928070636,
            "auditor_fn_violation": 0.04190031830858747,
            "auditor_fp_violation": 0.02854006586169045,
            "ave_precision_score": 0.7020877020436462,
            "fpr": 0.14489571899012074,
            "logloss": 0.6302012079945128,
            "mae": 0.44814092351039864,
            "precision": 0.6944444444444444,
            "recall": 0.6263048016701461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7559680063123273,
            "auditor_fn_violation": 0.012927054478301015,
            "auditor_fp_violation": 0.02031143361837089,
            "ave_precision_score": 0.531686672822407,
            "fpr": 0.43969298245614036,
            "logloss": 15.90854113996139,
            "mae": 0.4615994315398367,
            "precision": 0.5315420560747663,
            "recall": 0.9578947368421052
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7575534355709361,
            "auditor_fn_violation": 0.014093576766452245,
            "auditor_fp_violation": 0.0256128796194658,
            "ave_precision_score": 0.5391299837643062,
            "fpr": 0.424807903402854,
            "logloss": 15.585231982835605,
            "mae": 0.45244207194751757,
            "precision": 0.539833531510107,
            "recall": 0.9478079331941545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7400093352585526,
            "auditor_fn_violation": 0.00907663896583564,
            "auditor_fp_violation": 0.005126159219559198,
            "ave_precision_score": 0.6522799575339906,
            "fpr": 0.3815789473684211,
            "logloss": 4.948517851699161,
            "mae": 0.4351191461216985,
            "precision": 0.5328859060402684,
            "recall": 0.8357894736842105
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7409021550988285,
            "auditor_fn_violation": 0.0031395447430958715,
            "auditor_fp_violation": 0.005247082977598891,
            "ave_precision_score": 0.663031266195584,
            "fpr": 0.38748627881448955,
            "logloss": 4.449622838732148,
            "mae": 0.4341326956887669,
            "precision": 0.5280748663101604,
            "recall": 0.824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6309417835579804,
            "auditor_fn_violation": 0.06753924284395199,
            "auditor_fp_violation": 0.08306485607611708,
            "ave_precision_score": 0.6323228558447682,
            "fpr": 0.28399122807017546,
            "logloss": 0.687451184993392,
            "mae": 0.49688609829989444,
            "precision": 0.5888888888888889,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5843759373204127,
            "auditor_fn_violation": 0.08777433777376487,
            "auditor_fp_violation": 0.08632658454283045,
            "ave_precision_score": 0.5859237152266061,
            "fpr": 0.3106476399560922,
            "logloss": 0.6918903897368861,
            "mae": 0.49908334828103545,
            "precision": 0.5500794912559619,
            "recall": 0.7223382045929019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6287927305570897,
            "auditor_fn_violation": 0.06553324099722992,
            "auditor_fp_violation": 0.09178660323577827,
            "ave_precision_score": 0.6304606691516709,
            "fpr": 0.2883771929824561,
            "logloss": 0.6876066816023235,
            "mae": 0.4969933422837864,
            "precision": 0.5871271585557299,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5931474660852609,
            "auditor_fn_violation": 0.09090242432436768,
            "auditor_fp_violation": 0.08963491482701143,
            "ave_precision_score": 0.5951957695986263,
            "fpr": 0.31394072447859495,
            "logloss": 0.6916839661966262,
            "mae": 0.49901584445056224,
            "precision": 0.553125,
            "recall": 0.7390396659707724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.681977901407137,
            "auditor_fn_violation": 0.029379039704524473,
            "auditor_fp_violation": 0.031339074230197925,
            "ave_precision_score": 0.682779292796482,
            "fpr": 0.16337719298245615,
            "logloss": 0.6352272765062792,
            "mae": 0.4517005463702637,
            "precision": 0.6725274725274726,
            "recall": 0.6442105263157895
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7011957278710086,
            "auditor_fn_violation": 0.04190031830858747,
            "auditor_fp_violation": 0.02854006586169045,
            "ave_precision_score": 0.7021304663815071,
            "fpr": 0.14489571899012074,
            "logloss": 0.6301967042121899,
            "mae": 0.44814102554491403,
            "precision": 0.6944444444444444,
            "recall": 0.6263048016701461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6323346887844261,
            "auditor_fn_violation": 0.06306555863342567,
            "auditor_fp_violation": 0.09802681761612271,
            "ave_precision_score": 0.6336223671405092,
            "fpr": 0.3157894736842105,
            "logloss": 0.6870578912704968,
            "mae": 0.4966588468013102,
            "precision": 0.5752212389380531,
            "recall": 0.8210526315789474
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5827811026317924,
            "auditor_fn_violation": 0.08416500713845393,
            "auditor_fp_violation": 0.093418404683498,
            "ave_precision_score": 0.5842895753638018,
            "fpr": 0.33260153677277715,
            "logloss": 0.6913190146364624,
            "mae": 0.4987732087610582,
            "precision": 0.545045045045045,
            "recall": 0.7578288100208769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7414081189643523,
            "auditor_fn_violation": 0.000997229916897507,
            "auditor_fp_violation": 0.008618872696615692,
            "ave_precision_score": 0.6519891094015648,
            "fpr": 0.4100877192982456,
            "logloss": 4.9999711851159105,
            "mae": 0.4291946546811807,
            "precision": 0.527180783817952,
            "recall": 0.8778947368421053
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7422852872308887,
            "auditor_fn_violation": 0.006450962373587494,
            "auditor_fp_violation": 0.005468146521933581,
            "ave_precision_score": 0.6584418368728738,
            "fpr": 0.41712403951701427,
            "logloss": 4.678402370880146,
            "mae": 0.4274093815249224,
            "precision": 0.5220125786163522,
            "recall": 0.8663883089770354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6202193522771584,
            "auditor_fn_violation": 0.02003462603878116,
            "auditor_fp_violation": 0.03809115179252479,
            "ave_precision_score": 0.6205198750723584,
            "fpr": 0.125,
            "logloss": 1.5682830737947013,
            "mae": 0.3917862647120863,
            "precision": 0.6850828729281768,
            "recall": 0.5221052631578947
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.5981021275031322,
            "auditor_fn_violation": 0.017583742199835467,
            "auditor_fp_violation": 0.03527106964263935,
            "ave_precision_score": 0.5967147053700324,
            "fpr": 0.141602634467618,
            "logloss": 1.869438785873576,
            "mae": 0.40985597124922696,
            "precision": 0.6614173228346457,
            "recall": 0.5260960334029228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6279453911269228,
            "auditor_fn_violation": 0.01174284395198523,
            "auditor_fp_violation": 0.02883245011843109,
            "ave_precision_score": 0.6299263360456018,
            "fpr": 0.28728070175438597,
            "logloss": 0.6322790930665164,
            "mae": 0.4252836484535548,
            "precision": 0.6152716593245228,
            "recall": 0.8821052631578947
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6392715419133447,
            "auditor_fn_violation": 0.01657083798344979,
            "auditor_fp_violation": 0.03061348944993292,
            "ave_precision_score": 0.6419748482058911,
            "fpr": 0.2645444566410538,
            "logloss": 0.6375629740445101,
            "mae": 0.4291751876383464,
            "precision": 0.6292307692307693,
            "recall": 0.8538622129436325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7559680063123273,
            "auditor_fn_violation": 0.012927054478301015,
            "auditor_fp_violation": 0.02031143361837089,
            "ave_precision_score": 0.531686672822407,
            "fpr": 0.43969298245614036,
            "logloss": 15.908543206234219,
            "mae": 0.4616040493149245,
            "precision": 0.5315420560747663,
            "recall": 0.9578947368421052
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7575534355709361,
            "auditor_fn_violation": 0.014093576766452245,
            "auditor_fp_violation": 0.0256128796194658,
            "ave_precision_score": 0.5391299837643062,
            "fpr": 0.424807903402854,
            "logloss": 15.58525403485207,
            "mae": 0.4524482904261737,
            "precision": 0.539833531510107,
            "recall": 0.9478079331941545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7541390058094387,
            "auditor_fn_violation": 0.005145429362880883,
            "auditor_fp_violation": 0.022454233409610985,
            "ave_precision_score": 0.6745672362404462,
            "fpr": 0.1425438596491228,
            "logloss": 4.399395719584726,
            "mae": 0.39726242605434453,
            "precision": 0.7058823529411765,
            "recall": 0.6568421052631579
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7466893963413987,
            "auditor_fn_violation": 0.021628484149882325,
            "auditor_fp_violation": 0.018071309509289757,
            "ave_precision_score": 0.6771088097648384,
            "fpr": 0.12952799121844127,
            "logloss": 3.9306615956398216,
            "mae": 0.3976089835348595,
            "precision": 0.7170263788968825,
            "recall": 0.6242171189979123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7534129921516515,
            "auditor_fn_violation": 0.005320867959372119,
            "auditor_fp_violation": 0.021636255971737125,
            "ave_precision_score": 0.6738319785552405,
            "fpr": 0.14144736842105263,
            "logloss": 4.396440114918752,
            "mae": 0.3958236616731228,
            "precision": 0.7068181818181818,
            "recall": 0.6547368421052632
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7473194585932108,
            "auditor_fn_violation": 0.022224310159520956,
            "auditor_fp_violation": 0.01896572752774729,
            "ave_precision_score": 0.6777045588873842,
            "fpr": 0.1251372118551043,
            "logloss": 3.9281194353227127,
            "mae": 0.3963024901745206,
            "precision": 0.7233009708737864,
            "recall": 0.6221294363256785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6201427397981875,
            "auditor_fn_violation": 0.02003462603878116,
            "auditor_fp_violation": 0.03809115179252479,
            "ave_precision_score": 0.6204432963510746,
            "fpr": 0.125,
            "logloss": 1.5689821710393341,
            "mae": 0.3917792425879072,
            "precision": 0.6850828729281768,
            "recall": 0.5221052631578947
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.5979471343329423,
            "auditor_fn_violation": 0.017583742199835467,
            "auditor_fp_violation": 0.03569541000935073,
            "ave_precision_score": 0.5965598364286654,
            "fpr": 0.14050493962678376,
            "logloss": 1.870421405674272,
            "mae": 0.4098771070019782,
            "precision": 0.6631578947368421,
            "recall": 0.5260960334029228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7550575518482473,
            "auditor_fn_violation": 0.011890581717451523,
            "auditor_fp_violation": 0.018033140631900115,
            "ave_precision_score": 0.5413177091115782,
            "fpr": 0.4100877192982456,
            "logloss": 14.974093389359378,
            "mae": 0.44215993785397395,
            "precision": 0.5466666666666666,
            "recall": 0.9494736842105264
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7581438387353115,
            "auditor_fn_violation": 0.01568855716148489,
            "auditor_fp_violation": 0.026161727039882926,
            "ave_precision_score": 0.5524324731344191,
            "fpr": 0.3951701427003293,
            "logloss": 14.483366924568283,
            "mae": 0.43344426985097595,
            "precision": 0.5533498759305211,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6491629718921599,
            "auditor_fn_violation": 0.02003462603878116,
            "auditor_fp_violation": 0.03433748845798707,
            "ave_precision_score": 0.6497174748890996,
            "fpr": 0.11513157894736842,
            "logloss": 1.2959584677771296,
            "mae": 0.37787224264934083,
            "precision": 0.7025495750708215,
            "recall": 0.5221052631578947
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6274753654845632,
            "auditor_fn_violation": 0.017006249298185713,
            "auditor_fp_violation": 0.03241248932796683,
            "ave_precision_score": 0.6272450285651779,
            "fpr": 0.12733260153677278,
            "logloss": 1.5520977699548297,
            "mae": 0.39460141251940134,
            "precision": 0.6847826086956522,
            "recall": 0.5260960334029228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7563814014057906,
            "auditor_fn_violation": 0.008783471837488463,
            "auditor_fp_violation": 0.019864807900758775,
            "ave_precision_score": 0.6771656875787729,
            "fpr": 0.17763157894736842,
            "logloss": 4.406613923321491,
            "mae": 0.39891786932080886,
            "precision": 0.660377358490566,
            "recall": 0.6631578947368421
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.748199434997355,
            "auditor_fn_violation": 0.017730407063746505,
            "auditor_fp_violation": 0.0163434565190877,
            "ave_precision_score": 0.6788411646613086,
            "fpr": 0.15477497255762898,
            "logloss": 3.93790985009614,
            "mae": 0.39951944988294225,
            "precision": 0.6845637583892618,
            "recall": 0.6388308977035491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7413747384831627,
            "auditor_fn_violation": 0.000997229916897507,
            "auditor_fp_violation": 0.008618872696615692,
            "ave_precision_score": 0.6519557652153576,
            "fpr": 0.4100877192982456,
            "logloss": 5.00154630309241,
            "mae": 0.4295912447401829,
            "precision": 0.527180783817952,
            "recall": 0.8778947368421053
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7422753698127553,
            "auditor_fn_violation": 0.006450962373587494,
            "auditor_fp_violation": 0.005468146521933581,
            "ave_precision_score": 0.658431976299864,
            "fpr": 0.41712403951701427,
            "logloss": 4.6800806133088715,
            "mae": 0.42784045226095013,
            "precision": 0.5220125786163522,
            "recall": 0.8663883089770354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.760989010989011,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00046669878357220385,
            "ave_precision_score": 0.521978021978022,
            "fpr": 0.4780701754385965,
            "logloss": 16.47607650520368,
            "mae": 0.47795775598078444,
            "precision": 0.5214050493962679,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7624306955194255,
            "auditor_fn_violation": 0.0005866594556441911,
            "auditor_fp_violation": 0.0006022075862910168,
            "ave_precision_score": 0.5258524667689665,
            "fpr": 0.47310647639956094,
            "logloss": 16.343417883554995,
            "mae": 0.4744279724346427,
            "precision": 0.5258525852585259,
            "recall": 0.9979123173277662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 27690,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7121528325219229,
            "auditor_fn_violation": 0.04668744228993536,
            "auditor_fp_violation": 0.01994259103135413,
            "ave_precision_score": 0.6406994402922949,
            "fpr": 0.16228070175438597,
            "logloss": 9.79665943195311,
            "mae": 0.3804575224004557,
            "precision": 0.6501182033096927,
            "recall": 0.5789473684210527
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7329046622696285,
            "auditor_fn_violation": 0.03712225203898535,
            "auditor_fp_violation": 0.030186608122941824,
            "ave_precision_score": 0.6708366324518289,
            "fpr": 0.145993413830955,
            "logloss": 8.798991661079002,
            "mae": 0.36117583113959506,
            "precision": 0.6795180722891566,
            "recall": 0.5887265135699373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7559680063123273,
            "auditor_fn_violation": 0.012927054478301015,
            "auditor_fp_violation": 0.02031143361837089,
            "ave_precision_score": 0.531686672822407,
            "fpr": 0.43969298245614036,
            "logloss": 15.907946020007824,
            "mae": 0.46151516898616884,
            "precision": 0.5315420560747663,
            "recall": 0.9578947368421052
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7567838947145966,
            "auditor_fn_violation": 0.014657319837110334,
            "auditor_fp_violation": 0.0256128796194658,
            "ave_precision_score": 0.5385814544665314,
            "fpr": 0.424807903402854,
            "logloss": 15.622954385009802,
            "mae": 0.453568597345661,
            "precision": 0.5392857142857143,
            "recall": 0.9457202505219207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.7435537961843868,
            "auditor_fn_violation": 0.004349030470914131,
            "auditor_fp_violation": 0.008453269902444917,
            "ave_precision_score": 0.6541327247931953,
            "fpr": 0.40899122807017546,
            "logloss": 4.95830031491124,
            "mae": 0.41659500021814255,
            "precision": 0.5260482846251588,
            "recall": 0.871578947368421
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.7445674928132506,
            "auditor_fn_violation": 0.006902415157813686,
            "auditor_fp_violation": 0.0051276578444525754,
            "ave_precision_score": 0.6607226003935738,
            "fpr": 0.4105378704720088,
            "logloss": 4.633118426126978,
            "mae": 0.4131819373558957,
            "precision": 0.5223499361430396,
            "recall": 0.8538622129436325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7682894881439535,
            "auditor_fn_violation": 0.026288088642659288,
            "auditor_fp_violation": 0.04836605243084829,
            "ave_precision_score": 0.6895430968256913,
            "fpr": 0.20065789473684212,
            "logloss": 4.39512474394742,
            "mae": 0.38042899762881877,
            "precision": 0.6666666666666666,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7551146099097701,
            "auditor_fn_violation": 0.03448228448858649,
            "auditor_fp_violation": 0.04133634183030452,
            "ave_precision_score": 0.6864588027616827,
            "fpr": 0.18660812294182216,
            "logloss": 3.9358153211961957,
            "mae": 0.38539161854720755,
            "precision": 0.6686159844054581,
            "recall": 0.7160751565762005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6305531650670535,
            "auditor_fn_violation": 0.06445521698984304,
            "auditor_fp_violation": 0.09787125135493197,
            "ave_precision_score": 0.632178199759332,
            "fpr": 0.3059210526315789,
            "logloss": 0.68782909647059,
            "mae": 0.49712799584264294,
            "precision": 0.5746951219512195,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5949190963433071,
            "auditor_fn_violation": 0.09004535152588751,
            "auditor_fp_violation": 0.09260275643371144,
            "ave_precision_score": 0.5969527901487005,
            "fpr": 0.3227222832052689,
            "logloss": 0.6916530880243345,
            "mae": 0.49902661319752556,
            "precision": 0.5483870967741935,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6516720199606694,
            "auditor_fn_violation": 0.022839335180055403,
            "auditor_fp_violation": 0.035095246697980656,
            "ave_precision_score": 0.6522360801434465,
            "fpr": 0.1162280701754386,
            "logloss": 1.2788569176066036,
            "mae": 0.37244203048719265,
            "precision": 0.7079889807162535,
            "recall": 0.5410526315789473
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6301355513460419,
            "auditor_fn_violation": 0.016518130297981756,
            "auditor_fp_violation": 0.03159430011790056,
            "ave_precision_score": 0.6298541454306048,
            "fpr": 0.13062568605927552,
            "logloss": 1.5583886058927072,
            "mae": 0.38864721924026746,
            "precision": 0.6818181818181818,
            "recall": 0.5323590814196242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 27690,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7121419818188383,
            "auditor_fn_violation": 0.04668744228993536,
            "auditor_fp_violation": 0.01994259103135413,
            "ave_precision_score": 0.6407017137101743,
            "fpr": 0.16228070175438597,
            "logloss": 9.791785594402862,
            "mae": 0.3804424508028501,
            "precision": 0.6501182033096927,
            "recall": 0.5789473684210527
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7328450917289615,
            "auditor_fn_violation": 0.03712225203898535,
            "auditor_fp_violation": 0.030186608122941824,
            "ave_precision_score": 0.6708507697227883,
            "fpr": 0.145993413830955,
            "logloss": 8.794425426718094,
            "mae": 0.36116371939156167,
            "precision": 0.6795180722891566,
            "recall": 0.5887265135699373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7619440412909457,
            "auditor_fn_violation": 0.008411819021237308,
            "auditor_fp_violation": 0.021089264924324544,
            "ave_precision_score": 0.6836072919064926,
            "fpr": 0.24671052631578946,
            "logloss": 4.443078989228303,
            "mae": 0.39343179563734065,
            "precision": 0.6173469387755102,
            "recall": 0.7642105263157895
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7523096593240768,
            "auditor_fn_violation": 0.012186933535608624,
            "auditor_fp_violation": 0.01722008781558727,
            "ave_precision_score": 0.6838481319665815,
            "fpr": 0.2535675082327113,
            "logloss": 3.9761739770294784,
            "mae": 0.39470309060071174,
            "precision": 0.611764705882353,
            "recall": 0.7599164926931107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.760989010989011,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00046669878357220385,
            "ave_precision_score": 0.521978021978022,
            "fpr": 0.4780701754385965,
            "logloss": 16.47608264146766,
            "mae": 0.4779589406721163,
            "precision": 0.5214050493962679,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7624306955194255,
            "auditor_fn_violation": 0.0005866594556441911,
            "auditor_fp_violation": 0.0006022075862910168,
            "ave_precision_score": 0.5258524667689665,
            "fpr": 0.47310647639956094,
            "logloss": 16.34342690230544,
            "mae": 0.47442968853807604,
            "precision": 0.5258525852585259,
            "recall": 0.9979123173277662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6969592990217564,
            "auditor_fn_violation": 0.004129732225300091,
            "auditor_fp_violation": 0.029033180778032044,
            "ave_precision_score": 0.6950857558033796,
            "fpr": 0.20285087719298245,
            "logloss": 7.618700415034899,
            "mae": 0.4449135134415208,
            "precision": 0.5727482678983834,
            "recall": 0.5221052631578947
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6921127870439371,
            "auditor_fn_violation": 0.015612933091030774,
            "auditor_fp_violation": 0.011856120665121766,
            "ave_precision_score": 0.6908896237528157,
            "fpr": 0.19978046103183314,
            "logloss": 7.239027307943898,
            "mae": 0.4271696614273471,
            "precision": 0.5928411633109619,
            "recall": 0.5532359081419624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7529181244430483,
            "auditor_fn_violation": 0.012518467220683286,
            "auditor_fp_violation": 0.0290030711790919,
            "ave_precision_score": 0.7534683131739852,
            "fpr": 0.24671052631578946,
            "logloss": 0.6002335129887653,
            "mae": 0.38582058921211254,
            "precision": 0.6473354231974922,
            "recall": 0.8694736842105263
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7725241744544362,
            "auditor_fn_violation": 0.022325142253459804,
            "auditor_fp_violation": 0.027465239663373588,
            "ave_precision_score": 0.7730446332691865,
            "fpr": 0.22722283205268934,
            "logloss": 0.5977265541726,
            "mae": 0.3833456528357728,
            "precision": 0.6623164763458401,
            "recall": 0.8475991649269311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7574739069628847,
            "auditor_fn_violation": 0.014099722991689751,
            "auditor_fp_violation": 0.0213527239150508,
            "ave_precision_score": 0.5413127384719668,
            "fpr": 0.41776315789473684,
            "logloss": 15.268363439694468,
            "mae": 0.44638559748083634,
            "precision": 0.5404101326899879,
            "recall": 0.9431578947368421
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7605465220952441,
            "auditor_fn_violation": 0.01432503225481187,
            "auditor_fp_violation": 0.027767613936658945,
            "ave_precision_score": 0.5524381111063517,
            "fpr": 0.3973655323819978,
            "logloss": 14.749806259873441,
            "mae": 0.43162650335183284,
            "precision": 0.5530864197530864,
            "recall": 0.9352818371607515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7025511828387714,
            "auditor_fn_violation": 0.002460757156048019,
            "auditor_fp_violation": 0.024328555943634835,
            "ave_precision_score": 0.7008255905448462,
            "fpr": 0.15570175438596492,
            "logloss": 7.199774528005756,
            "mae": 0.4170565893323514,
            "precision": 0.6263157894736842,
            "recall": 0.5010526315789474
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6977172906003396,
            "auditor_fn_violation": 0.015674807330493225,
            "auditor_fp_violation": 0.010275643371142826,
            "ave_precision_score": 0.696449291543392,
            "fpr": 0.15148188803512624,
            "logloss": 6.8219385937332815,
            "mae": 0.4040490782487705,
            "precision": 0.6434108527131783,
            "recall": 0.5198329853862212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6824970224067357,
            "auditor_fn_violation": 0.04445752539242844,
            "auditor_fp_violation": 0.012146714039102335,
            "ave_precision_score": 0.6837240259999824,
            "fpr": 0.11074561403508772,
            "logloss": 3.9302948857231366,
            "mae": 0.3578794197371283,
            "precision": 0.7299465240641712,
            "recall": 0.5747368421052632
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6885128078376707,
            "auditor_fn_violation": 0.04505361288267499,
            "auditor_fp_violation": 0.022462088872626747,
            "ave_precision_score": 0.6884776736729221,
            "fpr": 0.10757409440175632,
            "logloss": 4.030530549476383,
            "mae": 0.3597006209455302,
            "precision": 0.7400530503978779,
            "recall": 0.5824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7158295824487853,
            "auditor_fn_violation": 0.0462488457987073,
            "auditor_fp_violation": 0.02034907061704605,
            "ave_precision_score": 0.6492386584123327,
            "fpr": 0.16228070175438597,
            "logloss": 9.077943754230379,
            "mae": 0.37714311285683455,
            "precision": 0.6542056074766355,
            "recall": 0.5894736842105263
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7291808177778294,
            "auditor_fn_violation": 0.03655392569133004,
            "auditor_fp_violation": 0.02888309549945116,
            "ave_precision_score": 0.6695007070039649,
            "fpr": 0.14818880351262348,
            "logloss": 8.242858949544337,
            "mae": 0.351816727042641,
            "precision": 0.6845794392523364,
            "recall": 0.6116910229645094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7445479487316929,
            "auditor_fn_violation": 0.004547553093259468,
            "auditor_fp_violation": 0.008380505038339576,
            "ave_precision_score": 0.6551321152677315,
            "fpr": 0.4024122807017544,
            "logloss": 4.9434897601746455,
            "mae": 0.4108708948877297,
            "precision": 0.5276705276705277,
            "recall": 0.8631578947368421
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7452904260779889,
            "auditor_fn_violation": 0.007938235759185465,
            "auditor_fp_violation": 0.002200471602227926,
            "ave_precision_score": 0.6614453761705597,
            "fpr": 0.4061470911086718,
            "logloss": 4.617764232734661,
            "mae": 0.40739367652017905,
            "precision": 0.5238095238095238,
            "recall": 0.8496868475991649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7288288846291341,
            "auditor_fn_violation": 0.047149122807017545,
            "auditor_fp_violation": 0.0423290778433498,
            "ave_precision_score": 0.5339790359545517,
            "fpr": 0.38048245614035087,
            "logloss": 15.87616810291627,
            "mae": 0.4638115225273416,
            "precision": 0.535475234270415,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7425660370506446,
            "auditor_fn_violation": 0.03770891149462956,
            "auditor_fp_violation": 0.05053461804285075,
            "ave_precision_score": 0.5539011264532433,
            "fpr": 0.3534577387486279,
            "logloss": 14.78468858330254,
            "mae": 0.4314274986924226,
            "precision": 0.5589041095890411,
            "recall": 0.8517745302713987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7412705046102475,
            "auditor_fn_violation": 0.000997229916897507,
            "auditor_fp_violation": 0.008618872696615692,
            "ave_precision_score": 0.6518491649406762,
            "fpr": 0.4100877192982456,
            "logloss": 5.003396821733141,
            "mae": 0.43005032974638435,
            "precision": 0.527180783817952,
            "recall": 0.8778947368421053
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.742268944305085,
            "auditor_fn_violation": 0.006450962373587494,
            "auditor_fp_violation": 0.005468146521933581,
            "ave_precision_score": 0.6584262894553975,
            "fpr": 0.41712403951701427,
            "logloss": 4.682051223733447,
            "mae": 0.4283393449369822,
            "precision": 0.5220125786163522,
            "recall": 0.8663883089770354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7563814014057906,
            "auditor_fn_violation": 0.008783471837488463,
            "auditor_fp_violation": 0.019864807900758775,
            "ave_precision_score": 0.6771656875787729,
            "fpr": 0.17763157894736842,
            "logloss": 4.406613883412224,
            "mae": 0.3989178702235215,
            "precision": 0.660377358490566,
            "recall": 0.6631578947368421
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.748199434997355,
            "auditor_fn_violation": 0.017730407063746505,
            "auditor_fp_violation": 0.0163434565190877,
            "ave_precision_score": 0.6788411646613086,
            "fpr": 0.15477497255762898,
            "logloss": 3.9379098044987293,
            "mae": 0.3995194503296339,
            "precision": 0.6845637583892618,
            "recall": 0.6388308977035491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7555709611666045,
            "auditor_fn_violation": 0.006525854108956609,
            "auditor_fp_violation": 0.021603637239551977,
            "ave_precision_score": 0.6764063526446893,
            "fpr": 0.14473684210526316,
            "logloss": 4.406106107331046,
            "mae": 0.3988433043768963,
            "precision": 0.7033707865168539,
            "recall": 0.6589473684210526
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7482191903376549,
            "auditor_fn_violation": 0.018754769472625235,
            "auditor_fp_violation": 0.01817294792047811,
            "ave_precision_score": 0.6788361071439896,
            "fpr": 0.13172338090010977,
            "logloss": 3.9368659965554254,
            "mae": 0.39908255892753053,
            "precision": 0.7169811320754716,
            "recall": 0.6346555323590815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6821390026341334,
            "auditor_fn_violation": 0.04445752539242844,
            "auditor_fp_violation": 0.012146714039102335,
            "ave_precision_score": 0.68336619429746,
            "fpr": 0.11074561403508772,
            "logloss": 3.929191695425441,
            "mae": 0.3578356727388277,
            "precision": 0.7299465240641712,
            "recall": 0.5747368421052632
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6883731773285066,
            "auditor_fn_violation": 0.04505361288267499,
            "auditor_fp_violation": 0.022462088872626747,
            "ave_precision_score": 0.688336421698843,
            "fpr": 0.10757409440175632,
            "logloss": 4.029816616797044,
            "mae": 0.35985935256952867,
            "precision": 0.7400530503978779,
            "recall": 0.5824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7019506350103296,
            "auditor_fn_violation": 0.006862880886426612,
            "auditor_fp_violation": 0.02270263760086716,
            "ave_precision_score": 0.7000272800213976,
            "fpr": 0.1524122807017544,
            "logloss": 7.237984540636588,
            "mae": 0.4166969068794679,
            "precision": 0.6303191489361702,
            "recall": 0.49894736842105264
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6964985887612771,
            "auditor_fn_violation": 0.015651890945507126,
            "auditor_fp_violation": 0.007912550311013537,
            "ave_precision_score": 0.6952012706395252,
            "fpr": 0.14709110867178923,
            "logloss": 6.86282495701946,
            "mae": 0.4045264602855318,
            "precision": 0.6492146596858639,
            "recall": 0.5177453027139874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7550589116453281,
            "auditor_fn_violation": 0.011890581717451523,
            "auditor_fp_violation": 0.020158376490425158,
            "ave_precision_score": 0.5413190687865888,
            "fpr": 0.41228070175438597,
            "logloss": 14.974499805374132,
            "mae": 0.44231922999677953,
            "precision": 0.5453446191051995,
            "recall": 0.9494736842105264
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7581354209537342,
            "auditor_fn_violation": 0.01568855716148489,
            "auditor_fp_violation": 0.026161727039882926,
            "ave_precision_score": 0.55242405628668,
            "fpr": 0.3951701427003293,
            "logloss": 14.485232093798796,
            "mae": 0.43361655536564514,
            "precision": 0.5533498759305211,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7529168929830561,
            "auditor_fn_violation": 0.012518467220683286,
            "auditor_fp_violation": 0.0290030711790919,
            "ave_precision_score": 0.7534692507265723,
            "fpr": 0.24671052631578946,
            "logloss": 0.6001632857463338,
            "mae": 0.38588564760223226,
            "precision": 0.6473354231974922,
            "recall": 0.8694736842105263
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7725276411034825,
            "auditor_fn_violation": 0.022325142253459804,
            "auditor_fp_violation": 0.027894661950644398,
            "ave_precision_score": 0.7730481271534152,
            "fpr": 0.2261251372118551,
            "logloss": 0.5976663404656165,
            "mae": 0.38339695000957646,
            "precision": 0.6633986928104575,
            "recall": 0.8475991649269311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 27690,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.737765390605974,
            "auditor_fn_violation": 0.05153047091412743,
            "auditor_fp_violation": 0.04073075996627726,
            "ave_precision_score": 0.6595791793168986,
            "fpr": 0.32456140350877194,
            "logloss": 9.707607144054354,
            "mae": 0.43458791597070506,
            "precision": 0.5608308605341247,
            "recall": 0.7957894736842105
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7509823578563561,
            "auditor_fn_violation": 0.04731546008080318,
            "auditor_fp_violation": 0.0517136236126357,
            "ave_precision_score": 0.6721422194552019,
            "fpr": 0.3194291986827662,
            "logloss": 9.588451986289199,
            "mae": 0.42719509839878655,
            "precision": 0.5682492581602374,
            "recall": 0.7995824634655533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.629035220859125,
            "auditor_fn_violation": 0.0645752539242844,
            "auditor_fp_violation": 0.09747480830222008,
            "ave_precision_score": 0.6305671628034859,
            "fpr": 0.3059210526315789,
            "logloss": 0.6867857939385994,
            "mae": 0.496513361764843,
            "precision": 0.5817091454272864,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5882090888894713,
            "auditor_fn_violation": 0.08772392172679544,
            "auditor_fp_violation": 0.09302201487986339,
            "ave_precision_score": 0.5902319991346852,
            "fpr": 0.32821075740944017,
            "logloss": 0.6911929434767426,
            "mae": 0.4987007430892614,
            "precision": 0.5483383685800605,
            "recall": 0.7578288100208769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 27690,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7122685277301772,
            "auditor_fn_violation": 0.04712834718374886,
            "auditor_fp_violation": 0.020344052350556027,
            "ave_precision_score": 0.6381459096343928,
            "fpr": 0.16337719298245615,
            "logloss": 9.83437927024368,
            "mae": 0.3799046155394091,
            "precision": 0.6494117647058824,
            "recall": 0.5810526315789474
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.733465677301651,
            "auditor_fn_violation": 0.03707412763051455,
            "auditor_fp_violation": 0.02888309549945116,
            "ave_precision_score": 0.6681558438819455,
            "fpr": 0.14818880351262348,
            "logloss": 8.851979654116848,
            "mae": 0.35657422359263374,
            "precision": 0.6778042959427207,
            "recall": 0.592901878914405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 27690,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6937841185785969,
            "auditor_fn_violation": 0.05195983379501386,
            "auditor_fp_violation": 0.03880625476735318,
            "ave_precision_score": 0.6912634597765135,
            "fpr": 0.3081140350877193,
            "logloss": 5.983218260220329,
            "mae": 0.4193325132838613,
            "precision": 0.5709923664122137,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6984619659314915,
            "auditor_fn_violation": 0.05361288267498379,
            "auditor_fp_violation": 0.048786437370411044,
            "ave_precision_score": 0.6958784157040905,
            "fpr": 0.2996706915477497,
            "logloss": 6.022882827544925,
            "mae": 0.42023057112669604,
            "precision": 0.5754276827371695,
            "recall": 0.7724425887265136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7764171537134442,
            "auditor_fn_violation": 0.007225300092336107,
            "auditor_fp_violation": 0.027954253482676952,
            "ave_precision_score": 0.6876760305685428,
            "fpr": 0.24342105263157895,
            "logloss": 6.627406304262422,
            "mae": 0.3184115357386942,
            "precision": 0.645933014354067,
            "recall": 0.8526315789473684
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7854654799931722,
            "auditor_fn_violation": 0.018394982228343446,
            "auditor_fp_violation": 0.019494247265926745,
            "ave_precision_score": 0.7055523186347246,
            "fpr": 0.2327113062568606,
            "logloss": 6.0798043160787865,
            "mae": 0.30628081858456274,
            "precision": 0.6591639871382636,
            "recall": 0.8559498956158664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7550575181890634,
            "auditor_fn_violation": 0.011890581717451523,
            "auditor_fp_violation": 0.01933287165281626,
            "ave_precision_score": 0.5413176754727959,
            "fpr": 0.41118421052631576,
            "logloss": 14.974141616824305,
            "mae": 0.4421338331477161,
            "precision": 0.5460048426150121,
            "recall": 0.9494736842105264
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.758143812767743,
            "auditor_fn_violation": 0.01568855716148489,
            "auditor_fp_violation": 0.026161727039882926,
            "ave_precision_score": 0.5524324471778751,
            "fpr": 0.3951701427003293,
            "logloss": 14.484808902965092,
            "mae": 0.4334170122710251,
            "precision": 0.5533498759305211,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7285372401310534,
            "auditor_fn_violation": 0.050433979686057256,
            "auditor_fp_violation": 0.0391299329559597,
            "ave_precision_score": 0.5660182439683445,
            "fpr": 0.32346491228070173,
            "logloss": 13.46741928938302,
            "mae": 0.4325264244284313,
            "precision": 0.5616641901931649,
            "recall": 0.7957894736842105
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7309587879598692,
            "auditor_fn_violation": 0.04980647112879237,
            "auditor_fp_violation": 0.0517136236126357,
            "ave_precision_score": 0.5712157237572589,
            "fpr": 0.3194291986827662,
            "logloss": 13.206938019090837,
            "mae": 0.42340030681195534,
            "precision": 0.5701624815361891,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7610523010198728,
            "auditor_fn_violation": 0.014385964912280705,
            "auditor_fp_violation": 0.017024469067405356,
            "ave_precision_score": 0.6728098378368697,
            "fpr": 0.17324561403508773,
            "logloss": 4.99179717794149,
            "mae": 0.37723638864951337,
            "precision": 0.6673684210526316,
            "recall": 0.6673684210526316
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7643496881201205,
            "auditor_fn_violation": 0.021837023253255847,
            "auditor_fp_violation": 0.020299731674594472,
            "ave_precision_score": 0.6856688836022131,
            "fpr": 0.15697036223929747,
            "logloss": 4.637017500420328,
            "mae": 0.37221415021401205,
            "precision": 0.6877729257641921,
            "recall": 0.6576200417536534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.753484787077008,
            "auditor_fn_violation": 0.005145429362880883,
            "auditor_fp_violation": 0.022454233409610985,
            "ave_precision_score": 0.6760444694147072,
            "fpr": 0.1425438596491228,
            "logloss": 4.335499321029856,
            "mae": 0.3977733440139336,
            "precision": 0.7058823529411765,
            "recall": 0.6568421052631579
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7457496261921883,
            "auditor_fn_violation": 0.021628484149882325,
            "auditor_fp_violation": 0.018071309509289757,
            "ave_precision_score": 0.676978783323924,
            "fpr": 0.12952799121844127,
            "logloss": 3.906639133051523,
            "mae": 0.3982029438530434,
            "precision": 0.7170263788968825,
            "recall": 0.6242171189979123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.760989010989011,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00046669878357220385,
            "ave_precision_score": 0.521978021978022,
            "fpr": 0.4780701754385965,
            "logloss": 16.476079540861512,
            "mae": 0.477958339315496,
            "precision": 0.5214050493962679,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7624306955194255,
            "auditor_fn_violation": 0.0005866594556441911,
            "auditor_fp_violation": 0.0006022075862910168,
            "ave_precision_score": 0.5258524667689665,
            "fpr": 0.47310647639956094,
            "logloss": 16.343419368879108,
            "mae": 0.47442776551950644,
            "precision": 0.5258525852585259,
            "recall": 0.9979123173277662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7413814114425052,
            "auditor_fn_violation": 0.0519713758079409,
            "auditor_fp_violation": 0.0449335581516721,
            "ave_precision_score": 0.634546962922776,
            "fpr": 0.33223684210526316,
            "logloss": 10.918987818544178,
            "mae": 0.43893559947252886,
            "precision": 0.5557184750733137,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7477822369480148,
            "auditor_fn_violation": 0.046742550456150646,
            "auditor_fp_violation": 0.05435622230353296,
            "ave_precision_score": 0.6418370585348897,
            "fpr": 0.32491767288693746,
            "logloss": 10.748464713788906,
            "mae": 0.4312944469219991,
            "precision": 0.5647058823529412,
            "recall": 0.8016701461377871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6736843660987788,
            "auditor_fn_violation": 0.04573176361957526,
            "auditor_fp_violation": 0.032159560801316815,
            "ave_precision_score": 0.6729484152430105,
            "fpr": 0.25109649122807015,
            "logloss": 4.288361139907131,
            "mae": 0.3826559468150541,
            "precision": 0.6098807495741057,
            "recall": 0.7536842105263157
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.676446099090436,
            "auditor_fn_violation": 0.04293155563296202,
            "auditor_fp_violation": 0.03851079399926822,
            "ave_precision_score": 0.6765657421096054,
            "fpr": 0.24698133918770582,
            "logloss": 4.377834271317544,
            "mae": 0.3833538891136911,
            "precision": 0.614065180102916,
            "recall": 0.7473903966597077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7142308229281814,
            "auditor_fn_violation": 0.0462488457987073,
            "auditor_fp_violation": 0.02034907061704605,
            "ave_precision_score": 0.6460748100618856,
            "fpr": 0.16228070175438597,
            "logloss": 9.164968025249031,
            "mae": 0.37745231503744203,
            "precision": 0.6542056074766355,
            "recall": 0.5894736842105263
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.729265299425452,
            "auditor_fn_violation": 0.03793807534449057,
            "auditor_fp_violation": 0.02888309549945116,
            "ave_precision_score": 0.6694866962436137,
            "fpr": 0.14818880351262348,
            "logloss": 8.271676517270963,
            "mae": 0.35275414449772796,
            "precision": 0.6816037735849056,
            "recall": 0.6033402922755741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6406634930537127,
            "auditor_fn_violation": 0.014921514312096033,
            "auditor_fp_violation": 0.033125577100646356,
            "ave_precision_score": 0.6410217921863484,
            "fpr": 0.11842105263157894,
            "logloss": 1.2859190727058472,
            "mae": 0.37991369030641525,
            "precision": 0.7032967032967034,
            "recall": 0.5389473684210526
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6123639495187818,
            "auditor_fn_violation": 0.016536463405970637,
            "auditor_fp_violation": 0.034099686953693545,
            "ave_precision_score": 0.6118016985344142,
            "fpr": 0.13611416026344675,
            "logloss": 1.612370448148606,
            "mae": 0.40118020010367067,
            "precision": 0.6745406824146981,
            "recall": 0.5365344467640919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6819859705466403,
            "auditor_fn_violation": 0.029379039704524473,
            "auditor_fp_violation": 0.031339074230197925,
            "ave_precision_score": 0.6827873511185656,
            "fpr": 0.16337719298245615,
            "logloss": 0.6352193674687546,
            "mae": 0.45169890770002413,
            "precision": 0.6725274725274726,
            "recall": 0.6442105263157895
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7012137722382424,
            "auditor_fn_violation": 0.04190031830858747,
            "auditor_fp_violation": 0.02854006586169045,
            "ave_precision_score": 0.7021484929731084,
            "fpr": 0.14489571899012074,
            "logloss": 0.6301915074844311,
            "mae": 0.4481411012447757,
            "precision": 0.6944444444444444,
            "recall": 0.6263048016701461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7564782487952699,
            "auditor_fn_violation": 0.006525854108956609,
            "auditor_fp_violation": 0.021603637239551977,
            "ave_precision_score": 0.6767766931728103,
            "fpr": 0.14473684210526316,
            "logloss": 4.406372435330007,
            "mae": 0.3987670459745659,
            "precision": 0.7033707865168539,
            "recall": 0.6589473684210526
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7500150915996988,
            "auditor_fn_violation": 0.018754769472625235,
            "auditor_fp_violation": 0.01817294792047811,
            "ave_precision_score": 0.6805721238408413,
            "fpr": 0.13172338090010977,
            "logloss": 3.9371243014838146,
            "mae": 0.39893878455506027,
            "precision": 0.7169811320754716,
            "recall": 0.6346555323590815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 27690,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.6722543392025049,
            "auditor_fn_violation": 0.001715143120960304,
            "auditor_fp_violation": 0.0024714962463366656,
            "ave_precision_score": 0.6731343818703431,
            "fpr": 0.005482456140350877,
            "logloss": 6.166090840513134,
            "mae": 0.5097492439273975,
            "precision": 0.5454545454545454,
            "recall": 0.01263157894736842
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.6806774372840256,
            "auditor_fn_violation": 0.0007722821740316246,
            "auditor_fp_violation": 0.000650485831605481,
            "ave_precision_score": 0.6795059588114363,
            "fpr": 0.008781558726673985,
            "logloss": 6.28075180500103,
            "mae": 0.5160658438513357,
            "precision": 0.3333333333333333,
            "recall": 0.008350730688935281
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7720829099113505,
            "auditor_fn_violation": 0.009829178208679595,
            "auditor_fp_violation": 0.007921333654502396,
            "ave_precision_score": 0.683913088067326,
            "fpr": 0.37609649122807015,
            "logloss": 5.412624406576402,
            "mae": 0.394178259536562,
            "precision": 0.5652724968314322,
            "recall": 0.9389473684210526
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7763312216612248,
            "auditor_fn_violation": 0.009982377299945689,
            "auditor_fp_violation": 0.005518965727527759,
            "ave_precision_score": 0.6951816087628454,
            "fpr": 0.3677277716794731,
            "logloss": 5.088409170260415,
            "mae": 0.3904451943947119,
            "precision": 0.5705128205128205,
            "recall": 0.9290187891440501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6686989214897956,
            "auditor_fn_violation": 0.030136195752539244,
            "auditor_fp_violation": 0.025563049500180658,
            "ave_precision_score": 0.6696017686281224,
            "fpr": 0.1787280701754386,
            "logloss": 4.880855799354971,
            "mae": 0.402781681492761,
            "precision": 0.6235565819861432,
            "recall": 0.5684210526315789
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.678295999126031,
            "auditor_fn_violation": 0.016777085448324704,
            "auditor_fp_violation": 0.017420823677684275,
            "ave_precision_score": 0.6771407998016884,
            "fpr": 0.15916575192096596,
            "logloss": 4.978049630902963,
            "mae": 0.3836581286391814,
            "precision": 0.6563981042654028,
            "recall": 0.5782881002087683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6813891654445206,
            "auditor_fn_violation": 0.034351338873499546,
            "auditor_fp_violation": 0.022266048416235095,
            "ave_precision_score": 0.6820066050762392,
            "fpr": 0.18530701754385964,
            "logloss": 4.597504956293772,
            "mae": 0.39071231162482567,
            "precision": 0.6261061946902655,
            "recall": 0.5957894736842105
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6880920486022835,
            "auditor_fn_violation": 0.02093870096180068,
            "auditor_fp_violation": 0.01818057080131724,
            "ave_precision_score": 0.6863919064562523,
            "fpr": 0.16136114160263446,
            "logloss": 4.677382824552377,
            "mae": 0.3752348885781105,
            "precision": 0.6589327146171694,
            "recall": 0.592901878914405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7618428464804338,
            "auditor_fn_violation": 0.013684210526315788,
            "auditor_fp_violation": 0.022818057730137703,
            "ave_precision_score": 0.6735054814020187,
            "fpr": 0.17982456140350878,
            "logloss": 4.789747610791633,
            "mae": 0.38999843157788444,
            "precision": 0.6597510373443983,
            "recall": 0.6694736842105263
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7662241981729927,
            "auditor_fn_violation": 0.02118848955814918,
            "auditor_fp_violation": 0.019758507135016475,
            "ave_precision_score": 0.6875790810250778,
            "fpr": 0.15806805708013172,
            "logloss": 4.333690089411485,
            "mae": 0.38684418162710604,
            "precision": 0.6869565217391305,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6912467536400575,
            "auditor_fn_violation": 0.05195983379501386,
            "auditor_fp_violation": 0.03788791199967885,
            "ave_precision_score": 0.6900898159833575,
            "fpr": 0.30701754385964913,
            "logloss": 5.9003560822786705,
            "mae": 0.4186922193946256,
            "precision": 0.5718654434250765,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6956738413280223,
            "auditor_fn_violation": 0.05361288267498379,
            "auditor_fp_violation": 0.048786437370411044,
            "ave_precision_score": 0.694762950731121,
            "fpr": 0.2996706915477497,
            "logloss": 5.945453230819472,
            "mae": 0.4200814475523845,
            "precision": 0.5754276827371695,
            "recall": 0.7724425887265136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 27690,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7122062698738723,
            "auditor_fn_violation": 0.04890350877192983,
            "auditor_fp_violation": 0.019879862700228842,
            "ave_precision_score": 0.6600809751581845,
            "fpr": 0.16666666666666666,
            "logloss": 8.273252225323063,
            "mae": 0.3762019481236356,
            "precision": 0.6521739130434783,
            "recall": 0.6
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7296772176371049,
            "auditor_fn_violation": 0.03950555607753989,
            "auditor_fp_violation": 0.03183315038419319,
            "ave_precision_score": 0.6851246604481795,
            "fpr": 0.14709110867178923,
            "logloss": 7.438604025743414,
            "mae": 0.34864194864154313,
            "precision": 0.6890951276102089,
            "recall": 0.6200417536534447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 27690,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.685405242476395,
            "auditor_fn_violation": 0.038561865189289016,
            "auditor_fp_violation": 0.02588672768878719,
            "ave_precision_score": 0.6862993981854377,
            "fpr": 0.19517543859649122,
            "logloss": 4.605149285729849,
            "mae": 0.38976928069791844,
            "precision": 0.6228813559322034,
            "recall": 0.6189473684210526
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6890282102420352,
            "auditor_fn_violation": 0.01681146002580385,
            "auditor_fp_violation": 0.015901329430418353,
            "ave_precision_score": 0.6878562748191281,
            "fpr": 0.1690450054884742,
            "logloss": 4.652896142606583,
            "mae": 0.37058592685471387,
            "precision": 0.6600441501103753,
            "recall": 0.6242171189979123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.753484787077008,
            "auditor_fn_violation": 0.005145429362880883,
            "auditor_fp_violation": 0.022454233409610985,
            "ave_precision_score": 0.6760444694147072,
            "fpr": 0.1425438596491228,
            "logloss": 4.3348248100530675,
            "mae": 0.3977435543950524,
            "precision": 0.7058823529411765,
            "recall": 0.6568421052631579
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7457496261921883,
            "auditor_fn_violation": 0.021628484149882325,
            "auditor_fp_violation": 0.018071309509289757,
            "ave_precision_score": 0.676978783323924,
            "fpr": 0.12952799121844127,
            "logloss": 3.9060962218430153,
            "mae": 0.3981987163940802,
            "precision": 0.7170263788968825,
            "recall": 0.6242171189979123
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7559680063123273,
            "auditor_fn_violation": 0.012927054478301015,
            "auditor_fp_violation": 0.02031143361837089,
            "ave_precision_score": 0.531686672822407,
            "fpr": 0.43969298245614036,
            "logloss": 15.908798350672306,
            "mae": 0.4616434246040227,
            "precision": 0.5315420560747663,
            "recall": 0.9578947368421052
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7575534355709361,
            "auditor_fn_violation": 0.014093576766452245,
            "auditor_fp_violation": 0.0256128796194658,
            "ave_precision_score": 0.5391299837643062,
            "fpr": 0.424807903402854,
            "logloss": 15.585279406197856,
            "mae": 0.4524695043146414,
            "precision": 0.539833531510107,
            "recall": 0.9478079331941545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 27690,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7121650137013196,
            "auditor_fn_violation": 0.04668744228993536,
            "auditor_fp_violation": 0.01994259103135413,
            "ave_precision_score": 0.6406481605996504,
            "fpr": 0.16228070175438597,
            "logloss": 9.809386740983012,
            "mae": 0.38048639252257505,
            "precision": 0.6501182033096927,
            "recall": 0.5789473684210527
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7324104025213436,
            "auditor_fn_violation": 0.03712225203898535,
            "auditor_fp_violation": 0.030186608122941824,
            "ave_precision_score": 0.6696985179109809,
            "fpr": 0.145993413830955,
            "logloss": 8.828907588793664,
            "mae": 0.3612683283692248,
            "precision": 0.6795180722891566,
            "recall": 0.5887265135699373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7574739069628847,
            "auditor_fn_violation": 0.014852262234533705,
            "auditor_fp_violation": 0.0213527239150508,
            "ave_precision_score": 0.5413127384719668,
            "fpr": 0.41776315789473684,
            "logloss": 15.269112549338615,
            "mae": 0.4462594144301356,
            "precision": 0.5409638554216868,
            "recall": 0.9452631578947368
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7602265049209227,
            "auditor_fn_violation": 0.01432503225481187,
            "auditor_fp_violation": 0.027767613936658945,
            "ave_precision_score": 0.5517980767577086,
            "fpr": 0.3973655323819978,
            "logloss": 14.766751182689514,
            "mae": 0.43143401629177663,
            "precision": 0.5530864197530864,
            "recall": 0.9352818371607515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6796490570113302,
            "auditor_fn_violation": 0.03339566020313943,
            "auditor_fp_violation": 0.023370067044040307,
            "ave_precision_score": 0.6802698416809629,
            "fpr": 0.1787280701754386,
            "logloss": 4.603395492505954,
            "mae": 0.39173627024559676,
            "precision": 0.6328828828828829,
            "recall": 0.5915789473684211
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6872430267809518,
            "auditor_fn_violation": 0.020381832806638422,
            "auditor_fp_violation": 0.017624100500060986,
            "ave_precision_score": 0.6855436942691074,
            "fpr": 0.1602634467618002,
            "logloss": 4.693817360154224,
            "mae": 0.37693581544420635,
            "precision": 0.6596736596736597,
            "recall": 0.5908141962421712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6774550491448613,
            "auditor_fn_violation": 0.04603416435826409,
            "auditor_fp_violation": 0.011348809667188568,
            "ave_precision_score": 0.6786928934465046,
            "fpr": 0.1118421052631579,
            "logloss": 3.9643355319569316,
            "mae": 0.35944686977058987,
            "precision": 0.7287234042553191,
            "recall": 0.5768421052631579
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6831911936047724,
            "auditor_fn_violation": 0.045236943962563794,
            "auditor_fp_violation": 0.02439321868520551,
            "ave_precision_score": 0.683193608710315,
            "fpr": 0.1141602634467618,
            "logloss": 4.067831582847111,
            "mae": 0.3620821024712274,
            "precision": 0.7270341207349081,
            "recall": 0.5782881002087683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6168831258497763,
            "auditor_fn_violation": 0.06861495844875345,
            "auditor_fp_violation": 0.0880053394355454,
            "ave_precision_score": 0.618797329151701,
            "fpr": 0.2916666666666667,
            "logloss": 0.6875646979067553,
            "mae": 0.49694111015190157,
            "precision": 0.5863141524105754,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.5906935304180396,
            "auditor_fn_violation": 0.09051055414110534,
            "auditor_fp_violation": 0.08963745578729113,
            "ave_precision_score": 0.5923928128400093,
            "fpr": 0.3150384193194292,
            "logloss": 0.6917323276161581,
            "mae": 0.49900164032348815,
            "precision": 0.5536547433903577,
            "recall": 0.7432150313152401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7098605312406285,
            "auditor_fn_violation": 0.04734302862419206,
            "auditor_fp_violation": 0.01994259103135413,
            "ave_precision_score": 0.6367143917557703,
            "fpr": 0.16228070175438597,
            "logloss": 9.952149211303807,
            "mae": 0.3816028292166649,
            "precision": 0.6492890995260664,
            "recall": 0.5768421052631579
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.730492044132426,
            "auditor_fn_violation": 0.03987450987581612,
            "auditor_fp_violation": 0.03128430296377607,
            "ave_precision_score": 0.6666386116508102,
            "fpr": 0.1437980241492865,
            "logloss": 8.963265139331908,
            "mae": 0.36354490633403985,
            "precision": 0.6797066014669927,
            "recall": 0.5803757828810021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7550575518482473,
            "auditor_fn_violation": 0.011890581717451523,
            "auditor_fp_violation": 0.018033140631900115,
            "ave_precision_score": 0.5413177091115782,
            "fpr": 0.4100877192982456,
            "logloss": 14.974093228968123,
            "mae": 0.44216003958462624,
            "precision": 0.5466666666666666,
            "recall": 0.9494736842105264
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7581438387353115,
            "auditor_fn_violation": 0.01568855716148489,
            "auditor_fp_violation": 0.026161727039882926,
            "ave_precision_score": 0.5524324731344191,
            "fpr": 0.3951701427003293,
            "logloss": 14.483366772525907,
            "mae": 0.4334444167942951,
            "precision": 0.5533498759305211,
            "recall": 0.9311064718162839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7789990816472345,
            "auditor_fn_violation": 0.010242382271468148,
            "auditor_fp_violation": 0.015112509534706334,
            "ave_precision_score": 0.6906920758743352,
            "fpr": 0.16666666666666666,
            "logloss": 6.383794780541521,
            "mae": 0.295256636343159,
            "precision": 0.7093690248565966,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7858579352169499,
            "auditor_fn_violation": 0.017480618467398006,
            "auditor_fp_violation": 0.020718990120746437,
            "ave_precision_score": 0.7065673594183426,
            "fpr": 0.1602634467618002,
            "logloss": 5.834877560144257,
            "mae": 0.2889653345653459,
            "precision": 0.7213740458015268,
            "recall": 0.7891440501043842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7158356954971652,
            "auditor_fn_violation": 0.0462488457987073,
            "auditor_fp_violation": 0.02034907061704605,
            "ave_precision_score": 0.6492447916213554,
            "fpr": 0.16228070175438597,
            "logloss": 9.075033817402316,
            "mae": 0.37714522438922854,
            "precision": 0.6542056074766355,
            "recall": 0.5894736842105263
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.7297358631475439,
            "auditor_fn_violation": 0.037122252038985365,
            "auditor_fp_violation": 0.02888309549945116,
            "ave_precision_score": 0.6705825131325629,
            "fpr": 0.14818880351262348,
            "logloss": 8.221195649808791,
            "mae": 0.3518676579522248,
            "precision": 0.6838407494145199,
            "recall": 0.6096033402922756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7510863313770788,
            "auditor_fn_violation": 0.01353185595567867,
            "auditor_fp_violation": 0.03124874543337751,
            "ave_precision_score": 0.7516369842227176,
            "fpr": 0.25548245614035087,
            "logloss": 0.6045943901339828,
            "mae": 0.39126087456386077,
            "precision": 0.6442748091603053,
            "recall": 0.888421052631579
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7755065098504272,
            "auditor_fn_violation": 0.018342274542875413,
            "auditor_fp_violation": 0.02937604179371469,
            "ave_precision_score": 0.775996673804615,
            "fpr": 0.24478594950603733,
            "logloss": 0.5990947575295695,
            "mae": 0.3878472938225835,
            "precision": 0.6521060842433697,
            "recall": 0.872651356993737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 27690,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.40662064522645863,
            "auditor_fn_violation": 0.0019575253924284507,
            "auditor_fp_violation": 0.0022306194548155286,
            "ave_precision_score": 0.5235040971059791,
            "fpr": 0.006578947368421052,
            "logloss": 17.601812741065935,
            "mae": 0.5219215687337279,
            "precision": 0.4,
            "recall": 0.008421052631578947
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.4262676894625689,
            "auditor_fn_violation": 0.002087682672233836,
            "auditor_fp_violation": 0.0007394194413952922,
            "ave_precision_score": 0.523800602977913,
            "fpr": 0.005488474204171241,
            "logloss": 17.63225653221572,
            "mae": 0.5270221340498769,
            "precision": 0.5,
            "recall": 0.010438413361169102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.760989010989011,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00046669878357220385,
            "ave_precision_score": 0.521978021978022,
            "fpr": 0.4780701754385965,
            "logloss": 16.476068472704245,
            "mae": 0.47795548275309174,
            "precision": 0.5214050493962679,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7624306955194255,
            "auditor_fn_violation": 0.0005866594556441911,
            "auditor_fp_violation": 0.0006022075862910168,
            "ave_precision_score": 0.5258524667689665,
            "fpr": 0.47310647639956094,
            "logloss": 16.343417926187126,
            "mae": 0.4744278903392222,
            "precision": 0.5258525852585259,
            "recall": 0.9979123173277662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 27690,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7561431851321977,
            "auditor_fn_violation": 0.014349030470914128,
            "auditor_fp_violation": 0.01839194668593682,
            "ave_precision_score": 0.5388257435446848,
            "fpr": 0.42105263157894735,
            "logloss": 15.420238917613368,
            "mae": 0.45068601589606366,
            "precision": 0.5384615384615384,
            "recall": 0.9431578947368421
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7609872388243033,
            "auditor_fn_violation": 0.013825455062114864,
            "auditor_fp_violation": 0.027023112574704237,
            "ave_precision_score": 0.5523718741281787,
            "fpr": 0.39846322722283206,
            "logloss": 14.740930284586247,
            "mae": 0.4313690053376952,
            "precision": 0.5529556650246306,
            "recall": 0.9373695198329853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6901448416405291,
            "auditor_fn_violation": 0.03797091412742382,
            "auditor_fp_violation": 0.027369625436589183,
            "ave_precision_score": 0.6910126775249351,
            "fpr": 0.19846491228070176,
            "logloss": 4.5451703140693684,
            "mae": 0.3888232248747423,
            "precision": 0.6221294363256785,
            "recall": 0.6273684210526316
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6908994251018501,
            "auditor_fn_violation": 0.021023491586249256,
            "auditor_fp_violation": 0.015512562507622882,
            "ave_precision_score": 0.689729160056539,
            "fpr": 0.17233809001097694,
            "logloss": 4.582122398295173,
            "mae": 0.36948926902012974,
            "precision": 0.6609071274298056,
            "recall": 0.6388308977035491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7520854326738015,
            "auditor_fn_violation": 0.013457987072945522,
            "auditor_fp_violation": 0.030265165201332857,
            "ave_precision_score": 0.7526358305505343,
            "fpr": 0.26206140350877194,
            "logloss": 0.6048443178639521,
            "mae": 0.3915013128364655,
            "precision": 0.6411411411411412,
            "recall": 0.8989473684210526
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7752815844124874,
            "auditor_fn_violation": 0.018385815674349007,
            "auditor_fp_violation": 0.030049396267837546,
            "ave_precision_score": 0.7757721803049833,
            "fpr": 0.24698133918770582,
            "logloss": 0.5998493909597832,
            "mae": 0.38825115087338846,
            "precision": 0.6489859594383776,
            "recall": 0.8684759916492694
        }
    }
]