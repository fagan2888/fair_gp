[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 24284,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8468171283458659,
            "auditor_fn_violation": 0.01565134718186059,
            "auditor_fp_violation": 0.018290406868234417,
            "ave_precision_score": 0.8471350593088921,
            "fpr": 0.11403508771929824,
            "logloss": 0.7968689038612914,
            "mae": 0.26795287435114207,
            "precision": 0.775377969762419,
            "recall": 0.7341513292433538
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8018357078563384,
            "auditor_fn_violation": 0.017211382977467753,
            "auditor_fp_violation": 0.031048027841085298,
            "ave_precision_score": 0.8024119464340627,
            "fpr": 0.150384193194292,
            "logloss": 0.9125011014426407,
            "mae": 0.27861273079755705,
            "precision": 0.7254509018036072,
            "recall": 0.7784946236559139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7751680024516931,
            "auditor_fn_violation": 0.007836885157679482,
            "auditor_fp_violation": 0.009075214632325497,
            "ave_precision_score": 0.7702014417517052,
            "fpr": 0.07894736842105263,
            "logloss": 0.6008378480576709,
            "mae": 0.38738968789313505,
            "precision": 0.828978622327791,
            "recall": 0.7137014314928425
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.7739276811090292,
            "auditor_fn_violation": 0.010183775362062254,
            "auditor_fp_violation": 0.010322269422553444,
            "ave_precision_score": 0.7623071617954144,
            "fpr": 0.09879253567508232,
            "logloss": 0.5796207343982508,
            "mae": 0.3809336118331602,
            "precision": 0.7902097902097902,
            "recall": 0.7290322580645161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8136431737788862,
            "auditor_fn_violation": 0.013305887417931333,
            "auditor_fp_violation": 0.007753203931815354,
            "ave_precision_score": 0.8140146564244406,
            "fpr": 0.08223684210526316,
            "logloss": 1.556836356784808,
            "mae": 0.3001327840784707,
            "precision": 0.8010610079575596,
            "recall": 0.6175869120654397
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7793543752489402,
            "auditor_fn_violation": 0.0168053539180624,
            "auditor_fp_violation": 0.01285238219470055,
            "ave_precision_score": 0.7799626110391863,
            "fpr": 0.10537870472008781,
            "logloss": 1.5126368290287142,
            "mae": 0.3137935512260782,
            "precision": 0.7433155080213903,
            "recall": 0.5978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7615646358717714,
            "auditor_fn_violation": 0.05953790406486565,
            "auditor_fp_violation": 0.022930405209240595,
            "ave_precision_score": 0.762083229395295,
            "fpr": 0.08114035087719298,
            "logloss": 0.7046710366755025,
            "mae": 0.3742445512780371,
            "precision": 0.7658227848101266,
            "recall": 0.4948875255623722
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7675413512867094,
            "auditor_fn_violation": 0.06430367196629015,
            "auditor_fp_violation": 0.025141149773815794,
            "ave_precision_score": 0.768129515092368,
            "fpr": 0.07354555433589462,
            "logloss": 0.6615811906556174,
            "mae": 0.3610930275051235,
            "precision": 0.7788778877887789,
            "recall": 0.5075268817204301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.768092105263158,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5361842105263158,
            "fpr": 0.46381578947368424,
            "logloss": 0.6915093471442919,
            "mae": 0.49898427999333334,
            "precision": 0.5361842105263158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7544186335482677,
            "auditor_fn_violation": 0.0005830766143786222,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5098912668602126,
            "fpr": 0.48957189901207465,
            "logloss": 0.6940706707946127,
            "mae": 0.5000671895975339,
            "precision": 0.5098901098901099,
            "recall": 0.9978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.805363900056638,
            "auditor_fn_violation": 0.017173877946399744,
            "auditor_fp_violation": 0.014902430425946673,
            "ave_precision_score": 0.7781441873665168,
            "fpr": 0.11732456140350878,
            "logloss": 0.5719574324637745,
            "mae": 0.3975426349788904,
            "precision": 0.7482352941176471,
            "recall": 0.6503067484662577
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7855773473752935,
            "auditor_fn_violation": 0.008592708001369168,
            "auditor_fp_violation": 0.006760914187828888,
            "ave_precision_score": 0.7587016687370963,
            "fpr": 0.13062568605927552,
            "logloss": 0.5691601853036234,
            "mae": 0.39399002909080627,
            "precision": 0.7289293849658315,
            "recall": 0.6881720430107527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8584505770089872,
            "auditor_fn_violation": 0.005735837548882433,
            "auditor_fp_violation": 0.011042677616025884,
            "ave_precision_score": 0.824218298117952,
            "fpr": 0.08552631578947369,
            "logloss": 0.5300653780568628,
            "mae": 0.35307792829055534,
            "precision": 0.8160377358490566,
            "recall": 0.7075664621676891
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8310419601153928,
            "auditor_fn_violation": 0.010844752900629116,
            "auditor_fp_violation": 0.008048121366654688,
            "ave_precision_score": 0.7885472831838318,
            "fpr": 0.10757409440175632,
            "logloss": 0.544293111423557,
            "mae": 0.36092445103024284,
            "precision": 0.774712643678161,
            "recall": 0.7247311827956989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7679086123744292,
            "auditor_fn_violation": 0.001251210849208912,
            "auditor_fp_violation": 0.0057909253038032635,
            "ave_precision_score": 0.546982142585439,
            "fpr": 0.43530701754385964,
            "logloss": 14.985078254532658,
            "mae": 0.4456737067191984,
            "precision": 0.5488636363636363,
            "recall": 0.9877300613496932
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.7530585433196115,
            "auditor_fn_violation": 0.0010363183551101828,
            "auditor_fp_violation": 0.00359827322264501,
            "ave_precision_score": 0.521504522972558,
            "fpr": 0.45334796926454446,
            "logloss": 15.677528416648677,
            "mae": 0.46488577640861783,
            "precision": 0.5258323765786452,
            "recall": 0.9849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.590399442852356,
            "auditor_fn_violation": 0.012211638503210992,
            "auditor_fp_violation": 0.007760980465347765,
            "ave_precision_score": 0.5880781791596232,
            "fpr": 0.05701754385964912,
            "logloss": 9.416720162697043,
            "mae": 0.5120875752146121,
            "precision": 0.6312056737588653,
            "recall": 0.18200408997955012
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6005131691197803,
            "auditor_fn_violation": 0.007912845390271851,
            "auditor_fp_violation": 0.0029189822449090103,
            "ave_precision_score": 0.5975370654371928,
            "fpr": 0.052689352360043906,
            "logloss": 8.77448903697794,
            "mae": 0.4756466392840536,
            "precision": 0.6712328767123288,
            "recall": 0.210752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.768092105263158,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5361842105263158,
            "fpr": 0.46381578947368424,
            "logloss": 0.691934318712004,
            "mae": 0.49930010539920705,
            "precision": 0.5361842105263158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7552140504939626,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5104281009879253,
            "fpr": 0.48957189901207465,
            "logloss": 0.6929308202446893,
            "mae": 0.4997982940218451,
            "precision": 0.5104281009879253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6763070256997883,
            "auditor_fn_violation": 0.015030226383955826,
            "auditor_fp_violation": 0.012038073908174692,
            "ave_precision_score": 0.6766294587792261,
            "fpr": 0.049342105263157895,
            "logloss": 5.228597146221179,
            "mae": 0.45935248095381337,
            "precision": 0.7680412371134021,
            "recall": 0.3047034764826176
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6755330185320553,
            "auditor_fn_violation": 0.021717833410053955,
            "auditor_fp_violation": 0.009012911450975374,
            "ave_precision_score": 0.6755887958523118,
            "fpr": 0.059275521405049394,
            "logloss": 4.890082429555249,
            "mae": 0.4339426590443017,
            "precision": 0.7440758293838863,
            "recall": 0.33763440860215055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7868965064437178,
            "auditor_fn_violation": 0.0386731783446346,
            "auditor_fp_violation": 0.007652108995893992,
            "ave_precision_score": 0.7759258167751378,
            "fpr": 0.041666666666666664,
            "logloss": 0.592537640112284,
            "mae": 0.37902335887938216,
            "precision": 0.8766233766233766,
            "recall": 0.5521472392638037
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.757953664163729,
            "auditor_fn_violation": 0.03565501693754942,
            "auditor_fp_violation": 0.010497014565376833,
            "ave_precision_score": 0.7423658380648281,
            "fpr": 0.06476399560922064,
            "logloss": 0.581553032086772,
            "mae": 0.3735610650674441,
            "precision": 0.8244047619047619,
            "recall": 0.5956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7703287731352872,
            "auditor_fn_violation": 0.011657787105801313,
            "auditor_fp_violation": 0.010226141595122563,
            "ave_precision_score": 0.7687240787887574,
            "fpr": 0.08442982456140351,
            "logloss": 0.6225178702458717,
            "mae": 0.4129645982185346,
            "precision": 0.7924528301886793,
            "recall": 0.6012269938650306
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7321656615043972,
            "auditor_fn_violation": 0.02094118480223789,
            "auditor_fp_violation": 0.020811900390346198,
            "ave_precision_score": 0.7214333213720218,
            "fpr": 0.11855104281009879,
            "logloss": 0.629607277802306,
            "mae": 0.41650404522663675,
            "precision": 0.7194805194805195,
            "recall": 0.5956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7719628935172527,
            "auditor_fn_violation": 0.005083324364079936,
            "auditor_fp_violation": 0.018049334328729634,
            "ave_precision_score": 0.713269426060135,
            "fpr": 0.2598684210526316,
            "logloss": 0.5982681427937654,
            "mae": 0.4122833326099473,
            "precision": 0.6381679389312978,
            "recall": 0.8548057259713702
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7537198113446502,
            "auditor_fn_violation": 0.008089892945245095,
            "auditor_fp_violation": 0.009559297672197807,
            "ave_precision_score": 0.6890462035218334,
            "fpr": 0.27332601536772777,
            "logloss": 0.6056657555420978,
            "mae": 0.4146497697619523,
            "precision": 0.6186830015313936,
            "recall": 0.8688172043010752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7022683424324484,
            "mae": 0.5009984915520538,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7014522962257771,
            "mae": 0.5007945413647054,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8522310568726343,
            "auditor_fn_violation": 0.011189143615685432,
            "auditor_fp_violation": 0.011314856289660323,
            "ave_precision_score": 0.8561522639126397,
            "fpr": 0.16776315789473684,
            "logloss": 0.5156404544369207,
            "mae": 0.34269329864253995,
            "precision": 0.7325174825174825,
            "recall": 0.8568507157464212
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8367550111596286,
            "auditor_fn_violation": 0.01249955738111257,
            "auditor_fp_violation": 0.010917879627669798,
            "ave_precision_score": 0.8269419706054116,
            "fpr": 0.18441273326015367,
            "logloss": 0.5355738043705346,
            "mae": 0.3474533611460784,
            "precision": 0.7062937062937062,
            "recall": 0.8688172043010752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8017354968561632,
            "auditor_fn_violation": 0.008581333189825284,
            "auditor_fp_violation": 0.019612417568744562,
            "ave_precision_score": 0.7549309453759012,
            "fpr": 0.13157894736842105,
            "logloss": 3.8456676323021792,
            "mae": 0.3048946871361104,
            "precision": 0.7430406852248393,
            "recall": 0.7096114519427403
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7665431337279052,
            "auditor_fn_violation": 0.014659537551786414,
            "auditor_fp_violation": 0.02715933311346621,
            "ave_precision_score": 0.7064687012632185,
            "fpr": 0.150384193194292,
            "logloss": 4.549767130237698,
            "mae": 0.30550461600582807,
            "precision": 0.7157676348547718,
            "recall": 0.7419354838709677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7901433403243556,
            "auditor_fn_violation": 0.008307770961145194,
            "auditor_fp_violation": 0.01586672058396583,
            "ave_precision_score": 0.670898405576035,
            "fpr": 0.1206140350877193,
            "logloss": 0.6144637995370276,
            "mae": 0.434079246432112,
            "precision": 0.7423887587822015,
            "recall": 0.6482617586912065
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7554869783314144,
            "auditor_fn_violation": 0.01842710952161751,
            "auditor_fp_violation": 0.02606409947182666,
            "ave_precision_score": 0.6253012977200919,
            "fpr": 0.14489571899012074,
            "logloss": 0.6377436004447211,
            "mae": 0.44437757749458046,
            "precision": 0.6901408450704225,
            "recall": 0.632258064516129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8612208841143649,
            "auditor_fn_violation": 0.012922451835109247,
            "auditor_fp_violation": 0.0071388577827547605,
            "ave_precision_score": 0.8423370814899742,
            "fpr": 0.08333333333333333,
            "logloss": 0.49313067020674034,
            "mae": 0.3248418847409387,
            "precision": 0.8264840182648402,
            "recall": 0.7402862985685071
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8185614600712686,
            "auditor_fn_violation": 0.008226809721091093,
            "auditor_fp_violation": 0.004400624160115775,
            "ave_precision_score": 0.7974770738293768,
            "fpr": 0.10428100987925357,
            "logloss": 0.5292257069619333,
            "mae": 0.34319190593471116,
            "precision": 0.7816091954022989,
            "recall": 0.7311827956989247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7793809704317947,
            "auditor_fn_violation": 0.019198686901302334,
            "auditor_fp_violation": 0.009611795446061971,
            "ave_precision_score": 0.7771126558276615,
            "fpr": 0.14802631578947367,
            "logloss": 0.7472919120519644,
            "mae": 0.3554599026517775,
            "precision": 0.7433460076045627,
            "recall": 0.7995910020449898
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7331641988741319,
            "auditor_fn_violation": 0.010788097683037666,
            "auditor_fp_violation": 0.005559848980817419,
            "ave_precision_score": 0.7308340976812996,
            "fpr": 0.1877058177826564,
            "logloss": 0.8060939432038617,
            "mae": 0.380716899827503,
            "precision": 0.6879562043795621,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8741731841042706,
            "auditor_fn_violation": 0.006908567430847057,
            "auditor_fp_violation": 0.018451121894570946,
            "ave_precision_score": 0.8743594532523173,
            "fpr": 0.16885964912280702,
            "logloss": 0.5036044293829289,
            "mae": 0.3379555466143708,
            "precision": 0.7363013698630136,
            "recall": 0.8793456032719836
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.837453975441128,
            "auditor_fn_violation": 0.011342846688620564,
            "auditor_fp_violation": 0.009155661004267726,
            "ave_precision_score": 0.8378135391908169,
            "fpr": 0.19099890230515917,
            "logloss": 0.5456003004092275,
            "mae": 0.3523914255406278,
            "precision": 0.6984402079722704,
            "recall": 0.8666666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.679810801656207,
            "auditor_fn_violation": 0.048945215800236794,
            "auditor_fp_violation": 0.04268539255941272,
            "ave_precision_score": 0.6806645203319406,
            "fpr": 0.13157894736842105,
            "logloss": 2.138099616927352,
            "mae": 0.41525202154666,
            "precision": 0.6638655462184874,
            "recall": 0.48466257668711654
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6263583547930693,
            "auditor_fn_violation": 0.051506674692822496,
            "auditor_fp_violation": 0.042539366881119166,
            "ave_precision_score": 0.6276689888232933,
            "fpr": 0.14928649835345773,
            "logloss": 2.1521476236322425,
            "mae": 0.4116161367251877,
            "precision": 0.6353887399463807,
            "recall": 0.5096774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5102572662223621,
            "auditor_fn_violation": 0.0062560542460445775,
            "auditor_fp_violation": 0.005917942018165986,
            "ave_precision_score": 0.5117665179354072,
            "fpr": 0.12938596491228072,
            "logloss": 0.6944392688204699,
            "mae": 0.5005782584806806,
            "precision": 0.5021097046413502,
            "recall": 0.24335378323108384
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.5041526515251668,
            "auditor_fn_violation": 0.009395323583914643,
            "auditor_fp_violation": 0.008769252730700507,
            "ave_precision_score": 0.5063235901013406,
            "fpr": 0.132821075740944,
            "logloss": 0.6935570833135939,
            "mae": 0.5001415083293203,
            "precision": 0.47619047619047616,
            "recall": 0.23655913978494625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.845097223943181,
            "auditor_fn_violation": 0.01562668173501238,
            "auditor_fp_violation": 0.03630604288499025,
            "ave_precision_score": 0.8451052369112857,
            "fpr": 0.20614035087719298,
            "logloss": 0.5400130094109766,
            "mae": 0.36640426459346426,
            "precision": 0.6877076411960132,
            "recall": 0.8466257668711656
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7989887418842664,
            "auditor_fn_violation": 0.010268758188449419,
            "auditor_fp_violation": 0.02838008791403524,
            "ave_precision_score": 0.7988429749867019,
            "fpr": 0.23600439077936333,
            "logloss": 0.5965967489904234,
            "mae": 0.38729721863072214,
            "precision": 0.6498371335504886,
            "recall": 0.8580645161290322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5814181174510964,
            "auditor_fn_violation": 0.006832328776952619,
            "auditor_fp_violation": 0.00868379577786073,
            "ave_precision_score": 0.5306204673423662,
            "fpr": 0.13267543859649122,
            "logloss": 0.7094520305578612,
            "mae": 0.5020423012932664,
            "precision": 0.5140562248995983,
            "recall": 0.261758691206544
        },
        "train": {
            "accuracy": 0.446761800219539,
            "auc_prc": 0.5272297061622031,
            "auditor_fn_violation": 0.012457065967919005,
            "auditor_fp_violation": 0.007664174292282174,
            "ave_precision_score": 0.4934854683074755,
            "fpr": 0.16465422612513722,
            "logloss": 0.7216475522655782,
            "mae": 0.5076910147420923,
            "precision": 0.42528735632183906,
            "recall": 0.23870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 24284,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6699907442274845,
            "auditor_fn_violation": 0.007276306820220286,
            "auditor_fp_violation": 0.035476545974866235,
            "ave_precision_score": 0.6674710501809404,
            "fpr": 0.2807017543859649,
            "logloss": 0.6433097833369347,
            "mae": 0.4440312968370946,
            "precision": 0.6337625178826896,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.59491391236871,
            "auditor_fn_violation": 0.0069591492274825055,
            "auditor_fp_violation": 0.034759516226686306,
            "ave_precision_score": 0.5987583546548079,
            "fpr": 0.31284302963776073,
            "logloss": 0.6831620903269754,
            "mae": 0.4619768485835826,
            "precision": 0.5875542691751086,
            "recall": 0.8731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8165165196856912,
            "auditor_fn_violation": 0.0017310659060739795,
            "auditor_fp_violation": 0.012266185558458799,
            "ave_precision_score": 0.8169860264455294,
            "fpr": 0.11403508771929824,
            "logloss": 0.5707645562059269,
            "mae": 0.34303806523735547,
            "precision": 0.7647058823529411,
            "recall": 0.6912065439672802
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7933330583129022,
            "auditor_fn_violation": 0.0036920316797091784,
            "auditor_fp_violation": 0.014294644922792183,
            "ave_precision_score": 0.7936901410460513,
            "fpr": 0.13721185510428102,
            "logloss": 0.588710056953884,
            "mae": 0.34602716297415564,
            "precision": 0.7258771929824561,
            "recall": 0.7118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 24284,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6539811161145839,
            "auditor_fn_violation": 0.03664612707638216,
            "auditor_fp_violation": 0.08047675334909378,
            "ave_precision_score": 0.6195441983898824,
            "fpr": 0.3168859649122807,
            "logloss": 0.6647236583717123,
            "mae": 0.4579322395494959,
            "precision": 0.5980528511821975,
            "recall": 0.8793456032719836
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.655268466450984,
            "auditor_fn_violation": 0.04108919655819553,
            "auditor_fp_violation": 0.08050090326010446,
            "ave_precision_score": 0.6141286841786293,
            "fpr": 0.32491767288693746,
            "logloss": 0.6666499430634614,
            "mae": 0.45586008816941115,
            "precision": 0.5722543352601156,
            "recall": 0.8516129032258064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7677556311989844,
            "auditor_fn_violation": 0.0027647723603487244,
            "auditor_fp_violation": 0.005622433743934302,
            "ave_precision_score": 0.546822909593459,
            "fpr": 0.4331140350877193,
            "logloss": 0.6876346203471578,
            "mae": 0.4950759327529292,
            "precision": 0.5470183486238532,
            "recall": 0.9754601226993865
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7526593161855519,
            "auditor_fn_violation": 0.0018058850607273113,
            "auditor_fp_violation": 0.00359827322264501,
            "ave_precision_score": 0.5211039255323852,
            "fpr": 0.45334796926454446,
            "logloss": 0.6898569921742195,
            "mae": 0.49574499494681373,
            "precision": 0.5214368482039398,
            "recall": 0.967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7340762741103642,
            "auditor_fn_violation": 0.019357891149140747,
            "auditor_fp_violation": 0.04080087926672473,
            "ave_precision_score": 0.743811087952894,
            "fpr": 0.1699561403508772,
            "logloss": 0.6152517303223046,
            "mae": 0.4181092981118382,
            "precision": 0.6849593495934959,
            "recall": 0.689161554192229
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6777216927280997,
            "auditor_fn_violation": 0.013880528309904041,
            "auditor_fp_violation": 0.03777448524018843,
            "ave_precision_score": 0.6852991273831077,
            "fpr": 0.20197585071350166,
            "logloss": 0.6435997963654879,
            "mae": 0.43021672643500286,
            "precision": 0.6377952755905512,
            "recall": 0.6967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 24284,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5921962948135469,
            "auditor_fn_violation": 0.008671025723818754,
            "auditor_fp_violation": 0.011203392642362408,
            "ave_precision_score": 0.5933615285089203,
            "fpr": 0.03728070175438596,
            "logloss": 9.330899128322768,
            "mae": 0.5095629399819213,
            "precision": 0.6046511627906976,
            "recall": 0.10633946830265849
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.5877462510340905,
            "auditor_fn_violation": 0.0064067608559659215,
            "auditor_fp_violation": 0.010770207675988049,
            "ave_precision_score": 0.5891384259472032,
            "fpr": 0.038419319429198684,
            "logloss": 8.33737987723666,
            "mae": 0.4804501375578949,
            "precision": 0.6236559139784946,
            "recall": 0.12473118279569892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6169135049015236,
            "auditor_fn_violation": 0.013810407921644613,
            "auditor_fp_violation": 0.011384845091452036,
            "ave_precision_score": 0.6187193709882431,
            "fpr": 0.08991228070175439,
            "logloss": 0.7895863455783557,
            "mae": 0.47729154355137754,
            "precision": 0.6940298507462687,
            "recall": 0.3803680981595092
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5683399643510733,
            "auditor_fn_violation": 0.007273113558301768,
            "auditor_fp_violation": 0.013492293985321412,
            "ave_precision_score": 0.5704435000402649,
            "fpr": 0.10976948408342481,
            "logloss": 0.7958865286468878,
            "mae": 0.48051801258871896,
            "precision": 0.6415770609318996,
            "recall": 0.3849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8027203526028959,
            "auditor_fn_violation": 0.01685546945072292,
            "auditor_fp_violation": 0.014298452988262628,
            "ave_precision_score": 0.7442002484587178,
            "fpr": 0.14692982456140352,
            "logloss": 6.768384805299288,
            "mae": 0.30488437670487595,
            "precision": 0.7214137214137214,
            "recall": 0.7096114519427403
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7662708640163509,
            "auditor_fn_violation": 0.01654804480483458,
            "auditor_fp_violation": 0.028995387712709146,
            "ave_precision_score": 0.6902387816003901,
            "fpr": 0.17014270032930845,
            "logloss": 7.389777981695399,
            "mae": 0.32095867279696616,
            "precision": 0.6790890269151139,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7981781732669302,
            "auditor_fn_violation": 0.007962454705270334,
            "auditor_fp_violation": 0.02620173364854217,
            "ave_precision_score": 0.7502785645794029,
            "fpr": 0.22149122807017543,
            "logloss": 4.549365933493124,
            "mae": 0.29941161013683,
            "precision": 0.6693944353518821,
            "recall": 0.83640081799591
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.759149216415905,
            "auditor_fn_violation": 0.006975673665946673,
            "auditor_fp_violation": 0.021722544092383576,
            "ave_precision_score": 0.6993382661193401,
            "fpr": 0.2283205268935236,
            "logloss": 5.25871364101042,
            "mae": 0.3121646310452095,
            "precision": 0.6521739130434783,
            "recall": 0.8387096774193549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7494203116877647,
            "auditor_fn_violation": 0.012572650952534714,
            "auditor_fp_violation": 0.011216353531583102,
            "ave_precision_score": 0.6824312959088024,
            "fpr": 0.31469298245614036,
            "logloss": 0.6392618961618006,
            "mae": 0.43490344972202655,
            "precision": 0.5991620111731844,
            "recall": 0.8773006134969326
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7541741544502292,
            "auditor_fn_violation": 0.004716546864487803,
            "auditor_fp_violation": 0.017700944608250935,
            "ave_precision_score": 0.6838929478842823,
            "fpr": 0.33150384193194293,
            "logloss": 0.6449239287060644,
            "mae": 0.4369805230463637,
            "precision": 0.5746478873239437,
            "recall": 0.8774193548387097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6681226483424194,
            "auditor_fn_violation": 0.016400279840706057,
            "auditor_fp_violation": 0.02157210401891254,
            "ave_precision_score": 0.6691987800525403,
            "fpr": 0.1962719298245614,
            "logloss": 0.6976835097368133,
            "mae": 0.43135576103009443,
            "precision": 0.6316872427983539,
            "recall": 0.6278118609406953
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6073548654720913,
            "auditor_fn_violation": 0.009917023712569204,
            "auditor_fp_violation": 0.008247478501425034,
            "ave_precision_score": 0.6092894681662202,
            "fpr": 0.22283205268935236,
            "logloss": 0.7354589899441502,
            "mae": 0.44293509307154505,
            "precision": 0.5898989898989899,
            "recall": 0.6279569892473118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 24284,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.826647566987078,
            "auditor_fn_violation": 0.012426900584795323,
            "auditor_fp_violation": 0.0048473725685371834,
            "ave_precision_score": 0.827881240490081,
            "fpr": 0.020833333333333332,
            "logloss": 0.9493054552366739,
            "mae": 0.384664789704131,
            "precision": 0.8972972972972973,
            "recall": 0.3394683026584867
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7703440418975643,
            "auditor_fn_violation": 0.017433282579700917,
            "auditor_fp_violation": 0.008220405310283384,
            "ave_precision_score": 0.7707664156649917,
            "fpr": 0.030735455543358946,
            "logloss": 0.9723733426057258,
            "mae": 0.3820884459774588,
            "precision": 0.8541666666666666,
            "recall": 0.35268817204301073
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8267336809535488,
            "auditor_fn_violation": 0.006141696265202892,
            "auditor_fp_violation": 0.0031987474596657166,
            "ave_precision_score": 0.8178149085757352,
            "fpr": 0.0668859649122807,
            "logloss": 0.5370240081604921,
            "mae": 0.33954293756304604,
            "precision": 0.8439897698209718,
            "recall": 0.6748466257668712
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8060970991712237,
            "auditor_fn_violation": 0.007334490044025829,
            "auditor_fp_violation": 0.005636146155852983,
            "ave_precision_score": 0.7962327820751189,
            "fpr": 0.0867178924259056,
            "logloss": 0.5372814355169623,
            "mae": 0.3357423112925007,
            "precision": 0.8049382716049382,
            "recall": 0.7010752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8447063782835954,
            "auditor_fn_violation": 0.011404405697269767,
            "auditor_fp_violation": 0.011431504292646512,
            "ave_precision_score": 0.8452116341143032,
            "fpr": 0.09868421052631579,
            "logloss": 0.5082797606536215,
            "mae": 0.3433544180813458,
            "precision": 0.7991071428571429,
            "recall": 0.7321063394683026
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.823162817184116,
            "auditor_fn_violation": 0.0061376485724065465,
            "auditor_fp_violation": 0.012753934226912721,
            "ave_precision_score": 0.8235691432264934,
            "fpr": 0.10537870472008781,
            "logloss": 0.5227492310430252,
            "mae": 0.34668289569874106,
            "precision": 0.7741176470588236,
            "recall": 0.7075268817204301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5918472833612949,
            "auditor_fn_violation": 0.010819161912962373,
            "auditor_fp_violation": 0.007076645514495463,
            "ave_precision_score": 0.5908149270394729,
            "fpr": 0.1337719298245614,
            "logloss": 0.6712243047144729,
            "mae": 0.47917964306186167,
            "precision": 0.6336336336336337,
            "recall": 0.43149284253578735
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.5870159882142948,
            "auditor_fn_violation": 0.002910661803760484,
            "auditor_fp_violation": 0.003856699138088047,
            "ave_precision_score": 0.5819662528686599,
            "fpr": 0.12403951701427003,
            "logloss": 0.6693851708167066,
            "mae": 0.47841541738986443,
            "precision": 0.630718954248366,
            "recall": 0.4150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8448802850962875,
            "auditor_fn_violation": 0.009455835396261618,
            "auditor_fp_violation": 0.007115528182157524,
            "ave_precision_score": 0.8466034702400371,
            "fpr": 0.06578947368421052,
            "logloss": 0.516476034869901,
            "mae": 0.3164661180620131,
            "precision": 0.8465473145780051,
            "recall": 0.6768916155419223
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8328877596890588,
            "auditor_fn_violation": 0.010403314330229105,
            "auditor_fp_violation": 0.010834198855050138,
            "ave_precision_score": 0.8147086768013313,
            "fpr": 0.08781558726673985,
            "logloss": 0.515985369606487,
            "mae": 0.31434678174269054,
            "precision": 0.8062953995157385,
            "recall": 0.7161290322580646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8718386214969289,
            "auditor_fn_violation": 0.014178147311017835,
            "auditor_fp_violation": 0.012051034797395381,
            "ave_precision_score": 0.8691129688819345,
            "fpr": 0.10964912280701754,
            "logloss": 0.4773600197026255,
            "mae": 0.32367317184903904,
            "precision": 0.7938144329896907,
            "recall": 0.787321063394683
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8172681736547163,
            "auditor_fn_violation": 0.008819328871734951,
            "auditor_fp_violation": 0.01998001506253907,
            "ave_precision_score": 0.8139833427669059,
            "fpr": 0.14709110867178923,
            "logloss": 0.5153687665474703,
            "mae": 0.3385571896432849,
            "precision": 0.7357001972386588,
            "recall": 0.8021505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7594387928332215,
            "auditor_fn_violation": 0.01213764216266638,
            "auditor_fp_violation": 0.016818049852764295,
            "ave_precision_score": 0.7591655502497994,
            "fpr": 0.12280701754385964,
            "logloss": 1.4968934639248306,
            "mae": 0.39526772090502205,
            "precision": 0.7314148681055156,
            "recall": 0.623721881390593
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7084574508881334,
            "auditor_fn_violation": 0.01010587443787402,
            "auditor_fp_violation": 0.02152072575841854,
            "ave_precision_score": 0.7082655255797337,
            "fpr": 0.13611416026344675,
            "logloss": 1.6969908447928785,
            "mae": 0.4066713662562366,
            "precision": 0.6945812807881774,
            "recall": 0.6064516129032258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7965823667989562,
            "auditor_fn_violation": 0.009502923976608192,
            "auditor_fp_violation": 0.009121873833519973,
            "ave_precision_score": 0.7596745284270714,
            "fpr": 0.08442982456140351,
            "logloss": 0.5553765430192461,
            "mae": 0.38226157705413927,
            "precision": 0.8089330024813896,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7716356270772635,
            "auditor_fn_violation": 0.00716688502531781,
            "auditor_fp_violation": 0.011043400786599263,
            "ave_precision_score": 0.7277005948739537,
            "fpr": 0.10647639956092206,
            "logloss": 0.568475602783414,
            "mae": 0.38775409429316726,
            "precision": 0.7634146341463415,
            "recall": 0.6731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7229144933767184,
            "auditor_fn_violation": 0.05653993111613389,
            "auditor_fp_violation": 0.028742067935796943,
            "ave_precision_score": 0.7234466598756913,
            "fpr": 0.08223684210526316,
            "logloss": 0.6695239161143409,
            "mae": 0.4220790877718725,
            "precision": 0.755700325732899,
            "recall": 0.47443762781186094
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6883078947542136,
            "auditor_fn_violation": 0.049601643001310154,
            "auditor_fp_violation": 0.017287463143542063,
            "ave_precision_score": 0.6893488132333598,
            "fpr": 0.07574094401756312,
            "logloss": 0.7042375158889759,
            "mae": 0.4252085913482853,
            "precision": 0.764505119453925,
            "recall": 0.4817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.5176617810638636,
            "auditor_fn_violation": 0.0007265095253471292,
            "auditor_fp_violation": 0.0023873957944506663,
            "ave_precision_score": 0.536492127713471,
            "fpr": 0.006578947368421052,
            "logloss": 18.308052463228663,
            "mae": 0.5360928555591065,
            "precision": 0.5,
            "recall": 0.012269938650306749
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.48654605972618786,
            "auditor_fn_violation": 0.0014281836101176883,
            "auditor_fp_violation": 0.0017449902290391972,
            "ave_precision_score": 0.5143661500812452,
            "fpr": 0.005488474204171241,
            "logloss": 17.45442420472997,
            "mae": 0.5107522109271928,
            "precision": 0.5,
            "recall": 0.010752688172043012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8543564798417488,
            "auditor_fn_violation": 0.003130269436372122,
            "auditor_fp_violation": 0.00989175065322882,
            "ave_precision_score": 0.8545443330860021,
            "fpr": 0.09758771929824561,
            "logloss": 0.6540339625083492,
            "mae": 0.33578727626764593,
            "precision": 0.8013392857142857,
            "recall": 0.7341513292433538
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8241015979585038,
            "auditor_fn_violation": 0.005500277374502793,
            "auditor_fp_violation": 0.014223270146146012,
            "ave_precision_score": 0.824336863011395,
            "fpr": 0.11306256860592755,
            "logloss": 0.7325603409465179,
            "mae": 0.3386437116818488,
            "precision": 0.7674943566591422,
            "recall": 0.7311827956989247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7639229945414241,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.002957674920160943,
            "ave_precision_score": 0.5410020287501941,
            "fpr": 0.45285087719298245,
            "logloss": 15.294529307354779,
            "mae": 0.45664742106383893,
            "precision": 0.5400890868596881,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7473198295349418,
            "auditor_fn_violation": 4.721268132620428e-05,
            "auditor_fp_violation": 0.0032143261482724837,
            "ave_precision_score": 0.5125324645183736,
            "fpr": 0.4807903402854007,
            "logloss": 16.22510607765038,
            "mae": 0.48912069817716675,
            "precision": 0.5106145251396648,
            "recall": 0.9827956989247312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6228121266454434,
            "auditor_fn_violation": 0.010709288558820373,
            "auditor_fp_violation": 0.015195346522334207,
            "ave_precision_score": 0.6192991233006766,
            "fpr": 0.13048245614035087,
            "logloss": 10.613272708528577,
            "mae": 0.45167595712915093,
            "precision": 0.6246056782334385,
            "recall": 0.4049079754601227
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5874237222270889,
            "auditor_fn_violation": 0.01627657188720891,
            "auditor_fp_violation": 0.02159948413264879,
            "ave_precision_score": 0.5794374728903687,
            "fpr": 0.14050493962678376,
            "logloss": 10.126266038440496,
            "mae": 0.44949067043590507,
            "precision": 0.5974842767295597,
            "recall": 0.40860215053763443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.768976897689769,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5379537953795379,
            "fpr": 0.46381578947368424,
            "logloss": 15.942720692013733,
            "mae": 0.4638126276825604,
            "precision": 0.5361842105263158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.755828981762485,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005906878067269513,
            "ave_precision_score": 0.5127071220618449,
            "fpr": 0.4884742041712404,
            "logloss": 16.756724139356646,
            "mae": 0.4883386159184275,
            "precision": 0.510989010989011,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7920601829644032,
            "auditor_fn_violation": 0.019961073440246845,
            "auditor_fp_violation": 0.009497739620919916,
            "ave_precision_score": 0.7900998205608278,
            "fpr": 0.09429824561403509,
            "logloss": 3.137076576951515,
            "mae": 0.3189352366425465,
            "precision": 0.7730870712401056,
            "recall": 0.5991820040899796
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7222504632269758,
            "auditor_fn_violation": 0.019003104233797207,
            "auditor_fp_violation": 0.018454071561827785,
            "ave_precision_score": 0.7167419979874206,
            "fpr": 0.13172338090010977,
            "logloss": 3.2617176410499633,
            "mae": 0.3388159834383256,
            "precision": 0.7115384615384616,
            "recall": 0.6365591397849463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7781916494207921,
            "auditor_fn_violation": 0.014711817888278987,
            "auditor_fp_violation": 0.0035460992907801426,
            "ave_precision_score": 0.7786704943980127,
            "fpr": 0.01644736842105263,
            "logloss": 0.8087812068925596,
            "mae": 0.42509243222721443,
            "precision": 0.9,
            "recall": 0.27607361963190186
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7589740036660764,
            "auditor_fn_violation": 0.014730356573775714,
            "auditor_fp_violation": 0.004991311966842725,
            "ave_precision_score": 0.7594899821612712,
            "fpr": 0.027442371020856202,
            "logloss": 0.7661969289389879,
            "mae": 0.40712845592292357,
            "precision": 0.8571428571428571,
            "recall": 0.3225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7693557993266197,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5424538841923711,
            "fpr": 0.44846491228070173,
            "logloss": 0.6903518211669971,
            "mae": 0.498258293263222,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7515077950614736,
            "auditor_fn_violation": 0.0013455614177968205,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5134770090894271,
            "fpr": 0.47310647639956094,
            "logloss": 0.6926632434830676,
            "mae": 0.4994137435333658,
            "precision": 0.5135440180586908,
            "recall": 0.978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.780551920655675,
            "auditor_fn_violation": 0.016519122448247412,
            "auditor_fp_violation": 0.010482767201692174,
            "ave_precision_score": 0.6999796897158476,
            "fpr": 0.09210526315789473,
            "logloss": 0.6713834748087288,
            "mae": 0.4039489636994212,
            "precision": 0.7653631284916201,
            "recall": 0.5603271983640081
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7728892242771828,
            "auditor_fn_violation": 0.022579464844257168,
            "auditor_fp_violation": 0.02938425718547105,
            "ave_precision_score": 0.6893990230876222,
            "fpr": 0.0889132821075741,
            "logloss": 0.6370719204633308,
            "mae": 0.39671344485677756,
            "precision": 0.7624633431085044,
            "recall": 0.5591397849462365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8317834818310132,
            "auditor_fn_violation": 0.010736196319018405,
            "auditor_fp_violation": 0.021704305088963552,
            "ave_precision_score": 0.832070635768819,
            "fpr": 0.18969298245614036,
            "logloss": 0.8650988334757881,
            "mae": 0.28853800191416884,
            "precision": 0.7012089810017271,
            "recall": 0.8302658486707567
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7972118125589844,
            "auditor_fn_violation": 0.009832040886182032,
            "auditor_fp_violation": 0.02970667427997618,
            "ave_precision_score": 0.7976215763941911,
            "fpr": 0.19978046103183314,
            "logloss": 0.9562223098526313,
            "mae": 0.2933916136848751,
            "precision": 0.6829268292682927,
            "recall": 0.843010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7979846502070197,
            "auditor_fn_violation": 0.02478204714239588,
            "auditor_fp_violation": 0.019127680311890837,
            "ave_precision_score": 0.7900565241964195,
            "fpr": 0.10307017543859649,
            "logloss": 2.659907565007397,
            "mae": 0.2850316010589206,
            "precision": 0.7772511848341233,
            "recall": 0.6707566462167689
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7503615020140412,
            "auditor_fn_violation": 0.02732906058567332,
            "auditor_fp_violation": 0.028397316308398105,
            "ave_precision_score": 0.7378141716542028,
            "fpr": 0.13391877058177826,
            "logloss": 2.751850769013358,
            "mae": 0.29678167011721324,
            "precision": 0.735357917570499,
            "recall": 0.7290322580645161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.857534132213251,
            "auditor_fn_violation": 0.003455404872098444,
            "auditor_fp_violation": 0.020234540251337568,
            "ave_precision_score": 0.8577393180900561,
            "fpr": 0.0756578947368421,
            "logloss": 0.5137170524311312,
            "mae": 0.3249901047981295,
            "precision": 0.8239795918367347,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.824358171727306,
            "auditor_fn_violation": 0.007693306422104983,
            "auditor_fp_violation": 0.007792156650406348,
            "ave_precision_score": 0.8248784900997348,
            "fpr": 0.07683863885839737,
            "logloss": 0.520340834476807,
            "mae": 0.32451201233558935,
            "precision": 0.8186528497409327,
            "recall": 0.6795698924731183
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.733281519569529,
            "auditor_fn_violation": 0.013290191224482474,
            "auditor_fp_violation": 0.010303906930446697,
            "ave_precision_score": 0.7346483159746782,
            "fpr": 0.29276315789473684,
            "logloss": 0.9963387955061552,
            "mae": 0.40408926833065617,
            "precision": 0.5929878048780488,
            "recall": 0.7955010224948875
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7137924179686057,
            "auditor_fn_violation": 0.008290546840881463,
            "auditor_fp_violation": 0.005350647049268286,
            "ave_precision_score": 0.715209388549004,
            "fpr": 0.3062568605927552,
            "logloss": 1.0766032461104516,
            "mae": 0.40244795522385746,
            "precision": 0.5823353293413174,
            "recall": 0.8365591397849462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5608150989725458,
            "auditor_fn_violation": 0.003829871201521203,
            "auditor_fp_violation": 0.0017808261789224835,
            "ave_precision_score": 0.5579251370869516,
            "fpr": 0.005482456140350877,
            "logloss": 14.490888115346335,
            "mae": 0.525233857554065,
            "precision": 0.8148148148148148,
            "recall": 0.044989775051124746
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5736600004834096,
            "auditor_fn_violation": 0.003821866553356225,
            "auditor_fp_violation": 0.001137074027949378,
            "ave_precision_score": 0.5681660794024392,
            "fpr": 0.0043907793633369925,
            "logloss": 13.198999083132845,
            "mae": 0.49368519106035647,
            "precision": 0.8666666666666667,
            "recall": 0.05591397849462366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6700297046013658,
            "auditor_fn_violation": 0.02044317081046174,
            "auditor_fp_violation": 0.028879453361536227,
            "ave_precision_score": 0.6698614300315601,
            "fpr": 0.32785087719298245,
            "logloss": 0.644872505263634,
            "mae": 0.42924519510645615,
            "precision": 0.5975773889636609,
            "recall": 0.9079754601226994
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6448558114827458,
            "auditor_fn_violation": 0.024456168926973786,
            "auditor_fp_violation": 0.03801814396046331,
            "ave_precision_score": 0.6402731705250259,
            "fpr": 0.36553238199780463,
            "logloss": 0.6635581774933669,
            "mae": 0.43648589280169175,
            "precision": 0.5583554376657824,
            "recall": 0.9053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.5746721444899512,
            "auditor_fn_violation": 0.007621623076095148,
            "auditor_fp_violation": 0.030071855169839495,
            "ave_precision_score": 0.5895955344385763,
            "fpr": 0.28618421052631576,
            "logloss": 1.1610726648805332,
            "mae": 0.43232065785610885,
            "precision": 0.6297872340425532,
            "recall": 0.9079754601226994
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.568821468661792,
            "auditor_fn_violation": 0.0056796855635423684,
            "auditor_fp_violation": 0.03398916087874655,
            "ave_precision_score": 0.5667777231463009,
            "fpr": 0.3205268935236004,
            "logloss": 1.2295750456947687,
            "mae": 0.446978128767694,
            "precision": 0.5858156028368794,
            "recall": 0.8881720430107527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7661759053278994,
            "auditor_fn_violation": 0.004838912208947737,
            "auditor_fp_violation": 0.003203931815353988,
            "ave_precision_score": 0.7694322823955246,
            "fpr": 0.01864035087719298,
            "logloss": 0.7861711484053232,
            "mae": 0.40957707043720837,
            "precision": 0.8650793650793651,
            "recall": 0.2229038854805726
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7988247256067765,
            "auditor_fn_violation": 0.006111681597677131,
            "auditor_fp_violation": 0.0025055007802001457,
            "ave_precision_score": 0.765446419397331,
            "fpr": 0.01756311745334797,
            "logloss": 0.716116546702966,
            "mae": 0.3866013385821645,
            "precision": 0.8796992481203008,
            "recall": 0.25161290322580643
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6674673950189024,
            "auditor_fn_violation": 0.13058336024109354,
            "auditor_fp_violation": 0.11413359047737548,
            "ave_precision_score": 0.5366248905367188,
            "fpr": 0.26096491228070173,
            "logloss": 0.7254271713510415,
            "mae": 0.49530000644817684,
            "precision": 0.5369649805447471,
            "recall": 0.5644171779141104
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6576561166200343,
            "auditor_fn_violation": 0.12497668873859519,
            "auditor_fp_violation": 0.12239051355382397,
            "ave_precision_score": 0.5236237705838641,
            "fpr": 0.24588364434687157,
            "logloss": 0.7179231933170596,
            "mae": 0.49244016768772697,
            "precision": 0.5343035343035343,
            "recall": 0.5526881720430108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8651487481629963,
            "auditor_fn_violation": 0.011375255623721882,
            "auditor_fp_violation": 0.015799323960018253,
            "ave_precision_score": 0.8653431103304641,
            "fpr": 0.14912280701754385,
            "logloss": 0.505772823385455,
            "mae": 0.30497828229706275,
            "precision": 0.7476808905380334,
            "recall": 0.8241308793456033
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8373773816745262,
            "auditor_fn_violation": 0.00548847420417124,
            "auditor_fp_violation": 0.01932041367836065,
            "ave_precision_score": 0.8381088504751466,
            "fpr": 0.1712403951701427,
            "logloss": 0.5252973282551173,
            "mae": 0.3086116185777797,
            "precision": 0.7209302325581395,
            "recall": 0.8666666666666667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8761687083084252,
            "auditor_fn_violation": 0.009061188246690352,
            "auditor_fp_violation": 0.013997760358342668,
            "ave_precision_score": 0.8744109060071246,
            "fpr": 0.07894736842105263,
            "logloss": 0.4896719047894737,
            "mae": 0.3247623924786846,
            "precision": 0.8333333333333334,
            "recall": 0.7361963190184049
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8196118348416123,
            "auditor_fn_violation": 0.006720725186785178,
            "auditor_fp_violation": 0.011031094790625785,
            "ave_precision_score": 0.8209681056343,
            "fpr": 0.10098792535675083,
            "logloss": 0.49979827070222416,
            "mae": 0.32843045728397685,
            "precision": 0.7923250564334086,
            "recall": 0.7548387096774194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5656362570544041,
            "auditor_fn_violation": 0.051407275858357554,
            "auditor_fp_violation": 0.05362697523951724,
            "ave_precision_score": 0.5346085655888833,
            "fpr": 0.26864035087719296,
            "logloss": 0.6984436246602854,
            "mae": 0.4991682942368482,
            "precision": 0.5251937984496124,
            "recall": 0.5541922290388548
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5711397665857493,
            "auditor_fn_violation": 0.04410844752900629,
            "auditor_fp_violation": 0.042504910092393426,
            "ave_precision_score": 0.5178589835896589,
            "fpr": 0.2854006586169045,
            "logloss": 0.6932904487350875,
            "mae": 0.4966425644775646,
            "precision": 0.5,
            "recall": 0.5591397849462365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 24284,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8737321101280184,
            "auditor_fn_violation": 0.02959853621784523,
            "auditor_fp_violation": 0.010412778399900461,
            "ave_precision_score": 0.8738792508981306,
            "fpr": 0.07236842105263158,
            "logloss": 0.5166531588860463,
            "mae": 0.3278463905475004,
            "precision": 0.8320610687022901,
            "recall": 0.6687116564417178
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8434591196222139,
            "auditor_fn_violation": 0.024508102876432614,
            "auditor_fp_violation": 0.012894222581010376,
            "ave_precision_score": 0.843771171262821,
            "fpr": 0.09549945115257959,
            "logloss": 0.5200449072563567,
            "mae": 0.330063041991684,
            "precision": 0.7908653846153846,
            "recall": 0.7075268817204301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7648859879051074,
            "auditor_fn_violation": 0.0150481648907545,
            "auditor_fp_violation": 0.022264215503297255,
            "ave_precision_score": 0.7608598791739748,
            "fpr": 0.16447368421052633,
            "logloss": 0.9156815211273033,
            "mae": 0.3539921357868272,
            "precision": 0.6993987975951904,
            "recall": 0.7137014314928425
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7324685884713127,
            "auditor_fn_violation": 0.011798449063418441,
            "auditor_fp_violation": 0.02811427840100811,
            "ave_precision_score": 0.7267206777836653,
            "fpr": 0.17672886937431395,
            "logloss": 1.0067321866210241,
            "mae": 0.36365003600863804,
            "precision": 0.676056338028169,
            "recall": 0.7225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8513991504705436,
            "auditor_fn_violation": 0.0004641588634162109,
            "auditor_fp_violation": 0.00914520343411721,
            "ave_precision_score": 0.8096078180966862,
            "fpr": 0.05921052631578947,
            "logloss": 0.5073149896610886,
            "mae": 0.34379682912115467,
            "precision": 0.8528610354223434,
            "recall": 0.6400817995910021
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8152750491733913,
            "auditor_fn_violation": 0.010417478134626961,
            "auditor_fp_violation": 0.005449095017056111,
            "ave_precision_score": 0.7688820618580043,
            "fpr": 0.07574094401756312,
            "logloss": 0.5296476338145599,
            "mae": 0.34821345932724446,
            "precision": 0.8217054263565892,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.4451211168114271,
            "auditor_fn_violation": 0.007789796577332904,
            "auditor_fp_violation": 0.0012572062544067202,
            "ave_precision_score": 0.43233734277103764,
            "fpr": 0.3793859649122807,
            "logloss": 5.532411982589089,
            "mae": 0.4511410807517199,
            "precision": 0.5728395061728395,
            "recall": 0.9488752556237219
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.4447749339010239,
            "auditor_fn_violation": 0.006215549496594785,
            "auditor_fp_violation": 0.014875487932740367,
            "ave_precision_score": 0.42835767591979074,
            "fpr": 0.37980241492864986,
            "logloss": 5.176789104593269,
            "mae": 0.4467283161643291,
            "precision": 0.5609137055837563,
            "recall": 0.9505376344086022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.830292321796939,
            "auditor_fn_violation": 0.012736339827072793,
            "auditor_fp_violation": 0.009124466011364112,
            "ave_precision_score": 0.8265139562442618,
            "fpr": 0.0581140350877193,
            "logloss": 1.5164569654739186,
            "mae": 0.325638793061362,
            "precision": 0.8284789644012945,
            "recall": 0.523517382413088
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8046028084402441,
            "auditor_fn_violation": 0.006668791237326355,
            "auditor_fp_violation": 0.010782513671961529,
            "ave_precision_score": 0.7978204842083562,
            "fpr": 0.06256860592755215,
            "logloss": 1.7574834807809705,
            "mae": 0.3184773706636624,
            "precision": 0.8143322475570033,
            "recall": 0.5376344086021505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.821090702455036,
            "auditor_fn_violation": 0.0074153302479101684,
            "auditor_fp_violation": 0.012255816847082247,
            "ave_precision_score": 0.8205807296817642,
            "fpr": 0.14473684210526316,
            "logloss": 0.5301474471324057,
            "mae": 0.3416302524784809,
            "precision": 0.7416829745596869,
            "recall": 0.7750511247443763
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7909044974689716,
            "auditor_fn_violation": 0.006494104316419393,
            "auditor_fp_violation": 0.01515606464093565,
            "ave_precision_score": 0.7916341769814076,
            "fpr": 0.17672886937431395,
            "logloss": 0.555355905594111,
            "mae": 0.3506754765125517,
            "precision": 0.6962264150943396,
            "recall": 0.7935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.5963885819151236,
            "auditor_fn_violation": 0.020940964374125504,
            "auditor_fp_violation": 0.058907241508025385,
            "ave_precision_score": 0.5975821576804221,
            "fpr": 0.2532894736842105,
            "logloss": 0.6670842393568901,
            "mae": 0.47772217009281903,
            "precision": 0.6188118811881188,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.5416542760189162,
            "auditor_fn_violation": 0.017463970822562944,
            "auditor_fp_violation": 0.044518171033654436,
            "ave_precision_score": 0.5436118744338457,
            "fpr": 0.27661909989023054,
            "logloss": 0.6787146566242304,
            "mae": 0.4834626942513149,
            "precision": 0.5757575757575758,
            "recall": 0.7354838709677419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8709222114517255,
            "auditor_fn_violation": 0.012478473791841574,
            "auditor_fp_violation": 0.013821492264941313,
            "ave_precision_score": 0.8710776320012605,
            "fpr": 0.08662280701754387,
            "logloss": 0.6281963184243343,
            "mae": 0.2824610367391423,
            "precision": 0.8096385542168675,
            "recall": 0.6871165644171779
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8136065351581098,
            "auditor_fn_violation": 0.016529159732304097,
            "auditor_fp_violation": 0.023602900277131033,
            "ave_precision_score": 0.8143635288341255,
            "fpr": 0.1141602634467618,
            "logloss": 0.6569004726228445,
            "mae": 0.287048159602514,
            "precision": 0.7636363636363637,
            "recall": 0.7225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8251495077567434,
            "auditor_fn_violation": 0.02277741900764181,
            "auditor_fp_violation": 0.011006387126207958,
            "ave_precision_score": 0.8198400093327565,
            "fpr": 0.09978070175438597,
            "logloss": 0.5693681202569171,
            "mae": 0.35723130387793245,
            "precision": 0.7868852459016393,
            "recall": 0.6871165644171779
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7520569665993211,
            "auditor_fn_violation": 0.0278106299352006,
            "auditor_fp_violation": 0.021663475311710877,
            "ave_precision_score": 0.7455311899404562,
            "fpr": 0.13391877058177826,
            "logloss": 0.5828666675362016,
            "mae": 0.36373251063174655,
            "precision": 0.7288888888888889,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5487054199946139,
            "auditor_fn_violation": 0.010050048433968357,
            "auditor_fp_violation": 0.010195035460992905,
            "ave_precision_score": 0.5520437735564634,
            "fpr": 0.44298245614035087,
            "logloss": 0.6899632970525114,
            "mae": 0.4899703519124734,
            "precision": 0.5382857142857143,
            "recall": 0.9631901840490797
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5193323170544403,
            "auditor_fn_violation": 0.00715036058685363,
            "auditor_fp_violation": 0.01010076149503084,
            "ave_precision_score": 0.5234386737594598,
            "fpr": 0.4698133918770582,
            "logloss": 0.6989436022049235,
            "mae": 0.4941478642490902,
            "precision": 0.5136363636363637,
            "recall": 0.9720430107526882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7249101237971145,
            "auditor_fn_violation": 0.0017265812793743002,
            "auditor_fp_violation": 0.009269627970635812,
            "ave_precision_score": 0.7262454497751756,
            "fpr": 0.13925438596491227,
            "logloss": 0.6332785925663146,
            "mae": 0.44631815231160116,
            "precision": 0.6954436450839329,
            "recall": 0.5930470347648262
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7163905857983539,
            "auditor_fn_violation": 0.0015367727771679462,
            "auditor_fp_violation": 0.005626301359074196,
            "ave_precision_score": 0.7178502518363692,
            "fpr": 0.14270032930845225,
            "logloss": 0.6280707688586856,
            "mae": 0.4437482185277405,
            "precision": 0.6821515892420538,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.768092105263158,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5361842105263158,
            "fpr": 0.46381578947368424,
            "logloss": 0.6910682526390273,
            "mae": 0.49619545513077784,
            "precision": 0.5361842105263158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7552140504939626,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5104281009879253,
            "fpr": 0.48957189901207465,
            "logloss": 0.6965045348448979,
            "mae": 0.49890354998679637,
            "precision": 0.5104281009879253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7421068218631018,
            "auditor_fn_violation": 0.038377192982456135,
            "auditor_fp_violation": 0.03503328356351872,
            "ave_precision_score": 0.7100611817330639,
            "fpr": 0.11513157894736842,
            "logloss": 0.6173645021607166,
            "mae": 0.42061373852846917,
            "precision": 0.7286821705426356,
            "recall": 0.5766871165644172
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7547764270136841,
            "auditor_fn_violation": 0.03813604334124147,
            "auditor_fp_violation": 0.03331233110020527,
            "ave_precision_score": 0.7182010750695041,
            "fpr": 0.11964873765093303,
            "logloss": 0.5991341169946738,
            "mae": 0.4096994634909897,
            "precision": 0.7275,
            "recall": 0.6258064516129033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8649551481645101,
            "auditor_fn_violation": 0.0009014099666343774,
            "auditor_fp_violation": 0.011478163493841,
            "ave_precision_score": 0.8651659985365125,
            "fpr": 0.4144736842105263,
            "logloss": 0.9237649116530886,
            "mae": 0.38841659005878393,
            "precision": 0.5630057803468208,
            "recall": 0.9959100204498977
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.8412969541039212,
            "auditor_fn_violation": 0.000979663137518738,
            "auditor_fp_violation": 0.011065551579351532,
            "ave_precision_score": 0.841604774759062,
            "fpr": 0.4500548847420417,
            "logloss": 1.0034295445470678,
            "mae": 0.41330172025018935,
            "precision": 0.5287356321839081,
            "recall": 0.989247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8592570361634011,
            "auditor_fn_violation": 0.012875363254762686,
            "auditor_fp_violation": 0.01353376052424205,
            "ave_precision_score": 0.8583687881710271,
            "fpr": 0.09758771929824561,
            "logloss": 1.469034814913821,
            "mae": 0.26085817892874114,
            "precision": 0.8022222222222222,
            "recall": 0.7382413087934561
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7941021592325891,
            "auditor_fn_violation": 0.0156510038596367,
            "auditor_fp_violation": 0.025611238820002658,
            "ave_precision_score": 0.7933986116847496,
            "fpr": 0.1251372118551043,
            "logloss": 1.7814183852210919,
            "mae": 0.28192196868674135,
            "precision": 0.7543103448275862,
            "recall": 0.7526881720430108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8058830613425891,
            "auditor_fn_violation": 0.0068816596706490285,
            "auditor_fp_violation": 0.007802455310853968,
            "ave_precision_score": 0.8020265731090099,
            "fpr": 0.043859649122807015,
            "logloss": 0.6920221047670452,
            "mae": 0.3896509465412237,
            "precision": 0.8586572438162544,
            "recall": 0.49693251533742333
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7548562178586189,
            "auditor_fn_violation": 0.006772659136244002,
            "auditor_fp_violation": 0.009463310903604675,
            "ave_precision_score": 0.7530119429890121,
            "fpr": 0.05378704720087816,
            "logloss": 0.6892997952801184,
            "mae": 0.3929566533798526,
            "precision": 0.8164794007490637,
            "recall": 0.46881720430107526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6798419462345046,
            "auditor_fn_violation": 0.012462777598392715,
            "auditor_fp_violation": 0.035448032018580725,
            "ave_precision_score": 0.6827112233452556,
            "fpr": 0.22807017543859648,
            "logloss": 0.6293377974813178,
            "mae": 0.4348990744666049,
            "precision": 0.6645161290322581,
            "recall": 0.8425357873210634
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6667575843984493,
            "auditor_fn_violation": 0.018483764739208958,
            "auditor_fp_violation": 0.030336741273818264,
            "ave_precision_score": 0.657153434610847,
            "fpr": 0.2349066959385291,
            "logloss": 0.6294339023049439,
            "mae": 0.43462845957894225,
            "precision": 0.6409395973154363,
            "recall": 0.821505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6016979375944562,
            "auditor_fn_violation": 0.0030764539159760366,
            "auditor_fp_violation": 0.023130002903239192,
            "ave_precision_score": 0.5960753288423045,
            "fpr": 0.16885964912280702,
            "logloss": 7.85714506754253,
            "mae": 0.46692684728195744,
            "precision": 0.6081424936386769,
            "recall": 0.4887525562372188
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.5982351040967673,
            "auditor_fn_violation": 0.00982731961804942,
            "auditor_fp_violation": 0.01916289692990013,
            "ave_precision_score": 0.5916329534683078,
            "fpr": 0.18880351262349068,
            "logloss": 7.313973701568531,
            "mae": 0.4512277747553368,
            "precision": 0.5815085158150851,
            "recall": 0.513978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7394854870964147,
            "auditor_fn_violation": 0.0306950274459154,
            "auditor_fp_violation": 0.08527487453859235,
            "ave_precision_score": 0.6786631854756162,
            "fpr": 0.31030701754385964,
            "logloss": 0.6561382689501305,
            "mae": 0.4264904829068926,
            "precision": 0.6074895977808599,
            "recall": 0.8957055214723927
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.734658860912589,
            "auditor_fn_violation": 0.02274706986296519,
            "auditor_fp_violation": 0.08490644981860963,
            "ave_precision_score": 0.6722034538874704,
            "fpr": 0.31833150384193193,
            "logloss": 0.6324119269716685,
            "mae": 0.4181554287622972,
            "precision": 0.5949720670391061,
            "recall": 0.9161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8797414413051525,
            "auditor_fn_violation": 0.003545097406091921,
            "auditor_fp_violation": 0.006057919621749413,
            "ave_precision_score": 0.8653258056787371,
            "fpr": 0.05592105263157895,
            "logloss": 0.49210375373698917,
            "mae": 0.3089930029267347,
            "precision": 0.8671875,
            "recall": 0.6809815950920245
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8495122872875924,
            "auditor_fn_violation": 0.010552034276406646,
            "auditor_fp_violation": 0.006775681382997051,
            "ave_precision_score": 0.8248550422642671,
            "fpr": 0.08232711306256861,
            "logloss": 0.501722419030295,
            "mae": 0.30979407754952637,
            "precision": 0.8148148148148148,
            "recall": 0.7096774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7622177902949054,
            "auditor_fn_violation": 0.01379695404154559,
            "auditor_fp_violation": 0.018793289369997107,
            "ave_precision_score": 0.7638424061975729,
            "fpr": 0.15570175438596492,
            "logloss": 1.6370147031914932,
            "mae": 0.34341238460225787,
            "precision": 0.7010526315789474,
            "recall": 0.6809815950920245
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7075525747429109,
            "auditor_fn_violation": 0.010271118822515732,
            "auditor_fp_violation": 0.02955161873071036,
            "ave_precision_score": 0.7086175926115428,
            "fpr": 0.17892425905598244,
            "logloss": 1.627101031768293,
            "mae": 0.3573980527365336,
            "precision": 0.6539278131634819,
            "recall": 0.6623655913978495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 24284,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8718880985040074,
            "auditor_fn_violation": 0.02366313278082733,
            "auditor_fp_violation": 0.017193915640164245,
            "ave_precision_score": 0.8720334997828781,
            "fpr": 0.08442982456140351,
            "logloss": 0.6328025590709337,
            "mae": 0.30066817797058465,
            "precision": 0.8144578313253013,
            "recall": 0.6912065439672802
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8144939622145907,
            "auditor_fn_violation": 0.028391345915512914,
            "auditor_fp_violation": 0.026290529797738653,
            "ave_precision_score": 0.8147624991362796,
            "fpr": 0.10867178924259056,
            "logloss": 0.8394679976406383,
            "mae": 0.3150253709908772,
            "precision": 0.7659574468085106,
            "recall": 0.6967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8292202455634685,
            "auditor_fn_violation": 0.009875147992681091,
            "auditor_fp_violation": 0.003670523827298744,
            "ave_precision_score": 0.8295587740233759,
            "fpr": 0.027412280701754384,
            "logloss": 1.4058156029896405,
            "mae": 0.35662388997294175,
            "precision": 0.8878923766816144,
            "recall": 0.4049079754601227
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7894659438569238,
            "auditor_fn_violation": 0.019723097624021812,
            "auditor_fp_violation": 0.005227587089533505,
            "ave_precision_score": 0.7899141206588405,
            "fpr": 0.04171240395170143,
            "logloss": 1.3684204530287996,
            "mae": 0.364077704664904,
            "precision": 0.8173076923076923,
            "recall": 0.3655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8178976848279502,
            "auditor_fn_violation": 0.00978769777203746,
            "auditor_fp_violation": 0.014161067562523333,
            "ave_precision_score": 0.8188006220587913,
            "fpr": 0.19407894736842105,
            "logloss": 0.5412653001843467,
            "mae": 0.37231072408490273,
            "precision": 0.6974358974358974,
            "recall": 0.8343558282208589
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7562081879548557,
            "auditor_fn_violation": 0.009874532299375616,
            "auditor_fp_violation": 0.010974487209147787,
            "ave_precision_score": 0.7578145895665604,
            "fpr": 0.21405049396267836,
            "logloss": 0.5686368930346503,
            "mae": 0.3814682600657843,
            "precision": 0.6689303904923599,
            "recall": 0.8473118279569892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8117796141609513,
            "auditor_fn_violation": 0.011595002332005881,
            "auditor_fp_violation": 0.010433515822653562,
            "ave_precision_score": 0.8121380863420462,
            "fpr": 0.09100877192982457,
            "logloss": 0.7718124217034922,
            "mae": 0.3315608844745081,
            "precision": 0.7860824742268041,
            "recall": 0.623721881390593
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7870434972621798,
            "auditor_fn_violation": 0.01698476210710197,
            "auditor_fp_violation": 0.02110232189532028,
            "ave_precision_score": 0.7874557000435105,
            "fpr": 0.10098792535675083,
            "logloss": 0.7526104148560662,
            "mae": 0.32755662872706864,
            "precision": 0.7622739018087855,
            "recall": 0.6344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.782858098914172,
            "auditor_fn_violation": 0.017981110752340976,
            "auditor_fp_violation": 0.01746090995811041,
            "ave_precision_score": 0.7836446077570819,
            "fpr": 0.13267543859649122,
            "logloss": 0.7010111973399912,
            "mae": 0.3625262180249321,
            "precision": 0.7311111111111112,
            "recall": 0.6728016359918201
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7026642122060014,
            "auditor_fn_violation": 0.019284019687688125,
            "auditor_fp_violation": 0.026566184107544563,
            "ave_precision_score": 0.703478534341229,
            "fpr": 0.1525795828759605,
            "logloss": 0.7144290781944823,
            "mae": 0.36710138764727196,
            "precision": 0.6897321428571429,
            "recall": 0.6645161290322581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.804885590572176,
            "auditor_fn_violation": 0.0004641588634162109,
            "auditor_fp_violation": 0.00914520343411721,
            "ave_precision_score": 0.8067839869843436,
            "fpr": 0.05921052631578947,
            "logloss": 0.5547609338978754,
            "mae": 0.3518108746788481,
            "precision": 0.8528610354223434,
            "recall": 0.6400817995910021
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8034554018597828,
            "auditor_fn_violation": 0.010417478134626961,
            "auditor_fp_violation": 0.005449095017056111,
            "ave_precision_score": 0.798450689854715,
            "fpr": 0.07574094401756312,
            "logloss": 0.5382798589811331,
            "mae": 0.34511818622293117,
            "precision": 0.8217054263565892,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7795759883661316,
            "auditor_fn_violation": 0.0004641588634162109,
            "auditor_fp_violation": 0.00914520343411721,
            "ave_precision_score": 0.7683012328917516,
            "fpr": 0.05921052631578947,
            "logloss": 0.5495347022548297,
            "mae": 0.3631704743755491,
            "precision": 0.8528610354223434,
            "recall": 0.6400817995910021
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.7855174532979876,
            "auditor_fn_violation": 0.010417478134626961,
            "auditor_fp_violation": 0.005449095017056111,
            "ave_precision_score": 0.7597272420582762,
            "fpr": 0.07574094401756312,
            "logloss": 0.5385987563878942,
            "mae": 0.3565982316511261,
            "precision": 0.8217054263565892,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.785766770449992,
            "auditor_fn_violation": 0.005888314856671331,
            "auditor_fp_violation": 0.013432665588320689,
            "ave_precision_score": 0.7865846144114768,
            "fpr": 0.1206140350877193,
            "logloss": 0.5782038172390738,
            "mae": 0.36237406766444463,
            "precision": 0.7693920335429769,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7879193756113537,
            "auditor_fn_violation": 0.014765766084770371,
            "auditor_fp_violation": 0.00388869472761909,
            "ave_precision_score": 0.7887125434592753,
            "fpr": 0.13172338090010977,
            "logloss": 0.5636536898965796,
            "mae": 0.3552476931296894,
            "precision": 0.7484276729559748,
            "recall": 0.7677419354838709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.839917377497587,
            "auditor_fn_violation": 0.0017691852330212106,
            "auditor_fp_violation": 0.00781541620007466,
            "ave_precision_score": 0.8401625770282508,
            "fpr": 0.11074561403508772,
            "logloss": 0.5589067663734544,
            "mae": 0.34177846239468773,
            "precision": 0.7775330396475771,
            "recall": 0.721881390593047
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.805914842778063,
            "auditor_fn_violation": 0.008547855954109281,
            "auditor_fp_violation": 0.0025202679753683257,
            "ave_precision_score": 0.8062985200015849,
            "fpr": 0.12733260153677278,
            "logloss": 0.5410703111104348,
            "mae": 0.34445043849361245,
            "precision": 0.7516059957173448,
            "recall": 0.7548387096774194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.803359590314746,
            "auditor_fn_violation": 0.01373416926775016,
            "auditor_fp_violation": 0.0069237070216913435,
            "ave_precision_score": 0.799171774931378,
            "fpr": 0.03508771929824561,
            "logloss": 0.7517082869690261,
            "mae": 0.3949524241227967,
            "precision": 0.8649789029535865,
            "recall": 0.41922290388548056
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7660177598881368,
            "auditor_fn_violation": 0.01895117028433838,
            "auditor_fp_violation": 0.010228743853155012,
            "ave_precision_score": 0.7599593036184882,
            "fpr": 0.050493962678375415,
            "logloss": 0.7457915369334931,
            "mae": 0.3837050264453338,
            "precision": 0.8122448979591836,
            "recall": 0.42795698924731185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.850027155907916,
            "auditor_fn_violation": 0.005879345603271988,
            "auditor_fp_violation": 0.006112355356476297,
            "ave_precision_score": 0.832404721216562,
            "fpr": 0.06798245614035088,
            "logloss": 0.511965384109752,
            "mae": 0.3392587574035452,
            "precision": 0.8442211055276382,
            "recall": 0.6871165644171779
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7947749824600667,
            "auditor_fn_violation": 0.010766851976440873,
            "auditor_fp_violation": 0.006738763395076618,
            "ave_precision_score": 0.7869633141046309,
            "fpr": 0.0889132821075741,
            "logloss": 0.5242781871888693,
            "mae": 0.33995920131811064,
            "precision": 0.8019559902200489,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5876271394446455,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405777693499041,
            "fpr": 0.46381578947368424,
            "logloss": 0.6922697753218241,
            "mae": 0.49751100068291026,
            "precision": 0.5361842105263158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5478962156581264,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5298950003975282,
            "fpr": 0.48957189901207465,
            "logloss": 0.6909561372960193,
            "mae": 0.4968031365444841,
            "precision": 0.5104281009879253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.8028177901313998,
            "auditor_fn_violation": 0.0011973953288128413,
            "auditor_fp_violation": 0.006744846750445855,
            "ave_precision_score": 0.8033147151133804,
            "fpr": 0.03179824561403509,
            "logloss": 0.7876774851915499,
            "mae": 0.4056884595991968,
            "precision": 0.8786610878661087,
            "recall": 0.4294478527607362
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7746294235286968,
            "auditor_fn_violation": 0.006996919372543467,
            "auditor_fp_violation": 0.002978051025581704,
            "ave_precision_score": 0.7756528032071851,
            "fpr": 0.03732162458836443,
            "logloss": 0.7673616821538756,
            "mae": 0.39425552499648475,
            "precision": 0.8589211618257261,
            "recall": 0.44516129032258067
        }
    }
]