[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5682014549363621,
            "auditor_fn_violation": 0.009174815954290752,
            "auditor_fp_violation": 0.00691068028037762,
            "ave_precision_score": 0.5554052661896676,
            "fpr": 0.0625,
            "logloss": 0.6939049909523134,
            "mae": 0.49361976285121945,
            "precision": 0.5714285714285714,
            "recall": 0.15866388308977036
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.567238671856211,
            "auditor_fn_violation": 0.005576289791437992,
            "auditor_fp_violation": 0.01336367939254172,
            "ave_precision_score": 0.5543787491320118,
            "fpr": 0.06147091108671789,
            "logloss": 0.6922744853953692,
            "mae": 0.49201915646227473,
            "precision": 0.5942028985507246,
            "recall": 0.1726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6270101361042029,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6183431470142713,
            "fpr": 0.47478070175438597,
            "logloss": 0.6922677644631798,
            "mae": 0.49945513779918355,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5904434013773681,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5902087621444839,
            "fpr": 0.47859495060373214,
            "logloss": 0.6924380517837923,
            "mae": 0.49954034716839585,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6277433702603947,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6195176646344227,
            "fpr": 0.47478070175438597,
            "logloss": 0.6922675165138122,
            "mae": 0.4994550478693686,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5898713178511228,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5901725102468516,
            "fpr": 0.47859495060373214,
            "logloss": 0.6924378409878812,
            "mae": 0.49954027611390167,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7625279398995993,
            "auditor_fn_violation": 0.018450353441013815,
            "auditor_fp_violation": 0.01227918236700296,
            "ave_precision_score": 0.6372077873631867,
            "fpr": 0.13486842105263158,
            "logloss": 0.6663196724723286,
            "mae": 0.4831030475008383,
            "precision": 0.7064439140811456,
            "recall": 0.6179540709812108
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.759596880009707,
            "auditor_fn_violation": 0.013248598994742625,
            "auditor_fp_violation": 0.02073535483741025,
            "ave_precision_score": 0.6340824487338653,
            "fpr": 0.13172338090010977,
            "logloss": 0.6668968378066603,
            "mae": 0.4834711520915236,
            "precision": 0.706601466992665,
            "recall": 0.608421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6258193247076285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6157656555939328,
            "fpr": 0.47478070175438597,
            "logloss": 0.6922676657663573,
            "mae": 0.499455136688132,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5913886547355184,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5902461431464154,
            "fpr": 0.47859495060373214,
            "logloss": 0.6924379792212164,
            "mae": 0.49954035946880554,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7448063484708964,
            "auditor_fn_violation": 0.009156502948393968,
            "auditor_fp_violation": 0.0038896317004983596,
            "ave_precision_score": 0.5951977099667157,
            "fpr": 0.01644736842105263,
            "logloss": 0.6554223214627953,
            "mae": 0.468642515179358,
            "precision": 0.8672566371681416,
            "recall": 0.2045929018789144
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.741668508070112,
            "auditor_fn_violation": 0.0021376162689930233,
            "auditor_fp_violation": 0.0013796714971953397,
            "ave_precision_score": 0.584910537572671,
            "fpr": 0.013172338090010977,
            "logloss": 0.6591241110356846,
            "mae": 0.4723700379828067,
            "precision": 0.8762886597938144,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7448063484708964,
            "auditor_fn_violation": 0.009156502948393968,
            "auditor_fp_violation": 0.0038896317004983596,
            "ave_precision_score": 0.5951977099667157,
            "fpr": 0.01644736842105263,
            "logloss": 0.6554223214627953,
            "mae": 0.468642515179358,
            "precision": 0.8672566371681416,
            "recall": 0.2045929018789144
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.741668508070112,
            "auditor_fn_violation": 0.0021376162689930233,
            "auditor_fp_violation": 0.0013796714971953397,
            "ave_precision_score": 0.584910537572671,
            "fpr": 0.013172338090010977,
            "logloss": 0.6591241110356846,
            "mae": 0.4723700379828067,
            "precision": 0.8762886597938144,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6192189636467313,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6206436664529631,
            "fpr": 0.47478070175438597,
            "logloss": 0.6922597233036842,
            "mae": 0.49945132257907016,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5760909526074123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5783986828666281,
            "fpr": 0.47859495060373214,
            "logloss": 0.692439785929701,
            "mae": 0.49954133087403163,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7649324976405244,
            "auditor_fn_violation": 0.011173222722777718,
            "auditor_fp_violation": 0.003547769539321744,
            "ave_precision_score": 0.7237258744702001,
            "fpr": 0.2236842105263158,
            "logloss": 2.933168826247841,
            "mae": 0.3445466954726726,
            "precision": 0.6725521669341894,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7777432107755038,
            "auditor_fn_violation": 0.006158645791206892,
            "auditor_fp_violation": 0.013293185228451453,
            "ave_precision_score": 0.7355945630884931,
            "fpr": 0.22063666300768386,
            "logloss": 2.8634429894925715,
            "mae": 0.34229028256432154,
            "precision": 0.6683168316831684,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7448063484708964,
            "auditor_fn_violation": 0.009156502948393968,
            "auditor_fp_violation": 0.0038896317004983596,
            "ave_precision_score": 0.5951977099667157,
            "fpr": 0.01644736842105263,
            "logloss": 0.6554223214627953,
            "mae": 0.468642515179358,
            "precision": 0.8672566371681416,
            "recall": 0.2045929018789144
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.741668508070112,
            "auditor_fn_violation": 0.0021376162689930233,
            "auditor_fp_violation": 0.0013796714971953397,
            "ave_precision_score": 0.584910537572671,
            "fpr": 0.013172338090010977,
            "logloss": 0.6591241110356846,
            "mae": 0.4723700379828067,
            "precision": 0.8762886597938144,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6781424025158289,
            "auditor_fn_violation": 0.10262608504559939,
            "auditor_fp_violation": 0.09951734127466473,
            "ave_precision_score": 0.545453957457956,
            "fpr": 0.28289473684210525,
            "logloss": 0.6930551058434357,
            "mae": 0.49073490912192747,
            "precision": 0.5574614065180102,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.702087741208622,
            "auditor_fn_violation": 0.10590328730718125,
            "auditor_fp_violation": 0.090695777399571,
            "ave_precision_score": 0.5759877660682228,
            "fpr": 0.2502744237102086,
            "logloss": 0.6821642431996314,
            "mae": 0.48573215075172527,
            "precision": 0.5846994535519126,
            "recall": 0.6757894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7448063484708964,
            "auditor_fn_violation": 0.009156502948393968,
            "auditor_fp_violation": 0.0038896317004983596,
            "ave_precision_score": 0.5951977099667157,
            "fpr": 0.01644736842105263,
            "logloss": 0.6554223214627953,
            "mae": 0.468642515179358,
            "precision": 0.8672566371681416,
            "recall": 0.2045929018789144
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.741668508070112,
            "auditor_fn_violation": 0.0021376162689930233,
            "auditor_fp_violation": 0.0013796714971953397,
            "ave_precision_score": 0.584910537572671,
            "fpr": 0.013172338090010977,
            "logloss": 0.6591241110356846,
            "mae": 0.4723700379828067,
            "precision": 0.8762886597938144,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7690624395050033,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7693842999258289,
            "fpr": 0.36951754385964913,
            "logloss": 0.7005961257899515,
            "mae": 0.3951822919689839,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7463328245219478,
            "auditor_fn_violation": 0.022323646657808078,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7474558445840114,
            "fpr": 0.36223929747530187,
            "logloss": 0.6941784219916496,
            "mae": 0.3929199418697085,
            "precision": 0.5741935483870968,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.596474147409163,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6075208951519462,
            "fpr": 0.47478070175438597,
            "logloss": 0.6923707572505866,
            "mae": 0.4995188834635835,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5859247948238835,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5941945709987543,
            "fpr": 0.47859495060373214,
            "logloss": 0.6924375384986051,
            "mae": 0.499552730932979,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7787974198564344,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7334464409697979,
            "fpr": 0.4682017543859649,
            "logloss": 1.1647861136251028,
            "mae": 0.4431909221292013,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7844925212945729,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7407187637770504,
            "fpr": 0.47200878155872666,
            "logloss": 1.154407481078282,
            "mae": 0.4425801309939928,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7722251206255639,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7727128772034917,
            "fpr": 0.36951754385964913,
            "logloss": 0.7216081542127746,
            "mae": 0.39746077690470455,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7534229658076237,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7542769476732413,
            "fpr": 0.36223929747530187,
            "logloss": 0.7056758782865864,
            "mae": 0.3931848820949098,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 9675,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5930277231257378,
            "auditor_fn_violation": 0.009488426180273232,
            "auditor_fp_violation": 0.0030894210121145847,
            "ave_precision_score": 0.5700379335493344,
            "fpr": 0.051535087719298246,
            "logloss": 0.6797346317223942,
            "mae": 0.4880865174100587,
            "precision": 0.5803571428571429,
            "recall": 0.13569937369519833
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5829109321652319,
            "auditor_fn_violation": 0.003489514125599415,
            "auditor_fp_violation": 0.005911439188712878,
            "ave_precision_score": 0.5616254370165775,
            "fpr": 0.052689352360043906,
            "logloss": 0.6845769677797341,
            "mae": 0.48948444686134873,
            "precision": 0.5752212389380531,
            "recall": 0.1368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7927371721925094,
            "auditor_fn_violation": 0.009934805699007437,
            "auditor_fp_violation": 0.010098861472387673,
            "ave_precision_score": 0.7512018109297698,
            "fpr": 0.19188596491228072,
            "logloss": 2.6506547072008737,
            "mae": 0.31936736071580335,
            "precision": 0.7063758389261745,
            "recall": 0.8789144050104384
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7976823138952838,
            "auditor_fn_violation": 0.007364954647871054,
            "auditor_fp_violation": 0.012384314041430436,
            "ave_precision_score": 0.7534988520452637,
            "fpr": 0.19209659714599342,
            "logloss": 2.6611402349269,
            "mae": 0.32138216797299235,
            "precision": 0.7003424657534246,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7591260899607357,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06563247032129979,
            "ave_precision_score": 0.7599726847470438,
            "fpr": 0.36951754385964913,
            "logloss": 0.6999922166328176,
            "mae": 0.4032753780679661,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7595008426920606,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7602842691752979,
            "fpr": 0.36223929747530187,
            "logloss": 0.6925910378453068,
            "mae": 0.4010086120745222,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7664342114373393,
            "auditor_fn_violation": 0.015263890414972716,
            "auditor_fp_violation": 0.011294112880353306,
            "ave_precision_score": 0.7667791217127586,
            "fpr": 0.41118421052631576,
            "logloss": 0.7417549737201568,
            "mae": 0.41196272838759407,
            "precision": 0.5426829268292683,
            "recall": 0.9290187891440501
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7770285788120632,
            "auditor_fn_violation": 0.016266682072910047,
            "auditor_fp_violation": 0.023474556642060846,
            "ave_precision_score": 0.7773696065598483,
            "fpr": 0.40175631174533477,
            "logloss": 0.7341186013286212,
            "mae": 0.4089082676414339,
            "precision": 0.5481481481481482,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7591345908432758,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06563247032129979,
            "ave_precision_score": 0.7599726847470438,
            "fpr": 0.36951754385964913,
            "logloss": 0.6999938748834768,
            "mae": 0.40327587840115053,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7595008494516955,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.760283786098216,
            "fpr": 0.36223929747530187,
            "logloss": 0.6925931748664048,
            "mae": 0.4010093174179613,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7528031421928645,
            "auditor_fn_violation": 0.002293703988572685,
            "auditor_fp_violation": 0.007055022081763306,
            "ave_precision_score": 0.7379298684805617,
            "fpr": 0.4473684210526316,
            "logloss": 5.103499892146604,
            "mae": 0.4522763862101456,
            "precision": 0.5363636363636364,
            "recall": 0.9853862212943633
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7619211124261825,
            "auditor_fn_violation": 0.0005084060315442833,
            "auditor_fp_violation": 0.005130968086284863,
            "ave_precision_score": 0.7448642473038399,
            "fpr": 0.45773874862788144,
            "logloss": 5.136238159465393,
            "mae": 0.4560872085655447,
            "precision": 0.531986531986532,
            "recall": 0.9978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7632925786891529,
            "auditor_fn_violation": 0.029245870417170278,
            "auditor_fp_violation": 0.0670758883351566,
            "ave_precision_score": 0.7638140554870921,
            "fpr": 0.3684210526315789,
            "logloss": 0.6846993068596027,
            "mae": 0.40482329421240393,
            "precision": 0.5653298835705045,
            "recall": 0.9123173277661796
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7537412213777716,
            "auditor_fn_violation": 0.02205557802299382,
            "auditor_fp_violation": 0.07189901207464326,
            "ave_precision_score": 0.7545852438151153,
            "fpr": 0.3589462129527991,
            "logloss": 0.6632616868228037,
            "mae": 0.3997719749464816,
            "precision": 0.5747724317295189,
            "recall": 0.9305263157894736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7937852650092136,
            "auditor_fn_violation": 0.010420100355272313,
            "auditor_fp_violation": 0.007738746404116535,
            "ave_precision_score": 0.7536113574727292,
            "fpr": 0.17653508771929824,
            "logloss": 2.5921318126587014,
            "mae": 0.3150229994738638,
            "precision": 0.72,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7990388287759383,
            "auditor_fn_violation": 0.004654226125137211,
            "auditor_fp_violation": 0.012598314182418757,
            "ave_precision_score": 0.7555544913920786,
            "fpr": 0.17014270032930845,
            "logloss": 2.619825289866659,
            "mae": 0.3150355675913042,
            "precision": 0.720216606498195,
            "recall": 0.84
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7644433793146032,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5318328438020234,
            "fpr": 0.47478070175438597,
            "logloss": 15.940768539157771,
            "mae": 0.473891378886867,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7577591924527417,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5235472256897061,
            "fpr": 0.47859495060373214,
            "logloss": 16.17911604312467,
            "mae": 0.4781976104698642,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017544,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7192269763717504,
            "auditor_fn_violation": 0.003598505658718822,
            "auditor_fp_violation": 0.007067683643288368,
            "ave_precision_score": 0.7198956268234289,
            "fpr": 0.4517543859649123,
            "logloss": 3.089102088849719,
            "mae": 0.45297185846663557,
            "precision": 0.5344632768361582,
            "recall": 0.9874739039665971
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7546649983473346,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.004249791035156448,
            "ave_precision_score": 0.7546336594010574,
            "fpr": 0.44127332601536773,
            "logloss": 2.8699078578051505,
            "mae": 0.4447942431653432,
            "precision": 0.5368663594470046,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017544,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017545,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 9675,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7696648250767895,
            "auditor_fn_violation": 0.008513258616269276,
            "auditor_fp_violation": 0.0065384303715408714,
            "ave_precision_score": 0.7282112637378813,
            "fpr": 0.24780701754385964,
            "logloss": 2.9997400365965623,
            "mae": 0.34673963816378983,
            "precision": 0.6533742331288344,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7714801486822189,
            "auditor_fn_violation": 0.0054445664105378724,
            "auditor_fp_violation": 0.00634447476812456,
            "ave_precision_score": 0.7272803054425236,
            "fpr": 0.2524698133918771,
            "logloss": 3.0589179177747132,
            "mae": 0.35195444765552863,
            "precision": 0.6450617283950617,
            "recall": 0.88
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5963638918551863,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6107525417946994,
            "fpr": 0.47478070175438597,
            "logloss": 0.6923705863288666,
            "mae": 0.49951882405500664,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5854275354120123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5989741360625773,
            "fpr": 0.47859495060373214,
            "logloss": 0.6924373925769667,
            "mae": 0.4995526841521656,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.7048383948492336,
            "auditor_fn_violation": 0.03003561879646925,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7060139163095359,
            "fpr": 0.36951754385964913,
            "logloss": 0.7038312763265788,
            "mae": 0.39623350775963717,
            "precision": 0.5657216494845361,
            "recall": 0.9164926931106472
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7280817561401434,
            "auditor_fn_violation": 0.021683517245363684,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7293078737944066,
            "fpr": 0.36223929747530187,
            "logloss": 0.6973363619054965,
            "mae": 0.39401838749352713,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7692298332972127,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7697649362646484,
            "fpr": 0.36951754385964913,
            "logloss": 0.7005961058636284,
            "mae": 0.3951823174882205,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7464258357673913,
            "auditor_fn_violation": 0.022323646657808078,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7477815900329197,
            "fpr": 0.36223929747530187,
            "logloss": 0.6941784004273439,
            "mae": 0.3929199691857779,
            "precision": 0.5741935483870968,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5088080245286123,
            "auditor_fn_violation": 0.005688477456689762,
            "auditor_fp_violation": 0.00403144118957903,
            "ave_precision_score": 0.5193488319142425,
            "fpr": 0.03399122807017544,
            "logloss": 17.13476635712713,
            "mae": 0.531206743205576,
            "precision": 0.46551724137931033,
            "recall": 0.05636743215031315
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.501374933864469,
            "auditor_fn_violation": 0.003131318967011385,
            "auditor_fp_violation": 0.003867108430094967,
            "ave_precision_score": 0.5195922289809463,
            "fpr": 0.026344676180021953,
            "logloss": 17.143653167376076,
            "mae": 0.5243623512847183,
            "precision": 0.45454545454545453,
            "recall": 0.042105263157894736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7787974198564344,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7334464409697979,
            "fpr": 0.4682017543859649,
            "logloss": 1.1647857898767129,
            "mae": 0.44319089841328124,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7844925212945729,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7407187637770504,
            "fpr": 0.47200878155872666,
            "logloss": 1.1544071617071672,
            "mae": 0.4425801053524639,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.3817084419347746,
            "auditor_fn_violation": 0.001329982053254234,
            "auditor_fp_violation": 0.002519650743486893,
            "ave_precision_score": 0.5234419516558843,
            "fpr": 0.007675438596491228,
            "logloss": 18.04599318258898,
            "mae": 0.5304497842832158,
            "precision": 0.36363636363636365,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.46635239183074356,
            "auditor_fn_violation": 0.003579640649373165,
            "auditor_fp_violation": 0.0031823079789323155,
            "ave_precision_score": 0.5213082823480883,
            "fpr": 0.008781558726673985,
            "logloss": 17.761590458001187,
            "mae": 0.5219060572602354,
            "precision": 0.5,
            "recall": 0.016842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7171687498738508,
            "auditor_fn_violation": 0.002907189686115079,
            "auditor_fp_violation": 0.007067683643288368,
            "ave_precision_score": 0.7175969792152075,
            "fpr": 0.4517543859649123,
            "logloss": 3.3035726846194526,
            "mae": 0.45396059220317436,
            "precision": 0.5349887133182845,
            "recall": 0.9895615866388309
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7518252916331197,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.0028927783764187147,
            "ave_precision_score": 0.7524604891228708,
            "fpr": 0.442371020856202,
            "logloss": 3.0790655983765993,
            "mae": 0.44621007895010445,
            "precision": 0.5362485615650172,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.72284548853106,
            "auditor_fn_violation": 0.003598505658718822,
            "auditor_fp_violation": 0.007067683643288368,
            "ave_precision_score": 0.7234862570223604,
            "fpr": 0.4517543859649123,
            "logloss": 3.271408922169549,
            "mae": 0.4540310510010452,
            "precision": 0.5344632768361582,
            "recall": 0.9874739039665971
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7568056090724075,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.005377697660600812,
            "ave_precision_score": 0.7574972256214525,
            "fpr": 0.43907793633369924,
            "logloss": 3.04844147476852,
            "mae": 0.4456762928255317,
            "precision": 0.5381062355658198,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7787974198564344,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7334464409697979,
            "fpr": 0.4682017543859649,
            "logloss": 1.1669805812757432,
            "mae": 0.44331367919760833,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7844925212945729,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7407187637770504,
            "fpr": 0.47200878155872666,
            "logloss": 1.156603693708958,
            "mae": 0.44271643594230403,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6781424025158289,
            "auditor_fn_violation": 0.10262608504559939,
            "auditor_fp_violation": 0.09951734127466473,
            "ave_precision_score": 0.545453957457956,
            "fpr": 0.28289473684210525,
            "logloss": 0.693068436132136,
            "mae": 0.49073055667573945,
            "precision": 0.5574614065180102,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.702087741208622,
            "auditor_fn_violation": 0.10590328730718125,
            "auditor_fp_violation": 0.090695777399571,
            "ave_precision_score": 0.5759877660682228,
            "fpr": 0.2502744237102086,
            "logloss": 0.6821746483079578,
            "mae": 0.4857266208670142,
            "precision": 0.5846994535519126,
            "recall": 0.6757894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7507447732696619,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06563247032129979,
            "ave_precision_score": 0.7516713668561259,
            "fpr": 0.36951754385964913,
            "logloss": 0.7001569141542572,
            "mae": 0.4030505294770516,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7492098523764251,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7500917068265401,
            "fpr": 0.36223929747530187,
            "logloss": 0.692866994390878,
            "mae": 0.400824680384637,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7944819409657279,
            "auditor_fn_violation": 0.010207211661722159,
            "auditor_fp_violation": 0.0098304363680564,
            "ave_precision_score": 0.754888119634617,
            "fpr": 0.18859649122807018,
            "logloss": 2.585296988564131,
            "mae": 0.3184688397225711,
            "precision": 0.7089678510998308,
            "recall": 0.8747390396659708
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7980277507197077,
            "auditor_fn_violation": 0.007995840314287366,
            "auditor_fp_violation": 0.016231281281785314,
            "ave_precision_score": 0.7545521959598187,
            "fpr": 0.18990120746432493,
            "logloss": 2.6347940599873056,
            "mae": 0.320333042436583,
            "precision": 0.7006920415224913,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.772226461191345,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7727128772034918,
            "fpr": 0.36951754385964913,
            "logloss": 0.7216081610704628,
            "mae": 0.39746077876703056,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7534230198119729,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7542703369953175,
            "fpr": 0.36223929747530187,
            "logloss": 0.7056758813409316,
            "mae": 0.3931848825529038,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 9675,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7203997505642953,
            "auditor_fn_violation": 0.002907189686115079,
            "auditor_fp_violation": 0.009782322434261177,
            "ave_precision_score": 0.7202385259118356,
            "fpr": 0.4506578947368421,
            "logloss": 2.765809130157123,
            "mae": 0.4491776827890872,
            "precision": 0.535593220338983,
            "recall": 0.9895615866388309
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7550238005668845,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.004662685424828045,
            "ave_precision_score": 0.7542614911821404,
            "fpr": 0.44127332601536773,
            "logloss": 2.5641564037185414,
            "mae": 0.44074798989133407,
            "precision": 0.5368663594470046,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017544,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7673337767403202,
            "auditor_fn_violation": 0.01224682269347691,
            "auditor_fp_violation": 0.010572403873424905,
            "ave_precision_score": 0.7676659160383248,
            "fpr": 0.4166666666666667,
            "logloss": 0.7443131785420912,
            "mae": 0.41178210757200423,
            "precision": 0.5416164053075995,
            "recall": 0.9373695198329853
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7742788506790679,
            "auditor_fn_violation": 0.01669651626321567,
            "auditor_fp_violation": 0.02194382622181493,
            "ave_precision_score": 0.7746557543509797,
            "fpr": 0.4039517014270033,
            "logloss": 0.7367150908685713,
            "mae": 0.408795924957445,
            "precision": 0.5473554735547356,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.45827589388599166,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.001182589846440582,
            "ave_precision_score": 0.5281919569278101,
            "fpr": 0.0043859649122807015,
            "logloss": 17.965260182826135,
            "mae": 0.5246480933304778,
            "precision": 0.5555555555555556,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.00014558899994223415,
            "auditor_fp_violation": 0.0007678828588404718,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.003293084522502744,
            "logloss": 17.754613393049485,
            "mae": 0.5179023282391834,
            "precision": 0.6666666666666666,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.3820846370449436,
            "auditor_fn_violation": 0.001329982053254234,
            "auditor_fp_violation": 0.004173250678659699,
            "ave_precision_score": 0.523839718468056,
            "fpr": 0.008771929824561403,
            "logloss": 18.04361263562458,
            "mae": 0.530389334834916,
            "precision": 0.3333333333333333,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.46627180575015753,
            "auditor_fn_violation": 0.003579640649373165,
            "auditor_fp_violation": 0.0031218844097120817,
            "ave_precision_score": 0.5212280818468352,
            "fpr": 0.008781558726673985,
            "logloss": 17.759926508914837,
            "mae": 0.5219303082948721,
            "precision": 0.5,
            "recall": 0.016842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7212267951033868,
            "auditor_fn_violation": 0.003101765373768451,
            "auditor_fp_violation": 0.004507515902921283,
            "ave_precision_score": 0.7212961248252148,
            "fpr": 0.4506578947368421,
            "logloss": 3.15215258873421,
            "mae": 0.453016303957858,
            "precision": 0.5345413363533409,
            "recall": 0.9853862212943633
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7549565990635656,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.005611838991329227,
            "ave_precision_score": 0.7551778631749898,
            "fpr": 0.43798024149286496,
            "logloss": 2.934291854905999,
            "mae": 0.4445719363724577,
            "precision": 0.5387283236994219,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6806515383584614,
            "auditor_fn_violation": 0.0011766106288686226,
            "auditor_fp_violation": 0.002813398970868291,
            "ave_precision_score": 0.6827439723973141,
            "fpr": 0.46600877192982454,
            "logloss": 0.8326701528685898,
            "mae": 0.43758444049346606,
            "precision": 0.5288248337028825,
            "recall": 0.9958246346555324
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.667188197770715,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.6685537974711115,
            "fpr": 0.47200878155872666,
            "logloss": 0.8409549557333601,
            "mae": 0.4433215463515596,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.75936666200689,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.761637943761879,
            "fpr": 0.4682017543859649,
            "logloss": 1.1005195251609066,
            "mae": 0.44488002851951597,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7500867176745218,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7506269654599454,
            "fpr": 0.47200878155872666,
            "logloss": 1.102067725639004,
            "mae": 0.4488557806942902,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7644409203318394,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0019903974717393994,
            "ave_precision_score": 0.5318303849727294,
            "fpr": 0.46710526315789475,
            "logloss": 15.905350822549432,
            "mae": 0.46935319877638104,
            "precision": 0.5292817679558011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7577616435179875,
            "auditor_fn_violation": 0.0004991622855162054,
            "auditor_fp_violation": 0.0017145187766241386,
            "ave_precision_score": 0.5235496766320143,
            "fpr": 0.47530186608122943,
            "logloss": 16.14848622822839,
            "mae": 0.4759576346165001,
            "precision": 0.5226019845644984,
            "recall": 0.9978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7633031217559034,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0017523601150682927,
            "ave_precision_score": 0.5275936920965788,
            "fpr": 0.4692982456140351,
            "logloss": 16.215217811494675,
            "mae": 0.4705047602960285,
            "precision": 0.5275938189845475,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7618522601984565,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002255813250888742,
            "ave_precision_score": 0.523704520396913,
            "fpr": 0.47420417124039516,
            "logloss": 16.37904482979418,
            "mae": 0.47441547993629607,
            "precision": 0.523704520396913,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6924890764850002,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.6947955192455246,
            "fpr": 0.4682017543859649,
            "logloss": 0.836948386236332,
            "mae": 0.4372462253494744,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6824946859834369,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004118873301845942,
            "ave_precision_score": 0.6843410160098703,
            "fpr": 0.4698133918770582,
            "logloss": 0.8474460383457586,
            "mae": 0.44287319546391624,
            "precision": 0.5260243632336655,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6834383173846238,
            "auditor_fn_violation": 0.0044683734388162475,
            "auditor_fp_violation": 0.007812183460961877,
            "ave_precision_score": 0.6848283739572626,
            "fpr": 0.4418859649122807,
            "logloss": 0.7894706154288722,
            "mae": 0.4356530485123298,
            "precision": 0.5373134328358209,
            "recall": 0.9770354906054279
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6662930038541279,
            "auditor_fn_violation": 0.002380264602230054,
            "auditor_fp_violation": 0.0063545453629946045,
            "ave_precision_score": 0.6684330646870169,
            "fpr": 0.4522502744237102,
            "logloss": 0.8028704927289461,
            "mae": 0.44201830790289215,
            "precision": 0.5318181818181819,
            "recall": 0.9852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7787974198564344,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7334464409697979,
            "fpr": 0.4682017543859649,
            "logloss": 1.1120645781722538,
            "mae": 0.439955506778604,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7844925212945729,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7407187637770504,
            "fpr": 0.47200878155872666,
            "logloss": 1.1017361592562416,
            "mae": 0.43900762265496995,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7974765065071234,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7166765687166373,
            "fpr": 0.4682017543859649,
            "logloss": 1.15692870895608,
            "mae": 0.4422083570318551,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8037036992980288,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7227987033733754,
            "fpr": 0.47200878155872666,
            "logloss": 1.1520353225235838,
            "mae": 0.44252553955845036,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.45827589388599166,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.001182589846440582,
            "ave_precision_score": 0.5281919569278101,
            "fpr": 0.0043859649122807015,
            "logloss": 17.965925011698808,
            "mae": 0.5248300923635006,
            "precision": 0.5555555555555556,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.00014558899994223415,
            "auditor_fp_violation": 0.0007678828588404718,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.003293084522502744,
            "logloss": 17.754945162587294,
            "mae": 0.5179211648771975,
            "precision": 0.6666666666666666,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.764444612915707,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000757161379198591,
            "ave_precision_score": 0.5318340773238462,
            "fpr": 0.47149122807017546,
            "logloss": 15.906838057764416,
            "mae": 0.47074022283777595,
            "precision": 0.5269526952695269,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7577616435179875,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013192479279751082,
            "ave_precision_score": 0.5235496766320143,
            "fpr": 0.47639956092206365,
            "logloss": 16.152155290954063,
            "mae": 0.47679352295778193,
            "precision": 0.5225522552255225,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.677347116556221,
            "auditor_fn_violation": 8.469765227264423e-05,
            "auditor_fp_violation": 0.00557868400794134,
            "ave_precision_score": 0.679341157114364,
            "fpr": 0.45614035087719296,
            "logloss": 0.7276953267684082,
            "mae": 0.4313426141549523,
            "precision": 0.5341545352743561,
            "recall": 0.9958246346555324
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.660260669369934,
            "auditor_fn_violation": 0.0018233289040383617,
            "auditor_fp_violation": 0.006080121652786032,
            "ave_precision_score": 0.6621062780091682,
            "fpr": 0.45993413830954993,
            "logloss": 0.7386846948221977,
            "mae": 0.4388410899784052,
            "precision": 0.5297418630751964,
            "recall": 0.9936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7589926344263542,
            "auditor_fn_violation": 0.013247170640588947,
            "auditor_fp_violation": 0.01381629593614524,
            "ave_precision_score": 0.759430235556455,
            "fpr": 0.4166666666666667,
            "logloss": 0.7421335281595554,
            "mae": 0.4130519908045905,
            "precision": 0.5399515738498789,
            "recall": 0.9311064718162839
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7628956751312537,
            "auditor_fn_violation": 0.01669651626321567,
            "auditor_fp_violation": 0.01870109467366238,
            "ave_precision_score": 0.7634881060421566,
            "fpr": 0.40504939626783754,
            "logloss": 0.7354058794711764,
            "mae": 0.41020076214024054,
            "precision": 0.5466830466830467,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7974992513300272,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7797098728267032,
            "fpr": 0.4682017543859649,
            "logloss": 1.1747792792828795,
            "mae": 0.44298387830218544,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7969545529725037,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7793389623500014,
            "fpr": 0.47200878155872666,
            "logloss": 1.1609817959355166,
            "mae": 0.4423685362235399,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7644409203318394,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0019903974717393994,
            "ave_precision_score": 0.5318303849727294,
            "fpr": 0.46710526315789475,
            "logloss": 15.907189582022482,
            "mae": 0.46918388508799436,
            "precision": 0.5292817679558011,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7577616435179875,
            "auditor_fn_violation": 0.0004991622855162054,
            "auditor_fp_violation": 0.002124895517578238,
            "ave_precision_score": 0.5235496766320143,
            "fpr": 0.47420417124039516,
            "logloss": 16.14923304148993,
            "mae": 0.47585536773458664,
            "precision": 0.5231788079470199,
            "recall": 0.9978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017545,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7644482966875419,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5318377608633096,
            "fpr": 0.47478070175438597,
            "logloss": 15.950313725488714,
            "mae": 0.474387156531999,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7577628910740206,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5235509241178555,
            "fpr": 0.47859495060373214,
            "logloss": 16.187274739962085,
            "mae": 0.47849543636376457,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7616938094797121,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.735871342454797,
            "fpr": 0.4682017543859649,
            "logloss": 1.1574849623738355,
            "mae": 0.4425337534746512,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7262537471874697,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7396836167032623,
            "fpr": 0.47200878155872666,
            "logloss": 1.1474272911222398,
            "mae": 0.44188455995846987,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7688956963688365,
            "auditor_fn_violation": 0.008822290590777573,
            "auditor_fp_violation": 0.0012484299663709044,
            "ave_precision_score": 0.7260836843985081,
            "fpr": 0.24780701754385964,
            "logloss": 3.034514567977253,
            "mae": 0.3466705610003453,
            "precision": 0.6549618320610687,
            "recall": 0.8956158663883089
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.769873492148489,
            "auditor_fn_violation": 0.005003177537697154,
            "auditor_fp_violation": 0.007600781478161916,
            "ave_precision_score": 0.7243557700984101,
            "fpr": 0.2513721185510428,
            "logloss": 3.096416096582816,
            "mae": 0.3526704059555947,
            "precision": 0.6444099378881988,
            "recall": 0.8736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7633031217559034,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0017523601150682927,
            "ave_precision_score": 0.5275936920965788,
            "fpr": 0.4692982456140351,
            "logloss": 16.215087520047508,
            "mae": 0.47041061683315194,
            "precision": 0.5275938189845475,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7618522601984565,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002255813250888742,
            "ave_precision_score": 0.523704520396913,
            "fpr": 0.47420417124039516,
            "logloss": 16.37885388302843,
            "mae": 0.47424627225180993,
            "precision": 0.523704520396913,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.38174084877364095,
            "auditor_fn_violation": 0.001329982053254234,
            "auditor_fp_violation": 0.004173250678659699,
            "ave_precision_score": 0.5234760641178489,
            "fpr": 0.008771929824561403,
            "logloss": 18.050558771133957,
            "mae": 0.5312409628705498,
            "precision": 0.3333333333333333,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.4662070284222222,
            "auditor_fn_violation": 0.003579640649373165,
            "auditor_fp_violation": 0.0038545201865074173,
            "ave_precision_score": 0.5211579064082387,
            "fpr": 0.009879253567508232,
            "logloss": 17.76543597859426,
            "mae": 0.5224010398699345,
            "precision": 0.47058823529411764,
            "recall": 0.016842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.45827589388599166,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0021068838377699445,
            "ave_precision_score": 0.5281919569278101,
            "fpr": 0.005482456140350877,
            "logloss": 17.966295837919382,
            "mae": 0.5249024963459784,
            "precision": 0.5,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.00014558899994223415,
            "auditor_fp_violation": 0.0007678828588404718,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.003293084522502744,
            "logloss": 17.755168727104202,
            "mae": 0.5179300347811304,
            "precision": 0.6666666666666666,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7234252926293331,
            "auditor_fn_violation": 0.003598505658718822,
            "auditor_fp_violation": 0.007067683643288368,
            "ave_precision_score": 0.7239224616470543,
            "fpr": 0.4517543859649123,
            "logloss": 3.225650807067391,
            "mae": 0.453838343257901,
            "precision": 0.5344632768361582,
            "recall": 0.9874739039665971
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7572367560578117,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.005377697660600812,
            "ave_precision_score": 0.7577647486449967,
            "fpr": 0.43907793633369924,
            "logloss": 3.004974423909787,
            "mae": 0.4454848992862567,
            "precision": 0.5381062355658198,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7644421454301983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0034819294193914525,
            "ave_precision_score": 0.5318316099945348,
            "fpr": 0.46600877192982454,
            "logloss": 15.9036099746414,
            "mae": 0.4684811120591404,
            "precision": 0.5298672566371682,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7577616435179875,
            "auditor_fn_violation": 0.0004991622855162054,
            "auditor_fp_violation": 0.002124895517578238,
            "ave_precision_score": 0.5235496766320143,
            "fpr": 0.47420417124039516,
            "logloss": 16.146263256139573,
            "mae": 0.4756821864719056,
            "precision": 0.5231788079470199,
            "recall": 0.9978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7644433793146032,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5318328438020234,
            "fpr": 0.47478070175438597,
            "logloss": 15.942778338754504,
            "mae": 0.4739868381436457,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7577604180468334,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5235484512229497,
            "fpr": 0.47859495060373214,
            "logloss": 16.180932488466254,
            "mae": 0.47823270491266096,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.45827589388599166,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.001182589846440582,
            "ave_precision_score": 0.5281919569278101,
            "fpr": 0.0043859649122807015,
            "logloss": 17.96561136816133,
            "mae": 0.5247427099649876,
            "precision": 0.5555555555555556,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.00014558899994223415,
            "auditor_fp_violation": 0.0007678828588404718,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.003293084522502744,
            "logloss": 17.754824687430023,
            "mae": 0.517916640714547,
            "precision": 0.6666666666666666,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 9675,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7191937394888783,
            "auditor_fn_violation": 0.003101765373768451,
            "auditor_fp_violation": 0.0035072525424415637,
            "ave_precision_score": 0.7199894945242624,
            "fpr": 0.44846491228070173,
            "logloss": 3.337617290334661,
            "mae": 0.45333254417160956,
            "precision": 0.5357548240635641,
            "recall": 0.9853862212943633
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7525991271329899,
            "auditor_fn_violation": 0.0017609336183488364,
            "auditor_fp_violation": 0.003592684719886408,
            "ave_precision_score": 0.753600622007387,
            "fpr": 0.43578485181119647,
            "logloss": 3.113044797918935,
            "mae": 0.44440804771882897,
            "precision": 0.5399768250289687,
            "recall": 0.9810526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7455793010031085,
            "auditor_fn_violation": 0.010294198439731901,
            "auditor_fp_violation": 0.0037604837729427495,
            "ave_precision_score": 0.6922711585262288,
            "fpr": 0.2642543859649123,
            "logloss": 3.6605415304533833,
            "mae": 0.3591733757863965,
            "precision": 0.6365007541478129,
            "recall": 0.8810020876826722
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7549087776073435,
            "auditor_fn_violation": 0.007346467155814896,
            "auditor_fp_violation": 0.002479883986747092,
            "ave_precision_score": 0.6968862990092126,
            "fpr": 0.2711306256860593,
            "logloss": 3.770819080803611,
            "mae": 0.35462911341351616,
            "precision": 0.6274509803921569,
            "recall": 0.8757894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.38304169871442695,
            "auditor_fn_violation": 0.001329982053254234,
            "auditor_fp_violation": 0.002519650743486893,
            "ave_precision_score": 0.5255028228190518,
            "fpr": 0.007675438596491228,
            "logloss": 17.99605054110781,
            "mae": 0.5291999718092644,
            "precision": 0.36363636363636365,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.4663084942078986,
            "auditor_fn_violation": 0.003579640649373165,
            "auditor_fp_violation": 0.002510095771357214,
            "ave_precision_score": 0.5212680418867952,
            "fpr": 0.007683863885839737,
            "logloss": 17.719085558721183,
            "mae": 0.5219343997104631,
            "precision": 0.5333333333333333,
            "recall": 0.016842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.45914576166608906,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0031400672582148213,
            "ave_precision_score": 0.528887851151888,
            "fpr": 0.007675438596491228,
            "logloss": 17.976626106844705,
            "mae": 0.5266855398454425,
            "precision": 0.4166666666666667,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5825972070181441,
            "auditor_fn_violation": 0.0005569356981917043,
            "auditor_fp_violation": 7.049416409027294e-05,
            "ave_precision_score": 0.5261436051960057,
            "fpr": 0.0043907793633369925,
            "logloss": 17.760778160184767,
            "mae": 0.5180783032978405,
            "precision": 0.6363636363636364,
            "recall": 0.014736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.45914576166608906,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0031400672582148213,
            "ave_precision_score": 0.528887851151888,
            "fpr": 0.007675438596491228,
            "logloss": 17.976568392480438,
            "mae": 0.5266543022405944,
            "precision": 0.4166666666666667,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5832080523131998,
            "auditor_fn_violation": 0.0005569356981917043,
            "auditor_fp_violation": 7.049416409027294e-05,
            "ave_precision_score": 0.5266986291194505,
            "fpr": 0.0043907793633369925,
            "logloss": 17.76024782808544,
            "mae": 0.5180183764870159,
            "precision": 0.6363636363636364,
            "recall": 0.014736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7270195048674973,
            "auditor_fn_violation": 0.002907189686115079,
            "auditor_fp_violation": 0.0045961468335966975,
            "ave_precision_score": 0.7279060670690229,
            "fpr": 0.45285087719298245,
            "logloss": 3.5023127498615247,
            "mae": 0.45495028707050067,
            "precision": 0.5343855693348365,
            "recall": 0.9895615866388309
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7581129003775275,
            "auditor_fn_violation": 0.0017840429834190307,
            "auditor_fp_violation": 0.004259861630026485,
            "ave_precision_score": 0.7591329099096115,
            "fpr": 0.4434687156970362,
            "logloss": 3.292436653064923,
            "mae": 0.4472898926224729,
            "precision": 0.5372279495990836,
            "recall": 0.9873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.45914576166608906,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0031400672582148213,
            "ave_precision_score": 0.528887851151888,
            "fpr": 0.007675438596491228,
            "logloss": 17.9761015699126,
            "mae": 0.526681268367132,
            "precision": 0.4166666666666667,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.582298961404109,
            "auditor_fn_violation": 0.0005569356981917043,
            "auditor_fp_violation": 7.049416409027294e-05,
            "ave_precision_score": 0.5258629034416197,
            "fpr": 0.0043907793633369925,
            "logloss": 17.76016596626573,
            "mae": 0.5180711026510999,
            "precision": 0.6363636363636364,
            "recall": 0.014736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7639969722796338,
            "auditor_fn_violation": 0.0004830055305277809,
            "auditor_fp_violation": 0.00489749199789313,
            "ave_precision_score": 0.5319110252284761,
            "fpr": 0.4594298245614035,
            "logloss": 15.876132126089132,
            "mae": 0.46102922693901144,
            "precision": 0.5328874024526199,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.757231933240393,
            "auditor_fn_violation": 0.003410942284360737,
            "auditor_fp_violation": 0.003474355230163453,
            "ave_precision_score": 0.523554682281984,
            "fpr": 0.47200878155872666,
            "logloss": 16.341302220521403,
            "mae": 0.47923595953134424,
            "precision": 0.5216907675194661,
            "recall": 0.9873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.45914576166608906,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0021068838377699445,
            "ave_precision_score": 0.528887851151888,
            "fpr": 0.005482456140350877,
            "logloss": 17.966032695045385,
            "mae": 0.525097929963458,
            "precision": 0.5,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.00014558899994223415,
            "auditor_fp_violation": 0.0007678828588404718,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.003293084522502744,
            "logloss": 17.754398824963005,
            "mae": 0.5179037245646789,
            "precision": 0.6666666666666666,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7204808941194406,
            "auditor_fn_violation": 0.002907189686115079,
            "auditor_fp_violation": 0.007067683643288368,
            "ave_precision_score": 0.7222895816389562,
            "fpr": 0.4517543859649123,
            "logloss": 3.6119156743194107,
            "mae": 0.45529726718425334,
            "precision": 0.5349887133182845,
            "recall": 0.9895615866388309
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.754063413952333,
            "auditor_fn_violation": 0.0014951759200415968,
            "auditor_fp_violation": 0.003139507950734655,
            "ave_precision_score": 0.7561224588858092,
            "fpr": 0.4445664105378705,
            "logloss": 3.383311611825014,
            "mae": 0.44780316088722033,
            "precision": 0.5355504587155964,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7644433793146032,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5318328438020234,
            "fpr": 0.47478070175438597,
            "logloss": 15.941156586668663,
            "mae": 0.4739120445099839,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7577591955411189,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5235472287801376,
            "fpr": 0.47859495060373214,
            "logloss": 16.17965482868306,
            "mae": 0.4782049031079666,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7291220900571498,
            "auditor_fn_violation": 0.002907189686115079,
            "auditor_fp_violation": 0.004894959685588115,
            "ave_precision_score": 0.7292055047032928,
            "fpr": 0.44956140350877194,
            "logloss": 2.9202426409486746,
            "mae": 0.4515399781575445,
            "precision": 0.5361990950226244,
            "recall": 0.9895615866388309
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7623202598802659,
            "auditor_fn_violation": 0.0014951759200415968,
            "auditor_fp_violation": 0.005611838991329227,
            "ave_precision_score": 0.7617282338943443,
            "fpr": 0.43798024149286496,
            "logloss": 2.720878265614306,
            "mae": 0.4427171688221967,
            "precision": 0.5392609699769053,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017544,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7786919850842995,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7333524973855998,
            "fpr": 0.4682017543859649,
            "logloss": 1.162400574167736,
            "mae": 0.44391314882612504,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7844925212945729,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7407187637770504,
            "fpr": 0.47200878155872666,
            "logloss": 1.15394758024698,
            "mae": 0.44359591733521153,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7101747189920591,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06636177626514322,
            "ave_precision_score": 0.7114772027046707,
            "fpr": 0.36951754385964913,
            "logloss": 0.7174985493787664,
            "mae": 0.40019739474434884,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7290382059293574,
            "auditor_fn_violation": 0.022323646657808078,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7303574630058337,
            "fpr": 0.36223929747530187,
            "logloss": 0.7127246889341167,
            "mae": 0.39885483350109974,
            "precision": 0.5741935483870968,
            "recall": 0.9368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.3817084419347746,
            "auditor_fn_violation": 0.001329982053254234,
            "auditor_fp_violation": 0.002519650743486893,
            "ave_precision_score": 0.5234419516558843,
            "fpr": 0.007675438596491228,
            "logloss": 18.0464144323835,
            "mae": 0.5304966393506906,
            "precision": 0.36363636363636365,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.46635239183074356,
            "auditor_fn_violation": 0.003579640649373165,
            "auditor_fp_violation": 0.0031823079789323155,
            "ave_precision_score": 0.5213082823480883,
            "fpr": 0.008781558726673985,
            "logloss": 17.76194403879629,
            "mae": 0.5219424372348775,
            "precision": 0.5,
            "recall": 0.016842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7644458492688498,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.000757161379198591,
            "ave_precision_score": 0.5318353135959966,
            "fpr": 0.47149122807017546,
            "logloss": 15.906550988495928,
            "mae": 0.47081330364668056,
            "precision": 0.5269526952695269,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.7577579610276138,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013192479279751082,
            "ave_precision_score": 0.5235459943249842,
            "fpr": 0.47639956092206365,
            "logloss": 16.152349261670473,
            "mae": 0.47685916406132123,
            "precision": 0.5225522552255225,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7644446044129621,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5318340688238288,
            "fpr": 0.47478070175438597,
            "logloss": 15.969919203341172,
            "mae": 0.47462289505883265,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.75776166287505,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5235496959826306,
            "fpr": 0.47859495060373214,
            "logloss": 16.202123036629327,
            "mae": 0.4785549822544554,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7633031217559034,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0017523601150682927,
            "ave_precision_score": 0.5275936920965788,
            "fpr": 0.4692982456140351,
            "logloss": 16.214518879167045,
            "mae": 0.4704156832733339,
            "precision": 0.5275938189845475,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7621412803532008,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002255813250888742,
            "ave_precision_score": 0.5242825607064018,
            "fpr": 0.47420417124039516,
            "logloss": 16.35920588096466,
            "mae": 0.4742512885187022,
            "precision": 0.523704520396913,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7511028368891186,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06563247032129979,
            "ave_precision_score": 0.7520245223910824,
            "fpr": 0.36951754385964913,
            "logloss": 0.7001333082795828,
            "mae": 0.40303610365853315,
            "precision": 0.5662805662805663,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7494561774451232,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7503320370201405,
            "fpr": 0.36223929747530187,
            "logloss": 0.6928596165657519,
            "mae": 0.4008162537861603,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7633031217559034,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0017523601150682927,
            "ave_precision_score": 0.5275936920965788,
            "fpr": 0.4692982456140351,
            "logloss": 16.216004779801413,
            "mae": 0.47040393062161107,
            "precision": 0.5275938189845475,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7618522601984565,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002255813250888742,
            "ave_precision_score": 0.523704520396913,
            "fpr": 0.47420417124039516,
            "logloss": 16.378833927163292,
            "mae": 0.4742268667155872,
            "precision": 0.523704520396913,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017545,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.45914576166608906,
            "auditor_fn_violation": 0.002895744057429594,
            "auditor_fp_violation": 0.0031400672582148213,
            "ave_precision_score": 0.528887851151888,
            "fpr": 0.007675438596491228,
            "logloss": 17.97844327888813,
            "mae": 0.5268774436982838,
            "precision": 0.4166666666666667,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5830708912286704,
            "auditor_fn_violation": 0.0005569356981917043,
            "auditor_fp_violation": 7.049416409027294e-05,
            "ave_precision_score": 0.5265646578275845,
            "fpr": 0.0043907793633369925,
            "logloss": 17.76170200701076,
            "mae": 0.5180906451232609,
            "precision": 0.6363636363636364,
            "recall": 0.014736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.429345447386734,
            "auditor_fn_violation": 0.0006409552063875849,
            "auditor_fp_violation": 0.0012534945909809165,
            "ave_precision_score": 0.5242441306816101,
            "fpr": 0.003289473684210526,
            "logloss": 18.21617746134247,
            "mae": 0.5274122807017545,
            "precision": 0.25,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5112063088566642,
            "auditor_fn_violation": 0.0004968513490091865,
            "auditor_fp_violation": 0.0005614356640046727,
            "ave_precision_score": 0.5213599861343811,
            "fpr": 0.0010976948408342481,
            "logloss": 18.008693289989026,
            "mae": 0.5214050493962679,
            "precision": 0.5,
            "recall": 0.002105263157894737
        }
    }
]