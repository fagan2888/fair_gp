[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5795651171528399,
            "auditor_fn_violation": 0.013624629292171377,
            "auditor_fp_violation": 0.0009740800933450047,
            "ave_precision_score": 0.5726319166315919,
            "fpr": 0.1162280701754386,
            "logloss": 1.8136508192788414,
            "mae": 0.4845336663618991,
            "precision": 0.576,
            "recall": 0.29327902240325865
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5349366576309816,
            "auditor_fn_violation": 0.006088294495167065,
            "auditor_fp_violation": 0.008021993100203859,
            "ave_precision_score": 0.5283018405207098,
            "fpr": 0.1251372118551043,
            "logloss": 2.1546432829372524,
            "mae": 0.4924812353019351,
            "precision": 0.545816733067729,
            "recall": 0.2958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.47067443448463386,
            "auditor_fn_violation": 0.0936662557616036,
            "auditor_fp_violation": 0.09179532858273952,
            "ave_precision_score": 0.4821296496062568,
            "fpr": 0.23684210526315788,
            "logloss": 0.8081092953001509,
            "mae": 0.5235978787470805,
            "precision": 0.4988399071925754,
            "recall": 0.4378818737270876
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.46113078290331516,
            "auditor_fn_violation": 0.06709689349989213,
            "auditor_fp_violation": 0.0887564685588835,
            "ave_precision_score": 0.4757818442908364,
            "fpr": 0.21075740944017562,
            "logloss": 0.7739217049824216,
            "mae": 0.5075317402702524,
            "precision": 0.5012987012987012,
            "recall": 0.4168466522678186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.47020574938216175,
            "auditor_fn_violation": 0.09411289169971773,
            "auditor_fp_violation": 0.09179532858273952,
            "ave_precision_score": 0.4816183437499124,
            "fpr": 0.23684210526315788,
            "logloss": 0.808448532726663,
            "mae": 0.5237158434628918,
            "precision": 0.49767441860465117,
            "recall": 0.43584521384928715
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.46069866969755846,
            "auditor_fn_violation": 0.06709689349989213,
            "auditor_fp_violation": 0.0887564685588835,
            "ave_precision_score": 0.4754054473933301,
            "fpr": 0.21075740944017562,
            "logloss": 0.774011442219636,
            "mae": 0.5075496008903868,
            "precision": 0.5012987012987012,
            "recall": 0.4168466522678186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.4863326551939318,
            "auditor_fn_violation": 0.09411289169971773,
            "auditor_fp_violation": 0.09233706296620411,
            "ave_precision_score": 0.5002881997042483,
            "fpr": 0.23793859649122806,
            "logloss": 0.7996203508876701,
            "mae": 0.5218279402735725,
            "precision": 0.4965197215777262,
            "recall": 0.43584521384928715
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.4802198911719583,
            "auditor_fn_violation": 0.0682017008342955,
            "auditor_fp_violation": 0.0887564685588835,
            "ave_precision_score": 0.498415053206554,
            "fpr": 0.21075740944017562,
            "logloss": 0.7667998443911375,
            "mae": 0.5049068806232919,
            "precision": 0.5038759689922481,
            "recall": 0.42116630669546434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.471913871976955,
            "auditor_fn_violation": 0.0880498088398185,
            "auditor_fp_violation": 0.08989925824061341,
            "ave_precision_score": 0.4875337109472031,
            "fpr": 0.2576754385964912,
            "logloss": 0.8028372210262672,
            "mae": 0.5228772965635646,
            "precision": 0.49678800856531047,
            "recall": 0.4725050916496945
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.45536913625654607,
            "auditor_fn_violation": 0.08403885318153693,
            "auditor_fp_violation": 0.08762692096597145,
            "ave_precision_score": 0.47943980609513737,
            "fpr": 0.23819978046103182,
            "logloss": 0.7697575168823824,
            "mae": 0.5074817297651006,
            "precision": 0.4965197215777262,
            "recall": 0.46220302375809935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5274128812706511,
            "auditor_fn_violation": 0.01084208739772038,
            "auditor_fp_violation": 0.007998395632787434,
            "ave_precision_score": 0.5309845322439499,
            "fpr": 0.33114035087719296,
            "logloss": 0.8037555688821602,
            "mae": 0.503421584658913,
            "precision": 0.5492537313432836,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5086456264785707,
            "auditor_fn_violation": 0.005272728565907926,
            "auditor_fp_violation": 0.013564371961737504,
            "ave_precision_score": 0.5156170984467685,
            "fpr": 0.3578485181119649,
            "logloss": 0.8074593581327577,
            "mae": 0.4999849300434901,
            "precision": 0.5060606060606061,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6742695206852822,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5683276383508464,
            "fpr": 0.15460526315789475,
            "logloss": 0.684435861713258,
            "mae": 0.49241337487310693,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6376071758101569,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5350247356207626,
            "fpr": 0.14270032930845225,
            "logloss": 0.6885180965840401,
            "mae": 0.4948685719139882,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5060787640714128,
            "auditor_fn_violation": 0.09325981705791979,
            "auditor_fp_violation": 0.0847658040588407,
            "ave_precision_score": 0.5169089169689403,
            "fpr": 0.22039473684210525,
            "logloss": 0.787961996165085,
            "mae": 0.5187082619063164,
            "precision": 0.5121359223300971,
            "recall": 0.42973523421588594
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5046051871128302,
            "auditor_fn_violation": 0.06708978100632303,
            "auditor_fp_violation": 0.07341814332758351,
            "ave_precision_score": 0.5160978256013089,
            "fpr": 0.1986827661909989,
            "logloss": 0.7574211980628855,
            "mae": 0.5031243296080442,
            "precision": 0.5134408602150538,
            "recall": 0.41252699784017277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6742695206852822,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5683276383508464,
            "fpr": 0.15460526315789475,
            "logloss": 0.6844270326762228,
            "mae": 0.492361357598974,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6376071758101569,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5350247356207626,
            "fpr": 0.14270032930845225,
            "logloss": 0.6885074458932645,
            "mae": 0.49482046890468157,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 4719,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.5095963006164721,
            "auditor_fn_violation": 0.012427644978025513,
            "auditor_fp_violation": 0.027646685002291973,
            "ave_precision_score": 0.5255283527841339,
            "fpr": 0.30153508771929827,
            "logloss": 0.8278537367694621,
            "mae": 0.4905703005854759,
            "precision": 0.5045045045045045,
            "recall": 0.570264765784114
        },
        "train": {
            "accuracy": 0.45993413830954993,
            "auc_prc": 0.48671039258438853,
            "auditor_fn_violation": 0.012691059358500498,
            "auditor_fp_violation": 0.023051591657519226,
            "ave_precision_score": 0.5089158814247867,
            "fpr": 0.31613611416026344,
            "logloss": 0.8530571614876882,
            "mae": 0.49344619334921747,
            "precision": 0.473491773308958,
            "recall": 0.5593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5124862296606135,
            "auditor_fn_violation": 0.0007391824775788759,
            "auditor_fp_violation": 0.008201546026586662,
            "ave_precision_score": 0.5711050450254467,
            "fpr": 0.4451754385964912,
            "logloss": 0.6935690293931817,
            "mae": 0.4894170638239175,
            "precision": 0.5458612975391499,
            "recall": 0.9938900203665988
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5133454296290199,
            "auditor_fn_violation": 0.0023234145659126637,
            "auditor_fp_violation": 0.004135957346714759,
            "ave_precision_score": 0.5341300847663489,
            "fpr": 0.47530186608122943,
            "logloss": 0.7028398623892825,
            "mae": 0.4947301204654702,
            "precision": 0.5145739910313901,
            "recall": 0.9913606911447084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6311961876771914,
            "auditor_fn_violation": 0.0016279879944259845,
            "auditor_fp_violation": 0.02393788806934201,
            "ave_precision_score": 0.6050822373193363,
            "fpr": 0.29605263157894735,
            "logloss": 3.5525250918806814,
            "mae": 0.3464615044914379,
            "precision": 0.6316507503410641,
            "recall": 0.9429735234215886
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6033297389867722,
            "auditor_fn_violation": 0.001967789887456644,
            "auditor_fp_violation": 0.02166232162458837,
            "ave_precision_score": 0.5703506920588375,
            "fpr": 0.34357848518111966,
            "logloss": 4.040089205879294,
            "mae": 0.3763211975384015,
            "precision": 0.5876152832674572,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6746294157999781,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5781478509743696,
            "fpr": 0.15460526315789475,
            "logloss": 0.684562368488017,
            "mae": 0.4924365285326514,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6374170471429697,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5448253134816885,
            "fpr": 0.14270032930845225,
            "logloss": 0.6881660070132298,
            "mae": 0.49463022484737484,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.518454023863868,
            "auditor_fn_violation": 0.017251313109658082,
            "auditor_fp_violation": 0.01138684002166938,
            "ave_precision_score": 0.5217301547390126,
            "fpr": 0.11513157894736842,
            "logloss": 0.7059863700225849,
            "mae": 0.5027184234768675,
            "precision": 0.5138888888888888,
            "recall": 0.22606924643584522
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5054639990380398,
            "auditor_fn_violation": 0.0022167271623758796,
            "auditor_fp_violation": 0.010173278971303119,
            "ave_precision_score": 0.5109241776206941,
            "fpr": 0.1141602634467618,
            "logloss": 0.7029323577750065,
            "mae": 0.5006107372588567,
            "precision": 0.514018691588785,
            "recall": 0.23758099352051837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4401744828082823,
            "auditor_fn_violation": 0.00048683317254440335,
            "auditor_fp_violation": 0.0010782597824728092,
            "ave_precision_score": 0.4585537267771635,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6937435615123768,
            "mae": 0.5002831730076618,
            "precision": 0.3333333333333333,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.39305954094418816,
            "auditor_fn_violation": 0.0004433454324751741,
            "auditor_fp_violation": 0.0008575740944017565,
            "ave_precision_score": 0.41543708140287583,
            "fpr": 0.003293084522502744,
            "logloss": 0.6947147890137864,
            "mae": 0.5004508132534152,
            "precision": 0.25,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.4408778559356776,
            "auditor_fn_violation": 6.029585164541372e-05,
            "auditor_fp_violation": 0.0010782597824728092,
            "ave_precision_score": 0.4554431989889882,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6939934284682463,
            "mae": 0.5003958425500936,
            "precision": 0.5,
            "recall": 0.004073319755600814
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.39401649605821726,
            "auditor_fn_violation": 0.0004433454324751741,
            "auditor_fp_violation": 0.001283910929904344,
            "ave_precision_score": 0.4144225182195758,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6978702488564333,
            "mae": 0.5006081578367759,
            "precision": 0.3333333333333333,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6779868623656726,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5799643681530711,
            "fpr": 0.15460526315789475,
            "logloss": 0.6824123007399195,
            "mae": 0.4914309454983787,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.638930585045761,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5409186217972899,
            "fpr": 0.14270032930845225,
            "logloss": 0.6873048855404721,
            "mae": 0.4942219500091544,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7082568920033898,
            "auditor_fn_violation": 0.00761290956515525,
            "auditor_fp_violation": 0.0029925615701962747,
            "ave_precision_score": 0.6882678452600122,
            "fpr": 0.025219298245614034,
            "logloss": 0.8155211699391429,
            "mae": 0.4595945670058045,
            "precision": 0.8685714285714285,
            "recall": 0.3095723014256619
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6797706301059623,
            "auditor_fn_violation": 0.005156557837612295,
            "auditor_fp_violation": 0.0014603261721812782,
            "ave_precision_score": 0.6577065393063228,
            "fpr": 0.03402854006586169,
            "logloss": 0.9479386963838348,
            "mae": 0.45242937868846617,
            "precision": 0.8165680473372781,
            "recall": 0.2980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6654064649585612,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.6317667929225134,
            "fpr": 0.1962719298245614,
            "logloss": 3.6336270463105413,
            "mae": 0.30536747377962203,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6223593037772924,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5783811318616775,
            "fpr": 0.2305159165751921,
            "logloss": 4.5967250703550135,
            "mae": 0.3316385591091942,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4555240521185948,
            "auditor_fn_violation": 0.00048683317254440335,
            "auditor_fp_violation": 0.0003047255906988375,
            "ave_precision_score": 0.4796830270878433,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6942499547519864,
            "mae": 0.5004553852374094,
            "precision": 0.3333333333333333,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.4078386959709374,
            "auditor_fn_violation": 0.0004433454324751741,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.43881306385214414,
            "fpr": 0.0,
            "logloss": 0.6932420485185661,
            "mae": 0.5000406153639114,
            "precision": 1.0,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.4482576048652428,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4848930520735689,
            "fpr": 0.4616228070175439,
            "logloss": 0.6955837137218333,
            "mae": 0.49834939791706573,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.40362629295034164,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.44957938534727176,
            "fpr": 0.49176728869374314,
            "logloss": 0.6997892543268857,
            "mae": 0.5004276474273296,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6654064649585612,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.6317667929225134,
            "fpr": 0.1962719298245614,
            "logloss": 3.633627029864492,
            "mae": 0.3053674772173392,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6223593037772924,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5783811318616775,
            "fpr": 0.2305159165751921,
            "logloss": 4.59672504043202,
            "mae": 0.3316385629539042,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 4719,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.4674172390488994,
            "auditor_fn_violation": 0.09000384106906778,
            "auditor_fp_violation": 0.08989925824061341,
            "ave_precision_score": 0.48534921235146705,
            "fpr": 0.2576754385964912,
            "logloss": 0.8022828311269412,
            "mae": 0.5230831878521202,
            "precision": 0.4957081545064378,
            "recall": 0.47046843177189407
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.4569675919056051,
            "auditor_fn_violation": 0.0845130194194783,
            "auditor_fp_violation": 0.08762692096597145,
            "ave_precision_score": 0.4810956410661113,
            "fpr": 0.23819978046103182,
            "logloss": 0.7686571513510072,
            "mae": 0.5073682109689346,
            "precision": 0.49534883720930234,
            "recall": 0.46004319654427644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6742695206852822,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5683276383508464,
            "fpr": 0.15460526315789475,
            "logloss": 0.6842769918073781,
            "mae": 0.4918430480909975,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6376071758101569,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5350247356207626,
            "fpr": 0.14270032930845225,
            "logloss": 0.6887547689127707,
            "mae": 0.4945638682591012,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6606446278066642,
            "auditor_fn_violation": 0.004068853396219676,
            "auditor_fp_violation": 0.025026565820727598,
            "ave_precision_score": 0.6399718526928019,
            "fpr": 0.20723684210526316,
            "logloss": 2.706729470259866,
            "mae": 0.3153202932635956,
            "precision": 0.6834170854271356,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6327627757501617,
            "auditor_fn_violation": 0.0056473198938816,
            "auditor_fp_violation": 0.03913968166849618,
            "ave_precision_score": 0.603992084582706,
            "fpr": 0.24698133918770582,
            "logloss": 3.1500872316244912,
            "mae": 0.33859254855987087,
            "precision": 0.6323529411764706,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6742695206852822,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5683276383508464,
            "fpr": 0.15460526315789475,
            "logloss": 0.684451223922625,
            "mae": 0.49240881335317044,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6376071758101569,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5350247356207626,
            "fpr": 0.14270032930845225,
            "logloss": 0.6884707606056849,
            "mae": 0.4948311098058975,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6329264779771826,
            "auditor_fn_violation": 0.06885339621967342,
            "auditor_fp_violation": 0.07859836646247449,
            "ave_precision_score": 0.6165063819327327,
            "fpr": 0.24342105263157895,
            "logloss": 0.7278063328602096,
            "mae": 0.4775731330247302,
            "precision": 0.5515151515151515,
            "recall": 0.5560081466395111
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6335343928606246,
            "auditor_fn_violation": 0.06201620226035045,
            "auditor_fp_violation": 0.07716696722596833,
            "ave_precision_score": 0.6215972679888631,
            "fpr": 0.23929747530186607,
            "logloss": 0.6858458170741579,
            "mae": 0.4598713054778678,
            "precision": 0.551440329218107,
            "recall": 0.5788336933045356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6331421703210569,
            "auditor_fn_violation": 0.0016279879944259845,
            "auditor_fp_violation": 0.02160686752510732,
            "ave_precision_score": 0.6061856745119741,
            "fpr": 0.30153508771929827,
            "logloss": 3.605511256195969,
            "mae": 0.34833942207297813,
            "precision": 0.6273712737127372,
            "recall": 0.9429735234215886
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6012257311038187,
            "auditor_fn_violation": 0.0003200622106104178,
            "auditor_fp_violation": 0.02093460875019604,
            "ave_precision_score": 0.5659667620791562,
            "fpr": 0.34906695938529086,
            "logloss": 4.215575890716695,
            "mae": 0.37773295005158236,
            "precision": 0.5843137254901961,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6680059051087649,
            "auditor_fn_violation": 0.06192607281952336,
            "auditor_fp_violation": 0.04865191482268617,
            "ave_precision_score": 0.6519094494525264,
            "fpr": 0.1787280701754386,
            "logloss": 0.6990362548928379,
            "mae": 0.4568157893964988,
            "precision": 0.6164705882352941,
            "recall": 0.5336048879837068
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.666955093394047,
            "auditor_fn_violation": 0.05570504963335097,
            "auditor_fp_violation": 0.03961502273796457,
            "ave_precision_score": 0.6533896083537638,
            "fpr": 0.1668496158068057,
            "logloss": 0.6620531536605779,
            "mae": 0.4402124870212751,
            "precision": 0.6265356265356266,
            "recall": 0.550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.627649496290353,
            "auditor_fn_violation": 0.05109961767963698,
            "auditor_fp_violation": 0.0634167812643247,
            "ave_precision_score": 0.6218004881496472,
            "fpr": 0.24671052631578946,
            "logloss": 0.7239116322355477,
            "mae": 0.47264579254643696,
            "precision": 0.5689655172413793,
            "recall": 0.604887983706721
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6427901106376586,
            "auditor_fn_violation": 0.04697327836166082,
            "auditor_fp_violation": 0.05608779598557316,
            "ave_precision_score": 0.6395616802446202,
            "fpr": 0.21624588364434688,
            "logloss": 0.6777132769897428,
            "mae": 0.4537915445692453,
            "precision": 0.5946502057613169,
            "recall": 0.6241900647948164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6266590066425062,
            "auditor_fn_violation": 0.05513274020080752,
            "auditor_fp_violation": 0.0620754677668042,
            "ave_precision_score": 0.6210738860302383,
            "fpr": 0.24232456140350878,
            "logloss": 0.7308523465784539,
            "mae": 0.46614084402129885,
            "precision": 0.5700389105058365,
            "recall": 0.5967413441955194
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6473157605474684,
            "auditor_fn_violation": 0.05332236428769563,
            "auditor_fp_violation": 0.05712668574564843,
            "ave_precision_score": 0.6439726683422433,
            "fpr": 0.20965971459934138,
            "logloss": 0.6856861565077528,
            "mae": 0.4449598602413861,
            "precision": 0.5961945031712473,
            "recall": 0.6090712742980562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6664233770293875,
            "auditor_fn_violation": 0.005243505913459824,
            "auditor_fp_violation": 0.035376817935575275,
            "ave_precision_score": 0.6343234468819975,
            "fpr": 0.19956140350877194,
            "logloss": 3.3873000106012423,
            "mae": 0.3166873870326414,
            "precision": 0.6867469879518072,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6503953654911234,
            "auditor_fn_violation": 0.005979236260440548,
            "auditor_fp_violation": 0.043199682452563906,
            "ave_precision_score": 0.6077632152912611,
            "fpr": 0.22063666300768386,
            "logloss": 3.9409928682766835,
            "mae": 0.3218785720504005,
            "precision": 0.6575809199318569,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6654707177830865,
            "auditor_fn_violation": 0.0066995390717118665,
            "auditor_fp_violation": 0.03557996832937451,
            "ave_precision_score": 0.6333679476637164,
            "fpr": 0.20175438596491227,
            "logloss": 3.417294522048707,
            "mae": 0.31592186500683545,
            "precision": 0.6838487972508591,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6478757924934946,
            "auditor_fn_violation": 0.007072189438895387,
            "auditor_fp_violation": 0.04638005723694528,
            "ave_precision_score": 0.605928922198452,
            "fpr": 0.22063666300768386,
            "logloss": 3.9715765485503094,
            "mae": 0.32129806482451934,
            "precision": 0.6581632653061225,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6334816552207441,
            "auditor_fn_violation": 0.06885339621967342,
            "auditor_fp_violation": 0.07859836646247449,
            "ave_precision_score": 0.615480147696114,
            "fpr": 0.24342105263157895,
            "logloss": 0.7278036168730282,
            "mae": 0.4775718738929483,
            "precision": 0.5515151515151515,
            "recall": 0.5560081466395111
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6331224200867148,
            "auditor_fn_violation": 0.06201620226035045,
            "auditor_fp_violation": 0.07716696722596833,
            "ave_precision_score": 0.6202091273459945,
            "fpr": 0.23929747530186607,
            "logloss": 0.6858447283679215,
            "mae": 0.45987071013476793,
            "precision": 0.551440329218107,
            "recall": 0.5788336933045356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6653986417096944,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.6317589737990233,
            "fpr": 0.1962719298245614,
            "logloss": 3.633724833462394,
            "mae": 0.30536942655664223,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6223635208604583,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5783819966995415,
            "fpr": 0.2305159165751921,
            "logloss": 4.596816796726753,
            "mae": 0.3316411371880516,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6729261131601483,
            "auditor_fn_violation": 0.0008709400793225406,
            "auditor_fp_violation": 0.023487310913864242,
            "ave_precision_score": 0.6394608457881521,
            "fpr": 0.1962719298245614,
            "logloss": 3.3881937117254175,
            "mae": 0.31145686654681976,
            "precision": 0.6934931506849316,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6296185111580558,
            "auditor_fn_violation": 0.002875818233114348,
            "auditor_fp_violation": 0.032303591030265026,
            "ave_precision_score": 0.585071546955293,
            "fpr": 0.2283205268935236,
            "logloss": 4.421690962030315,
            "mae": 0.33146213424514814,
            "precision": 0.6480541455160744,
            "recall": 0.8272138228941684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 4719,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6779868623656726,
            "auditor_fn_violation": 0.10612739843498768,
            "auditor_fp_violation": 0.07565008126015753,
            "ave_precision_score": 0.5799643681530711,
            "fpr": 0.15460526315789475,
            "logloss": 0.6824123007399195,
            "mae": 0.4914309454983787,
            "precision": 0.6061452513966481,
            "recall": 0.4419551934826884
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.638930585045761,
            "auditor_fn_violation": 0.09495178914775733,
            "auditor_fp_violation": 0.07580954994511527,
            "ave_precision_score": 0.5409186217972899,
            "fpr": 0.14270032930845225,
            "logloss": 0.6873048855404721,
            "mae": 0.4942219500091544,
            "precision": 0.577922077922078,
            "recall": 0.38444924406047515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6552200211439257,
            "auditor_fn_violation": 0.007883124307714299,
            "auditor_fp_violation": 0.026844501396007837,
            "ave_precision_score": 0.6364800774781774,
            "fpr": 0.19956140350877194,
            "logloss": 2.6438639839299944,
            "mae": 0.32463624260269514,
            "precision": 0.6829268292682927,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6282344887590516,
            "auditor_fn_violation": 0.005132849525715218,
            "auditor_fp_violation": 0.04089648345617062,
            "ave_precision_score": 0.6015919891487731,
            "fpr": 0.23380900109769484,
            "logloss": 3.042712927987257,
            "mae": 0.34866180811472075,
            "precision": 0.6314878892733564,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.614627103398456,
            "auditor_fn_violation": 0.0461866223603816,
            "auditor_fp_violation": 0.020611951493936742,
            "ave_precision_score": 0.6260179896479197,
            "fpr": 0.26096491228070173,
            "logloss": 0.6731348205803345,
            "mae": 0.4716773100428103,
            "precision": 0.6210191082802548,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6092825685113192,
            "auditor_fn_violation": 0.05490370869123006,
            "auditor_fp_violation": 0.029868080602164032,
            "ave_precision_score": 0.6121443701215695,
            "fpr": 0.2645444566410538,
            "logloss": 0.661759414559457,
            "mae": 0.4701397466916963,
            "precision": 0.588034188034188,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6659674460488905,
            "auditor_fn_violation": 0.006431557508843392,
            "auditor_fp_violation": 0.033819331583114565,
            "ave_precision_score": 0.6336769339102187,
            "fpr": 0.20065789473684212,
            "logloss": 3.4063082069214277,
            "mae": 0.31603818133353556,
            "precision": 0.6871794871794872,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6492049043816307,
            "auditor_fn_violation": 0.006780577202561447,
            "auditor_fp_violation": 0.04420181903716482,
            "ave_precision_score": 0.6066896523141692,
            "fpr": 0.2217343578485181,
            "logloss": 3.955587013061748,
            "mae": 0.320677985998425,
            "precision": 0.6587837837837838,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6386939041477968,
            "auditor_fn_violation": 0.07531845142387537,
            "auditor_fp_violation": 0.03443920073342502,
            "ave_precision_score": 0.6281243250119184,
            "fpr": 0.23355263157894737,
            "logloss": 0.663837830492978,
            "mae": 0.4743005197103086,
            "precision": 0.6236749116607774,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6092532789760904,
            "auditor_fn_violation": 0.06448423752883524,
            "auditor_fp_violation": 0.0395268151168261,
            "ave_precision_score": 0.5987197849774711,
            "fpr": 0.23161361141602635,
            "logloss": 0.669246451617989,
            "mae": 0.4759425866355226,
            "precision": 0.6026365348399246,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6653376074678881,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.6316980052762864,
            "fpr": 0.1962719298245614,
            "logloss": 3.633638447359702,
            "mae": 0.3053788082214064,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.622538769129781,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5785605175869105,
            "fpr": 0.2305159165751921,
            "logloss": 4.595104492415828,
            "mae": 0.3313979749433103,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6345047356600756,
            "auditor_fn_violation": 0.004008557544574267,
            "auditor_fp_violation": 0.026459036546234948,
            "ave_precision_score": 0.6095296447450987,
            "fpr": 0.3125,
            "logloss": 3.491416462512946,
            "mae": 0.35013422005833916,
            "precision": 0.62,
            "recall": 0.9470468431771895
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6026608180397204,
            "auditor_fn_violation": 0.0009910074372974427,
            "auditor_fp_violation": 0.02620991453661598,
            "ave_precision_score": 0.5700510550140534,
            "fpr": 0.35236004390779363,
            "logloss": 4.112852859312844,
            "mae": 0.38291233219562454,
            "precision": 0.5814863102998696,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6608625265618074,
            "auditor_fn_violation": 0.0038343695287097568,
            "auditor_fp_violation": 0.02770398383131225,
            "ave_precision_score": 0.6425532236731007,
            "fpr": 0.18969298245614036,
            "logloss": 2.581752392683584,
            "mae": 0.3148487302598249,
            "precision": 0.6943462897526502,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6362216711449629,
            "auditor_fn_violation": 0.005983977922819963,
            "auditor_fp_violation": 0.03934549945115259,
            "ave_precision_score": 0.6096860096207493,
            "fpr": 0.22722283205268934,
            "logloss": 2.969055290406368,
            "mae": 0.33471255104073594,
            "precision": 0.6443298969072165,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6546172836434878,
            "auditor_fn_violation": 0.0052390395540786805,
            "auditor_fp_violation": 0.02391965662374465,
            "ave_precision_score": 0.6362943603450204,
            "fpr": 0.21162280701754385,
            "logloss": 2.6371781751117105,
            "mae": 0.322633638370777,
            "precision": 0.6799336650082919,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6271224272149778,
            "auditor_fn_violation": 0.0049171038874519036,
            "auditor_fp_violation": 0.03570938529088914,
            "ave_precision_score": 0.6005806870098753,
            "fpr": 0.26125137211855104,
            "logloss": 3.067251524993975,
            "mae": 0.35176338016104564,
            "precision": 0.6216216216216216,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6570899226758982,
            "auditor_fn_violation": 0.0008731732590131133,
            "auditor_fp_violation": 0.024057694711838978,
            "ave_precision_score": 0.6396016869371737,
            "fpr": 0.20394736842105263,
            "logloss": 2.5901944881425263,
            "mae": 0.3202208676337224,
            "precision": 0.6868686868686869,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6295483133138786,
            "auditor_fn_violation": 0.004212967024108984,
            "auditor_fp_violation": 0.04061470911086719,
            "ave_precision_score": 0.6035393653641783,
            "fpr": 0.24588364434687157,
            "logloss": 2.9879024618984746,
            "mae": 0.34766086989361905,
            "precision": 0.6285240464344942,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.5873716409939213,
            "auditor_fn_violation": 0.07994559974273771,
            "auditor_fp_violation": 0.04460453390007084,
            "ave_precision_score": 0.598469394092733,
            "fpr": 0.24342105263157895,
            "logloss": 0.6712322073340932,
            "mae": 0.46632866723168837,
            "precision": 0.6091549295774648,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5620235082646966,
            "auditor_fn_violation": 0.081208080741027,
            "auditor_fp_violation": 0.05440450054884743,
            "ave_precision_score": 0.5726567641710362,
            "fpr": 0.2535675082327113,
            "logloss": 0.6852717410279242,
            "mae": 0.4741049285908562,
            "precision": 0.5761467889908257,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.5281499092359704,
            "auditor_fn_violation": 0.08346955729445815,
            "auditor_fp_violation": 0.040312330708005176,
            "ave_precision_score": 0.6098099855446071,
            "fpr": 0.20942982456140352,
            "logloss": 0.6679259492763074,
            "mae": 0.46419650522476297,
            "precision": 0.6375711574952562,
            "recall": 0.6843177189409368
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.5020582673062028,
            "auditor_fn_violation": 0.07778222967190067,
            "auditor_fp_violation": 0.044010702524698145,
            "ave_precision_score": 0.5872557888269344,
            "fpr": 0.2074643249176729,
            "logloss": 0.6728593674788822,
            "mae": 0.4724769052655693,
            "precision": 0.6174089068825911,
            "recall": 0.6587473002159827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6509140979677579,
            "auditor_fn_violation": 0.008416854253760677,
            "auditor_fp_violation": 0.02808423969662874,
            "ave_precision_score": 0.6347954067899428,
            "fpr": 0.19846491228070176,
            "logloss": 2.5428391770372683,
            "mae": 0.328571447296713,
            "precision": 0.6835664335664335,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6263405644230075,
            "auditor_fn_violation": 0.006216319379411233,
            "auditor_fp_violation": 0.04366767288693743,
            "ave_precision_score": 0.6008679385064752,
            "fpr": 0.23380900109769484,
            "logloss": 2.933594981540629,
            "mae": 0.35232519350163594,
            "precision": 0.6321243523316062,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 4719,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6551208620008,
            "auditor_fn_violation": 0.004144781505699077,
            "auditor_fp_violation": 0.026057944743092885,
            "ave_precision_score": 0.6353169325475305,
            "fpr": 0.22039473684210525,
            "logloss": 2.7048655850865484,
            "mae": 0.32704921438055345,
            "precision": 0.6726384364820847,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.626702918630132,
            "auditor_fn_violation": 0.005991090416389083,
            "auditor_fp_violation": 0.035165438293868596,
            "ave_precision_score": 0.5989615075888781,
            "fpr": 0.26344676180021953,
            "logloss": 3.1324067756790632,
            "mae": 0.3544792314814927,
            "precision": 0.6208530805687204,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6654431714949204,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.6318034782377131,
            "fpr": 0.1962719298245614,
            "logloss": 3.633074772365706,
            "mae": 0.3053358340368781,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6223848198158379,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5784032553206335,
            "fpr": 0.2305159165751921,
            "logloss": 4.596102445191896,
            "mae": 0.33162011217400317,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5795729302735088,
            "auditor_fn_violation": 0.013624629292171377,
            "auditor_fp_violation": 0.0009740800933450047,
            "ave_precision_score": 0.5726433943545708,
            "fpr": 0.1162280701754386,
            "logloss": 1.8132421360622193,
            "mae": 0.48453205576656755,
            "precision": 0.576,
            "recall": 0.29327902240325865
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5349290754956001,
            "auditor_fn_violation": 0.006088294495167065,
            "auditor_fp_violation": 0.008021993100203859,
            "ave_precision_score": 0.5282976203095828,
            "fpr": 0.1251372118551043,
            "logloss": 2.1542092341325243,
            "mae": 0.49248555636952684,
            "precision": 0.545816733067729,
            "recall": 0.2958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6523630961506357,
            "auditor_fn_violation": 0.031900971879801336,
            "auditor_fp_violation": 0.014733612534900218,
            "ave_precision_score": 0.6531644276768996,
            "fpr": 0.26973684210526316,
            "logloss": 0.6844648039152315,
            "mae": 0.47446964816353693,
            "precision": 0.6244274809160305,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6389949964401511,
            "auditor_fn_violation": 0.028815082279696442,
            "auditor_fp_violation": 0.032227634467618005,
            "ave_precision_score": 0.6399906420799203,
            "fpr": 0.2689352360043908,
            "logloss": 0.6714142237537463,
            "mae": 0.47316542593813393,
            "precision": 0.6048387096774194,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.627035617398481,
            "auditor_fn_violation": 0.05513274020080752,
            "auditor_fp_violation": 0.06426063674625997,
            "ave_precision_score": 0.6209212427586721,
            "fpr": 0.24561403508771928,
            "logloss": 0.7312353699547204,
            "mae": 0.4661085004683404,
            "precision": 0.5667311411992263,
            "recall": 0.5967413441955194
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6476246480225961,
            "auditor_fn_violation": 0.05332236428769563,
            "auditor_fp_violation": 0.05712668574564843,
            "ave_precision_score": 0.6442828440830115,
            "fpr": 0.20965971459934138,
            "logloss": 0.6856253708713997,
            "mae": 0.4448430053143467,
            "precision": 0.5961945031712473,
            "recall": 0.6090712742980562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.66615034686359,
            "auditor_fn_violation": 0.004808035873798554,
            "auditor_fp_violation": 0.024794766012418226,
            "ave_precision_score": 0.6318758110788694,
            "fpr": 0.19846491228070176,
            "logloss": 3.658337602134609,
            "mae": 0.3057881759137716,
            "precision": 0.6895368782161235,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6241305429126591,
            "auditor_fn_violation": 0.0007491826559473506,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5786476507942393,
            "fpr": 0.2305159165751921,
            "logloss": 4.659563453688657,
            "mae": 0.3317707594315533,
            "precision": 0.6440677966101694,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6673614049809324,
            "auditor_fn_violation": 0.0027200128631150204,
            "auditor_fp_violation": 0.035376817935575275,
            "ave_precision_score": 0.6352641728955903,
            "fpr": 0.19956140350877194,
            "logloss": 3.3736586289362953,
            "mae": 0.3158719850903578,
            "precision": 0.6872852233676976,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6497074225932095,
            "auditor_fn_violation": 0.007529759858508795,
            "auditor_fp_violation": 0.043199682452563906,
            "ave_precision_score": 0.6077338346222791,
            "fpr": 0.22063666300768386,
            "logloss": 3.925432881327608,
            "mae": 0.3200578301768603,
            "precision": 0.660472972972973,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.565933128443764,
            "auditor_fn_violation": 0.07999026333654911,
            "auditor_fp_violation": 0.03876265783222904,
            "ave_precision_score": 0.5900099140900353,
            "fpr": 0.2138157894736842,
            "logloss": 0.6657889139192479,
            "mae": 0.4672051263771943,
            "precision": 0.6355140186915887,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.5637460599398589,
            "auditor_fn_violation": 0.07812362936321846,
            "auditor_fp_violation": 0.041986827661909996,
            "ave_precision_score": 0.579164034972611,
            "fpr": 0.21514818880351264,
            "logloss": 0.6759712645675734,
            "mae": 0.47552172688608346,
            "precision": 0.6095617529880478,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6655696295421192,
            "auditor_fn_violation": 0.0013309750955800936,
            "auditor_fp_violation": 0.025057819727465937,
            "ave_precision_score": 0.64540341775378,
            "fpr": 0.17543859649122806,
            "logloss": 2.635796178963264,
            "mae": 0.3148739061021156,
            "precision": 0.7096188747731398,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6345298181922675,
            "auditor_fn_violation": 0.006910972917995319,
            "auditor_fp_violation": 0.04086218049239455,
            "ave_precision_score": 0.6065537888276833,
            "fpr": 0.21185510428100987,
            "logloss": 3.035584680591586,
            "mae": 0.33538277623766677,
            "precision": 0.6565836298932385,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 4719,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.5078249818522254,
            "auditor_fn_violation": 0.09411289169971773,
            "auditor_fp_violation": 0.08964141351002208,
            "ave_precision_score": 0.5204725733738498,
            "fpr": 0.23026315789473684,
            "logloss": 0.7897515811536663,
            "mae": 0.5190402415352302,
            "precision": 0.5047169811320755,
            "recall": 0.43584521384928715
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.49710010128911797,
            "auditor_fn_violation": 0.0676421846735247,
            "auditor_fp_violation": 0.07611337619570331,
            "ave_precision_score": 0.5129681193639403,
            "fpr": 0.20417124039517015,
            "logloss": 0.7582503824453612,
            "mae": 0.5032788436086981,
            "precision": 0.5079365079365079,
            "recall": 0.4146868250539957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 4719,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6551950503871107,
            "auditor_fn_violation": 0.004144781505699077,
            "auditor_fp_violation": 0.026057944743092885,
            "ave_precision_score": 0.6353910750721203,
            "fpr": 0.22039473684210525,
            "logloss": 2.7044999678110746,
            "mae": 0.3270122270782114,
            "precision": 0.6726384364820847,
            "recall": 0.8411405295315683
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6268129818428689,
            "auditor_fn_violation": 0.005991090416389083,
            "auditor_fp_violation": 0.03504782813235065,
            "ave_precision_score": 0.5990758904489557,
            "fpr": 0.2645444566410538,
            "logloss": 3.1316741776270973,
            "mae": 0.3544586509902817,
            "precision": 0.6198738170347003,
            "recall": 0.8488120950323974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6253489878266015,
            "auditor_fn_violation": 0.042613534855468614,
            "auditor_fp_violation": 0.058189565362336965,
            "ave_precision_score": 0.6191174321647829,
            "fpr": 0.2642543859649123,
            "logloss": 0.7264731259084954,
            "mae": 0.46512224090800275,
            "precision": 0.5696428571428571,
            "recall": 0.6496945010183299
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6473920503811397,
            "auditor_fn_violation": 0.038962239771641545,
            "auditor_fp_violation": 0.051699466833934456,
            "ave_precision_score": 0.6440095327775576,
            "fpr": 0.2327113062568606,
            "logloss": 0.6810227162340835,
            "mae": 0.44472995294313206,
            "precision": 0.5930902111324377,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7039943388620893,
            "auditor_fn_violation": 0.08465537571015115,
            "auditor_fp_violation": 0.04789400758428137,
            "ave_precision_score": 0.7055976453620425,
            "fpr": 0.23135964912280702,
            "logloss": 0.6710303998196527,
            "mae": 0.46365226998749387,
            "precision": 0.6163636363636363,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6885514000847696,
            "auditor_fn_violation": 0.07880642874585402,
            "auditor_fp_violation": 0.058876136898228015,
            "ave_precision_score": 0.6899978969186913,
            "fpr": 0.24039517014270034,
            "logloss": 0.6769938805821353,
            "mae": 0.4722793609122547,
            "precision": 0.5844402277039848,
            "recall": 0.6652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6278932992459578,
            "auditor_fn_violation": 0.05448288491085147,
            "auditor_fp_violation": 0.0634167812643247,
            "ave_precision_score": 0.6295732619271999,
            "fpr": 0.24671052631578946,
            "logloss": 0.7275954813086191,
            "mae": 0.47353836640780955,
            "precision": 0.563953488372093,
            "recall": 0.5926680244399185
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6426181965886628,
            "auditor_fn_violation": 0.054230392633353344,
            "auditor_fp_violation": 0.05484308844284148,
            "ave_precision_score": 0.6443591644413895,
            "fpr": 0.21185510428100987,
            "logloss": 0.6805108944063447,
            "mae": 0.45430086538375536,
            "precision": 0.5928270042194093,
            "recall": 0.6069114470842333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6509657596628022,
            "auditor_fn_violation": 0.007007717869010617,
            "auditor_fp_violation": 0.027615431095553613,
            "ave_precision_score": 0.6347610439782702,
            "fpr": 0.19956140350877194,
            "logloss": 2.535306510301846,
            "mae": 0.32927943674790466,
            "precision": 0.6829268292682927,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6273901972500647,
            "auditor_fn_violation": 0.00805134272024429,
            "auditor_fp_violation": 0.04366767288693743,
            "ave_precision_score": 0.601926767648032,
            "fpr": 0.23380900109769484,
            "logloss": 2.9241517732121585,
            "mae": 0.35174021788911247,
            "precision": 0.6327586206896552,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6156798079104813,
            "auditor_fn_violation": 0.06081841569300033,
            "auditor_fp_violation": 0.02611263907988499,
            "ave_precision_score": 0.6172212316345989,
            "fpr": 0.27960526315789475,
            "logloss": 0.6680180944474102,
            "mae": 0.475351819801226,
            "precision": 0.5990566037735849,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5895260397504648,
            "auditor_fn_violation": 0.061876323220157764,
            "auditor_fp_violation": 0.024700584130468883,
            "ave_precision_score": 0.5886348330891359,
            "fpr": 0.27332601536772777,
            "logloss": 0.6737676364312719,
            "mae": 0.4770550615308575,
            "precision": 0.5815126050420169,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6554530074688971,
            "auditor_fn_violation": 0.009071175903097868,
            "auditor_fp_violation": 0.025732383214568486,
            "ave_precision_score": 0.6365901871581848,
            "fpr": 0.19736842105263158,
            "logloss": 2.6691364994425966,
            "mae": 0.3241393382544217,
            "precision": 0.6836555360281195,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6272380739351523,
            "auditor_fn_violation": 0.008233896721851718,
            "auditor_fp_violation": 0.04204808295436725,
            "ave_precision_score": 0.6003595130904056,
            "fpr": 0.23380900109769484,
            "logloss": 3.067365795299941,
            "mae": 0.34912179524461573,
            "precision": 0.6321243523316062,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6654442387036852,
            "auditor_fn_violation": 0.007023350126844605,
            "auditor_fp_violation": 0.03557996832937451,
            "ave_precision_score": 0.6333414954027768,
            "fpr": 0.20175438596491227,
            "logloss": 3.4160805141686588,
            "mae": 0.316036170831597,
            "precision": 0.6843910806174958,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6479368453124585,
            "auditor_fn_violation": 0.004874428926037179,
            "auditor_fp_violation": 0.04638005723694528,
            "ave_precision_score": 0.6059741132826666,
            "fpr": 0.22063666300768386,
            "logloss": 3.970184553275161,
            "mae": 0.32122347393865885,
            "precision": 0.6575809199318569,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.672255761762292,
            "auditor_fn_violation": 0.01698333154678959,
            "auditor_fp_violation": 0.028459286577488856,
            "ave_precision_score": 0.6668949604633702,
            "fpr": 0.22916666666666666,
            "logloss": 0.6591024373079596,
            "mae": 0.4371534289956591,
            "precision": 0.6186131386861314,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6963102881799172,
            "auditor_fn_violation": 0.030443843307025015,
            "auditor_fp_violation": 0.020630782499607966,
            "ave_precision_score": 0.6936012308901666,
            "fpr": 0.21405049396267836,
            "logloss": 0.6310152087764757,
            "mae": 0.4237744257520602,
            "precision": 0.6299810246679317,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 4719,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6724473688871221,
            "auditor_fn_violation": 0.00014515667988709616,
            "auditor_fp_violation": 0.023719110722173604,
            "ave_precision_score": 0.6384666218742446,
            "fpr": 0.19846491228070176,
            "logloss": 3.4187422065877415,
            "mae": 0.311681929313494,
            "precision": 0.6905982905982906,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6304498126642226,
            "auditor_fn_violation": 0.003914242294205929,
            "auditor_fp_violation": 0.03208797240081542,
            "ave_precision_score": 0.5849637529274152,
            "fpr": 0.2327113062568606,
            "logloss": 4.4529367231715105,
            "mae": 0.33143314329383955,
            "precision": 0.6430976430976431,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 4719,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6606312870595775,
            "auditor_fn_violation": 0.007713402651230929,
            "auditor_fp_violation": 0.024531712297370504,
            "ave_precision_score": 0.6419171306499551,
            "fpr": 0.20285087719298245,
            "logloss": 2.5883264899245346,
            "mae": 0.31419893390585873,
            "precision": 0.688026981450253,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6363331111656203,
            "auditor_fn_violation": 0.005194491136647601,
            "auditor_fp_violation": 0.039370001568135485,
            "ave_precision_score": 0.6094546871907001,
            "fpr": 0.2414928649835346,
            "logloss": 2.9949006599028327,
            "mae": 0.3348939672345006,
            "precision": 0.638752052545156,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6070923704431912,
            "auditor_fn_violation": 0.07531845142387537,
            "auditor_fp_violation": 0.03443920073342502,
            "ave_precision_score": 0.6180611738828802,
            "fpr": 0.23355263157894737,
            "logloss": 0.665163698724401,
            "mae": 0.4751821880539258,
            "precision": 0.6236749116607774,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.5847202328369976,
            "auditor_fn_violation": 0.06448423752883524,
            "auditor_fp_violation": 0.0395268151168261,
            "ave_precision_score": 0.5883238950693226,
            "fpr": 0.23161361141602635,
            "logloss": 0.6690848704346449,
            "mae": 0.4762132852680728,
            "precision": 0.6026365348399246,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6303220328431998,
            "auditor_fn_violation": 0.07531845142387537,
            "auditor_fp_violation": 0.0337411968162687,
            "ave_precision_score": 0.6182242416493923,
            "fpr": 0.23464912280701755,
            "logloss": 0.6680370264368206,
            "mae": 0.47531581790954397,
            "precision": 0.6225749559082893,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6171776077713769,
            "auditor_fn_violation": 0.06281517237128165,
            "auditor_fp_violation": 0.040369687941038124,
            "ave_precision_score": 0.5985563802886479,
            "fpr": 0.23380900109769484,
            "logloss": 0.6707075801364928,
            "mae": 0.4760109907185861,
            "precision": 0.6026119402985075,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.656236830803359,
            "auditor_fn_violation": 0.004901829420802514,
            "auditor_fp_violation": 0.02548756094511815,
            "ave_precision_score": 0.6378991362662378,
            "fpr": 0.20942982456140352,
            "logloss": 2.629584847626915,
            "mae": 0.320898885728133,
            "precision": 0.6800670016750419,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6287195480900073,
            "auditor_fn_violation": 0.0029919889614099804,
            "auditor_fp_violation": 0.03873294652657992,
            "ave_precision_score": 0.6023967288789489,
            "fpr": 0.25466520307354557,
            "logloss": 3.0401097660811907,
            "mae": 0.34996702936966756,
            "precision": 0.6252019386106623,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.641084218101182,
            "auditor_fn_violation": 0.003088487512059172,
            "auditor_fp_violation": 0.025883443763803818,
            "ave_precision_score": 0.6068218563112604,
            "fpr": 0.3157894736842105,
            "logloss": 3.9988018803414596,
            "mae": 0.3529067565869409,
            "precision": 0.6180371352785146,
            "recall": 0.9490835030549898
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.5984181134470484,
            "auditor_fn_violation": 0.001967789887456644,
            "auditor_fp_violation": 0.022786968794103815,
            "ave_precision_score": 0.5525695977658767,
            "fpr": 0.3556531284302964,
            "logloss": 5.143739226524712,
            "mae": 0.38469618286271395,
            "precision": 0.5792207792207792,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6640438132839438,
            "auditor_fn_violation": 0.002979061707221209,
            "auditor_fp_violation": 0.03491582281118474,
            "ave_precision_score": 0.6315648634837564,
            "fpr": 0.20065789473684212,
            "logloss": 3.469005675135532,
            "mae": 0.3163750621514808,
            "precision": 0.6855670103092784,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6479779368715269,
            "auditor_fn_violation": 0.006571944057867252,
            "auditor_fp_violation": 0.04684069703622392,
            "ave_precision_score": 0.6049553281994673,
            "fpr": 0.22283205268935236,
            "logloss": 4.022128863819818,
            "mae": 0.32202268844585963,
            "precision": 0.6547619047619048,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6655125247898749,
            "auditor_fn_violation": 0.006047450602065246,
            "auditor_fp_violation": 0.023099241571863154,
            "ave_precision_score": 0.6315560298297106,
            "fpr": 0.20614035087719298,
            "logloss": 3.6593067368565473,
            "mae": 0.30418285492449637,
            "precision": 0.6845637583892618,
            "recall": 0.8309572301425662
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.625243259782633,
            "auditor_fn_violation": 0.0007065076945326262,
            "auditor_fp_violation": 0.03318566724164968,
            "ave_precision_score": 0.5793918992868861,
            "fpr": 0.23710208562019758,
            "logloss": 4.665765199097213,
            "mae": 0.33126449783623907,
            "precision": 0.6423841059602649,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6495172188890769,
            "auditor_fn_violation": 0.006558848751205918,
            "auditor_fp_violation": 0.026060549235321084,
            "ave_precision_score": 0.627670009023735,
            "fpr": 0.2708333333333333,
            "logloss": 2.9711487205194627,
            "mae": 0.33451255408073133,
            "precision": 0.6461318051575932,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6204448792153163,
            "auditor_fn_violation": 0.004459533467838492,
            "auditor_fp_violation": 0.026815116826093784,
            "ave_precision_score": 0.5907620552229909,
            "fpr": 0.31613611416026344,
            "logloss": 3.534932113032031,
            "mae": 0.3638981656268167,
            "precision": 0.5966386554621849,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6647262183167754,
            "auditor_fn_violation": 0.00016972165648336974,
            "auditor_fp_violation": 0.027750864691419765,
            "ave_precision_score": 0.6435544648161843,
            "fpr": 0.18311403508771928,
            "logloss": 2.715515552937753,
            "mae": 0.3134346085905613,
            "precision": 0.7023172905525846,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6299302698098561,
            "auditor_fn_violation": 0.005080691239541674,
            "auditor_fp_violation": 0.0409234357848518,
            "ave_precision_score": 0.6007086176459379,
            "fpr": 0.21624588364434688,
            "logloss": 3.174080676245773,
            "mae": 0.3366755135722496,
            "precision": 0.6561954624781849,
            "recall": 0.8120950323974082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6673614049809324,
            "auditor_fn_violation": 0.0027200128631150204,
            "auditor_fp_violation": 0.035376817935575275,
            "ave_precision_score": 0.6352641728955903,
            "fpr": 0.19956140350877194,
            "logloss": 3.3736586087180256,
            "mae": 0.3158719878083747,
            "precision": 0.6872852233676976,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6497074225932095,
            "auditor_fn_violation": 0.007529759858508795,
            "auditor_fp_violation": 0.043199682452563906,
            "ave_precision_score": 0.6077338346222791,
            "fpr": 0.22063666300768386,
            "logloss": 3.9254328729099868,
            "mae": 0.32005782905030083,
            "precision": 0.660472972972973,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6658613586414462,
            "auditor_fn_violation": 0.0038522349662343243,
            "auditor_fp_violation": 0.03756980039171563,
            "ave_precision_score": 0.633570959382063,
            "fpr": 0.19956140350877194,
            "logloss": 3.4061687389388178,
            "mae": 0.31526385499392917,
            "precision": 0.6888888888888889,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6494288701666096,
            "auditor_fn_violation": 0.007655413911563259,
            "auditor_fp_violation": 0.043949447232240875,
            "ave_precision_score": 0.6069320625889476,
            "fpr": 0.21844127332601537,
            "logloss": 3.9533076550416655,
            "mae": 0.3205908807446765,
            "precision": 0.6615646258503401,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5863543987160567,
            "auditor_fn_violation": 0.07858782649087077,
            "auditor_fp_violation": 0.04927959744968122,
            "ave_precision_score": 0.588903785232732,
            "fpr": 0.25,
            "logloss": 0.6688831961491954,
            "mae": 0.4610051179333823,
            "precision": 0.6062176165803109,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5707998280292597,
            "auditor_fn_violation": 0.08112273081819757,
            "auditor_fp_violation": 0.05533068057080134,
            "ave_precision_score": 0.5731901883755565,
            "fpr": 0.26125137211855104,
            "logloss": 0.6842130974574222,
            "mae": 0.4724796456215815,
            "precision": 0.5719424460431655,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6664173750938458,
            "auditor_fn_violation": 0.005243505913459824,
            "auditor_fp_violation": 0.035376817935575275,
            "ave_precision_score": 0.6343174484633431,
            "fpr": 0.19956140350877194,
            "logloss": 3.3873217870033048,
            "mae": 0.316689320586843,
            "precision": 0.6867469879518072,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6503872704027636,
            "auditor_fn_violation": 0.005979236260440548,
            "auditor_fp_violation": 0.043199682452563906,
            "ave_precision_score": 0.6077551217898551,
            "fpr": 0.22063666300768386,
            "logloss": 3.941030009693869,
            "mae": 0.321878899516622,
            "precision": 0.6575809199318569,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6593959509762892,
            "auditor_fn_violation": 0.00275351055847358,
            "auditor_fp_violation": 0.027927970162937032,
            "ave_precision_score": 0.6387028820357976,
            "fpr": 0.19407894736842105,
            "logloss": 2.7028398780527327,
            "mae": 0.31948244518261953,
            "precision": 0.6878306878306878,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6306472577633522,
            "auditor_fn_violation": 0.009085025118956458,
            "auditor_fp_violation": 0.04170995374000314,
            "ave_precision_score": 0.6018898128589885,
            "fpr": 0.23161361141602635,
            "logloss": 3.132837739191615,
            "mae": 0.33947403651432595,
            "precision": 0.641156462585034,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5961770993836947,
            "auditor_fn_violation": 0.01887706792439347,
            "auditor_fp_violation": 0.03604356794599327,
            "ave_precision_score": 0.6010207661885635,
            "fpr": 0.39364035087719296,
            "logloss": 0.6831436015617384,
            "mae": 0.4746017743947736,
            "precision": 0.5584255842558425,
            "recall": 0.924643584521385
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5931424813192132,
            "auditor_fn_violation": 0.016145360401903303,
            "auditor_fp_violation": 0.03697614473890545,
            "ave_precision_score": 0.5943673593799425,
            "fpr": 0.411635565312843,
            "logloss": 0.6892512312738972,
            "mae": 0.4782115916520128,
            "precision": 0.5358910891089109,
            "recall": 0.9352051835853131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6345232361272677,
            "auditor_fn_violation": 0.004008557544574267,
            "auditor_fp_violation": 0.026459036546234948,
            "ave_precision_score": 0.6095473876917401,
            "fpr": 0.3125,
            "logloss": 3.4911212846281123,
            "mae": 0.35021808338413674,
            "precision": 0.62,
            "recall": 0.9470468431771895
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6028315254397583,
            "auditor_fn_violation": 0.0009910074372974427,
            "auditor_fp_violation": 0.02620991453661598,
            "ave_precision_score": 0.5702375029693432,
            "fpr": 0.35236004390779363,
            "logloss": 4.111842443159106,
            "mae": 0.3830905453189466,
            "precision": 0.5814863102998696,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.655532078812445,
            "auditor_fn_violation": 0.009071175903097868,
            "auditor_fp_violation": 0.025732383214568486,
            "ave_precision_score": 0.6368188693947259,
            "fpr": 0.19736842105263158,
            "logloss": 2.6489340712274934,
            "mae": 0.3243497236759102,
            "precision": 0.6836555360281195,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6273029196593412,
            "auditor_fn_violation": 0.008321617475870869,
            "auditor_fp_violation": 0.04204808295436725,
            "ave_precision_score": 0.6004242915333359,
            "fpr": 0.23380900109769484,
            "logloss": 3.0663339656053537,
            "mae": 0.3492239462355525,
            "precision": 0.6314878892733564,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6651135639546268,
            "auditor_fn_violation": 0.005772769500125062,
            "auditor_fp_violation": 0.023565445680710097,
            "ave_precision_score": 0.6311536208444801,
            "fpr": 0.2050438596491228,
            "logloss": 3.677263355573351,
            "mae": 0.30411120397418506,
            "precision": 0.6862416107382551,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6240224968527648,
            "auditor_fn_violation": 0.0007065076945326262,
            "auditor_fp_violation": 0.03224478594950605,
            "ave_precision_score": 0.5785352150124725,
            "fpr": 0.23819978046103182,
            "logloss": 4.683388968484211,
            "mae": 0.33118746534270116,
            "precision": 0.6413223140495867,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6659730655578493,
            "auditor_fn_violation": 0.006431557508843392,
            "auditor_fp_violation": 0.033819331583114565,
            "ave_precision_score": 0.6336825456483052,
            "fpr": 0.20065789473684212,
            "logloss": 3.4061823106136173,
            "mae": 0.31603539726985663,
            "precision": 0.6871794871794872,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6492095198913548,
            "auditor_fn_violation": 0.006780577202561447,
            "auditor_fp_violation": 0.04420181903716482,
            "ave_precision_score": 0.6066942642086918,
            "fpr": 0.2217343578485181,
            "logloss": 3.9555443967628134,
            "mae": 0.32067382053766214,
            "precision": 0.6587837837837838,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6500165994136996,
            "auditor_fn_violation": 0.008416854253760677,
            "auditor_fp_violation": 0.026992957453014957,
            "ave_precision_score": 0.632880007003361,
            "fpr": 0.19956140350877194,
            "logloss": 2.5931243078951436,
            "mae": 0.33014996462413987,
            "precision": 0.6823734729493892,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6243563095586617,
            "auditor_fn_violation": 0.008172255110919341,
            "auditor_fp_violation": 0.043594166535988715,
            "ave_precision_score": 0.5985700944573362,
            "fpr": 0.23710208562019758,
            "logloss": 2.974085006195302,
            "mae": 0.3536373464699734,
            "precision": 0.6301369863013698,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6654364179117884,
            "auditor_fn_violation": 0.0009558009075642269,
            "auditor_fp_violation": 0.02777690961370171,
            "ave_precision_score": 0.6454444910733841,
            "fpr": 0.18092105263157895,
            "logloss": 2.625886072812244,
            "mae": 0.3145938724015648,
            "precision": 0.7027027027027027,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6386656476078876,
            "auditor_fn_violation": 0.0057042198424345604,
            "auditor_fp_violation": 0.04023737650933041,
            "ave_precision_score": 0.6108907015743492,
            "fpr": 0.21185510428100987,
            "logloss": 3.0022799812553633,
            "mae": 0.3340195397039692,
            "precision": 0.6547406082289803,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 4719,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5609867243059239,
            "auditor_fn_violation": 0.0917747525636903,
            "auditor_fp_violation": 0.08641705213151644,
            "ave_precision_score": 0.5626140556639303,
            "fpr": 0.21929824561403508,
            "logloss": 0.788414591457489,
            "mae": 0.5187975032287732,
            "precision": 0.5098039215686274,
            "recall": 0.42362525458248473
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.577450019818422,
            "auditor_fn_violation": 0.06718461425391128,
            "auditor_fp_violation": 0.07184020699388428,
            "ave_precision_score": 0.5792856369652286,
            "fpr": 0.19099890230515917,
            "logloss": 0.7570866920980458,
            "mae": 0.5023118905093353,
            "precision": 0.521978021978022,
            "recall": 0.4103671706263499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6654428953349404,
            "auditor_fn_violation": 0.006666041376353308,
            "auditor_fp_violation": 0.024005604867275078,
            "ave_precision_score": 0.631803203794986,
            "fpr": 0.1962719298245614,
            "logloss": 3.633060840326679,
            "mae": 0.3053542256501039,
            "precision": 0.6924398625429553,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6223844403236602,
            "auditor_fn_violation": 0.001825540016074238,
            "auditor_fp_violation": 0.03492041712403952,
            "ave_precision_score": 0.5784088034821786,
            "fpr": 0.2305159165751921,
            "logloss": 4.596065075852157,
            "mae": 0.3316229134484305,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6317643817448693,
            "auditor_fn_violation": 0.06885339621967342,
            "auditor_fp_violation": 0.07859836646247449,
            "ave_precision_score": 0.6145656812408617,
            "fpr": 0.24342105263157895,
            "logloss": 0.7278047873529793,
            "mae": 0.4775723373321326,
            "precision": 0.5515151515151515,
            "recall": 0.5560081466395111
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.632585278695208,
            "auditor_fn_violation": 0.06201620226035045,
            "auditor_fp_violation": 0.07716696722596833,
            "ave_precision_score": 0.6195825307900833,
            "fpr": 0.23929747530186607,
            "logloss": 0.6858453228573349,
            "mae": 0.45987095692809404,
            "precision": 0.551440329218107,
            "recall": 0.5788336933045356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6494114989425978,
            "auditor_fn_violation": 0.006558848751205918,
            "auditor_fp_violation": 0.026060549235321084,
            "ave_precision_score": 0.6275548585119436,
            "fpr": 0.2708333333333333,
            "logloss": 2.972971246135224,
            "mae": 0.334621421617466,
            "precision": 0.6461318051575932,
            "recall": 0.9185336048879837
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6202503475156742,
            "auditor_fn_violation": 0.004459533467838492,
            "auditor_fp_violation": 0.026815116826093784,
            "ave_precision_score": 0.590569492741855,
            "fpr": 0.31613611416026344,
            "logloss": 3.5367992630832097,
            "mae": 0.36398705944508325,
            "precision": 0.5966386554621849,
            "recall": 0.9200863930885529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6561004719782706,
            "auditor_fn_violation": 0.004656179654839751,
            "auditor_fp_violation": 0.026795016043672133,
            "ave_precision_score": 0.6378070674821307,
            "fpr": 0.21271929824561403,
            "logloss": 2.6349941168020656,
            "mae": 0.32101964473052474,
            "precision": 0.6782752902155887,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.628785247341092,
            "auditor_fn_violation": 0.0054292034244285735,
            "auditor_fp_violation": 0.03709375490042341,
            "ave_precision_score": 0.6024624287423438,
            "fpr": 0.2579582875960483,
            "logloss": 3.0497495271677963,
            "mae": 0.35009230047257345,
            "precision": 0.6246006389776357,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6560664822271647,
            "auditor_fn_violation": 0.003240343731017978,
            "auditor_fp_violation": 0.026552798266449976,
            "ave_precision_score": 0.6377599348545506,
            "fpr": 0.20833333333333334,
            "logloss": 2.633039950929934,
            "mae": 0.32083488541227423,
            "precision": 0.6801346801346801,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6286457771254089,
            "auditor_fn_violation": 0.005049870434075486,
            "auditor_fp_violation": 0.03873294652657992,
            "ave_precision_score": 0.6023229895343354,
            "fpr": 0.25466520307354557,
            "logloss": 3.0437577778619116,
            "mae": 0.34993458198764205,
            "precision": 0.6245954692556634,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.6410580784866016,
            "auditor_fn_violation": 0.004008557544574267,
            "auditor_fp_violation": 0.025901675209401197,
            "ave_precision_score": 0.6068096527186031,
            "fpr": 0.31359649122807015,
            "logloss": 3.989871264312624,
            "mae": 0.35171003505217047,
            "precision": 0.6191744340878829,
            "recall": 0.9470468431771895
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.5988763330577102,
            "auditor_fn_violation": 0.0026624434260407357,
            "auditor_fp_violation": 0.022786968794103815,
            "ave_precision_score": 0.5530418765974123,
            "fpr": 0.3556531284302964,
            "logloss": 5.132787886945243,
            "mae": 0.3838365970593609,
            "precision": 0.5786736020806242,
            "recall": 0.9611231101511879
        }
    }
]