[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.807585836917031,
            "auditor_fn_violation": 0.040547798066595066,
            "auditor_fp_violation": 0.025557079903550353,
            "ave_precision_score": 0.8080104070831552,
            "fpr": 0.11513157894736842,
            "logloss": 1.008954044363078,
            "mae": 0.30172132011725944,
            "precision": 0.7586206896551724,
            "recall": 0.673469387755102
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8374385292458959,
            "auditor_fn_violation": 0.03432188954918809,
            "auditor_fp_violation": 0.0272287257162643,
            "ave_precision_score": 0.8378362937813109,
            "fpr": 0.10757409440175632,
            "logloss": 0.800040199688958,
            "mae": 0.261138608632664,
            "precision": 0.7752293577981652,
            "recall": 0.728448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7930724226769389,
            "auditor_fn_violation": 0.018069727891156462,
            "auditor_fp_violation": 0.017364575538372,
            "ave_precision_score": 0.793442282891426,
            "fpr": 0.11732456140350878,
            "logloss": 0.9644879039282727,
            "mae": 0.3149872290166705,
            "precision": 0.7523148148148148,
            "recall": 0.6632653061224489
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8020524145255692,
            "auditor_fn_violation": 0.02767421174154965,
            "auditor_fp_violation": 0.028714420075782697,
            "ave_precision_score": 0.8035563531688399,
            "fpr": 0.11306256860592755,
            "logloss": 0.8060726330380844,
            "mae": 0.2756877745101869,
            "precision": 0.7643020594965675,
            "recall": 0.7198275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8333069404819722,
            "auditor_fn_violation": 0.030343716433941997,
            "auditor_fp_violation": 0.026986156148665504,
            "ave_precision_score": 0.8340287761327412,
            "fpr": 0.14473684210526316,
            "logloss": 0.6947562974309298,
            "mae": 0.29248285471403423,
            "precision": 0.736,
            "recall": 0.7510204081632653
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.863109134067044,
            "auditor_fn_violation": 0.030879764563382418,
            "auditor_fp_violation": 0.0313027206624478,
            "ave_precision_score": 0.8633463817156048,
            "fpr": 0.12952799121844127,
            "logloss": 0.5854725035923105,
            "mae": 0.2596762897183148,
            "precision": 0.7546777546777547,
            "recall": 0.7823275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.83223993602532,
            "auditor_fn_violation": 0.005672663802363051,
            "auditor_fp_violation": 0.01347229151076744,
            "ave_precision_score": 0.8325084711737898,
            "fpr": 0.051535087719298246,
            "logloss": 0.6707353875923594,
            "mae": 0.34902855249042897,
            "precision": 0.8493589743589743,
            "recall": 0.5408163265306123
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.841233088918778,
            "auditor_fn_violation": 0.014109163859343658,
            "auditor_fp_violation": 0.008445128764270648,
            "ave_precision_score": 0.8415592906232602,
            "fpr": 0.04061470911086718,
            "logloss": 0.6125935133512967,
            "mae": 0.3262560678789794,
            "precision": 0.8697183098591549,
            "recall": 0.5323275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.761821286354869,
            "auditor_fn_violation": 0.03486842105263158,
            "auditor_fp_violation": 0.03510330922091961,
            "ave_precision_score": 0.7624902711430837,
            "fpr": 0.22478070175438597,
            "logloss": 1.2136120117411102,
            "mae": 0.376161260639587,
            "precision": 0.6397188049209139,
            "recall": 0.7428571428571429
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7801036569559561,
            "auditor_fn_violation": 0.03463416480563231,
            "auditor_fp_violation": 0.03390575540805026,
            "ave_precision_score": 0.7804532381327328,
            "fpr": 0.21514818880351264,
            "logloss": 1.0081227125744443,
            "mae": 0.34793268621695955,
            "precision": 0.6474820143884892,
            "recall": 0.7758620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7789879473537487,
            "auditor_fn_violation": 0.01576038310060867,
            "auditor_fp_violation": 0.018076515340483906,
            "ave_precision_score": 0.7551108911097271,
            "fpr": 0.17434210526315788,
            "logloss": 2.244394199347399,
            "mae": 0.3005853693217212,
            "precision": 0.7087912087912088,
            "recall": 0.789795918367347
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8010965015326432,
            "auditor_fn_violation": 0.022304023619364854,
            "auditor_fp_violation": 0.03372157842133311,
            "ave_precision_score": 0.7754837934578611,
            "fpr": 0.14928649835345773,
            "logloss": 2.051599053239925,
            "mae": 0.2579600928417933,
            "precision": 0.7364341085271318,
            "recall": 0.8189655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8263868845273239,
            "auditor_fn_violation": 0.02356337271750806,
            "auditor_fp_violation": 0.025910451484160647,
            "ave_precision_score": 0.8268663401006695,
            "fpr": 0.1513157894736842,
            "logloss": 0.8052700077404089,
            "mae": 0.2867650277995615,
            "precision": 0.7330754352030948,
            "recall": 0.773469387755102
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8556138134286154,
            "auditor_fn_violation": 0.023091808925394607,
            "auditor_fp_violation": 0.03431585616514046,
            "ave_precision_score": 0.8560061417665963,
            "fpr": 0.13611416026344675,
            "logloss": 0.6645976928408259,
            "mae": 0.2472590767309089,
            "precision": 0.751503006012024,
            "recall": 0.8081896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7781774251902883,
            "auditor_fn_violation": 0.016160938059434304,
            "auditor_fp_violation": 0.018076515340483906,
            "ave_precision_score": 0.7536019045472716,
            "fpr": 0.17434210526315788,
            "logloss": 2.272866233575846,
            "mae": 0.30066998540980233,
            "precision": 0.7093235831809872,
            "recall": 0.7918367346938775
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8018750189900612,
            "auditor_fn_violation": 0.0206669442446724,
            "auditor_fp_violation": 0.033097832359651,
            "ave_precision_score": 0.7761511212316181,
            "fpr": 0.150384193194292,
            "logloss": 2.0613782741936215,
            "mae": 0.2582159214722123,
            "precision": 0.7370441458733206,
            "recall": 0.8275862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7917237455942068,
            "auditor_fn_violation": 0.026309076262083786,
            "auditor_fp_violation": 0.02972478589839528,
            "ave_precision_score": 0.7782508269255437,
            "fpr": 0.17763157894736842,
            "logloss": 1.5418824176403039,
            "mae": 0.29122855833585104,
            "precision": 0.7132743362831858,
            "recall": 0.8224489795918367
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8124723663380009,
            "auditor_fn_violation": 0.021466558158900795,
            "auditor_fp_violation": 0.03453932424235727,
            "ave_precision_score": 0.8022967489850418,
            "fpr": 0.1602634467618002,
            "logloss": 1.2865671196050832,
            "mae": 0.2618861427833009,
            "precision": 0.7276119402985075,
            "recall": 0.8405172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7028490553583324,
            "auditor_fn_violation": 0.022323666308628712,
            "auditor_fp_violation": 0.02303151243036501,
            "ave_precision_score": 0.6912515898663248,
            "fpr": 0.18201754385964913,
            "logloss": 1.7599983263819514,
            "mae": 0.33480003279701903,
            "precision": 0.6925925925925925,
            "recall": 0.763265306122449
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7109648267753385,
            "auditor_fn_violation": 0.024773837011241914,
            "auditor_fp_violation": 0.02874634408681367,
            "ave_precision_score": 0.6949371692382438,
            "fpr": 0.17672886937431395,
            "logloss": 1.8118159088043706,
            "mae": 0.3071097453425609,
            "precision": 0.6939163498098859,
            "recall": 0.7866379310344828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8085775823237111,
            "auditor_fn_violation": 0.042534908700322234,
            "auditor_fp_violation": 0.025884468279704004,
            "ave_precision_score": 0.808921532425738,
            "fpr": 0.14035087719298245,
            "logloss": 0.6652387639702807,
            "mae": 0.3319327186785127,
            "precision": 0.7355371900826446,
            "recall": 0.726530612244898
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8421385291124142,
            "auditor_fn_violation": 0.032665884401377805,
            "auditor_fp_violation": 0.03613552479390596,
            "ave_precision_score": 0.8423627114213352,
            "fpr": 0.1119648737650933,
            "logloss": 0.5387763198205655,
            "mae": 0.28984829897649284,
            "precision": 0.7713004484304933,
            "recall": 0.7413793103448276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7946233894087867,
            "auditor_fn_violation": 0.012974400286430363,
            "auditor_fp_violation": 0.012882472769601729,
            "ave_precision_score": 0.7908631236118744,
            "fpr": 0.14144736842105263,
            "logloss": 1.1416575585867756,
            "mae": 0.28620995129320004,
            "precision": 0.7399193548387096,
            "recall": 0.7489795918367347
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8097983255331401,
            "auditor_fn_violation": 0.012169272114765893,
            "auditor_fp_violation": 0.022494149311055284,
            "ave_precision_score": 0.8038810462809562,
            "fpr": 0.132821075740944,
            "logloss": 1.0813190544320332,
            "mae": 0.24837427141556878,
            "precision": 0.7565392354124748,
            "recall": 0.8103448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8148329538006335,
            "auditor_fn_violation": 0.02255639097744361,
            "auditor_fp_violation": 0.027116072170948708,
            "ave_precision_score": 0.8151683064425775,
            "fpr": 0.16337719298245615,
            "logloss": 0.9844598709044029,
            "mae": 0.29108480923542657,
            "precision": 0.7209737827715356,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8380375916886416,
            "auditor_fn_violation": 0.021215791665089516,
            "auditor_fp_violation": 0.03239304842381335,
            "ave_precision_score": 0.8386177762740012,
            "fpr": 0.1437980241492865,
            "logloss": 0.8364439006278255,
            "mae": 0.25413388615287963,
            "precision": 0.7390438247011952,
            "recall": 0.7995689655172413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8188071355078391,
            "auditor_fn_violation": 0.032626208378088085,
            "auditor_fp_violation": 0.02003564895651451,
            "ave_precision_score": 0.8187620594547567,
            "fpr": 0.11293859649122807,
            "logloss": 2.346087909084758,
            "mae": 0.303018717729388,
            "precision": 0.7648401826484018,
            "recall": 0.6836734693877551
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8321785776169203,
            "auditor_fn_violation": 0.03550475036905258,
            "auditor_fp_violation": 0.03131008774191647,
            "ave_precision_score": 0.8322090395162869,
            "fpr": 0.10867178924259056,
            "logloss": 1.687620535654342,
            "mae": 0.27141049174688636,
            "precision": 0.7724137931034483,
            "recall": 0.7241379310344828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7779187035511061,
            "auditor_fn_violation": 0.01588345864661654,
            "auditor_fp_violation": 0.02397470275214102,
            "ave_precision_score": 0.7612003842911986,
            "fpr": 0.19188596491228072,
            "logloss": 1.9295629023115697,
            "mae": 0.30701518603054023,
            "precision": 0.6897163120567376,
            "recall": 0.7938775510204081
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8007332455183448,
            "auditor_fn_violation": 0.020761573110261555,
            "auditor_fp_violation": 0.040133393252246345,
            "ave_precision_score": 0.7855867765400217,
            "fpr": 0.16575192096597147,
            "logloss": 1.6514517893277183,
            "mae": 0.26027108676551153,
            "precision": 0.7198515769944341,
            "recall": 0.8362068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8119742824086473,
            "auditor_fn_violation": 0.01695085929108486,
            "auditor_fp_violation": 0.023842188409412154,
            "ave_precision_score": 0.812348853728817,
            "fpr": 0.14692982456140352,
            "logloss": 0.9829832510797314,
            "mae": 0.2882943884713568,
            "precision": 0.7314629258517034,
            "recall": 0.7448979591836735
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8375437810069668,
            "auditor_fn_violation": 0.018362731367576372,
            "auditor_fp_violation": 0.03290628829346517,
            "ave_precision_score": 0.8379408040182598,
            "fpr": 0.12733260153677278,
            "logloss": 0.8208307554434813,
            "mae": 0.24670291436865924,
            "precision": 0.7593360995850622,
            "recall": 0.7887931034482759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8210119792974628,
            "auditor_fn_violation": 0.03110902255639098,
            "auditor_fp_violation": 0.01771534879853663,
            "ave_precision_score": 0.8210931480081296,
            "fpr": 0.11403508771929824,
            "logloss": 2.1407563021220515,
            "mae": 0.2989378509332046,
            "precision": 0.7668161434977578,
            "recall": 0.6979591836734694
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8392325692972044,
            "auditor_fn_violation": 0.02733354782542867,
            "auditor_fp_violation": 0.027368700226169343,
            "ave_precision_score": 0.8394421272960877,
            "fpr": 0.11525795828759605,
            "logloss": 1.5210524585616854,
            "mae": 0.2575606286167502,
            "precision": 0.7692307692307693,
            "recall": 0.7543103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.79009285957197,
            "auditor_fn_violation": 0.026893125671321162,
            "auditor_fp_violation": 0.01641618857570467,
            "ave_precision_score": 0.7606269599660925,
            "fpr": 0.16228070175438597,
            "logloss": 2.25017009339177,
            "mae": 0.2919208695558741,
            "precision": 0.7313974591651543,
            "recall": 0.8224489795918367
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8041811273104201,
            "auditor_fn_violation": 0.02110460274802226,
            "auditor_fp_violation": 0.02801209183310127,
            "ave_precision_score": 0.773517293709906,
            "fpr": 0.15367727771679474,
            "logloss": 2.101113487575524,
            "mae": 0.2622526628797159,
            "precision": 0.7333333333333333,
            "recall": 0.8297413793103449
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7760099063263457,
            "auditor_fn_violation": 0.027367525957751517,
            "auditor_fp_violation": 0.03373139602560904,
            "ave_precision_score": 0.7769762174744599,
            "fpr": 0.17543859649122806,
            "logloss": 1.3330135379880217,
            "mae": 0.3008972204466696,
            "precision": 0.7037037037037037,
            "recall": 0.7755102040816326
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8164165556912765,
            "auditor_fn_violation": 0.026690071539422388,
            "auditor_fp_violation": 0.043816932986589466,
            "ave_precision_score": 0.8168269936768947,
            "fpr": 0.1602634467618002,
            "logloss": 1.0523281384648981,
            "mae": 0.2584386213451052,
            "precision": 0.7234848484848485,
            "recall": 0.8232758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7271895942426805,
            "auditor_fn_violation": 0.031686358754027935,
            "auditor_fp_violation": 0.020363037332668175,
            "ave_precision_score": 0.699189810266108,
            "fpr": 0.20065789473684212,
            "logloss": 4.338884831531185,
            "mae": 0.35616207764226104,
            "precision": 0.6585820895522388,
            "recall": 0.7204081632653061
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7520490884171983,
            "auditor_fn_violation": 0.038968166849615814,
            "auditor_fp_violation": 0.030634772123953567,
            "ave_precision_score": 0.7250115915249922,
            "fpr": 0.17892425905598244,
            "logloss": 3.4927206338411105,
            "mae": 0.3079897415733291,
            "precision": 0.6778656126482213,
            "recall": 0.7392241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8171866862412727,
            "auditor_fn_violation": 0.03489079842463302,
            "auditor_fp_violation": 0.03431341980543777,
            "ave_precision_score": 0.8175123420208685,
            "fpr": 0.17214912280701755,
            "logloss": 0.8711190192615367,
            "mae": 0.29816531472376934,
            "precision": 0.7119266055045872,
            "recall": 0.7918367346938775
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8374300942697657,
            "auditor_fn_violation": 0.029041598849312997,
            "auditor_fp_violation": 0.041756606428513546,
            "ave_precision_score": 0.8377897653260835,
            "fpr": 0.16465422612513722,
            "logloss": 0.7197230270197131,
            "mae": 0.26713598746487793,
            "precision": 0.7201492537313433,
            "recall": 0.8318965517241379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7560220043917985,
            "auditor_fn_violation": 0.022372896527031866,
            "auditor_fp_violation": 0.02922071173193649,
            "ave_precision_score": 0.7223668653352592,
            "fpr": 0.20065789473684212,
            "logloss": 2.8408679562799297,
            "mae": 0.34945998535803513,
            "precision": 0.6579439252336449,
            "recall": 0.7183673469387755
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7747703675543349,
            "auditor_fn_violation": 0.020250577236080092,
            "auditor_fp_violation": 0.034197982893641475,
            "ave_precision_score": 0.7394403786333722,
            "fpr": 0.17672886937431395,
            "logloss": 2.590055117816186,
            "mae": 0.30586070276930977,
            "precision": 0.690978886756238,
            "recall": 0.7758620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7672739172657261,
            "auditor_fn_violation": 0.023650644468313643,
            "auditor_fp_violation": 0.024819156896981796,
            "ave_precision_score": 0.7689458907496439,
            "fpr": 0.15570175438596492,
            "logloss": 1.1693381161680458,
            "mae": 0.31129114047743267,
            "precision": 0.7188118811881188,
            "recall": 0.7408163265306122
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8068327913674415,
            "auditor_fn_violation": 0.0276955032363072,
            "auditor_fp_violation": 0.03303398433758905,
            "ave_precision_score": 0.8072007478687853,
            "fpr": 0.13611416026344675,
            "logloss": 0.9214805217137872,
            "mae": 0.27195855706886735,
            "precision": 0.7432712215320911,
            "recall": 0.7737068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8161750802836649,
            "auditor_fn_violation": 0.03369584675975654,
            "auditor_fp_violation": 0.020178556581026023,
            "ave_precision_score": 0.8161273829789131,
            "fpr": 0.11403508771929824,
            "logloss": 2.4261352306055746,
            "mae": 0.3004057381309823,
            "precision": 0.7614678899082569,
            "recall": 0.6775510204081633
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8363270781974516,
            "auditor_fn_violation": 0.02990272152617435,
            "auditor_fp_violation": 0.02621206874958561,
            "ave_precision_score": 0.8362942014750216,
            "fpr": 0.1141602634467618,
            "logloss": 1.6783856236370756,
            "mae": 0.26238093756664205,
            "precision": 0.7678571428571429,
            "recall": 0.7413793103448276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7973173516840402,
            "auditor_fn_violation": 0.016364572144647337,
            "auditor_fp_violation": 0.013610002494387638,
            "ave_precision_score": 0.7641279078191989,
            "fpr": 0.15789473684210525,
            "logloss": 2.2678578204945303,
            "mae": 0.28242009324144657,
            "precision": 0.7338262476894639,
            "recall": 0.810204081632653
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8088491342761588,
            "auditor_fn_violation": 0.019065350694575874,
            "auditor_fp_violation": 0.0335423128209284,
            "ave_precision_score": 0.774358698568664,
            "fpr": 0.14050493962678376,
            "logloss": 2.1560150095326884,
            "mae": 0.2534989134508575,
            "precision": 0.7524177949709865,
            "recall": 0.8383620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 9540,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.714779256741749,
            "auditor_fn_violation": 0.030392946652345147,
            "auditor_fp_violation": 0.042674814999584296,
            "ave_precision_score": 0.7125646272999622,
            "fpr": 0.2993421052631579,
            "logloss": 2.443727610699618,
            "mae": 0.3562884584796507,
            "precision": 0.6160337552742616,
            "recall": 0.8938775510204081
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7492980905992278,
            "auditor_fn_violation": 0.020759207388621824,
            "auditor_fp_violation": 0.052259606057703877,
            "ave_precision_score": 0.7444912651931879,
            "fpr": 0.287596048298573,
            "logloss": 2.1925978253128338,
            "mae": 0.32712555788572223,
            "precision": 0.6208393632416788,
            "recall": 0.9245689655172413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8128153731612295,
            "auditor_fn_violation": 0.050845864661654146,
            "auditor_fp_violation": 0.05188845929990855,
            "ave_precision_score": 0.8131295675339767,
            "fpr": 0.19078947368421054,
            "logloss": 0.7248114626305147,
            "mae": 0.3358767978949852,
            "precision": 0.6847826086956522,
            "recall": 0.7714285714285715
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8278169652926924,
            "auditor_fn_violation": 0.045000757030924717,
            "auditor_fp_violation": 0.046309461540161634,
            "ave_precision_score": 0.828183953971552,
            "fpr": 0.16794731064763996,
            "logloss": 0.6214316487587147,
            "mae": 0.30724936491024024,
            "precision": 0.7102272727272727,
            "recall": 0.8081896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7948537791560055,
            "auditor_fn_violation": 0.018141335481561053,
            "auditor_fp_violation": 0.015179388043568642,
            "ave_precision_score": 0.7624570119035325,
            "fpr": 0.16447368421052633,
            "logloss": 2.240894665296631,
            "mae": 0.2892178033815215,
            "precision": 0.72875226039783,
            "recall": 0.8224489795918367
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8076130561752608,
            "auditor_fn_violation": 0.020856201975850718,
            "auditor_fp_violation": 0.037491067416144226,
            "ave_precision_score": 0.7738458090574785,
            "fpr": 0.14709110867178923,
            "logloss": 2.1288302686343608,
            "mae": 0.2592375802254426,
            "precision": 0.7442748091603053,
            "recall": 0.8405172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7835043968501765,
            "auditor_fn_violation": 0.010951485857500897,
            "auditor_fp_violation": 0.00811455475180843,
            "ave_precision_score": 0.7838301345001264,
            "fpr": 0.10855263157894737,
            "logloss": 1.833211107346316,
            "mae": 0.3335701868337578,
            "precision": 0.7543424317617866,
            "recall": 0.6204081632653061
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.796553276419187,
            "auditor_fn_violation": 0.01710889889852001,
            "auditor_fp_violation": 0.023898805796418128,
            "ave_precision_score": 0.7968761005227714,
            "fpr": 0.10208562019758508,
            "logloss": 1.416938069697059,
            "mae": 0.3017467311862254,
            "precision": 0.7657430730478589,
            "recall": 0.6551724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8140857087415928,
            "auditor_fn_violation": 0.03399122807017544,
            "auditor_fp_violation": 0.03417830714226324,
            "ave_precision_score": 0.8144363592219231,
            "fpr": 0.1962719298245614,
            "logloss": 0.8873544985807685,
            "mae": 0.30609842861632847,
            "precision": 0.6865148861646234,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8260259769216004,
            "auditor_fn_violation": 0.029905087247814075,
            "auditor_fp_violation": 0.044165641414773936,
            "ave_precision_score": 0.8263627749290547,
            "fpr": 0.19099890230515917,
            "logloss": 0.7767472195887981,
            "mae": 0.27938107837399717,
            "precision": 0.6920353982300885,
            "recall": 0.8426724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6447187049812018,
            "auditor_fn_violation": 0.009237379162191191,
            "auditor_fp_violation": 0.009021368587345141,
            "ave_precision_score": 0.6457566891424188,
            "fpr": 0.07456140350877193,
            "logloss": 3.795751391651561,
            "mae": 0.4512795140230975,
            "precision": 0.6991150442477876,
            "recall": 0.3224489795918367
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6617767688841909,
            "auditor_fn_violation": 0.018393485748892848,
            "auditor_fp_violation": 0.012163048202800964,
            "ave_precision_score": 0.6629914008421978,
            "fpr": 0.052689352360043906,
            "logloss": 3.2865217291196402,
            "mae": 0.4147667993891696,
            "precision": 0.7563451776649747,
            "recall": 0.32112068965517243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6760521114435395,
            "auditor_fn_violation": 0.033778643036161835,
            "auditor_fp_violation": 0.031348736176935246,
            "ave_precision_score": 0.6738318079383889,
            "fpr": 0.22039473684210525,
            "logloss": 2.04962589307973,
            "mae": 0.33378366300949075,
            "precision": 0.662751677852349,
            "recall": 0.8061224489795918
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7044321362489063,
            "auditor_fn_violation": 0.026784700405011547,
            "auditor_fp_violation": 0.036388461188997516,
            "ave_precision_score": 0.7002134650921124,
            "fpr": 0.21185510428100987,
            "logloss": 1.7107936177505092,
            "mae": 0.30165317978474526,
            "precision": 0.6683848797250859,
            "recall": 0.8383620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8160791740342757,
            "auditor_fn_violation": 0.03638784461152882,
            "auditor_fp_violation": 0.031556601812588354,
            "ave_precision_score": 0.8164669590249836,
            "fpr": 0.1611842105263158,
            "logloss": 0.9427532220906533,
            "mae": 0.29065272342904014,
            "precision": 0.7215909090909091,
            "recall": 0.7775510204081633
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.848309906655817,
            "auditor_fn_violation": 0.0280054127711117,
            "auditor_fp_violation": 0.036953270614930124,
            "ave_precision_score": 0.8487728656911947,
            "fpr": 0.145993413830955,
            "logloss": 0.7637622055409689,
            "mae": 0.24879065797546182,
            "precision": 0.7422480620155039,
            "recall": 0.8254310344827587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.813056321320588,
            "auditor_fn_violation": 0.01944817400644468,
            "auditor_fp_violation": 0.025419368919930165,
            "ave_precision_score": 0.8134175596814459,
            "fpr": 0.14802631578947367,
            "logloss": 0.9625393879085341,
            "mae": 0.287581113434323,
            "precision": 0.7321428571428571,
            "recall": 0.753061224489796
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8388895144319283,
            "auditor_fn_violation": 0.01890684734471403,
            "auditor_fp_violation": 0.033775603670770135,
            "ave_precision_score": 0.8392133324988325,
            "fpr": 0.12623490669593854,
            "logloss": 0.8054573961675068,
            "mae": 0.246813385911278,
            "precision": 0.7599164926931107,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7732719998515316,
            "auditor_fn_violation": 0.020175438596491235,
            "auditor_fp_violation": 0.01576401014384302,
            "ave_precision_score": 0.7510638889457396,
            "fpr": 0.20285087719298245,
            "logloss": 2.1426747417609837,
            "mae": 0.3186857586127152,
            "precision": 0.6843003412969283,
            "recall": 0.8183673469387756
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7965311200185002,
            "auditor_fn_violation": 0.026150687005564183,
            "auditor_fp_violation": 0.03310274374596346,
            "ave_precision_score": 0.7742169273071481,
            "fpr": 0.1756311745334797,
            "logloss": 1.9270450192994346,
            "mae": 0.2748233716345176,
            "precision": 0.7085610200364298,
            "recall": 0.8383620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6633174095377896,
            "auditor_fn_violation": 0.019061045470819913,
            "auditor_fp_violation": 0.040726074665336336,
            "ave_precision_score": 0.6647286168089974,
            "fpr": 0.1600877192982456,
            "logloss": 0.7121951663776884,
            "mae": 0.4206352502744841,
            "precision": 0.6719101123595506,
            "recall": 0.610204081632653
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.642705794808418,
            "auditor_fn_violation": 0.025873897573715887,
            "auditor_fp_violation": 0.04439893226461568,
            "ave_precision_score": 0.6440392573345313,
            "fpr": 0.1525795828759605,
            "logloss": 0.6949762426881677,
            "mae": 0.4137730231267348,
            "precision": 0.6674641148325359,
            "recall": 0.6012931034482759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8140650554275716,
            "auditor_fn_violation": 0.022605621195846762,
            "auditor_fp_violation": 0.031460463956098784,
            "ave_precision_score": 0.8145158752054263,
            "fpr": 0.16447368421052633,
            "logloss": 0.890301097130681,
            "mae": 0.29041480959833005,
            "precision": 0.7201492537313433,
            "recall": 0.7877551020408163
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.842110242086382,
            "auditor_fn_violation": 0.023198266399182405,
            "auditor_fp_violation": 0.03274912393146652,
            "ave_precision_score": 0.842463499988073,
            "fpr": 0.14050493962678376,
            "logloss": 0.762238084279789,
            "mae": 0.25134375211787435,
            "precision": 0.7490196078431373,
            "recall": 0.8232758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8153321809651632,
            "auditor_fn_violation": 0.026987110633727177,
            "auditor_fp_violation": 0.028103433940300987,
            "ave_precision_score": 0.8159596134389497,
            "fpr": 0.1513157894736842,
            "logloss": 0.8760509026739548,
            "mae": 0.29228268219236886,
            "precision": 0.7283464566929134,
            "recall": 0.7551020408163265
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8459583062102287,
            "auditor_fn_violation": 0.025748514326810256,
            "auditor_fp_violation": 0.034811906182698665,
            "ave_precision_score": 0.8462542104958898,
            "fpr": 0.13611416026344675,
            "logloss": 0.7377202346803957,
            "mae": 0.25454369304798063,
            "precision": 0.7459016393442623,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7077364342932928,
            "auditor_fn_violation": 0.036023093447905476,
            "auditor_fp_violation": 0.07139664920595327,
            "ave_precision_score": 0.6456038927795223,
            "fpr": 0.31359649122807015,
            "logloss": 5.521799107794535,
            "mae": 0.38035706068602537,
            "precision": 0.6016713091922006,
            "recall": 0.8816326530612245
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7442903450152373,
            "auditor_fn_violation": 0.02601820659373936,
            "auditor_fp_violation": 0.06749963778525947,
            "ave_precision_score": 0.6820099808360394,
            "fpr": 0.3106476399560922,
            "logloss": 5.094425978812008,
            "mae": 0.35478901243636635,
            "precision": 0.5985815602836879,
            "recall": 0.9094827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8168517644464142,
            "auditor_fn_violation": 0.019669709989258866,
            "auditor_fp_violation": 0.028753014051716968,
            "ave_precision_score": 0.8172894161456108,
            "fpr": 0.14802631578947367,
            "logloss": 0.8599073750800066,
            "mae": 0.2854869150015626,
            "precision": 0.7347740667976425,
            "recall": 0.763265306122449
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8442403465939767,
            "auditor_fn_violation": 0.02252640145349938,
            "auditor_fp_violation": 0.029699153031430423,
            "ave_precision_score": 0.844667905874113,
            "fpr": 0.13062568605927552,
            "logloss": 0.7185749488835496,
            "mae": 0.2441352601510355,
            "precision": 0.7571428571428571,
            "recall": 0.7995689655172413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7472970592508845,
            "auditor_fn_violation": 0.011638471177944868,
            "auditor_fp_violation": 0.0015148208198220712,
            "ave_precision_score": 0.7342453245232361,
            "fpr": 0.09978070175438597,
            "logloss": 3.4468453363605267,
            "mae": 0.349256572199879,
            "precision": 0.7458100558659218,
            "recall": 0.5448979591836735
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7532649938789953,
            "auditor_fn_violation": 0.013579242212044366,
            "auditor_fp_violation": 0.019476102422050157,
            "ave_precision_score": 0.742759829166663,
            "fpr": 0.09001097694840834,
            "logloss": 2.865605882113825,
            "mae": 0.3256964785223005,
            "precision": 0.7537537537537538,
            "recall": 0.540948275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7254004616655404,
            "auditor_fn_violation": 0.03352130325814536,
            "auditor_fp_violation": 0.031086305811923176,
            "ave_precision_score": 0.7256333382948223,
            "fpr": 0.17763157894736842,
            "logloss": 1.4515804553020435,
            "mae": 0.3116674551956287,
            "precision": 0.7,
            "recall": 0.7714285714285715
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7287003397428503,
            "auditor_fn_violation": 0.023713993716643327,
            "auditor_fp_violation": 0.0262710053853351,
            "ave_precision_score": 0.7279936673884908,
            "fpr": 0.17453347969264543,
            "logloss": 1.2999502548931279,
            "mae": 0.28020469659149005,
            "precision": 0.702803738317757,
            "recall": 0.8103448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7769099028760493,
            "auditor_fn_violation": 0.02662459720730397,
            "auditor_fp_violation": 0.03557880186247609,
            "ave_precision_score": 0.7777903664503837,
            "fpr": 0.17653508771929824,
            "logloss": 1.2773512554227908,
            "mae": 0.29929322331889074,
            "precision": 0.7067395264116576,
            "recall": 0.7918367346938775
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8178402751640492,
            "auditor_fn_violation": 0.024463927476437417,
            "auditor_fp_violation": 0.04098060739114527,
            "ave_precision_score": 0.8182444046438924,
            "fpr": 0.16355653128430298,
            "logloss": 0.9919973726326675,
            "mae": 0.2585272939663772,
            "precision": 0.7220149253731343,
            "recall": 0.834051724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.836019607975322,
            "auditor_fn_violation": 0.02647243107769424,
            "auditor_fp_violation": 0.022215639810426544,
            "ave_precision_score": 0.8363035335625437,
            "fpr": 0.14035087719298245,
            "logloss": 0.763709363918072,
            "mae": 0.2841552565456402,
            "precision": 0.7470355731225297,
            "recall": 0.7714285714285715
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8583612881893659,
            "auditor_fn_violation": 0.02517127824671638,
            "auditor_fp_violation": 0.030136266413239143,
            "ave_precision_score": 0.8586316294347733,
            "fpr": 0.132821075740944,
            "logloss": 0.6314399580102371,
            "mae": 0.24707987994858138,
            "precision": 0.7565392354124748,
            "recall": 0.8103448275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7882338162093174,
            "auditor_fn_violation": 0.02956050841389188,
            "auditor_fp_violation": 0.02964683628502536,
            "ave_precision_score": 0.7701940068751976,
            "fpr": 0.16885964912280702,
            "logloss": 1.6902100910684261,
            "mae": 0.29177581896981375,
            "precision": 0.7220216606498195,
            "recall": 0.8163265306122449
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8084046207494028,
            "auditor_fn_violation": 0.022923842688973847,
            "auditor_fp_violation": 0.036029929988188124,
            "ave_precision_score": 0.7946220615711646,
            "fpr": 0.15697036223929747,
            "logloss": 1.4163181797584707,
            "mae": 0.2619279751730984,
            "precision": 0.7270992366412213,
            "recall": 0.8211206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8063940698357057,
            "auditor_fn_violation": 0.03311179735051916,
            "auditor_fp_violation": 0.028064459133616035,
            "ave_precision_score": 0.8068305499073569,
            "fpr": 0.13486842105263158,
            "logloss": 0.8951557094677102,
            "mae": 0.29466263904183165,
            "precision": 0.7469135802469136,
            "recall": 0.7408163265306122
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8461720076362268,
            "auditor_fn_violation": 0.025190204019834215,
            "auditor_fp_violation": 0.03177421374844371,
            "ave_precision_score": 0.8464724998086373,
            "fpr": 0.12843029637760703,
            "logloss": 0.6928476662814027,
            "mae": 0.2539272715630904,
            "precision": 0.7547169811320755,
            "recall": 0.7758620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7784123231040961,
            "auditor_fn_violation": 0.016498836376655928,
            "auditor_fp_violation": 0.019528976469610045,
            "ave_precision_score": 0.7601528505212347,
            "fpr": 0.18969298245614036,
            "logloss": 1.9985607550095357,
            "mae": 0.304975503127204,
            "precision": 0.6932624113475178,
            "recall": 0.7979591836734694
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8016588837363946,
            "auditor_fn_violation": 0.02090351640864529,
            "auditor_fp_violation": 0.03624848667909248,
            "ave_precision_score": 0.7845699441550357,
            "fpr": 0.15697036223929747,
            "logloss": 1.7357364473503691,
            "mae": 0.259061132638659,
            "precision": 0.7306967984934086,
            "recall": 0.8362068965517241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8133272159023672,
            "auditor_fn_violation": 0.023621553884711786,
            "auditor_fp_violation": 0.02527126465452732,
            "ave_precision_score": 0.8136743335289142,
            "fpr": 0.14035087719298245,
            "logloss": 0.9777436484549714,
            "mae": 0.29040651418975894,
            "precision": 0.7398373983739838,
            "recall": 0.7428571428571429
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8393033107102505,
            "auditor_fn_violation": 0.022479087020704797,
            "auditor_fp_violation": 0.03142550532025922,
            "ave_precision_score": 0.8397756943771759,
            "fpr": 0.12952799121844127,
            "logloss": 0.8067597334063129,
            "mae": 0.25006529133836,
            "precision": 0.7546777546777547,
            "recall": 0.7823275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8175057557553133,
            "auditor_fn_violation": 0.02484335839598998,
            "auditor_fp_violation": 0.025848091793464704,
            "ave_precision_score": 0.817838544684052,
            "fpr": 0.15679824561403508,
            "logloss": 1.0034232757921298,
            "mae": 0.288050173283043,
            "precision": 0.7286527514231499,
            "recall": 0.7836734693877551
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8437101118542937,
            "auditor_fn_violation": 0.02485190582535297,
            "auditor_fp_violation": 0.03156056844385181,
            "ave_precision_score": 0.8442626812579944,
            "fpr": 0.1437980241492865,
            "logloss": 0.8256623357038496,
            "mae": 0.24547619685627017,
            "precision": 0.745136186770428,
            "recall": 0.8254310344827587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8248366612918203,
            "auditor_fn_violation": 0.02108843537414966,
            "auditor_fp_violation": 0.019887544691111664,
            "ave_precision_score": 0.825144918398474,
            "fpr": 0.12938596491228072,
            "logloss": 0.8086695836327621,
            "mae": 0.2881481617159482,
            "precision": 0.756198347107438,
            "recall": 0.746938775510204
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8606790083242952,
            "auditor_fn_violation": 0.022240149135092174,
            "auditor_fp_violation": 0.02810049678672551,
            "ave_precision_score": 0.8609779871795745,
            "fpr": 0.12294182217343579,
            "logloss": 0.6501329842960993,
            "mae": 0.24666590726531598,
            "precision": 0.7632135306553911,
            "recall": 0.7780172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8261224922526409,
            "auditor_fn_violation": 0.04066192266380236,
            "auditor_fp_violation": 0.016647439095368755,
            "ave_precision_score": 0.8264482172869775,
            "fpr": 0.0712719298245614,
            "logloss": 0.7150128941439293,
            "mae": 0.32321011989368725,
            "precision": 0.8233695652173914,
            "recall": 0.6183673469387755
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8466660513024274,
            "auditor_fn_violation": 0.03813543283243121,
            "auditor_fp_violation": 0.01793392711993851,
            "ave_precision_score": 0.8472862707194104,
            "fpr": 0.07135016465422613,
            "logloss": 0.565765956968379,
            "mae": 0.2819767127217695,
            "precision": 0.8284960422163589,
            "recall": 0.6767241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7881587588431639,
            "auditor_fn_violation": 0.05642006802721088,
            "auditor_fp_violation": 0.036657104847426625,
            "ave_precision_score": 0.7889661070262877,
            "fpr": 0.1118421052631579,
            "logloss": 0.8286802828410541,
            "mae": 0.34537652173653466,
            "precision": 0.7530266343825666,
            "recall": 0.6346938775510204
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8181320437735833,
            "auditor_fn_violation": 0.05323819978046103,
            "auditor_fp_violation": 0.035664031707910035,
            "ave_precision_score": 0.8185149728591663,
            "fpr": 0.10757409440175632,
            "logloss": 0.655370816429734,
            "mae": 0.3128070539362148,
            "precision": 0.7609756097560976,
            "recall": 0.6724137931034483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7818427005196458,
            "auditor_fn_violation": 0.02974400286430362,
            "auditor_fp_violation": 0.024754198885840198,
            "ave_precision_score": 0.7823849699606926,
            "fpr": 0.13706140350877194,
            "logloss": 1.2368351996773035,
            "mae": 0.29741670816221605,
            "precision": 0.7412008281573499,
            "recall": 0.7306122448979592
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8227859376660266,
            "auditor_fn_violation": 0.03561120784284038,
            "auditor_fp_violation": 0.03369211010345836,
            "ave_precision_score": 0.823159333064402,
            "fpr": 0.1207464324917673,
            "logloss": 0.9721891687171114,
            "mae": 0.25600998017823884,
            "precision": 0.7624190064794817,
            "recall": 0.7607758620689655
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7293236259987774,
            "auditor_fn_violation": 0.03622896527031866,
            "auditor_fp_violation": 0.030909620021618033,
            "ave_precision_score": 0.729613823326509,
            "fpr": 0.17105263157894737,
            "logloss": 1.3966886393657592,
            "mae": 0.3099259746513403,
            "precision": 0.7034220532319392,
            "recall": 0.7551020408163265
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7306206390156373,
            "auditor_fn_violation": 0.019029864869979936,
            "auditor_fp_violation": 0.024495539233381713,
            "ave_precision_score": 0.7299092609530963,
            "fpr": 0.16465422612513722,
            "logloss": 1.2540508711404252,
            "mae": 0.27793101179692276,
            "precision": 0.7120921305182342,
            "recall": 0.7995689655172413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.819576223568059,
            "auditor_fn_violation": 0.03319011815252417,
            "auditor_fp_violation": 0.031211025193315044,
            "ave_precision_score": 0.8199485992939596,
            "fpr": 0.16228070175438597,
            "logloss": 0.9328094939413527,
            "mae": 0.28918806788654716,
            "precision": 0.725417439703154,
            "recall": 0.7979591836734694
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8514053266267614,
            "auditor_fn_violation": 0.027253113289677885,
            "auditor_fp_violation": 0.03534724729075653,
            "ave_precision_score": 0.851852362604531,
            "fpr": 0.145993413830955,
            "logloss": 0.7594878822129624,
            "mae": 0.24789749175601988,
            "precision": 0.7427466150870407,
            "recall": 0.8275862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8157940325993507,
            "auditor_fn_violation": 0.028839957035445764,
            "auditor_fp_violation": 0.028950486405587436,
            "ave_precision_score": 0.8161221581227903,
            "fpr": 0.15350877192982457,
            "logloss": 0.9235473102205866,
            "mae": 0.28951043171875407,
            "precision": 0.7265625,
            "recall": 0.7591836734693878
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8409061060628307,
            "auditor_fn_violation": 0.024624796547938987,
            "auditor_fp_violation": 0.03413659056473576,
            "ave_precision_score": 0.841347008293097,
            "fpr": 0.13721185510428102,
            "logloss": 0.7546483770178877,
            "mae": 0.2513248687881214,
            "precision": 0.7459349593495935,
            "recall": 0.790948275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8151622650386835,
            "auditor_fn_violation": 0.024037773003938417,
            "auditor_fp_violation": 0.02527126465452732,
            "ave_precision_score": 0.8155263218270855,
            "fpr": 0.14035087719298245,
            "logloss": 0.950995091872205,
            "mae": 0.29045303869324046,
            "precision": 0.7419354838709677,
            "recall": 0.7510204081632653
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8417031503314304,
            "auditor_fn_violation": 0.022479087020704797,
            "auditor_fp_violation": 0.03253056724056216,
            "ave_precision_score": 0.8421167268160268,
            "fpr": 0.12733260153677278,
            "logloss": 0.7835614241307765,
            "mae": 0.25000338894448565,
            "precision": 0.7578288100208769,
            "recall": 0.7823275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8092017573115333,
            "auditor_fn_violation": 0.036134980307912644,
            "auditor_fp_violation": 0.02843601895734598,
            "ave_precision_score": 0.8095845504670127,
            "fpr": 0.12280701754385964,
            "logloss": 1.0178775322981715,
            "mae": 0.2982569901641996,
            "precision": 0.7533039647577092,
            "recall": 0.6979591836734694
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8402326756475278,
            "auditor_fn_violation": 0.036498353457738754,
            "auditor_fp_violation": 0.030661784748672084,
            "ave_precision_score": 0.8406690139206605,
            "fpr": 0.11525795828759605,
            "logloss": 0.8013205404525752,
            "mae": 0.25558854488870847,
            "precision": 0.7682119205298014,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8053948886652483,
            "auditor_fn_violation": 0.024248120300751887,
            "auditor_fp_violation": 0.026398935727945456,
            "ave_precision_score": 0.8057649452709117,
            "fpr": 0.14692982456140352,
            "logloss": 1.0761264136992748,
            "mae": 0.2950845000775606,
            "precision": 0.7298387096774194,
            "recall": 0.7387755102040816
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8285378916445971,
            "auditor_fn_violation": 0.023354404027404522,
            "auditor_fp_violation": 0.032869452896121726,
            "ave_precision_score": 0.8291123904558111,
            "fpr": 0.13391877058177826,
            "logloss": 0.8998853149576209,
            "mae": 0.2557348695684526,
            "precision": 0.7468879668049793,
            "recall": 0.7758620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8113419228594416,
            "auditor_fn_violation": 0.016899391335481562,
            "auditor_fp_violation": 0.022792466949363932,
            "ave_precision_score": 0.8115955202420434,
            "fpr": 0.11513157894736842,
            "logloss": 0.6993113693810704,
            "mae": 0.37138495949563366,
            "precision": 0.75177304964539,
            "recall": 0.6489795918367347
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8117150651547137,
            "auditor_fn_violation": 0.017861198379953834,
            "auditor_fp_violation": 0.024507817699162854,
            "ave_precision_score": 0.8120837410236339,
            "fpr": 0.09659714599341383,
            "logloss": 0.6469125235031443,
            "mae": 0.34758068841778256,
            "precision": 0.7788944723618091,
            "recall": 0.6681034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8063563322980517,
            "auditor_fn_violation": 0.023925886143931253,
            "auditor_fp_violation": 0.028482788725367927,
            "ave_precision_score": 0.8067341431012536,
            "fpr": 0.14912280701754385,
            "logloss": 1.015000708722923,
            "mae": 0.29224217798319013,
            "precision": 0.7322834645669292,
            "recall": 0.7591836734693878
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8325164386528006,
            "auditor_fn_violation": 0.022706196298118778,
            "auditor_fp_violation": 0.034470564833982864,
            "ave_precision_score": 0.832908618773623,
            "fpr": 0.13391877058177826,
            "logloss": 0.8346710921617858,
            "mae": 0.25278195974551115,
            "precision": 0.7479338842975206,
            "recall": 0.7801724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7964417505626584,
            "auditor_fn_violation": 0.03241138560687433,
            "auditor_fp_violation": 0.057469651617194674,
            "ave_precision_score": 0.7972868405633187,
            "fpr": 0.3223684210526316,
            "logloss": 1.0087352517336055,
            "mae": 0.37696137150674924,
            "precision": 0.5978112175102599,
            "recall": 0.8918367346938776
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8377957487312044,
            "auditor_fn_violation": 0.02106438548014686,
            "auditor_fp_violation": 0.05486755218961881,
            "ave_precision_score": 0.8380590202189121,
            "fpr": 0.33479692645444564,
            "logloss": 0.9045525519256796,
            "mae": 0.3612880012608599,
            "precision": 0.5827633378932968,
            "recall": 0.9181034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7761523844036654,
            "auditor_fn_violation": 0.02106829573934837,
            "auditor_fp_violation": 0.018136276710734187,
            "ave_precision_score": 0.7522659164076787,
            "fpr": 0.17653508771929824,
            "logloss": 2.2570328973146867,
            "mae": 0.30442266039222216,
            "precision": 0.7051282051282052,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7964436304271704,
            "auditor_fn_violation": 0.022786630833869562,
            "auditor_fp_violation": 0.03487575420476061,
            "ave_precision_score": 0.7708968580538756,
            "fpr": 0.1525795828759605,
            "logloss": 2.0763778259884105,
            "mae": 0.26589070925743474,
            "precision": 0.7290448343079922,
            "recall": 0.8060344827586207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8355478709958426,
            "auditor_fn_violation": 0.01701127819548872,
            "auditor_fp_violation": 0.01442067847343478,
            "ave_precision_score": 0.8358243209067847,
            "fpr": 0.14364035087719298,
            "logloss": 0.7418090513046162,
            "mae": 0.29209565135122856,
            "precision": 0.7321063394683026,
            "recall": 0.7306122448979592
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8513155382409368,
            "auditor_fn_violation": 0.02170313032287369,
            "auditor_fp_violation": 0.03002576022120884,
            "ave_precision_score": 0.8525612556163229,
            "fpr": 0.12294182217343579,
            "logloss": 0.6338925674725974,
            "mae": 0.2531799974291635,
            "precision": 0.7637130801687764,
            "recall": 0.7801724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8156720360510428,
            "auditor_fn_violation": 0.020027747941281773,
            "auditor_fp_violation": 0.028695851001912364,
            "ave_precision_score": 0.8160693619751187,
            "fpr": 0.1513157894736842,
            "logloss": 0.8851468934903991,
            "mae": 0.28579161550612764,
            "precision": 0.7294117647058823,
            "recall": 0.7591836734693878
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8430043760862278,
            "auditor_fn_violation": 0.022739316401074985,
            "auditor_fp_violation": 0.03258459248999919,
            "ave_precision_score": 0.8434506563840175,
            "fpr": 0.12952799121844127,
            "logloss": 0.7411545061809454,
            "mae": 0.24384393493752082,
            "precision": 0.7591836734693878,
            "recall": 0.8017241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6622368798221813,
            "auditor_fn_violation": 0.005106516290726817,
            "auditor_fp_violation": 0.011042861894071679,
            "ave_precision_score": 0.562046616959613,
            "fpr": 0.39035087719298245,
            "logloss": 8.052843492822664,
            "mae": 0.40858000724971116,
            "precision": 0.5705669481302774,
            "recall": 0.9653061224489796
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6345440040122903,
            "auditor_fn_violation": 0.004580037094515312,
            "auditor_fp_violation": 0.019272279890083177,
            "ave_precision_score": 0.5240725817739583,
            "fpr": 0.40175631174533477,
            "logloss": 8.923205459414442,
            "mae": 0.423128916781385,
            "precision": 0.5525672371638142,
            "recall": 0.9741379310344828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8085580825594552,
            "auditor_fn_violation": 0.03696741854636591,
            "auditor_fp_violation": 0.027323937806601813,
            "ave_precision_score": 0.8089447990882804,
            "fpr": 0.13157894736842105,
            "logloss": 1.0102437212474802,
            "mae": 0.2984472575393787,
            "precision": 0.7446808510638298,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8391416676509937,
            "auditor_fn_violation": 0.035374635678867485,
            "auditor_fp_violation": 0.03289400982768401,
            "ave_precision_score": 0.8395814848699781,
            "fpr": 0.12184412733260154,
            "logloss": 0.7982792877113372,
            "mae": 0.25552749399465974,
            "precision": 0.7597402597402597,
            "recall": 0.7564655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.826612137847316,
            "auditor_fn_violation": 0.024176512710347303,
            "auditor_fp_violation": 0.02386297497297747,
            "ave_precision_score": 0.8269442984106096,
            "fpr": 0.13925438596491227,
            "logloss": 0.8636713893316875,
            "mae": 0.2909940932322146,
            "precision": 0.7408163265306122,
            "recall": 0.7408163265306122
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8440078479518414,
            "auditor_fn_violation": 0.02114008857261819,
            "auditor_fp_violation": 0.030691253066546836,
            "ave_precision_score": 0.8445859165988585,
            "fpr": 0.12184412733260154,
            "logloss": 0.7236499655044275,
            "mae": 0.2511343000146167,
            "precision": 0.7648305084745762,
            "recall": 0.7780172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8225597643642796,
            "auditor_fn_violation": 0.029157715717866097,
            "auditor_fp_violation": 0.02490230315124304,
            "ave_precision_score": 0.8229966197005987,
            "fpr": 0.14692982456140352,
            "logloss": 0.8165908320794311,
            "mae": 0.29158666973710723,
            "precision": 0.7341269841269841,
            "recall": 0.7551020408163265
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8489194007181476,
            "auditor_fn_violation": 0.027586680040879673,
            "auditor_fp_violation": 0.03470876707013706,
            "ave_precision_score": 0.849377971978872,
            "fpr": 0.132821075740944,
            "logloss": 0.6783124262076683,
            "mae": 0.25307480714029523,
            "precision": 0.75,
            "recall": 0.7823275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6595767094301561,
            "auditor_fn_violation": 0.0054041353383458696,
            "auditor_fp_violation": 0.022886006485407832,
            "ave_precision_score": 0.6470707642723857,
            "fpr": 0.21271929824561403,
            "logloss": 2.391706083274815,
            "mae": 0.36105832422091383,
            "precision": 0.647912885662432,
            "recall": 0.7285714285714285
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6500454079770623,
            "auditor_fn_violation": 0.016278530602975134,
            "auditor_fp_violation": 0.031035050108418862,
            "ave_precision_score": 0.6401108190701309,
            "fpr": 0.18990120746432493,
            "logloss": 2.25162568010006,
            "mae": 0.32040334245427454,
            "precision": 0.6760299625468165,
            "recall": 0.7780172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 9540,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7744175078212044,
            "auditor_fn_violation": 0.025519155030433224,
            "auditor_fp_violation": 0.027420075663091383,
            "ave_precision_score": 0.7749055335541897,
            "fpr": 0.15021929824561403,
            "logloss": 1.3139308887535546,
            "mae": 0.3037974971389635,
            "precision": 0.7237903225806451,
            "recall": 0.7326530612244898
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8125134824396664,
            "auditor_fn_violation": 0.03248608955675839,
            "auditor_fp_violation": 0.03507220965725891,
            "ave_precision_score": 0.812839323665814,
            "fpr": 0.13391877058177826,
            "logloss": 1.023126105856789,
            "mae": 0.2615957752441,
            "precision": 0.7489711934156379,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7838639004578536,
            "auditor_fn_violation": 0.011622807017543861,
            "auditor_fp_violation": 0.003858505861810926,
            "ave_precision_score": 0.7479209731996431,
            "fpr": 0.12828947368421054,
            "logloss": 2.4994091903375577,
            "mae": 0.3109025392024267,
            "precision": 0.7515923566878981,
            "recall": 0.7224489795918367
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.794157105875178,
            "auditor_fn_violation": 0.015795923388470426,
            "auditor_fp_violation": 0.027029814570609777,
            "ave_precision_score": 0.7586552629022476,
            "fpr": 0.12623490669593854,
            "logloss": 2.3416599837939853,
            "mae": 0.29596204021361405,
            "precision": 0.7466960352422908,
            "recall": 0.7306034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8149762558127087,
            "auditor_fn_violation": 0.02331945936269245,
            "auditor_fp_violation": 0.02527126465452732,
            "ave_precision_score": 0.815341127700305,
            "fpr": 0.14035087719298245,
            "logloss": 0.9589257997037344,
            "mae": 0.29027808370648633,
            "precision": 0.7424547283702213,
            "recall": 0.753061224489796
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8412950423135915,
            "auditor_fn_violation": 0.023401718460199103,
            "auditor_fp_violation": 0.03142550532025922,
            "ave_precision_score": 0.8417124761004923,
            "fpr": 0.12952799121844127,
            "logloss": 0.7906977582905025,
            "mae": 0.2499289500743774,
            "precision": 0.7551867219917012,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8046661768270509,
            "auditor_fn_violation": 0.03496464375223774,
            "auditor_fp_violation": 0.030847260330922093,
            "ave_precision_score": 0.8051263369860181,
            "fpr": 0.1425438596491228,
            "logloss": 0.9222635631164513,
            "mae": 0.2945401094342134,
            "precision": 0.7373737373737373,
            "recall": 0.7448979591836735
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8444183417361564,
            "auditor_fn_violation": 0.0269928839093077,
            "auditor_fp_violation": 0.031892087019942686,
            "ave_precision_score": 0.8447253845848772,
            "fpr": 0.13172338090010977,
            "logloss": 0.7113259180357506,
            "mae": 0.25415954091800386,
            "precision": 0.7505197505197505,
            "recall": 0.7780172413793104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 9540,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7799941730145203,
            "auditor_fn_violation": 0.01526136770497673,
            "auditor_fp_violation": 0.018235012887669412,
            "ave_precision_score": 0.7608363171983404,
            "fpr": 0.18421052631578946,
            "logloss": 2.0352520215098124,
            "mae": 0.3020526473589877,
            "precision": 0.6989247311827957,
            "recall": 0.7959183673469388
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7999672413875915,
            "auditor_fn_violation": 0.022919111245694387,
            "auditor_fp_violation": 0.03548476610750534,
            "ave_precision_score": 0.7805490412765755,
            "fpr": 0.15367727771679474,
            "logloss": 1.8224831591248412,
            "mae": 0.2591376013737605,
            "precision": 0.7323135755258127,
            "recall": 0.8254310344827587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7648546250468844,
            "auditor_fn_violation": 0.017105263157894738,
            "auditor_fp_violation": 0.009218840941215597,
            "ave_precision_score": 0.7662315904879938,
            "fpr": 0.15350877192982457,
            "logloss": 0.7024766537696986,
            "mae": 0.3307588660825052,
            "precision": 0.7137014314928425,
            "recall": 0.7122448979591837
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8196228829637622,
            "auditor_fn_violation": 0.018812218479124877,
            "auditor_fp_violation": 0.022413111436899738,
            "ave_precision_score": 0.8198971438318937,
            "fpr": 0.14928649835345773,
            "logloss": 0.6249310782432356,
            "mae": 0.30396191007023193,
            "precision": 0.7213114754098361,
            "recall": 0.7586206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7829036016838664,
            "auditor_fn_violation": 0.0274749373433584,
            "auditor_fp_violation": 0.03259333167040825,
            "ave_precision_score": 0.7839890421949252,
            "fpr": 0.1699561403508772,
            "logloss": 1.223555343718445,
            "mae": 0.2987990451358694,
            "precision": 0.7113594040968343,
            "recall": 0.7795918367346939
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.82361698339952,
            "auditor_fn_violation": 0.029313656837881834,
            "auditor_fp_violation": 0.0421200490156354,
            "ave_precision_score": 0.823995355839478,
            "fpr": 0.14928649835345773,
            "logloss": 0.975113737836321,
            "mae": 0.25627803010109335,
            "precision": 0.7369439071566731,
            "recall": 0.8211206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7670690510535948,
            "auditor_fn_violation": 0.025843626924453994,
            "auditor_fp_violation": 0.02123867132285692,
            "ave_precision_score": 0.7684857681848736,
            "fpr": 0.15350877192982457,
            "logloss": 1.0837085169706016,
            "mae": 0.31555552997462283,
            "precision": 0.7216699801192843,
            "recall": 0.7408163265306122
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8072533445799017,
            "auditor_fn_violation": 0.02933494833263939,
            "auditor_fp_violation": 0.03237585857171975,
            "ave_precision_score": 0.8076141074794001,
            "fpr": 0.13391877058177826,
            "logloss": 0.8479305395270629,
            "mae": 0.27990122621173835,
            "precision": 0.7453027139874739,
            "recall": 0.7693965517241379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7212512976930946,
            "auditor_fn_violation": 0.03477219835302542,
            "auditor_fp_violation": 0.021880456472935902,
            "ave_precision_score": 0.7218430977573584,
            "fpr": 0.2225877192982456,
            "logloss": 1.111354948961222,
            "mae": 0.3722132060627859,
            "precision": 0.6400709219858156,
            "recall": 0.736734693877551
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.736038919015573,
            "auditor_fn_violation": 0.03070943260532193,
            "auditor_fp_violation": 0.02544589248484223,
            "ave_precision_score": 0.7369546979214572,
            "fpr": 0.18441273326015367,
            "logloss": 0.9315513327202412,
            "mae": 0.3387053654761501,
            "precision": 0.6712328767123288,
            "recall": 0.7392241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8178883920351954,
            "auditor_fn_violation": 0.025845864661654137,
            "auditor_fp_violation": 0.02766951442587512,
            "ave_precision_score": 0.818212546932892,
            "fpr": 0.15679824561403508,
            "logloss": 0.9344535138096021,
            "mae": 0.2913868793462546,
            "precision": 0.7239382239382239,
            "recall": 0.7653061224489796
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8359639870160007,
            "auditor_fn_violation": 0.022020137022597374,
            "auditor_fp_violation": 0.034784893557980145,
            "ave_precision_score": 0.836334227711921,
            "fpr": 0.14050493962678376,
            "logloss": 0.778501139073583,
            "mae": 0.25565315685922396,
            "precision": 0.7414141414141414,
            "recall": 0.790948275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.817373166480873,
            "auditor_fn_violation": 0.037564894378804156,
            "auditor_fp_violation": 0.02154787145589091,
            "ave_precision_score": 0.8173347166463023,
            "fpr": 0.11951754385964912,
            "logloss": 2.348742233964282,
            "mae": 0.2989817850258035,
            "precision": 0.7577777777777778,
            "recall": 0.6959183673469388
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8324803323490043,
            "auditor_fn_violation": 0.03262803285514214,
            "auditor_fp_violation": 0.028137332184068938,
            "ave_precision_score": 0.8326142711306099,
            "fpr": 0.11306256860592755,
            "logloss": 1.6542503437651328,
            "mae": 0.2660246517581438,
            "precision": 0.7695749440715883,
            "recall": 0.7413793103448276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8092282301918672,
            "auditor_fn_violation": 0.028725832438238456,
            "auditor_fp_violation": 0.027495426956015635,
            "ave_precision_score": 0.8095820656852708,
            "fpr": 0.14692982456140352,
            "logloss": 1.0444276535012131,
            "mae": 0.29429847845420076,
            "precision": 0.7303822937625755,
            "recall": 0.7408163265306122
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8375061249365487,
            "auditor_fn_violation": 0.02206745145539196,
            "auditor_fp_violation": 0.03464246335491888,
            "ave_precision_score": 0.8377831929503196,
            "fpr": 0.132821075740944,
            "logloss": 0.8504809119095262,
            "mae": 0.2508210258579538,
            "precision": 0.7505154639175258,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7087678548562161,
            "auditor_fn_violation": 0.03282312925170068,
            "auditor_fp_violation": 0.06730169618358693,
            "ave_precision_score": 0.6158572767286546,
            "fpr": 0.3223684210526316,
            "logloss": 7.139059513666736,
            "mae": 0.38774974662297174,
            "precision": 0.5978112175102599,
            "recall": 0.8918367346938776
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7423495030849243,
            "auditor_fn_violation": 0.02477383701124191,
            "auditor_fp_violation": 0.06903444600790244,
            "ave_precision_score": 0.6426710771417967,
            "fpr": 0.3205268935236004,
            "logloss": 6.87043732656005,
            "mae": 0.36622978540597956,
            "precision": 0.5933147632311978,
            "recall": 0.9181034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7122649228797985,
            "auditor_fn_violation": 0.034103114930182594,
            "auditor_fp_violation": 0.06930240292674815,
            "ave_precision_score": 0.6344695634137547,
            "fpr": 0.3168859649122807,
            "logloss": 6.28867949684344,
            "mae": 0.3825155502627523,
            "precision": 0.600828729281768,
            "recall": 0.8877551020408163
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7380964036664056,
            "auditor_fn_violation": 0.027021272568984445,
            "auditor_fp_violation": 0.06860224401240617,
            "ave_precision_score": 0.6540980218355334,
            "fpr": 0.3150384193194292,
            "logloss": 6.095698359764885,
            "mae": 0.3579725834923839,
            "precision": 0.594632768361582,
            "recall": 0.9073275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.774788461575415,
            "auditor_fn_violation": 0.032440476190476186,
            "auditor_fp_violation": 0.027916354868213193,
            "ave_precision_score": 0.7758901684467561,
            "fpr": 0.1513157894736842,
            "logloss": 1.264936542770272,
            "mae": 0.3052723065640689,
            "precision": 0.7212121212121212,
            "recall": 0.7285714285714285
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8128985081237375,
            "auditor_fn_violation": 0.034828153980090086,
            "auditor_fp_violation": 0.037665421630236465,
            "ave_precision_score": 0.8132600752991712,
            "fpr": 0.13611416026344675,
            "logloss": 1.0076867046371083,
            "mae": 0.26408001156220196,
            "precision": 0.7448559670781894,
            "recall": 0.7801724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8560949672365874,
            "auditor_fn_violation": 0.02532447189402077,
            "auditor_fp_violation": 0.02223642637399186,
            "ave_precision_score": 0.8562931875626076,
            "fpr": 0.15789473684210525,
            "logloss": 0.5832697864268068,
            "mae": 0.2898175705629974,
            "precision": 0.7396021699819169,
            "recall": 0.8346938775510204
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8714019326238958,
            "auditor_fn_violation": 0.016463056890873996,
            "auditor_fp_violation": 0.025821613537745237,
            "ave_precision_score": 0.8716445298761816,
            "fpr": 0.141602634467618,
            "logloss": 0.49328343704936045,
            "mae": 0.2619966483150787,
            "precision": 0.7547528517110266,
            "recall": 0.8556034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8167713400671802,
            "auditor_fn_violation": 0.018530701754385964,
            "auditor_fp_violation": 0.02488671322856906,
            "ave_precision_score": 0.8171408313896648,
            "fpr": 0.14692982456140352,
            "logloss": 0.9024822884164297,
            "mae": 0.28655660192513194,
            "precision": 0.7346534653465346,
            "recall": 0.7571428571428571
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8421846271681888,
            "auditor_fn_violation": 0.021002876717513917,
            "auditor_fp_violation": 0.03400398313429941,
            "ave_precision_score": 0.8425910269395991,
            "fpr": 0.12733260153677278,
            "logloss": 0.7546955876207887,
            "mae": 0.2457022621925755,
            "precision": 0.7598343685300207,
            "recall": 0.790948275862069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7965075504901015,
            "auditor_fn_violation": 0.015585839598997493,
            "auditor_fp_violation": 0.016192733017377576,
            "ave_precision_score": 0.7639679189095173,
            "fpr": 0.1600877192982456,
            "logloss": 2.2575495915410855,
            "mae": 0.28539554036229164,
            "precision": 0.7321100917431193,
            "recall": 0.8142857142857143
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8079697086648336,
            "auditor_fn_violation": 0.019065350694575874,
            "auditor_fp_violation": 0.03513360198616463,
            "ave_precision_score": 0.773479465245154,
            "fpr": 0.141602634467618,
            "logloss": 2.160860001337981,
            "mae": 0.25582564130719454,
            "precision": 0.750965250965251,
            "recall": 0.8383620689655172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8079709581549767,
            "auditor_fn_violation": 0.02377372001432152,
            "auditor_fp_violation": 0.02880498046063025,
            "ave_precision_score": 0.8083290512905599,
            "fpr": 0.16228070175438597,
            "logloss": 1.0599126048853689,
            "mae": 0.2933119213273137,
            "precision": 0.7175572519083969,
            "recall": 0.7673469387755102
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8334706222157852,
            "auditor_fn_violation": 0.02094846511980015,
            "auditor_fp_violation": 0.03303398433758905,
            "ave_precision_score": 0.833536393629617,
            "fpr": 0.14270032930845225,
            "logloss": 0.8949529652433053,
            "mae": 0.2549980897798463,
            "precision": 0.7394789579158316,
            "recall": 0.7952586206896551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8248198754691525,
            "auditor_fn_violation": 0.031820622986036516,
            "auditor_fp_violation": 0.018034942213353295,
            "ave_precision_score": 0.8248869899535606,
            "fpr": 0.11074561403508772,
            "logloss": 2.13080540695162,
            "mae": 0.30175621988516593,
            "precision": 0.766743648960739,
            "recall": 0.6775510204081633
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8416054503141221,
            "auditor_fn_violation": 0.025857337522237796,
            "auditor_fp_violation": 0.02848849630540965,
            "ave_precision_score": 0.8419459160076801,
            "fpr": 0.10976948408342481,
            "logloss": 1.5147536397313965,
            "mae": 0.2586085938022719,
            "precision": 0.7752808988764045,
            "recall": 0.7435344827586207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7777894926561245,
            "auditor_fn_violation": 0.02756892230576441,
            "auditor_fp_violation": 0.033824935561652954,
            "ave_precision_score": 0.7791188959458855,
            "fpr": 0.1699561403508772,
            "logloss": 1.324278271077459,
            "mae": 0.29996097576710257,
            "precision": 0.7091932457786116,
            "recall": 0.7714285714285715
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8172116839253701,
            "auditor_fn_violation": 0.02817101328589273,
            "auditor_fp_violation": 0.04434245132202241,
            "ave_precision_score": 0.8176045805755208,
            "fpr": 0.15806805708013172,
            "logloss": 1.0472635844714897,
            "mae": 0.2567157075809349,
            "precision": 0.7251908396946565,
            "recall": 0.8189655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6660505471130201,
            "auditor_fn_violation": 0.024279448621553887,
            "auditor_fp_violation": 8.834289515257453e-05,
            "ave_precision_score": 0.6668792889970659,
            "fpr": 0.17434210526315788,
            "logloss": 1.1196753445903296,
            "mae": 0.4072559883113706,
            "precision": 0.647450110864745,
            "recall": 0.5959183673469388
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6738118419045103,
            "auditor_fn_violation": 0.030593512244975214,
            "auditor_fp_violation": 0.01646542261251372,
            "ave_precision_score": 0.6748947142409911,
            "fpr": 0.16355653128430298,
            "logloss": 0.9629369314789493,
            "mae": 0.3760123820719682,
            "precision": 0.6628959276018099,
            "recall": 0.6314655172413793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7078579401088773,
            "auditor_fn_violation": 0.03142901897601146,
            "auditor_fp_violation": 0.06724453313378234,
            "ave_precision_score": 0.6240388144225812,
            "fpr": 0.31798245614035087,
            "logloss": 6.618047480854607,
            "mae": 0.3853030220579938,
            "precision": 0.598893499308437,
            "recall": 0.8836734693877552
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7382512177529552,
            "auditor_fn_violation": 0.02842414550134373,
            "auditor_fp_violation": 0.0681528521648163,
            "ave_precision_score": 0.6483826589406669,
            "fpr": 0.31394072447859495,
            "logloss": 6.364640497497426,
            "mae": 0.36210454849376394,
            "precision": 0.5954738330975955,
            "recall": 0.9073275862068966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8094382660568825,
            "auditor_fn_violation": 0.019087898317221623,
            "auditor_fp_violation": 0.01980439843685042,
            "ave_precision_score": 0.8097828608374296,
            "fpr": 0.1425438596491228,
            "logloss": 1.0402740260569923,
            "mae": 0.2889869412627387,
            "precision": 0.7389558232931727,
            "recall": 0.7510204081632653
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8330780336041881,
            "auditor_fn_violation": 0.021608501457284532,
            "auditor_fp_violation": 0.03028360800261285,
            "ave_precision_score": 0.8336207150320771,
            "fpr": 0.12952799121844127,
            "logloss": 0.8701055192329885,
            "mae": 0.24912450286325716,
            "precision": 0.7541666666666667,
            "recall": 0.7801724137931034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 9540,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5928986495153328,
            "auditor_fn_violation": 0.015901360544217702,
            "auditor_fp_violation": 0.004897834040076497,
            "ave_precision_score": 0.5923211339082542,
            "fpr": 0.04276315789473684,
            "logloss": 8.770709993867777,
            "mae": 0.49740135997321777,
            "precision": 0.6608695652173913,
            "recall": 0.15510204081632653
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5901573532435211,
            "auditor_fn_violation": 0.013184166698209624,
            "auditor_fp_violation": 0.011831529626710083,
            "ave_precision_score": 0.589262681400657,
            "fpr": 0.03732162458836443,
            "logloss": 8.458466526876325,
            "mae": 0.464431713723292,
            "precision": 0.6991150442477876,
            "recall": 0.17025862068965517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7750841009921932,
            "auditor_fn_violation": 0.031189581095596136,
            "auditor_fp_violation": 0.028155400349214283,
            "ave_precision_score": 0.7757392145081494,
            "fpr": 0.24780701754385964,
            "logloss": 1.1631831891283781,
            "mae": 0.3734578132250799,
            "precision": 0.6282894736842105,
            "recall": 0.7795918367346939
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7947128548065342,
            "auditor_fn_violation": 0.029554960445134185,
            "auditor_fp_violation": 0.03123150556091716,
            "ave_precision_score": 0.7950121416303717,
            "fpr": 0.2349066959385291,
            "logloss": 0.9657413959450833,
            "mae": 0.34481811342245466,
            "precision": 0.6366723259762309,
            "recall": 0.8081896551724138
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8133427226144476,
            "auditor_fn_violation": 0.024113856068743295,
            "auditor_fp_violation": 0.024694437515589925,
            "ave_precision_score": 0.8137015202816917,
            "fpr": 0.1425438596491228,
            "logloss": 0.9833127364219897,
            "mae": 0.2907282065370462,
            "precision": 0.7379032258064516,
            "recall": 0.746938775510204
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8402332472035211,
            "auditor_fn_violation": 0.022692001968280407,
            "auditor_fp_violation": 0.03253056724056216,
            "ave_precision_score": 0.8406559942184717,
            "fpr": 0.12733260153677278,
            "logloss": 0.8069900103322554,
            "mae": 0.2499794356896351,
            "precision": 0.7583333333333333,
            "recall": 0.7844827586206896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 9540,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7808865727128464,
            "auditor_fn_violation": 0.012240422484783391,
            "auditor_fp_violation": 0.00754032593331671,
            "ave_precision_score": 0.7790272914742321,
            "fpr": 0.12280701754385964,
            "logloss": 0.745342761557764,
            "mae": 0.3275821092109637,
            "precision": 0.7622080679405521,
            "recall": 0.7326530612244898
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7964833770684432,
            "auditor_fn_violation": 0.011431166963170454,
            "auditor_fp_violation": 0.014085855944128069,
            "ave_precision_score": 0.7928243251079548,
            "fpr": 0.11745334796926454,
            "logloss": 0.766751647882759,
            "mae": 0.31038591248656977,
            "precision": 0.7627494456762749,
            "recall": 0.7413793103448276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7251628658944146,
            "auditor_fn_violation": 0.03300662370211242,
            "auditor_fp_violation": 0.02840483911199801,
            "ave_precision_score": 0.725392184462216,
            "fpr": 0.17982456140350878,
            "logloss": 1.4581432197303874,
            "mae": 0.3115928893241335,
            "precision": 0.6968576709796673,
            "recall": 0.7693877551020408
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7266268569232726,
            "auditor_fn_violation": 0.021996479806200085,
            "auditor_fp_violation": 0.025099639749813978,
            "ave_precision_score": 0.7259111765776048,
            "fpr": 0.17453347969264543,
            "logloss": 1.3149068891776121,
            "mae": 0.28122381289047754,
            "precision": 0.701688555347092,
            "recall": 0.8060344827586207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 9540,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7392881300797727,
            "auditor_fn_violation": 0.029817848191908344,
            "auditor_fp_violation": 0.029329841190654363,
            "ave_precision_score": 0.7382597266435464,
            "fpr": 0.16666666666666666,
            "logloss": 1.4632340989671042,
            "mae": 0.31831652789378123,
            "precision": 0.7037037037037037,
            "recall": 0.736734693877551
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.730441429826608,
            "auditor_fn_violation": 0.02143107233430486,
            "auditor_fp_violation": 0.026403612815771447,
            "ave_precision_score": 0.7289565787597013,
            "fpr": 0.17014270032930845,
            "logloss": 1.379643416540284,
            "mae": 0.2873226471867411,
            "precision": 0.7030651340996169,
            "recall": 0.790948275862069
        }
    }
]