[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6085373230132046,
            "auditor_fn_violation": 0.0446349922924466,
            "auditor_fp_violation": 0.038192760126121765,
            "ave_precision_score": 0.6110346124857091,
            "fpr": 0.2576754385964912,
            "logloss": 1.0128937231618673,
            "mae": 0.45857908058734576,
            "precision": 0.5574387947269304,
            "recall": 0.6192468619246861
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6420225562109296,
            "auditor_fn_violation": 0.037736719276074866,
            "auditor_fp_violation": 0.041258185396873474,
            "ave_precision_score": 0.642360203591128,
            "fpr": 0.22063666300768386,
            "logloss": 0.9675461956693703,
            "mae": 0.44041260073182076,
            "precision": 0.5906313645621182,
            "recall": 0.6092436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6463606691667168,
            "auditor_fn_violation": 0.022806099977978413,
            "auditor_fp_violation": 0.01576016654539575,
            "ave_precision_score": 0.544874465094894,
            "fpr": 0.02631578947368421,
            "logloss": 0.7141215849490864,
            "mae": 0.48155694860115383,
            "precision": 0.7391304347826086,
            "recall": 0.14225941422594143
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.61321447285824,
            "auditor_fn_violation": 0.015123283122249998,
            "auditor_fp_violation": 0.01609952433223564,
            "ave_precision_score": 0.5327909605460591,
            "fpr": 0.027442371020856202,
            "logloss": 0.7257046365416758,
            "mae": 0.4886991267800985,
            "precision": 0.6835443037974683,
            "recall": 0.1134453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7829098821178122,
            "auditor_fn_violation": 0.012102693973427288,
            "auditor_fp_violation": 0.0027235427277872105,
            "ave_precision_score": 0.6634591687421203,
            "fpr": 0.007675438596491228,
            "logloss": 1.8650554969422635,
            "mae": 0.4189377516704874,
            "precision": 0.943089430894309,
            "recall": 0.24267782426778242
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.773437246925296,
            "auditor_fn_violation": 0.006706085288121846,
            "auditor_fp_violation": 0.003600943765219476,
            "ave_precision_score": 0.6526521929790579,
            "fpr": 0.007683863885839737,
            "logloss": 1.8518919300337933,
            "mae": 0.4214401038437822,
            "precision": 0.9345794392523364,
            "recall": 0.21008403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8265479644420484,
            "auditor_fn_violation": 0.0195349776113925,
            "auditor_fp_violation": 0.02351645242137602,
            "ave_precision_score": 0.8269050453240459,
            "fpr": 0.1524122807017544,
            "logloss": 0.8529712329074408,
            "mae": 0.31728261965512905,
            "precision": 0.7269155206286837,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.828418644909062,
            "auditor_fn_violation": 0.013949487588668836,
            "auditor_fp_violation": 0.022493912209647103,
            "ave_precision_score": 0.8289819823880995,
            "fpr": 0.1437980241492865,
            "logloss": 0.9780797649659323,
            "mae": 0.31574432308748784,
            "precision": 0.7348178137651822,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.623393939844147,
            "auditor_fn_violation": 0.04573148352051677,
            "auditor_fp_violation": 0.03482243916242219,
            "ave_precision_score": 0.6262920874632616,
            "fpr": 0.2532894736842105,
            "logloss": 0.9826322253350304,
            "mae": 0.4504152117834692,
            "precision": 0.5616698292220114,
            "recall": 0.6192468619246861
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6530924497409248,
            "auditor_fn_violation": 0.03784741119279765,
            "auditor_fp_violation": 0.03998385000693946,
            "ave_precision_score": 0.6540046339545377,
            "fpr": 0.21624588364434688,
            "logloss": 0.9452447449445655,
            "mae": 0.4344288534532245,
            "precision": 0.5938144329896907,
            "recall": 0.6050420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7207625872222092,
            "auditor_fn_violation": 0.08832489172722603,
            "auditor_fp_violation": 0.0937626323874202,
            "ave_precision_score": 0.5563137351951191,
            "fpr": 0.29276315789473684,
            "logloss": 0.6867005186722325,
            "mae": 0.49567754697381405,
            "precision": 0.5679611650485437,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7252075458166489,
            "auditor_fn_violation": 0.09108561097325868,
            "auditor_fp_violation": 0.09599152125364324,
            "ave_precision_score": 0.5630570027023611,
            "fpr": 0.27991218441273324,
            "logloss": 0.6853019654870803,
            "mae": 0.4949962154897717,
            "precision": 0.5778145695364238,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7596070927639837,
            "auditor_fn_violation": 0.03904472216105116,
            "auditor_fp_violation": 0.009408602150537633,
            "ave_precision_score": 0.7606005563446314,
            "fpr": 0.03837719298245614,
            "logloss": 0.6806836175832899,
            "mae": 0.4694353753798886,
            "precision": 0.8653846153846154,
            "recall": 0.4707112970711297
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7405657955553413,
            "auditor_fn_violation": 0.03685118394229262,
            "auditor_fp_violation": 0.005904841212763542,
            "ave_precision_score": 0.7411570978805615,
            "fpr": 0.042810098792535674,
            "logloss": 0.6981738593940793,
            "mae": 0.4793685118204676,
            "precision": 0.8395061728395061,
            "recall": 0.42857142857142855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6738302440432711,
            "auditor_fn_violation": 0.005626972766644646,
            "auditor_fp_violation": 0.018145161290322585,
            "ave_precision_score": 0.6446404037166125,
            "fpr": 0.23355263157894737,
            "logloss": 3.010475257997682,
            "mae": 0.3431541720683319,
            "precision": 0.6473509933774835,
            "recall": 0.8179916317991632
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.667038504008741,
            "auditor_fn_violation": 0.012711121770332724,
            "auditor_fp_violation": 0.01997299923035189,
            "ave_precision_score": 0.6382850828974953,
            "fpr": 0.23819978046103182,
            "logloss": 3.1280004049283443,
            "mae": 0.34496016168377913,
            "precision": 0.642504118616145,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8184714297659175,
            "auditor_fn_violation": 0.027896296704103356,
            "auditor_fp_violation": 0.024885803217721728,
            "ave_precision_score": 0.8187410179660873,
            "fpr": 0.11951754385964912,
            "logloss": 0.8468969367638248,
            "mae": 0.3455639612053918,
            "precision": 0.7476851851851852,
            "recall": 0.6757322175732218
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8125478712023937,
            "auditor_fn_violation": 0.03494866662361982,
            "auditor_fp_violation": 0.022471201281905707,
            "ave_precision_score": 0.8128480143672122,
            "fpr": 0.10976948408342481,
            "logloss": 0.9564604713519743,
            "mae": 0.3462656152813338,
            "precision": 0.7590361445783133,
            "recall": 0.6617647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7665101009576338,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.688838134757928,
            "fpr": 0.01644736842105263,
            "logloss": 1.001794197013172,
            "mae": 0.40251805210403335,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7658655346558608,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.693162862484201,
            "fpr": 0.015367727771679473,
            "logloss": 1.026446845380455,
            "mae": 0.39932053931915296,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.672846346255054,
            "auditor_fn_violation": 0.07573588783674669,
            "auditor_fp_violation": 0.09171365914786968,
            "ave_precision_score": 0.6740585675909025,
            "fpr": 0.3059210526315789,
            "logloss": 0.7105708111272062,
            "mae": 0.48725175311821595,
            "precision": 0.5714285714285714,
            "recall": 0.7782426778242678
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6686758718257979,
            "auditor_fn_violation": 0.07229104594636977,
            "auditor_fp_violation": 0.08733613434775479,
            "ave_precision_score": 0.6697829710619565,
            "fpr": 0.29747530186608123,
            "logloss": 0.7098706262308246,
            "mae": 0.4878961924631169,
            "precision": 0.57984496124031,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7304678385258606,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.7210889399885543,
            "fpr": 0.01644736842105263,
            "logloss": 1.0006571942184772,
            "mae": 0.4018212128422121,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7271432549742339,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.7132928832415931,
            "fpr": 0.015367727771679473,
            "logloss": 1.0248585135119828,
            "mae": 0.3985426951421642,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7665101009576338,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.688838134757928,
            "fpr": 0.01644736842105263,
            "logloss": 1.0017942966586446,
            "mae": 0.4025180521367112,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7658655346558608,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.693162862484201,
            "fpr": 0.015367727771679473,
            "logloss": 1.026446949612742,
            "mae": 0.3993205391228696,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7289965022349685,
            "auditor_fn_violation": 0.07577947221610512,
            "auditor_fp_violation": 0.09570802005012531,
            "ave_precision_score": 0.7306056654192662,
            "fpr": 0.3059210526315789,
            "logloss": 0.7114967716889594,
            "mae": 0.48762125900962894,
            "precision": 0.5694444444444444,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7238967498345679,
            "auditor_fn_violation": 0.07448643562803826,
            "auditor_fp_violation": 0.09290031164439735,
            "ave_precision_score": 0.7245545445248904,
            "fpr": 0.300768386388584,
            "logloss": 0.7101666858823983,
            "mae": 0.4879505965699218,
            "precision": 0.5771604938271605,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8330520919230131,
            "auditor_fn_violation": 0.011721904132716744,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.7692305739992696,
            "fpr": 0.013157894736842105,
            "logloss": 0.5929257607057346,
            "mae": 0.4150364367258653,
            "precision": 0.9178082191780822,
            "recall": 0.2803347280334728
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7962465360815938,
            "auditor_fn_violation": 0.009787010303572577,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.7272524365351898,
            "fpr": 0.013172338090010977,
            "logloss": 0.6088356179602139,
            "mae": 0.4233231938042311,
            "precision": 0.905511811023622,
            "recall": 0.2415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6317049830523563,
            "auditor_fn_violation": 0.04160014314027748,
            "auditor_fp_violation": 0.027947893928369317,
            "ave_precision_score": 0.6339791375826621,
            "fpr": 0.2324561403508772,
            "logloss": 0.9517171830141785,
            "mae": 0.4481695287440424,
            "precision": 0.5628865979381443,
            "recall": 0.5711297071129707
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.660474114263816,
            "auditor_fn_violation": 0.046255384700532254,
            "auditor_fp_violation": 0.034974828721753275,
            "ave_precision_score": 0.661127784170236,
            "fpr": 0.20087815587266739,
            "logloss": 0.9239045558818963,
            "mae": 0.4328271544387616,
            "precision": 0.5915178571428571,
            "recall": 0.5567226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7207625872222092,
            "auditor_fn_violation": 0.08832489172722603,
            "auditor_fp_violation": 0.0937626323874202,
            "ave_precision_score": 0.5563137351951191,
            "fpr": 0.29276315789473684,
            "logloss": 0.6868433637618458,
            "mae": 0.4958931639006263,
            "precision": 0.5679611650485437,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7252075458166489,
            "auditor_fn_violation": 0.09108561097325868,
            "auditor_fp_violation": 0.09599152125364324,
            "ave_precision_score": 0.5630570027023611,
            "fpr": 0.27991218441273324,
            "logloss": 0.6854618334570721,
            "mae": 0.4952149538713805,
            "precision": 0.5778145695364238,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6224020604609415,
            "auditor_fn_violation": 0.04634625266094107,
            "auditor_fp_violation": 0.028458242380143918,
            "ave_precision_score": 0.6238300047494829,
            "fpr": 0.2324561403508772,
            "logloss": 0.9687226947469169,
            "mae": 0.4563061943632707,
            "precision": 0.5527426160337553,
            "recall": 0.5481171548117155
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6513563434100235,
            "auditor_fn_violation": 0.04636607661725504,
            "auditor_fp_violation": 0.035996820470116216,
            "ave_precision_score": 0.6518647848738276,
            "fpr": 0.2030735455543359,
            "logloss": 0.9331665814642233,
            "mae": 0.43895275887397656,
            "precision": 0.5870535714285714,
            "recall": 0.5525210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.818518841641328,
            "auditor_fn_violation": 0.027896296704103356,
            "auditor_fp_violation": 0.024885803217721728,
            "ave_precision_score": 0.818788343470678,
            "fpr": 0.11951754385964912,
            "logloss": 0.8467096924728232,
            "mae": 0.3455367583495782,
            "precision": 0.7476851851851852,
            "recall": 0.6757322175732218
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.812682714159358,
            "auditor_fn_violation": 0.03494866662361982,
            "auditor_fp_violation": 0.022471201281905707,
            "ave_precision_score": 0.8129826205441815,
            "fpr": 0.10976948408342481,
            "logloss": 0.9562752943238461,
            "mae": 0.3462475517494263,
            "precision": 0.7590361445783133,
            "recall": 0.6617647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6936262456110792,
            "auditor_fn_violation": 0.06907206562431184,
            "auditor_fp_violation": 0.06912442396313366,
            "ave_precision_score": 0.5650065559774307,
            "fpr": 0.19736842105263158,
            "logloss": 0.6829473321043558,
            "mae": 0.4919833133095189,
            "precision": 0.5973154362416108,
            "recall": 0.5585774058577406
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6868208142165486,
            "auditor_fn_violation": 0.07312584748498742,
            "auditor_fp_violation": 0.06788043958262362,
            "ave_precision_score": 0.5599497133108842,
            "fpr": 0.1964873765093304,
            "logloss": 0.6841493780591412,
            "mae": 0.4926306713949051,
            "precision": 0.591324200913242,
            "recall": 0.5441176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.659852712359118,
            "auditor_fn_violation": 0.04021920648902592,
            "auditor_fp_violation": 0.032548609426792795,
            "ave_precision_score": 0.6620839779846145,
            "fpr": 0.24671052631578946,
            "logloss": 0.8592738121863855,
            "mae": 0.4344254017280416,
            "precision": 0.5738636363636364,
            "recall": 0.6338912133891214
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6805129242565355,
            "auditor_fn_violation": 0.03592413913973933,
            "auditor_fp_violation": 0.034646781987710866,
            "ave_precision_score": 0.6809451424408026,
            "fpr": 0.20636663007683864,
            "logloss": 0.8256942106767364,
            "mae": 0.42273037076049946,
            "precision": 0.6091476091476091,
            "recall": 0.615546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 29756,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7971810548711412,
            "auditor_fn_violation": 0.014770516773104318,
            "auditor_fp_violation": 0.013031570862640477,
            "ave_precision_score": 0.7981209776142528,
            "fpr": 0.10855263157894737,
            "logloss": 1.0976580067327963,
            "mae": 0.33195611148032506,
            "precision": 0.7573529411764706,
            "recall": 0.6464435146443515
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8099172994265812,
            "auditor_fn_violation": 0.008398749181341036,
            "auditor_fp_violation": 0.012634846133464555,
            "ave_precision_score": 0.8099850854235944,
            "fpr": 0.10647639956092206,
            "logloss": 1.076784608313549,
            "mae": 0.3257758204719105,
            "precision": 0.7616707616707616,
            "recall": 0.6512605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8317936617445209,
            "auditor_fn_violation": 0.017883359025178014,
            "auditor_fp_violation": 0.0265002223300186,
            "ave_precision_score": 0.8277038184674783,
            "fpr": 0.12390350877192982,
            "logloss": 0.7877407762486175,
            "mae": 0.31815340535710573,
            "precision": 0.754880694143167,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8420617254369591,
            "auditor_fn_violation": 0.023752640463430157,
            "auditor_fp_violation": 0.022463630972658567,
            "ave_precision_score": 0.8386493050035312,
            "fpr": 0.10318331503841932,
            "logloss": 0.7872420282708602,
            "mae": 0.3109670868950104,
            "precision": 0.7844036697247706,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7082240216900602,
            "auditor_fn_violation": 0.07563495558981136,
            "auditor_fp_violation": 0.08789867814698037,
            "ave_precision_score": 0.6585502920692966,
            "fpr": 0.17434210526315788,
            "logloss": 0.6534712599318938,
            "mae": 0.44304952522935837,
            "precision": 0.6131386861313869,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7131277260838613,
            "auditor_fn_violation": 0.08601223145679787,
            "auditor_fp_violation": 0.07948824709489383,
            "ave_precision_score": 0.6513856074698634,
            "fpr": 0.16136114160263446,
            "logloss": 0.6623220076115063,
            "mae": 0.4507586263553633,
            "precision": 0.6343283582089553,
            "recall": 0.5357142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8260239651324056,
            "auditor_fn_violation": 0.024969261542978793,
            "auditor_fp_violation": 0.024059645080443046,
            "ave_precision_score": 0.8262827318351591,
            "fpr": 0.11951754385964912,
            "logloss": 0.8271330817011522,
            "mae": 0.3422020087885192,
            "precision": 0.75,
            "recall": 0.6841004184100419
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8193809987211218,
            "auditor_fn_violation": 0.026771301275724347,
            "auditor_fp_violation": 0.019614671259320947,
            "ave_precision_score": 0.8196711626854846,
            "fpr": 0.10867178924259056,
            "logloss": 0.9352183044430038,
            "mae": 0.34381612852154725,
            "precision": 0.7665094339622641,
            "recall": 0.6827731092436975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 29756,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6799385371740077,
            "auditor_fn_violation": 0.008776517653967558,
            "auditor_fp_violation": 0.012834505618885921,
            "ave_precision_score": 0.6741012584126067,
            "fpr": 0.17105263157894737,
            "logloss": 2.7520521452347038,
            "mae": 0.3671412131087162,
            "precision": 0.6517857142857143,
            "recall": 0.6108786610878661
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6660543397830534,
            "auditor_fn_violation": 0.017212593050392497,
            "auditor_fp_violation": 0.02224913887732314,
            "ave_precision_score": 0.6616819679537882,
            "fpr": 0.16575192096597147,
            "logloss": 3.009938272047542,
            "mae": 0.3699737939037558,
            "precision": 0.6621923937360179,
            "recall": 0.6218487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8028408941946861,
            "auditor_fn_violation": 0.027595793878000444,
            "auditor_fp_violation": 0.025643746462931532,
            "ave_precision_score": 0.8042215547343842,
            "fpr": 0.12280701754385964,
            "logloss": 0.9991473651342317,
            "mae": 0.3430898977054073,
            "precision": 0.7442922374429224,
            "recall": 0.6820083682008368
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8058274997582036,
            "auditor_fn_violation": 0.03218136870555028,
            "auditor_fp_violation": 0.02091928788624349,
            "ave_precision_score": 0.80619599262165,
            "fpr": 0.10428100987925357,
            "logloss": 1.1495999550333098,
            "mae": 0.341274753537982,
            "precision": 0.7716346153846154,
            "recall": 0.6743697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6224186498212322,
            "auditor_fn_violation": 0.04634625266094107,
            "auditor_fp_violation": 0.028458242380143918,
            "ave_precision_score": 0.6242445948850468,
            "fpr": 0.2324561403508772,
            "logloss": 0.9691039954791244,
            "mae": 0.4563312660527612,
            "precision": 0.5527426160337553,
            "recall": 0.5481171548117155
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6526128673444597,
            "auditor_fn_violation": 0.04636607661725504,
            "auditor_fp_violation": 0.035996820470116216,
            "ave_precision_score": 0.6525565222115879,
            "fpr": 0.2030735455543359,
            "logloss": 0.9335158487525665,
            "mae": 0.43896915739633857,
            "precision": 0.5870535714285714,
            "recall": 0.5525210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8054511771175362,
            "auditor_fn_violation": 0.029040960140938127,
            "auditor_fp_violation": 0.024961597542242704,
            "ave_precision_score": 0.8068272540085357,
            "fpr": 0.1162280701754386,
            "logloss": 1.0048744896630195,
            "mae": 0.3448537548005014,
            "precision": 0.7534883720930232,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.806108742651872,
            "auditor_fn_violation": 0.03416921104336356,
            "auditor_fp_violation": 0.02374048979900829,
            "ave_precision_score": 0.8064636455893189,
            "fpr": 0.10208562019758508,
            "logloss": 1.1563439445825625,
            "mae": 0.3449442240160833,
            "precision": 0.770935960591133,
            "recall": 0.657563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7331600015930916,
            "auditor_fn_violation": 0.010579534610585039,
            "auditor_fp_violation": 0.007587011884550087,
            "ave_precision_score": 0.722061276307318,
            "fpr": 0.19407894736842105,
            "logloss": 1.6735873110500274,
            "mae": 0.3215432543574656,
            "precision": 0.6752293577981652,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7546269105300392,
            "auditor_fn_violation": 0.016387015838168418,
            "auditor_fp_violation": 0.025577551509645833,
            "ave_precision_score": 0.7467727823691197,
            "fpr": 0.18990120746432493,
            "logloss": 1.4519292510421187,
            "mae": 0.31607534856316083,
            "precision": 0.6837294332723949,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.718925410883366,
            "auditor_fn_violation": 0.08834783087425677,
            "auditor_fp_violation": 0.09299458323227426,
            "ave_precision_score": 0.5557321381896766,
            "fpr": 0.2905701754385965,
            "logloss": 0.6869543547418675,
            "mae": 0.49555058738118724,
            "precision": 0.567699836867863,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.723777833439507,
            "auditor_fn_violation": 0.08710531413443534,
            "auditor_fp_violation": 0.09276152264153323,
            "ave_precision_score": 0.5646185382513906,
            "fpr": 0.27442371020856204,
            "logloss": 0.6846795129575096,
            "mae": 0.49445544112919454,
            "precision": 0.5791245791245792,
            "recall": 0.7226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8151426540477306,
            "auditor_fn_violation": 0.015369228510607064,
            "auditor_fp_violation": 0.019923801439081575,
            "ave_precision_score": 0.8156230802379827,
            "fpr": 0.16337719298245615,
            "logloss": 0.8804074968004199,
            "mae": 0.3238316800777282,
            "precision": 0.7084148727984344,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8274807795255836,
            "auditor_fn_violation": 0.0076377422538719125,
            "auditor_fp_violation": 0.017782656421514824,
            "ave_precision_score": 0.8277963058174566,
            "fpr": 0.15587266739846323,
            "logloss": 1.0005961945517619,
            "mae": 0.32358026454253824,
            "precision": 0.716,
            "recall": 0.7521008403361344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6861534203887373,
            "auditor_fn_violation": 0.052654518094399194,
            "auditor_fp_violation": 0.005361185221117321,
            "ave_precision_score": 0.6846562247613912,
            "fpr": 0.17982456140350878,
            "logloss": 1.099425832060751,
            "mae": 0.4217780828407171,
            "precision": 0.6057692307692307,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7275637124992658,
            "auditor_fn_violation": 0.05059543026870464,
            "auditor_fp_violation": 0.007618254539031254,
            "ave_precision_score": 0.7249365225008539,
            "fpr": 0.1437980241492865,
            "logloss": 1.0780010642878521,
            "mae": 0.39411160445098686,
            "precision": 0.661498708010336,
            "recall": 0.5378151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7561587497051445,
            "auditor_fn_violation": 0.008930209939073626,
            "auditor_fp_violation": 0.014183644595359373,
            "ave_precision_score": 0.7295176616787906,
            "fpr": 0.23026315789473684,
            "logloss": 2.4175852015637904,
            "mae": 0.30798265862462704,
            "precision": 0.6618357487922706,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7778969366194035,
            "auditor_fn_violation": 0.012715733933529505,
            "auditor_fp_violation": 0.02773761308149438,
            "ave_precision_score": 0.7585697111079404,
            "fpr": 0.22063666300768386,
            "logloss": 2.0875439999736454,
            "mae": 0.312347232963684,
            "precision": 0.6661129568106312,
            "recall": 0.842436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8330228694935179,
            "auditor_fn_violation": 0.011721904132716744,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.7696270355268945,
            "fpr": 0.013157894736842105,
            "logloss": 0.5921777889094024,
            "mae": 0.41674086681093303,
            "precision": 0.9178082191780822,
            "recall": 0.2803347280334728
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7961798533139375,
            "auditor_fn_violation": 0.009787010303572577,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.7276075552656731,
            "fpr": 0.013172338090010977,
            "logloss": 0.6085684744479248,
            "mae": 0.42509337030473837,
            "precision": 0.905511811023622,
            "recall": 0.2415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7700835054539558,
            "auditor_fn_violation": 0.012644057843353158,
            "auditor_fp_violation": 0.007948298164766757,
            "ave_precision_score": 0.761081545426775,
            "fpr": 0.08333333333333333,
            "logloss": 0.5962286681430143,
            "mae": 0.4127690767718218,
            "precision": 0.8118811881188119,
            "recall": 0.6861924686192469
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7487915297328352,
            "auditor_fn_violation": 0.013462904371408289,
            "auditor_fp_violation": 0.011368081052777677,
            "ave_precision_score": 0.7363873763640647,
            "fpr": 0.09659714599341383,
            "logloss": 0.5924191810235897,
            "mae": 0.41531135354847387,
            "precision": 0.7690288713910761,
            "recall": 0.615546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7207625872222092,
            "auditor_fn_violation": 0.08832489172722603,
            "auditor_fp_violation": 0.0937626323874202,
            "ave_precision_score": 0.5563137351951191,
            "fpr": 0.29276315789473684,
            "logloss": 0.6867005186722325,
            "mae": 0.49567754697381405,
            "precision": 0.5679611650485437,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7252075458166489,
            "auditor_fn_violation": 0.09108561097325868,
            "auditor_fp_violation": 0.09599152125364324,
            "ave_precision_score": 0.5630570027023611,
            "fpr": 0.27991218441273324,
            "logloss": 0.6853019654870803,
            "mae": 0.4949962154897717,
            "precision": 0.5778145695364238,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7550908886235155,
            "auditor_fn_violation": 0.008930209939073626,
            "auditor_fp_violation": 0.014741996119330594,
            "ave_precision_score": 0.7277740517929776,
            "fpr": 0.23135964912280702,
            "logloss": 2.4564518304029908,
            "mae": 0.30843412896439154,
            "precision": 0.6607717041800643,
            "recall": 0.8598326359832636
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7771624729997659,
            "auditor_fn_violation": 0.012715733933529505,
            "auditor_fp_violation": 0.02773761308149438,
            "ave_precision_score": 0.7577427132870959,
            "fpr": 0.22063666300768386,
            "logloss": 2.1118655750352953,
            "mae": 0.31301917602243423,
            "precision": 0.6661129568106312,
            "recall": 0.842436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6803805130515076,
            "auditor_fn_violation": 0.014713168905527424,
            "auditor_fp_violation": 0.012662705149971708,
            "ave_precision_score": 0.6735379991502134,
            "fpr": 0.125,
            "logloss": 2.2929741771750836,
            "mae": 0.3752897689332621,
            "precision": 0.6885245901639344,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6832604504199352,
            "auditor_fn_violation": 0.015026427695117575,
            "auditor_fp_violation": 0.019203351123560072,
            "ave_precision_score": 0.6777255179172288,
            "fpr": 0.11745334796926454,
            "logloss": 2.23276542703202,
            "mae": 0.3771097500877117,
            "precision": 0.6925287356321839,
            "recall": 0.5063025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6787004493599167,
            "auditor_fn_violation": 0.008147985025324836,
            "auditor_fp_violation": 0.010954806370765626,
            "ave_precision_score": 0.66922294191026,
            "fpr": 0.043859649122807015,
            "logloss": 7.285396262015541,
            "mae": 0.48089565627976993,
            "precision": 0.6694214876033058,
            "recall": 0.1694560669456067
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7179058926250259,
            "auditor_fn_violation": 0.006318663579592107,
            "auditor_fp_violation": 0.008970816457852304,
            "ave_precision_score": 0.7104025686929156,
            "fpr": 0.03293084522502744,
            "logloss": 6.889225954549669,
            "mae": 0.4519012494321088,
            "precision": 0.7540983606557377,
            "recall": 0.19327731092436976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8317936617445209,
            "auditor_fn_violation": 0.017883359025178014,
            "auditor_fp_violation": 0.0265002223300186,
            "ave_precision_score": 0.8277038184674783,
            "fpr": 0.12390350877192982,
            "logloss": 0.7877407096795729,
            "mae": 0.3181534053932671,
            "precision": 0.754880694143167,
            "recall": 0.7280334728033473
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8420617254369591,
            "auditor_fn_violation": 0.023752640463430157,
            "auditor_fp_violation": 0.022463630972658567,
            "ave_precision_score": 0.8386493050035312,
            "fpr": 0.10318331503841932,
            "logloss": 0.7872419654578532,
            "mae": 0.3109670874987844,
            "precision": 0.7844036697247706,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7156762878591666,
            "auditor_fn_violation": 0.057712600014681065,
            "auditor_fp_violation": 0.0662745573611448,
            "ave_precision_score": 0.7167517429284256,
            "fpr": 0.20175438596491227,
            "logloss": 0.6803336143430242,
            "mae": 0.46923269808553814,
            "precision": 0.5865168539325842,
            "recall": 0.5460251046025104
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.693460413164023,
            "auditor_fn_violation": 0.06275078637382507,
            "auditor_fp_violation": 0.06451417540406526,
            "ave_precision_score": 0.6942491364513743,
            "fpr": 0.2052689352360044,
            "logloss": 0.6980884838588863,
            "mae": 0.47933062601887694,
            "precision": 0.5844444444444444,
            "recall": 0.5525210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.679549484869665,
            "auditor_fn_violation": 0.008147985025324836,
            "auditor_fp_violation": 0.010954806370765626,
            "ave_precision_score": 0.6700712365644147,
            "fpr": 0.043859649122807015,
            "logloss": 7.1682211163910114,
            "mae": 0.4805125079660717,
            "precision": 0.6694214876033058,
            "recall": 0.1694560669456067
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7198015588809463,
            "auditor_fn_violation": 0.0034498980711933636,
            "auditor_fp_violation": 0.008970816457852304,
            "ave_precision_score": 0.7130444506893292,
            "fpr": 0.03293084522502744,
            "logloss": 6.7592045694805885,
            "mae": 0.45116656089399765,
            "precision": 0.7560975609756098,
            "recall": 0.1953781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7294301909442161,
            "auditor_fn_violation": 0.06177512295382808,
            "auditor_fp_violation": 0.06858375778155067,
            "ave_precision_score": 0.7311401068422609,
            "fpr": 0.2149122807017544,
            "logloss": 0.7005580083860791,
            "mae": 0.48036824121025573,
            "precision": 0.5933609958506224,
            "recall": 0.5983263598326359
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7187108069340011,
            "auditor_fn_violation": 0.06548349306791872,
            "auditor_fp_violation": 0.06412051932321436,
            "ave_precision_score": 0.7193990225716198,
            "fpr": 0.20417124039517015,
            "logloss": 0.7027792177942094,
            "mae": 0.4816774185481108,
            "precision": 0.5974025974025974,
            "recall": 0.5798319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7885288828153182,
            "auditor_fn_violation": 0.0059182999339352565,
            "auditor_fp_violation": 0.024648314334222664,
            "ave_precision_score": 0.7657039073338447,
            "fpr": 0.22807017543859648,
            "logloss": 2.4597849497287583,
            "mae": 0.2991057084843014,
            "precision": 0.6687898089171974,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8027306665527818,
            "auditor_fn_violation": 0.01286332315582655,
            "auditor_fp_violation": 0.029885057471264367,
            "ave_precision_score": 0.7879536789847376,
            "fpr": 0.21514818880351264,
            "logloss": 2.1784065338476335,
            "mae": 0.29783545688899443,
            "precision": 0.6749585406301825,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6055602531189996,
            "auditor_fn_violation": 0.08450552374660503,
            "auditor_fp_violation": 0.08902548710485891,
            "ave_precision_score": 0.5691590799250036,
            "fpr": 0.2774122807017544,
            "logloss": 0.7143046315178768,
            "mae": 0.48857437956490013,
            "precision": 0.5783333333333334,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5805475768540878,
            "auditor_fn_violation": 0.08246547795847209,
            "auditor_fp_violation": 0.09038192210151785,
            "ave_precision_score": 0.5636081900424671,
            "fpr": 0.278814489571899,
            "logloss": 0.7177040662035767,
            "mae": 0.491302953527997,
            "precision": 0.5752508361204013,
            "recall": 0.7226890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7617329510588737,
            "auditor_fn_violation": 0.00613392791602438,
            "auditor_fp_violation": 0.004102999434069043,
            "ave_precision_score": 0.7627230997579361,
            "fpr": 0.015350877192982455,
            "logloss": 0.6805418409303284,
            "mae": 0.46937704331388597,
            "precision": 0.8813559322033898,
            "recall": 0.2175732217573222
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7389453890037112,
            "auditor_fn_violation": 0.007902941637686912,
            "auditor_fp_violation": 5.5515601145640766e-05,
            "ave_precision_score": 0.7395549496344185,
            "fpr": 0.018660812294182216,
            "logloss": 0.6983864789480767,
            "mae": 0.4794829927147678,
            "precision": 0.8365384615384616,
            "recall": 0.18277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6305686389520032,
            "auditor_fn_violation": 0.009595445202965588,
            "auditor_fp_violation": 0.0174200622524052,
            "ave_precision_score": 0.5307129688354244,
            "fpr": 0.3190789473684211,
            "logloss": 10.56813432948436,
            "mae": 0.4513812759473616,
            "precision": 0.5495356037151703,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6238869410723435,
            "auditor_fn_violation": 0.007955981514449909,
            "auditor_fp_violation": 0.015662969832317665,
            "ave_precision_score": 0.5293358997649258,
            "fpr": 0.30954994511525796,
            "logloss": 10.064564646889107,
            "mae": 0.45421734641745204,
            "precision": 0.5545023696682464,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7665101009576338,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.688838134757928,
            "fpr": 0.01644736842105263,
            "logloss": 1.0017943235240996,
            "mae": 0.4025180521367111,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7658655346558608,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.693162862484201,
            "fpr": 0.015367727771679473,
            "logloss": 1.026446977893434,
            "mae": 0.3993205391228694,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8256273818234008,
            "auditor_fn_violation": 0.011783839829699772,
            "auditor_fp_violation": 0.007746179966044144,
            "ave_precision_score": 0.8212868761259802,
            "fpr": 0.03070175438596491,
            "logloss": 0.9230013762829835,
            "mae": 0.3434190449844369,
            "precision": 0.900355871886121,
            "recall": 0.5292887029288703
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.838949475440911,
            "auditor_fn_violation": 0.020676327611176194,
            "auditor_fp_violation": 0.007229645331011772,
            "ave_precision_score": 0.835866862123591,
            "fpr": 0.03293084522502744,
            "logloss": 0.9263016532142314,
            "mae": 0.3397451137509711,
            "precision": 0.8897058823529411,
            "recall": 0.5084033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7898828675676663,
            "auditor_fn_violation": 0.0035234529839242457,
            "auditor_fp_violation": 0.026346107203492602,
            "ave_precision_score": 0.7602966939632954,
            "fpr": 0.23355263157894737,
            "logloss": 2.73213372081392,
            "mae": 0.30392458619889495,
            "precision": 0.6697674418604651,
            "recall": 0.9037656903765691
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7955753275223214,
            "auditor_fn_violation": 0.01202160337241373,
            "auditor_fp_violation": 0.02632448868869627,
            "ave_precision_score": 0.7709277578541317,
            "fpr": 0.23161361141602635,
            "logloss": 2.5505579219827217,
            "mae": 0.30187311749747653,
            "precision": 0.667192429022082,
            "recall": 0.8886554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7207625872222092,
            "auditor_fn_violation": 0.08832489172722603,
            "auditor_fp_violation": 0.0937626323874202,
            "ave_precision_score": 0.5563137351951191,
            "fpr": 0.29276315789473684,
            "logloss": 0.6868523166923409,
            "mae": 0.49590097786041726,
            "precision": 0.5679611650485437,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7252075458166489,
            "auditor_fn_violation": 0.09108561097325868,
            "auditor_fp_violation": 0.09599152125364324,
            "ave_precision_score": 0.5630570027023611,
            "fpr": 0.27991218441273324,
            "logloss": 0.6854739612591267,
            "mae": 0.49522433964010126,
            "precision": 0.5778145695364238,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7085373220136713,
            "auditor_fn_violation": 0.08246164574616459,
            "auditor_fp_violation": 0.09337860780984719,
            "ave_precision_score": 0.7099682958545431,
            "fpr": 0.2916666666666667,
            "logloss": 0.7103565999682714,
            "mae": 0.48964950559954895,
            "precision": 0.5702746365105008,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6904222396936447,
            "auditor_fn_violation": 0.08166526764383032,
            "auditor_fp_violation": 0.09134839824873513,
            "ave_precision_score": 0.69123812002623,
            "fpr": 0.2810098792535675,
            "logloss": 0.7104167121294586,
            "mae": 0.4908592426489004,
            "precision": 0.5796387520525451,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6207349359941758,
            "auditor_fn_violation": 0.0036106217426411418,
            "auditor_fp_violation": 0.021601382488479277,
            "ave_precision_score": 0.528286382276888,
            "fpr": 0.20942982456140352,
            "logloss": 11.693403604027662,
            "mae": 0.5074512064935894,
            "precision": 0.5188916876574308,
            "recall": 0.4309623430962343
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6122468575907788,
            "auditor_fn_violation": 0.01891909343320204,
            "auditor_fp_violation": 0.018274726522578454,
            "ave_precision_score": 0.5226531120377504,
            "fpr": 0.19978046103183314,
            "logloss": 11.47989535878636,
            "mae": 0.5037375477268314,
            "precision": 0.5248041775456919,
            "recall": 0.4222689075630252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7466728141028244,
            "auditor_fn_violation": 0.07577717830140206,
            "auditor_fp_violation": 0.09312343358395991,
            "ave_precision_score": 0.7482563311348177,
            "fpr": 0.2883771929824561,
            "logloss": 0.7045672981263424,
            "mae": 0.48455976995459776,
            "precision": 0.5667215815485996,
            "recall": 0.7196652719665272
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7373453602801224,
            "auditor_fn_violation": 0.07966820097962347,
            "auditor_fp_violation": 0.08910001640233671,
            "ave_precision_score": 0.7379398275884546,
            "fpr": 0.29198682766191,
            "logloss": 0.7058072359380627,
            "mae": 0.486446471052688,
            "precision": 0.567479674796748,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 29756,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7494576805218487,
            "auditor_fn_violation": 0.07643553182118477,
            "auditor_fp_violation": 0.09065506508206,
            "ave_precision_score": 0.7510397500913382,
            "fpr": 0.2894736842105263,
            "logloss": 0.7182020201840753,
            "mae": 0.4832538912157217,
            "precision": 0.5693311582381729,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7361720332468347,
            "auditor_fn_violation": 0.07588853323986017,
            "auditor_fp_violation": 0.08895113365380976,
            "ave_precision_score": 0.7367914008878558,
            "fpr": 0.29088913282107576,
            "logloss": 0.7067509368510684,
            "mae": 0.48221067081984387,
            "precision": 0.5698051948051948,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6794971923280253,
            "auditor_fn_violation": 0.008147985025324836,
            "auditor_fp_violation": 0.010954806370765626,
            "ave_precision_score": 0.6700187248101013,
            "fpr": 0.043859649122807015,
            "logloss": 7.1996163402149564,
            "mae": 0.4805486295143807,
            "precision": 0.6694214876033058,
            "recall": 0.1694560669456067
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7198360175556113,
            "auditor_fn_violation": 0.0034498980711933636,
            "auditor_fp_violation": 0.008970816457852304,
            "ave_precision_score": 0.7130990816714011,
            "fpr": 0.03293084522502744,
            "logloss": 6.78983037921065,
            "mae": 0.45114593302087413,
            "precision": 0.7560975609756098,
            "recall": 0.1953781512605042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7289965022349685,
            "auditor_fn_violation": 0.07577947221610512,
            "auditor_fp_violation": 0.09570802005012531,
            "ave_precision_score": 0.7306056654192662,
            "fpr": 0.3059210526315789,
            "logloss": 0.7114987600031808,
            "mae": 0.4876214585740838,
            "precision": 0.5694444444444444,
            "recall": 0.7719665271966527
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7238967498345679,
            "auditor_fn_violation": 0.07448643562803826,
            "auditor_fp_violation": 0.09290031164439735,
            "ave_precision_score": 0.7245545445248904,
            "fpr": 0.300768386388584,
            "logloss": 0.7101665240501798,
            "mae": 0.48794978716370824,
            "precision": 0.5771604938271605,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7444926554707327,
            "auditor_fn_violation": 0.012185274902738021,
            "auditor_fp_violation": 0.008337375697307784,
            "ave_precision_score": 0.7406841368429827,
            "fpr": 0.09429824561403509,
            "logloss": 0.6145673496126944,
            "mae": 0.41928275520994995,
            "precision": 0.7937649880095923,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.703450136107865,
            "auditor_fn_violation": 0.011555774889538703,
            "auditor_fp_violation": 0.011395838853350493,
            "ave_precision_score": 0.6988221596264401,
            "fpr": 0.11086717892425905,
            "logloss": 0.6265686750290623,
            "mae": 0.4265158214043053,
            "precision": 0.7449494949494949,
            "recall": 0.6197478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8330520919230131,
            "auditor_fn_violation": 0.011721904132716744,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.7692305739992696,
            "fpr": 0.013157894736842105,
            "logloss": 0.5929257607057346,
            "mae": 0.4150364367258653,
            "precision": 0.9178082191780822,
            "recall": 0.2803347280334728
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7962465360815938,
            "auditor_fn_violation": 0.009787010303572577,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.7272524365351898,
            "fpr": 0.013172338090010977,
            "logloss": 0.6088356179602139,
            "mae": 0.4233231938042311,
            "precision": 0.905511811023622,
            "recall": 0.2415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7207625872222092,
            "auditor_fn_violation": 0.08832489172722603,
            "auditor_fp_violation": 0.0937626323874202,
            "ave_precision_score": 0.5563137351951191,
            "fpr": 0.29276315789473684,
            "logloss": 0.6868466796606584,
            "mae": 0.49589112139584723,
            "precision": 0.5679611650485437,
            "recall": 0.7343096234309623
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7252075458166489,
            "auditor_fn_violation": 0.09108561097325868,
            "auditor_fp_violation": 0.09599152125364324,
            "ave_precision_score": 0.5630570027023611,
            "fpr": 0.27991218441273324,
            "logloss": 0.6854690746441072,
            "mae": 0.4952152022349717,
            "precision": 0.5778145695364238,
            "recall": 0.7331932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7444926554707327,
            "auditor_fn_violation": 0.012185274902738021,
            "auditor_fp_violation": 0.008337375697307784,
            "ave_precision_score": 0.7406841368429827,
            "fpr": 0.09429824561403509,
            "logloss": 0.6145673496126944,
            "mae": 0.41928275520994995,
            "precision": 0.7937649880095923,
            "recall": 0.6924686192468619
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.703450136107865,
            "auditor_fn_violation": 0.011555774889538703,
            "auditor_fp_violation": 0.011395838853350493,
            "ave_precision_score": 0.6988221596264401,
            "fpr": 0.11086717892425905,
            "logloss": 0.6265686750290623,
            "mae": 0.4265158214043053,
            "precision": 0.7449494949494949,
            "recall": 0.6197478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8296545044143182,
            "auditor_fn_violation": 0.017341995155252154,
            "auditor_fp_violation": 0.025492157813889568,
            "ave_precision_score": 0.8224831914619426,
            "fpr": 0.12719298245614036,
            "logloss": 0.7758419519247942,
            "mae": 0.3183950521544736,
            "precision": 0.7510729613733905,
            "recall": 0.7322175732217573
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8368527449393969,
            "auditor_fn_violation": 0.025069413056111583,
            "auditor_fp_violation": 0.01918316363223438,
            "ave_precision_score": 0.8297116490776534,
            "fpr": 0.10647639956092206,
            "logloss": 0.7773213438943101,
            "mae": 0.3113240234740992,
            "precision": 0.7805429864253394,
            "recall": 0.7247899159663865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8143096779443184,
            "auditor_fn_violation": 0.015071019599207227,
            "auditor_fp_violation": 0.02274335031126203,
            "ave_precision_score": 0.8147535583310436,
            "fpr": 0.16447368421052633,
            "logloss": 0.8401781773601606,
            "mae": 0.3277706698456898,
            "precision": 0.70703125,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8293875286320045,
            "auditor_fn_violation": 0.009330406147091106,
            "auditor_fp_violation": 0.0205761005337068,
            "ave_precision_score": 0.8296427424446488,
            "fpr": 0.15806805708013172,
            "logloss": 0.9469686175575255,
            "mae": 0.32709554386417583,
            "precision": 0.7125748502994012,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6257490280397576,
            "auditor_fn_violation": 0.0010827277398517171,
            "auditor_fp_violation": 0.025282460182714843,
            "ave_precision_score": 0.5299225208804232,
            "fpr": 0.22039473684210525,
            "logloss": 10.947377965826266,
            "mae": 0.47940671086546455,
            "precision": 0.5421412300683371,
            "recall": 0.497907949790795
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6181526093222068,
            "auditor_fn_violation": 0.00987002924111468,
            "auditor_fp_violation": 0.018749132568732105,
            "ave_precision_score": 0.5259319786093978,
            "fpr": 0.21844127332601537,
            "logloss": 10.619057822286171,
            "mae": 0.4874222932417631,
            "precision": 0.5382830626450116,
            "recall": 0.48739495798319327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8261958917419158,
            "auditor_fn_violation": 0.018498128165602288,
            "auditor_fp_violation": 0.02343560514188698,
            "ave_precision_score": 0.8265534494797162,
            "fpr": 0.1513157894736842,
            "logloss": 0.8442938813717781,
            "mae": 0.31713540525824135,
            "precision": 0.7261904761904762,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8278858577882747,
            "auditor_fn_violation": 0.014597496517816791,
            "auditor_fp_violation": 0.021832771868730845,
            "ave_precision_score": 0.8284506475801316,
            "fpr": 0.13830954994511527,
            "logloss": 0.9659105909370717,
            "mae": 0.31509087739545283,
            "precision": 0.7418032786885246,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.8073654367657827,
            "auditor_fn_violation": 0.07529545621375616,
            "auditor_fp_violation": 0.07867956180774517,
            "ave_precision_score": 0.8074830601541172,
            "fpr": 0.26535087719298245,
            "logloss": 0.655952845277814,
            "mae": 0.4730106954903979,
            "precision": 0.5925925925925926,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7804107390536337,
            "auditor_fn_violation": 0.07840908042690183,
            "auditor_fp_violation": 0.08391183113163506,
            "ave_precision_score": 0.7806532951540412,
            "fpr": 0.2711306256860593,
            "logloss": 0.6707674848575738,
            "mae": 0.48059418669908943,
            "precision": 0.5883333333333334,
            "recall": 0.7415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8198284280007946,
            "auditor_fn_violation": 0.027896296704103356,
            "auditor_fp_violation": 0.024885803217721728,
            "ave_precision_score": 0.8200876257169498,
            "fpr": 0.11951754385964912,
            "logloss": 0.8466253073189165,
            "mae": 0.34546019620736407,
            "precision": 0.7476851851851852,
            "recall": 0.6757322175732218
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8129524122187193,
            "auditor_fn_violation": 0.03416921104336356,
            "auditor_fp_violation": 0.022471201281905707,
            "ave_precision_score": 0.8132508635467188,
            "fpr": 0.10976948408342481,
            "logloss": 0.9574865257096397,
            "mae": 0.34638644445174527,
            "precision": 0.7578692493946732,
            "recall": 0.657563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7670209936929903,
            "auditor_fn_violation": 0.00810669456066946,
            "auditor_fp_violation": 0.018013784461152885,
            "ave_precision_score": 0.6827415473850968,
            "fpr": 0.044956140350877194,
            "logloss": 0.6155296684025657,
            "mae": 0.42807656527382504,
            "precision": 0.8009708737864077,
            "recall": 0.34518828451882844
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.764291801022512,
            "auditor_fn_violation": 0.01941259489525779,
            "auditor_fp_violation": 0.01928410108886281,
            "ave_precision_score": 0.672552207746652,
            "fpr": 0.03512623490669594,
            "logloss": 0.6231791252218992,
            "mae": 0.43168004354386375,
            "precision": 0.8171428571428572,
            "recall": 0.3004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7082240216900602,
            "auditor_fn_violation": 0.07563495558981136,
            "auditor_fp_violation": 0.08789867814698037,
            "ave_precision_score": 0.6585502920692966,
            "fpr": 0.17434210526315788,
            "logloss": 0.6534712571228003,
            "mae": 0.4430495263730878,
            "precision": 0.6131386861313869,
            "recall": 0.5271966527196653
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7131277260838613,
            "auditor_fn_violation": 0.08601223145679787,
            "auditor_fp_violation": 0.07948824709489383,
            "ave_precision_score": 0.6513856074698634,
            "fpr": 0.16136114160263446,
            "logloss": 0.6623220057153782,
            "mae": 0.45075862815462536,
            "precision": 0.6343283582089553,
            "recall": 0.5357142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6379329280752047,
            "auditor_fn_violation": 0.04549062247669383,
            "auditor_fp_violation": 0.034036704664888034,
            "ave_precision_score": 0.6396385083113509,
            "fpr": 0.24013157894736842,
            "logloss": 0.9272078232272248,
            "mae": 0.44565845557568345,
            "precision": 0.5602409638554217,
            "recall": 0.5836820083682008
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6627266003173715,
            "auditor_fn_violation": 0.04191533913235986,
            "auditor_fp_violation": 0.03636019531397858,
            "ave_precision_score": 0.6634321248781193,
            "fpr": 0.20087815587266739,
            "logloss": 0.904689547807539,
            "mae": 0.4303602462279639,
            "precision": 0.5995623632385121,
            "recall": 0.5756302521008403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8286276994596827,
            "auditor_fn_violation": 0.020227739851721358,
            "auditor_fp_violation": 0.02266755598674105,
            "ave_precision_score": 0.828905965094831,
            "fpr": 0.15679824561403508,
            "logloss": 0.8423706000695405,
            "mae": 0.3181661216514452,
            "precision": 0.7190569744597249,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8284134890239245,
            "auditor_fn_violation": 0.009985333321034231,
            "auditor_fp_violation": 0.02084106135735645,
            "ave_precision_score": 0.8287946717840029,
            "fpr": 0.1437980241492865,
            "logloss": 0.961247893927944,
            "mae": 0.31650038183498913,
            "precision": 0.7348178137651822,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8212443781782139,
            "auditor_fn_violation": 0.016523067606254136,
            "auditor_fp_violation": 0.021715073975260735,
            "ave_precision_score": 0.8217324979056371,
            "fpr": 0.12171052631578948,
            "logloss": 0.7750336043026858,
            "mae": 0.3269589690284224,
            "precision": 0.75764192139738,
            "recall": 0.7259414225941423
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8213034489915596,
            "auditor_fn_violation": 0.014293093746829138,
            "auditor_fp_violation": 0.0146106968469662,
            "ave_precision_score": 0.8217138304511875,
            "fpr": 0.11086717892425905,
            "logloss": 0.8683847216797322,
            "mae": 0.3306999362617161,
            "precision": 0.764018691588785,
            "recall": 0.6869747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7270133762873163,
            "auditor_fn_violation": 0.08134221537106365,
            "auditor_fp_violation": 0.09337860780984719,
            "ave_precision_score": 0.7286194303575981,
            "fpr": 0.2916666666666667,
            "logloss": 0.7079993963565422,
            "mae": 0.48759180977287,
            "precision": 0.572347266881029,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7216718686195829,
            "auditor_fn_violation": 0.08287596048298573,
            "auditor_fp_violation": 0.09095726560429995,
            "ave_precision_score": 0.722348056330286,
            "fpr": 0.27991218441273324,
            "logloss": 0.7068644539926261,
            "mae": 0.4879884610911494,
            "precision": 0.5833333333333334,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7596070927639837,
            "auditor_fn_violation": 0.03904472216105116,
            "auditor_fp_violation": 0.009408602150537633,
            "ave_precision_score": 0.7606005563446314,
            "fpr": 0.03837719298245614,
            "logloss": 0.6806836173479422,
            "mae": 0.46943537515114275,
            "precision": 0.8653846153846154,
            "recall": 0.4707112970711297
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7405657955553413,
            "auditor_fn_violation": 0.03685118394229262,
            "auditor_fp_violation": 0.005904841212763542,
            "ave_precision_score": 0.7411570978805615,
            "fpr": 0.042810098792535674,
            "logloss": 0.6981738597000049,
            "mae": 0.4793685118695384,
            "precision": 0.8395061728395061,
            "recall": 0.42857142857142855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.10256043505187,
            "mae": 0.5241228070175439,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.046605448932475,
            "mae": 0.5225027442371021,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7579321397211743,
            "auditor_fn_violation": 0.012001761726491963,
            "auditor_fp_violation": 0.017003193467539826,
            "ave_precision_score": 0.7303192973493883,
            "fpr": 0.23903508771929824,
            "logloss": 2.4475502198470305,
            "mae": 0.31025699790959127,
            "precision": 0.6561514195583596,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7796289283121729,
            "auditor_fn_violation": 0.014454519458716533,
            "auditor_fp_violation": 0.023336739972494542,
            "ave_precision_score": 0.7609224447600407,
            "fpr": 0.22941822173435786,
            "logloss": 2.080641836792072,
            "mae": 0.31516951136020627,
            "precision": 0.6607142857142857,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7197866688502688,
            "auditor_fn_violation": 0.08470968215517875,
            "auditor_fp_violation": 0.08761823914625273,
            "ave_precision_score": 0.5640733697363227,
            "fpr": 0.27521929824561403,
            "logloss": 0.6837285781443703,
            "mae": 0.4933567742506663,
            "precision": 0.5788590604026845,
            "recall": 0.7217573221757322
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.716255716194951,
            "auditor_fn_violation": 0.08872418341650602,
            "auditor_fp_violation": 0.09385921748236749,
            "ave_precision_score": 0.5617605007959761,
            "fpr": 0.27442371020856204,
            "logloss": 0.6845140244255437,
            "mae": 0.49383080980518645,
            "precision": 0.5755517826825127,
            "recall": 0.7121848739495799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7503126435766087,
            "auditor_fn_violation": 0.08246164574616459,
            "auditor_fp_violation": 0.09337860780984719,
            "ave_precision_score": 0.7519302291855507,
            "fpr": 0.2916666666666667,
            "logloss": 0.7125254260716052,
            "mae": 0.4874591958431298,
            "precision": 0.5702746365105008,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7436217507666891,
            "auditor_fn_violation": 0.08203654678117132,
            "auditor_fp_violation": 0.09025070340790088,
            "ave_precision_score": 0.74423475003424,
            "fpr": 0.2810098792535675,
            "logloss": 0.7110278456798219,
            "mae": 0.4876606690438728,
            "precision": 0.580327868852459,
            "recall": 0.7436974789915967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8330520919230131,
            "auditor_fn_violation": 0.011721904132716744,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.7692305739992696,
            "fpr": 0.013157894736842105,
            "logloss": 0.5966700777722491,
            "mae": 0.41370469717341557,
            "precision": 0.9178082191780822,
            "recall": 0.2803347280334728
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7962465360815938,
            "auditor_fn_violation": 0.009787010303572577,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.7272524365351898,
            "fpr": 0.013172338090010977,
            "logloss": 0.6143090989113382,
            "mae": 0.4227948140365232,
            "precision": 0.905511811023622,
            "recall": 0.2415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.726187052074069,
            "auditor_fn_violation": 0.06067863172575791,
            "auditor_fp_violation": 0.0693619128466327,
            "ave_precision_score": 0.7279006106704854,
            "fpr": 0.21710526315789475,
            "logloss": 0.7019200816817642,
            "mae": 0.48076135005083,
            "precision": 0.5909090909090909,
            "recall": 0.5983263598326359
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7120857527915564,
            "auditor_fn_violation": 0.06473632263003995,
            "auditor_fp_violation": 0.0652182141640486,
            "ave_precision_score": 0.7128356277372493,
            "fpr": 0.20417124039517015,
            "logloss": 0.7076242614137119,
            "mae": 0.48461505008450456,
            "precision": 0.5974025974025974,
            "recall": 0.5798319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 29756,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6215639540814091,
            "auditor_fn_violation": 0.0030004404316230082,
            "auditor_fp_violation": 0.021601382488479277,
            "ave_precision_score": 0.5288337773272195,
            "fpr": 0.20942982456140352,
            "logloss": 11.584633861993671,
            "mae": 0.505396493254248,
            "precision": 0.5201005025125628,
            "recall": 0.4330543933054393
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6122627037517527,
            "auditor_fn_violation": 0.01891909343320204,
            "auditor_fp_violation": 0.01915035895883013,
            "ave_precision_score": 0.5226689566326411,
            "fpr": 0.1986827661909989,
            "logloss": 11.356591511934788,
            "mae": 0.5030753872405633,
            "precision": 0.5261780104712042,
            "recall": 0.4222689075630252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7152948627703014,
            "auditor_fn_violation": 0.010033582911253032,
            "auditor_fp_violation": 0.005174225887298893,
            "ave_precision_score": 0.6182466466504333,
            "fpr": 0.025219298245614034,
            "logloss": 0.6526712845696414,
            "mae": 0.4448209922564657,
            "precision": 0.8588957055214724,
            "recall": 0.2928870292887029
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.689494632381781,
            "auditor_fn_violation": 0.009980721157837448,
            "auditor_fp_violation": 0.0038154358605549054,
            "ave_precision_score": 0.5935714185470607,
            "fpr": 0.026344676180021953,
            "logloss": 0.6695214913692357,
            "mae": 0.45675291541379054,
            "precision": 0.8297872340425532,
            "recall": 0.24579831932773108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7849779535655884,
            "auditor_fn_violation": 0.013130367760405203,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6362919401506036,
            "fpr": 0.013157894736842105,
            "logloss": 0.626485795439404,
            "mae": 0.4449161317264825,
            "precision": 0.9154929577464789,
            "recall": 0.2719665271966527
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7610241347762218,
            "auditor_fn_violation": 0.007813004455349652,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.607386400097618,
            "fpr": 0.013172338090010977,
            "logloss": 0.6443730774412264,
            "mae": 0.4565136160468427,
            "precision": 0.8983050847457628,
            "recall": 0.22268907563025211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.742294775589543,
            "auditor_fn_violation": 0.011721904132716744,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6835993707598996,
            "fpr": 0.013157894736842105,
            "logloss": 0.6143935839199708,
            "mae": 0.42755505681168615,
            "precision": 0.9178082191780822,
            "recall": 0.2803347280334728
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7284146983565929,
            "auditor_fn_violation": 0.009787010303572577,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.6702564301063806,
            "fpr": 0.013172338090010977,
            "logloss": 0.6247347549774571,
            "mae": 0.4331471831686018,
            "precision": 0.905511811023622,
            "recall": 0.2415966386554622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6254583636990863,
            "auditor_fn_violation": 0.044800154151068056,
            "auditor_fp_violation": 0.03425398172851484,
            "ave_precision_score": 0.628417541903008,
            "fpr": 0.25219298245614036,
            "logloss": 0.9771669239422165,
            "mae": 0.44985102080046774,
            "precision": 0.5610687022900763,
            "recall": 0.6150627615062761
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6554592806121471,
            "auditor_fn_violation": 0.038451604571576155,
            "auditor_fp_violation": 0.039390842449247385,
            "ave_precision_score": 0.6564181366203697,
            "fpr": 0.21514818880351264,
            "logloss": 0.9423146315952959,
            "mae": 0.4343466849665438,
            "precision": 0.5942028985507246,
            "recall": 0.6029411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8261958917419158,
            "auditor_fn_violation": 0.018498128165602288,
            "auditor_fp_violation": 0.02343560514188698,
            "ave_precision_score": 0.8265534494797162,
            "fpr": 0.1513157894736842,
            "logloss": 0.8442937757580585,
            "mae": 0.3171354083018654,
            "precision": 0.7261904761904762,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8278858577882747,
            "auditor_fn_violation": 0.014597496517816791,
            "auditor_fp_violation": 0.021832771868730845,
            "ave_precision_score": 0.8284506475801316,
            "fpr": 0.13830954994511527,
            "logloss": 0.9659104516663567,
            "mae": 0.31509087946402886,
            "precision": 0.7418032786885246,
            "recall": 0.7605042016806722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7822997760899186,
            "auditor_fn_violation": 0.012102693973427288,
            "auditor_fp_violation": 0.0027235427277872105,
            "ave_precision_score": 0.6576008977243639,
            "fpr": 0.007675438596491228,
            "logloss": 1.5158395190693306,
            "mae": 0.4190787048896966,
            "precision": 0.943089430894309,
            "recall": 0.24267782426778242
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.773837424210379,
            "auditor_fn_violation": 0.006706085288121846,
            "auditor_fp_violation": 0.003600943765219476,
            "ave_precision_score": 0.6465487524401012,
            "fpr": 0.007683863885839737,
            "logloss": 1.512525867459959,
            "mae": 0.4216118597115479,
            "precision": 0.9345794392523364,
            "recall": 0.21008403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7849779535655884,
            "auditor_fn_violation": 0.013130367760405203,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6362919401506036,
            "fpr": 0.013157894736842105,
            "logloss": 0.6266969359280697,
            "mae": 0.44564167305565716,
            "precision": 0.9154929577464789,
            "recall": 0.2719665271966527
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7610241347762218,
            "auditor_fn_violation": 0.007813004455349652,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.607386400097618,
            "fpr": 0.013172338090010977,
            "logloss": 0.6444074342821554,
            "mae": 0.4570893800023097,
            "precision": 0.8983050847457628,
            "recall": 0.22268907563025211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7204182349022016,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.7171726761964292,
            "fpr": 0.01644736842105263,
            "logloss": 1.0659866110843577,
            "mae": 0.41146959886614554,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7051133088508192,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.702685783134134,
            "fpr": 0.015367727771679473,
            "logloss": 1.1011909739606849,
            "mae": 0.4129080721910365,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 29756,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6936262456110792,
            "auditor_fn_violation": 0.06907206562431184,
            "auditor_fp_violation": 0.06912442396313366,
            "ave_precision_score": 0.5650065559774307,
            "fpr": 0.19736842105263158,
            "logloss": 0.6829473321043558,
            "mae": 0.4919833133095189,
            "precision": 0.5973154362416108,
            "recall": 0.5585774058577406
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6868208142165486,
            "auditor_fn_violation": 0.07312584748498742,
            "auditor_fp_violation": 0.06788043958262362,
            "ave_precision_score": 0.5599497133108842,
            "fpr": 0.1964873765093304,
            "logloss": 0.6841493780591412,
            "mae": 0.4926306713949051,
            "precision": 0.591324200913242,
            "recall": 0.5441176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7849779535655884,
            "auditor_fn_violation": 0.013130367760405203,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6362919401506036,
            "fpr": 0.013157894736842105,
            "logloss": 0.626485795439404,
            "mae": 0.4449161317264825,
            "precision": 0.9154929577464789,
            "recall": 0.2719665271966527
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7610241347762218,
            "auditor_fn_violation": 0.007813004455349652,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.607386400097618,
            "fpr": 0.013172338090010977,
            "logloss": 0.6443730774412264,
            "mae": 0.4565136160468427,
            "precision": 0.8983050847457628,
            "recall": 0.22268907563025211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 29756,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7805945727107497,
            "auditor_fn_violation": 0.013559329809880364,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6334417008492568,
            "fpr": 0.013157894736842105,
            "logloss": 0.626479743414365,
            "mae": 0.44485151493235636,
            "precision": 0.916083916083916,
            "recall": 0.27405857740585776
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7574288736996486,
            "auditor_fn_violation": 0.007305666503703573,
            "auditor_fp_violation": 0.002854006586169046,
            "ave_precision_score": 0.6106924918587845,
            "fpr": 0.015367727771679473,
            "logloss": 0.6441280643840556,
            "mae": 0.4564213469444593,
            "precision": 0.8842975206611571,
            "recall": 0.22478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 29756,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8053786320948535,
            "auditor_fn_violation": 0.029040960140938127,
            "auditor_fp_violation": 0.024961597542242704,
            "ave_precision_score": 0.8067447297030955,
            "fpr": 0.1162280701754386,
            "logloss": 1.004740330480134,
            "mae": 0.34482697301568804,
            "precision": 0.7534883720930232,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8064203451168698,
            "auditor_fn_violation": 0.03416921104336356,
            "auditor_fp_violation": 0.02374048979900829,
            "ave_precision_score": 0.8067726830221823,
            "fpr": 0.10208562019758508,
            "logloss": 1.156088260473551,
            "mae": 0.344898563073621,
            "precision": 0.770935960591133,
            "recall": 0.657563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 29756,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7304678385258606,
            "auditor_fn_violation": 0.014545713132202896,
            "auditor_fp_violation": 0.0038377192982456147,
            "ave_precision_score": 0.7210889399885543,
            "fpr": 0.01644736842105263,
            "logloss": 1.0006546733640413,
            "mae": 0.4018211854580751,
            "precision": 0.90625,
            "recall": 0.303347280334728
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7271432549742339,
            "auditor_fn_violation": 0.019919932846903857,
            "auditor_fp_violation": 0.005082200941241783,
            "ave_precision_score": 0.7132928832415931,
            "fpr": 0.015367727771679473,
            "logloss": 1.0248558650270987,
            "mae": 0.3985426690692407,
            "precision": 0.9054054054054054,
            "recall": 0.2815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 29756,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7849779535655884,
            "auditor_fn_violation": 0.013130367760405203,
            "auditor_fp_violation": 0.004385964912280702,
            "ave_precision_score": 0.6362919401506036,
            "fpr": 0.013157894736842105,
            "logloss": 0.626485795439404,
            "mae": 0.4449161317264825,
            "precision": 0.9154929577464789,
            "recall": 0.2719665271966527
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7610241347762218,
            "auditor_fn_violation": 0.007813004455349652,
            "auditor_fp_violation": 0.004587607403762444,
            "ave_precision_score": 0.607386400097618,
            "fpr": 0.013172338090010977,
            "logloss": 0.6443730774412264,
            "mae": 0.4565136160468427,
            "precision": 0.8983050847457628,
            "recall": 0.22268907563025211
        }
    }
]