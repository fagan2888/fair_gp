[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8326351793969915,
            "auditor_fn_violation": 0.012045446255972576,
            "auditor_fp_violation": 0.01700706231937152,
            "ave_precision_score": 0.8329665260678437,
            "fpr": 0.10635964912280702,
            "logloss": 0.8233984149879532,
            "mae": 0.2782630496266337,
            "precision": 0.7775229357798165,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8527955772266048,
            "auditor_fn_violation": 0.012251017050241009,
            "auditor_fp_violation": 0.010901763830203155,
            "ave_precision_score": 0.8530230501724905,
            "fpr": 0.10318331503841932,
            "logloss": 0.71404994212561,
            "mae": 0.2578687880942685,
            "precision": 0.7915742793791575,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8137617697552405,
            "auditor_fn_violation": 0.04091895539263961,
            "auditor_fp_violation": 0.04506299100419262,
            "ave_precision_score": 0.8144269506871629,
            "fpr": 0.17214912280701755,
            "logloss": 0.6948560332839336,
            "mae": 0.31698739724841274,
            "precision": 0.7113970588235294,
            "recall": 0.8045738045738046
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8599459736853674,
            "auditor_fn_violation": 0.04235524004242255,
            "auditor_fp_violation": 0.05190743274739485,
            "ave_precision_score": 0.8601037100995879,
            "fpr": 0.17892425905598244,
            "logloss": 0.6089998640141961,
            "mae": 0.3020407467581207,
            "precision": 0.7047101449275363,
            "recall": 0.8224101479915433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8149845698368914,
            "auditor_fn_violation": 0.0019946565999197684,
            "auditor_fp_violation": 0.0053170920340293885,
            "ave_precision_score": 0.8153490139639572,
            "fpr": 0.07675438596491228,
            "logloss": 0.6110487110517746,
            "mae": 0.3299726851677916,
            "precision": 0.8082191780821918,
            "recall": 0.6133056133056133
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8567098836492317,
            "auditor_fn_violation": 0.004581077411853714,
            "auditor_fp_violation": 0.002862026274503907,
            "ave_precision_score": 0.8569149610745381,
            "fpr": 0.07025246981339188,
            "logloss": 0.5237028004199078,
            "mae": 0.30958312543407573,
            "precision": 0.8306878306878307,
            "recall": 0.6638477801268499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7978892146266646,
            "auditor_fn_violation": 0.015633548528285378,
            "auditor_fp_violation": 0.02443063866161925,
            "ave_precision_score": 0.7992795110411012,
            "fpr": 0.17763157894736842,
            "logloss": 0.9950435675780909,
            "mae": 0.2811956970825536,
            "precision": 0.7112299465240641,
            "recall": 0.8295218295218295
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8460526118202559,
            "auditor_fn_violation": 0.023211720503222302,
            "auditor_fp_violation": 0.030043757424477093,
            "ave_precision_score": 0.846305538635659,
            "fpr": 0.17233809001097694,
            "logloss": 0.8255839699436677,
            "mae": 0.2650214535179134,
            "precision": 0.718132854578097,
            "recall": 0.8456659619450317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8185439206969483,
            "auditor_fn_violation": 0.004796294269978482,
            "auditor_fp_violation": 0.018553852729270993,
            "ave_precision_score": 0.8189408037388184,
            "fpr": 0.2850877192982456,
            "logloss": 1.2898159952706634,
            "mae": 0.3200073035595926,
            "precision": 0.6373779637377964,
            "recall": 0.9501039501039501
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.8622795118520192,
            "auditor_fn_violation": 0.0052633655370234135,
            "auditor_fp_violation": 0.022224561297986563,
            "ave_precision_score": 0.8624826992354163,
            "fpr": 0.3194291986827662,
            "logloss": 1.2945409493639015,
            "mae": 0.33582390314549565,
            "precision": 0.6109625668449198,
            "recall": 0.9661733615221987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8247635206990542,
            "auditor_fn_violation": 0.01204772586351534,
            "auditor_fp_violation": 0.0291396995970204,
            "ave_precision_score": 0.8252701208157829,
            "fpr": 0.20175438596491227,
            "logloss": 0.9572907344602728,
            "mae": 0.27842256136182625,
            "precision": 0.6963696369636964,
            "recall": 0.8773388773388774
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.855823944391287,
            "auditor_fn_violation": 0.021255363736154075,
            "auditor_fp_violation": 0.03599837601311219,
            "ave_precision_score": 0.856078145084117,
            "fpr": 0.19978046103183314,
            "logloss": 0.8543880079142359,
            "mae": 0.27226210805476986,
            "precision": 0.697171381031614,
            "recall": 0.8858350951374208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7823127073038523,
            "auditor_fn_violation": 0.012599390888864583,
            "auditor_fp_violation": 0.008082488704359512,
            "ave_precision_score": 0.7816230715680952,
            "fpr": 0.125,
            "logloss": 1.6744365656951998,
            "mae": 0.33566241259981516,
            "precision": 0.7397260273972602,
            "recall": 0.6735966735966736
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8273052841765429,
            "auditor_fn_violation": 0.02058932056634556,
            "auditor_fp_violation": 0.010736357758296629,
            "ave_precision_score": 0.8269477194934161,
            "fpr": 0.1119648737650933,
            "logloss": 1.069148294160931,
            "mae": 0.3040832311980941,
            "precision": 0.7707865168539326,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8334354305685199,
            "auditor_fn_violation": 0.015530966188860932,
            "auditor_fp_violation": 0.017582020596735463,
            "ave_precision_score": 0.8337892377092366,
            "fpr": 0.10855263157894737,
            "logloss": 0.8162540234147513,
            "mae": 0.27730191487806954,
            "precision": 0.7744874715261959,
            "recall": 0.7068607068607069
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8566490316499208,
            "auditor_fn_violation": 0.017753415501864697,
            "auditor_fp_violation": 0.012721230621174985,
            "ave_precision_score": 0.8568695246874389,
            "fpr": 0.09659714599341383,
            "logloss": 0.6982513598726988,
            "mae": 0.25626233491752093,
            "precision": 0.8009049773755657,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7916495771674722,
            "auditor_fn_violation": 0.03015008936061568,
            "auditor_fp_violation": 0.029121891154801165,
            "ave_precision_score": 0.7931772498331872,
            "fpr": 0.12609649122807018,
            "logloss": 1.6665176347016253,
            "mae": 0.2889562828190043,
            "precision": 0.7505422993492408,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8156385912266889,
            "auditor_fn_violation": 0.03586189931376667,
            "auditor_fp_violation": 0.03196848262484399,
            "ave_precision_score": 0.8159833320830114,
            "fpr": 0.13172338090010977,
            "logloss": 1.7224950556041183,
            "mae": 0.26812842087773836,
            "precision": 0.7478991596638656,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.820023509042864,
            "auditor_fn_violation": 0.009836506547032869,
            "auditor_fp_violation": 0.02199088207758375,
            "ave_precision_score": 0.8205269306943759,
            "fpr": 0.125,
            "logloss": 0.9156882520635264,
            "mae": 0.2804112956902897,
            "precision": 0.7553648068669528,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8362614099746871,
            "auditor_fn_violation": 0.012568954033738453,
            "auditor_fp_violation": 0.015598293811306762,
            "ave_precision_score": 0.836563652964472,
            "fpr": 0.13611416026344675,
            "logloss": 0.8044892658195616,
            "mae": 0.26344313021938986,
            "precision": 0.75,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.824784113878328,
            "auditor_fn_violation": 0.012079640369114058,
            "auditor_fp_violation": 0.006520433915414989,
            "ave_precision_score": 0.8251514696336921,
            "fpr": 0.05921052631578947,
            "logloss": 1.0492035896058864,
            "mae": 0.3252324721984851,
            "precision": 0.8235294117647058,
            "recall": 0.5239085239085239
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8642884064407499,
            "auditor_fn_violation": 0.021979424603681113,
            "auditor_fp_violation": 0.007879343789002,
            "ave_precision_score": 0.8644490918742711,
            "fpr": 0.043907793633369926,
            "logloss": 0.8587771632949677,
            "mae": 0.2955783468811555,
            "precision": 0.873015873015873,
            "recall": 0.5813953488372093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8209605270528346,
            "auditor_fn_violation": 0.02215778531568006,
            "auditor_fp_violation": 0.029083730207188505,
            "ave_precision_score": 0.8215940464925888,
            "fpr": 0.11074561403508772,
            "logloss": 0.9323148433855871,
            "mae": 0.28025219277207314,
            "precision": 0.7720090293453724,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8468933733257582,
            "auditor_fn_violation": 0.027600179158650557,
            "auditor_fp_violation": 0.022029081394824304,
            "ave_precision_score": 0.8471503736993593,
            "fpr": 0.10537870472008781,
            "logloss": 0.7956105461740499,
            "mae": 0.26250803062399447,
            "precision": 0.7876106194690266,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7886632050733264,
            "auditor_fn_violation": 0.01246945325892694,
            "auditor_fp_violation": 0.01633797370456304,
            "ave_precision_score": 0.7892745675592152,
            "fpr": 0.13157894736842105,
            "logloss": 1.0019042912482876,
            "mae": 0.3025848920202105,
            "precision": 0.7345132743362832,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8326693847336208,
            "auditor_fn_violation": 0.009008988101730552,
            "auditor_fp_violation": 0.012758822910244655,
            "ave_precision_score": 0.8329265408243027,
            "fpr": 0.1350164654226125,
            "logloss": 0.801331186357262,
            "mae": 0.27278177464896414,
            "precision": 0.7448132780082988,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8512989395581766,
            "auditor_fn_violation": 0.011557610241820771,
            "auditor_fp_violation": 0.004790470956974803,
            "ave_precision_score": 0.851851371108442,
            "fpr": 0.0712719298245614,
            "logloss": 0.5615890240608189,
            "mae": 0.2957442895319872,
            "precision": 0.8275862068965517,
            "recall": 0.6486486486486487
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8852667942156107,
            "auditor_fn_violation": 0.011868100245298835,
            "auditor_fp_violation": 0.008638708028209258,
            "ave_precision_score": 0.8854566510956711,
            "fpr": 0.05817782656421515,
            "logloss": 0.47388220360068706,
            "mae": 0.2746475695943052,
            "precision": 0.8626943005181347,
            "recall": 0.7040169133192389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7802816396079335,
            "auditor_fn_violation": 0.0070827406353722285,
            "auditor_fp_violation": 0.014104286237635858,
            "ave_precision_score": 0.7808999269822259,
            "fpr": 0.12938596491228072,
            "logloss": 1.0643852503689828,
            "mae": 0.30856403303131497,
            "precision": 0.7336343115124153,
            "recall": 0.6756756756756757
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.826706661053779,
            "auditor_fn_violation": 0.010638125053666368,
            "auditor_fp_violation": 0.0073229779107709435,
            "ave_precision_score": 0.8269667272990002,
            "fpr": 0.132821075740944,
            "logloss": 0.8455696543072173,
            "mae": 0.27724867913507567,
            "precision": 0.7430997876857749,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8217028230105452,
            "auditor_fn_violation": 0.015576558339716237,
            "auditor_fp_violation": 0.0045004477551186545,
            "ave_precision_score": 0.822049327759755,
            "fpr": 0.03837719298245614,
            "logloss": 1.1290068534712305,
            "mae": 0.3477059508251358,
            "precision": 0.8643410852713178,
            "recall": 0.46361746361746364
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8559023804152897,
            "auditor_fn_violation": 0.016268162440270788,
            "auditor_fp_violation": 0.0022179450551102963,
            "ave_precision_score": 0.8560741808366054,
            "fpr": 0.02305159165751921,
            "logloss": 0.973366035750722,
            "mae": 0.3247019655566343,
            "precision": 0.9142857142857143,
            "recall": 0.47357293868921774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8283769978614106,
            "auditor_fn_violation": 0.017505106320895802,
            "auditor_fp_violation": 0.02306447673708634,
            "ave_precision_score": 0.8288885345324172,
            "fpr": 0.13706140350877194,
            "logloss": 0.8038397135496153,
            "mae": 0.27221471044004925,
            "precision": 0.749498997995992,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8499053749448704,
            "auditor_fn_violation": 0.014768985131224429,
            "auditor_fp_violation": 0.02307665318356566,
            "ave_precision_score": 0.8502019597978535,
            "fpr": 0.14709110867178923,
            "logloss": 0.7045283177548051,
            "mae": 0.2553573180824801,
            "precision": 0.7428023032629558,
            "recall": 0.8181818181818182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8253374730593503,
            "auditor_fn_violation": 0.011217948717948721,
            "auditor_fp_violation": 0.021683050433508374,
            "ave_precision_score": 0.8257701062719821,
            "fpr": 0.13157894736842105,
            "logloss": 0.8713651763725151,
            "mae": 0.27994591085216675,
            "precision": 0.7473684210526316,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.838596703681451,
            "auditor_fn_violation": 0.011343620257923478,
            "auditor_fp_violation": 0.021853650712499187,
            "ave_precision_score": 0.8388960327421966,
            "fpr": 0.132821075740944,
            "logloss": 0.7843843184852696,
            "mae": 0.2599300334602358,
            "precision": 0.7550607287449392,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7916028822678656,
            "auditor_fn_violation": 0.028882627566838102,
            "auditor_fp_violation": 0.030292160214922467,
            "ave_precision_score": 0.7919244677105827,
            "fpr": 0.12609649122807018,
            "logloss": 1.71712167888196,
            "mae": 0.2895666326579339,
            "precision": 0.7478070175438597,
            "recall": 0.7089397089397089
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8145384506349966,
            "auditor_fn_violation": 0.036442076290951794,
            "auditor_fp_violation": 0.030665283270428913,
            "ave_precision_score": 0.8149500871899314,
            "fpr": 0.12294182217343579,
            "logloss": 1.7558952205066782,
            "mae": 0.2677529706579909,
            "precision": 0.7591397849462366,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.821540092554859,
            "auditor_fn_violation": 0.010529507240033558,
            "auditor_fp_violation": 0.019838604632230226,
            "ave_precision_score": 0.8219887272834855,
            "fpr": 0.11842105263157894,
            "logloss": 0.8729850554297485,
            "mae": 0.2832779861061393,
            "precision": 0.7615894039735099,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8371447909118159,
            "auditor_fn_violation": 0.007783654325915585,
            "auditor_fp_violation": 0.011277686720899816,
            "ave_precision_score": 0.8374711340796562,
            "fpr": 0.11525795828759605,
            "logloss": 0.7512294383832193,
            "mae": 0.2615562835926812,
            "precision": 0.7746781115879828,
            "recall": 0.7632135306553911
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 10132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8273272711056237,
            "auditor_fn_violation": 0.01688049385417807,
            "auditor_fp_violation": 0.025399926730980585,
            "ave_precision_score": 0.8278123647175529,
            "fpr": 0.12609649122807018,
            "logloss": 0.8732889554149745,
            "mae": 0.2712755531678346,
            "precision": 0.7589098532494759,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8450111773503577,
            "auditor_fn_violation": 0.019452173691062728,
            "auditor_fp_violation": 0.024044028088958395,
            "ave_precision_score": 0.8453341835127104,
            "fpr": 0.13062568605927552,
            "logloss": 0.7590034634735433,
            "mae": 0.25634953965119167,
            "precision": 0.7586206896551724,
            "recall": 0.7906976744186046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.831939288560011,
            "auditor_fn_violation": 0.014999817631396583,
            "auditor_fp_violation": 0.016121728334758008,
            "ave_precision_score": 0.8326990848496009,
            "fpr": 0.1074561403508772,
            "logloss": 0.8212539398684542,
            "mae": 0.2862814530175947,
            "precision": 0.7757437070938215,
            "recall": 0.7047817047817048
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8734747069844,
            "auditor_fn_violation": 0.010324829485986411,
            "auditor_fp_violation": 0.012834007488383982,
            "ave_precision_score": 0.8736233426770276,
            "fpr": 0.0889132821075741,
            "logloss": 0.674528388561748,
            "mae": 0.26037611669235483,
            "precision": 0.8137931034482758,
            "recall": 0.7484143763213531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8286137621124459,
            "auditor_fn_violation": 0.01168298865667287,
            "auditor_fp_violation": 0.02123529531485327,
            "ave_precision_score": 0.8291153574018505,
            "fpr": 0.13486842105263158,
            "logloss": 0.833719508361224,
            "mae": 0.2727558208034053,
            "precision": 0.7479508196721312,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8489619911365476,
            "auditor_fn_violation": 0.013520444276322055,
            "auditor_fp_violation": 0.023788400523284667,
            "ave_precision_score": 0.8492374280872121,
            "fpr": 0.141602634467618,
            "logloss": 0.7301447264958048,
            "mae": 0.2554410570772258,
            "precision": 0.7504835589941973,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7980714753904706,
            "auditor_fn_violation": 0.016714082503556195,
            "auditor_fp_violation": 0.025460984247160836,
            "ave_precision_score": 0.7986043911525949,
            "fpr": 0.14364035087719298,
            "logloss": 0.9659967203542238,
            "mae": 0.2978294181602067,
            "precision": 0.7282157676348547,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8073771593900223,
            "auditor_fn_violation": 0.017799829660039495,
            "auditor_fp_violation": 0.02269070568245042,
            "ave_precision_score": 0.8080111219974466,
            "fpr": 0.1394072447859495,
            "logloss": 0.858156298195156,
            "mae": 0.27708260495405146,
            "precision": 0.7413441955193483,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.822719405614899,
            "auditor_fn_violation": 0.0032005689900426746,
            "auditor_fp_violation": 0.00025949444376603155,
            "ave_precision_score": 0.8230898373719381,
            "fpr": 0.08223684210526316,
            "logloss": 0.5845549535372337,
            "mae": 0.3287072758672334,
            "precision": 0.805699481865285,
            "recall": 0.6465696465696466
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8641296080600801,
            "auditor_fn_violation": 0.00980499091442854,
            "auditor_fp_violation": 0.010360434867599957,
            "ave_precision_score": 0.8643199342210899,
            "fpr": 0.07903402854006586,
            "logloss": 0.5075773618208517,
            "mae": 0.31124385087224365,
            "precision": 0.8181818181818182,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.8200489611486175,
            "auditor_fn_violation": 0.007039428092059671,
            "auditor_fp_violation": 0.015900394838604642,
            "ave_precision_score": 0.8202190215402589,
            "fpr": 0.34649122807017546,
            "logloss": 1.8737871157625785,
            "mae": 0.3580884414083861,
            "precision": 0.5959079283887468,
            "recall": 0.9688149688149689
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.8546027825166007,
            "auditor_fn_violation": 0.004850279529267609,
            "auditor_fp_violation": 0.021166964898826635,
            "ave_precision_score": 0.8545127261047325,
            "fpr": 0.3578485181119649,
            "logloss": 1.9269496286221892,
            "mae": 0.37268770281324665,
            "precision": 0.5857687420584498,
            "recall": 0.9746300211416491
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7988639373527124,
            "auditor_fn_violation": 0.02284850640113799,
            "auditor_fp_violation": 0.022537855660031754,
            "ave_precision_score": 0.7998250529163266,
            "fpr": 0.1206140350877193,
            "logloss": 1.0092144110279164,
            "mae": 0.2892576509005787,
            "precision": 0.7544642857142857,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8388856599956661,
            "auditor_fn_violation": 0.027939002513326667,
            "auditor_fp_violation": 0.020996546521710804,
            "ave_precision_score": 0.8391559218790712,
            "fpr": 0.10976948408342481,
            "logloss": 0.8452215827828351,
            "mae": 0.26405205902010076,
            "precision": 0.7777777777777778,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8243853756881596,
            "auditor_fn_violation": 0.020033191085822667,
            "auditor_fp_violation": 0.008769385761387229,
            "ave_precision_score": 0.8247217106766058,
            "fpr": 0.046052631578947366,
            "logloss": 1.0632563391199683,
            "mae": 0.3390648479113194,
            "precision": 0.8478260869565217,
            "recall": 0.4864864864864865
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8615587039147987,
            "auditor_fn_violation": 0.016955091981257973,
            "auditor_fp_violation": 0.003638933581943671,
            "ave_precision_score": 0.8617258683614553,
            "fpr": 0.029637760702524697,
            "logloss": 0.89620729158532,
            "mae": 0.31464729997726976,
            "precision": 0.8984962406015038,
            "recall": 0.5052854122621564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6518262765703359,
            "auditor_fn_violation": 0.008060692271218587,
            "auditor_fp_violation": 0.033428990108682395,
            "ave_precision_score": 0.6342933377201792,
            "fpr": 0.31469298245614036,
            "logloss": 3.5176026894355585,
            "mae": 0.34246122234399956,
            "precision": 0.6132075471698113,
            "recall": 0.9459459459459459
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6567717043906621,
            "auditor_fn_violation": 0.007567828490402713,
            "auditor_fp_violation": 0.035938228350600725,
            "ave_precision_score": 0.6435878702502814,
            "fpr": 0.3391877058177827,
            "logloss": 3.5586273540588387,
            "mae": 0.3560726972835156,
            "precision": 0.5955497382198953,
            "recall": 0.9619450317124736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8226426453517556,
            "auditor_fn_violation": 0.010105500237079193,
            "auditor_fp_violation": 0.017803354092888836,
            "ave_precision_score": 0.8232247066686988,
            "fpr": 0.11293859649122807,
            "logloss": 0.8678965633859259,
            "mae": 0.28623435636871764,
            "precision": 0.765375854214123,
            "recall": 0.6985446985446986
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8377970259962727,
            "auditor_fn_violation": 0.00966806914781285,
            "auditor_fp_violation": 0.006200221543890252,
            "ave_precision_score": 0.8381381019360366,
            "fpr": 0.10318331503841932,
            "logloss": 0.7406562373302491,
            "mae": 0.26145276475798157,
            "precision": 0.7911111111111111,
            "recall": 0.7526427061310782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8202541593422805,
            "auditor_fn_violation": 0.012435259145785466,
            "auditor_fp_violation": 0.02471557373712704,
            "ave_precision_score": 0.8207650326004208,
            "fpr": 0.13596491228070176,
            "logloss": 0.9395661323052333,
            "mae": 0.2802904398029242,
            "precision": 0.7427385892116183,
            "recall": 0.7442827442827443
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.830611513398053,
            "auditor_fn_violation": 0.014369823370921067,
            "auditor_fp_violation": 0.02190878606980136,
            "ave_precision_score": 0.8310131406678005,
            "fpr": 0.13611416026344675,
            "logloss": 0.8281189183926926,
            "mae": 0.25810376722998896,
            "precision": 0.7524950099800399,
            "recall": 0.7970401691331924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7972881691764202,
            "auditor_fn_violation": 0.022647900937374624,
            "auditor_fp_violation": 0.033271258191883424,
            "ave_precision_score": 0.7977129202583482,
            "fpr": 0.13157894736842105,
            "logloss": 1.9316451315246606,
            "mae": 0.29142361277140866,
            "precision": 0.7430406852248393,
            "recall": 0.7214137214137214
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8245339579231556,
            "auditor_fn_violation": 0.03726592759855467,
            "auditor_fp_violation": 0.03505105032855661,
            "ave_precision_score": 0.8244433160032324,
            "fpr": 0.1350164654226125,
            "logloss": 2.089651936498412,
            "mae": 0.27498550868880467,
            "precision": 0.74375,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8330155229150173,
            "auditor_fn_violation": 0.014165481270744438,
            "auditor_fp_violation": 0.01958928644116091,
            "ave_precision_score": 0.8333581607793313,
            "fpr": 0.10526315789473684,
            "logloss": 0.8076693532955973,
            "mae": 0.2776028423536076,
            "precision": 0.7788018433179723,
            "recall": 0.7027027027027027
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8541226514562505,
            "auditor_fn_violation": 0.014390709742099736,
            "auditor_fp_violation": 0.008936940188161942,
            "ave_precision_score": 0.8543569093858938,
            "fpr": 0.10318331503841932,
            "logloss": 0.6981726763875277,
            "mae": 0.2569209806681962,
            "precision": 0.7924944812362031,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 10132,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6685275809635678,
            "auditor_fn_violation": 0.00863515337199548,
            "auditor_fp_violation": 0.025336325151626173,
            "ave_precision_score": 0.6487179365001736,
            "fpr": 0.3475877192982456,
            "logloss": 3.7935182274524415,
            "mae": 0.3658917037838412,
            "precision": 0.5930680359435173,
            "recall": 0.9604989604989606
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6737224084620236,
            "auditor_fn_violation": 0.004311875294439816,
            "auditor_fp_violation": 0.02729200186457756,
            "ave_precision_score": 0.6560661349077723,
            "fpr": 0.36882546652030734,
            "logloss": 3.878387865498578,
            "mae": 0.3804555405550791,
            "precision": 0.58,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7974278736646006,
            "auditor_fn_violation": 0.01698763540868804,
            "auditor_fp_violation": 0.02094272804982293,
            "ave_precision_score": 0.79708595014034,
            "fpr": 0.10964912280701754,
            "logloss": 3.11692237656465,
            "mae": 0.3014605134796924,
            "precision": 0.7601918465227818,
            "recall": 0.659043659043659
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.809022918170268,
            "auditor_fn_violation": 0.02079354286231472,
            "auditor_fp_violation": 0.018385135507671336,
            "ave_precision_score": 0.8072567336956842,
            "fpr": 0.10647639956092206,
            "logloss": 3.284558476356826,
            "mae": 0.28432112356099243,
            "precision": 0.7690476190476191,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.828405978150909,
            "auditor_fn_violation": 0.011958821169347489,
            "auditor_fp_violation": 0.015284731550453862,
            "ave_precision_score": 0.8288402219072651,
            "fpr": 0.1206140350877193,
            "logloss": 0.8651804117027557,
            "mae": 0.2754369415530919,
            "precision": 0.7629310344827587,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8439345134064845,
            "auditor_fn_violation": 0.009904781354504379,
            "auditor_fp_violation": 0.017137071510558422,
            "ave_precision_score": 0.8442137195977523,
            "fpr": 0.12952799121844127,
            "logloss": 0.7657121338961267,
            "mae": 0.25809849376896615,
            "precision": 0.7591836734693878,
            "recall": 0.7864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7762923780624382,
            "auditor_fn_violation": 0.015273370536528441,
            "auditor_fp_violation": 0.024311067692432936,
            "ave_precision_score": 0.775089947875155,
            "fpr": 0.14912280701754385,
            "logloss": 3.3639647103195274,
            "mae": 0.3164811922334674,
            "precision": 0.7068965517241379,
            "recall": 0.681912681912682
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7786776151395098,
            "auditor_fn_violation": 0.012854401106513532,
            "auditor_fp_violation": 0.017939040344044633,
            "ave_precision_score": 0.7764982985424072,
            "fpr": 0.14818880351262348,
            "logloss": 2.817903599655153,
            "mae": 0.29325716930838697,
            "precision": 0.7204968944099379,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8143143831062417,
            "auditor_fn_violation": 0.017318178502389044,
            "auditor_fp_violation": 0.015134631823177433,
            "ave_precision_score": 0.8148664229944269,
            "fpr": 0.08442982456140351,
            "logloss": 1.082338545922649,
            "mae": 0.2974956241700206,
            "precision": 0.7941176470588235,
            "recall": 0.6174636174636174
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8345006010614144,
            "auditor_fn_violation": 0.02548601425378799,
            "auditor_fp_violation": 0.013172338090010975,
            "ave_precision_score": 0.8348939183420835,
            "fpr": 0.08232711306256861,
            "logloss": 0.9169647881458484,
            "mae": 0.27185584910126975,
            "precision": 0.8076923076923077,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.5511016979112711,
            "auditor_fn_violation": 0.009898055950687535,
            "auditor_fp_violation": 0.009390137175886363,
            "ave_precision_score": 0.5492822805772087,
            "fpr": 0.3190789473684211,
            "logloss": 3.0270176331642316,
            "mae": 0.41833679145723823,
            "precision": 0.5842857142857143,
            "recall": 0.8503118503118503
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5996662219339687,
            "auditor_fn_violation": 0.014232901604305377,
            "auditor_fp_violation": 0.018420221644136356,
            "ave_precision_score": 0.6009151379860322,
            "fpr": 0.3358946212952799,
            "logloss": 2.7128258178133953,
            "mae": 0.42074802195310745,
            "precision": 0.5609756097560976,
            "recall": 0.8266384778012685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8249129679415815,
            "auditor_fn_violation": 0.006401137980085353,
            "auditor_fp_violation": 0.01985132494810111,
            "ave_precision_score": 0.8252884835408056,
            "fpr": 0.1162280701754386,
            "logloss": 0.7980488833621862,
            "mae": 0.2812544759272,
            "precision": 0.7680525164113785,
            "recall": 0.7297297297297297
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8439105268182701,
            "auditor_fn_violation": 0.008203702457397608,
            "auditor_fp_violation": 0.007879343789002007,
            "ave_precision_score": 0.8442042891295312,
            "fpr": 0.1251372118551043,
            "logloss": 0.6897971701893093,
            "mae": 0.2609282101999752,
            "precision": 0.762993762993763,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8454703059607808,
            "auditor_fn_violation": 0.02676259255206624,
            "auditor_fp_violation": 0.020118451581389668,
            "ave_precision_score": 0.845957661762171,
            "fpr": 0.10964912280701754,
            "logloss": 0.5023511140887061,
            "mae": 0.29729650690926956,
            "precision": 0.791231732776618,
            "recall": 0.7879417879417879
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8822815645412253,
            "auditor_fn_violation": 0.02716156536389861,
            "auditor_fp_violation": 0.025191845981885532,
            "ave_precision_score": 0.8824354455599144,
            "fpr": 0.10647639956092206,
            "logloss": 0.45855244368663933,
            "mae": 0.2856936938324626,
            "precision": 0.7983367983367984,
            "recall": 0.8118393234672304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8147692774470332,
            "auditor_fn_violation": 0.019410858226647704,
            "auditor_fp_violation": 0.028697032604713645,
            "ave_precision_score": 0.8153169807671585,
            "fpr": 0.16557017543859648,
            "logloss": 0.9671584448253062,
            "mae": 0.27485261564506946,
            "precision": 0.7208872458410351,
            "recall": 0.8108108108108109
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.829349680557154,
            "auditor_fn_violation": 0.019607661120948337,
            "auditor_fp_violation": 0.02934704700038596,
            "ave_precision_score": 0.8297706929747649,
            "fpr": 0.1734357848518112,
            "logloss": 0.9089621636648004,
            "mae": 0.2656158118026732,
            "precision": 0.7173524150268337,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8043220342209241,
            "auditor_fn_violation": 0.012239212897107636,
            "auditor_fp_violation": 0.0201489803394798,
            "ave_precision_score": 0.8046741831920775,
            "fpr": 0.14912280701754385,
            "logloss": 0.9247679496238453,
            "mae": 0.29113610788395994,
            "precision": 0.728,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8168443311358776,
            "auditor_fn_violation": 0.008173533254583986,
            "auditor_fp_violation": 0.018853786044739838,
            "ave_precision_score": 0.8172413533609062,
            "fpr": 0.15916575192096596,
            "logloss": 0.8282013355153874,
            "mae": 0.2715825552433647,
            "precision": 0.7248576850094877,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7875432504503722,
            "auditor_fn_violation": 0.026689645110697744,
            "auditor_fp_violation": 0.03221038384825172,
            "ave_precision_score": 0.7884412369892144,
            "fpr": 0.14912280701754385,
            "logloss": 1.0800286956750202,
            "mae": 0.2929041698696892,
            "precision": 0.7263581488933601,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8310094235112628,
            "auditor_fn_violation": 0.03444394678152624,
            "auditor_fp_violation": 0.03250730543484254,
            "ave_precision_score": 0.8313829685826304,
            "fpr": 0.150384193194292,
            "logloss": 0.8903008164948731,
            "mae": 0.2660680673214439,
            "precision": 0.7355212355212355,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8311836726398855,
            "auditor_fn_violation": 0.0062803187803187836,
            "auditor_fp_violation": 0.01702232669841658,
            "ave_precision_score": 0.8316256969204718,
            "fpr": 0.10416666666666667,
            "logloss": 0.7744521643265826,
            "mae": 0.2840370713050969,
            "precision": 0.7769953051643192,
            "recall": 0.6881496881496881
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8543468723029481,
            "auditor_fn_violation": 0.009324604377319258,
            "auditor_fp_violation": 0.008315414342210128,
            "ave_precision_score": 0.8545992355588459,
            "fpr": 0.09769484083424808,
            "logloss": 0.6528164729145423,
            "mae": 0.2561758950596171,
            "precision": 0.8013392857142857,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8438953019293235,
            "auditor_fn_violation": 0.011523416128679288,
            "auditor_fp_violation": 0.01135924207269915,
            "ave_precision_score": 0.8442126614232397,
            "fpr": 0.08114035087719298,
            "logloss": 0.5217874930763319,
            "mae": 0.3121140764940943,
            "precision": 0.8102564102564103,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8807258319837207,
            "auditor_fn_violation": 0.008899914830019754,
            "auditor_fp_violation": 0.00856853575527921,
            "ave_precision_score": 0.8809021912155086,
            "fpr": 0.07354555433589462,
            "logloss": 0.46334898614349385,
            "mae": 0.294056442572861,
            "precision": 0.8349753694581281,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 10132,
        "test": {
            "accuracy": 0.49122807017543857,
            "auc_prc": 0.6652578496908644,
            "auditor_fn_violation": 0.014192836561257615,
            "auditor_fp_violation": 0.016549130948019707,
            "ave_precision_score": 0.5979496440369183,
            "fpr": 0.3881578947368421,
            "logloss": 10.159413764181277,
            "mae": 0.5050190485082036,
            "precision": 0.5117241379310344,
            "recall": 0.7713097713097713
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.66960066734837,
            "auditor_fn_violation": 0.010870195844540428,
            "auditor_fp_violation": 0.00943817070909083,
            "ave_precision_score": 0.6017907220286329,
            "fpr": 0.39626783754116357,
            "logloss": 10.849938339711175,
            "mae": 0.5250183378299164,
            "precision": 0.49297752808988765,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.555197325462833,
            "auditor_fn_violation": 0.006774993617098881,
            "auditor_fp_violation": 0.013119733789229456,
            "ave_precision_score": 0.5534614360548956,
            "fpr": 0.36622807017543857,
            "logloss": 3.2357823219124224,
            "mae": 0.4310952802155071,
            "precision": 0.5611038107752957,
            "recall": 0.8877338877338877
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6056952600398042,
            "auditor_fn_violation": 0.007170987438008094,
            "auditor_fp_violation": 0.008831681778766892,
            "ave_precision_score": 0.6069450724690149,
            "fpr": 0.38309549945115257,
            "logloss": 2.891957125119794,
            "mae": 0.4445484597026363,
            "precision": 0.5413929040735874,
            "recall": 0.8710359408033826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 10132,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.852778748377921,
            "auditor_fn_violation": 0.004101013969435029,
            "auditor_fp_violation": 0.004454654617983477,
            "ave_precision_score": 0.8532201279800791,
            "fpr": 0.051535087719298246,
            "logloss": 0.5560029500026795,
            "mae": 0.3049264541298191,
            "precision": 0.8645533141210374,
            "recall": 0.6237006237006237
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8908291985620782,
            "auditor_fn_violation": 0.004968635632613381,
            "auditor_fp_violation": 0.0068869073575628156,
            "ave_precision_score": 0.8909692002957859,
            "fpr": 0.052689352360043906,
            "logloss": 0.47555389897794365,
            "mae": 0.2867051956608681,
            "precision": 0.8706199460916442,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8279372465516981,
            "auditor_fn_violation": 0.005452821242294928,
            "auditor_fp_violation": 0.01888966906826231,
            "ave_precision_score": 0.8283514228034354,
            "fpr": 0.2576754385964912,
            "logloss": 1.3109533770521824,
            "mae": 0.30685661420074994,
            "precision": 0.6549192364170338,
            "recall": 0.9272349272349273
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.855469973674006,
            "auditor_fn_violation": 0.0063007219722304095,
            "auditor_fp_violation": 0.02609406091955752,
            "ave_precision_score": 0.8556045847735405,
            "fpr": 0.300768386388584,
            "logloss": 1.3552135911936125,
            "mae": 0.3213506700075101,
            "precision": 0.6231086657496562,
            "recall": 0.9577167019027484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8264756892105947,
            "auditor_fn_violation": 0.007912517780938847,
            "auditor_fp_violation": 0.013623458297716454,
            "ave_precision_score": 0.8268646202274266,
            "fpr": 0.10855263157894737,
            "logloss": 0.8028972175919585,
            "mae": 0.2849856276317013,
            "precision": 0.7724137931034483,
            "recall": 0.6985446985446986
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8458291261464355,
            "auditor_fn_violation": 0.009015950225456775,
            "auditor_fp_violation": 0.010205053406112007,
            "ave_precision_score": 0.8461190700673751,
            "fpr": 0.09769484083424808,
            "logloss": 0.6837371259110687,
            "mae": 0.25975603617517573,
            "precision": 0.8008948545861297,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.746146136865343,
            "auditor_fn_violation": 0.005363916548127074,
            "auditor_fp_violation": 0.009438474376195716,
            "ave_precision_score": 0.743113845395999,
            "fpr": 0.13815789473684212,
            "logloss": 1.4285128859788572,
            "mae": 0.29840764309879847,
            "precision": 0.7352941176470589,
            "recall": 0.7276507276507277
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7933085406344059,
            "auditor_fn_violation": 0.00909717500226269,
            "auditor_fp_violation": 0.009946919687833632,
            "ave_precision_score": 0.7884113196055288,
            "fpr": 0.1350164654226125,
            "logloss": 1.1348169074108914,
            "mae": 0.2680430955145861,
            "precision": 0.75,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8006142276783386,
            "auditor_fn_violation": 0.020350056534267063,
            "auditor_fp_violation": 0.021688138559856716,
            "ave_precision_score": 0.8011693564106972,
            "fpr": 0.11403508771929824,
            "logloss": 0.9691316849267216,
            "mae": 0.303161218974152,
            "precision": 0.7570093457943925,
            "recall": 0.6735966735966736
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8073915606436877,
            "auditor_fn_violation": 0.020329401280566636,
            "auditor_fp_violation": 0.019846222476179023,
            "ave_precision_score": 0.8078371550749912,
            "fpr": 0.11745334796926454,
            "logloss": 0.8579333736499416,
            "mae": 0.28404982694807207,
            "precision": 0.7579185520361991,
            "recall": 0.7082452431289641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8244888689326767,
            "auditor_fn_violation": 0.008559926323084227,
            "auditor_fp_violation": 0.015185513086660975,
            "ave_precision_score": 0.824876719144781,
            "fpr": 0.10087719298245613,
            "logloss": 0.8800828190004288,
            "mae": 0.2895663219879139,
            "precision": 0.7772397094430993,
            "recall": 0.6673596673596673
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.837684476496178,
            "auditor_fn_violation": 0.011480542024539167,
            "auditor_fp_violation": 0.007688876191049028,
            "ave_precision_score": 0.8380115892193093,
            "fpr": 0.09110867178924259,
            "logloss": 0.751726768506859,
            "mae": 0.2630960202607645,
            "precision": 0.8051643192488263,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8231792042113143,
            "auditor_fn_violation": 0.013693602509391988,
            "auditor_fp_violation": 0.028684312288842762,
            "ave_precision_score": 0.8236396340242216,
            "fpr": 0.21600877192982457,
            "logloss": 1.018055740790109,
            "mae": 0.2853630157349391,
            "precision": 0.6832797427652733,
            "recall": 0.8835758835758836
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8544568649332709,
            "auditor_fn_violation": 0.017635059398518928,
            "auditor_fp_violation": 0.03518638256920741,
            "ave_precision_score": 0.8547169584384231,
            "fpr": 0.21844127332601537,
            "logloss": 0.9095532081290774,
            "mae": 0.2796954462111921,
            "precision": 0.682615629984051,
            "recall": 0.904862579281184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8270162973097002,
            "auditor_fn_violation": 0.008799285115074598,
            "auditor_fp_violation": 0.01985132494810111,
            "ave_precision_score": 0.8275070326568044,
            "fpr": 0.1162280701754386,
            "logloss": 0.8533265833501354,
            "mae": 0.2847588484499201,
            "precision": 0.7654867256637168,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8573706546226053,
            "auditor_fn_violation": 0.00717330814591683,
            "auditor_fp_violation": 0.0066212551814705135,
            "ave_precision_score": 0.8575910138900027,
            "fpr": 0.1163556531284303,
            "logloss": 0.6955160175340414,
            "mae": 0.2602148669547977,
            "precision": 0.7739872068230277,
            "recall": 0.7674418604651163
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7441194324744831,
            "auditor_fn_violation": 0.06821041689462744,
            "auditor_fp_violation": 0.06396029226197746,
            "ave_precision_score": 0.7437233481777441,
            "fpr": 0.20065789473684212,
            "logloss": 2.1332274948395558,
            "mae": 0.35224754719327817,
            "precision": 0.6514285714285715,
            "recall": 0.7110187110187111
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7783809691261842,
            "auditor_fn_violation": 0.06889253497886996,
            "auditor_fp_violation": 0.06112506202727696,
            "ave_precision_score": 0.7782071019862326,
            "fpr": 0.1734357848518112,
            "logloss": 1.56344198543948,
            "mae": 0.3201815339516468,
            "precision": 0.6932038834951456,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8221830471400814,
            "auditor_fn_violation": 0.0151571105518474,
            "auditor_fp_violation": 0.017999246957300444,
            "ave_precision_score": 0.822435863795683,
            "fpr": 0.10526315789473684,
            "logloss": 0.9261545833069206,
            "mae": 0.287465998881347,
            "precision": 0.7757009345794392,
            "recall": 0.6902286902286903
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8353065600178577,
            "auditor_fn_violation": 0.014017075768792513,
            "auditor_fp_violation": 0.015563207674841744,
            "ave_precision_score": 0.8355533428684576,
            "fpr": 0.10537870472008781,
            "logloss": 0.8096340838785057,
            "mae": 0.26609387080187297,
            "precision": 0.7847533632286996,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8261438951057689,
            "auditor_fn_violation": 0.009417058759164026,
            "auditor_fp_violation": 0.018876948752391428,
            "ave_precision_score": 0.8264378699490047,
            "fpr": 0.13486842105263158,
            "logloss": 0.9131591774208444,
            "mae": 0.2782217778968361,
            "precision": 0.7458677685950413,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8407809766399768,
            "auditor_fn_violation": 0.007159383898464388,
            "auditor_fp_violation": 0.009540922965881238,
            "ave_precision_score": 0.8410504771472225,
            "fpr": 0.141602634467618,
            "logloss": 0.8150216464930352,
            "mae": 0.25838148563008756,
            "precision": 0.7475538160469667,
            "recall": 0.8076109936575053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7875737731346566,
            "auditor_fn_violation": 0.01165107415107416,
            "auditor_fp_violation": 0.014424838197582123,
            "ave_precision_score": 0.7881794411760372,
            "fpr": 0.11732456140350878,
            "logloss": 0.9915938502051183,
            "mae": 0.30822808657140693,
            "precision": 0.7470449172576832,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8340470511415752,
            "auditor_fn_violation": 0.011717254231230694,
            "auditor_fp_violation": 0.009773995158113167,
            "ave_precision_score": 0.8342964624434519,
            "fpr": 0.1163556531284303,
            "logloss": 0.7743423740885294,
            "mae": 0.27355868304556374,
            "precision": 0.7665198237885462,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8244376324928252,
            "auditor_fn_violation": 0.009831947331947337,
            "auditor_fp_violation": 0.006782472422355197,
            "ave_precision_score": 0.824898107965887,
            "fpr": 0.11513157894736842,
            "logloss": 0.5126928473003987,
            "mae": 0.32633239195289016,
            "precision": 0.782608695652174,
            "recall": 0.7858627858627859
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8697130414835076,
            "auditor_fn_violation": 0.011403958663550732,
            "auditor_fp_violation": 0.008240229764070798,
            "ave_precision_score": 0.8699181428223615,
            "fpr": 0.11855104281009879,
            "logloss": 0.4755748466524544,
            "mae": 0.31928947186301804,
            "precision": 0.7826961770623743,
            "recall": 0.8224101479915433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6701912133066956,
            "auditor_fn_violation": 0.00863515337199548,
            "auditor_fp_violation": 0.023685228151585462,
            "ave_precision_score": 0.6508462357270945,
            "fpr": 0.34868421052631576,
            "logloss": 3.7560222387740554,
            "mae": 0.365861884172663,
            "precision": 0.5923076923076923,
            "recall": 0.9604989604989606
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6766218372144474,
            "auditor_fn_violation": 0.004311875294439816,
            "auditor_fp_violation": 0.02729200186457756,
            "ave_precision_score": 0.658394689571511,
            "fpr": 0.36882546652030734,
            "logloss": 3.8632179202043613,
            "mae": 0.38074550643367894,
            "precision": 0.58,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8217541569795881,
            "auditor_fn_violation": 0.01435468869679396,
            "auditor_fp_violation": 0.01193928847641145,
            "ave_precision_score": 0.8220849746344301,
            "fpr": 0.1118421052631579,
            "logloss": 0.5769254827168683,
            "mae": 0.3171638013958919,
            "precision": 0.7713004484304933,
            "recall": 0.7151767151767152
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8725971062712742,
            "auditor_fn_violation": 0.01475506088377199,
            "auditor_fp_violation": 0.011728794189735804,
            "ave_precision_score": 0.8727507337315459,
            "fpr": 0.10757409440175632,
            "logloss": 0.4823814757444021,
            "mae": 0.2946854465023607,
            "precision": 0.7846153846153846,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 10132,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7932800798650123,
            "auditor_fn_violation": 0.013477039792829269,
            "auditor_fp_violation": 0.013564944844710389,
            "ave_precision_score": 0.7925883035852438,
            "fpr": 0.125,
            "logloss": 1.639206862760332,
            "mae": 0.32625927605491406,
            "precision": 0.7414965986394558,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8391437016488872,
            "auditor_fn_violation": 0.019830449080187426,
            "auditor_fp_violation": 0.010485742497832183,
            "ave_precision_score": 0.8387534660453682,
            "fpr": 0.10976948408342481,
            "logloss": 1.036118941609187,
            "mae": 0.295334150653747,
            "precision": 0.7752808988764045,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8023356823044063,
            "auditor_fn_violation": 0.0009961884961885057,
            "auditor_fp_violation": 0.008041783693572679,
            "ave_precision_score": 0.8026933877024032,
            "fpr": 0.03399122807017544,
            "logloss": 1.2954206633612333,
            "mae": 0.3851546046361735,
            "precision": 0.8359788359788359,
            "recall": 0.3284823284823285
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8307864755275833,
            "auditor_fn_violation": 0.007820785652455437,
            "auditor_fp_violation": 0.0018821206060879458,
            "ave_precision_score": 0.8310282646637299,
            "fpr": 0.018660812294182216,
            "logloss": 1.1897900507709174,
            "mae": 0.3615738694195393,
            "precision": 0.9128205128205128,
            "recall": 0.3763213530655391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8150926772629872,
            "auditor_fn_violation": 0.009458091694933808,
            "auditor_fp_violation": 0.014928562706069121,
            "ave_precision_score": 0.8156461401361073,
            "fpr": 0.10307017543859649,
            "logloss": 0.874598011979601,
            "mae": 0.2899861715412479,
            "precision": 0.7679012345679013,
            "recall": 0.6465696465696466
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8678371739989588,
            "auditor_fn_violation": 0.01626584173236204,
            "auditor_fp_violation": 0.009706329037787774,
            "ave_precision_score": 0.8680323006288443,
            "fpr": 0.09330406147091108,
            "logloss": 0.6550776164810646,
            "mae": 0.24588629008778945,
            "precision": 0.8085585585585585,
            "recall": 0.758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5543373099233238,
            "auditor_fn_violation": 0.006774993617098881,
            "auditor_fp_violation": 0.011415211462531041,
            "ave_precision_score": 0.5525078289307501,
            "fpr": 0.36403508771929827,
            "logloss": 3.2294935577520216,
            "mae": 0.4308860014519257,
            "precision": 0.5625823451910409,
            "recall": 0.8877338877338877
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6046004458518726,
            "auditor_fn_violation": 0.008458980327359063,
            "auditor_fp_violation": 0.009987018129507952,
            "ave_precision_score": 0.6059529328431685,
            "fpr": 0.3809001097694841,
            "logloss": 2.889475306747254,
            "mae": 0.44330384417221336,
            "precision": 0.5422163588390502,
            "recall": 0.86892177589852
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8154375851623091,
            "auditor_fn_violation": 0.016194331983805682,
            "auditor_fp_violation": 0.017724488134489354,
            "ave_precision_score": 0.8147295564782743,
            "fpr": 0.11074561403508772,
            "logloss": 1.5341306992251391,
            "mae": 0.3182183187863414,
            "precision": 0.7672811059907834,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8652786171873884,
            "auditor_fn_violation": 0.015339879276774587,
            "auditor_fp_violation": 0.014671017347588335,
            "ave_precision_score": 0.8648462353370338,
            "fpr": 0.09001097694840834,
            "logloss": 0.948803505808098,
            "mae": 0.29298145020315186,
            "precision": 0.8093023255813954,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7881685793327757,
            "auditor_fn_violation": 0.017338694970273925,
            "auditor_fp_violation": 0.02353767248748322,
            "ave_precision_score": 0.7887360325315951,
            "fpr": 0.18421052631578946,
            "logloss": 1.0949733353971536,
            "mae": 0.2911688012081313,
            "precision": 0.7005347593582888,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8151773913244726,
            "auditor_fn_violation": 0.01843802433494313,
            "auditor_fp_violation": 0.03034950804224371,
            "ave_precision_score": 0.8156545296870215,
            "fpr": 0.18880351262349068,
            "logloss": 0.9616258730104102,
            "mae": 0.2803312343168149,
            "precision": 0.699825479930192,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7450034290189833,
            "auditor_fn_violation": 0.008113123244702194,
            "auditor_fp_violation": 0.020301624129930404,
            "ave_precision_score": 0.7457966539019961,
            "fpr": 0.26096491228070173,
            "logloss": 1.3326568819850304,
            "mae": 0.33479905109438607,
            "precision": 0.6371951219512195,
            "recall": 0.8690228690228691
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7500591230985151,
            "auditor_fn_violation": 0.0024599503832649114,
            "auditor_fp_violation": 0.02400894195249339,
            "ave_precision_score": 0.7501387986191754,
            "fpr": 0.2810098792535675,
            "logloss": 1.369688955707987,
            "mae": 0.3372168891593407,
            "precision": 0.6273653566229985,
            "recall": 0.9112050739957717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8246964327880897,
            "auditor_fn_violation": 0.01526653171390014,
            "auditor_fp_violation": 0.019144075385679984,
            "ave_precision_score": 0.8251154494545151,
            "fpr": 0.10964912280701754,
            "logloss": 0.9331738685317948,
            "mae": 0.28207883052919,
            "precision": 0.76905311778291,
            "recall": 0.6923076923076923
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8418656426688635,
            "auditor_fn_violation": 0.015980394659586967,
            "auditor_fp_violation": 0.014059516112055095,
            "ave_precision_score": 0.8421570168084312,
            "fpr": 0.10537870472008781,
            "logloss": 0.8029982688430525,
            "mae": 0.26069746223187845,
            "precision": 0.7842696629213484,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8065217401558488,
            "auditor_fn_violation": 0.007990024437392869,
            "auditor_fp_violation": 0.01933996825009159,
            "ave_precision_score": 0.8079523893119196,
            "fpr": 0.12938596491228072,
            "logloss": 0.9554266347164571,
            "mae": 0.28754884026541405,
            "precision": 0.7456896551724138,
            "recall": 0.7193347193347194
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8498796000468862,
            "auditor_fn_violation": 0.009162154823707431,
            "auditor_fp_violation": 0.004751665338405784,
            "ave_precision_score": 0.850149592327675,
            "fpr": 0.13391877058177826,
            "logloss": 0.7499002086658529,
            "mae": 0.25577169926489396,
            "precision": 0.7545271629778671,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8059222447565283,
            "auditor_fn_violation": 0.008026498158077107,
            "auditor_fp_violation": 0.019492612040542194,
            "ave_precision_score": 0.8055801886344037,
            "fpr": 0.2576754385964912,
            "logloss": 2.8507836295923226,
            "mae": 0.33381169299567454,
            "precision": 0.6350931677018633,
            "recall": 0.8503118503118503
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.8439516983960518,
            "auditor_fn_violation": 0.0036411907088138183,
            "auditor_fp_violation": 0.01894651369111168,
            "ave_precision_score": 0.8435414483256218,
            "fpr": 0.27661909989023054,
            "logloss": 2.4559135897438105,
            "mae": 0.3299330669280528,
            "precision": 0.6272189349112426,
            "recall": 0.8964059196617337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 10132,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.8093333800322756,
            "auditor_fn_violation": 0.006350986614144515,
            "auditor_fp_violation": 0.003398868400700126,
            "ave_precision_score": 0.8096714247204121,
            "fpr": 0.01206140350877193,
            "logloss": 1.5178962846033048,
            "mae": 0.4098328632336199,
            "precision": 0.9090909090909091,
            "recall": 0.2286902286902287
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.8370264535192736,
            "auditor_fn_violation": 0.010844668057544292,
            "auditor_fp_violation": 0.001308211659624378,
            "ave_precision_score": 0.8372190369063006,
            "fpr": 0.006586169045005488,
            "logloss": 1.4216812130099532,
            "mae": 0.3897207012288259,
            "precision": 0.9516129032258065,
            "recall": 0.24947145877378435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8433587407194025,
            "auditor_fn_violation": 0.008110843637159429,
            "auditor_fp_violation": 0.013134998168274518,
            "ave_precision_score": 0.8436782199978077,
            "fpr": 0.08442982456140351,
            "logloss": 0.5212178838250615,
            "mae": 0.31231870631656194,
            "precision": 0.8050632911392405,
            "recall": 0.6611226611226612
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8791622068411962,
            "auditor_fn_violation": 0.008182816086218944,
            "auditor_fp_violation": 0.006463367567377912,
            "ave_precision_score": 0.8793475282587269,
            "fpr": 0.07354555433589462,
            "logloss": 0.46462694775656604,
            "mae": 0.2947114631886319,
            "precision": 0.8369829683698297,
            "recall": 0.7272727272727273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7919774387376779,
            "auditor_fn_violation": 0.0035539081591713173,
            "auditor_fp_violation": 0.006026885659624703,
            "ave_precision_score": 0.792313284693027,
            "fpr": 0.43969298245614036,
            "logloss": 1.930961969491534,
            "mae": 0.43935864785820694,
            "precision": 0.5411899313501144,
            "recall": 0.9833679833679834
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.8382359199542946,
            "auditor_fn_violation": 0.0018936976535322335,
            "auditor_fp_violation": 0.005563658782310579,
            "ave_precision_score": 0.838445477406785,
            "fpr": 0.45773874862788144,
            "logloss": 1.9399006869520325,
            "mae": 0.44997891412895996,
            "precision": 0.5293453724604966,
            "recall": 0.9915433403805497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8283949291605319,
            "auditor_fn_violation": 0.019823467191888253,
            "auditor_fp_violation": 0.028111898074652995,
            "ave_precision_score": 0.8288663141454375,
            "fpr": 0.13815789473684212,
            "logloss": 0.881422349069472,
            "mae": 0.2702384932546629,
            "precision": 0.744421906693712,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8488679467031022,
            "auditor_fn_violation": 0.021577942135469007,
            "auditor_fp_violation": 0.023993905036865507,
            "ave_precision_score": 0.8491888536603619,
            "fpr": 0.13391877058177826,
            "logloss": 0.7622606747091454,
            "mae": 0.2545685495632491,
            "precision": 0.757455268389662,
            "recall": 0.8054968287526427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8270612678529892,
            "auditor_fn_violation": 0.015991446912499544,
            "auditor_fp_violation": 0.02470285342125616,
            "ave_precision_score": 0.8275209283768161,
            "fpr": 0.15570175438596492,
            "logloss": 0.825556114850123,
            "mae": 0.2722895715817446,
            "precision": 0.7320754716981132,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8463529634376586,
            "auditor_fn_violation": 0.010127569313743466,
            "auditor_fp_violation": 0.01988632091785333,
            "ave_precision_score": 0.8466730726938747,
            "fpr": 0.16136114160263446,
            "logloss": 0.7421039520260411,
            "mae": 0.2602470486755548,
            "precision": 0.7287822878228782,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7826038232431363,
            "auditor_fn_violation": 0.009453532479848271,
            "auditor_fp_violation": 0.011254935482557913,
            "ave_precision_score": 0.7830323998177373,
            "fpr": 0.21820175438596492,
            "logloss": 0.9894603689645082,
            "mae": 0.3060307822747774,
            "precision": 0.6764227642276422,
            "recall": 0.8648648648648649
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8296476397137349,
            "auditor_fn_violation": 0.01246452217784513,
            "auditor_fp_violation": 0.023713215945145347,
            "ave_precision_score": 0.8298733555752513,
            "fpr": 0.24588364434687157,
            "logloss": 0.8715171975901324,
            "mae": 0.30987082434886026,
            "precision": 0.65,
            "recall": 0.879492600422833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.8008316132199274,
            "auditor_fn_violation": 0.0002051646788488903,
            "auditor_fp_violation": 0.012097020393210409,
            "ave_precision_score": 0.8009635672510467,
            "fpr": 0.37719298245614036,
            "logloss": 2.7448094553813225,
            "mae": 0.41320708739951145,
            "precision": 0.559539052496799,
            "recall": 0.9085239085239085
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.8584553336649917,
            "auditor_fn_violation": 0.007198835932912977,
            "auditor_fp_violation": 0.01593913056553841,
            "ave_precision_score": 0.8584719008837826,
            "fpr": 0.3951701427003293,
            "logloss": 2.5115379544618204,
            "mae": 0.4149390220875384,
            "precision": 0.5533498759305211,
            "recall": 0.9429175475687104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.674040774409045,
            "auditor_fn_violation": 0.011352445562971882,
            "auditor_fp_violation": 0.005879329995522452,
            "ave_precision_score": 0.6748777910972475,
            "fpr": 0.11951754385964912,
            "logloss": 0.7578461472796697,
            "mae": 0.4421420277519566,
            "precision": 0.660436137071651,
            "recall": 0.4407484407484408
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7149389678481621,
            "auditor_fn_violation": 0.018106163103993253,
            "auditor_fp_violation": 0.0030023708203639984,
            "ave_precision_score": 0.7154817508876097,
            "fpr": 0.09769484083424808,
            "logloss": 0.7023887345767991,
            "mae": 0.42682108751967596,
            "precision": 0.7156549520766773,
            "recall": 0.47357293868921774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5596405706393797,
            "auditor_fn_violation": 0.005735492577597842,
            "auditor_fp_violation": 0.005970916269792834,
            "ave_precision_score": 0.557851871302819,
            "fpr": 0.4298245614035088,
            "logloss": 3.4325425778973675,
            "mae": 0.45767548259282803,
            "precision": 0.5311004784688995,
            "recall": 0.9230769230769231
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.6141353593915782,
            "auditor_fn_violation": 0.006098820384169988,
            "auditor_fp_violation": 0.007518457813933215,
            "ave_precision_score": 0.6153967194965975,
            "fpr": 0.44127332601536773,
            "logloss": 3.0888018628428693,
            "mae": 0.4750470774184643,
            "precision": 0.5144927536231884,
            "recall": 0.9006342494714588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8173747432856655,
            "auditor_fn_violation": 0.013862293467556635,
            "auditor_fp_violation": 0.0221613343102536,
            "ave_precision_score": 0.8177594289376503,
            "fpr": 0.10964912280701754,
            "logloss": 0.9652044121490525,
            "mae": 0.2899847639576727,
            "precision": 0.765807962529274,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8305591182526808,
            "auditor_fn_violation": 0.015606760686279747,
            "auditor_fp_violation": 0.012290172373176145,
            "ave_precision_score": 0.830815845072695,
            "fpr": 0.10976948408342481,
            "logloss": 0.8323673830043946,
            "mae": 0.26902738418916194,
            "precision": 0.7752808988764045,
            "recall": 0.7293868921775899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7966319137914782,
            "auditor_fn_violation": 0.01698763540868804,
            "auditor_fp_violation": 0.02152277445353523,
            "ave_precision_score": 0.796290317346217,
            "fpr": 0.10855263157894737,
            "logloss": 3.113824149381648,
            "mae": 0.3024672273672616,
            "precision": 0.7620192307692307,
            "recall": 0.659043659043659
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8077794624681849,
            "auditor_fn_violation": 0.02079354286231472,
            "auditor_fp_violation": 0.018385135507671336,
            "ave_precision_score": 0.8060167375343997,
            "fpr": 0.10647639956092206,
            "logloss": 3.2783468702953904,
            "mae": 0.28468534371206605,
            "precision": 0.7690476190476191,
            "recall": 0.6828752642706131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8158054155260885,
            "auditor_fn_violation": 0.023046832257358575,
            "auditor_fp_violation": 0.027788802051532543,
            "ave_precision_score": 0.8163132678276552,
            "fpr": 0.13157894736842105,
            "logloss": 1.1364465135005442,
            "mae": 0.2796937144995321,
            "precision": 0.7463002114164905,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8429692503129238,
            "auditor_fn_violation": 0.02969345769233447,
            "auditor_fp_violation": 0.025705607265837635,
            "ave_precision_score": 0.8433779480503598,
            "fpr": 0.12843029637760703,
            "logloss": 0.9833649474894132,
            "mae": 0.2584831106197489,
            "precision": 0.7567567567567568,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 10132,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.8235609122579971,
            "auditor_fn_violation": 0.0012309880730933386,
            "auditor_fp_violation": 0.01176374811739327,
            "ave_precision_score": 0.8241860121127931,
            "fpr": 0.3201754385964912,
            "logloss": 0.7377243670463834,
            "mae": 0.35655350417864773,
            "precision": 0.6054054054054054,
            "recall": 0.9313929313929314
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.8514787977838956,
            "auditor_fn_violation": 0.00370384982234981,
            "auditor_fp_violation": 0.004917071410312328,
            "ave_precision_score": 0.8516887500670502,
            "fpr": 0.34577387486278816,
            "logloss": 0.7119707415967369,
            "mae": 0.3616623731954156,
            "precision": 0.58984375,
            "recall": 0.9577167019027484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.824284750042491,
            "auditor_fn_violation": 0.023596217675165045,
            "auditor_fp_violation": 0.034566186347539385,
            "ave_precision_score": 0.8247909736100683,
            "fpr": 0.14802631578947367,
            "logloss": 0.8787854304301649,
            "mae": 0.2713800847848886,
            "precision": 0.7347740667976425,
            "recall": 0.7775467775467776
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8447875467145205,
            "auditor_fn_violation": 0.020621810477067924,
            "auditor_fp_violation": 0.030083855866151404,
            "ave_precision_score": 0.8451080320423006,
            "fpr": 0.14928649835345773,
            "logloss": 0.7738970484804217,
            "mae": 0.25882381213697,
            "precision": 0.7404580152671756,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8017230736326506,
            "auditor_fn_violation": 0.018954936718094617,
            "auditor_fp_violation": 0.024166056091504868,
            "ave_precision_score": 0.8022242000654143,
            "fpr": 0.1425438596491228,
            "logloss": 1.042515750659167,
            "mae": 0.29061205457992423,
            "precision": 0.7286012526096033,
            "recall": 0.7255717255717256
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8430843884588118,
            "auditor_fn_violation": 0.02678328997477391,
            "auditor_fp_violation": 0.025788310301790907,
            "ave_precision_score": 0.8432910901011083,
            "fpr": 0.13830954994511527,
            "logloss": 0.8370585501563831,
            "mae": 0.2619558876500267,
            "precision": 0.7464788732394366,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8268426821331711,
            "auditor_fn_violation": 0.0048145311303206175,
            "auditor_fp_violation": 0.012995074693694797,
            "ave_precision_score": 0.8272007719964712,
            "fpr": 0.09320175438596491,
            "logloss": 0.8195522813315104,
            "mae": 0.29343486351101067,
            "precision": 0.7853535353535354,
            "recall": 0.6465696465696466
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.846693799289594,
            "auditor_fn_violation": 0.00950329888629228,
            "auditor_fp_violation": 0.008150008270303596,
            "ave_precision_score": 0.8469841785776853,
            "fpr": 0.08232711306256861,
            "logloss": 0.6834750479606863,
            "mae": 0.2629044478605634,
            "precision": 0.8188405797101449,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.8139625415364145,
            "auditor_fn_violation": 0.014270343217711656,
            "auditor_fp_violation": 0.008657446981723452,
            "ave_precision_score": 0.8143008279452801,
            "fpr": 0.03837719298245614,
            "logloss": 1.19841160427415,
            "mae": 0.37037575599911393,
            "precision": 0.8394495412844036,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.844339785940748,
            "auditor_fn_violation": 0.019247951395093568,
            "auditor_fp_violation": 0.00434316246384875,
            "ave_precision_score": 0.8445312830480873,
            "fpr": 0.018660812294182216,
            "logloss": 1.0925903234292076,
            "mae": 0.34957554789264855,
            "precision": 0.9158415841584159,
            "recall": 0.39112050739957716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8265176686668582,
            "auditor_fn_violation": 0.006223328591749651,
            "auditor_fp_violation": 0.004714149061749506,
            "ave_precision_score": 0.8272645742282605,
            "fpr": 0.10964912280701754,
            "logloss": 0.5246023295374276,
            "mae": 0.3034431896251095,
            "precision": 0.7844827586206896,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8578333084949856,
            "auditor_fn_violation": 0.006305363388047893,
            "auditor_fp_violation": 0.010069721165461206,
            "ave_precision_score": 0.8581477776488519,
            "fpr": 0.10976948408342481,
            "logloss": 0.4704252851970147,
            "mae": 0.2920652681835912,
            "precision": 0.7916666666666666,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 10132,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7803810262532336,
            "auditor_fn_violation": 0.0020516467884888947,
            "auditor_fp_violation": 0.013262201326983353,
            "ave_precision_score": 0.7806936207097807,
            "fpr": 0.4100877192982456,
            "logloss": 1.4710550613221183,
            "mae": 0.4158140860096287,
            "precision": 0.5515587529976019,
            "recall": 0.9563409563409564
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.8276773503421904,
            "auditor_fn_violation": 0.0016987581891980336,
            "auditor_fp_violation": 0.0058042494323564415,
            "ave_precision_score": 0.8279150977352716,
            "fpr": 0.42590559824368823,
            "logloss": 1.4373319385632464,
            "mae": 0.4228102493444612,
            "precision": 0.5419126328217237,
            "recall": 0.9704016913319239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8230294045688732,
            "auditor_fn_violation": 0.011176915782178947,
            "auditor_fp_violation": 0.01985132494810111,
            "ave_precision_score": 0.8234246361680677,
            "fpr": 0.1162280701754386,
            "logloss": 0.81694260439843,
            "mae": 0.28179405040082367,
            "precision": 0.7670329670329671,
            "recall": 0.7255717255717256
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8430786030640423,
            "auditor_fn_violation": 0.008988101730551886,
            "auditor_fp_violation": 0.007428236320166008,
            "ave_precision_score": 0.8433744455327885,
            "fpr": 0.12952799121844127,
            "logloss": 0.7059285500930349,
            "mae": 0.2610282727517624,
            "precision": 0.757700205338809,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6684243264667358,
            "auditor_fn_violation": 0.00863515337199548,
            "auditor_fp_violation": 0.026633797370456302,
            "ave_precision_score": 0.6485052380218406,
            "fpr": 0.34539473684210525,
            "logloss": 3.7563363506234158,
            "mae": 0.36365860790209903,
            "precision": 0.5945945945945946,
            "recall": 0.9604989604989606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6731017679114759,
            "auditor_fn_violation": 0.004311875294439816,
            "auditor_fp_violation": 0.028169155276203086,
            "ave_precision_score": 0.655227014604097,
            "fpr": 0.36443468715697036,
            "logloss": 3.836889603831283,
            "mae": 0.3780066334309501,
            "precision": 0.5829145728643216,
            "recall": 0.9809725158562368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.846625868603285,
            "auditor_fn_violation": 0.012113834482255545,
            "auditor_fp_violation": 0.0075889404485692214,
            "ave_precision_score": 0.8469322658129934,
            "fpr": 0.0625,
            "logloss": 0.5435328257332135,
            "mae": 0.315731605151852,
            "precision": 0.8429752066115702,
            "recall": 0.6361746361746362
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.884451174767608,
            "auditor_fn_violation": 0.020955992415926553,
            "auditor_fp_violation": 0.006099975439704475,
            "ave_precision_score": 0.8846278244546324,
            "fpr": 0.05817782656421515,
            "logloss": 0.4751947614949731,
            "mae": 0.29741334289815335,
            "precision": 0.8586666666666667,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7539821091919289,
            "auditor_fn_violation": 0.015822755954334904,
            "auditor_fp_violation": 0.0271604184475109,
            "ave_precision_score": 0.7545957454570239,
            "fpr": 0.17105263157894737,
            "logloss": 1.1690965184974393,
            "mae": 0.32646450755266665,
            "precision": 0.688622754491018,
            "recall": 0.7172557172557172
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7523552679890679,
            "auditor_fn_violation": 0.022608336446949776,
            "auditor_fp_violation": 0.03246470084056358,
            "ave_precision_score": 0.7535401233238695,
            "fpr": 0.16465422612513722,
            "logloss": 1.085581381338503,
            "mae": 0.30482881984815713,
            "precision": 0.7029702970297029,
            "recall": 0.7505285412262156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 10132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8258561874391694,
            "auditor_fn_violation": 0.00663821716453296,
            "auditor_fp_violation": 0.017844059103675668,
            "ave_precision_score": 0.8262464772359494,
            "fpr": 0.11074561403508772,
            "logloss": 0.808977934669503,
            "mae": 0.28457937967260816,
            "precision": 0.7725225225225225,
            "recall": 0.7130977130977131
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8460858722326642,
            "auditor_fn_violation": 0.01099319336370367,
            "auditor_fp_violation": 0.010879208456761352,
            "ave_precision_score": 0.8463800520793044,
            "fpr": 0.10867178924259056,
            "logloss": 0.6881594751039107,
            "mae": 0.25841630626684814,
            "precision": 0.7852494577006508,
            "recall": 0.7653276955602537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7509740465724442,
            "auditor_fn_violation": 0.012492249334354609,
            "auditor_fp_violation": 0.02645062482191558,
            "ave_precision_score": 0.7515420125795844,
            "fpr": 0.15789473684210525,
            "logloss": 1.0957217545992446,
            "mae": 0.3345060536933304,
            "precision": 0.6923076923076923,
            "recall": 0.6735966735966736
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7546267276255211,
            "auditor_fn_violation": 0.014669194691148591,
            "auditor_fp_violation": 0.017518006706464372,
            "ave_precision_score": 0.7552480257909958,
            "fpr": 0.16465422612513722,
            "logloss": 1.005009093697905,
            "mae": 0.31338010514466175,
            "precision": 0.6993987975951904,
            "recall": 0.7378435517970402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 10132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8402792942132014,
            "auditor_fn_violation": 0.0038092242039610602,
            "auditor_fp_violation": 0.002862071070948836,
            "ave_precision_score": 0.8407349237665873,
            "fpr": 0.06469298245614036,
            "logloss": 0.5415884333310889,
            "mae": 0.3236428814707324,
            "precision": 0.8333333333333334,
            "recall": 0.6133056133056133
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8806611394107929,
            "auditor_fn_violation": 0.004235291933451383,
            "auditor_fp_violation": 0.00184954062222757,
            "ave_precision_score": 0.8808264208341599,
            "fpr": 0.054884742041712405,
            "logloss": 0.476344212091829,
            "mae": 0.3066074025710384,
            "precision": 0.8663101604278075,
            "recall": 0.6849894291754757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 10132,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8057801413730237,
            "auditor_fn_violation": 0.00553716672137725,
            "auditor_fp_violation": 0.018785362478121067,
            "ave_precision_score": 0.8051518276995135,
            "fpr": 0.25877192982456143,
            "logloss": 2.816583796738257,
            "mae": 0.3342581027095808,
            "precision": 0.6346749226006192,
            "recall": 0.8523908523908524
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.8449068189075362,
            "auditor_fn_violation": 0.0036411907088138183,
            "auditor_fp_violation": 0.01670601326255958,
            "ave_precision_score": 0.8446764515522842,
            "fpr": 0.278814489571899,
            "logloss": 2.4245744363464983,
            "mae": 0.3305463770767632,
            "precision": 0.6253687315634219,
            "recall": 0.8964059196617337
        }
    }
]