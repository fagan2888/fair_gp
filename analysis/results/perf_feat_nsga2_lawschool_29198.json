[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.7617172469442,
            "mae": 0.5142543859649122,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.38782277884927,
            "mae": 0.5323819978046103,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.7617172469442,
            "mae": 0.5142543859649122,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.38782277884927,
            "mae": 0.5323819978046103,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5282020678994184,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5185461693942525,
            "fpr": 0.03728070175438596,
            "logloss": 0.6982883154451298,
            "mae": 0.5013602989349972,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5815587252793349,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.565484049178128,
            "fpr": 0.02854006586169045,
            "logloss": 0.6976888315683273,
            "mae": 0.5010557237166081,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6862679170318272,
            "auditor_fn_violation": 0.002242079078292776,
            "auditor_fp_violation": 0.011823789156865078,
            "ave_precision_score": 0.6357469228283936,
            "fpr": 0.07017543859649122,
            "logloss": 0.687748206347537,
            "mae": 0.4944119339057228,
            "precision": 0.6049382716049383,
            "recall": 0.208955223880597
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7601234643538346,
            "auditor_fn_violation": 0.017146672400330455,
            "auditor_fp_violation": 0.0007343733090088276,
            "ave_precision_score": 0.7033385489194446,
            "fpr": 0.04939626783754116,
            "logloss": 0.6818094676160932,
            "mae": 0.49132943222080444,
            "precision": 0.7204968944099379,
            "recall": 0.23917525773195877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5104318040025903,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5038748712891636,
            "fpr": 0.03728070175438596,
            "logloss": 0.699957600393152,
            "mae": 0.5009540348526156,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5354587605147315,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5214856756076162,
            "fpr": 0.02854006586169045,
            "logloss": 0.7038164472001985,
            "mae": 0.5030585142705103,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5183721771110685,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5092173282989619,
            "fpr": 0.06907894736842106,
            "logloss": 0.6971133507543487,
            "mae": 0.5013087490214068,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5763095795866546,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5623113773857693,
            "fpr": 0.042810098792535674,
            "logloss": 0.6958016710970849,
            "mae": 0.5006392215400051,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 29198,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5472019143896537,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.006935368896281338,
            "ave_precision_score": 0.537319168456098,
            "fpr": 0.03508771929824561,
            "logloss": 0.6953782621884517,
            "mae": 0.495388975448645,
            "precision": 0.4666666666666667,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.5776717855834937,
            "auditor_fn_violation": 0.0018921090452318292,
            "auditor_fp_violation": 0.0027519673474436087,
            "ave_precision_score": 0.5652287639271375,
            "fpr": 0.026344676180021953,
            "logloss": 0.6916972407162622,
            "mae": 0.49455890432409083,
            "precision": 0.5714285714285714,
            "recall": 0.06597938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.759469469267051,
            "auditor_fn_violation": 0.010361725208543754,
            "auditor_fp_violation": 0.0038661835174844564,
            "ave_precision_score": 0.7409040225419746,
            "fpr": 0.1074561403508772,
            "logloss": 1.4436585152384658,
            "mae": 0.3626486972444201,
            "precision": 0.7441253263707572,
            "recall": 0.6076759061833689
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7823234925361231,
            "auditor_fn_violation": 0.0031459707809476435,
            "auditor_fp_violation": 0.013195528826084943,
            "ave_precision_score": 0.7649563110437937,
            "fpr": 0.09769484083424808,
            "logloss": 1.4751250003938197,
            "mae": 0.34939416281646685,
            "precision": 0.7797029702970297,
            "recall": 0.6494845360824743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7014640316851704,
            "auditor_fn_violation": 0.006950678936146338,
            "auditor_fp_violation": 0.009603580056235416,
            "ave_precision_score": 0.6538297303460078,
            "fpr": 0.4506578947368421,
            "logloss": 6.8457858119333,
            "mae": 0.4785437582573467,
            "precision": 0.519298245614035,
            "recall": 0.9466950959488273
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7326831012579329,
            "auditor_fn_violation": 0.0007491484377652296,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.6922379033003577,
            "fpr": 0.4489571899012075,
            "logloss": 6.37432554137973,
            "mae": 0.4719148650189897,
            "precision": 0.5315005727376861,
            "recall": 0.9567010309278351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8356840427532696,
            "auditor_fn_violation": 0.003371301387797861,
            "auditor_fp_violation": 0.004549324779216665,
            "ave_precision_score": 0.8342951543387478,
            "fpr": 0.025219298245614034,
            "logloss": 0.639361869135759,
            "mae": 0.428729436280647,
            "precision": 0.8963963963963963,
            "recall": 0.42430703624733473
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8649603146997801,
            "auditor_fn_violation": 0.0027838446478889176,
            "auditor_fp_violation": 0.005998670397798427,
            "ave_precision_score": 0.8634607400998521,
            "fpr": 0.01756311745334797,
            "logloss": 0.5889030485180108,
            "mae": 0.4229145332532971,
            "precision": 0.9292035398230089,
            "recall": 0.4329896907216495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7496882758799114,
            "auditor_fn_violation": 0.013873302659634167,
            "auditor_fp_violation": 0.027422181299750513,
            "ave_precision_score": 0.6998360964416692,
            "fpr": 0.14035087719298245,
            "logloss": 3.8664988857793947,
            "mae": 0.39402057808654656,
            "precision": 0.7070938215102975,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7469012000789137,
            "auditor_fn_violation": 0.017004085235438574,
            "auditor_fp_violation": 0.012221517910978497,
            "ave_precision_score": 0.6961026297269011,
            "fpr": 0.1394072447859495,
            "logloss": 3.811995665340951,
            "mae": 0.3989734838792592,
            "precision": 0.7113636363636363,
            "recall": 0.6453608247422681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7460882201066898,
            "auditor_fn_violation": 0.000568118056334867,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.722436298619237,
            "fpr": 0.4857456140350877,
            "logloss": 2.0057072056823015,
            "mae": 0.43886135849683233,
            "precision": 0.5137211855104281,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7735471913951684,
            "auditor_fn_violation": 0.0006676700578270169,
            "auditor_fp_violation": 0.0006493406100709731,
            "ave_precision_score": 0.7515410078433169,
            "fpr": 0.4665203073545554,
            "logloss": 1.9592582039899917,
            "mae": 0.41755982635056343,
            "precision": 0.5324532453245324,
            "recall": 0.9979381443298969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5715562500123622,
            "auditor_fn_violation": 0.004624434219878063,
            "auditor_fp_violation": 0.012143083442239912,
            "ave_precision_score": 0.5300027013151597,
            "fpr": 0.07236842105263158,
            "logloss": 0.6876502013321738,
            "mae": 0.49360632559840095,
            "precision": 0.6,
            "recall": 0.21108742004264391
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6320864950048819,
            "auditor_fn_violation": 0.01665101225570632,
            "auditor_fp_violation": 0.0007343733090088276,
            "ave_precision_score": 0.5693549515685994,
            "fpr": 0.04939626783754116,
            "logloss": 0.6825047174726695,
            "mae": 0.4909020135614665,
            "precision": 0.7222222222222222,
            "recall": 0.24123711340206186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7744092230539524,
            "auditor_fn_violation": 0.01918742752403397,
            "auditor_fp_violation": 0.021593204229535475,
            "ave_precision_score": 0.7642964447089486,
            "fpr": 0.16557017543859648,
            "logloss": 2.3801452732425883,
            "mae": 0.3129217308792887,
            "precision": 0.7112810707456979,
            "recall": 0.7931769722814499
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.796591469082375,
            "auditor_fn_violation": 0.005644641099052817,
            "auditor_fp_violation": 0.01510489942950789,
            "ave_precision_score": 0.7907126141210281,
            "fpr": 0.15477497255762898,
            "logloss": 2.0285795706980463,
            "mae": 0.3013798434747395,
            "precision": 0.7422303473491774,
            "recall": 0.8371134020618557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8199419566888511,
            "auditor_fn_violation": 0.002700314218381775,
            "auditor_fp_violation": 0.007566532018533922,
            "ave_precision_score": 0.8200030377108745,
            "fpr": 0.046052631578947366,
            "logloss": 0.5703383359270697,
            "mae": 0.39796133457045807,
            "precision": 0.8531468531468531,
            "recall": 0.5202558635394456
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8399827152899462,
            "auditor_fn_violation": 0.010116898842328024,
            "auditor_fp_violation": 0.0024891390052720294,
            "ave_precision_score": 0.8400768204027683,
            "fpr": 0.036223929747530186,
            "logloss": 0.5597262777134965,
            "mae": 0.38904054477630934,
            "precision": 0.8873720136518771,
            "recall": 0.5360824742268041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 29198,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.8136711253932127,
            "auditor_fn_violation": 0.007448658960834923,
            "auditor_fp_violation": 0.013016811215397415,
            "ave_precision_score": 0.8122807043371518,
            "fpr": 0.41776315789473684,
            "logloss": 1.4798365236340316,
            "mae": 0.4351155314800827,
            "precision": 0.5189393939393939,
            "recall": 0.8763326226012793
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8492159538266485,
            "auditor_fn_violation": 0.0022338655833059862,
            "auditor_fp_violation": 0.0029220327453193455,
            "ave_precision_score": 0.8476672496645765,
            "fpr": 0.4149286498353458,
            "logloss": 1.2439048721226027,
            "mae": 0.42678040777023535,
            "precision": 0.5401459854014599,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7979790593496456,
            "auditor_fn_violation": 0.013155556802453897,
            "auditor_fp_violation": 0.02238030177022693,
            "ave_precision_score": 0.771468308799318,
            "fpr": 0.17653508771929824,
            "logloss": 2.047802981990425,
            "mae": 0.30715183114517186,
            "precision": 0.7119856887298748,
            "recall": 0.8486140724946695
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8026841663645852,
            "auditor_fn_violation": 0.00813652155216314,
            "auditor_fp_violation": 0.014872992068768265,
            "ave_precision_score": 0.7717515612735216,
            "fpr": 0.16245883644346873,
            "logloss": 2.2258391136314666,
            "mae": 0.2991579990717966,
            "precision": 0.7394366197183099,
            "recall": 0.865979381443299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8313930784861885,
            "auditor_fn_violation": 0.002700314218381775,
            "auditor_fp_violation": 0.00778682032394757,
            "ave_precision_score": 0.8314862268217462,
            "fpr": 0.044956140350877194,
            "logloss": 0.5706454955764407,
            "mae": 0.3972094704053904,
            "precision": 0.856140350877193,
            "recall": 0.5202558635394456
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8503212576597041,
            "auditor_fn_violation": 0.010116898842328024,
            "auditor_fp_violation": 0.0024891390052720294,
            "ave_precision_score": 0.8504546613937677,
            "fpr": 0.036223929747530186,
            "logloss": 0.5599237134892002,
            "mae": 0.38844975106148244,
            "precision": 0.8873720136518771,
            "recall": 0.5360824742268041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5104318040025903,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5038748712891636,
            "fpr": 0.03728070175438596,
            "logloss": 0.6998265956533131,
            "mae": 0.5009513243771436,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5354587605147315,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5214856756076162,
            "fpr": 0.02854006586169045,
            "logloss": 0.7035148886283531,
            "mae": 0.5029685918965533,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8081453130174735,
            "auditor_fn_violation": 0.006824430479183032,
            "auditor_fp_violation": 0.005987386638152945,
            "ave_precision_score": 0.8082408131597305,
            "fpr": 0.03837719298245614,
            "logloss": 0.6409129750374819,
            "mae": 0.39520157657036753,
            "precision": 0.8674242424242424,
            "recall": 0.488272921108742
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.829180050464492,
            "auditor_fn_violation": 0.011750993017755498,
            "auditor_fp_violation": 0.0062975732183072845,
            "ave_precision_score": 0.8293809914836068,
            "fpr": 0.030735455543358946,
            "logloss": 0.6223277168160284,
            "mae": 0.3874829983477748,
            "precision": 0.899641577060932,
            "recall": 0.5175257731958763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8078494623069562,
            "auditor_fn_violation": 0.005419331911869235,
            "auditor_fp_violation": 0.005791849827729596,
            "ave_precision_score": 0.8080989050541857,
            "fpr": 0.03618421052631579,
            "logloss": 0.6434009048815598,
            "mae": 0.3947013011917047,
            "precision": 0.872093023255814,
            "recall": 0.47974413646055436
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8306780040922385,
            "auditor_fn_violation": 0.010436022497086014,
            "auditor_fp_violation": 0.006957220822188898,
            "ave_precision_score": 0.8309897205879745,
            "fpr": 0.029637760702524697,
            "logloss": 0.6245943238497705,
            "mae": 0.38718071094439105,
            "precision": 0.9021739130434783,
            "recall": 0.51340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6853284086853875,
            "auditor_fn_violation": 0.0012648225040212606,
            "auditor_fp_violation": 0.011823789156865078,
            "ave_precision_score": 0.6348073480454225,
            "fpr": 0.07017543859649122,
            "logloss": 0.6881191431340106,
            "mae": 0.49481447286119584,
            "precision": 0.6024844720496895,
            "recall": 0.2068230277185501
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7599791963052537,
            "auditor_fn_violation": 0.017040297848744466,
            "auditor_fp_violation": 0.0013965976613431051,
            "ave_precision_score": 0.7032182509521274,
            "fpr": 0.048298572996706916,
            "logloss": 0.682080502280768,
            "mae": 0.4917524349676398,
            "precision": 0.7215189873417721,
            "recall": 0.23505154639175257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8026180335433075,
            "auditor_fn_violation": 0.01238871432312124,
            "auditor_fp_violation": 0.018281454199833673,
            "ave_precision_score": 0.7647460564490253,
            "fpr": 0.16776315789473684,
            "logloss": 2.3898398421784774,
            "mae": 0.3119791427764045,
            "precision": 0.720292504570384,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8025956901680733,
            "auditor_fn_violation": 0.010782305611823424,
            "auditor_fp_violation": 0.01406904655153755,
            "ave_precision_score": 0.7618442278287878,
            "fpr": 0.15148188803512624,
            "logloss": 2.584585351349905,
            "mae": 0.3048530345420741,
            "precision": 0.7486338797814208,
            "recall": 0.8474226804123711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5265294641061018,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5165443512503936,
            "fpr": 0.03728070175438596,
            "logloss": 0.6979903984769893,
            "mae": 0.501407850174266,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5888866161498968,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5725703489964281,
            "fpr": 0.02854006586169045,
            "logloss": 0.6975650761792543,
            "mae": 0.5011702869843966,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7871290871775047,
            "auditor_fn_violation": 0.016052257509445257,
            "auditor_fp_violation": 0.02081600728684013,
            "ave_precision_score": 0.7529846581413144,
            "fpr": 0.1611842105263158,
            "logloss": 2.2979326577145405,
            "mae": 0.3266349014246085,
            "precision": 0.7178502879078695,
            "recall": 0.7974413646055437
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.790029339500925,
            "auditor_fn_violation": 0.0015118766055201612,
            "auditor_fp_violation": 0.0176094989254959,
            "ave_precision_score": 0.7526821517592996,
            "fpr": 0.150384193194292,
            "logloss": 2.5082196381572466,
            "mae": 0.31473865033087495,
            "precision": 0.7458256029684601,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 29198,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.519530923320407,
            "auditor_fn_violation": 0.00738085886357688,
            "auditor_fp_violation": 0.010353550354441413,
            "ave_precision_score": 0.5116436713149981,
            "fpr": 0.06907894736842106,
            "logloss": 0.7187812290332085,
            "mae": 0.4940891884790178,
            "precision": 0.45689655172413796,
            "recall": 0.11300639658848614
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.5760304260794725,
            "auditor_fn_violation": 0.006036189980422559,
            "auditor_fp_violation": 0.004104760285091449,
            "ave_precision_score": 0.5637926745776299,
            "fpr": 0.042810098792535674,
            "logloss": 0.7348609427269851,
            "mae": 0.49602001193914924,
            "precision": 0.6176470588235294,
            "recall": 0.12989690721649486
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7601912020510289,
            "auditor_fn_violation": 0.017866494594695692,
            "auditor_fp_violation": 0.005173062452972165,
            "ave_precision_score": 0.7598938726082706,
            "fpr": 0.09100877192982457,
            "logloss": 1.5273143476614037,
            "mae": 0.35090465254909164,
            "precision": 0.7688022284122563,
            "recall": 0.5884861407249466
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.784357713287682,
            "auditor_fn_violation": 0.007758552400783098,
            "auditor_fp_violation": 0.007591100941543885,
            "ave_precision_score": 0.7839890279993047,
            "fpr": 0.08562019758507135,
            "logloss": 1.3653909563397395,
            "mae": 0.34251217158950686,
            "precision": 0.8010204081632653,
            "recall": 0.6474226804123712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7969116267690007,
            "auditor_fn_violation": 0.009672034564021997,
            "auditor_fp_violation": 0.02277880083957071,
            "ave_precision_score": 0.7713182757567183,
            "fpr": 0.1524122807017544,
            "logloss": 1.9821591402832885,
            "mae": 0.2870724720029938,
            "precision": 0.7321772639691715,
            "recall": 0.8102345415778252
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8028177260878038,
            "auditor_fn_violation": 0.006398316113481283,
            "auditor_fp_violation": 0.013690264528996148,
            "ave_precision_score": 0.774136544500253,
            "fpr": 0.1350164654226125,
            "logloss": 2.1251798684555125,
            "mae": 0.2819696789157565,
            "precision": 0.7611650485436893,
            "recall": 0.8082474226804124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6863222661506554,
            "auditor_fn_violation": 0.002242079078292776,
            "auditor_fp_violation": 0.013303928557284864,
            "ave_precision_score": 0.635792806412778,
            "fpr": 0.0712719298245614,
            "logloss": 0.6876217859105713,
            "mae": 0.4941783830065999,
            "precision": 0.6012269938650306,
            "recall": 0.208955223880597
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7607290992190414,
            "auditor_fn_violation": 0.01665101225570632,
            "auditor_fp_violation": 0.0007343733090088276,
            "ave_precision_score": 0.7039445144421627,
            "fpr": 0.04939626783754116,
            "logloss": 0.6817382769389952,
            "mae": 0.49107288486609474,
            "precision": 0.7222222222222222,
            "recall": 0.24123711340206186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5282020678994184,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5185461693942525,
            "fpr": 0.03728070175438596,
            "logloss": 0.6983302859249556,
            "mae": 0.5013999622315168,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5815587252793349,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.565484049178128,
            "fpr": 0.02854006586169045,
            "logloss": 0.6984168223957875,
            "mae": 0.5014178447351759,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7927797980289866,
            "auditor_fn_violation": 0.009524744697564813,
            "auditor_fp_violation": 0.007170508098689162,
            "ave_precision_score": 0.7930500334057654,
            "fpr": 0.03837719298245614,
            "logloss": 0.6462686254400795,
            "mae": 0.3947979692357445,
            "precision": 0.8648648648648649,
            "recall": 0.47761194029850745
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8295171058740916,
            "auditor_fn_violation": 0.0005160297396086849,
            "auditor_fp_violation": 0.004164025499502689,
            "ave_precision_score": 0.8298311350519977,
            "fpr": 0.030735455543358946,
            "logloss": 0.620703253450846,
            "mae": 0.3851863746475081,
            "precision": 0.8970588235294118,
            "recall": 0.5030927835051546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6903926310560968,
            "auditor_fn_violation": 0.006300733176224144,
            "auditor_fp_violation": 0.009205080986891613,
            "ave_precision_score": 0.6522314498949827,
            "fpr": 0.4517543859649123,
            "logloss": 5.741880028169011,
            "mae": 0.4767997658563661,
            "precision": 0.5181286549707602,
            "recall": 0.9445628997867804
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7211848443549532,
            "auditor_fn_violation": 0.0006269308678579104,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.690555192263002,
            "fpr": 0.4489571899012075,
            "logloss": 5.248353081428817,
            "mae": 0.4707788104075786,
            "precision": 0.5304247990815155,
            "recall": 0.9525773195876288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.7918477781167451,
            "auditor_fn_violation": 0.0006242284816518909,
            "auditor_fp_violation": 0.0035295631856164075,
            "ave_precision_score": 0.7526944510325415,
            "fpr": 0.4780701754385965,
            "logloss": 4.022530279441342,
            "mae": 0.4717445188409265,
            "precision": 0.5176991150442478,
            "recall": 0.997867803837953
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7856949758370784,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026282834217158163,
            "ave_precision_score": 0.7407178003975929,
            "fpr": 0.4621295279912184,
            "logloss": 4.212087373068241,
            "mae": 0.45443733028844396,
            "precision": 0.5353200883002207,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7876987321482921,
            "auditor_fn_violation": 0.015121759622937945,
            "auditor_fp_violation": 0.015588491544889312,
            "ave_precision_score": 0.7578220266322777,
            "fpr": 0.25548245614035087,
            "logloss": 2.1836622490507405,
            "mae": 0.3407200250709266,
            "precision": 0.6431852986217458,
            "recall": 0.8955223880597015
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7867287812795685,
            "auditor_fn_violation": 0.004350040173367888,
            "auditor_fp_violation": 0.022556855954607997,
            "ave_precision_score": 0.7540610206046122,
            "fpr": 0.24368825466520308,
            "logloss": 2.387695146455245,
            "mae": 0.32974308470732294,
            "precision": 0.665158371040724,
            "recall": 0.9092783505154639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.531642466372285,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5221439958509286,
            "fpr": 0.03728070175438596,
            "logloss": 0.697669308158516,
            "mae": 0.5010471335171085,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5850561017098334,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5692433897555687,
            "fpr": 0.02854006586169045,
            "logloss": 0.6963363101357404,
            "mae": 0.5003967596919293,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5265294641061018,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5165443512503936,
            "fpr": 0.03728070175438596,
            "logloss": 0.6976286842375662,
            "mae": 0.50135288387537,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5888866161498968,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5725703489964281,
            "fpr": 0.02854006586169045,
            "logloss": 0.6970084337245743,
            "mae": 0.5010205944335552,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7913776144744953,
            "auditor_fn_violation": 0.012648225040212473,
            "auditor_fp_violation": 0.021419943764603388,
            "ave_precision_score": 0.761059253072582,
            "fpr": 0.17324561403508773,
            "logloss": 2.4875174864505065,
            "mae": 0.30472788157184144,
            "precision": 0.7148014440433214,
            "recall": 0.8443496801705757
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7889036739195951,
            "auditor_fn_violation": 0.007536750144284636,
            "auditor_fp_violation": 0.012930123735460704,
            "ave_precision_score": 0.7555020965680728,
            "fpr": 0.16575192096597147,
            "logloss": 2.641130494377037,
            "mae": 0.3033468681779914,
            "precision": 0.7332155477031802,
            "recall": 0.8556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7982096611320925,
            "auditor_fn_violation": 0.008047170164216511,
            "auditor_fp_violation": 0.013615797394162611,
            "ave_precision_score": 0.7751126122171563,
            "fpr": 0.13486842105263158,
            "logloss": 1.8757653921020223,
            "mae": 0.28908850911986445,
            "precision": 0.7458677685950413,
            "recall": 0.7697228144989339
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8007217246264693,
            "auditor_fn_violation": 0.002953591272760191,
            "auditor_fp_violation": 0.0140999675329695,
            "ave_precision_score": 0.77392602293434,
            "fpr": 0.12403951701427003,
            "logloss": 2.043802593211104,
            "mae": 0.2859017131273459,
            "precision": 0.7684426229508197,
            "recall": 0.7731958762886598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7972864700051239,
            "auditor_fn_violation": 0.01374237833389444,
            "auditor_fp_violation": 0.021281335392657717,
            "ave_precision_score": 0.7708276083136159,
            "fpr": 0.17653508771929824,
            "logloss": 2.0414119029343234,
            "mae": 0.30570597396271887,
            "precision": 0.7114695340501792,
            "recall": 0.8464818763326226
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8035267781684867,
            "auditor_fn_violation": 0.0051082417644595845,
            "auditor_fp_violation": 0.01576970053029484,
            "ave_precision_score": 0.7733057498835383,
            "fpr": 0.1602634467618002,
            "logloss": 2.1980419333072967,
            "mae": 0.297334456857208,
            "precision": 0.7411347517730497,
            "recall": 0.8618556701030928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7869181759915679,
            "auditor_fn_violation": 0.014647158942131451,
            "auditor_fp_violation": 0.013647974337649992,
            "ave_precision_score": 0.7579386451084326,
            "fpr": 0.2543859649122807,
            "logloss": 2.1412110289912962,
            "mae": 0.33997313592484907,
            "precision": 0.6436251920122887,
            "recall": 0.8933901918976546
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7880361354069586,
            "auditor_fn_violation": 0.004350040173367888,
            "auditor_fp_violation": 0.022556855954607997,
            "ave_precision_score": 0.7582779654048546,
            "fpr": 0.24368825466520308,
            "logloss": 2.2865058038680974,
            "mae": 0.3292056176112198,
            "precision": 0.665158371040724,
            "recall": 0.9092783505154639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7880474450320947,
            "auditor_fn_violation": 0.015385946208805597,
            "auditor_fp_violation": 0.008952615737990567,
            "ave_precision_score": 0.7589223807940507,
            "fpr": 0.24671052631578946,
            "logloss": 2.1408483283790587,
            "mae": 0.34172882429699886,
            "precision": 0.6439873417721519,
            "recall": 0.8678038379530917
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7874856232128136,
            "auditor_fn_violation": 0.005766858668960133,
            "auditor_fp_violation": 0.019758507135016465,
            "ave_precision_score": 0.7555107013170785,
            "fpr": 0.23380900109769484,
            "logloss": 2.3447813128047237,
            "mae": 0.33245033573698657,
            "precision": 0.6728110599078341,
            "recall": 0.9030927835051547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7933272182392261,
            "auditor_fn_violation": 0.010530056484494824,
            "auditor_fp_violation": 0.007170508098689162,
            "ave_precision_score": 0.7934855885255216,
            "fpr": 0.03837719298245614,
            "logloss": 0.6461267244294704,
            "mae": 0.3963410388790643,
            "precision": 0.8659003831417624,
            "recall": 0.48187633262260127
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8312623810739999,
            "auditor_fn_violation": 0.004515260221575938,
            "auditor_fp_violation": 0.004164025499502689,
            "ave_precision_score": 0.8314589578699518,
            "fpr": 0.030735455543358946,
            "logloss": 0.6204189743591709,
            "mae": 0.38678852200679864,
            "precision": 0.8974358974358975,
            "recall": 0.5051546391752577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6878444911424368,
            "auditor_fn_violation": 0.006300733176224144,
            "auditor_fp_violation": 0.009205080986891613,
            "ave_precision_score": 0.646952378990653,
            "fpr": 0.4517543859649123,
            "logloss": 5.884911873114561,
            "mae": 0.4769753304021518,
            "precision": 0.5181286549707602,
            "recall": 0.9445628997867804
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7190756453825821,
            "auditor_fn_violation": 0.0006269308678579104,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.6870272619987767,
            "fpr": 0.4489571899012075,
            "logloss": 5.324418542018977,
            "mae": 0.4707747524531854,
            "precision": 0.5304247990815155,
            "recall": 0.9525773195876288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.527763601676099,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5191893863104269,
            "fpr": 0.03728070175438596,
            "logloss": 0.7325472140246376,
            "mae": 0.4936796305537747,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5883404576665904,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5740562078990591,
            "fpr": 0.02854006586169045,
            "logloss": 0.7554437148121291,
            "mae": 0.49617097759874934,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8149193283986487,
            "auditor_fn_violation": 0.010062469606852956,
            "auditor_fp_violation": 0.015692447823848564,
            "ave_precision_score": 0.7997032514967665,
            "fpr": 0.15789473684210525,
            "logloss": 2.2169537777518658,
            "mae": 0.29153857201288047,
            "precision": 0.7230769230769231,
            "recall": 0.8017057569296375
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8247147018252348,
            "auditor_fn_violation": 0.0028132673961999426,
            "auditor_fp_violation": 0.004699989177656498,
            "ave_precision_score": 0.8098495909749748,
            "fpr": 0.14709110867178923,
            "logloss": 2.114051212479125,
            "mae": 0.27396755715136056,
            "precision": 0.7545787545787546,
            "recall": 0.8494845360824742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.791953816725656,
            "auditor_fn_violation": 0.009615924138704976,
            "auditor_fp_violation": 0.006536869826937547,
            "ave_precision_score": 0.7922192103349134,
            "fpr": 0.03728070175438596,
            "logloss": 0.6494364188189322,
            "mae": 0.39634016508097647,
            "precision": 0.8671875,
            "recall": 0.47334754797441364
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8304830990081891,
            "auditor_fn_violation": 0.0029309583894440326,
            "auditor_fp_violation": 0.004164025499502689,
            "ave_precision_score": 0.8307635391750919,
            "fpr": 0.030735455543358946,
            "logloss": 0.6232805443866078,
            "mae": 0.3870396973160387,
            "precision": 0.8962962962962963,
            "recall": 0.49896907216494846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5376906418496723,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5294096502809191,
            "fpr": 0.03728070175438596,
            "logloss": 0.7544968613687986,
            "mae": 0.4935990237516531,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5708054263405122,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5593698236993133,
            "fpr": 0.02854006586169045,
            "logloss": 0.7874267949062386,
            "mae": 0.4967511630464758,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7864993262975397,
            "auditor_fn_violation": 0.016861182807765687,
            "auditor_fp_violation": 0.02081600728684013,
            "ave_precision_score": 0.7509528487982807,
            "fpr": 0.1611842105263158,
            "logloss": 2.339487191178649,
            "mae": 0.32565010825515184,
            "precision": 0.7173076923076923,
            "recall": 0.7953091684434968
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.7899842859388772,
            "auditor_fn_violation": 0.0015118766055201612,
            "auditor_fp_violation": 0.019201929469241357,
            "ave_precision_score": 0.7526215294553615,
            "fpr": 0.14928649835345773,
            "logloss": 2.5102774129588674,
            "mae": 0.31372483690094477,
            "precision": 0.7472118959107806,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7970328547246157,
            "auditor_fn_violation": 0.009494351550518088,
            "auditor_fp_violation": 0.02277880083957071,
            "ave_precision_score": 0.7714624796598278,
            "fpr": 0.1524122807017544,
            "logloss": 1.980407827169939,
            "mae": 0.2874542923030375,
            "precision": 0.7326923076923076,
            "recall": 0.8123667377398721
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8026757757276789,
            "auditor_fn_violation": 0.006398316113481283,
            "auditor_fp_violation": 0.013690264528996148,
            "ave_precision_score": 0.7739823021607224,
            "fpr": 0.1350164654226125,
            "logloss": 2.125159331742135,
            "mae": 0.2824935355110092,
            "precision": 0.7611650485436893,
            "recall": 0.8082474226804124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5265294641061018,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5165443512503936,
            "fpr": 0.03728070175438596,
            "logloss": 0.6973357152396297,
            "mae": 0.5013206360306133,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5888866161498968,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5725703489964281,
            "fpr": 0.02854006586169045,
            "logloss": 0.6964242975744569,
            "mae": 0.5008460231918666,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5357186198635796,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5258562900480067,
            "fpr": 0.03728070175438596,
            "logloss": 0.6988721441337586,
            "mae": 0.501414634908239,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.569617525361052,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.5561479053787995,
            "fpr": 0.02854006586169045,
            "logloss": 0.6994863977836143,
            "mae": 0.5016977738274178,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.770213589777031,
            "auditor_fn_violation": 0.019007406576141847,
            "auditor_fp_violation": 0.0008465011286681692,
            "ave_precision_score": 0.7671271137376612,
            "fpr": 0.08333333333333333,
            "logloss": 0.7660105040782793,
            "mae": 0.34756793455821217,
            "precision": 0.7744807121661721,
            "recall": 0.5565031982942431
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7946345363054892,
            "auditor_fn_violation": 0.012294182217343585,
            "auditor_fp_violation": 0.007877120019789432,
            "ave_precision_score": 0.7905326453162237,
            "fpr": 0.07574094401756312,
            "logloss": 0.7595760873861372,
            "mae": 0.3386558848006428,
            "precision": 0.8083333333333333,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.5282020678994184,
            "auditor_fn_violation": 0.005236973029588927,
            "auditor_fp_violation": 0.009403092946813988,
            "ave_precision_score": 0.5185461693942525,
            "fpr": 0.03728070175438596,
            "logloss": 0.6983601026317953,
            "mae": 0.5014461314207629,
            "precision": 0.45161290322580644,
            "recall": 0.05970149253731343
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5815587252793349,
            "auditor_fn_violation": 0.0026842599612977827,
            "auditor_fp_violation": 0.0030920981431950658,
            "ave_precision_score": 0.565484049178128,
            "fpr": 0.02854006586169045,
            "logloss": 0.698213050307049,
            "mae": 0.5013456587341301,
            "precision": 0.559322033898305,
            "recall": 0.06804123711340206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7879897156674266,
            "auditor_fn_violation": 0.009784255414656044,
            "auditor_fp_violation": 0.022392677517722084,
            "ave_precision_score": 0.7597978199122039,
            "fpr": 0.2598684210526316,
            "logloss": 2.1058671036129235,
            "mae": 0.3355045261948059,
            "precision": 0.6419939577039275,
            "recall": 0.906183368869936
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.78931144220936,
            "auditor_fn_violation": 0.0021523872033677735,
            "auditor_fp_violation": 0.023584978587220373,
            "ave_precision_score": 0.7603452568079304,
            "fpr": 0.2491767288693743,
            "logloss": 2.2459129896742085,
            "mae": 0.3276039551254505,
            "precision": 0.6637037037037037,
            "recall": 0.9237113402061856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7915205948380131,
            "auditor_fn_violation": 0.013711985186847716,
            "auditor_fp_violation": 0.016217179517642878,
            "ave_precision_score": 0.7640764223760735,
            "fpr": 0.23135964912280702,
            "logloss": 2.0490654435715467,
            "mae": 0.32465809205977914,
            "precision": 0.665079365079365,
            "recall": 0.8933901918976546
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7903562037469454,
            "auditor_fn_violation": 0.00300338361605577,
            "auditor_fp_violation": 0.01865050530037156,
            "ave_precision_score": 0.7622622009211151,
            "fpr": 0.2261251372118551,
            "logloss": 2.186554663267515,
            "mae": 0.3186203141402326,
            "precision": 0.6806201550387597,
            "recall": 0.9051546391752577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6875121584047142,
            "auditor_fn_violation": 0.0007645045449444507,
            "auditor_fp_violation": 0.003014732089818236,
            "ave_precision_score": 0.6569156412287533,
            "fpr": 0.47149122807017546,
            "logloss": 4.231105858650769,
            "mae": 0.469519824916987,
            "precision": 0.5190156599552572,
            "recall": 0.9893390191897654
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.729192196771266,
            "auditor_fn_violation": 0.0015616689488157347,
            "auditor_fp_violation": 0.0012110717727514119,
            "ave_precision_score": 0.7056121728284872,
            "fpr": 0.4654226125137212,
            "logloss": 3.7270937745220447,
            "mae": 0.45865015860577446,
            "precision": 0.5309734513274337,
            "recall": 0.9896907216494846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7891068071700978,
            "auditor_fn_violation": 0.015764691579695504,
            "auditor_fp_violation": 0.02039275672250604,
            "ave_precision_score": 0.7649297698459206,
            "fpr": 0.1524122807017544,
            "logloss": 2.6766120016896817,
            "mae": 0.31584208362339544,
            "precision": 0.728515625,
            "recall": 0.7953091684434968
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7884319071880406,
            "auditor_fn_violation": 0.006755915669876767,
            "auditor_fp_violation": 0.01675401843921193,
            "ave_precision_score": 0.7615737327760262,
            "fpr": 0.1437980241492865,
            "logloss": 2.700950738275232,
            "mae": 0.31066462075258344,
            "precision": 0.7504761904761905,
            "recall": 0.8123711340206186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5347754004906168,
            "auditor_fn_violation": 0.008007425279616974,
            "auditor_fp_violation": 0.014427646429844366,
            "ave_precision_score": 0.5256345715228392,
            "fpr": 0.09100877192982457,
            "logloss": 0.6977245771826908,
            "mae": 0.5010306228017598,
            "precision": 0.49079754601226994,
            "recall": 0.17057569296375266
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5801819510288146,
            "auditor_fn_violation": 0.0055903221790940035,
            "auditor_fp_violation": 0.012048875764650102,
            "ave_precision_score": 0.5661243892835652,
            "fpr": 0.07464324917672886,
            "logloss": 0.6964015550922299,
            "mae": 0.500389763670355,
            "precision": 0.5244755244755245,
            "recall": 0.15463917525773196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6862679170318272,
            "auditor_fn_violation": 0.002242079078292776,
            "auditor_fp_violation": 0.011823789156865078,
            "ave_precision_score": 0.6357469228283936,
            "fpr": 0.07017543859649122,
            "logloss": 0.6877832081895626,
            "mae": 0.49444387072141754,
            "precision": 0.6049382716049383,
            "recall": 0.208955223880597
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7601234643538346,
            "auditor_fn_violation": 0.017146672400330455,
            "auditor_fp_violation": 0.0007343733090088276,
            "ave_precision_score": 0.7033385489194446,
            "fpr": 0.04939626783754116,
            "logloss": 0.681810231068604,
            "mae": 0.491349579833865,
            "precision": 0.7204968944099379,
            "recall": 0.23917525773195877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7954899624623532,
            "auditor_fn_violation": 0.01222505891594659,
            "auditor_fp_violation": 0.0250163359866936,
            "ave_precision_score": 0.7689618621762324,
            "fpr": 0.18201754385964913,
            "logloss": 2.0681323621799956,
            "mae": 0.31180643166902755,
            "precision": 0.7056737588652482,
            "recall": 0.8486140724946695
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8000675434493978,
            "auditor_fn_violation": 0.0027046295562823215,
            "auditor_fp_violation": 0.016565915802167562,
            "ave_precision_score": 0.769196166821242,
            "fpr": 0.16355653128430298,
            "logloss": 2.2408113707591117,
            "mae": 0.3027148442802916,
            "precision": 0.7367491166077739,
            "recall": 0.8597938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.8190803484258234,
            "auditor_fn_violation": 0.008706467661691546,
            "auditor_fp_violation": 0.00034404578036513413,
            "ave_precision_score": 0.7703961746294056,
            "fpr": 0.005482456140350877,
            "logloss": 0.6498340045183754,
            "mae": 0.45874058233018505,
            "precision": 0.9596774193548387,
            "recall": 0.2537313432835821
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.8330780514435736,
            "auditor_fn_violation": 0.0037547953421526144,
            "auditor_fp_violation": 0.0015743933045768211,
            "ave_precision_score": 0.7860180837144766,
            "fpr": 0.007683863885839737,
            "logloss": 0.6361909286008148,
            "mae": 0.45512548319660084,
            "precision": 0.9513888888888888,
            "recall": 0.2824742268041237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6998345981604852,
            "auditor_fn_violation": 0.006950678936146338,
            "auditor_fp_violation": 0.007729891885469886,
            "ave_precision_score": 0.6513902887621721,
            "fpr": 0.45285087719298245,
            "logloss": 6.929538183066178,
            "mae": 0.4787036782116343,
            "precision": 0.5180863477246208,
            "recall": 0.9466950959488273
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7317595761601503,
            "auditor_fn_violation": 0.0007491484377652296,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.690317637511677,
            "fpr": 0.4489571899012075,
            "logloss": 6.458982292715161,
            "mae": 0.47184744040550824,
            "precision": 0.5315005727376861,
            "recall": 0.9567010309278351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7719620359195769,
            "auditor_fn_violation": 0.01535321512737067,
            "auditor_fp_violation": 0.011373311948041667,
            "ave_precision_score": 0.7689031758799687,
            "fpr": 0.1206140350877193,
            "logloss": 0.7623665242658172,
            "mae": 0.3468689345090911,
            "precision": 0.7393364928909952,
            "recall": 0.6652452025586354
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7955823200032844,
            "auditor_fn_violation": 0.004137291070195894,
            "auditor_fp_violation": 0.008101297135171078,
            "ave_precision_score": 0.7915154685276983,
            "fpr": 0.10647639956092206,
            "logloss": 0.7548458671020205,
            "mae": 0.33727059359370315,
            "precision": 0.7815315315315315,
            "recall": 0.7154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8139796359074848,
            "auditor_fn_violation": 0.0015500504993828088,
            "auditor_fp_violation": 0.003777078135519386,
            "ave_precision_score": 0.8138122799469516,
            "fpr": 0.03399122807017544,
            "logloss": 0.6287180041322282,
            "mae": 0.4177246434172969,
            "precision": 0.8744939271255061,
            "recall": 0.4605543710021322
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8550115887146187,
            "auditor_fn_violation": 0.006629171523306219,
            "auditor_fp_violation": 0.0055039346948872175,
            "ave_precision_score": 0.8543740151451278,
            "fpr": 0.024149286498353458,
            "logloss": 0.5778323535669582,
            "mae": 0.41013846364032275,
            "precision": 0.912,
            "recall": 0.47010309278350515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7830007718400516,
            "auditor_fn_violation": 0.01422165488347735,
            "auditor_fp_violation": 0.020882836323313933,
            "ave_precision_score": 0.746781739527529,
            "fpr": 0.15570175438596492,
            "logloss": 3.12080571997624,
            "mae": 0.3124360684547954,
            "precision": 0.7258687258687259,
            "recall": 0.8017057569296375
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7869036945415904,
            "auditor_fn_violation": 0.008700080346735776,
            "auditor_fp_violation": 0.013775297227934026,
            "ave_precision_score": 0.7494960184986633,
            "fpr": 0.14818880351262348,
            "logloss": 3.1120231426760516,
            "mae": 0.30587736199584237,
            "precision": 0.7462406015037594,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 29198,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7723506401303792,
            "auditor_fn_violation": 0.013461826207309324,
            "auditor_fp_violation": 0.027422181299750513,
            "ave_precision_score": 0.7214071189365986,
            "fpr": 0.14035087719298245,
            "logloss": 3.018852786758694,
            "mae": 0.3934633156709504,
            "precision": 0.7050691244239631,
            "recall": 0.652452025586354
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7675976757199847,
            "auditor_fn_violation": 0.01914741928547988,
            "auditor_fp_violation": 0.011317079204093939,
            "ave_precision_score": 0.7153824338009579,
            "fpr": 0.13830954994511527,
            "logloss": 3.1502608554343356,
            "mae": 0.39540658058633393,
            "precision": 0.7123287671232876,
            "recall": 0.643298969072165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6291923133190064,
            "auditor_fn_violation": 0.008942599034900696,
            "auditor_fp_violation": 0.012143083442239912,
            "ave_precision_score": 0.5582477692818193,
            "fpr": 0.07236842105263158,
            "logloss": 0.6839081044678784,
            "mae": 0.49156865738985833,
            "precision": 0.6071428571428571,
            "recall": 0.21748400852878466
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6983870173026676,
            "auditor_fn_violation": 0.01665101225570632,
            "auditor_fp_violation": 0.0007343733090088276,
            "ave_precision_score": 0.5992096305363783,
            "fpr": 0.04939626783754116,
            "logloss": 0.680330171207271,
            "mae": 0.4898242534973488,
            "precision": 0.7222222222222222,
            "recall": 0.24123711340206186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.8157278362957794,
            "auditor_fn_violation": 0.006284367635506676,
            "auditor_fp_violation": 0.013016811215397415,
            "ave_precision_score": 0.8142618265441057,
            "fpr": 0.41776315789473684,
            "logloss": 1.4789650302275457,
            "mae": 0.43409935616926276,
            "precision": 0.5201511335012594,
            "recall": 0.8805970149253731
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8492759108528407,
            "auditor_fn_violation": 0.0022338655833059862,
            "auditor_fp_violation": 0.0029220327453193455,
            "ave_precision_score": 0.8477382185762607,
            "fpr": 0.4149286498353458,
            "logloss": 1.2434252073300969,
            "mae": 0.42602115599844387,
            "precision": 0.5401459854014599,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7974185054770666,
            "auditor_fn_violation": 0.008900516215912918,
            "auditor_fp_violation": 0.02277880083957071,
            "ave_precision_score": 0.7717810812640257,
            "fpr": 0.1524122807017544,
            "logloss": 1.982463327253126,
            "mae": 0.2872664039971612,
            "precision": 0.7332053742802304,
            "recall": 0.814498933901919
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8027884083350618,
            "auditor_fn_violation": 0.00680344472484072,
            "auditor_fp_violation": 0.013690264528996148,
            "ave_precision_score": 0.7740880789619149,
            "fpr": 0.1350164654226125,
            "logloss": 2.1257603709176847,
            "mae": 0.2821915722933294,
            "precision": 0.7616279069767442,
            "recall": 0.8103092783505155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8099164520309423,
            "auditor_fn_violation": 0.014883290315340594,
            "auditor_fp_violation": 0.020268999247554553,
            "ave_precision_score": 0.7912597007227655,
            "fpr": 0.15789473684210525,
            "logloss": 2.3987256884057286,
            "mae": 0.29398668209218204,
            "precision": 0.7230769230769231,
            "recall": 0.8017057569296375
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8177672198150958,
            "auditor_fn_violation": 0.0046442676564780955,
            "auditor_fp_violation": 0.017470354509052117,
            "ave_precision_score": 0.7971499426351203,
            "fpr": 0.14050493962678376,
            "logloss": 2.322725720953903,
            "mae": 0.27793573661703835,
            "precision": 0.7634011090573013,
            "recall": 0.8515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8151607273164722,
            "auditor_fn_violation": 0.009106254442075341,
            "auditor_fp_violation": 0.011967347827808806,
            "ave_precision_score": 0.7998943103657316,
            "fpr": 0.15679824561403508,
            "logloss": 2.2117423491046133,
            "mae": 0.2908585896007807,
            "precision": 0.7239382239382239,
            "recall": 0.7995735607675906
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8247650037024041,
            "auditor_fn_violation": 0.0026367309063338165,
            "auditor_fp_violation": 0.011275851228851335,
            "ave_precision_score": 0.8098600886126387,
            "fpr": 0.14270032930845225,
            "logloss": 2.1154317751401597,
            "mae": 0.2731093071025766,
            "precision": 0.7592592592592593,
            "recall": 0.845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6854420750051905,
            "auditor_fn_violation": 0.006300733176224144,
            "auditor_fp_violation": 0.009205080986891613,
            "ave_precision_score": 0.6442062217588649,
            "fpr": 0.4517543859649123,
            "logloss": 5.9097569724576795,
            "mae": 0.4771649888567512,
            "precision": 0.5181286549707602,
            "recall": 0.9445628997867804
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7166554003468238,
            "auditor_fn_violation": 0.0006269308678579104,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.6849322411847759,
            "fpr": 0.4489571899012075,
            "logloss": 5.321579546985202,
            "mae": 0.47065772588692045,
            "precision": 0.5304247990815155,
            "recall": 0.9525773195876288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8175960699008467,
            "auditor_fn_violation": 0.0025039277297721914,
            "auditor_fp_violation": 0.007465050889073703,
            "ave_precision_score": 0.8175731993004084,
            "fpr": 0.04276315789473684,
            "logloss": 0.5746084937881537,
            "mae": 0.39575667966059164,
            "precision": 0.8555555555555555,
            "recall": 0.4925373134328358
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8420200225932417,
            "auditor_fn_violation": 0.0058166510122557155,
            "auditor_fp_violation": 0.0005024659482691975,
            "ave_precision_score": 0.8419347545979714,
            "fpr": 0.029637760702524697,
            "logloss": 0.5617003020782853,
            "mae": 0.38746091828126417,
            "precision": 0.9,
            "recall": 0.5010309278350515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7729091198654892,
            "auditor_fn_violation": 0.016781693038566563,
            "auditor_fp_violation": 0.01827897905033465,
            "ave_precision_score": 0.76278630469548,
            "fpr": 0.16557017543859648,
            "logloss": 2.3847258182595876,
            "mae": 0.3141798046780671,
            "precision": 0.7096153846153846,
            "recall": 0.7867803837953091
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7940684136583632,
            "auditor_fn_violation": 0.010698563943553596,
            "auditor_fp_violation": 0.012121024721324664,
            "ave_precision_score": 0.7882117393870917,
            "fpr": 0.15148188803512624,
            "logloss": 2.036514940460104,
            "mae": 0.30427990576453845,
            "precision": 0.744916820702403,
            "recall": 0.8309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 29198,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7566807715463377,
            "auditor_fn_violation": 0.013461826207309324,
            "auditor_fp_violation": 0.027422181299750513,
            "ave_precision_score": 0.7071349038541956,
            "fpr": 0.14035087719298245,
            "logloss": 3.8156177334581045,
            "mae": 0.3892868832269679,
            "precision": 0.7050691244239631,
            "recall": 0.652452025586354
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7554482230122535,
            "auditor_fn_violation": 0.018706078060814563,
            "auditor_fp_violation": 0.010263189086954958,
            "ave_precision_score": 0.7041465144810515,
            "fpr": 0.13721185510428102,
            "logloss": 3.778383751559967,
            "mae": 0.3936954927290191,
            "precision": 0.713302752293578,
            "recall": 0.6412371134020619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7957956564254348,
            "auditor_fn_violation": 0.009863745183855164,
            "auditor_fp_violation": 0.0213209377846422,
            "ave_precision_score": 0.7656387013137484,
            "fpr": 0.24561403508771928,
            "logloss": 2.175221622289719,
            "mae": 0.3318823476479258,
            "precision": 0.6527131782945736,
            "recall": 0.8976545842217484
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.794213120583907,
            "auditor_fn_violation": 0.004571842429866353,
            "auditor_fp_violation": 0.014646238204933961,
            "ave_precision_score": 0.7586314305913574,
            "fpr": 0.2261251372118551,
            "logloss": 2.4320733313448213,
            "mae": 0.3222648901297505,
            "precision": 0.6835637480798771,
            "recall": 0.9175257731958762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7944239096170411,
            "auditor_fn_violation": 0.011759809972692927,
            "auditor_fp_violation": 0.01674191121143717,
            "ave_precision_score": 0.7643242242204175,
            "fpr": 0.22916666666666666,
            "logloss": 2.170475399583286,
            "mae": 0.32623677530985634,
            "precision": 0.6645264847512039,
            "recall": 0.8827292110874201
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7920590277748607,
            "auditor_fn_violation": 0.00566274740570575,
            "auditor_fp_violation": 0.021103569827306327,
            "ave_precision_score": 0.7565083468574771,
            "fpr": 0.21295279912184412,
            "logloss": 2.433399896691466,
            "mae": 0.3171875527001811,
            "precision": 0.693522906793049,
            "recall": 0.9051546391752577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8133048763285831,
            "auditor_fn_violation": 0.011577451090412597,
            "auditor_fp_violation": 0.015811254999801995,
            "ave_precision_score": 0.7962770690366383,
            "fpr": 0.1524122807017544,
            "logloss": 2.295843009026067,
            "mae": 0.2903848562907492,
            "precision": 0.728515625,
            "recall": 0.7953091684434968
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8210356350030847,
            "auditor_fn_violation": 0.003324770559145383,
            "auditor_fp_violation": 0.012311704106821683,
            "ave_precision_score": 0.8019664077411358,
            "fpr": 0.14050493962678376,
            "logloss": 2.260679308606519,
            "mae": 0.2733619746223727,
            "precision": 0.7602996254681648,
            "recall": 0.8371134020618557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7567565751493595,
            "auditor_fn_violation": 0.0020386787865185356,
            "auditor_fp_violation": 0.011675280186923305,
            "ave_precision_score": 0.7261927215801532,
            "fpr": 0.43201754385964913,
            "logloss": 4.878483612167066,
            "mae": 0.4560052157527116,
            "precision": 0.5292712066905615,
            "recall": 0.9445628997867804
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7483042685956569,
            "auditor_fn_violation": 0.00012221756990731932,
            "auditor_fp_violation": 0.002051091768319405,
            "ave_precision_score": 0.7123987550204447,
            "fpr": 0.43249176728869376,
            "logloss": 5.10749660951761,
            "mae": 0.4499480391154915,
            "precision": 0.5402567094515752,
            "recall": 0.954639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.82270883518875,
            "auditor_fn_violation": 0.002700314218381775,
            "auditor_fp_violation": 0.005333947170409095,
            "ave_precision_score": 0.822784018162054,
            "fpr": 0.04276315789473684,
            "logloss": 0.5675770117132043,
            "mae": 0.3962920641101766,
            "precision": 0.8621908127208481,
            "recall": 0.5202558635394456
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8432618233321576,
            "auditor_fn_violation": 0.010030893885726574,
            "auditor_fp_violation": 0.0048339800971949525,
            "ave_precision_score": 0.8434223819359206,
            "fpr": 0.03512623490669594,
            "logloss": 0.55745653182038,
            "mae": 0.3870617376985979,
            "precision": 0.8900343642611683,
            "recall": 0.534020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8146095653568868,
            "auditor_fn_violation": 0.009106254442075341,
            "auditor_fp_violation": 0.013177695932834342,
            "ave_precision_score": 0.7994294146228086,
            "fpr": 0.15570175438596492,
            "logloss": 2.207820163655372,
            "mae": 0.2914045721108081,
            "precision": 0.7253384912959381,
            "recall": 0.7995735607675906
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8242396353736796,
            "auditor_fn_violation": 0.0023764527481978594,
            "auditor_fp_violation": 0.005426632241307339,
            "ave_precision_score": 0.8094320505718171,
            "fpr": 0.14489571899012074,
            "logloss": 2.101769967038,
            "mae": 0.2738029963720612,
            "precision": 0.7564575645756457,
            "recall": 0.845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7586074033711022,
            "auditor_fn_violation": 0.017314742079078297,
            "auditor_fp_violation": 0.008368480456219556,
            "ave_precision_score": 0.7582507307415844,
            "fpr": 0.08771929824561403,
            "logloss": 1.5316356928514623,
            "mae": 0.35079469175300804,
            "precision": 0.773371104815864,
            "recall": 0.582089552238806
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7834656647123082,
            "auditor_fn_violation": 0.007898876277343352,
            "auditor_fp_violation": 0.006539787572857564,
            "ave_precision_score": 0.7830869817311394,
            "fpr": 0.0845225027442371,
            "logloss": 1.3691849839585906,
            "mae": 0.34292048634217753,
            "precision": 0.8010335917312662,
            "recall": 0.6391752577319587
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7969415246635092,
            "auditor_fn_violation": 0.001767478397486267,
            "auditor_fp_violation": 0.005863629163201458,
            "ave_precision_score": 0.7955010059243601,
            "fpr": 0.029605263157894735,
            "logloss": 0.6558302642394919,
            "mae": 0.429337918958545,
            "precision": 0.88,
            "recall": 0.42217484008528783
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8333472925967421,
            "auditor_fn_violation": 0.0026887865379610016,
            "auditor_fp_violation": 0.0027931953226862094,
            "ave_precision_score": 0.8322394262476257,
            "fpr": 0.020856201975850714,
            "logloss": 0.6301605170986041,
            "mae": 0.42424744012654153,
            "precision": 0.9128440366972477,
            "recall": 0.41030927835051545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7950853744297461,
            "auditor_fn_violation": 0.01374237833389444,
            "auditor_fp_violation": 0.02182091798344621,
            "ave_precision_score": 0.7611100086815454,
            "fpr": 0.1787280701754386,
            "logloss": 2.2907359447940836,
            "mae": 0.3212521467592747,
            "precision": 0.7089285714285715,
            "recall": 0.8464818763326226
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7981348079934938,
            "auditor_fn_violation": 0.00628967827356366,
            "auditor_fp_violation": 0.015653746849925026,
            "ave_precision_score": 0.763582129065123,
            "fpr": 0.16575192096597147,
            "logloss": 2.411165383595063,
            "mae": 0.3126757971264794,
            "precision": 0.7350877192982456,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7937903739245589,
            "auditor_fn_violation": 0.010675008416563799,
            "auditor_fp_violation": 0.01846461526276188,
            "ave_precision_score": 0.7694493573281825,
            "fpr": 0.2532894736842105,
            "logloss": 1.9285882844909519,
            "mae": 0.33640962537212643,
            "precision": 0.6478658536585366,
            "recall": 0.906183368869936
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7921395897838636,
            "auditor_fn_violation": 0.004666900539794268,
            "auditor_fp_violation": 0.02361589956865232,
            "ave_precision_score": 0.7649267992852495,
            "fpr": 0.24698133918770582,
            "logloss": 2.1095873550065005,
            "mae": 0.3290469928283723,
            "precision": 0.6661721068249258,
            "recall": 0.9257731958762887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6935684795267056,
            "auditor_fn_violation": 0.006950678936146338,
            "auditor_fp_violation": 0.009205080986891613,
            "ave_precision_score": 0.6538637422103328,
            "fpr": 0.4517543859649123,
            "logloss": 5.84716941998284,
            "mae": 0.4761815630426024,
            "precision": 0.5186915887850467,
            "recall": 0.9466950959488273
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.7275032441772936,
            "auditor_fn_violation": 0.0013579729989702041,
            "auditor_fp_violation": 0.0014713233664703342,
            "ave_precision_score": 0.6951388447778252,
            "fpr": 0.4489571899012075,
            "logloss": 5.336028932642029,
            "mae": 0.46970162787497083,
            "precision": 0.5320366132723112,
            "recall": 0.9587628865979382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8198060052689692,
            "auditor_fn_violation": 0.004173212882953665,
            "auditor_fp_violation": 0.007465050889073703,
            "ave_precision_score": 0.8198515031472173,
            "fpr": 0.04276315789473684,
            "logloss": 0.5694938927213048,
            "mae": 0.39394882414489985,
            "precision": 0.8576642335766423,
            "recall": 0.5010660980810234
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8402007194567349,
            "auditor_fn_violation": 0.010807201783471205,
            "auditor_fp_violation": 0.0047463706498044244,
            "ave_precision_score": 0.8402869536910915,
            "fpr": 0.03293084522502744,
            "logloss": 0.5589429258194837,
            "mae": 0.38550711657062714,
            "precision": 0.8920863309352518,
            "recall": 0.511340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8126291586225882,
            "auditor_fn_violation": 0.010310290652003146,
            "auditor_fp_violation": 0.01880371074412895,
            "ave_precision_score": 0.7956625526572538,
            "fpr": 0.15350877192982457,
            "logloss": 2.2928933382215106,
            "mae": 0.29089527410136123,
            "precision": 0.726027397260274,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.821685781826806,
            "auditor_fn_violation": 0.003324770559145383,
            "auditor_fp_violation": 0.01281674680354355,
            "ave_precision_score": 0.8042560914360825,
            "fpr": 0.141602634467618,
            "logloss": 2.2098665255856993,
            "mae": 0.2739846105966519,
            "precision": 0.7588785046728972,
            "recall": 0.8371134020618557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7635133360854738,
            "auditor_fn_violation": 0.003502225713537575,
            "auditor_fp_violation": 0.01075947487228229,
            "ave_precision_score": 0.7606596104882777,
            "fpr": 0.4440789473684211,
            "logloss": 3.449330080340017,
            "mae": 0.4705952181522557,
            "precision": 0.5212765957446809,
            "recall": 0.9402985074626866
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7863677814506568,
            "auditor_fn_violation": 0.004266298505098058,
            "auditor_fp_violation": 0.002422143545502818,
            "ave_precision_score": 0.7828562791705578,
            "fpr": 0.44017563117453345,
            "logloss": 3.307552106630194,
            "mae": 0.4628456818149818,
            "precision": 0.5348027842227379,
            "recall": 0.9505154639175257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8112719400888734,
            "auditor_fn_violation": 0.009901152134066511,
            "auditor_fp_violation": 0.016934972872361488,
            "ave_precision_score": 0.7942752039288185,
            "fpr": 0.15899122807017543,
            "logloss": 2.292893261241964,
            "mae": 0.29556764404625946,
            "precision": 0.7189922480620154,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8194725561446605,
            "auditor_fn_violation": 0.0015888284087951427,
            "auditor_fp_violation": 0.0059162144473132285,
            "ave_precision_score": 0.8012669287624506,
            "fpr": 0.14270032930845225,
            "logloss": 2.239496912703094,
            "mae": 0.2800258464544707,
            "precision": 0.7556390977443609,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7584616553334528,
            "auditor_fn_violation": 0.027176149328545243,
            "auditor_fp_violation": 0.07098728763217299,
            "ave_precision_score": 0.7516512533789173,
            "fpr": 0.17543859649122806,
            "logloss": 2.3136555993376575,
            "mae": 0.33980620844793424,
            "precision": 0.68,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7382430559460876,
            "auditor_fn_violation": 0.03213643102062987,
            "auditor_fp_violation": 0.06944852429616118,
            "ave_precision_score": 0.7254145194644968,
            "fpr": 0.1986827661909989,
            "logloss": 2.501559641543998,
            "mae": 0.34204703508213496,
            "precision": 0.6691042047531993,
            "recall": 0.7546391752577319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5375609986900349,
            "auditor_fn_violation": 0.008007425279616974,
            "auditor_fp_violation": 0.014427646429844366,
            "ave_precision_score": 0.5280792906998676,
            "fpr": 0.09100877192982457,
            "logloss": 0.6982687736768206,
            "mae": 0.5009630629629419,
            "precision": 0.49079754601226994,
            "recall": 0.17057569296375266
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5722625761198511,
            "auditor_fn_violation": 0.0055903221790940035,
            "auditor_fp_violation": 0.012048875764650102,
            "ave_precision_score": 0.559182828457675,
            "fpr": 0.07464324917672886,
            "logloss": 0.6978379713753493,
            "mae": 0.500785517803793,
            "precision": 0.5244755244755245,
            "recall": 0.15463917525773196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.759863892986758,
            "auditor_fn_violation": 0.017812722103766887,
            "auditor_fp_violation": 0.006732406637360899,
            "ave_precision_score": 0.7594311129814726,
            "fpr": 0.08881578947368421,
            "logloss": 1.5276371499587393,
            "mae": 0.3506239848993636,
            "precision": 0.7737430167597765,
            "recall": 0.5906183368869936
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7841260768613372,
            "auditor_fn_violation": 0.006210463181957079,
            "auditor_fp_violation": 0.006539787572857564,
            "ave_precision_score": 0.7834075740702677,
            "fpr": 0.0845225027442371,
            "logloss": 1.3651460710626855,
            "mae": 0.34267311254008054,
            "precision": 0.80306905370844,
            "recall": 0.6474226804123712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7859078378144924,
            "auditor_fn_violation": 0.016052257509445257,
            "auditor_fp_violation": 0.02081600728684013,
            "ave_precision_score": 0.7496649097793596,
            "fpr": 0.1611842105263158,
            "logloss": 2.364078520219939,
            "mae": 0.3260974648465778,
            "precision": 0.7178502879078695,
            "recall": 0.7974413646055437
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7883904509070926,
            "auditor_fn_violation": 0.0015118766055201612,
            "auditor_fp_violation": 0.0176094989254959,
            "ave_precision_score": 0.7491276920985954,
            "fpr": 0.150384193194292,
            "logloss": 2.57408791408883,
            "mae": 0.31401205445822783,
            "precision": 0.7458256029684601,
            "recall": 0.8288659793814434
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7921125629920567,
            "auditor_fn_violation": 0.012739404481352634,
            "auditor_fp_violation": 0.022895132866025108,
            "ave_precision_score": 0.7634148401988531,
            "fpr": 0.17105263157894737,
            "logloss": 2.403454333401003,
            "mae": 0.30599577741562506,
            "precision": 0.7163636363636363,
            "recall": 0.8400852878464818
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7878316002652135,
            "auditor_fn_violation": 0.0049430217162515465,
            "auditor_fp_violation": 0.015012136485212043,
            "ave_precision_score": 0.7546814383500928,
            "fpr": 0.16465422612513722,
            "logloss": 2.602910314015832,
            "mae": 0.3055416351801723,
            "precision": 0.7340425531914894,
            "recall": 0.8536082474226804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8158222035064996,
            "auditor_fn_violation": 0.009681386301574835,
            "auditor_fp_violation": 0.008712526236584694,
            "ave_precision_score": 0.8014990120827019,
            "fpr": 0.15350877192982457,
            "logloss": 2.2192928736321607,
            "mae": 0.2901027687438688,
            "precision": 0.7276264591439688,
            "recall": 0.7974413646055437
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8254365924947712,
            "auditor_fn_violation": 0.0030599658243461937,
            "auditor_fp_violation": 0.010397180006493409,
            "ave_precision_score": 0.8106871900138473,
            "fpr": 0.141602634467618,
            "logloss": 2.106336508762851,
            "mae": 0.272460707110132,
            "precision": 0.7597765363128491,
            "recall": 0.8412371134020619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6765267730331298,
            "auditor_fn_violation": 0.0014004226985373884,
            "auditor_fp_violation": 0.006925468298285222,
            "ave_precision_score": 0.6119008660619181,
            "fpr": 0.43201754385964913,
            "logloss": 7.209948001119294,
            "mae": 0.4578028255763027,
            "precision": 0.5303933253873659,
            "recall": 0.9488272921108742
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7068277929740724,
            "auditor_fn_violation": 0.00015390360654995715,
            "auditor_fp_violation": 0.0007137593213875433,
            "ave_precision_score": 0.6507780487266603,
            "fpr": 0.429198682766191,
            "logloss": 6.702449504504006,
            "mae": 0.4542567410393087,
            "precision": 0.5416178194607268,
            "recall": 0.9525773195876288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7833168235225221,
            "auditor_fn_violation": 0.016070960984550936,
            "auditor_fp_violation": 0.02031107678903807,
            "ave_precision_score": 0.7517658295530583,
            "fpr": 0.15460526315789475,
            "logloss": 2.9375625653523607,
            "mae": 0.31803225601045204,
            "precision": 0.724609375,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7901595763034248,
            "auditor_fn_violation": 0.006755915669876767,
            "auditor_fp_violation": 0.014331874893709129,
            "ave_precision_score": 0.7584954288450789,
            "fpr": 0.14709110867178923,
            "logloss": 2.8923631256340347,
            "mae": 0.31273092356617227,
            "precision": 0.7462121212121212,
            "recall": 0.8123711340206186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7851490189417053,
            "auditor_fn_violation": 0.015481801518722181,
            "auditor_fp_violation": 0.020573442635935215,
            "ave_precision_score": 0.7532814325627185,
            "fpr": 0.15570175438596492,
            "logloss": 2.9627270954376215,
            "mae": 0.31654653706513025,
            "precision": 0.7237354085603113,
            "recall": 0.7931769722814499
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7899222718592873,
            "auditor_fn_violation": 0.00556542600744622,
            "auditor_fp_violation": 0.01564601660456703,
            "ave_precision_score": 0.7568187271296168,
            "fpr": 0.14818880351262348,
            "logloss": 2.956828166682948,
            "mae": 0.3106248554206312,
            "precision": 0.7462406015037594,
            "recall": 0.8185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7791139841650456,
            "auditor_fn_violation": 0.012896046085362661,
            "auditor_fp_violation": 0.02438764801394005,
            "ave_precision_score": 0.7508447549648338,
            "fpr": 0.23355263157894737,
            "logloss": 2.9541823331940598,
            "mae": 0.3353614582849149,
            "precision": 0.6519607843137255,
            "recall": 0.8507462686567164
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7801297554325327,
            "auditor_fn_violation": 0.0029581178494234263,
            "auditor_fp_violation": 0.014952871270800807,
            "ave_precision_score": 0.751272262434074,
            "fpr": 0.23600439077936333,
            "logloss": 2.9131063460603714,
            "mae": 0.33181229297225084,
            "precision": 0.6645865834633385,
            "recall": 0.8783505154639175
        }
    }
]