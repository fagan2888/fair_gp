[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 15860,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.736244882568412,
            "auditor_fn_violation": 0.007638581748488881,
            "auditor_fp_violation": 0.0028644575889264444,
            "ave_precision_score": 0.5670599008834303,
            "fpr": 0.007675438596491228,
            "logloss": 0.6809182417108063,
            "mae": 0.4918099932633994,
            "precision": 0.8923076923076924,
            "recall": 0.12184873949579832
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7589513307171497,
            "auditor_fn_violation": 0.009989482338135935,
            "auditor_fp_violation": 0.0029407067329508727,
            "ave_precision_score": 0.5796181426058475,
            "fpr": 0.005488474204171241,
            "logloss": 0.678011516825514,
            "mae": 0.490286369747702,
            "precision": 0.9285714285714286,
            "recall": 0.13598326359832635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7099817202412833,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7110049512852679,
            "fpr": 0.4780701754385965,
            "logloss": 0.7983287868813966,
            "mae": 0.4653987087832208,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6970119349224159,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6980257446453608,
            "fpr": 0.47530186608122943,
            "logloss": 0.8002967878365602,
            "mae": 0.4660261433027709,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6753563742964995,
            "mae": 0.488142389444667,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6735137975434059,
            "mae": 0.4871612586383631,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6729704769654027,
            "mae": 0.48492525596367686,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6711452130485928,
            "mae": 0.48395491771718935,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.814758024564979,
            "auditor_fn_violation": 0.020310426802299865,
            "auditor_fp_violation": 0.007388741348784809,
            "ave_precision_score": 0.814445482277964,
            "fpr": 0.22478070175438597,
            "logloss": 0.8661952347637033,
            "mae": 0.32543860482697357,
            "precision": 0.6661237785016286,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8056500455229975,
            "auditor_fn_violation": 0.01867459089051068,
            "auditor_fp_violation": 0.02988619971961883,
            "ave_precision_score": 0.8052510247044697,
            "fpr": 0.2074643249176729,
            "logloss": 0.8681423563073989,
            "mae": 0.3159704773700116,
            "precision": 0.6855241264559068,
            "recall": 0.8619246861924686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.736244882568412,
            "auditor_fn_violation": 0.007638581748488881,
            "auditor_fp_violation": 0.0028644575889264444,
            "ave_precision_score": 0.5670599008834303,
            "fpr": 0.007675438596491228,
            "logloss": 0.6811358080563132,
            "mae": 0.49207634027851255,
            "precision": 0.8923076923076924,
            "recall": 0.12184873949579832
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7589513307171497,
            "auditor_fn_violation": 0.009989482338135935,
            "auditor_fp_violation": 0.0029407067329508727,
            "ave_precision_score": 0.5796181426058475,
            "fpr": 0.005488474204171241,
            "logloss": 0.6783243150714727,
            "mae": 0.4906035426811905,
            "precision": 0.9285714285714286,
            "recall": 0.13598326359832635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6736884135133362,
            "mae": 0.48618010790985927,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6720055437992417,
            "mae": 0.4852868930961115,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 15860,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7277924140173797,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09964992757122164,
            "ave_precision_score": 0.5657460711524042,
            "fpr": 0.29385964912280704,
            "logloss": 0.685727932598945,
            "mae": 0.495238975278641,
            "precision": 0.5746031746031746,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7085816097621227,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5475955506160481,
            "fpr": 0.305159165751921,
            "logloss": 0.6883021055537533,
            "mae": 0.49647989963987915,
            "precision": 0.5537720706260032,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7487139491966848,
            "auditor_fn_violation": 0.035078505086245035,
            "auditor_fp_violation": 0.03654132464187994,
            "ave_precision_score": 0.7203455111356061,
            "fpr": 0.1524122807017544,
            "logloss": 0.6220917378165467,
            "mae": 0.44928899028322156,
            "precision": 0.6997840172786177,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7566324918392551,
            "auditor_fn_violation": 0.03891764532974478,
            "auditor_fp_violation": 0.04245265081896148,
            "ave_precision_score": 0.7242478229977805,
            "fpr": 0.15697036223929747,
            "logloss": 0.62393223307406,
            "mae": 0.44987182081988825,
            "precision": 0.6877729257641921,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8095611536746099,
            "auditor_fn_violation": 0.013332964764853312,
            "auditor_fp_violation": 0.01616821583775954,
            "ave_precision_score": 0.8089528194668033,
            "fpr": 0.21162280701754385,
            "logloss": 0.9450760183173652,
            "mae": 0.3190146020058085,
            "precision": 0.6820428336079077,
            "recall": 0.8697478991596639
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8083528341683983,
            "auditor_fn_violation": 0.014382558134194343,
            "auditor_fp_violation": 0.024952910665892634,
            "ave_precision_score": 0.807827709358036,
            "fpr": 0.19319429198682767,
            "logloss": 0.9281963054735973,
            "mae": 0.30945594993273756,
            "precision": 0.704201680672269,
            "recall": 0.8765690376569037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7877641336075657,
            "auditor_fn_violation": 0.021284829721362235,
            "auditor_fp_violation": 0.01649766618380815,
            "ave_precision_score": 0.7874281723405492,
            "fpr": 0.1162280701754386,
            "logloss": 1.0587251882964555,
            "mae": 0.3688723967482104,
            "precision": 0.7389162561576355,
            "recall": 0.6302521008403361
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7631050709274572,
            "auditor_fn_violation": 0.02585783244308292,
            "auditor_fp_violation": 0.016848221506199572,
            "ave_precision_score": 0.7649340465427598,
            "fpr": 0.10647639956092206,
            "logloss": 1.3444155797289399,
            "mae": 0.37206341261057835,
            "precision": 0.7506426735218509,
            "recall": 0.6108786610878661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.673248167000454,
            "mae": 0.48545268746583087,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6714827684907179,
            "mae": 0.48451473880416085,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.8035232075286256,
            "auditor_fn_violation": 0.005302779006339389,
            "auditor_fp_violation": 0.0023891437308868504,
            "ave_precision_score": 0.6394460415745244,
            "fpr": 0.006578947368421052,
            "logloss": 0.6684372877407087,
            "mae": 0.4863324168938817,
            "precision": 0.9555555555555556,
            "recall": 0.2710084033613445
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.749476130991233,
            "auditor_fn_violation": 0.0098930321638367,
            "auditor_fp_violation": 0.0038406643969142867,
            "ave_precision_score": 0.6010168754676158,
            "fpr": 0.01756311745334797,
            "logloss": 0.6756791544226997,
            "mae": 0.490046532859394,
            "precision": 0.8688524590163934,
            "recall": 0.2217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6734264198432859,
            "mae": 0.4857604885964017,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6716959456389631,
            "mae": 0.4848414599306628,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7277924140173797,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5657460711524042,
            "fpr": 0.2949561403508772,
            "logloss": 0.6863819193428891,
            "mae": 0.49560101529616013,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7085816097621227,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10214899749786417,
            "ave_precision_score": 0.5475955506160481,
            "fpr": 0.30735455543358947,
            "logloss": 0.6880942898018214,
            "mae": 0.4963926948386149,
            "precision": 0.552,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6733375534007848,
            "mae": 0.48560959538608267,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6715899590700765,
            "mae": 0.48468128994974163,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7487139491966848,
            "auditor_fn_violation": 0.035078505086245035,
            "auditor_fp_violation": 0.03654132464187994,
            "ave_precision_score": 0.7203455111356061,
            "fpr": 0.1524122807017544,
            "logloss": 0.6243612638801657,
            "mae": 0.45120361718561564,
            "precision": 0.6997840172786177,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7566324918392551,
            "auditor_fn_violation": 0.03891764532974478,
            "auditor_fp_violation": 0.04245265081896148,
            "ave_precision_score": 0.7242478229977805,
            "fpr": 0.15697036223929747,
            "logloss": 0.6259609869499511,
            "mae": 0.45154926148125685,
            "precision": 0.6877729257641921,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7258418258096642,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5642643027758746,
            "fpr": 0.2949561403508772,
            "logloss": 1.6000410739842417,
            "mae": 0.49614058022533986,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7065014797964063,
            "auditor_fn_violation": 0.09632157406684455,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5456830799824597,
            "fpr": 0.305159165751921,
            "logloss": 2.014885308675854,
            "mae": 0.5048095166462017,
            "precision": 0.5544871794871795,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6113304972747239,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09812842024786739,
            "ave_precision_score": 0.5937162505981928,
            "fpr": 0.29276315789473684,
            "logloss": 0.6802037529261593,
            "mae": 0.4913988971037039,
            "precision": 0.575516693163752,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5705995713673134,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10140368044658181,
            "ave_precision_score": 0.552720651874822,
            "fpr": 0.305159165751921,
            "logloss": 0.6872314126832867,
            "mae": 0.49437615267613455,
            "precision": 0.5537720706260032,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7910921507460766,
            "auditor_fn_violation": 0.008200648680524841,
            "auditor_fp_violation": 0.00882725736359247,
            "ave_precision_score": 0.6708889322806391,
            "fpr": 0.0537280701754386,
            "logloss": 0.6454683444191736,
            "mae": 0.47150044064772756,
            "precision": 0.8262411347517731,
            "recall": 0.4894957983193277
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7852619920666364,
            "auditor_fn_violation": 0.006062582384523884,
            "auditor_fp_violation": 0.005169052610764507,
            "ave_precision_score": 0.6638640288056232,
            "fpr": 0.050493962678375415,
            "logloss": 0.648433993994873,
            "mae": 0.47321101996953613,
            "precision": 0.8270676691729323,
            "recall": 0.4602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6746672121664444,
            "mae": 0.48728200198526966,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6726991224024086,
            "mae": 0.4862317726195971,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.811915219433167,
            "auditor_fn_violation": 0.013715354562877783,
            "auditor_fp_violation": 0.024173104780299378,
            "ave_precision_score": 0.8115434027619672,
            "fpr": 0.20175438596491227,
            "logloss": 0.9263635293389235,
            "mae": 0.3131060939856086,
            "precision": 0.6923076923076923,
            "recall": 0.8697478991596639
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8116760821441555,
            "auditor_fn_violation": 0.00974606046966642,
            "auditor_fp_violation": 0.021677571787468024,
            "ave_precision_score": 0.8114600506836982,
            "fpr": 0.1877058177826564,
            "logloss": 0.9052818295330907,
            "mae": 0.3048303890191264,
            "precision": 0.7091836734693877,
            "recall": 0.8723849372384938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.725829428536323,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5642537901532795,
            "fpr": 0.2949561403508772,
            "logloss": 1.600490078759604,
            "mae": 0.49618583573631175,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7064967966787702,
            "auditor_fn_violation": 0.09632157406684455,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5456784062198459,
            "fpr": 0.305159165751921,
            "logloss": 2.0144841945952554,
            "mae": 0.5047793000170366,
            "precision": 0.5544871794871795,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6749641813129907,
            "mae": 0.48766668967641236,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6730521845250582,
            "mae": 0.48664734719482655,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7992634333150801,
            "auditor_fn_violation": 0.019769091847265226,
            "auditor_fp_violation": 0.021074762594559798,
            "ave_precision_score": 0.7994397558704351,
            "fpr": 0.18530701754385964,
            "logloss": 0.829649443417539,
            "mae": 0.3175984819722464,
            "precision": 0.6910420475319927,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7920314920500071,
            "auditor_fn_violation": 0.019951407483614955,
            "auditor_fp_violation": 0.03628223686378697,
            "ave_precision_score": 0.7924095595005138,
            "fpr": 0.1800219538968167,
            "logloss": 0.8647638546141573,
            "mae": 0.31000408643774574,
            "precision": 0.6962962962962963,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7108656942658234,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7120059962181096,
            "fpr": 0.4780701754385965,
            "logloss": 0.842743468754159,
            "mae": 0.467715749811185,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7132517886301193,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7143518212551033,
            "fpr": 0.47530186608122943,
            "logloss": 0.8433099620866464,
            "mae": 0.467632524857275,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8338746942163369,
            "auditor_fn_violation": 0.012183491817779746,
            "auditor_fp_violation": 0.014737244487365209,
            "ave_precision_score": 0.8341659652524834,
            "fpr": 0.18859649122807018,
            "logloss": 0.7591491226359094,
            "mae": 0.30026372158905007,
            "precision": 0.706984667802385,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8257007086692123,
            "auditor_fn_violation": 0.015271277597380232,
            "auditor_fp_violation": 0.027946854331077953,
            "ave_precision_score": 0.8260587942579511,
            "fpr": 0.1712403951701427,
            "logloss": 0.7678391277891398,
            "mae": 0.2908725054221178,
            "precision": 0.7282229965156795,
            "recall": 0.8744769874476988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8230245263271133,
            "auditor_fn_violation": 0.009711779448621553,
            "auditor_fp_violation": 0.00829913085465959,
            "ave_precision_score": 0.8227029437773228,
            "fpr": 0.19736842105263158,
            "logloss": 0.794064837713976,
            "mae": 0.30656693155386866,
            "precision": 0.6938775510204082,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8176170287124742,
            "auditor_fn_violation": 0.015482549407750002,
            "auditor_fp_violation": 0.026111447714994816,
            "ave_precision_score": 0.8172956102579727,
            "fpr": 0.16465422612513722,
            "logloss": 0.7842609484769409,
            "mae": 0.29262865385264014,
            "precision": 0.7321428571428571,
            "recall": 0.8577405857740585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7835631535878211,
            "auditor_fn_violation": 0.015979747162022703,
            "auditor_fp_violation": 0.009395622082729762,
            "ave_precision_score": 0.781430201940446,
            "fpr": 0.08114035087719298,
            "logloss": 0.5951699945387541,
            "mae": 0.42352106003397094,
            "precision": 0.8126582278481013,
            "recall": 0.6743697478991597
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7855953237985782,
            "auditor_fn_violation": 0.02185285377694291,
            "auditor_fp_violation": 0.008350593084776014,
            "ave_precision_score": 0.7800022565280172,
            "fpr": 0.07574094401756312,
            "logloss": 0.5993018279189615,
            "mae": 0.42378089022050835,
            "precision": 0.8164893617021277,
            "recall": 0.6422594142259415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6757920516160904,
            "mae": 0.48863581930728334,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6740215631924081,
            "mae": 0.48769434399976425,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.833936519059254,
            "auditor_fn_violation": 0.011229820875718707,
            "auditor_fp_violation": 0.005017201834862387,
            "ave_precision_score": 0.7932794550386904,
            "fpr": 0.09320175438596491,
            "logloss": 2.3881094891778374,
            "mae": 0.3141987754784487,
            "precision": 0.804147465437788,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8048043167463694,
            "auditor_fn_violation": 0.016791516058954035,
            "auditor_fp_violation": 0.0078866712467329,
            "ave_precision_score": 0.7614711495100862,
            "fpr": 0.08232711306256861,
            "logloss": 2.8671946150828878,
            "mae": 0.3362780643503684,
            "precision": 0.8134328358208955,
            "recall": 0.6841004184100419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 15860,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6092011040280471,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09964992757122164,
            "ave_precision_score": 0.5914201432242328,
            "fpr": 0.29385964912280704,
            "logloss": 0.6850770199886146,
            "mae": 0.49485767508546513,
            "precision": 0.5746031746031746,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5680650738466776,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10287403381305724,
            "ave_precision_score": 0.5500658365580655,
            "fpr": 0.3062568605927552,
            "logloss": 0.6882301291934887,
            "mae": 0.4963939151308539,
            "precision": 0.5528846153846154,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6734811029401667,
            "mae": 0.48585102328082974,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.671760900138469,
            "mae": 0.4849375621154986,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7108656942658234,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7120059962181096,
            "fpr": 0.4780701754385965,
            "logloss": 0.842782738360384,
            "mae": 0.46771640984112756,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7132517886301193,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7143518212551033,
            "fpr": 0.47530186608122943,
            "logloss": 0.8433483476863765,
            "mae": 0.4676328523229689,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.729200807493946,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09812842024786739,
            "ave_precision_score": 0.5678727721635058,
            "fpr": 0.29276315789473684,
            "logloss": 0.6818003521030693,
            "mae": 0.49261228225537035,
            "precision": 0.575516693163752,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.5296807333620843,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10140368044658181,
            "ave_precision_score": 0.5492362646592859,
            "fpr": 0.305159165751921,
            "logloss": 0.6867413269157454,
            "mae": 0.49494332876608477,
            "precision": 0.5537720706260032,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6747873544626879,
            "mae": 0.48744048210873936,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6728423690265576,
            "mae": 0.4864029756754342,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8051842544289682,
            "auditor_fn_violation": 0.026069309302668438,
            "auditor_fp_violation": 0.021783961049412524,
            "ave_precision_score": 0.8051854089343424,
            "fpr": 0.17324561403508773,
            "logloss": 0.8059908395840522,
            "mae": 0.3125298506608703,
            "precision": 0.7024482109227872,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.798337360298085,
            "auditor_fn_violation": 0.019303813456177175,
            "auditor_fp_violation": 0.030707569531236146,
            "ave_precision_score": 0.7986193606148013,
            "fpr": 0.1712403951701427,
            "logloss": 0.8348095036904655,
            "mae": 0.30193754471646794,
            "precision": 0.7073170731707317,
            "recall": 0.7887029288702929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6744368627180833,
            "mae": 0.48696592584121645,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6724227089019928,
            "mae": 0.48589032829527534,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6755902560070244,
            "mae": 0.4884113762527704,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6737869660359556,
            "mae": 0.4874518607241131,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.736244882568412,
            "auditor_fn_violation": 0.007638581748488881,
            "auditor_fp_violation": 0.0028644575889264444,
            "ave_precision_score": 0.5670599008834303,
            "fpr": 0.007675438596491228,
            "logloss": 0.6809182417108063,
            "mae": 0.4918099932633994,
            "precision": 0.8923076923076924,
            "recall": 0.12184873949579832
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7589513307171497,
            "auditor_fn_violation": 0.009989482338135935,
            "auditor_fp_violation": 0.0029407067329508727,
            "ave_precision_score": 0.5796181426058475,
            "fpr": 0.005488474204171241,
            "logloss": 0.678011516825514,
            "mae": 0.490286369747702,
            "precision": 0.9285714285714286,
            "recall": 0.13598326359832635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6737738281000113,
            "mae": 0.48630987480282784,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6721056794417668,
            "mae": 0.48542464754322356,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7276043220225665,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5869573043415651,
            "fpr": 0.008771929824561403,
            "logloss": 0.6834765383560597,
            "mae": 0.4879501832877858,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7492359577396516,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5973671249193861,
            "fpr": 0.007683863885839737,
            "logloss": 0.6813920089960747,
            "mae": 0.48694145407948874,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7258373143971855,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5642597925605735,
            "fpr": 0.2949561403508772,
            "logloss": 1.5948687018848788,
            "mae": 0.49629519879423006,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.706507009766183,
            "auditor_fn_violation": 0.09632157406684455,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5456821210075309,
            "fpr": 0.305159165751921,
            "logloss": 2.0102879484090472,
            "mae": 0.5046942789951735,
            "precision": 0.5544871794871795,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5842195472929937,
            "auditor_fn_violation": 0.0005252100840336137,
            "auditor_fp_violation": 0.0015164775470787077,
            "ave_precision_score": 0.585720104299267,
            "fpr": 0.47039473684210525,
            "logloss": 1.0018015311711563,
            "mae": 0.48154113050489294,
            "precision": 0.5233333333333333,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.550551480681033,
            "auditor_fn_violation": 0.003215005809974785,
            "auditor_fp_violation": 2.2815828100501424e-05,
            "ave_precision_score": 0.5520870828372327,
            "fpr": 0.4698133918770582,
            "logloss": 1.043405145009335,
            "mae": 0.4835439519938755,
            "precision": 0.5239154616240267,
            "recall": 0.9853556485355649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6740232567749631,
            "mae": 0.48667225405050996,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6723962190618403,
            "mae": 0.48580934383735697,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7871808273052825,
            "auditor_fn_violation": 0.04474882058086393,
            "auditor_fp_violation": 0.009946382584902626,
            "ave_precision_score": 0.7843120905073695,
            "fpr": 0.0712719298245614,
            "logloss": 0.6188705932489053,
            "mae": 0.4084196075049189,
            "precision": 0.8142857142857143,
            "recall": 0.5987394957983193
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7648355449432078,
            "auditor_fn_violation": 0.04184559704954325,
            "auditor_fp_violation": 0.01054091258242218,
            "ave_precision_score": 0.7635963862629049,
            "fpr": 0.06366630076838639,
            "logloss": 0.640997003286992,
            "mae": 0.4112882335912068,
            "precision": 0.8304093567251462,
            "recall": 0.5941422594142259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8381021529809413,
            "auditor_fn_violation": 0.0011932404540763706,
            "auditor_fp_violation": 0.015969539674875265,
            "ave_precision_score": 0.7284169341324168,
            "fpr": 0.09429824561403509,
            "logloss": 0.5912424682239448,
            "mae": 0.43576219625640333,
            "precision": 0.8027522935779816,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8349599433186115,
            "auditor_fn_violation": 0.00522668087393044,
            "auditor_fp_violation": 0.008378479096898823,
            "ave_precision_score": 0.7254803879379541,
            "fpr": 0.09001097694840834,
            "logloss": 0.5946457517849414,
            "mae": 0.43755014314347906,
            "precision": 0.806146572104019,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8119754868541307,
            "auditor_fn_violation": 0.012998949579831937,
            "auditor_fp_violation": 0.02360725494929986,
            "ave_precision_score": 0.8115832831587109,
            "fpr": 0.20285087719298245,
            "logloss": 0.9258245989143314,
            "mae": 0.3129882043372562,
            "precision": 0.6916666666666667,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8117131692438725,
            "auditor_fn_violation": 0.010205347013948535,
            "auditor_fp_violation": 0.021677571787468024,
            "ave_precision_score": 0.8115031712155982,
            "fpr": 0.1877058177826564,
            "logloss": 0.9048463892096456,
            "mae": 0.3047473128930012,
            "precision": 0.7096774193548387,
            "recall": 0.8744769874476988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8343026387849011,
            "auditor_fn_violation": 0.034018870706177214,
            "auditor_fp_violation": 0.013761467889908263,
            "ave_precision_score": 0.8323996815802509,
            "fpr": 0.12280701754385964,
            "logloss": 1.4327677108639116,
            "mae": 0.35339261606142425,
            "precision": 0.7543859649122807,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8171564258177824,
            "auditor_fn_violation": 0.04029780139531252,
            "auditor_fp_violation": 0.007975399467123669,
            "ave_precision_score": 0.8162404741821245,
            "fpr": 0.10976948408342481,
            "logloss": 1.8407897401782838,
            "mae": 0.3571091200922827,
            "precision": 0.7652582159624414,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7525735294117647,
            "auditor_fn_violation": 0.007094943240454072,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5840397923875432,
            "fpr": 0.008771929824561403,
            "logloss": 0.6751200692133238,
            "mae": 0.48785978859584583,
            "precision": 0.9058823529411765,
            "recall": 0.16176470588235295
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6732362435855045,
            "mae": 0.486855954945938,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6781235298988628,
            "mae": 0.4909401747087638,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.676982534389378,
            "mae": 0.49034119947812427,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8333822888690778,
            "auditor_fn_violation": 0.01761066268612708,
            "auditor_fp_violation": 0.015567157572831164,
            "ave_precision_score": 0.8336650375160083,
            "fpr": 0.19078947368421054,
            "logloss": 0.7680675956365924,
            "mae": 0.30076117798057966,
            "precision": 0.7045840407470289,
            "recall": 0.8718487394957983
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8253472060725736,
            "auditor_fn_violation": 0.01669047301921196,
            "auditor_fp_violation": 0.027939249055044454,
            "ave_precision_score": 0.8256953137416455,
            "fpr": 0.1734357848518112,
            "logloss": 0.7793802193349917,
            "mae": 0.29125103229777194,
            "precision": 0.7271157167530224,
            "recall": 0.8807531380753139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6736019729647935,
            "mae": 0.48604546023304,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6719038283737647,
            "mae": 0.48514395971853047,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7920563572887214,
            "auditor_fn_violation": 0.029245908889871736,
            "auditor_fp_violation": 0.009124014163849994,
            "ave_precision_score": 0.7852736908419111,
            "fpr": 0.06907894736842106,
            "logloss": 1.4344372329739774,
            "mae": 0.3738955973713856,
            "precision": 0.8306451612903226,
            "recall": 0.6491596638655462
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7635186678501307,
            "auditor_fn_violation": 0.04077086653592311,
            "auditor_fp_violation": 0.011707054907557872,
            "ave_precision_score": 0.7582200930150611,
            "fpr": 0.06586169045005488,
            "logloss": 1.8838275969002076,
            "mae": 0.385296051525861,
            "precision": 0.8265895953757225,
            "recall": 0.5983263598326359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8314262598753881,
            "auditor_fn_violation": 0.004789086687306503,
            "auditor_fp_violation": 0.011513157894736845,
            "ave_precision_score": 0.7883221036684331,
            "fpr": 0.08881578947368421,
            "logloss": 2.3786770545466847,
            "mae": 0.3213981694662508,
            "precision": 0.8080568720379147,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8065294338894795,
            "auditor_fn_violation": 0.00981495345130874,
            "auditor_fp_violation": 0.006157738495118682,
            "ave_precision_score": 0.7613995886263614,
            "fpr": 0.08232711306256861,
            "logloss": 2.8520955639093417,
            "mae": 0.33959530808575333,
            "precision": 0.8129675810473815,
            "recall": 0.6820083682008368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.733704032196973,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7348498542461983,
            "fpr": 0.4780701754385965,
            "logloss": 0.8489281102426807,
            "mae": 0.4672996656675088,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7131041964000475,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7141642014768821,
            "fpr": 0.47530186608122943,
            "logloss": 0.8521112479350218,
            "mae": 0.46823731558775666,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8356522665396504,
            "auditor_fn_violation": 0.01336982161285567,
            "auditor_fp_violation": 0.013213222275873166,
            "ave_precision_score": 0.8358728789553259,
            "fpr": 0.20833333333333334,
            "logloss": 0.7482272399805412,
            "mae": 0.3041029437201635,
            "precision": 0.6905537459283387,
            "recall": 0.8907563025210085
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8228207033150642,
            "auditor_fn_violation": 0.016228890042208434,
            "auditor_fp_violation": 0.027249704028007707,
            "ave_precision_score": 0.8232319094046573,
            "fpr": 0.20087815587266739,
            "logloss": 0.7705302953482881,
            "mae": 0.29642352267539623,
            "precision": 0.698019801980198,
            "recall": 0.8849372384937239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7910921507460766,
            "auditor_fn_violation": 0.008200648680524841,
            "auditor_fp_violation": 0.00882725736359247,
            "ave_precision_score": 0.6708889322806391,
            "fpr": 0.0537280701754386,
            "logloss": 0.6460502257517401,
            "mae": 0.4719198607561881,
            "precision": 0.8262411347517731,
            "recall": 0.4894957983193277
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7852619920666364,
            "auditor_fn_violation": 0.006062582384523884,
            "auditor_fp_violation": 0.005169052610764507,
            "ave_precision_score": 0.6638640288056232,
            "fpr": 0.050493962678375415,
            "logloss": 0.6489736088627989,
            "mae": 0.4736036267683613,
            "precision": 0.8270676691729323,
            "recall": 0.4602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.736244882568412,
            "auditor_fn_violation": 0.007638581748488881,
            "auditor_fp_violation": 0.0028644575889264444,
            "ave_precision_score": 0.5670599008834303,
            "fpr": 0.007675438596491228,
            "logloss": 0.6807797883908412,
            "mae": 0.49163094636771765,
            "precision": 0.8923076923076924,
            "recall": 0.12184873949579832
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7589513307171497,
            "auditor_fn_violation": 0.009989482338135935,
            "auditor_fp_violation": 0.0029407067329508727,
            "ave_precision_score": 0.5796181426058475,
            "fpr": 0.005488474204171241,
            "logloss": 0.6778090135264213,
            "mae": 0.4900731468894217,
            "precision": 0.9285714285714286,
            "recall": 0.13598326359832635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8385572910439185,
            "auditor_fn_violation": 0.013821318000884566,
            "auditor_fp_violation": 0.01586391437308869,
            "ave_precision_score": 0.8388060225079411,
            "fpr": 0.18859649122807018,
            "logloss": 0.7403883084778553,
            "mae": 0.2896101913766918,
            "precision": 0.7054794520547946,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.83375789049058,
            "auditor_fn_violation": 0.017328881315764093,
            "auditor_fp_violation": 0.029589593954312578,
            "ave_precision_score": 0.834093641105379,
            "fpr": 0.17233809001097694,
            "logloss": 0.7346097985653861,
            "mae": 0.278855033080849,
            "precision": 0.7269565217391304,
            "recall": 0.8744769874476988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7910921507460766,
            "auditor_fn_violation": 0.008200648680524841,
            "auditor_fp_violation": 0.00882725736359247,
            "ave_precision_score": 0.6708889322806391,
            "fpr": 0.0537280701754386,
            "logloss": 0.6422102073676863,
            "mae": 0.46910189327440766,
            "precision": 0.8262411347517731,
            "recall": 0.4894957983193277
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7852619920666364,
            "auditor_fn_violation": 0.006062582384523884,
            "auditor_fp_violation": 0.005169052610764507,
            "ave_precision_score": 0.6638640288056232,
            "fpr": 0.050493962678375415,
            "logloss": 0.6454153468383409,
            "mae": 0.4709659206356882,
            "precision": 0.8270676691729323,
            "recall": 0.4602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8354734921480718,
            "auditor_fn_violation": 0.009131284092584404,
            "auditor_fp_violation": 0.01204882906808306,
            "ave_precision_score": 0.8357423518470686,
            "fpr": 0.1875,
            "logloss": 0.766978946317373,
            "mae": 0.29744244195479586,
            "precision": 0.7086882453151618,
            "recall": 0.8739495798319328
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8272015625045767,
            "auditor_fn_violation": 0.013943939484404925,
            "auditor_fp_violation": 0.026126658267061804,
            "ave_precision_score": 0.8275539723025257,
            "fpr": 0.17672886937431395,
            "logloss": 0.7794310377762886,
            "mae": 0.288397274646546,
            "precision": 0.7228915662650602,
            "recall": 0.8786610878661087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.729200807493946,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09812842024786739,
            "ave_precision_score": 0.5678727721635058,
            "fpr": 0.29276315789473684,
            "logloss": 0.6808562951053788,
            "mae": 0.4917553004955775,
            "precision": 0.575516693163752,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7096468218591186,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10140368044658181,
            "ave_precision_score": 0.5493370173763379,
            "fpr": 0.305159165751921,
            "logloss": 0.6873337756359247,
            "mae": 0.49444550493758677,
            "precision": 0.5537720706260032,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7922498836769498,
            "auditor_fn_violation": 0.029245908889871736,
            "auditor_fp_violation": 0.009124014163849994,
            "ave_precision_score": 0.7854427841445044,
            "fpr": 0.06907894736842106,
            "logloss": 1.4225442923876306,
            "mae": 0.36467255190064424,
            "precision": 0.8306451612903226,
            "recall": 0.6491596638655462
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7615686686103649,
            "auditor_fn_violation": 0.04178129693334376,
            "auditor_fp_violation": 0.012850381404593086,
            "ave_precision_score": 0.7564037980549376,
            "fpr": 0.06476399560922064,
            "logloss": 1.8668120985677839,
            "mae": 0.3765478981367102,
            "precision": 0.8294797687861272,
            "recall": 0.600418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7910921507460766,
            "auditor_fn_violation": 0.008200648680524841,
            "auditor_fp_violation": 0.00882725736359247,
            "ave_precision_score": 0.6708889322806391,
            "fpr": 0.0537280701754386,
            "logloss": 0.6435680367447866,
            "mae": 0.47011210155068783,
            "precision": 0.8262411347517731,
            "recall": 0.4894957983193277
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7852619920666364,
            "auditor_fn_violation": 0.006062582384523884,
            "auditor_fp_violation": 0.005169052610764507,
            "ave_precision_score": 0.6638640288056232,
            "fpr": 0.050493962678375415,
            "logloss": 0.6466727671763433,
            "mae": 0.4719114772378417,
            "precision": 0.8270676691729323,
            "recall": 0.4602510460251046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7882242481386391,
            "auditor_fn_violation": 0.02426793085655316,
            "auditor_fp_violation": 0.016115403186866252,
            "ave_precision_score": 0.7878114548637334,
            "fpr": 0.11732456140350878,
            "logloss": 1.0557479453755665,
            "mae": 0.3691032251786671,
            "precision": 0.7377450980392157,
            "recall": 0.6323529411764706
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.763093181747182,
            "auditor_fn_violation": 0.028016479201208838,
            "auditor_fp_violation": 0.016848221506199572,
            "ave_precision_score": 0.7648873365943231,
            "fpr": 0.10647639956092206,
            "logloss": 1.3398329120459853,
            "mae": 0.3722958104101463,
            "precision": 0.7531806615776081,
            "recall": 0.6192468619246861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7487139491966848,
            "auditor_fn_violation": 0.035078505086245035,
            "auditor_fp_violation": 0.03654132464187994,
            "ave_precision_score": 0.7203455111356061,
            "fpr": 0.1524122807017544,
            "logloss": 0.6228038669651568,
            "mae": 0.4499566185761962,
            "precision": 0.6997840172786177,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7566324918392551,
            "auditor_fn_violation": 0.03891764532974478,
            "auditor_fp_violation": 0.04245265081896148,
            "ave_precision_score": 0.7242478229977805,
            "fpr": 0.15697036223929747,
            "logloss": 0.6244775615210914,
            "mae": 0.4502720013996903,
            "precision": 0.6877729257641921,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7258399456771492,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5642643027758746,
            "fpr": 0.2949561403508772,
            "logloss": 1.5914558704766573,
            "mae": 0.4963601393628072,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.706507009766183,
            "auditor_fn_violation": 0.09632157406684455,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5456821210075309,
            "fpr": 0.305159165751921,
            "logloss": 2.007844831638675,
            "mae": 0.504641148497022,
            "precision": 0.5544871794871795,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7667505710484795,
            "auditor_fn_violation": 0.012109778121775026,
            "auditor_fp_violation": 0.0074340093352647735,
            "ave_precision_score": 0.7685322870202306,
            "fpr": 0.2050438596491228,
            "logloss": 1.1012206566818732,
            "mae": 0.31154396636702586,
            "precision": 0.6914191419141914,
            "recall": 0.8802521008403361
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7774575168241675,
            "auditor_fn_violation": 0.012997809203183776,
            "auditor_fp_violation": 0.024156891774386957,
            "ave_precision_score": 0.7787283514387701,
            "fpr": 0.18880351262349068,
            "logloss": 1.0188899295328324,
            "mae": 0.29936761395406036,
            "precision": 0.7114093959731543,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 15860,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.822879634910554,
            "auditor_fn_violation": 0.010347560076662246,
            "auditor_fp_violation": 0.007841421213584424,
            "ave_precision_score": 0.8225834535078989,
            "fpr": 0.18969298245614036,
            "logloss": 0.7855715103518686,
            "mae": 0.3065121038409671,
            "precision": 0.7001733102253033,
            "recall": 0.8487394957983193
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8168425178120085,
            "auditor_fn_violation": 0.018867491239109167,
            "auditor_fp_violation": 0.02631425507588799,
            "ave_precision_score": 0.8165778084518192,
            "fpr": 0.16136114160263446,
            "logloss": 0.7742779344606115,
            "mae": 0.2925757129365347,
            "precision": 0.7327272727272728,
            "recall": 0.8430962343096234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8343495857276474,
            "auditor_fn_violation": 0.006201164676396876,
            "auditor_fp_violation": 0.016075164976661845,
            "ave_precision_score": 0.8346160000136846,
            "fpr": 0.1600877192982456,
            "logloss": 0.8163585721499488,
            "mae": 0.2799880131063431,
            "precision": 0.7197696737044146,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8232771660133684,
            "auditor_fn_violation": 0.015330984848136907,
            "auditor_fp_violation": 0.028623723898058888,
            "ave_precision_score": 0.8236070607680626,
            "fpr": 0.150384193194292,
            "logloss": 0.8441339483065087,
            "mae": 0.26928228896585904,
            "precision": 0.7390476190476191,
            "recall": 0.8117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8024464986177845,
            "auditor_fn_violation": 0.03400044228217603,
            "auditor_fp_violation": 0.025719760985031388,
            "ave_precision_score": 0.8023073558865595,
            "fpr": 0.1699561403508772,
            "logloss": 1.6502714161309584,
            "mae": 0.3202049592562582,
            "precision": 0.712430426716141,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8016509200618062,
            "auditor_fn_violation": 0.0442499621088601,
            "auditor_fp_violation": 0.039337022737240254,
            "ave_precision_score": 0.801383227051387,
            "fpr": 0.16794731064763996,
            "logloss": 2.026976550842308,
            "mae": 0.3235749518196714,
            "precision": 0.7124060150375939,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7546022814044792,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7556364446633955,
            "fpr": 0.4780701754385965,
            "logloss": 0.8447376051254256,
            "mae": 0.4675915097458321,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.758546755649502,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7596082155792185,
            "fpr": 0.47530186608122943,
            "logloss": 0.8464363696333137,
            "mae": 0.4678475970625223,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7546022814044792,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7556364446633955,
            "fpr": 0.4780701754385965,
            "logloss": 0.8483603309199643,
            "mae": 0.468228989917981,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.758546755649502,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7596082155792185,
            "fpr": 0.47530186608122943,
            "logloss": 0.849678713467902,
            "mae": 0.46838505947236564,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5842413067819104,
            "auditor_fn_violation": 0.0005252100840336137,
            "auditor_fp_violation": 0.0015164775470787077,
            "ave_precision_score": 0.5857344381667591,
            "fpr": 0.47039473684210525,
            "logloss": 0.972562352005643,
            "mae": 0.4814722507423561,
            "precision": 0.5233333333333333,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5542372978939494,
            "auditor_fn_violation": 0.003215005809974785,
            "auditor_fp_violation": 2.2815828100501424e-05,
            "ave_precision_score": 0.5558070442110696,
            "fpr": 0.4698133918770582,
            "logloss": 1.0106244489180964,
            "mae": 0.4829299868539646,
            "precision": 0.5239154616240267,
            "recall": 0.9853556485355649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 15860,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7277924140173797,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09964992757122164,
            "ave_precision_score": 0.5657460711524042,
            "fpr": 0.29385964912280704,
            "logloss": 0.6854004233669336,
            "mae": 0.49502724559422123,
            "precision": 0.5746031746031746,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7085816097621227,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5475955506160481,
            "fpr": 0.305159165751921,
            "logloss": 0.6883634844416282,
            "mae": 0.49647001976108446,
            "precision": 0.5537720706260032,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7922493133367563,
            "auditor_fn_violation": 0.029245908889871736,
            "auditor_fp_violation": 0.009124014163849994,
            "ave_precision_score": 0.785442215640223,
            "fpr": 0.06907894736842106,
            "logloss": 1.4223147804046359,
            "mae": 0.36438565687787866,
            "precision": 0.8306451612903226,
            "recall": 0.6491596638655462
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7615513848741986,
            "auditor_fn_violation": 0.04178129693334376,
            "auditor_fp_violation": 0.012850381404593086,
            "ave_precision_score": 0.7563866934704614,
            "fpr": 0.06476399560922064,
            "logloss": 1.86609641991792,
            "mae": 0.3762566095849387,
            "precision": 0.8294797687861272,
            "recall": 0.600418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 15860,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8140944225895321,
            "auditor_fn_violation": 0.020310426802299865,
            "auditor_fp_violation": 0.013457166425237409,
            "ave_precision_score": 0.8133285559600547,
            "fpr": 0.22039473684210525,
            "logloss": 0.8683151028590727,
            "mae": 0.3251389942689505,
            "precision": 0.6704918032786885,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8057027559279977,
            "auditor_fn_violation": 0.018224490077114214,
            "auditor_fp_violation": 0.030410963765929888,
            "ave_precision_score": 0.8046724070450324,
            "fpr": 0.20636663007683864,
            "logloss": 0.8697930281087315,
            "mae": 0.3157487527388593,
            "precision": 0.6871880199667221,
            "recall": 0.8640167364016736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.7536228995882319,
            "auditor_fn_violation": 0.002801120448179284,
            "auditor_fp_violation": 0.003048044422984066,
            "ave_precision_score": 0.5850257483654416,
            "fpr": 0.008771929824561403,
            "logloss": 0.6778379982844993,
            "mae": 0.49070039378446445,
            "precision": 0.9069767441860465,
            "recall": 0.1638655462184874
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7637917943659579,
            "auditor_fn_violation": 0.009814953451308762,
            "auditor_fp_violation": 0.004187972002443829,
            "ave_precision_score": 0.5927427255849079,
            "fpr": 0.007683863885839737,
            "logloss": 0.6766695321185036,
            "mae": 0.49008654370396904,
            "precision": 0.9213483146067416,
            "recall": 0.17154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8339431598670028,
            "auditor_fn_violation": 0.004957246056317265,
            "auditor_fp_violation": 0.005286294865604383,
            "ave_precision_score": 0.7932813771356393,
            "fpr": 0.08552631578947369,
            "logloss": 2.3876331327756306,
            "mae": 0.3134962848005196,
            "precision": 0.8151658767772512,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8048136459159729,
            "auditor_fn_violation": 0.01953116029559682,
            "auditor_fp_violation": 0.0073872581205334876,
            "ave_precision_score": 0.7614996182482711,
            "fpr": 0.0801317233809001,
            "logloss": 2.8668666535374925,
            "mae": 0.33553587518480366,
            "precision": 0.8156565656565656,
            "recall": 0.6757322175732218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8363018903956185,
            "auditor_fn_violation": 0.0073897980244729475,
            "auditor_fp_violation": 0.02106470304200869,
            "ave_precision_score": 0.8365331240187014,
            "fpr": 0.18859649122807018,
            "logloss": 0.74780108275254,
            "mae": 0.2927298182407149,
            "precision": 0.7054794520547946,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8339046924589419,
            "auditor_fn_violation": 0.010173196955848786,
            "auditor_fp_violation": 0.027574195805436758,
            "ave_precision_score": 0.8342508531014852,
            "fpr": 0.1756311745334797,
            "logloss": 0.7261941577297811,
            "mae": 0.2830354400877723,
            "precision": 0.7217391304347827,
            "recall": 0.8682008368200836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7258373143971855,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5642597925605735,
            "fpr": 0.2949561403508772,
            "logloss": 1.5975163729792368,
            "mae": 0.49622770152921175,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.706507009766183,
            "auditor_fn_violation": 0.09632157406684455,
            "auditor_fp_violation": 0.10430382570735407,
            "ave_precision_score": 0.5456821210075309,
            "fpr": 0.305159165751921,
            "logloss": 2.0124512460406687,
            "mae": 0.5047468563220964,
            "precision": 0.5544871794871795,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8286682604781385,
            "auditor_fn_violation": 0.01097873359870264,
            "auditor_fp_violation": 0.017702297601802683,
            "ave_precision_score": 0.8286733783998635,
            "fpr": 0.1875,
            "logloss": 0.785150921180736,
            "mae": 0.3043854684097153,
            "precision": 0.7056798623063684,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8240720277679108,
            "auditor_fn_violation": 0.014141432698446234,
            "auditor_fp_violation": 0.02521149005103141,
            "ave_precision_score": 0.8242577918283442,
            "fpr": 0.17672886937431395,
            "logloss": 0.7788401365087543,
            "mae": 0.2992171481682108,
            "precision": 0.7195121951219512,
            "recall": 0.8640167364016736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7919413259518706,
            "auditor_fn_violation": 0.028499557717823976,
            "auditor_fp_violation": 0.008520441010783843,
            "ave_precision_score": 0.7852294132332205,
            "fpr": 0.07017543859649122,
            "logloss": 1.4256176449311082,
            "mae": 0.36635758090504617,
            "precision": 0.8288770053475936,
            "recall": 0.6512605042016807
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7624609862461766,
            "auditor_fn_violation": 0.040026822334186085,
            "auditor_fp_violation": 0.011707054907557872,
            "ave_precision_score": 0.7572630056004148,
            "fpr": 0.06586169045005488,
            "logloss": 1.8716856743677248,
            "mae": 0.3776548300607991,
            "precision": 0.8270893371757925,
            "recall": 0.600418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7267225902837101,
            "auditor_fn_violation": 0.0013176323160843284,
            "auditor_fp_violation": 0.0022432802188958705,
            "ave_precision_score": 0.5671596338554132,
            "fpr": 0.4682017543859649,
            "logloss": 0.6873283469680517,
            "mae": 0.4921277375532347,
            "precision": 0.5239687848383501,
            "recall": 0.9873949579831933
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.709934414422405,
            "auditor_fn_violation": 0.0018647033697853758,
            "auditor_fp_violation": 0.007491196892991236,
            "ave_precision_score": 0.5534993885649737,
            "fpr": 0.45334796926454446,
            "logloss": 0.6878014384842048,
            "mae": 0.49232103555380446,
            "precision": 0.5322763306908267,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7689773282819465,
            "auditor_fn_violation": 0.047001695415008114,
            "auditor_fp_violation": 0.010907069853532916,
            "ave_precision_score": 0.7651559373356545,
            "fpr": 0.0581140350877193,
            "logloss": 0.6213124286877503,
            "mae": 0.40734411404317045,
            "precision": 0.8417910447761194,
            "recall": 0.592436974789916
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7509405422808044,
            "auditor_fn_violation": 0.050131126308392546,
            "auditor_fp_violation": 0.015028025442183424,
            "ave_precision_score": 0.7470772297645656,
            "fpr": 0.059275521405049394,
            "logloss": 0.6532932675563894,
            "mae": 0.41443633189926826,
            "precision": 0.8348623853211009,
            "recall": 0.5711297071129707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8353003733641472,
            "auditor_fn_violation": 0.03871581527347782,
            "auditor_fp_violation": 0.017672118944149363,
            "ave_precision_score": 0.8340569950612414,
            "fpr": 0.13267543859649122,
            "logloss": 1.4326217688871026,
            "mae": 0.3488145266969083,
            "precision": 0.7425531914893617,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8225703490955577,
            "auditor_fn_violation": 0.04347606428174475,
            "auditor_fp_violation": 0.02108182516484436,
            "ave_precision_score": 0.8220466029949898,
            "fpr": 0.1163556531284303,
            "logloss": 1.838282182946894,
            "mae": 0.35242655690056446,
            "precision": 0.7633928571428571,
            "recall": 0.7154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 15860,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8142259247213139,
            "auditor_fn_violation": 0.020310426802299865,
            "auditor_fp_violation": 0.013457166425237409,
            "ave_precision_score": 0.8134395566546566,
            "fpr": 0.22039473684210525,
            "logloss": 0.869122368431704,
            "mae": 0.3250249962214168,
            "precision": 0.6704918032786885,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8057563382661465,
            "auditor_fn_violation": 0.018224490077114214,
            "auditor_fp_violation": 0.030410963765929888,
            "ave_precision_score": 0.8047329931036244,
            "fpr": 0.20636663007683864,
            "logloss": 0.8710440657889217,
            "mae": 0.3156317004726425,
            "precision": 0.6871880199667221,
            "recall": 0.8640167364016736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7487139491966848,
            "auditor_fn_violation": 0.035078505086245035,
            "auditor_fp_violation": 0.03654132464187994,
            "ave_precision_score": 0.7203455111356061,
            "fpr": 0.1524122807017544,
            "logloss": 0.6259112721659049,
            "mae": 0.4524777460059053,
            "precision": 0.6997840172786177,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7566324918392551,
            "auditor_fn_violation": 0.03891764532974478,
            "auditor_fp_violation": 0.04245265081896148,
            "ave_precision_score": 0.7242478229977805,
            "fpr": 0.15697036223929747,
            "logloss": 0.6274664806251741,
            "mae": 0.45269197840591163,
            "precision": 0.6877729257641921,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8017249988249828,
            "auditor_fn_violation": 0.024530535898569957,
            "auditor_fp_violation": 0.022357355544825368,
            "ave_precision_score": 0.8015856896051298,
            "fpr": 0.1699561403508772,
            "logloss": 1.6500411820028815,
            "mae": 0.31988433010148326,
            "precision": 0.7118959107806692,
            "recall": 0.8046218487394958
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8016807934919388,
            "auditor_fn_violation": 0.03946419631744049,
            "auditor_fp_violation": 0.03174442216380244,
            "ave_precision_score": 0.801484122379244,
            "fpr": 0.16355653128430298,
            "logloss": 2.0257937530244203,
            "mae": 0.32370364787728373,
            "precision": 0.7188679245283018,
            "recall": 0.797071129707113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7474258534896334,
            "auditor_fn_violation": 0.007435869084475895,
            "auditor_fp_violation": 0.007886689200064382,
            "ave_precision_score": 0.6229065986607101,
            "fpr": 0.04824561403508772,
            "logloss": 0.6699054329646406,
            "mae": 0.4866228272909658,
            "precision": 0.7981651376146789,
            "recall": 0.36554621848739494
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7516357617854204,
            "auditor_fn_violation": 0.0028337979782206424,
            "auditor_fp_violation": 0.004484577767750084,
            "ave_precision_score": 0.6269349359371819,
            "fpr": 0.04610318331503842,
            "logloss": 0.6695576174431269,
            "mae": 0.48646465421508095,
            "precision": 0.8055555555555556,
            "recall": 0.36401673640167365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 15860,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6092011040280471,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09964992757122164,
            "ave_precision_score": 0.5914201432242328,
            "fpr": 0.29385964912280704,
            "logloss": 0.6850763785632705,
            "mae": 0.49485833181493116,
            "precision": 0.5746031746031746,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5680363796236881,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10287403381305724,
            "ave_precision_score": 0.5500084481120867,
            "fpr": 0.3062568605927552,
            "logloss": 0.688233271642478,
            "mae": 0.49639668282117333,
            "precision": 0.5528846153846154,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7487139491966848,
            "auditor_fn_violation": 0.035078505086245035,
            "auditor_fp_violation": 0.03654132464187994,
            "ave_precision_score": 0.7203455111356061,
            "fpr": 0.1524122807017544,
            "logloss": 0.6213411866633353,
            "mae": 0.44870058669332874,
            "precision": 0.6997840172786177,
            "recall": 0.680672268907563
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7566324918392551,
            "auditor_fn_violation": 0.03891764532974478,
            "auditor_fp_violation": 0.04245265081896148,
            "ave_precision_score": 0.7242478229977805,
            "fpr": 0.15697036223929747,
            "logloss": 0.6230471748350082,
            "mae": 0.449145081963157,
            "precision": 0.6877729257641921,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.802166757243557,
            "auditor_fn_violation": 0.028861215538847115,
            "auditor_fp_violation": 0.025445638178013853,
            "ave_precision_score": 0.8026487829574551,
            "fpr": 0.17434210526315788,
            "logloss": 1.6534289632070465,
            "mae": 0.3180560222000189,
            "precision": 0.7119565217391305,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8004470445874177,
            "auditor_fn_violation": 0.041574617988416794,
            "auditor_fp_violation": 0.03530622643948862,
            "ave_precision_score": 0.8008523786862722,
            "fpr": 0.1756311745334797,
            "logloss": 2.0329433413338176,
            "mae": 0.32364411482255256,
            "precision": 0.7047970479704797,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7842712413245162,
            "auditor_fn_violation": 0.02018833849329205,
            "auditor_fp_violation": 0.017817982456140354,
            "ave_precision_score": 0.7845802754848958,
            "fpr": 0.11951754385964912,
            "logloss": 1.0617840884793812,
            "mae": 0.36928339674802474,
            "precision": 0.7379807692307693,
            "recall": 0.6449579831932774
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7671140997282464,
            "auditor_fn_violation": 0.022137611434397807,
            "auditor_fp_violation": 0.01674935291776415,
            "ave_precision_score": 0.7687937997870894,
            "fpr": 0.11525795828759605,
            "logloss": 1.3470475956682164,
            "mae": 0.3713071855930141,
            "precision": 0.7439024390243902,
            "recall": 0.6380753138075314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7277924140173797,
            "auditor_fn_violation": 0.08560924369747899,
            "auditor_fp_violation": 0.09897845243843555,
            "ave_precision_score": 0.5657460711524042,
            "fpr": 0.2949561403508772,
            "logloss": 0.6863094516028216,
            "mae": 0.495536584668515,
            "precision": 0.5736925515055468,
            "recall": 0.7605042016806722
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7085886724380207,
            "auditor_fn_violation": 0.09706791470130298,
            "auditor_fp_violation": 0.10214899749786417,
            "ave_precision_score": 0.5476096759678444,
            "fpr": 0.30735455543358947,
            "logloss": 0.6880569631243386,
            "mae": 0.49634519052557835,
            "precision": 0.552,
            "recall": 0.7217573221757322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8017863475109425,
            "auditor_fn_violation": 0.030434542237947813,
            "auditor_fp_violation": 0.026247887493964273,
            "ave_precision_score": 0.8016685516170691,
            "fpr": 0.17214912280701755,
            "logloss": 1.6549982533671836,
            "mae": 0.31908594558194725,
            "precision": 0.7124542124542125,
            "recall": 0.8172268907563025
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8015482257046915,
            "auditor_fn_violation": 0.04478273450022735,
            "auditor_fp_violation": 0.0391266101003136,
            "ave_precision_score": 0.8011753383940987,
            "fpr": 0.17014270032930845,
            "logloss": 2.03294174793063,
            "mae": 0.32235533108343567,
            "precision": 0.7118959107806692,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7836960754324819,
            "auditor_fn_violation": 0.015979747162022703,
            "auditor_fp_violation": 0.009395622082729762,
            "ave_precision_score": 0.7815979877933232,
            "fpr": 0.08114035087719298,
            "logloss": 0.5949684427982241,
            "mae": 0.4233516722339565,
            "precision": 0.8126582278481013,
            "recall": 0.6743697478991597
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.785595947986075,
            "auditor_fn_violation": 0.02185285377694291,
            "auditor_fp_violation": 0.008350593084776014,
            "ave_precision_score": 0.77985716389863,
            "fpr": 0.07574094401756312,
            "logloss": 0.5991002528750281,
            "mae": 0.4236181900845728,
            "precision": 0.8164893617021277,
            "recall": 0.6422594142259415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8358540937017566,
            "auditor_fn_violation": 0.03350287483414419,
            "auditor_fp_violation": 0.013404353774344121,
            "ave_precision_score": 0.83410003912717,
            "fpr": 0.12609649122807018,
            "logloss": 1.4300454686497917,
            "mae": 0.35265438168728214,
            "precision": 0.7510822510822511,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8180337047088934,
            "auditor_fn_violation": 0.04279632019620721,
            "auditor_fp_violation": 0.01568207918106388,
            "ave_precision_score": 0.8171548821459573,
            "fpr": 0.11086717892425905,
            "logloss": 1.8359969823540532,
            "mae": 0.3554947522067589,
            "precision": 0.7645687645687645,
            "recall": 0.6861924686192469
        }
    }
]