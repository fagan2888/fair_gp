[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7986204625994962,
            "auditor_fn_violation": 0.007527928565809147,
            "auditor_fp_violation": 0.016675608011444926,
            "ave_precision_score": 0.7990436313274449,
            "fpr": 0.16337719298245615,
            "logloss": 0.9785134819447026,
            "mae": 0.2747303465906901,
            "precision": 0.7066929133858267,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8543396844330942,
            "auditor_fn_violation": 0.009758247837022565,
            "auditor_fp_violation": 0.0162148322270131,
            "ave_precision_score": 0.8545980457768748,
            "fpr": 0.1207464324917673,
            "logloss": 0.88129890041545,
            "mae": 0.26045416180890385,
            "precision": 0.7791164658634538,
            "recall": 0.7637795275590551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8314053666941903,
            "auditor_fn_violation": 0.0053054441035323835,
            "auditor_fp_violation": 0.014216738197424895,
            "ave_precision_score": 0.8317975215167893,
            "fpr": 0.11403508771929824,
            "logloss": 0.5109367761236997,
            "mae": 0.29639435180676327,
            "precision": 0.7603686635944701,
            "recall": 0.7399103139013453
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.9108950021723011,
            "auditor_fn_violation": 0.004894249634821988,
            "auditor_fp_violation": 0.0004712188770826917,
            "ave_precision_score": 0.9109811215760217,
            "fpr": 0.06256860592755215,
            "logloss": 0.43867731763290096,
            "mae": 0.2710704499468183,
            "precision": 0.8710407239819005,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8172808821357381,
            "auditor_fn_violation": 0.012572771615136494,
            "auditor_fp_violation": 0.021148633386040214,
            "ave_precision_score": 0.8180092055042922,
            "fpr": 0.10964912280701754,
            "logloss": 0.5194474595361392,
            "mae": 0.28954514323043423,
            "precision": 0.7727272727272727,
            "recall": 0.7623318385650224
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.9037445099106949,
            "auditor_fn_violation": 0.011996853851007381,
            "auditor_fp_violation": 0.01005357731394345,
            "ave_precision_score": 0.9038849301020511,
            "fpr": 0.06037321624588365,
            "logloss": 0.4520044428274873,
            "mae": 0.27199618083871613,
            "precision": 0.8755656108597285,
            "recall": 0.7618110236220472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7958625300488309,
            "auditor_fn_violation": 0.002532255526709149,
            "auditor_fp_violation": 0.01244258715458174,
            "ave_precision_score": 0.7962510400379869,
            "fpr": 0.11074561403508772,
            "logloss": 0.5590453680806201,
            "mae": 0.3027231313917263,
            "precision": 0.7583732057416268,
            "recall": 0.7107623318385651
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.9001690487289352,
            "auditor_fn_violation": 0.0029559971304355405,
            "auditor_fp_violation": 0.004072093764385114,
            "ave_precision_score": 0.9002050037846685,
            "fpr": 0.07135016465422613,
            "logloss": 0.4596718504161365,
            "mae": 0.2720463447616273,
            "precision": 0.8549107142857143,
            "recall": 0.7539370078740157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8306055731479745,
            "auditor_fn_violation": 0.01179588545354418,
            "auditor_fp_violation": 0.01541205481514946,
            "ave_precision_score": 0.831047921741457,
            "fpr": 0.13596491228070176,
            "logloss": 0.5593315292038942,
            "mae": 0.27725094753897567,
            "precision": 0.7453798767967146,
            "recall": 0.8139013452914798
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8965761927074143,
            "auditor_fn_violation": 0.005445257871854937,
            "auditor_fp_violation": 0.01544944202782098,
            "ave_precision_score": 0.8967061874277509,
            "fpr": 0.09549945115257959,
            "logloss": 0.4845185872342557,
            "mae": 0.26443681583594647,
            "precision": 0.8160676532769556,
            "recall": 0.7598425196850394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.784342136034383,
            "auditor_fn_violation": 0.007075564471717414,
            "auditor_fp_violation": 0.012899066335366312,
            "ave_precision_score": 0.7850229105934631,
            "fpr": 0.10087719298245613,
            "logloss": 0.5476098457765215,
            "mae": 0.3036096248941153,
            "precision": 0.7745098039215687,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.9021660924742425,
            "auditor_fn_violation": 0.006430590248666777,
            "auditor_fp_violation": 0.0015171613556939894,
            "ave_precision_score": 0.9022974257224239,
            "fpr": 0.05817782656421515,
            "logloss": 0.4613902784640295,
            "mae": 0.2800581888004352,
            "precision": 0.8764568764568764,
            "recall": 0.7401574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8228628685074958,
            "auditor_fn_violation": 0.008830933836834243,
            "auditor_fp_violation": 0.018800353889014385,
            "ave_precision_score": 0.8233235905987912,
            "fpr": 0.15021929824561403,
            "logloss": 0.6658533327221098,
            "mae": 0.2735250878746426,
            "precision": 0.7232323232323232,
            "recall": 0.8026905829596412
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8768041628652226,
            "auditor_fn_violation": 0.009295833081238066,
            "auditor_fp_violation": 0.012973500066733314,
            "ave_precision_score": 0.8769886263007886,
            "fpr": 0.10318331503841932,
            "logloss": 0.6168164320913655,
            "mae": 0.26290827449274,
            "precision": 0.8029350104821803,
            "recall": 0.7539370078740157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.82602783219546,
            "auditor_fn_violation": 0.004299917394382818,
            "auditor_fp_violation": 0.012887301408026509,
            "ave_precision_score": 0.826446485784268,
            "fpr": 0.10416666666666667,
            "logloss": 0.5275219572415689,
            "mae": 0.29776618982360925,
            "precision": 0.7660098522167488,
            "recall": 0.6973094170403588
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.9073943621969414,
            "auditor_fn_violation": 0.0023250386786174346,
            "auditor_fp_violation": 0.002179046830440195,
            "ave_precision_score": 0.9074340930503568,
            "fpr": 0.05817782656421515,
            "logloss": 0.4407637730756895,
            "mae": 0.26845518826393555,
            "precision": 0.8761682242990654,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8129511865812818,
            "auditor_fn_violation": 0.008944024860357171,
            "auditor_fp_violation": 0.01772739251562383,
            "ave_precision_score": 0.8133606734534877,
            "fpr": 0.14912280701754385,
            "logloss": 0.7745163657801225,
            "mae": 0.2769834840362375,
            "precision": 0.7178423236514523,
            "recall": 0.7757847533632287
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8686653574757438,
            "auditor_fn_violation": 0.0070745136001797845,
            "auditor_fp_violation": 0.015029975512961242,
            "ave_precision_score": 0.8688616795458006,
            "fpr": 0.09330406147091108,
            "logloss": 0.7345570370919573,
            "mae": 0.26576796203701114,
            "precision": 0.8131868131868132,
            "recall": 0.7283464566929134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8224690411231989,
            "auditor_fn_violation": 0.026593600031468805,
            "auditor_fp_violation": 0.023228672539718397,
            "ave_precision_score": 0.8229582791653345,
            "fpr": 0.13157894736842105,
            "logloss": 0.5472539160446737,
            "mae": 0.2988370969730424,
            "precision": 0.738562091503268,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8947199113893268,
            "auditor_fn_violation": 0.027390511422076633,
            "auditor_fp_violation": 0.020940640040530277,
            "ave_precision_score": 0.894888034461227,
            "fpr": 0.09440175631174534,
            "logloss": 0.4823332984754033,
            "mae": 0.2801302475426982,
            "precision": 0.8208333333333333,
            "recall": 0.7755905511811023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8001943333179447,
            "auditor_fn_violation": 0.008464617260640392,
            "auditor_fp_violation": 0.01449674346811234,
            "ave_precision_score": 0.8004982059391229,
            "fpr": 0.1524122807017544,
            "logloss": 0.794270364177994,
            "mae": 0.2816561637291345,
            "precision": 0.7139917695473251,
            "recall": 0.7780269058295964
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8536239554011649,
            "auditor_fn_violation": 0.009957042965677596,
            "auditor_fp_violation": 0.013038871471646517,
            "ave_precision_score": 0.8538791485486716,
            "fpr": 0.10537870472008781,
            "logloss": 0.7567465980882118,
            "mae": 0.269535450357485,
            "precision": 0.7948717948717948,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8283958650963492,
            "auditor_fn_violation": 0.003122295649437502,
            "auditor_fp_violation": 0.016122656426473914,
            "ave_precision_score": 0.828792542651928,
            "fpr": 0.10526315789473684,
            "logloss": 0.5217030085094497,
            "mae": 0.29653516070602726,
            "precision": 0.7675544794188862,
            "recall": 0.7107623318385651
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.9106721729912128,
            "auditor_fn_violation": 0.0017675479917370384,
            "auditor_fp_violation": 0.0016206660801398962,
            "ave_precision_score": 0.9107589865558625,
            "fpr": 0.06476399560922064,
            "logloss": 0.4385210378165663,
            "mae": 0.26772880571169533,
            "precision": 0.8649885583524027,
            "recall": 0.7440944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8251730631210205,
            "auditor_fn_violation": 0.012617024624341127,
            "auditor_fp_violation": 0.017892101498381153,
            "ave_precision_score": 0.825663797278076,
            "fpr": 0.125,
            "logloss": 0.5013620244770186,
            "mae": 0.3040489910278682,
            "precision": 0.75054704595186,
            "recall": 0.7690582959641256
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.9020785089082926,
            "auditor_fn_violation": 0.010488603853168197,
            "auditor_fp_violation": 0.008710739704684686,
            "ave_precision_score": 0.9022062900292591,
            "fpr": 0.07354555433589462,
            "logloss": 0.44920180849886643,
            "mae": 0.28991910046667807,
            "precision": 0.8537117903930131,
            "recall": 0.7696850393700787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8136657324946668,
            "auditor_fn_violation": 0.00939884745496027,
            "auditor_fp_violation": 0.014122618778706426,
            "ave_precision_score": 0.8142477845281476,
            "fpr": 0.11513157894736842,
            "logloss": 0.525251764561194,
            "mae": 0.2995474659306765,
            "precision": 0.7569444444444444,
            "recall": 0.7331838565022422
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.9104691314898417,
            "auditor_fn_violation": 0.006311745334796928,
            "auditor_fp_violation": 0.005150721945453009,
            "ave_precision_score": 0.9105724398983854,
            "fpr": 0.06476399560922064,
            "logloss": 0.4427099504404603,
            "mae": 0.2723843529656873,
            "precision": 0.865909090909091,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7802843517895407,
            "auditor_fn_violation": 0.0026895995594367074,
            "auditor_fp_violation": 0.01479086665160756,
            "ave_precision_score": 0.7807300570238573,
            "fpr": 0.11293859649122807,
            "logloss": 0.5598748566200586,
            "mae": 0.30360346408193245,
            "precision": 0.7553444180522565,
            "recall": 0.7130044843049327
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8923512236739282,
            "auditor_fn_violation": 0.0036301719145699573,
            "auditor_fp_violation": 0.00722354024290925,
            "ave_precision_score": 0.8920264712761693,
            "fpr": 0.06915477497255763,
            "logloss": 0.4630508278821101,
            "mae": 0.2732570512929745,
            "precision": 0.8577878103837472,
            "recall": 0.7480314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8268035417450715,
            "auditor_fn_violation": 0.005629966171032966,
            "auditor_fp_violation": 0.022374538814848282,
            "ave_precision_score": 0.8271919984295761,
            "fpr": 0.17434210526315788,
            "logloss": 0.5352975125898436,
            "mae": 0.3124934845328793,
            "precision": 0.7039106145251397,
            "recall": 0.8475336322869955
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.894392106593294,
            "auditor_fn_violation": 0.0061496840886107705,
            "auditor_fp_violation": 0.012156357505318247,
            "ave_precision_score": 0.8945260424951377,
            "fpr": 0.12623490669593854,
            "logloss": 0.46425856708414365,
            "mae": 0.29455119587552453,
            "precision": 0.7846441947565543,
            "recall": 0.8248031496062992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7928384982810197,
            "auditor_fn_violation": 0.011073086303201956,
            "auditor_fp_violation": 0.014546156162939543,
            "ave_precision_score": 0.7935125321247636,
            "fpr": 0.11403508771929824,
            "logloss": 0.5204799291024671,
            "mae": 0.3150625797928098,
            "precision": 0.7636363636363637,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8996947827060129,
            "auditor_fn_violation": 0.006914613170609442,
            "auditor_fp_violation": 0.014259137696693028,
            "ave_precision_score": 0.8997925416025456,
            "fpr": 0.08232711306256861,
            "logloss": 0.45389177663943703,
            "mae": 0.2909614787806075,
            "precision": 0.8394004282655246,
            "recall": 0.7716535433070866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8030640666767207,
            "auditor_fn_violation": 0.0068985524348989125,
            "auditor_fp_violation": 0.015002635343724115,
            "ave_precision_score": 0.8033601950780203,
            "fpr": 0.12390350877192982,
            "logloss": 0.5867518440611558,
            "mae": 0.3008552521545936,
            "precision": 0.7414187643020596,
            "recall": 0.726457399103139
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8999416289806191,
            "auditor_fn_violation": 0.004943948416985746,
            "auditor_fp_violation": 0.014057575864877304,
            "ave_precision_score": 0.9000625993731949,
            "fpr": 0.08562019758507135,
            "logloss": 0.46769480554086085,
            "mae": 0.26732686340758266,
            "precision": 0.8340425531914893,
            "recall": 0.7716535433070866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7617670605687108,
            "auditor_fn_violation": 0.001952049406026278,
            "auditor_fp_violation": 0.011216681725773663,
            "ave_precision_score": 0.7633852237145606,
            "fpr": 0.09320175438596491,
            "logloss": 0.5840054176121928,
            "mae": 0.32178645194283473,
            "precision": 0.7875,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8857457221622358,
            "auditor_fn_violation": 0.002121921916730774,
            "auditor_fp_violation": 0.0031623417126763315,
            "ave_precision_score": 0.8859393896266006,
            "fpr": 0.05817782656421515,
            "logloss": 0.5326226779127734,
            "mae": 0.30810938559116796,
            "precision": 0.8755868544600939,
            "recall": 0.734251968503937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7744566262310024,
            "auditor_fn_violation": 0.01131893635433877,
            "auditor_fp_violation": 0.011967284090053463,
            "ave_precision_score": 0.7763082842986189,
            "fpr": 0.10197368421052631,
            "logloss": 0.5533433641626645,
            "mae": 0.30538956611825707,
            "precision": 0.770935960591133,
            "recall": 0.7017937219730942
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.9038849037944388,
            "auditor_fn_violation": 0.009693423338548115,
            "auditor_fp_violation": 0.0040067223594719105,
            "ave_precision_score": 0.9039850913690306,
            "fpr": 0.06147091108671789,
            "logloss": 0.4684741916434503,
            "mae": 0.28009636361258256,
            "precision": 0.8700696055684455,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8019780964282149,
            "auditor_fn_violation": 0.008523621272913227,
            "auditor_fp_violation": 0.011863752729463153,
            "ave_precision_score": 0.8026195426176226,
            "fpr": 0.17763157894736842,
            "logloss": 0.7199256141857713,
            "mae": 0.28959619024515215,
            "precision": 0.6983240223463687,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8601938386766996,
            "auditor_fn_violation": 0.007835121048946818,
            "auditor_fp_violation": 0.016863098659069056,
            "ave_precision_score": 0.8604721737803426,
            "fpr": 0.12952799121844127,
            "logloss": 0.583336326926477,
            "mae": 0.2626589170844181,
            "precision": 0.7846715328467153,
            "recall": 0.8464566929133859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.7735035124990748,
            "auditor_fn_violation": 0.013103807725592012,
            "auditor_fp_violation": 0.023052198629621268,
            "ave_precision_score": 0.7744518137978975,
            "fpr": 0.12828947368421054,
            "logloss": 0.5260533911967022,
            "mae": 0.3058964237080593,
            "precision": 0.7494646680942184,
            "recall": 0.7847533632286996
        },
        "train": {
            "accuracy": 0.8122941822173436,
            "auc_prc": 0.903187020632831,
            "auditor_fn_violation": 0.01049292548639982,
            "auditor_fp_violation": 0.012033786121105977,
            "ave_precision_score": 0.9033244300872536,
            "fpr": 0.08232711306256861,
            "logloss": 0.4319370493708598,
            "mae": 0.27757166720656873,
            "precision": 0.8459958932238193,
            "recall": 0.8110236220472441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7978610950903321,
            "auditor_fn_violation": 0.023874498465895688,
            "auditor_fp_violation": 0.01685678789247798,
            "ave_precision_score": 0.7984334288704256,
            "fpr": 0.1118421052631579,
            "logloss": 0.5718212410149631,
            "mae": 0.3072287316135771,
            "precision": 0.7553956834532374,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8889376083377836,
            "auditor_fn_violation": 0.024667882486149165,
            "auditor_fp_violation": 0.012120947994323585,
            "ave_precision_score": 0.8893200713877467,
            "fpr": 0.08342480790340286,
            "logloss": 0.4952913929613087,
            "mae": 0.28559724677933584,
            "precision": 0.8325991189427313,
            "recall": 0.7440944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8010594167478066,
            "auditor_fn_violation": 0.0057184721894422185,
            "auditor_fp_violation": 0.01598383028386417,
            "ave_precision_score": 0.8014677669632985,
            "fpr": 0.18969298245614036,
            "logloss": 0.7353810140946399,
            "mae": 0.29257071442317967,
            "precision": 0.6871609403254972,
            "recall": 0.852017937219731
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8526255743501456,
            "auditor_fn_violation": 0.013448922616835356,
            "auditor_fp_violation": 0.017998926819436017,
            "ave_precision_score": 0.8529331477599065,
            "fpr": 0.1394072447859495,
            "logloss": 0.6070359221997015,
            "mae": 0.2685706286331277,
            "precision": 0.7744227353463587,
            "recall": 0.8582677165354331
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.794835734199619,
            "auditor_fn_violation": 0.006082330265124697,
            "auditor_fp_violation": 0.0179815149461637,
            "ave_precision_score": 0.7952050541030891,
            "fpr": 0.17105263157894737,
            "logloss": 1.0040250745374482,
            "mae": 0.2778936118495729,
            "precision": 0.6994219653179191,
            "recall": 0.8139013452914798
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8506125170360742,
            "auditor_fn_violation": 0.008600050130945487,
            "auditor_fp_violation": 0.02028964979993627,
            "ave_precision_score": 0.8508918167218675,
            "fpr": 0.12843029637760703,
            "logloss": 0.8894084507340911,
            "mae": 0.26056216696173684,
            "precision": 0.771484375,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8220719077335625,
            "auditor_fn_violation": 0.008329399732515145,
            "auditor_fp_violation": 0.023925156238235074,
            "ave_precision_score": 0.8226361231149502,
            "fpr": 0.19298245614035087,
            "logloss": 0.5785516725141111,
            "mae": 0.2955450153829971,
            "precision": 0.6851520572450805,
            "recall": 0.8587443946188341
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.899253052960369,
            "auditor_fn_violation": 0.005860134662091502,
            "auditor_fp_violation": 0.02093519242345417,
            "ave_precision_score": 0.8993837826047045,
            "fpr": 0.15477497255762898,
            "logloss": 0.4573199784151725,
            "mae": 0.27173874440703144,
            "precision": 0.7573149741824441,
            "recall": 0.8661417322834646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7964924817255852,
            "auditor_fn_violation": 0.005846314216033358,
            "auditor_fp_violation": 0.016339131089526403,
            "ave_precision_score": 0.7969232003407155,
            "fpr": 0.17324561403508773,
            "logloss": 0.9961675874367096,
            "mae": 0.2773893871104392,
            "precision": 0.6984732824427481,
            "recall": 0.820627802690583
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8503356291942362,
            "auditor_fn_violation": 0.008355877853358338,
            "auditor_fp_violation": 0.018701669422252973,
            "ave_precision_score": 0.8506274080132884,
            "fpr": 0.13062568605927552,
            "logloss": 0.886046790918782,
            "mae": 0.26124054590888507,
            "precision": 0.7684824902723736,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7983022141357476,
            "auditor_fn_violation": 0.0077811541184800576,
            "auditor_fp_violation": 0.014922633837813424,
            "ave_precision_score": 0.7987391225678601,
            "fpr": 0.16228070175438597,
            "logloss": 0.9563462095691896,
            "mae": 0.2747964785081325,
            "precision": 0.7069306930693069,
            "recall": 0.8004484304932735
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8538004223056372,
            "auditor_fn_violation": 0.006800089889971228,
            "auditor_fp_violation": 0.014417118591899949,
            "ave_precision_score": 0.8540652236003795,
            "fpr": 0.1163556531284303,
            "logloss": 0.873877272066178,
            "mae": 0.2608500056755894,
            "precision": 0.7841140529531568,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8150635801742225,
            "auditor_fn_violation": 0.01650637243332547,
            "auditor_fp_violation": 0.010583728634891952,
            "ave_precision_score": 0.8154089968435203,
            "fpr": 0.044956140350877194,
            "logloss": 0.6697763723723519,
            "mae": 0.33036518847138885,
            "precision": 0.8530465949820788,
            "recall": 0.5336322869955157
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.906133205675193,
            "auditor_fn_violation": 0.01458983378998592,
            "auditor_fp_violation": 0.0010159805846927414,
            "ave_precision_score": 0.9062378705310603,
            "fpr": 0.013172338090010977,
            "logloss": 0.6858239564135392,
            "mae": 0.34301344233357506,
            "precision": 0.9552238805970149,
            "recall": 0.5039370078740157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8264612828669251,
            "auditor_fn_violation": 0.0038598458028479294,
            "auditor_fp_violation": 0.01671325577893231,
            "ave_precision_score": 0.8269515863721723,
            "fpr": 0.11951754385964912,
            "logloss": 0.5289753563169481,
            "mae": 0.2979780193602078,
            "precision": 0.7453271028037384,
            "recall": 0.7152466367713004
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9071076129482238,
            "auditor_fn_violation": 0.004840229219426606,
            "auditor_fp_violation": 0.004987293433169999,
            "ave_precision_score": 0.9072152352842724,
            "fpr": 0.06695938529088913,
            "logloss": 0.4451510606213649,
            "mae": 0.2710659148091804,
            "precision": 0.8623024830699775,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7884315194935311,
            "auditor_fn_violation": 0.020695657304696722,
            "auditor_fp_violation": 0.01983096152398164,
            "ave_precision_score": 0.7895155212705973,
            "fpr": 0.14692982456140352,
            "logloss": 0.5470363687562091,
            "mae": 0.30979881708634294,
            "precision": 0.7270875763747454,
            "recall": 0.8004484304932735
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8926828206582789,
            "auditor_fn_violation": 0.023090486356603886,
            "auditor_fp_violation": 0.022790106037866388,
            "ave_precision_score": 0.8930056423214203,
            "fpr": 0.1119648737650933,
            "logloss": 0.47249386116950176,
            "mae": 0.2884098941087876,
            "precision": 0.7972166998011928,
            "recall": 0.7893700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8113672581839011,
            "auditor_fn_violation": 0.00996184407206357,
            "auditor_fp_violation": 0.01683325803779836,
            "ave_precision_score": 0.8119907206000052,
            "fpr": 0.11074561403508772,
            "logloss": 0.5369822444178529,
            "mae": 0.2941791785108906,
            "precision": 0.7645687645687645,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.9084964496375888,
            "auditor_fn_violation": 0.011785093822657461,
            "auditor_fp_violation": 0.00828582557274884,
            "ave_precision_score": 0.9085962872713478,
            "fpr": 0.06476399560922064,
            "logloss": 0.44994677372336395,
            "mae": 0.26729952463824974,
            "precision": 0.8662131519274376,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8159032191557245,
            "auditor_fn_violation": 0.009745496027063177,
            "auditor_fp_violation": 0.012390821474286585,
            "ave_precision_score": 0.8163540136985278,
            "fpr": 0.17763157894736842,
            "logloss": 0.627584855633265,
            "mae": 0.29140620748244384,
            "precision": 0.6983240223463687,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8818773096457064,
            "auditor_fn_violation": 0.0077486883843141995,
            "auditor_fp_violation": 0.01784911734984325,
            "ave_precision_score": 0.8820630070719665,
            "fpr": 0.1251372118551043,
            "logloss": 0.5009168109016625,
            "mae": 0.2646947094185879,
            "precision": 0.7904411764705882,
            "recall": 0.8464566929133859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7810665433534181,
            "auditor_fn_violation": 0.005271025096373222,
            "auditor_fp_violation": 0.018647409833596872,
            "ave_precision_score": 0.7805356090312517,
            "fpr": 0.19188596491228072,
            "logloss": 0.9287182322700633,
            "mae": 0.3030133371347594,
            "precision": 0.6846846846846847,
            "recall": 0.852017937219731
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8338995000202649,
            "auditor_fn_violation": 0.01054046345194776,
            "auditor_fp_violation": 0.01990831660460923,
            "ave_precision_score": 0.8334555019573877,
            "fpr": 0.141602634467618,
            "logloss": 0.7571623449631943,
            "mae": 0.27001751922316336,
            "precision": 0.7708703374777975,
            "recall": 0.8543307086614174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8209327078519545,
            "auditor_fn_violation": 0.008511328770356392,
            "auditor_fp_violation": 0.01242611625630601,
            "ave_precision_score": 0.821431036025122,
            "fpr": 0.11074561403508772,
            "logloss": 0.5305240863479275,
            "mae": 0.29567651066871914,
            "precision": 0.7623529411764706,
            "recall": 0.726457399103139
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.9050674716764506,
            "auditor_fn_violation": 0.00976689110348583,
            "auditor_fp_violation": 0.0055674646517747,
            "ave_precision_score": 0.9052064387845288,
            "fpr": 0.06366630076838639,
            "logloss": 0.445811801672519,
            "mae": 0.26919575793817885,
            "precision": 0.8681818181818182,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8344370573274227,
            "auditor_fn_violation": 0.009330009440641962,
            "auditor_fp_violation": 0.016468545290264293,
            "ave_precision_score": 0.8347478067901163,
            "fpr": 0.13267543859649122,
            "logloss": 0.5009750544869194,
            "mae": 0.29900825205933007,
            "precision": 0.7468619246861925,
            "recall": 0.8004484304932735
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.910766014661718,
            "auditor_fn_violation": 0.0049569133166806455,
            "auditor_fp_violation": 0.0022634848951197553,
            "ave_precision_score": 0.9108844749805651,
            "fpr": 0.08781558726673985,
            "logloss": 0.43277013317145036,
            "mae": 0.27574987808890583,
            "precision": 0.83640081799591,
            "recall": 0.8051181102362205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 20404,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7807834719121037,
            "auditor_fn_violation": 0.014500236016049087,
            "auditor_fp_violation": 0.013494371658760636,
            "ave_precision_score": 0.7819683516414698,
            "fpr": 0.0800438596491228,
            "logloss": 0.5820262586215407,
            "mae": 0.3127736340643503,
            "precision": 0.7994505494505495,
            "recall": 0.6524663677130045
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.9001312725921973,
            "auditor_fn_violation": 0.019406294026638553,
            "auditor_fp_violation": 0.002985294157703069,
            "ave_precision_score": 0.9002578616638833,
            "fpr": 0.04610318331503842,
            "logloss": 0.5311974546808136,
            "mae": 0.2971044878503993,
            "precision": 0.8942065491183879,
            "recall": 0.6988188976377953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7981621752986322,
            "auditor_fn_violation": 0.008720301313822678,
            "auditor_fp_violation": 0.017101498381146003,
            "ave_precision_score": 0.7985360414888343,
            "fpr": 0.17324561403508773,
            "logloss": 0.9823375432782304,
            "mae": 0.2770902652746261,
            "precision": 0.6978967495219885,
            "recall": 0.8183856502242153
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8522832258107529,
            "auditor_fn_violation": 0.010475638953473298,
            "auditor_fp_violation": 0.02104142095643813,
            "ave_precision_score": 0.852556674572706,
            "fpr": 0.12952799121844127,
            "logloss": 0.8719485398667931,
            "mae": 0.25918954467448935,
            "precision": 0.7704280155642024,
            "recall": 0.7795275590551181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8008458776360825,
            "auditor_fn_violation": 0.010768232239792307,
            "auditor_fp_violation": 0.013059069347187712,
            "ave_precision_score": 0.8012085311378365,
            "fpr": 0.17982456140350878,
            "logloss": 0.7178278491279078,
            "mae": 0.2903990194103436,
            "precision": 0.6940298507462687,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8586385225703849,
            "auditor_fn_violation": 0.01400641330371574,
            "auditor_fp_violation": 0.015155270705711557,
            "ave_precision_score": 0.8589048664489789,
            "fpr": 0.12843029637760703,
            "logloss": 0.5845334584916229,
            "mae": 0.2640255452609088,
            "precision": 0.7861060329067642,
            "recall": 0.8464566929133859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 20404,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8038128888003413,
            "auditor_fn_violation": 0.026886161592321614,
            "auditor_fp_violation": 0.025388713199307283,
            "ave_precision_score": 0.8042083228628083,
            "fpr": 0.13157894736842105,
            "logloss": 0.5761716393695081,
            "mae": 0.3253808050379903,
            "precision": 0.7278911564625851,
            "recall": 0.7197309417040358
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8802669560146945,
            "auditor_fn_violation": 0.025852009991616035,
            "auditor_fp_violation": 0.01868260276248662,
            "ave_precision_score": 0.8804281340611971,
            "fpr": 0.09330406147091108,
            "logloss": 0.5112742909503246,
            "mae": 0.29621329919017086,
            "precision": 0.8202959830866807,
            "recall": 0.7637795275590551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8116556750607796,
            "auditor_fn_violation": 0.018999291951852723,
            "auditor_fp_violation": 0.011915518409758314,
            "ave_precision_score": 0.8125559592746034,
            "fpr": 0.1524122807017544,
            "logloss": 0.7708085377533934,
            "mae": 0.2764552603412565,
            "precision": 0.7145790554414785,
            "recall": 0.7802690582959642
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8596540568366914,
            "auditor_fn_violation": 0.018284830203030338,
            "auditor_fp_violation": 0.02558473359790594,
            "ave_precision_score": 0.859888650462702,
            "fpr": 0.10208562019758508,
            "logloss": 0.7416826528025048,
            "mae": 0.2615267180579144,
            "precision": 0.802547770700637,
            "recall": 0.7440944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.802653491172222,
            "auditor_fn_violation": 0.008934190858311703,
            "auditor_fp_violation": 0.009797831488592725,
            "ave_precision_score": 0.8033555821208739,
            "fpr": 0.19298245614035087,
            "logloss": 0.7186309204867192,
            "mae": 0.2934563975074541,
            "precision": 0.6845878136200717,
            "recall": 0.8565022421524664
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8552619784944093,
            "auditor_fn_violation": 0.009922469899824541,
            "auditor_fp_violation": 0.019453440578754838,
            "ave_precision_score": 0.8555578897647645,
            "fpr": 0.14818880351262348,
            "logloss": 0.5911596350746093,
            "mae": 0.270826981205117,
            "precision": 0.7660311958405546,
            "recall": 0.8700787401574803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7848658764275419,
            "auditor_fn_violation": 0.006618283376602944,
            "auditor_fp_violation": 0.013508489571568406,
            "ave_precision_score": 0.7860797071516064,
            "fpr": 0.10197368421052631,
            "logloss": 0.592771697567611,
            "mae": 0.281303470779676,
            "precision": 0.7726161369193154,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9056302087206182,
            "auditor_fn_violation": 0.008185173340708923,
            "auditor_fp_violation": 0.0037670272081234903,
            "ave_precision_score": 0.9057221600809657,
            "fpr": 0.06147091108671789,
            "logloss": 0.48838587112464854,
            "mae": 0.2547565966616584,
            "precision": 0.8706697459584296,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7915854147680903,
            "auditor_fn_violation": 0.02502753520572732,
            "auditor_fp_violation": 0.015099107747910553,
            "ave_precision_score": 0.7921295516422242,
            "fpr": 0.12390350877192982,
            "logloss": 0.5379612885010057,
            "mae": 0.30810495702622065,
            "precision": 0.7472035794183445,
            "recall": 0.7488789237668162
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8967723224533979,
            "auditor_fn_violation": 0.02048454151793046,
            "auditor_fp_violation": 0.012357919337133955,
            "ave_precision_score": 0.8973692159789708,
            "fpr": 0.08562019758507135,
            "logloss": 0.45208467033735267,
            "mae": 0.28225942479004895,
            "precision": 0.8326180257510729,
            "recall": 0.7637795275590551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7181769350876407,
            "auditor_fn_violation": 0.013443080796160812,
            "auditor_fp_violation": 0.019256833069798966,
            "ave_precision_score": 0.7199508533307217,
            "fpr": 0.16447368421052633,
            "logloss": 0.8639775813374767,
            "mae": 0.3401032988389569,
            "precision": 0.668141592920354,
            "recall": 0.6771300448430493
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.8197866246539012,
            "auditor_fn_violation": 0.019220463797678423,
            "auditor_fp_violation": 0.01861723135757342,
            "ave_precision_score": 0.8200865111487472,
            "fpr": 0.11306256860592755,
            "logloss": 0.7915820932845784,
            "mae": 0.3206103099970801,
            "precision": 0.7659090909090909,
            "recall": 0.6633858267716536
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 20404,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8197827321831848,
            "auditor_fn_violation": 0.005187436078986706,
            "auditor_fp_violation": 0.02010861380920112,
            "ave_precision_score": 0.820323749382945,
            "fpr": 0.11403508771929824,
            "logloss": 0.5220133466493591,
            "mae": 0.30177518276072907,
            "precision": 0.755868544600939,
            "recall": 0.7219730941704036
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.9058300178954825,
            "auditor_fn_violation": 0.009827393968728669,
            "auditor_fp_violation": 0.005235160010132567,
            "ave_precision_score": 0.9059381776895885,
            "fpr": 0.06805708013172337,
            "logloss": 0.44656250214592264,
            "mae": 0.2773565786341706,
            "precision": 0.8609865470852018,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8012306812850881,
            "auditor_fn_violation": 0.007803280623082371,
            "auditor_fp_violation": 0.012663767788570137,
            "ave_precision_score": 0.8017594878802374,
            "fpr": 0.18201754385964913,
            "logloss": 0.7217237058579918,
            "mae": 0.28909956443883283,
            "precision": 0.6931608133086876,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8608461253366695,
            "auditor_fn_violation": 0.010596644683958963,
            "auditor_fp_violation": 0.017372450855684462,
            "ave_precision_score": 0.8611137326719397,
            "fpr": 0.12403951701427003,
            "logloss": 0.5779971631846011,
            "mae": 0.26092324397525657,
            "precision": 0.7915129151291513,
            "recall": 0.844488188976378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.804406799796921,
            "auditor_fn_violation": 0.0068002124144441916,
            "auditor_fp_violation": 0.013061422332655679,
            "ave_precision_score": 0.8050503769342515,
            "fpr": 0.10197368421052631,
            "logloss": 0.5560166607363739,
            "mae": 0.28580675158918256,
            "precision": 0.7726161369193154,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9085806075724279,
            "auditor_fn_violation": 0.011547403994917759,
            "auditor_fp_violation": 0.0035491225250794695,
            "ave_precision_score": 0.9086790052598127,
            "fpr": 0.06147091108671789,
            "logloss": 0.46725251218666775,
            "mae": 0.2625937149461265,
            "precision": 0.8706697459584296,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8034485134577396,
            "auditor_fn_violation": 0.011446778380929905,
            "auditor_fp_violation": 0.01316965966418192,
            "ave_precision_score": 0.8039342726478687,
            "fpr": 0.1611842105263158,
            "logloss": 0.7733714429901088,
            "mae": 0.2793875478512261,
            "precision": 0.7077534791252486,
            "recall": 0.7982062780269058
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8612441790202499,
            "auditor_fn_violation": 0.007100443399569565,
            "auditor_fp_violation": 0.0184973837818992,
            "ave_precision_score": 0.8614741869851061,
            "fpr": 0.10867178924259056,
            "logloss": 0.6971954827119776,
            "mae": 0.2623048697681459,
            "precision": 0.7946058091286307,
            "recall": 0.7539370078740157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7593205089328735,
            "auditor_fn_violation": 0.008349067736606096,
            "auditor_fp_violation": 0.023525148708681578,
            "ave_precision_score": 0.7605613193796573,
            "fpr": 0.12938596491228072,
            "logloss": 0.5312922556694535,
            "mae": 0.31109441279662414,
            "precision": 0.7451403887688985,
            "recall": 0.773542600896861
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8986124635764945,
            "auditor_fn_violation": 0.0066185812942427215,
            "auditor_fp_violation": 0.005907940719030981,
            "ave_precision_score": 0.8987721189137559,
            "fpr": 0.0867178924259056,
            "logloss": 0.4398811606883235,
            "mae": 0.2822713141670015,
            "precision": 0.8354166666666667,
            "recall": 0.7893700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8223068755261237,
            "auditor_fn_violation": 0.003958185823302655,
            "auditor_fp_violation": 0.01312024696935472,
            "ave_precision_score": 0.8227262823040011,
            "fpr": 0.10526315789473684,
            "logloss": 0.5456014012030694,
            "mae": 0.3005294789511122,
            "precision": 0.7647058823529411,
            "recall": 0.6995515695067265
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.9042104585295426,
            "auditor_fn_violation": 0.005574906868803855,
            "auditor_fp_violation": 0.0005147998136914965,
            "ave_precision_score": 0.9043222822813222,
            "fpr": 0.059275521405049394,
            "logloss": 0.4577639220818528,
            "mae": 0.2727961433206968,
            "precision": 0.8747099767981439,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.823385010953098,
            "auditor_fn_violation": 0.015714735268664938,
            "auditor_fp_violation": 0.020089789925457426,
            "ave_precision_score": 0.8238381353526257,
            "fpr": 0.14802631578947367,
            "logloss": 0.5248017872742028,
            "mae": 0.3141382983926553,
            "precision": 0.7283702213279678,
            "recall": 0.8116591928251121
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.9016437853469194,
            "auditor_fn_violation": 0.003215295124333391,
            "auditor_fp_violation": 0.011595252946479883,
            "ave_precision_score": 0.90176171160503,
            "fpr": 0.10647639956092206,
            "logloss": 0.44696242711421785,
            "mae": 0.29378251356822077,
            "precision": 0.8123791102514507,
            "recall": 0.8267716535433071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.730842867751236,
            "auditor_fn_violation": 0.009012862874675481,
            "auditor_fp_violation": 0.02045214968752353,
            "ave_precision_score": 0.7319816669884507,
            "fpr": 0.10964912280701754,
            "logloss": 0.6072558870706279,
            "mae": 0.3204084742883743,
            "precision": 0.7578692493946732,
            "recall": 0.7017937219730942
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8664473292566977,
            "auditor_fn_violation": 0.005957371409803204,
            "auditor_fp_violation": 0.00857727308632022,
            "ave_precision_score": 0.8668502864100115,
            "fpr": 0.06256860592755215,
            "logloss": 0.5157552232881617,
            "mae": 0.2925399298555781,
            "precision": 0.8680555555555556,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7897467524830742,
            "auditor_fn_violation": 0.03610553850995202,
            "auditor_fp_violation": 0.02367573977863113,
            "ave_precision_score": 0.7895935287190986,
            "fpr": 0.15570175438596492,
            "logloss": 1.9996755650876592,
            "mae": 0.28863697170848834,
            "precision": 0.7096114519427403,
            "recall": 0.7780269058295964
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.830323759737489,
            "auditor_fn_violation": 0.03162571198907491,
            "auditor_fp_violation": 0.025729095450422595,
            "ave_precision_score": 0.8304466337977392,
            "fpr": 0.11964873765093303,
            "logloss": 2.2028288086860703,
            "mae": 0.28174014492865496,
            "precision": 0.7854330708661418,
            "recall": 0.7854330708661418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8239627394674984,
            "auditor_fn_violation": 0.004774407993076865,
            "auditor_fp_violation": 0.011066090655824113,
            "ave_precision_score": 0.824331995148316,
            "fpr": 0.10197368421052631,
            "logloss": 0.5341791490486945,
            "mae": 0.2976052558510115,
            "precision": 0.7692307692307693,
            "recall": 0.695067264573991
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.9064082745678208,
            "auditor_fn_violation": 0.0018194075905166155,
            "auditor_fp_violation": 0.002179046830440195,
            "ave_precision_score": 0.9064283845380736,
            "fpr": 0.05817782656421515,
            "logloss": 0.45738932464440096,
            "mae": 0.27210264551707847,
            "precision": 0.875,
            "recall": 0.7303149606299213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.761452242283443,
            "auditor_fn_violation": 0.005376740618362046,
            "auditor_fp_violation": 0.012000225886604926,
            "ave_precision_score": 0.7621958033649577,
            "fpr": 0.08991228070175439,
            "logloss": 0.557245221001127,
            "mae": 0.3241139979552252,
            "precision": 0.7859007832898173,
            "recall": 0.6748878923766816
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8786125885047684,
            "auditor_fn_violation": 0.010592323050727335,
            "auditor_fp_violation": 0.007531330607708924,
            "ave_precision_score": 0.878782107400075,
            "fpr": 0.059275521405049394,
            "logloss": 0.5035605818463879,
            "mae": 0.3089573169558393,
            "precision": 0.8689320388349514,
            "recall": 0.7047244094488189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8105703089535126,
            "auditor_fn_violation": 0.0095586499881992,
            "auditor_fp_violation": 0.013548490324523764,
            "ave_precision_score": 0.8122578119064167,
            "fpr": 0.11403508771929824,
            "logloss": 0.50244913969315,
            "mae": 0.3025696496959171,
            "precision": 0.7630979498861048,
            "recall": 0.7511210762331838
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.9030265216741318,
            "auditor_fn_violation": 0.010186089526954026,
            "auditor_fp_violation": 0.00803795899578627,
            "ave_precision_score": 0.903162389498542,
            "fpr": 0.07464324917672886,
            "logloss": 0.45077489559466083,
            "mae": 0.2856916768988032,
            "precision": 0.8540772532188842,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8138197455219438,
            "auditor_fn_violation": 0.008958775863425387,
            "auditor_fp_violation": 0.014122618778706426,
            "ave_precision_score": 0.8143997609965654,
            "fpr": 0.11513157894736842,
            "logloss": 0.5252286867407387,
            "mae": 0.2998346380129653,
            "precision": 0.7575057736720554,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.9104805128058546,
            "auditor_fn_violation": 0.0065170229132994,
            "auditor_fp_violation": 0.005150721945453009,
            "ave_precision_score": 0.9105834903845968,
            "fpr": 0.06476399560922064,
            "logloss": 0.44279162701472236,
            "mae": 0.2727269372963127,
            "precision": 0.8662131519274376,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8114775478435632,
            "auditor_fn_violation": 0.007658229092911658,
            "auditor_fp_violation": 0.013186130562457649,
            "ave_precision_score": 0.8123092821260398,
            "fpr": 0.1206140350877193,
            "logloss": 0.5706815705007479,
            "mae": 0.298343498688809,
            "precision": 0.7447795823665894,
            "recall": 0.7197309417040358
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.9025745395585828,
            "auditor_fn_violation": 0.0068497886721349726,
            "auditor_fp_violation": 0.008558206426553866,
            "ave_precision_score": 0.9026926580498951,
            "fpr": 0.0867178924259056,
            "logloss": 0.4584983053775921,
            "mae": 0.2654140317126593,
            "precision": 0.8319148936170213,
            "recall": 0.7696850393700787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7979151155885243,
            "auditor_fn_violation": 0.006942805444103537,
            "auditor_fp_violation": 0.017101498381146003,
            "ave_precision_score": 0.7983644784928603,
            "fpr": 0.17324561403508773,
            "logloss": 0.9881251444419941,
            "mae": 0.27679090678332857,
            "precision": 0.6973180076628352,
            "recall": 0.8161434977578476
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8514416316886695,
            "auditor_fn_violation": 0.007746527567698382,
            "auditor_fp_violation": 0.021163992340650393,
            "ave_precision_score": 0.8517179493402844,
            "fpr": 0.12733260153677278,
            "logloss": 0.87948131655958,
            "mae": 0.26005390344515933,
            "precision": 0.7729941291585127,
            "recall": 0.7775590551181102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7559125306851449,
            "auditor_fn_violation": 0.008255644717174099,
            "auditor_fp_violation": 0.022647485129131853,
            "ave_precision_score": 0.7568955476728978,
            "fpr": 0.13267543859649122,
            "logloss": 0.5356588894172235,
            "mae": 0.31289787524943485,
            "precision": 0.7386609071274298,
            "recall": 0.7668161434977578
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8972013789081533,
            "auditor_fn_violation": 0.01071981123106044,
            "auditor_fp_violation": 0.0049191982197187446,
            "ave_precision_score": 0.8973673721245169,
            "fpr": 0.08781558726673985,
            "logloss": 0.44177843773319597,
            "mae": 0.28398758276242,
            "precision": 0.8336798336798337,
            "recall": 0.7893700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7893041295640602,
            "auditor_fn_violation": 0.008570332782629218,
            "auditor_fp_violation": 0.02003331827422634,
            "ave_precision_score": 0.789744389302259,
            "fpr": 0.17214912280701755,
            "logloss": 0.9869793778972445,
            "mae": 0.2833778557323542,
            "precision": 0.6957364341085271,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8461144366057926,
            "auditor_fn_violation": 0.007018332368168576,
            "auditor_fp_violation": 0.019104793085884413,
            "ave_precision_score": 0.8464005106716564,
            "fpr": 0.12184412733260154,
            "logloss": 0.8933880421348576,
            "mae": 0.2636321535968064,
            "precision": 0.7784431137724551,
            "recall": 0.7677165354330708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7695816487668419,
            "auditor_fn_violation": 0.01455678152781056,
            "auditor_fp_violation": 0.012320231910247732,
            "ave_precision_score": 0.7428028196256072,
            "fpr": 0.16228070175438597,
            "logloss": 2.7408329466867465,
            "mae": 0.28124723180780864,
            "precision": 0.6985743380855397,
            "recall": 0.7690582959641256
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8133371951316394,
            "auditor_fn_violation": 0.010594483867343152,
            "auditor_fp_violation": 0.02292357265623085,
            "ave_precision_score": 0.7900278661301922,
            "fpr": 0.10976948408342481,
            "logloss": 2.9922074254415825,
            "mae": 0.2650118891939987,
            "precision": 0.790356394129979,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7895415551712307,
            "auditor_fn_violation": 0.00465885846904257,
            "auditor_fp_violation": 0.014367329267374445,
            "ave_precision_score": 0.7907444938204564,
            "fpr": 0.1074561403508772,
            "logloss": 0.5900262712426179,
            "mae": 0.28283064109436645,
            "precision": 0.7627118644067796,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.9063621818996155,
            "auditor_fn_violation": 0.0021953896816685,
            "auditor_fp_violation": 0.005556569417622497,
            "ave_precision_score": 0.9064586768481178,
            "fpr": 0.06476399560922064,
            "logloss": 0.48467388156352864,
            "mae": 0.2520025160253604,
            "precision": 0.865909090909091,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7977220641696681,
            "auditor_fn_violation": 0.007832782629218786,
            "auditor_fp_violation": 0.017750922370303443,
            "ave_precision_score": 0.7981785587774037,
            "fpr": 0.17982456140350878,
            "logloss": 1.0028621080050457,
            "mae": 0.2790934118761122,
            "precision": 0.6940298507462687,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8508981382036879,
            "auditor_fn_violation": 0.011145492104376084,
            "auditor_fp_violation": 0.024026715114141197,
            "ave_precision_score": 0.851174318938123,
            "fpr": 0.14050493962678376,
            "logloss": 0.8764727466619116,
            "mae": 0.25971542646573337,
            "precision": 0.7589453860640302,
            "recall": 0.7933070866141733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7782129427829825,
            "auditor_fn_violation": 0.006928054441035326,
            "auditor_fp_violation": 0.013793200813191783,
            "ave_precision_score": 0.7797474834437905,
            "fpr": 0.09868421052631579,
            "logloss": 0.5545048630049145,
            "mae": 0.30859199667496506,
            "precision": 0.7777777777777778,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8982657919068007,
            "auditor_fn_violation": 0.0036301719145699573,
            "auditor_fp_violation": 0.0025767228769955335,
            "ave_precision_score": 0.8983074679506728,
            "fpr": 0.06147091108671789,
            "logloss": 0.4610704604244204,
            "mae": 0.280132029110486,
            "precision": 0.8715596330275229,
            "recall": 0.7480314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7637786873052166,
            "auditor_fn_violation": 0.006485524348989065,
            "auditor_fp_violation": 0.017546212634590767,
            "ave_precision_score": 0.7362697382602549,
            "fpr": 0.15679824561403508,
            "logloss": 2.997665866019772,
            "mae": 0.2855493901749615,
            "precision": 0.7045454545454546,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8078265001611509,
            "auditor_fn_violation": 0.010244431575581048,
            "auditor_fp_violation": 0.013368452304750603,
            "ave_precision_score": 0.7833895244592686,
            "fpr": 0.10098792535675083,
            "logloss": 3.2738849705349757,
            "mae": 0.272103897999339,
            "precision": 0.8029978586723768,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8188658499331776,
            "auditor_fn_violation": 0.0010571552198882922,
            "auditor_fp_violation": 0.015680295158497108,
            "ave_precision_score": 0.8193874070552509,
            "fpr": 0.11293859649122807,
            "logloss": 0.5180189388457566,
            "mae": 0.3227219035963348,
            "precision": 0.7553444180522565,
            "recall": 0.7130044843049327
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8935414098653052,
            "auditor_fn_violation": 0.00461766510799762,
            "auditor_fp_violation": 0.0030234274772357734,
            "ave_precision_score": 0.8936931963834058,
            "fpr": 0.07244785949506037,
            "logloss": 0.45728446605590345,
            "mae": 0.29331693170810963,
            "precision": 0.8536585365853658,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.824305146786743,
            "auditor_fn_violation": 0.0034910707261427186,
            "auditor_fp_violation": 0.013844966493486937,
            "ave_precision_score": 0.8246735774855011,
            "fpr": 0.09868421052631579,
            "logloss": 0.5334761165795083,
            "mae": 0.29718022364530744,
            "precision": 0.775,
            "recall": 0.695067264573991
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.9071520098461885,
            "auditor_fn_violation": 0.0021154394668833243,
            "auditor_fp_violation": 0.0013809709287914743,
            "ave_precision_score": 0.9071687944867586,
            "fpr": 0.0570801317233809,
            "logloss": 0.457949993334382,
            "mae": 0.2720068121409712,
            "precision": 0.8770685579196218,
            "recall": 0.7303149606299213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8383344543434808,
            "auditor_fn_violation": 0.007223074502399502,
            "auditor_fp_violation": 0.010950794367893986,
            "ave_precision_score": 0.8385867830175175,
            "fpr": 0.10087719298245613,
            "logloss": 0.5027856659014255,
            "mae": 0.3015011213719845,
            "precision": 0.7830188679245284,
            "recall": 0.7443946188340808
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.9086155832858436,
            "auditor_fn_violation": 0.0008902564457159678,
            "auditor_fp_violation": 0.004053027104618767,
            "ave_precision_score": 0.9087213224999193,
            "fpr": 0.06805708013172337,
            "logloss": 0.4407039566549689,
            "mae": 0.28178370746852405,
            "precision": 0.8616071428571429,
            "recall": 0.7598425196850394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7653807161483357,
            "auditor_fn_violation": 0.0067903784123987095,
            "auditor_fp_violation": 0.017059144642722686,
            "ave_precision_score": 0.7328645557249176,
            "fpr": 0.15679824561403508,
            "logloss": 3.278857676679177,
            "mae": 0.292682119468406,
            "precision": 0.7014613778705637,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8101379205696408,
            "auditor_fn_violation": 0.011275141101325013,
            "auditor_fp_violation": 0.017127308087259933,
            "ave_precision_score": 0.7837041384246396,
            "fpr": 0.10428100987925357,
            "logloss": 3.4802543210342267,
            "mae": 0.2801946571472609,
            "precision": 0.7956989247311828,
            "recall": 0.7283464566929134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7260523402267292,
            "auditor_fn_violation": 0.010202777122177641,
            "auditor_fp_violation": 0.02303572773134553,
            "ave_precision_score": 0.7274575521924754,
            "fpr": 0.10964912280701754,
            "logloss": 0.6134530698629875,
            "mae": 0.3189948518360197,
            "precision": 0.7542997542997543,
            "recall": 0.6883408071748879
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8651210913658424,
            "auditor_fn_violation": 0.009840358868423563,
            "auditor_fp_violation": 0.009519710840485602,
            "ave_precision_score": 0.8655421296130028,
            "fpr": 0.06256860592755215,
            "logloss": 0.5182419908248885,
            "mae": 0.2910711471212192,
            "precision": 0.8665105386416861,
            "recall": 0.7283464566929134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8245122918987888,
            "auditor_fn_violation": 0.004720320981826765,
            "auditor_fp_violation": 0.014715571116632785,
            "ave_precision_score": 0.8250023490343006,
            "fpr": 0.1074561403508772,
            "logloss": 0.5242138442205088,
            "mae": 0.2986763360820253,
            "precision": 0.7627118644067796,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.9056710651012052,
            "auditor_fn_violation": 0.008792362809753068,
            "auditor_fp_violation": 0.005504817055399543,
            "ave_precision_score": 0.9057872454089602,
            "fpr": 0.06256860592755215,
            "logloss": 0.4485659847087984,
            "mae": 0.27456858964753467,
            "precision": 0.868663594470046,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.7918242962711021,
            "auditor_fn_violation": 0.025081622216977423,
            "auditor_fp_violation": 0.015216757021308636,
            "ave_precision_score": 0.7924024921010338,
            "fpr": 0.12171052631578948,
            "logloss": 0.5390796894309434,
            "mae": 0.3070782852293888,
            "precision": 0.7522321428571429,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8962901480434459,
            "auditor_fn_violation": 0.021063640370969,
            "auditor_fp_violation": 0.012706566830004387,
            "ave_precision_score": 0.8968891992249702,
            "fpr": 0.0889132821075741,
            "logloss": 0.4522301673613857,
            "mae": 0.28164244013821604,
            "precision": 0.8272921108742004,
            "recall": 0.7637795275590551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7745972656138593,
            "auditor_fn_violation": 0.03417807410903942,
            "auditor_fp_violation": 0.01968272343950004,
            "ave_precision_score": 0.7752533832263393,
            "fpr": 0.12828947368421054,
            "logloss": 0.5677302731509517,
            "mae": 0.3148315544700349,
            "precision": 0.7394209354120267,
            "recall": 0.7443946188340808
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8842838001296462,
            "auditor_fn_violation": 0.023135863505536012,
            "auditor_fp_violation": 0.018086088692653615,
            "ave_precision_score": 0.8854777019709436,
            "fpr": 0.09220636663007684,
            "logloss": 0.46747594622952976,
            "mae": 0.2843435613961653,
            "precision": 0.8231578947368421,
            "recall": 0.7696850393700787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.789340093906753,
            "auditor_fn_violation": 0.005497207143419089,
            "auditor_fp_violation": 0.011539040734884423,
            "ave_precision_score": 0.7899346802470396,
            "fpr": 0.10526315789473684,
            "logloss": 0.5519230586038845,
            "mae": 0.3091516966079852,
            "precision": 0.7647058823529411,
            "recall": 0.6995515695067265
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8972350982433578,
            "auditor_fn_violation": 0.004222235667303401,
            "auditor_fp_violation": 0.0021817706389782483,
            "ave_precision_score": 0.8972870958323877,
            "fpr": 0.05817782656421515,
            "logloss": 0.4753786086728764,
            "mae": 0.28475728773324865,
            "precision": 0.8758782201405152,
            "recall": 0.7362204724409449
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7817362983011709,
            "auditor_fn_violation": 0.03166056958539847,
            "auditor_fp_violation": 0.02200982606731421,
            "ave_precision_score": 0.7827730479509243,
            "fpr": 0.14692982456140352,
            "logloss": 0.5688219370210277,
            "mae": 0.31471979692114954,
            "precision": 0.7154989384288747,
            "recall": 0.7556053811659192
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8894101053700106,
            "auditor_fn_violation": 0.031005557620335883,
            "auditor_fp_violation": 0.026066847709140833,
            "ave_precision_score": 0.8897100414682707,
            "fpr": 0.10757409440175632,
            "logloss": 0.48693028891890344,
            "mae": 0.28937764487430684,
            "precision": 0.8036072144288577,
            "recall": 0.7893700787401575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7616485206393178,
            "auditor_fn_violation": 0.005098930060577454,
            "auditor_fp_violation": 0.013572020179203377,
            "ave_precision_score": 0.7627089969574896,
            "fpr": 0.12938596491228072,
            "logloss": 0.5277256284374731,
            "mae": 0.312718512186078,
            "precision": 0.7440347071583514,
            "recall": 0.7690582959641256
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8907688341345148,
            "auditor_fn_violation": 0.008396933369058834,
            "auditor_fp_violation": 0.0020864373401464895,
            "ave_precision_score": 0.8911306560822447,
            "fpr": 0.0845225027442371,
            "logloss": 0.4440197009991577,
            "mae": 0.2841744553461327,
            "precision": 0.8378947368421052,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8074852291204405,
            "auditor_fn_violation": 0.005543918653135081,
            "auditor_fp_violation": 0.01588265190874182,
            "ave_precision_score": 0.8079328256963522,
            "fpr": 0.15460526315789475,
            "logloss": 0.7663863469765907,
            "mae": 0.28094713613226047,
            "precision": 0.7134146341463414,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8561575914670041,
            "auditor_fn_violation": 0.004161732802060559,
            "auditor_fp_violation": 0.018927745530911148,
            "ave_precision_score": 0.8564039722005636,
            "fpr": 0.1119648737650933,
            "logloss": 0.7326914891150803,
            "mae": 0.26889425048589466,
            "precision": 0.7875,
            "recall": 0.7440944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8272580913713248,
            "auditor_fn_violation": 0.004056525843757378,
            "auditor_fp_violation": 0.01312024696935472,
            "ave_precision_score": 0.827770521582296,
            "fpr": 0.10526315789473684,
            "logloss": 0.5171300401060971,
            "mae": 0.2972337372157837,
            "precision": 0.7641277641277642,
            "recall": 0.6973094170403588
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9074427865113375,
            "auditor_fn_violation": 0.010229305859270345,
            "auditor_fp_violation": 0.002761941857582949,
            "ave_precision_score": 0.9075640991140494,
            "fpr": 0.0570801317233809,
            "logloss": 0.4507677473584805,
            "mae": 0.27608798726939243,
            "precision": 0.8776470588235294,
            "recall": 0.734251968503937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8139877397985136,
            "auditor_fn_violation": 0.008958775863425387,
            "auditor_fp_violation": 0.0166403132294255,
            "ave_precision_score": 0.8145693754443609,
            "fpr": 0.11513157894736842,
            "logloss": 0.5248725155023634,
            "mae": 0.2994011053754213,
            "precision": 0.7575057736720554,
            "recall": 0.7354260089686099
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.9105612830903023,
            "auditor_fn_violation": 0.0065170229132994,
            "auditor_fp_violation": 0.005360455202882878,
            "ave_precision_score": 0.9106643337053442,
            "fpr": 0.06366630076838639,
            "logloss": 0.4424751249648593,
            "mae": 0.27222049559960315,
            "precision": 0.8681818181818182,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8071001606959265,
            "auditor_fn_violation": 0.008280229722287787,
            "auditor_fp_violation": 0.012515529704088544,
            "ave_precision_score": 0.8076412003981396,
            "fpr": 0.18092105263157895,
            "logloss": 0.6796063755205889,
            "mae": 0.2901613956782967,
            "precision": 0.6950092421441775,
            "recall": 0.8430493273542601
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8657091676041512,
            "auditor_fn_violation": 0.011046094540048578,
            "auditor_fp_violation": 0.01607591799157254,
            "ave_precision_score": 0.8659542990211442,
            "fpr": 0.12843029637760703,
            "logloss": 0.5542497178489446,
            "mae": 0.26380849345234497,
            "precision": 0.7861060329067642,
            "recall": 0.8464566929133859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8140105699421678,
            "auditor_fn_violation": 0.009435724962630796,
            "auditor_fp_violation": 0.01730385513139071,
            "ave_precision_score": 0.8145167816742193,
            "fpr": 0.14473684210526316,
            "logloss": 0.7611227178115182,
            "mae": 0.27515666345631024,
            "precision": 0.7244258872651357,
            "recall": 0.7780269058295964
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8755351004610862,
            "auditor_fn_violation": 0.007761653284009097,
            "auditor_fp_violation": 0.01597241326712663,
            "ave_precision_score": 0.8757179170262966,
            "fpr": 0.0889132821075741,
            "logloss": 0.7050702390541512,
            "mae": 0.2610410520858401,
            "precision": 0.8211920529801324,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7660388184220112,
            "auditor_fn_violation": 0.00844986625757219,
            "auditor_fp_violation": 0.015157932384609593,
            "ave_precision_score": 0.7678926135033011,
            "fpr": 0.10307017543859649,
            "logloss": 0.5503742328121991,
            "mae": 0.32642458156649873,
            "precision": 0.7712895377128953,
            "recall": 0.7107623318385651
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8864988976954229,
            "auditor_fn_violation": 0.0069491862364624854,
            "auditor_fp_violation": 0.007564016310165528,
            "ave_precision_score": 0.8845332317966392,
            "fpr": 0.06915477497255763,
            "logloss": 0.47742192930380606,
            "mae": 0.30644550975657486,
            "precision": 0.8568181818181818,
            "recall": 0.7421259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8256187606345089,
            "auditor_fn_violation": 0.008250727716151374,
            "auditor_fp_violation": 0.013484959716888787,
            "ave_precision_score": 0.8261723649776143,
            "fpr": 0.10855263157894737,
            "logloss": 0.501198920616918,
            "mae": 0.3011151699955869,
            "precision": 0.7697674418604651,
            "recall": 0.742152466367713
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.9036683948555094,
            "auditor_fn_violation": 0.013721185510428101,
            "auditor_fp_violation": 0.007514987756480622,
            "ave_precision_score": 0.9037978042927499,
            "fpr": 0.06805708013172337,
            "logloss": 0.4526772238001845,
            "mae": 0.28730473026140513,
            "precision": 0.8600451467268623,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8331492338475652,
            "auditor_fn_violation": 0.008626878294390688,
            "auditor_fp_violation": 0.018950944958963933,
            "ave_precision_score": 0.8336376555138774,
            "fpr": 0.17653508771929824,
            "logloss": 0.5358344863834104,
            "mae": 0.3067271262703447,
            "precision": 0.7040441176470589,
            "recall": 0.8587443946188341
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.903588109952355,
            "auditor_fn_violation": 0.005013094548691846,
            "auditor_fp_violation": 0.013052490514336764,
            "ave_precision_score": 0.9037133633218885,
            "fpr": 0.13721185510428102,
            "logloss": 0.44701320338678535,
            "mae": 0.2823161047775478,
            "precision": 0.7791519434628975,
            "recall": 0.8681102362204725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7690611325782268,
            "auditor_fn_violation": 0.005507041145464558,
            "auditor_fp_violation": 0.015727354867856338,
            "ave_precision_score": 0.7705675455650405,
            "fpr": 0.09210526315789473,
            "logloss": 0.5680874727491433,
            "mae": 0.31251676772770126,
            "precision": 0.7857142857142857,
            "recall": 0.6905829596412556
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8934460720667405,
            "auditor_fn_violation": 0.006210186953853607,
            "auditor_fp_violation": 0.0029362656040181636,
            "ave_precision_score": 0.8936057613750423,
            "fpr": 0.05159165751920966,
            "logloss": 0.4921224714541026,
            "mae": 0.28945847993213625,
            "precision": 0.8875598086124402,
            "recall": 0.7303149606299213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8013465992555138,
            "auditor_fn_violation": 0.007803280623082371,
            "auditor_fp_violation": 0.012663767788570137,
            "ave_precision_score": 0.8018830724894149,
            "fpr": 0.18201754385964913,
            "logloss": 0.7217997740387078,
            "mae": 0.2890805783354792,
            "precision": 0.6931608133086876,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8609575848152078,
            "auditor_fn_violation": 0.010596644683958963,
            "auditor_fp_violation": 0.017372450855684462,
            "ave_precision_score": 0.8612233360361548,
            "fpr": 0.12403951701427003,
            "logloss": 0.5778844083563329,
            "mae": 0.2608538974509968,
            "precision": 0.7915129151291513,
            "recall": 0.844488188976378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7902328340633994,
            "auditor_fn_violation": 0.023906458972543468,
            "auditor_fp_violation": 0.015216757021308636,
            "ave_precision_score": 0.7908330709512351,
            "fpr": 0.12171052631578948,
            "logloss": 0.5358799364482607,
            "mae": 0.30676928996259095,
            "precision": 0.7527839643652561,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8971600385663852,
            "auditor_fn_violation": 0.019579159355903788,
            "auditor_fp_violation": 0.012357919337133955,
            "ave_precision_score": 0.8977573138190845,
            "fpr": 0.08562019758507135,
            "logloss": 0.4508550024629466,
            "mae": 0.28159056092626755,
            "precision": 0.8343949044585988,
            "recall": 0.7736220472440944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8011520803998633,
            "auditor_fn_violation": 0.01605646683974511,
            "auditor_fp_violation": 0.014190855357277314,
            "ave_precision_score": 0.8017110592130109,
            "fpr": 0.049342105263157895,
            "logloss": 0.5791933565706384,
            "mae": 0.3667067675667472,
            "precision": 0.82,
            "recall": 0.45964125560538116
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.8766918645433259,
            "auditor_fn_violation": 0.021796157203730435,
            "auditor_fp_violation": 0.004853826814805535,
            "ave_precision_score": 0.8768713765702987,
            "fpr": 0.021953896816684963,
            "logloss": 0.6170538270639586,
            "mae": 0.3857223519689427,
            "precision": 0.9183673469387755,
            "recall": 0.44291338582677164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 20404,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8225082261519302,
            "auditor_fn_violation": 0.004764573991031392,
            "auditor_fp_violation": 0.019440365936299976,
            "ave_precision_score": 0.8233437363645952,
            "fpr": 0.11732456140350878,
            "logloss": 0.5252831225227653,
            "mae": 0.29748668012223534,
            "precision": 0.7523148148148148,
            "recall": 0.7286995515695067
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.9096930640617263,
            "auditor_fn_violation": 0.007448334874715859,
            "auditor_fp_violation": 0.0016206660801398962,
            "ave_precision_score": 0.9098314279096282,
            "fpr": 0.06476399560922064,
            "logloss": 0.4343817615555647,
            "mae": 0.2665953350056098,
            "precision": 0.8671171171171171,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8235839542855707,
            "auditor_fn_violation": 0.0003589410746597393,
            "auditor_fp_violation": 0.013939085912205407,
            "ave_precision_score": 0.8240694442350549,
            "fpr": 0.10855263157894737,
            "logloss": 0.5294278374113758,
            "mae": 0.29830594606526,
            "precision": 0.7614457831325301,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.9049822418361433,
            "auditor_fn_violation": 0.008029594544370215,
            "auditor_fp_violation": 0.003216817883437339,
            "ave_precision_score": 0.9050973334416883,
            "fpr": 0.06037321624588365,
            "logloss": 0.45096676285108805,
            "mae": 0.27361660452332637,
            "precision": 0.8723897911832946,
            "recall": 0.7401574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.809860302427359,
            "auditor_fn_violation": 0.009553732987176461,
            "auditor_fp_violation": 0.01395320382501318,
            "ave_precision_score": 0.8104781919483921,
            "fpr": 0.125,
            "logloss": 0.5101129203096864,
            "mae": 0.3188136277277137,
            "precision": 0.7466666666666667,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8903578309009513,
            "auditor_fn_violation": 0.012416052274475573,
            "auditor_fp_violation": 0.0014218280568622317,
            "ave_precision_score": 0.8905213586848992,
            "fpr": 0.08122941822173436,
            "logloss": 0.4551338517236075,
            "mae": 0.2937936342109719,
            "precision": 0.8432203389830508,
            "recall": 0.7834645669291339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8231698105314651,
            "auditor_fn_violation": 0.007515636063252301,
            "auditor_fp_violation": 0.01444733077328515,
            "ave_precision_score": 0.8236713991158346,
            "fpr": 0.14692982456140352,
            "logloss": 0.5426451652155285,
            "mae": 0.3046598033530213,
            "precision": 0.7314629258517034,
            "recall": 0.8183856502242153
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.9012842554904278,
            "auditor_fn_violation": 0.00703777971771092,
            "auditor_fp_violation": 0.010132567761546911,
            "ave_precision_score": 0.9014118496823652,
            "fpr": 0.10647639956092206,
            "logloss": 0.445784392027098,
            "mae": 0.2785181523342622,
            "precision": 0.8098039215686275,
            "recall": 0.812992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7885941758653299,
            "auditor_fn_violation": 0.020823499331287864,
            "auditor_fp_violation": 0.020830980347865378,
            "ave_precision_score": 0.7895397348178401,
            "fpr": 0.15679824561403508,
            "logloss": 0.5544687015447421,
            "mae": 0.3124953464032028,
            "precision": 0.717391304347826,
            "recall": 0.8139013452914798
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8929034514494262,
            "auditor_fn_violation": 0.021884750684978874,
            "auditor_fp_violation": 0.025097171869594953,
            "ave_precision_score": 0.8931859055916864,
            "fpr": 0.12403951701427003,
            "logloss": 0.4732822356762323,
            "mae": 0.2887635395245455,
            "precision": 0.7863894139886578,
            "recall": 0.8188976377952756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 20404,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8228925748581835,
            "auditor_fn_violation": 0.011446778380929903,
            "auditor_fp_violation": 0.022247477599578343,
            "ave_precision_score": 0.8233471988777105,
            "fpr": 0.18092105263157895,
            "logloss": 0.556932305698634,
            "mae": 0.3222382822188369,
            "precision": 0.6955719557195572,
            "recall": 0.8452914798206278
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.89670211101488,
            "auditor_fn_violation": 0.002052775785024679,
            "auditor_fp_violation": 0.015975137075664676,
            "ave_precision_score": 0.8968331775471935,
            "fpr": 0.13062568605927552,
            "logloss": 0.4595861001816345,
            "mae": 0.295952762298196,
            "precision": 0.7832422586520947,
            "recall": 0.8464566929133859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7752509473739102,
            "auditor_fn_violation": 0.012299878058374639,
            "auditor_fp_violation": 0.01570853098411264,
            "ave_precision_score": 0.7761824212851436,
            "fpr": 0.15021929824561403,
            "logloss": 0.538552096680981,
            "mae": 0.3176982195275885,
            "precision": 0.7248995983935743,
            "recall": 0.8094170403587444
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8995962474338276,
            "auditor_fn_violation": 0.008167886807782401,
            "auditor_fp_violation": 0.008547311192401668,
            "ave_precision_score": 0.8997512187380647,
            "fpr": 0.10318331503841932,
            "logloss": 0.4399414535528888,
            "mae": 0.2899960200808345,
            "precision": 0.81640625,
            "recall": 0.8228346456692913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 20404,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7790862870632185,
            "auditor_fn_violation": 0.002365077491936124,
            "auditor_fp_violation": 0.016141480310217608,
            "ave_precision_score": 0.7800030992350212,
            "fpr": 0.11293859649122807,
            "logloss": 0.5526094151811675,
            "mae": 0.30962596960384153,
            "precision": 0.7535885167464115,
            "recall": 0.7062780269058296
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8925487391981195,
            "auditor_fn_violation": 0.005510082370329396,
            "auditor_fp_violation": 0.00722354024290925,
            "ave_precision_score": 0.8926223908316187,
            "fpr": 0.06915477497255763,
            "logloss": 0.47806098884313947,
            "mae": 0.2845914288603882,
            "precision": 0.8561643835616438,
            "recall": 0.7381889763779528
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7756994885850719,
            "auditor_fn_violation": 0.009327550940130597,
            "auditor_fp_violation": 0.02261219034711242,
            "ave_precision_score": 0.7764518980297627,
            "fpr": 0.12390350877192982,
            "logloss": 0.5291642461478121,
            "mae": 0.3100344834858429,
            "precision": 0.7521929824561403,
            "recall": 0.7690582959641256
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8999120678112251,
            "auditor_fn_violation": 0.008435828068143511,
            "auditor_fp_violation": 0.005542950374932251,
            "ave_precision_score": 0.9000751746661471,
            "fpr": 0.08122941822173436,
            "logloss": 0.4364968977207722,
            "mae": 0.28201114425167817,
            "precision": 0.8425531914893617,
            "recall": 0.7795275590551181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8108870977148979,
            "auditor_fn_violation": 0.008781763826606876,
            "auditor_fp_violation": 0.011336683984639717,
            "ave_precision_score": 0.8117216123836654,
            "fpr": 0.125,
            "logloss": 0.573978883186358,
            "mae": 0.2986257336351787,
            "precision": 0.7397260273972602,
            "recall": 0.726457399103139
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.9023709050955013,
            "auditor_fn_violation": 0.007517481006421952,
            "auditor_fp_violation": 0.01028782484821577,
            "ave_precision_score": 0.9024882058370731,
            "fpr": 0.08781558726673985,
            "logloss": 0.4593369498787079,
            "mae": 0.26524554832115704,
            "precision": 0.8315789473684211,
            "recall": 0.7775590551181102
        }
    }
]