[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7426643104856605,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6622189769760471,
            "fpr": 0.14035087719298245,
            "logloss": 3.091720325972617,
            "mae": 0.40586504918572147,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7577581923176904,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6819524786131307,
            "fpr": 0.13830954994511527,
            "logloss": 2.820834012155881,
            "mae": 0.4062541233852064,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7499483987969905,
            "auditor_fn_violation": 0.008366504496535462,
            "auditor_fp_violation": 0.006375241429261226,
            "ave_precision_score": 0.6609824867410518,
            "fpr": 0.11513157894736842,
            "logloss": 3.425193661143866,
            "mae": 0.40611006633231517,
            "precision": 0.7258485639686684,
            "recall": 0.5840336134453782
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7619720115132941,
            "auditor_fn_violation": 0.015606556774706171,
            "auditor_fp_violation": 0.022493871415063014,
            "ave_precision_score": 0.6761249701156036,
            "fpr": 0.11745334796926454,
            "logloss": 3.2579428640473185,
            "mae": 0.40836533671807246,
            "precision": 0.718421052631579,
            "recall": 0.5711297071129707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5640231625490562,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5134203094025779,
            "fpr": 0.4780701754385965,
            "logloss": 0.6967826369792639,
            "mae": 0.5002769431785533,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5937930110275789,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5260847072884255,
            "fpr": 0.47530186608122943,
            "logloss": 0.6935773670914758,
            "mae": 0.4986168722551557,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7581453634085213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5953811865303397,
            "fpr": 0.4780701754385965,
            "logloss": 0.6581534386540292,
            "mae": 0.45802062985144165,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7449974648774533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5891454305790476,
            "fpr": 0.47530186608122943,
            "logloss": 0.667791138936192,
            "mae": 0.4614920423792432,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7581453634085213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5953811865303397,
            "fpr": 0.4780701754385965,
            "logloss": 0.6581534386540292,
            "mae": 0.45802062985144165,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7449974648774533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5891454305790476,
            "fpr": 0.47530186608122943,
            "logloss": 0.667791138936192,
            "mae": 0.4614920423792432,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 15860,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 15860,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5221168319544949,
            "auditor_fn_violation": 0.003160474716202271,
            "auditor_fp_violation": 0.0055679623370352505,
            "ave_precision_score": 0.5212746920448565,
            "fpr": 0.33114035087719296,
            "logloss": 1.7209931921454407,
            "mae": 0.4996697038019958,
            "precision": 0.49750415973377704,
            "recall": 0.6281512605042017
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5139024355598328,
            "auditor_fn_violation": 0.005936278584846308,
            "auditor_fp_violation": 0.02962255015045772,
            "ave_precision_score": 0.5123154096843583,
            "fpr": 0.3205268935236004,
            "logloss": 1.5558678112693363,
            "mae": 0.5029105278780903,
            "precision": 0.4974182444061962,
            "recall": 0.604602510460251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6911522493714541,
            "auditor_fn_violation": 0.018882223942208468,
            "auditor_fp_violation": 0.00020873571543537778,
            "ave_precision_score": 0.681383444455155,
            "fpr": 0.01644736842105263,
            "logloss": 0.797310260375651,
            "mae": 0.4633135681383704,
            "precision": 0.765625,
            "recall": 0.10294117647058823
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6782878314459367,
            "auditor_fn_violation": 0.030517294434824954,
            "auditor_fp_violation": 0.003741795808478869,
            "ave_precision_score": 0.6752372620963012,
            "fpr": 0.02305159165751921,
            "logloss": 0.7959992050629672,
            "mae": 0.4627708072163794,
            "precision": 0.7307692307692307,
            "recall": 0.1192468619246862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.79340189402474,
            "auditor_fn_violation": 0.010960305174701458,
            "auditor_fp_violation": 0.00392071060679221,
            "ave_precision_score": 0.643486838628202,
            "fpr": 0.01425438596491228,
            "logloss": 0.61796093365278,
            "mae": 0.44160598647176175,
            "precision": 0.9182389937106918,
            "recall": 0.3067226890756303
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7991614611576662,
            "auditor_fn_violation": 0.02262904803677967,
            "auditor_fp_violation": 0.003371672374848845,
            "ave_precision_score": 0.6496236317932296,
            "fpr": 0.013172338090010977,
            "logloss": 0.6146301423017609,
            "mae": 0.4399533225335876,
            "precision": 0.9254658385093167,
            "recall": 0.3117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7478005778681633,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6903128074082561,
            "fpr": 0.14035087719298245,
            "logloss": 3.1332190044275388,
            "mae": 0.4014103319822696,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.760755323561459,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.707551650474185,
            "fpr": 0.13830954994511527,
            "logloss": 2.871856376374041,
            "mae": 0.4024519874876862,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.556787634923352,
            "auditor_fn_violation": 0.007048872180451128,
            "auditor_fp_violation": 0.005009657170449058,
            "ave_precision_score": 0.5559359336731147,
            "fpr": 0.3969298245614035,
            "logloss": 1.7196534467884588,
            "mae": 0.48256952867826874,
            "precision": 0.5400254129606099,
            "recall": 0.8928571428571429
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5770720534675612,
            "auditor_fn_violation": 0.008306197153341997,
            "auditor_fp_violation": 0.014640156364475253,
            "ave_precision_score": 0.5754296091539036,
            "fpr": 0.3699231613611416,
            "logloss": 1.5706562920159228,
            "mae": 0.47712665076575084,
            "precision": 0.5589005235602095,
            "recall": 0.893305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7581453634085213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5953811865303397,
            "fpr": 0.4780701754385965,
            "logloss": 0.6581534386540292,
            "mae": 0.45802062985144165,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7449974648774533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5891454305790476,
            "fpr": 0.47530186608122943,
            "logloss": 0.667791138936192,
            "mae": 0.4614920423792432,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5872364160800501,
            "auditor_fn_violation": 0.010508808786672569,
            "auditor_fp_violation": 0.01552440447448897,
            "ave_precision_score": 0.5876593817334624,
            "fpr": 0.16337719298245615,
            "logloss": 1.6674898092254686,
            "mae": 0.4737339991291887,
            "precision": 0.615979381443299,
            "recall": 0.5021008403361344
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.5984318877484047,
            "auditor_fn_violation": 0.00850828323282614,
            "auditor_fp_violation": 0.006652081437295772,
            "ave_precision_score": 0.597434495333794,
            "fpr": 0.15148188803512624,
            "logloss": 1.5143138111931789,
            "mae": 0.4754788624337424,
            "precision": 0.639686684073107,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6565616717240685,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6547834925070884,
            "fpr": 0.4780701754385965,
            "logloss": 0.6579685997262875,
            "mae": 0.4579987101779695,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6432511562933892,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6417955580049401,
            "fpr": 0.47530186608122943,
            "logloss": 0.6676203107572244,
            "mae": 0.46147490332862023,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 15860,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.744626773224319,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6642562838347544,
            "fpr": 0.14035087719298245,
            "logloss": 3.144289616329591,
            "mae": 0.4008882130055051,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7604912992708894,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6848795194337547,
            "fpr": 0.13830954994511527,
            "logloss": 2.88388973473168,
            "mae": 0.4013701243209525,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7426643104856605,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6622189769760471,
            "fpr": 0.14035087719298245,
            "logloss": 3.138965708945892,
            "mae": 0.40153229360779125,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7577581923176904,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6819524786131307,
            "fpr": 0.13830954994511527,
            "logloss": 2.876286261046369,
            "mae": 0.4020334079158293,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.79340189402474,
            "auditor_fn_violation": 0.010960305174701458,
            "auditor_fp_violation": 0.00392071060679221,
            "ave_precision_score": 0.643486838628202,
            "fpr": 0.01425438596491228,
            "logloss": 0.61796093365278,
            "mae": 0.44160598647176175,
            "precision": 0.9182389937106918,
            "recall": 0.3067226890756303
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7991614611576662,
            "auditor_fn_violation": 0.02262904803677967,
            "auditor_fp_violation": 0.003371672374848845,
            "ave_precision_score": 0.6496236317932296,
            "fpr": 0.013172338090010977,
            "logloss": 0.6146301423017609,
            "mae": 0.4399533225335876,
            "precision": 0.9254658385093167,
            "recall": 0.3117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.79340189402474,
            "auditor_fn_violation": 0.010960305174701458,
            "auditor_fp_violation": 0.00392071060679221,
            "ave_precision_score": 0.643486838628202,
            "fpr": 0.01425438596491228,
            "logloss": 0.61796093365278,
            "mae": 0.44160598647176175,
            "precision": 0.9182389937106918,
            "recall": 0.3067226890756303
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7991614611576662,
            "auditor_fn_violation": 0.02262904803677967,
            "auditor_fp_violation": 0.003371672374848845,
            "ave_precision_score": 0.6496236317932296,
            "fpr": 0.013172338090010977,
            "logloss": 0.6146301423017609,
            "mae": 0.4399533225335876,
            "precision": 0.9254658385093167,
            "recall": 0.3117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7581453634085213,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5953811865303397,
            "fpr": 0.4780701754385965,
            "logloss": 0.6581534386540292,
            "mae": 0.45802062985144165,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7449974648774533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5891454305790476,
            "fpr": 0.47530186608122943,
            "logloss": 0.667791138936192,
            "mae": 0.4614920423792432,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7426643104856605,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6622189769760471,
            "fpr": 0.14035087719298245,
            "logloss": 3.1341365796242346,
            "mae": 0.4019248357140704,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7577581923176904,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6819524786131307,
            "fpr": 0.13830954994511527,
            "logloss": 2.871556127269087,
            "mae": 0.40243442063797447,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 15860,
        "test": {
            "accuracy": 0.4550438596491228,
            "auc_prc": 0.4699143034886037,
            "auditor_fn_violation": 0.003167385375202712,
            "auditor_fp_violation": 0.006619185578625472,
            "ave_precision_score": 0.46907466809900716,
            "fpr": 0.3355263157894737,
            "logloss": 1.774708290931192,
            "mae": 0.5193528202362359,
            "precision": 0.48223350253807107,
            "recall": 0.5987394957983193
        },
        "train": {
            "accuracy": 0.4500548847420417,
            "auc_prc": 0.46576651715702094,
            "auditor_fn_violation": 0.005072819881595929,
            "auditor_fp_violation": 0.027325756788342655,
            "ave_precision_score": 0.464131773291906,
            "fpr": 0.3205268935236004,
            "logloss": 1.6525664150690218,
            "mae": 0.5220123775033475,
            "precision": 0.47950089126559714,
            "recall": 0.5627615062761506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.768960858740714,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.7009656100156357,
            "fpr": 0.14035087719298245,
            "logloss": 3.504592598362043,
            "mae": 0.39908583279241594,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7771258294251076,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.712033666064601,
            "fpr": 0.13830954994511527,
            "logloss": 3.348337497847764,
            "mae": 0.4011636969155983,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6940761829749628,
            "auditor_fn_violation": 0.005498581011351913,
            "auditor_fp_violation": 0.009184371479156616,
            "ave_precision_score": 0.6945597238438156,
            "fpr": 0.2324561403508772,
            "logloss": 0.6561812026126228,
            "mae": 0.47020643733833967,
            "precision": 0.5646817248459959,
            "recall": 0.5777310924369747
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6526439015882097,
            "auditor_fn_violation": 0.004735244271548579,
            "auditor_fp_violation": 0.02391605803332632,
            "ave_precision_score": 0.6542659272414928,
            "fpr": 0.2327113062568606,
            "logloss": 0.6709085259540865,
            "mae": 0.4778223773781476,
            "precision": 0.5564853556485355,
            "recall": 0.5564853556485355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 15860,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5128983089212527,
            "auditor_fn_violation": 0.009988205808639253,
            "auditor_fp_violation": 0.007871599871237731,
            "ave_precision_score": 0.5120639210870568,
            "fpr": 0.2774122807017544,
            "logloss": 1.7241041758062716,
            "mae": 0.50188632306169,
            "precision": 0.5134615384615384,
            "recall": 0.5609243697478992
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5053365722642522,
            "auditor_fn_violation": 0.009250031001841741,
            "auditor_fp_violation": 0.027564055437392102,
            "ave_precision_score": 0.5037475748607894,
            "fpr": 0.287596048298573,
            "logloss": 1.5639513835421532,
            "mae": 0.5063408936417849,
            "precision": 0.5037878787878788,
            "recall": 0.5564853556485355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.615973984241394,
            "auditor_fn_violation": 0.01238390092879257,
            "auditor_fp_violation": 0.015989658779977475,
            "ave_precision_score": 0.6166876008078213,
            "fpr": 0.29714912280701755,
            "logloss": 0.6996434133257622,
            "mae": 0.48466893783852194,
            "precision": 0.5203539823008849,
            "recall": 0.6176470588235294
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5694438183352518,
            "auditor_fn_violation": 0.01076797303069413,
            "auditor_fp_violation": 0.027667994209849858,
            "ave_precision_score": 0.5713029264271112,
            "fpr": 0.2996706915477497,
            "logloss": 0.7220366744502235,
            "mae": 0.4953167728515409,
            "precision": 0.510752688172043,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7649429960599814,
            "auditor_fn_violation": 0.058977867462774586,
            "auditor_fp_violation": 0.03220062771607919,
            "ave_precision_score": 0.7485989105204537,
            "fpr": 0.09429824561403509,
            "logloss": 0.5988716838529736,
            "mae": 0.40897095214836954,
            "precision": 0.7630853994490359,
            "recall": 0.5819327731092437
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.753198262460551,
            "auditor_fn_violation": 0.05758993978753405,
            "auditor_fp_violation": 0.041022858924664674,
            "ave_precision_score": 0.7395905349639293,
            "fpr": 0.11306256860592755,
            "logloss": 0.6049558856110336,
            "mae": 0.4089211402328033,
            "precision": 0.7338501291989664,
            "recall": 0.5941422594142259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 15860,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8230396539458285,
            "auditor_fn_violation": 0.013791371811882643,
            "auditor_fp_violation": 0.005567962337035252,
            "ave_precision_score": 0.8232693532995808,
            "fpr": 0.08114035087719298,
            "logloss": 0.5324402125963774,
            "mae": 0.36382801207844495,
            "precision": 0.8047493403693932,
            "recall": 0.6407563025210085
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8327490260576659,
            "auditor_fn_violation": 0.018963941413408413,
            "auditor_fp_violation": 0.007942443270978525,
            "ave_precision_score": 0.8326490118109799,
            "fpr": 0.07244785949506037,
            "logloss": 0.5303571878709281,
            "mae": 0.3656368638510467,
            "precision": 0.8225806451612904,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5640231625490562,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5134203094025779,
            "fpr": 0.4780701754385965,
            "logloss": 0.6967826369792639,
            "mae": 0.5002769431785533,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5937930110275789,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5260847072884255,
            "fpr": 0.47530186608122943,
            "logloss": 0.6935773670914758,
            "mae": 0.4986168722551557,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7499483987969905,
            "auditor_fn_violation": 0.008366504496535462,
            "auditor_fp_violation": 0.006375241429261226,
            "ave_precision_score": 0.6609824867410518,
            "fpr": 0.11513157894736842,
            "logloss": 3.4252459938898427,
            "mae": 0.4060991688778526,
            "precision": 0.7258485639686684,
            "recall": 0.5840336134453782
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7619720115132941,
            "auditor_fn_violation": 0.015606556774706171,
            "auditor_fp_violation": 0.022493871415063014,
            "ave_precision_score": 0.6761249701156036,
            "fpr": 0.11745334796926454,
            "logloss": 3.25801706193813,
            "mae": 0.4083585252353572,
            "precision": 0.718421052631579,
            "recall": 0.5711297071129707
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6667042922836126,
            "auditor_fn_violation": 0.046333665044965354,
            "auditor_fp_violation": 0.006790197971994206,
            "ave_precision_score": 0.6245801171353756,
            "fpr": 0.013157894736842105,
            "logloss": 0.65725952110912,
            "mae": 0.4729604547876015,
            "precision": 0.8811881188118812,
            "recall": 0.1869747899159664
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6777695893677784,
            "auditor_fn_violation": 0.052092279852477164,
            "auditor_fp_violation": 0.0078080833943868005,
            "ave_precision_score": 0.6341019601653294,
            "fpr": 0.015367727771679473,
            "logloss": 0.6504385570647828,
            "mae": 0.46782478958401014,
            "precision": 0.8842975206611571,
            "recall": 0.22384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.768960858740714,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.7009656100156357,
            "fpr": 0.14035087719298245,
            "logloss": 3.5036486588798703,
            "mae": 0.39939444548074615,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7771258294251076,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.712033666064601,
            "fpr": 0.13830954994511527,
            "logloss": 3.3472103870694663,
            "mae": 0.4015501206975868,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7466839428066103,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6785506887027543,
            "fpr": 0.14035087719298245,
            "logloss": 3.146442476582686,
            "mae": 0.40062459551712926,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7587184052487915,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6954878468729113,
            "fpr": 0.13830954994511527,
            "logloss": 2.8870055391887908,
            "mae": 0.401101191991247,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6153502915644888,
            "auditor_fn_violation": 0.005104673448326699,
            "auditor_fp_violation": 0.0053969499436665146,
            "ave_precision_score": 0.6117926372018228,
            "fpr": 0.375,
            "logloss": 1.6456471707840963,
            "mae": 0.47096068029350135,
            "precision": 0.5626598465473146,
            "recall": 0.9243697478991597
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6339000445762825,
            "auditor_fn_violation": 0.00850598680010472,
            "auditor_fp_violation": 0.013643865204087587,
            "ave_precision_score": 0.6284013950630392,
            "fpr": 0.36223929747530187,
            "logloss": 1.479996305615182,
            "mae": 0.47503776098478845,
            "precision": 0.5691906005221932,
            "recall": 0.9121338912133892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6927576609058905,
            "auditor_fn_violation": 0.009446870853604607,
            "auditor_fp_violation": 0.0001710123933687563,
            "ave_precision_score": 0.6933401434187771,
            "fpr": 0.33114035087719296,
            "logloss": 0.8327399825712876,
            "mae": 0.4633487676118057,
            "precision": 0.5273865414710485,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6537569072967726,
            "auditor_fn_violation": 0.008143150430121851,
            "auditor_fp_violation": 0.02177897546791462,
            "ave_precision_score": 0.6552722778644786,
            "fpr": 0.3238199780461032,
            "logloss": 1.0455713605071368,
            "mae": 0.4767126171266065,
            "precision": 0.5226537216828478,
            "recall": 0.6757322175732218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7443633255123319,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6523963157164848,
            "fpr": 0.4780701754385965,
            "logloss": 0.6480044247345254,
            "mae": 0.45456071263342573,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7134099912884708,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6221314327041964,
            "fpr": 0.47530186608122943,
            "logloss": 0.6669489548496523,
            "mae": 0.4652223914828965,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.744626773224319,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6642562838347544,
            "fpr": 0.14035087719298245,
            "logloss": 3.1422446841055947,
            "mae": 0.40113918613969235,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7604912992708894,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6848795194337547,
            "fpr": 0.13830954994511527,
            "logloss": 2.8809703852828976,
            "mae": 0.40162930929569196,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7443633255123319,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6523963157164848,
            "fpr": 0.4780701754385965,
            "logloss": 0.6479963712437183,
            "mae": 0.4545600743670213,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7134099912884708,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6221314327041964,
            "fpr": 0.47530186608122943,
            "logloss": 0.6669417692617794,
            "mae": 0.4652222972669926,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8326475664013027,
            "auditor_fn_violation": 0.011969261388766039,
            "auditor_fp_violation": 0.015109447931756,
            "ave_precision_score": 0.8330431535404594,
            "fpr": 0.15899122807017543,
            "logloss": 0.549714856507325,
            "mae": 0.3039871746514428,
            "precision": 0.7279549718574109,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8496792800540104,
            "auditor_fn_violation": 0.01027883286103367,
            "auditor_fp_violation": 0.018014363831335256,
            "ave_precision_score": 0.8500393678328624,
            "fpr": 0.145993413830955,
            "logloss": 0.5064750961805151,
            "mae": 0.2903213287796276,
            "precision": 0.7490566037735849,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8316412596348844,
            "auditor_fn_violation": 0.007012015332448774,
            "auditor_fp_violation": 0.014365041042974406,
            "ave_precision_score": 0.8320408879520096,
            "fpr": 0.1600877192982456,
            "logloss": 0.5517807241762928,
            "mae": 0.3046778366914575,
            "precision": 0.7265917602996255,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8494889796111358,
            "auditor_fn_violation": 0.009130616500328391,
            "auditor_fp_violation": 0.01608515881083904,
            "ave_precision_score": 0.8498455929652876,
            "fpr": 0.145993413830955,
            "logloss": 0.507694749112295,
            "mae": 0.2906969424187828,
            "precision": 0.75,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8317989727514497,
            "auditor_fn_violation": 0.012204223794781071,
            "auditor_fp_violation": 0.012851078384033486,
            "ave_precision_score": 0.832212312225843,
            "fpr": 0.18092105263157895,
            "logloss": 0.5664647855183901,
            "mae": 0.30834874600578477,
            "precision": 0.7125435540069687,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8363273953170987,
            "auditor_fn_violation": 0.001770549628207542,
            "auditor_fp_violation": 0.018189285180105614,
            "ave_precision_score": 0.8367469070350813,
            "fpr": 0.17233809001097694,
            "logloss": 0.5405037097540503,
            "mae": 0.30516895265717153,
            "precision": 0.7235915492957746,
            "recall": 0.8598326359832636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7689922275732886,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6997033374800077,
            "fpr": 0.14035087719298245,
            "logloss": 3.5039798668656723,
            "mae": 0.39928908642838923,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7764964644326218,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.7099456758985927,
            "fpr": 0.13830954994511527,
            "logloss": 3.347606863026789,
            "mae": 0.40141842266469047,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.817509334619801,
            "auditor_fn_violation": 0.013666979949874689,
            "auditor_fp_violation": 0.0025576412361178196,
            "ave_precision_score": 0.8179048046251978,
            "fpr": 0.049342105263157895,
            "logloss": 0.5701400207025679,
            "mae": 0.37140312668328224,
            "precision": 0.85,
            "recall": 0.5357142857142857
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8192435823724846,
            "auditor_fn_violation": 0.02038313683524014,
            "auditor_fp_violation": 0.0019342752045185482,
            "ave_precision_score": 0.8197149981562273,
            "fpr": 0.03732162458836443,
            "logloss": 0.5798751216782126,
            "mae": 0.375152645604,
            "precision": 0.8811188811188811,
            "recall": 0.5271966527196653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8376849094314205,
            "auditor_fn_violation": 0.008771929824561406,
            "auditor_fp_violation": 0.006830436182198623,
            "ave_precision_score": 0.8380398133703721,
            "fpr": 0.16228070175438597,
            "logloss": 0.7317347881979166,
            "mae": 0.2725072589099147,
            "precision": 0.725417439703154,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8452522507395807,
            "auditor_fn_violation": 0.013751039135806442,
            "auditor_fp_violation": 0.027122949427449475,
            "ave_precision_score": 0.8455444476962899,
            "fpr": 0.1525795828759605,
            "logloss": 0.6846953075344671,
            "mae": 0.2623377927490099,
            "precision": 0.7411545623836127,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7696134220411226,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.7008989684744004,
            "fpr": 0.14035087719298245,
            "logloss": 3.5038752693468105,
            "mae": 0.39932265073845263,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7768435155393052,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.710740823814412,
            "fpr": 0.13830954994511527,
            "logloss": 3.3474817604254876,
            "mae": 0.4014604043227781,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7819675617891376,
            "auditor_fn_violation": 0.017857142857142867,
            "auditor_fp_violation": 0.0073837115725092555,
            "ave_precision_score": 0.6544822594631969,
            "fpr": 0.03837719298245614,
            "logloss": 0.6213386500027005,
            "mae": 0.4429535800754501,
            "precision": 0.8471615720524017,
            "recall": 0.40756302521008403
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7877434913129961,
            "auditor_fn_violation": 0.02535261724437261,
            "auditor_fp_violation": 0.008502698605445884,
            "ave_precision_score": 0.6605027871974418,
            "fpr": 0.036223929747530186,
            "logloss": 0.6182323427611678,
            "mae": 0.4415920376123372,
            "precision": 0.8558951965065502,
            "recall": 0.4100418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.744626773224319,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6642562838347544,
            "fpr": 0.14035087719298245,
            "logloss": 3.1454620429705042,
            "mae": 0.4007450280743733,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7604912992708894,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6848795194337547,
            "fpr": 0.13830954994511527,
            "logloss": 2.8855632773559647,
            "mae": 0.4012218661418207,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8528236269351794,
            "auditor_fn_violation": 0.007938043638508037,
            "auditor_fp_violation": 0.010557500402382097,
            "ave_precision_score": 0.8531127477228954,
            "fpr": 0.17763157894736842,
            "logloss": 0.609310222815218,
            "mae": 0.2794016029249041,
            "precision": 0.7167832167832168,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8649439459564745,
            "auditor_fn_violation": 0.007860689205388353,
            "auditor_fp_violation": 0.026484106240636004,
            "ave_precision_score": 0.8652471421229745,
            "fpr": 0.16465422612513722,
            "logloss": 0.5273984953046511,
            "mae": 0.26390139532220186,
            "precision": 0.7391304347826086,
            "recall": 0.8891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8480140637493386,
            "auditor_fn_violation": 0.0075464396284829725,
            "auditor_fp_violation": 0.016344258007403856,
            "ave_precision_score": 0.8483426126000846,
            "fpr": 0.28399122807017546,
            "logloss": 1.0608534261301998,
            "mae": 0.32303787756823393,
            "precision": 0.6336633663366337,
            "recall": 0.9411764705882353
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8573263729764113,
            "auditor_fn_violation": 0.003573249314514832,
            "auditor_fp_violation": 0.029138347576325302,
            "ave_precision_score": 0.8576011801668366,
            "fpr": 0.278814489571899,
            "logloss": 0.9997082746452858,
            "mae": 0.31162843976918536,
            "precision": 0.6412429378531074,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7292606475765306,
            "auditor_fn_violation": 0.00683003464543713,
            "auditor_fp_violation": 0.008847376468694674,
            "ave_precision_score": 0.7293803902642537,
            "fpr": 0.04057017543859649,
            "logloss": 0.6159695408681494,
            "mae": 0.440083045087624,
            "precision": 0.8238095238095238,
            "recall": 0.3634453781512605
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7085708924723144,
            "auditor_fn_violation": 0.021659953428344418,
            "auditor_fp_violation": 0.007402468672600473,
            "ave_precision_score": 0.7087679592565657,
            "fpr": 0.042810098792535674,
            "logloss": 0.616293179829836,
            "mae": 0.44061543444901474,
            "precision": 0.8151658767772512,
            "recall": 0.3598326359832636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8266862901244543,
            "auditor_fn_violation": 0.011347302078726232,
            "auditor_fp_violation": 0.014274505070014489,
            "ave_precision_score": 0.82705465472876,
            "fpr": 0.16447368421052633,
            "logloss": 0.5519105957790598,
            "mae": 0.3089187028698481,
            "precision": 0.7247706422018348,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8353114859119442,
            "auditor_fn_violation": 0.01137882413458933,
            "auditor_fp_violation": 0.0163386680119555,
            "ave_precision_score": 0.8356886102622134,
            "fpr": 0.150384193194292,
            "logloss": 0.5260934746932779,
            "mae": 0.30565905613920824,
            "precision": 0.7415094339622641,
            "recall": 0.8221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6165461917154405,
            "auditor_fn_violation": 0.0048006044523072455,
            "auditor_fp_violation": 0.016115403186866252,
            "ave_precision_score": 0.6129425172200801,
            "fpr": 0.11732456140350878,
            "logloss": 1.6428837270425307,
            "mae": 0.4719588666027943,
            "precision": 0.7146666666666667,
            "recall": 0.5630252100840336
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.6387149807851176,
            "auditor_fn_violation": 0.003173670020989392,
            "auditor_fp_violation": 0.008028636399358122,
            "ave_precision_score": 0.633080976776085,
            "fpr": 0.10428100987925357,
            "logloss": 1.4772481668734982,
            "mae": 0.4759689926964146,
            "precision": 0.7293447293447294,
            "recall": 0.5355648535564853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8516668792250625,
            "auditor_fn_violation": 0.011153803626713843,
            "auditor_fp_violation": 0.01016517785288911,
            "ave_precision_score": 0.852884919297118,
            "fpr": 0.16557017543859648,
            "logloss": 0.5424828237278569,
            "mae": 0.3259022842140742,
            "precision": 0.7264492753623188,
            "recall": 0.842436974789916
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.864725917733649,
            "auditor_fn_violation": 0.0038947498955123148,
            "auditor_fp_violation": 0.006776300945842833,
            "ave_precision_score": 0.864962933343907,
            "fpr": 0.15806805708013172,
            "logloss": 0.4918951315950647,
            "mae": 0.3185137611043631,
            "precision": 0.7348066298342542,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8148720278764084,
            "auditor_fn_violation": 0.0074819401444788484,
            "auditor_fp_violation": 0.008958031546756806,
            "ave_precision_score": 0.8152420942061485,
            "fpr": 0.15899122807017543,
            "logloss": 0.8389126605716577,
            "mae": 0.26980827042316097,
            "precision": 0.7304832713754646,
            "recall": 0.8256302521008403
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8246256288970777,
            "auditor_fn_violation": 0.017448295817277443,
            "auditor_fp_violation": 0.028190223164149746,
            "ave_precision_score": 0.8250545613274355,
            "fpr": 0.14709110867178923,
            "logloss": 0.7938474451328439,
            "mae": 0.26061287882128176,
            "precision": 0.7490636704119851,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6829470579420958,
            "auditor_fn_violation": 0.002768870706177214,
            "auditor_fp_violation": 0.02298607757926928,
            "ave_precision_score": 0.6821762216162133,
            "fpr": 0.13157894736842105,
            "logloss": 1.2937594605297609,
            "mae": 0.3364284207292829,
            "precision": 0.7379912663755459,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.6908020582304657,
            "auditor_fn_violation": 0.006962784011316825,
            "auditor_fp_violation": 0.019847235355407233,
            "ave_precision_score": 0.6893592299555692,
            "fpr": 0.11855104281009879,
            "logloss": 1.1824903550617618,
            "mae": 0.3363934928315163,
            "precision": 0.762114537444934,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.851494517713584,
            "auditor_fn_violation": 0.011473997493734336,
            "auditor_fp_violation": 0.012939099468855627,
            "ave_precision_score": 0.8517662479622778,
            "fpr": 0.18311403508771928,
            "logloss": 0.5919474627967426,
            "mae": 0.28810016371952496,
            "precision": 0.7110726643598616,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8642528840511088,
            "auditor_fn_violation": 0.00711894143637274,
            "auditor_fp_violation": 0.024131540854275303,
            "ave_precision_score": 0.8645963401865884,
            "fpr": 0.16794731064763996,
            "logloss": 0.5095425273622748,
            "mae": 0.27105664518200184,
            "precision": 0.7375643224699828,
            "recall": 0.899581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8526256412138618,
            "auditor_fn_violation": 0.010506505233672416,
            "auditor_fp_violation": 0.010170207629164658,
            "ave_precision_score": 0.8529053556616616,
            "fpr": 0.17324561403508773,
            "logloss": 0.6024800392976722,
            "mae": 0.2782488296343446,
            "precision": 0.7213403880070547,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.864742394900259,
            "auditor_fn_violation": 0.0074725920754699655,
            "auditor_fp_violation": 0.02179672111199277,
            "ave_precision_score": 0.8650512700982445,
            "fpr": 0.15806805708013172,
            "logloss": 0.5191329054708935,
            "mae": 0.26253599292140556,
            "precision": 0.7464788732394366,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.814547897476632,
            "auditor_fn_violation": 0.009868421052631584,
            "auditor_fp_violation": 0.006267101239336876,
            "ave_precision_score": 0.8149587318873102,
            "fpr": 0.051535087719298246,
            "logloss": 0.5756033203951781,
            "mae": 0.37354126954941375,
            "precision": 0.8350877192982457,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8175433860330995,
            "auditor_fn_violation": 0.019763100000459284,
            "auditor_fp_violation": 0.003701234336300237,
            "ave_precision_score": 0.8180150578886473,
            "fpr": 0.03512623490669594,
            "logloss": 0.5841655690302009,
            "mae": 0.37637142807093954,
            "precision": 0.8832116788321168,
            "recall": 0.5062761506276151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8377716085399308,
            "auditor_fn_violation": 0.008771929824561406,
            "auditor_fp_violation": 0.006830436182198623,
            "ave_precision_score": 0.8381263204739158,
            "fpr": 0.16228070175438597,
            "logloss": 0.7311920318609828,
            "mae": 0.27249413794446875,
            "precision": 0.725417439703154,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8453172547678586,
            "auditor_fn_violation": 0.012931212654262872,
            "auditor_fp_violation": 0.027122949427449475,
            "ave_precision_score": 0.8456091125009138,
            "fpr": 0.1525795828759605,
            "logloss": 0.6841457400094139,
            "mae": 0.26232734281996056,
            "precision": 0.741635687732342,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8380384040706219,
            "auditor_fn_violation": 0.008771929824561406,
            "auditor_fp_violation": 0.006830436182198623,
            "ave_precision_score": 0.838393395099243,
            "fpr": 0.16228070175438597,
            "logloss": 0.7308757963814186,
            "mae": 0.27251336043637286,
            "precision": 0.725417439703154,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8452484066780539,
            "auditor_fn_violation": 0.013291752591524328,
            "auditor_fp_violation": 0.028573022057835594,
            "ave_precision_score": 0.8455409141740295,
            "fpr": 0.1525795828759605,
            "logloss": 0.6844695261850573,
            "mae": 0.2625020802035796,
            "precision": 0.7406716417910447,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5662195012285317,
            "auditor_fn_violation": 0.004819032876308418,
            "auditor_fp_violation": 0.0035711411556414115,
            "ave_precision_score": 0.565363988705367,
            "fpr": 0.44298245614035087,
            "logloss": 1.7298960822772058,
            "mae": 0.4773343750193976,
            "precision": 0.5324074074074074,
            "recall": 0.9663865546218487
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5885303064134898,
            "auditor_fn_violation": 0.0047628014642055036,
            "auditor_fp_violation": 0.010170789148792157,
            "ave_precision_score": 0.5868841932096243,
            "fpr": 0.41931942919868276,
            "logloss": 1.5756828904420754,
            "mae": 0.47114976838182016,
            "precision": 0.5463182897862233,
            "recall": 0.9623430962343096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5898514638266599,
            "auditor_fn_violation": 0.009596601798614187,
            "auditor_fp_violation": 0.01552440447448897,
            "ave_precision_score": 0.590176659192108,
            "fpr": 0.16337719298245615,
            "logloss": 1.66437435265417,
            "mae": 0.47244228597468974,
            "precision": 0.617948717948718,
            "recall": 0.5063025210084033
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.5991062284323495,
            "auditor_fn_violation": 0.00850828323282614,
            "auditor_fp_violation": 0.006652081437295772,
            "ave_precision_score": 0.5980986023658372,
            "fpr": 0.15148188803512624,
            "logloss": 1.512632888104405,
            "mae": 0.47500993342483344,
            "precision": 0.639686684073107,
            "recall": 0.5125523012552301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5875716608890225,
            "auditor_fn_violation": 0.02075501253132832,
            "auditor_fp_violation": 0.017682178496700472,
            "ave_precision_score": 0.5873792429942144,
            "fpr": 0.23355263157894737,
            "logloss": 1.660593343155779,
            "mae": 0.4720342318413028,
            "precision": 0.5895953757225434,
            "recall": 0.6428571428571429
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6022397155630456,
            "auditor_fn_violation": 0.013631624634293096,
            "auditor_fp_violation": 0.017626494753627094,
            "ave_precision_score": 0.6009831708016031,
            "fpr": 0.2305159165751921,
            "logloss": 1.4831709474604238,
            "mae": 0.47347109283102856,
            "precision": 0.58984375,
            "recall": 0.6317991631799164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.822429424820904,
            "auditor_fn_violation": 0.012955182072829132,
            "auditor_fp_violation": 0.014354981490423305,
            "ave_precision_score": 0.8228646334586177,
            "fpr": 0.18859649122807018,
            "logloss": 0.5770741040541857,
            "mae": 0.31355794630578376,
            "precision": 0.7003484320557491,
            "recall": 0.8445378151260504
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8224921750411367,
            "auditor_fn_violation": 0.009066316384128898,
            "auditor_fp_violation": 0.014637621272464086,
            "ave_precision_score": 0.8231446433688248,
            "fpr": 0.1756311745334797,
            "logloss": 0.556804656556753,
            "mae": 0.30902732258573,
            "precision": 0.7137745974955277,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8005313974494558,
            "auditor_fn_violation": 6.219593100398689e-05,
            "auditor_fp_violation": 0.018650410429744087,
            "ave_precision_score": 0.802037305159987,
            "fpr": 0.10416666666666667,
            "logloss": 0.5675561044942569,
            "mae": 0.3148299270797765,
            "precision": 0.7811059907834101,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7971583576770566,
            "auditor_fn_violation": 0.010301797188247782,
            "auditor_fp_violation": 0.016901458438434023,
            "ave_precision_score": 0.7980308965875805,
            "fpr": 0.09110867178924259,
            "logloss": 0.572628703384835,
            "mae": 0.3139467487014824,
            "precision": 0.8042452830188679,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8383295475641634,
            "auditor_fn_violation": 0.008771929824561406,
            "auditor_fp_violation": 0.006830436182198623,
            "ave_precision_score": 0.8386841876077913,
            "fpr": 0.16228070175438597,
            "logloss": 0.7262274187214962,
            "mae": 0.27226838059699754,
            "precision": 0.725417439703154,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8456284135035514,
            "auditor_fn_violation": 0.013291752591524328,
            "auditor_fp_violation": 0.02809895985174782,
            "ave_precision_score": 0.8459203505529493,
            "fpr": 0.15148188803512624,
            "logloss": 0.6798292324425481,
            "mae": 0.2623061562690124,
            "precision": 0.7420560747663552,
            "recall": 0.8305439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.856745873865101,
            "auditor_fn_violation": 0.01594980097302079,
            "auditor_fp_violation": 0.00822871398680187,
            "ave_precision_score": 0.8574277106913029,
            "fpr": 0.10635964912280702,
            "logloss": 0.5196204639529921,
            "mae": 0.3147513671387283,
            "precision": 0.7913978494623656,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.862993713651913,
            "auditor_fn_violation": 0.007881357099881048,
            "auditor_fp_violation": 0.003069996425520266,
            "ave_precision_score": 0.8632523947266835,
            "fpr": 0.09549945115257959,
            "logloss": 0.4777997588378236,
            "mae": 0.311037148706854,
            "precision": 0.8104575163398693,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8336521541807365,
            "auditor_fn_violation": 0.01421061845790948,
            "auditor_fp_violation": 0.009204490584258816,
            "ave_precision_score": 0.8340329929134344,
            "fpr": 0.18640350877192982,
            "logloss": 0.563670245310862,
            "mae": 0.3076880011240862,
            "precision": 0.7063903281519862,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8363053470443722,
            "auditor_fn_violation": 0.007174055821686597,
            "auditor_fp_violation": 0.01696990592273547,
            "ave_precision_score": 0.8367222697067163,
            "fpr": 0.17233809001097694,
            "logloss": 0.5403726513491476,
            "mae": 0.30535057011524547,
            "precision": 0.7221238938053097,
            "recall": 0.8535564853556485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7750314869416948,
            "auditor_fn_violation": 0.009336300309597525,
            "auditor_fp_violation": 0.021874497022372444,
            "ave_precision_score": 0.7765891537088708,
            "fpr": 0.1337719298245614,
            "logloss": 0.6452534198418975,
            "mae": 0.3161209210008576,
            "precision": 0.7505112474437627,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7719334510260775,
            "auditor_fn_violation": 0.011135402266119815,
            "auditor_fp_violation": 0.01591023746206869,
            "ave_precision_score": 0.7730280027572785,
            "fpr": 0.12733260153677278,
            "logloss": 0.6509539159375521,
            "mae": 0.31924908021992393,
            "precision": 0.7547568710359408,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8279180760849403,
            "auditor_fn_violation": 0.010064223057644109,
            "auditor_fp_violation": 0.017604216964429424,
            "ave_precision_score": 0.828368901096147,
            "fpr": 0.16337719298245615,
            "logloss": 0.5566802931354009,
            "mae": 0.30470634398382873,
            "precision": 0.7261029411764706,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8481039495104652,
            "auditor_fn_violation": 0.006544833256020104,
            "auditor_fp_violation": 0.018724189594461337,
            "ave_precision_score": 0.8484697639314457,
            "fpr": 0.14709110867178923,
            "logloss": 0.5092686408020866,
            "mae": 0.2900826362472561,
            "precision": 0.7485928705440901,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8005623938879457,
            "auditor_fn_violation": 0.002741228070175443,
            "auditor_fp_violation": 0.001468694672460969,
            "ave_precision_score": 0.6313667232597623,
            "fpr": 0.005482456140350877,
            "logloss": 0.6252747726999925,
            "mae": 0.4510750403921855,
            "precision": 0.9596774193548387,
            "recall": 0.25
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7635349584588963,
            "auditor_fn_violation": 0.006002875133767216,
            "auditor_fp_violation": 0.0019089242844069032,
            "ave_precision_score": 0.5990281587670822,
            "fpr": 0.009879253567508232,
            "logloss": 0.650650597824175,
            "mae": 0.465115363720874,
            "precision": 0.9108910891089109,
            "recall": 0.19246861924686193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7443633255123319,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6523963157164848,
            "fpr": 0.4780701754385965,
            "logloss": 0.6480045147439518,
            "mae": 0.4545607215218377,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7134099912884708,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6221314327041964,
            "fpr": 0.47530186608122943,
            "logloss": 0.6669490344035592,
            "mae": 0.46522239390372183,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.8448990141421198,
            "auditor_fn_violation": 0.00797950759251069,
            "auditor_fp_violation": 0.020139224207307266,
            "ave_precision_score": 0.8452668562381503,
            "fpr": 0.2807017543859649,
            "logloss": 1.0440445338573618,
            "mae": 0.3193564465836572,
            "precision": 0.6353276353276354,
            "recall": 0.9369747899159664
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8559055888005028,
            "auditor_fn_violation": 0.005474695607842777,
            "auditor_fp_violation": 0.030322235545539134,
            "ave_precision_score": 0.8561735651019089,
            "fpr": 0.2722283205268935,
            "logloss": 0.9842102795846747,
            "mae": 0.3087805836055033,
            "precision": 0.6441893830703013,
            "recall": 0.9393305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8517708156512183,
            "auditor_fn_violation": 0.00943074598260357,
            "auditor_fp_violation": 0.009616932238854018,
            "ave_precision_score": 0.8520204383090514,
            "fpr": 0.18092105263157895,
            "logloss": 0.6209283835558664,
            "mae": 0.28199913703106827,
            "precision": 0.7135416666666666,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8647169850911338,
            "auditor_fn_violation": 0.0056308530328986976,
            "auditor_fp_violation": 0.02548781508024834,
            "ave_precision_score": 0.8650252885546422,
            "fpr": 0.1690450054884742,
            "logloss": 0.529636046446085,
            "mae": 0.26320747936197386,
            "precision": 0.7344827586206897,
            "recall": 0.891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8517325165266385,
            "auditor_fn_violation": 0.012757076514816456,
            "auditor_fp_violation": 0.012416002736198294,
            "ave_precision_score": 0.8521081341684029,
            "fpr": 0.17434210526315788,
            "logloss": 0.5961516827004748,
            "mae": 0.27813277040286505,
            "precision": 0.7205623901581723,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8652832172605769,
            "auditor_fn_violation": 0.00581456765061154,
            "auditor_fp_violation": 0.023913522941315157,
            "ave_precision_score": 0.8655901961566188,
            "fpr": 0.15697036223929747,
            "logloss": 0.5166994052991268,
            "mae": 0.2634112382255667,
            "precision": 0.7469026548672566,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8279180760849403,
            "auditor_fn_violation": 0.010064223057644109,
            "auditor_fp_violation": 0.017604216964429424,
            "ave_precision_score": 0.828368901096147,
            "fpr": 0.16337719298245615,
            "logloss": 0.5566797812128279,
            "mae": 0.3047062830736921,
            "precision": 0.7261029411764706,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8481039495104652,
            "auditor_fn_violation": 0.006544833256020104,
            "auditor_fp_violation": 0.018724189594461337,
            "ave_precision_score": 0.8484697639314457,
            "fpr": 0.14709110867178923,
            "logloss": 0.5092683465043389,
            "mae": 0.2900826167373708,
            "precision": 0.7485928705440901,
            "recall": 0.8347280334728033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 15860,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5640231625490562,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5134203094025779,
            "fpr": 0.4780701754385965,
            "logloss": 0.6967826369792639,
            "mae": 0.5002769431785533,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5937930110275789,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5260847072884255,
            "fpr": 0.47530186608122943,
            "logloss": 0.6935773670914758,
            "mae": 0.4986168722551557,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8437943018758718,
            "auditor_fn_violation": 0.012167366946778712,
            "auditor_fp_violation": 0.005225937550297759,
            "ave_precision_score": 0.8441008718287935,
            "fpr": 0.14144736842105263,
            "logloss": 0.6797076881792687,
            "mae": 0.2692429779118309,
            "precision": 0.7475538160469667,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8510594251439213,
            "auditor_fn_violation": 0.014770655264112729,
            "auditor_fp_violation": 0.02651452734476998,
            "ave_precision_score": 0.8513307521979618,
            "fpr": 0.1394072447859495,
            "logloss": 0.6450983929816089,
            "mae": 0.2627444020103023,
            "precision": 0.7509803921568627,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8517827024094389,
            "auditor_fn_violation": 0.009149712516585586,
            "auditor_fp_violation": 0.010552470626106555,
            "ave_precision_score": 0.8530008557648149,
            "fpr": 0.16447368421052633,
            "logloss": 0.5420425940674399,
            "mae": 0.325753260837097,
            "precision": 0.7262773722627737,
            "recall": 0.8361344537815126
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8650619073958896,
            "auditor_fn_violation": 0.002810833651006526,
            "auditor_fp_violation": 0.012685600423867389,
            "ave_precision_score": 0.8653033758517436,
            "fpr": 0.15587266739846323,
            "logloss": 0.49047623892138636,
            "mae": 0.3178807952462715,
            "precision": 0.737037037037037,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 15860,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.8453881898062883,
            "auditor_fn_violation": 0.00827436237652956,
            "auditor_fp_violation": 0.019570859488169962,
            "ave_precision_score": 0.8456986558953301,
            "fpr": 0.2916666666666667,
            "logloss": 1.121276642939557,
            "mae": 0.328059687373848,
            "precision": 0.6290097629009763,
            "recall": 0.9474789915966386
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8534744099750061,
            "auditor_fn_violation": 0.0048041372531908945,
            "auditor_fp_violation": 0.029731559106937786,
            "ave_precision_score": 0.8537282450165118,
            "fpr": 0.287596048298573,
            "logloss": 1.0694208149056859,
            "mae": 0.3188487223995355,
            "precision": 0.6345885634588564,
            "recall": 0.9518828451882845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8253776002562638,
            "auditor_fn_violation": 0.011545407636738905,
            "auditor_fp_violation": 0.012773116851762434,
            "ave_precision_score": 0.8258220356696648,
            "fpr": 0.1962719298245614,
            "logloss": 0.5801079028316348,
            "mae": 0.31449350833549705,
            "precision": 0.6976351351351351,
            "recall": 0.8676470588235294
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8255095898313634,
            "auditor_fn_violation": 0.0051072663724170885,
            "auditor_fp_violation": 0.021495045162664185,
            "ave_precision_score": 0.8261086684975207,
            "fpr": 0.18441273326015367,
            "logloss": 0.5564959923122402,
            "mae": 0.31168616961832973,
            "precision": 0.7108433734939759,
            "recall": 0.8640167364016736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8469382922795514,
            "auditor_fn_violation": 0.0067609280554326995,
            "auditor_fp_violation": 0.01862526154836633,
            "ave_precision_score": 0.8472488863373143,
            "fpr": 0.28728070175438597,
            "logloss": 1.113734859444712,
            "mae": 0.3256837414916781,
            "precision": 0.6315049226441631,
            "recall": 0.9432773109243697
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8547828945606653,
            "auditor_fn_violation": 0.003959050011711806,
            "auditor_fp_violation": 0.028879768191186515,
            "ave_precision_score": 0.8550387364986296,
            "fpr": 0.2864983534577388,
            "logloss": 1.0618774688802568,
            "mae": 0.31732618705514,
            "precision": 0.634965034965035,
            "recall": 0.9497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8298554207951794,
            "auditor_fn_violation": 0.015341662980981868,
            "auditor_fp_violation": 0.013650812811846144,
            "ave_precision_score": 0.83029811987604,
            "fpr": 0.17982456140350878,
            "logloss": 0.5638476202821586,
            "mae": 0.30584239160599647,
            "precision": 0.7142857142857143,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8351608023917378,
            "auditor_fn_violation": 0.00841642592396971,
            "auditor_fp_violation": 0.018283083584518713,
            "ave_precision_score": 0.8356115536240573,
            "fpr": 0.1734357848518112,
            "logloss": 0.5389663076842314,
            "mae": 0.3043200880047302,
            "precision": 0.7193605683836589,
            "recall": 0.8472803347280334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8018409166215262,
            "auditor_fn_violation": 0.013793675364882801,
            "auditor_fp_violation": 0.02670811202317721,
            "ave_precision_score": 0.8023705078737868,
            "fpr": 0.1513157894736842,
            "logloss": 0.6058307611508364,
            "mae": 0.3205421352950636,
            "precision": 0.7228915662650602,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8256130351796627,
            "auditor_fn_violation": 0.015735157007105163,
            "auditor_fp_violation": 0.01716510800759514,
            "ave_precision_score": 0.8259768665573823,
            "fpr": 0.12403951701427003,
            "logloss": 0.5866233933018647,
            "mae": 0.3155419746597986,
            "precision": 0.7600849256900213,
            "recall": 0.7489539748953975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7727553806185912,
            "auditor_fn_violation": 0.004687730355300016,
            "auditor_fp_violation": 0.02259878480605183,
            "ave_precision_score": 0.7743601360321473,
            "fpr": 0.16447368421052633,
            "logloss": 0.635806435451451,
            "mae": 0.3335175052367326,
            "precision": 0.7109826589595376,
            "recall": 0.7752100840336135
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7813736509773537,
            "auditor_fn_violation": 0.004018757262468485,
            "auditor_fp_violation": 0.020815640503672087,
            "ave_precision_score": 0.7823449004157305,
            "fpr": 0.1437980241492865,
            "logloss": 0.6161321867393661,
            "mae": 0.3242031454418415,
            "precision": 0.7369477911646586,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7948012833821114,
            "auditor_fn_violation": 0.010960305174701458,
            "auditor_fp_violation": 0.00392071060679221,
            "ave_precision_score": 0.6462856173429448,
            "fpr": 0.01425438596491228,
            "logloss": 0.6181343661823617,
            "mae": 0.4418185964030655,
            "precision": 0.9182389937106918,
            "recall": 0.3067226890756303
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7995591348714612,
            "auditor_fn_violation": 0.02262904803677967,
            "auditor_fp_violation": 0.003371672374848845,
            "ave_precision_score": 0.6512524395038843,
            "fpr": 0.013172338090010977,
            "logloss": 0.6147934668575095,
            "mae": 0.44016128863513665,
            "precision": 0.9254658385093167,
            "recall": 0.3117154811715481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7748397511242645,
            "auditor_fn_violation": 0.012042975084770752,
            "auditor_fp_violation": 0.024007122163206183,
            "ave_precision_score": 0.7763947429028772,
            "fpr": 0.13815789473684212,
            "logloss": 0.6450328049844011,
            "mae": 0.31827780668664585,
            "precision": 0.7449392712550608,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7720518399409251,
            "auditor_fn_violation": 0.011661285359322829,
            "auditor_fp_violation": 0.020161586764791635,
            "ave_precision_score": 0.7731528729810286,
            "fpr": 0.12184412733260154,
            "logloss": 0.6481186496759402,
            "mae": 0.320893731799557,
            "precision": 0.7618025751072961,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.744626773224319,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6642562838347544,
            "fpr": 0.14035087719298245,
            "logloss": 3.145681842459624,
            "mae": 0.4007167714206796,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7604912992708894,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6848795194337547,
            "fpr": 0.13830954994511527,
            "logloss": 2.885876915055896,
            "mae": 0.4011925775905341,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8517274876548394,
            "auditor_fn_violation": 0.012757076514816456,
            "auditor_fp_violation": 0.012416002736198294,
            "ave_precision_score": 0.8521031021930907,
            "fpr": 0.17434210526315788,
            "logloss": 0.5961718851576325,
            "mae": 0.2781267861092057,
            "precision": 0.7205623901581723,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8652600347463149,
            "auditor_fn_violation": 0.00581456765061154,
            "auditor_fp_violation": 0.023913522941315157,
            "ave_precision_score": 0.8655670326914623,
            "fpr": 0.15697036223929747,
            "logloss": 0.516700797436066,
            "mae": 0.26340785340659756,
            "precision": 0.7469026548672566,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8337415284486508,
            "auditor_fn_violation": 0.015507518796992482,
            "auditor_fp_violation": 0.010004225012071467,
            "ave_precision_score": 0.8341215452223653,
            "fpr": 0.18640350877192982,
            "logloss": 0.5634505584026375,
            "mae": 0.30765285913290236,
            "precision": 0.7058823529411765,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8358980660080335,
            "auditor_fn_violation": 0.0042484005346095375,
            "auditor_fp_violation": 0.016630203593239426,
            "ave_precision_score": 0.8363175685057647,
            "fpr": 0.1712403951701427,
            "logloss": 0.540343900668673,
            "mae": 0.3054005303632255,
            "precision": 0.7238938053097345,
            "recall": 0.8556485355648535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 15860,
        "test": {
            "accuracy": 0.43530701754385964,
            "auc_prc": 0.42900077255788,
            "auditor_fn_violation": 0.013892728143889138,
            "auditor_fp_violation": 0.0014837840012876366,
            "ave_precision_score": 0.42808038802246806,
            "fpr": 0.34868421052631576,
            "logloss": 1.899894172981329,
            "mae": 0.543289203196764,
            "precision": 0.46733668341708545,
            "recall": 0.5861344537815126
        },
        "train": {
            "accuracy": 0.42041712403951703,
            "auc_prc": 0.42914527106443534,
            "auditor_fn_violation": 0.004987851870903735,
            "auditor_fp_violation": 0.029460304261743186,
            "ave_precision_score": 0.42743712317743093,
            "fpr": 0.3391877058177827,
            "logloss": 1.779337200499992,
            "mae": 0.5469721325486081,
            "precision": 0.45598591549295775,
            "recall": 0.5418410041841004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8235449365060752,
            "auditor_fn_violation": 0.014848702638950315,
            "auditor_fp_violation": 0.009511306937067438,
            "ave_precision_score": 0.8237805415118806,
            "fpr": 0.08442982456140351,
            "logloss": 0.5303803199417093,
            "mae": 0.3631146757847123,
            "precision": 0.7994791666666666,
            "recall": 0.6449579831932774
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8330570943687621,
            "auditor_fn_violation": 0.010956280513849791,
            "auditor_fp_violation": 0.006662221805340426,
            "ave_precision_score": 0.8329603278723777,
            "fpr": 0.07464324917672886,
            "logloss": 0.528115317551502,
            "mae": 0.3649384322014978,
            "precision": 0.820580474934037,
            "recall": 0.6506276150627615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8005313974494558,
            "auditor_fn_violation": 6.219593100398689e-05,
            "auditor_fp_violation": 0.018650410429744087,
            "ave_precision_score": 0.802037305159987,
            "fpr": 0.10416666666666667,
            "logloss": 0.5675557981590551,
            "mae": 0.31482979105702535,
            "precision": 0.7811059907834101,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7971583576770566,
            "auditor_fn_violation": 0.010301797188247782,
            "auditor_fp_violation": 0.016901458438434023,
            "ave_precision_score": 0.7980308965875805,
            "fpr": 0.09110867178924259,
            "logloss": 0.5726283920991788,
            "mae": 0.31394664715326615,
            "precision": 0.8042452830188679,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8370581930433245,
            "auditor_fn_violation": 0.006514447884416927,
            "auditor_fp_violation": 0.006639304683727674,
            "ave_precision_score": 0.8374132755333706,
            "fpr": 0.15789473684210525,
            "logloss": 0.737821266896491,
            "mae": 0.27171025621032713,
            "precision": 0.7283018867924528,
            "recall": 0.8109243697478992
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.844055376127853,
            "auditor_fn_violation": 0.012644158564086553,
            "auditor_fp_violation": 0.029072435184035007,
            "ave_precision_score": 0.8443518516533741,
            "fpr": 0.14818880351262348,
            "logloss": 0.6929144244184912,
            "mae": 0.2617695080055848,
            "precision": 0.7457627118644068,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8332827414862207,
            "auditor_fn_violation": 0.011835655314757484,
            "auditor_fp_violation": 0.012720304200869146,
            "ave_precision_score": 0.8336520087704704,
            "fpr": 0.1875,
            "logloss": 0.5662472467162073,
            "mae": 0.3080906351653475,
            "precision": 0.7071917808219178,
            "recall": 0.8676470588235294
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8362310420808108,
            "auditor_fn_violation": 0.005573442214863431,
            "auditor_fp_violation": 0.017616354385582435,
            "ave_precision_score": 0.8366474300532161,
            "fpr": 0.1734357848518112,
            "logloss": 0.5419821168427832,
            "mae": 0.30558545767400175,
            "precision": 0.7213403880070547,
            "recall": 0.8556485355648535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8002273456238026,
            "auditor_fn_violation": 0.0023496240601503793,
            "auditor_fp_violation": 0.018650410429744087,
            "ave_precision_score": 0.8016214945079735,
            "fpr": 0.10416666666666667,
            "logloss": 0.5682814520555327,
            "mae": 0.31482639652917116,
            "precision": 0.7816091954022989,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7968164584003367,
            "auditor_fn_violation": 0.010301797188247782,
            "auditor_fp_violation": 0.016901458438434023,
            "ave_precision_score": 0.7976895144875958,
            "fpr": 0.09110867178924259,
            "logloss": 0.5732159723242809,
            "mae": 0.3139560548473624,
            "precision": 0.8042452830188679,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.756386380254098,
            "auditor_fn_violation": 0.015668767507002797,
            "auditor_fp_violation": 0.02077800579430227,
            "ave_precision_score": 0.7578650642819498,
            "fpr": 0.11513157894736842,
            "logloss": 0.6674354700049063,
            "mae": 0.3212615594234968,
            "precision": 0.7651006711409396,
            "recall": 0.7184873949579832
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7490892848875585,
            "auditor_fn_violation": 0.015652485429134385,
            "auditor_fp_violation": 0.01979399842317277,
            "ave_precision_score": 0.749566774196159,
            "fpr": 0.11306256860592755,
            "logloss": 0.7080855652508525,
            "mae": 0.32711018691768734,
            "precision": 0.7669683257918553,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 15860,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.744626773224319,
            "auditor_fn_violation": 0.008062435500516002,
            "auditor_fp_violation": 0.0047179301464670845,
            "ave_precision_score": 0.6642562838347544,
            "fpr": 0.14035087719298245,
            "logloss": 3.1462231214205,
            "mae": 0.4006510803051162,
            "precision": 0.7023255813953488,
            "recall": 0.634453781512605
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7604912992708894,
            "auditor_fn_violation": 0.021131773902419985,
            "auditor_fp_violation": 0.027259844396052356,
            "ave_precision_score": 0.6848795194337547,
            "fpr": 0.13830954994511527,
            "logloss": 2.8866493997804348,
            "mae": 0.4011244456867486,
            "precision": 0.7142857142857143,
            "recall": 0.6589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8509608519471024,
            "auditor_fn_violation": 0.011932404540763678,
            "auditor_fp_violation": 0.015179864799613722,
            "ave_precision_score": 0.852178767424785,
            "fpr": 0.16666666666666666,
            "logloss": 0.5443228921977497,
            "mae": 0.32629514296326695,
            "precision": 0.7246376811594203,
            "recall": 0.8403361344537815
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8647785047882172,
            "auditor_fn_violation": 0.00445967234497931,
            "auditor_fp_violation": 0.00647716008852541,
            "ave_precision_score": 0.8650123061354766,
            "fpr": 0.14928649835345773,
            "logloss": 0.4924233784201565,
            "mae": 0.31715198099163855,
            "precision": 0.7453183520599251,
            "recall": 0.8326359832635983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.771695281632828,
            "auditor_fn_violation": 0.011287409700722398,
            "auditor_fp_violation": 0.02300368179623371,
            "ave_precision_score": 0.773326104334464,
            "fpr": 0.16337719298245615,
            "logloss": 0.6358456475733586,
            "mae": 0.3324932447617726,
            "precision": 0.7095516569200779,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7792779622402453,
            "auditor_fn_violation": 0.004836287311290643,
            "auditor_fp_violation": 0.022785406996346937,
            "ave_precision_score": 0.7802722974340588,
            "fpr": 0.14270032930845225,
            "logloss": 0.6202979686736633,
            "mae": 0.323893646680613,
            "precision": 0.7379032258064516,
            "recall": 0.7656903765690377
        }
    }
]