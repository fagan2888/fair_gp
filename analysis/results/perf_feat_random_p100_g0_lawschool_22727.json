[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8113297502082913,
            "auditor_fn_violation": 0.02693455630778191,
            "auditor_fp_violation": 0.026346389228886172,
            "ave_precision_score": 0.8117316407304164,
            "fpr": 0.14692982456140352,
            "logloss": 1.1468777611530343,
            "mae": 0.2864852698572056,
            "precision": 0.7309236947791165,
            "recall": 0.7551867219917012
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8295666312902655,
            "auditor_fn_violation": 0.019144542224041383,
            "auditor_fp_violation": 0.03374849035703838,
            "ave_precision_score": 0.8300707967021403,
            "fpr": 0.13391877058177826,
            "logloss": 0.8922875606930726,
            "mae": 0.25784769395911866,
            "precision": 0.7479338842975206,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8331078792621887,
            "auditor_fn_violation": 0.029218533886583686,
            "auditor_fp_violation": 0.023898408812729498,
            "ave_precision_score": 0.8322827957952698,
            "fpr": 0.11074561403508772,
            "logloss": 0.5509736385202307,
            "mae": 0.33193688811284994,
            "precision": 0.765661252900232,
            "recall": 0.6846473029045643
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8351852192307186,
            "auditor_fn_violation": 0.02268646858546205,
            "auditor_fp_violation": 0.021331286303318837,
            "ave_precision_score": 0.8340568558155143,
            "fpr": 0.10757409440175632,
            "logloss": 0.5155541807103151,
            "mae": 0.3219708154319441,
            "precision": 0.7777777777777778,
            "recall": 0.7266949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.7695819829635135,
            "auditor_fn_violation": 0.01525305743612145,
            "auditor_fp_violation": 0.005385556915544675,
            "ave_precision_score": 0.7709324520136862,
            "fpr": 0.02850877192982456,
            "logloss": 2.4893785642222266,
            "mae": 0.37586426099490367,
            "precision": 0.8779342723004695,
            "recall": 0.3879668049792531
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7919170209103958,
            "auditor_fn_violation": 0.0008442017525907506,
            "auditor_fp_violation": 0.006428641083792373,
            "ave_precision_score": 0.7922088763059272,
            "fpr": 0.019758507135016465,
            "logloss": 2.151269374890275,
            "mae": 0.3638728697069266,
            "precision": 0.9067357512953368,
            "recall": 0.3707627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8126177574454784,
            "auditor_fn_violation": 0.0016765851350367621,
            "auditor_fp_violation": 0.011028661770705838,
            "ave_precision_score": 0.7867161832688261,
            "fpr": 0.13706140350877194,
            "logloss": 0.554210912707775,
            "mae": 0.3251648625653041,
            "precision": 0.7529644268774703,
            "recall": 0.7904564315352697
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8276469341370998,
            "auditor_fn_violation": 0.0036651844685482524,
            "auditor_fp_violation": 0.010939441750910793,
            "ave_precision_score": 0.8045924141469489,
            "fpr": 0.12843029637760703,
            "logloss": 0.5186794934204156,
            "mae": 0.31302916128535957,
            "precision": 0.7678571428571429,
            "recall": 0.8199152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 22727,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7062206963101934,
            "auditor_fn_violation": 0.0005527953701681612,
            "auditor_fp_violation": 0.008593431252549978,
            "ave_precision_score": 0.7455370625733868,
            "fpr": 0.08771929824561403,
            "logloss": 0.5409480037250449,
            "mae": 0.35944399706561836,
            "precision": 0.814385150812065,
            "recall": 0.7282157676348547
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.6855290300626509,
            "auditor_fn_violation": 0.005841969152914478,
            "auditor_fp_violation": 0.005818532789570153,
            "ave_precision_score": 0.7209717796338712,
            "fpr": 0.09659714599341383,
            "logloss": 0.5530613705015962,
            "mae": 0.36416655988253566,
            "precision": 0.794392523364486,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7701742187793926,
            "auditor_fn_violation": 0.026302140205285,
            "auditor_fp_violation": 0.015248878008975925,
            "ave_precision_score": 0.7431267607472416,
            "fpr": 0.13157894736842105,
            "logloss": 3.2680160987299067,
            "mae": 0.29116323240919056,
            "precision": 0.744136460554371,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8081524385592529,
            "auditor_fn_violation": 0.01751660496009228,
            "auditor_fp_violation": 0.028477554765970962,
            "ave_precision_score": 0.7843875457742822,
            "fpr": 0.13062568605927552,
            "logloss": 2.4666473160504463,
            "mae": 0.2644902632573778,
            "precision": 0.7468085106382979,
            "recall": 0.7436440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7798899319713356,
            "auditor_fn_violation": 0.01798063623789765,
            "auditor_fp_violation": 0.021616177070583435,
            "ave_precision_score": 0.7721852277694676,
            "fpr": 0.20942982456140352,
            "logloss": 1.4777488934300809,
            "mae": 0.30317108496152895,
            "precision": 0.676818950930626,
            "recall": 0.8298755186721992
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8074341043852746,
            "auditor_fn_violation": 0.009123425552103295,
            "auditor_fp_violation": 0.02563705057647733,
            "ave_precision_score": 0.7995216090982067,
            "fpr": 0.1964873765093304,
            "logloss": 1.2994373192137363,
            "mae": 0.27406610365841755,
            "precision": 0.6986531986531986,
            "recall": 0.8792372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8426990619899475,
            "auditor_fn_violation": 0.03892771347455776,
            "auditor_fp_violation": 0.02695328437372501,
            "ave_precision_score": 0.8196747368029759,
            "fpr": 0.13157894736842105,
            "logloss": 0.5285159525474232,
            "mae": 0.32731412494914575,
            "precision": 0.7463002114164905,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8588681039845661,
            "auditor_fn_violation": 0.031093601741427744,
            "auditor_fp_violation": 0.03634645149514039,
            "ave_precision_score": 0.8383140382163836,
            "fpr": 0.13062568605927552,
            "logloss": 0.49097034130820394,
            "mae": 0.31549784976224343,
            "precision": 0.7586206896551724,
            "recall": 0.7923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8262504317938505,
            "auditor_fn_violation": 0.007033922981728181,
            "auditor_fp_violation": 0.016307119543043664,
            "ave_precision_score": 0.8265645852973493,
            "fpr": 0.2730263157894737,
            "logloss": 2.3043775586640534,
            "mae": 0.3279648039956968,
            "precision": 0.6343612334801763,
            "recall": 0.8962655601659751
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.845920010860766,
            "auditor_fn_violation": 0.003397737632328045,
            "auditor_fp_violation": 0.028087485528681354,
            "ave_precision_score": 0.846233374063966,
            "fpr": 0.2491767288693743,
            "logloss": 1.896925396948688,
            "mae": 0.29669633055179406,
            "precision": 0.656060606060606,
            "recall": 0.9173728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6991983114120603,
            "auditor_fn_violation": 0.02965076071922545,
            "auditor_fp_violation": 0.024365055079559366,
            "ave_precision_score": 0.7034707524950032,
            "fpr": 0.13706140350877194,
            "logloss": 4.798320296200588,
            "mae": 0.3612889385584614,
            "precision": 0.6943765281173594,
            "recall": 0.5892116182572614
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.746184442910276,
            "auditor_fn_violation": 0.02293065917505443,
            "auditor_fp_violation": 0.031478087360506495,
            "ave_precision_score": 0.7461707108809965,
            "fpr": 0.12733260153677278,
            "logloss": 3.81994352152519,
            "mae": 0.32007398501364176,
            "precision": 0.7211538461538461,
            "recall": 0.635593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.711668749264248,
            "auditor_fn_violation": 0.10268572104535198,
            "auditor_fp_violation": 0.10091289269685845,
            "ave_precision_score": 0.549152794247062,
            "fpr": 0.30043859649122806,
            "logloss": 0.6902749352358151,
            "mae": 0.4928768609503382,
            "precision": 0.5573505654281099,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7292876234884791,
            "auditor_fn_violation": 0.07959682970845969,
            "auditor_fp_violation": 0.10591379969944666,
            "ave_precision_score": 0.5579087222184236,
            "fpr": 0.300768386388584,
            "logloss": 0.68008232048133,
            "mae": 0.4879007090852237,
            "precision": 0.5698587127158555,
            "recall": 0.7690677966101694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.751691375884542,
            "auditor_fn_violation": 0.034216440998762476,
            "auditor_fp_violation": 0.003343023255813955,
            "ave_precision_score": 0.7489902793310331,
            "fpr": 0.0581140350877193,
            "logloss": 0.6367614086965638,
            "mae": 0.40459840521298085,
            "precision": 0.8133802816901409,
            "recall": 0.47925311203319504
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7163482092092567,
            "auditor_fn_violation": 0.0320285028558671,
            "auditor_fp_violation": 0.005533482193089273,
            "ave_precision_score": 0.7171235932805304,
            "fpr": 0.06695938529088913,
            "logloss": 0.6492025746500923,
            "mae": 0.41184634146506516,
            "precision": 0.7689393939393939,
            "recall": 0.4300847457627119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6299180649864009,
            "auditor_fn_violation": 0.00175620586736551,
            "auditor_fp_violation": 0.006323949408404733,
            "ave_precision_score": 0.5864130698916168,
            "fpr": 0.44846491228070173,
            "logloss": 5.600505806577303,
            "mae": 0.45949806943991595,
            "precision": 0.534698521046644,
            "recall": 0.975103734439834
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6364141262435705,
            "auditor_fn_violation": 0.0036093694766414263,
            "auditor_fp_violation": 0.004795851263599312,
            "ave_precision_score": 0.600698253841141,
            "fpr": 0.4566410537870472,
            "logloss": 4.919640380563652,
            "mae": 0.46902573913434753,
            "precision": 0.5240274599542334,
            "recall": 0.9703389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 22727,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8023537837726862,
            "auditor_fn_violation": 0.004790893208124048,
            "auditor_fp_violation": 0.009108527131782946,
            "ave_precision_score": 0.7500920690362293,
            "fpr": 0.07785087719298246,
            "logloss": 0.5424338032852338,
            "mae": 0.35506696899405177,
            "precision": 0.8233830845771144,
            "recall": 0.6867219917012448
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7998901446147002,
            "auditor_fn_violation": 0.011869988278851704,
            "auditor_fp_violation": 0.001260223689704928,
            "ave_precision_score": 0.7444902036978718,
            "fpr": 0.07464324917672886,
            "logloss": 0.5422000870112573,
            "mae": 0.3564271649793527,
            "precision": 0.8247422680412371,
            "recall": 0.6779661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6432023992467006,
            "auditor_fn_violation": 0.018462910388003212,
            "auditor_fp_violation": 0.025989392084863325,
            "ave_precision_score": 0.6388339102826316,
            "fpr": 0.13925438596491227,
            "logloss": 0.7005689426062948,
            "mae": 0.4640198314006914,
            "precision": 0.6649076517150396,
            "recall": 0.5228215767634855
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.654771465614937,
            "auditor_fn_violation": 0.03070057117341719,
            "auditor_fp_violation": 0.017665635650327933,
            "ave_precision_score": 0.6341777013595615,
            "fpr": 0.11964873765093303,
            "logloss": 0.6960446933606934,
            "mae": 0.4587179215299835,
            "precision": 0.6867816091954023,
            "recall": 0.5063559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7910875669914808,
            "auditor_fn_violation": 0.01278936449006334,
            "auditor_fp_violation": 0.00489596083231334,
            "ave_precision_score": 0.7867894144971431,
            "fpr": 0.046052631578947366,
            "logloss": 2.1182390407183305,
            "mae": 0.3545109387759275,
            "precision": 0.8653846153846154,
            "recall": 0.5601659751037344
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7658818841528023,
            "auditor_fn_violation": 0.016614262590931926,
            "auditor_fp_violation": 0.004300763385500928,
            "ave_precision_score": 0.7626219779355937,
            "fpr": 0.050493962678375415,
            "logloss": 2.186710303916314,
            "mae": 0.3628415400258228,
            "precision": 0.8413793103448276,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7725367329523216,
            "auditor_fn_violation": 0.006901980053869115,
            "auditor_fp_violation": 0.01773000815993473,
            "ave_precision_score": 0.7100958346677542,
            "fpr": 0.21162280701754385,
            "logloss": 0.5906325240790409,
            "mae": 0.37994559047122795,
            "precision": 0.6745362563237775,
            "recall": 0.8298755186721992
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7852748809697301,
            "auditor_fn_violation": 0.002455859643900353,
            "auditor_fp_violation": 0.02112124902170135,
            "ave_precision_score": 0.7218680333315154,
            "fpr": 0.2261251372118551,
            "logloss": 0.5623598142938152,
            "mae": 0.3721965056579278,
            "precision": 0.6633986928104575,
            "recall": 0.8601694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8343886789407218,
            "auditor_fn_violation": 0.005505204921016234,
            "auditor_fp_violation": 0.008863729090167286,
            "ave_precision_score": 0.7258463337669449,
            "fpr": 0.08552631578947369,
            "logloss": 0.551041209702702,
            "mae": 0.3635376351313633,
            "precision": 0.8115942028985508,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8362061103716936,
            "auditor_fn_violation": 0.010195538521646922,
            "auditor_fp_violation": 0.006496153067169423,
            "ave_precision_score": 0.7274284531407226,
            "fpr": 0.0801317233809001,
            "logloss": 0.5416326694627557,
            "mae": 0.35973835779859,
            "precision": 0.818407960199005,
            "recall": 0.6970338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6849407007017113,
            "auditor_fn_violation": 0.017411916721263746,
            "auditor_fp_violation": 0.01384893920848634,
            "ave_precision_score": 0.6857247350241119,
            "fpr": 0.13486842105263158,
            "logloss": 0.6273506165024049,
            "mae": 0.3874609150368263,
            "precision": 0.7278761061946902,
            "recall": 0.6825726141078838
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7354608346183142,
            "auditor_fn_violation": 0.008753651230720572,
            "auditor_fp_violation": 0.008854071597708598,
            "ave_precision_score": 0.7335797201325617,
            "fpr": 0.12294182217343579,
            "logloss": 0.5737221502971271,
            "mae": 0.3692083766726873,
            "precision": 0.7437070938215103,
            "recall": 0.6885593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6889357784023455,
            "auditor_fn_violation": 0.040561075926330355,
            "auditor_fp_violation": 0.00785903712770298,
            "ave_precision_score": 0.6753715948544124,
            "fpr": 0.039473684210526314,
            "logloss": 0.6515614377997041,
            "mae": 0.4340682400374167,
            "precision": 0.788235294117647,
            "recall": 0.27800829875518673
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7295805727295456,
            "auditor_fn_violation": 0.03406342443580346,
            "auditor_fp_violation": 0.010956944857712246,
            "ave_precision_score": 0.7086559775034603,
            "fpr": 0.03402854006586169,
            "logloss": 0.6187995017246092,
            "mae": 0.41826679131463906,
            "precision": 0.8197674418604651,
            "recall": 0.298728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8139351570591086,
            "auditor_fn_violation": 0.007507097619567594,
            "auditor_fp_violation": 0.021317829457364348,
            "ave_precision_score": 0.7817544738866502,
            "fpr": 0.2149122807017544,
            "logloss": 0.5827928188516273,
            "mae": 0.3706290214036575,
            "precision": 0.6694772344013491,
            "recall": 0.8236514522821576
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7870497040865118,
            "auditor_fn_violation": 0.0057768516623565086,
            "auditor_fp_violation": 0.027522385223377157,
            "ave_precision_score": 0.7842682939463479,
            "fpr": 0.21185510428100987,
            "logloss": 0.5687425603512473,
            "mae": 0.3671083048100529,
            "precision": 0.6689536878216124,
            "recall": 0.826271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8145008909561541,
            "auditor_fn_violation": 0.002097437577345873,
            "auditor_fp_violation": 0.009740922072623422,
            "ave_precision_score": 0.7959598949699848,
            "fpr": 0.07675438596491228,
            "logloss": 0.543458453552398,
            "mae": 0.38217476076903967,
            "precision": 0.8271604938271605,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8096023433720345,
            "auditor_fn_violation": 0.005786154161007655,
            "auditor_fp_violation": 0.010269322804797856,
            "ave_precision_score": 0.7859442785884319,
            "fpr": 0.07683863885839737,
            "logloss": 0.5536317123055794,
            "mae": 0.3882395500311082,
            "precision": 0.8167539267015707,
            "recall": 0.6610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5722250902459073,
            "auditor_fn_violation": 0.008107665429133002,
            "auditor_fp_violation": 0.005972052223582223,
            "ave_precision_score": 0.5599887248183659,
            "fpr": 0.3607456140350877,
            "logloss": 0.6838629092257252,
            "mae": 0.48646635220696527,
            "precision": 0.5480769230769231,
            "recall": 0.8278008298755186
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5651313413727886,
            "auditor_fn_violation": 0.007637351392584053,
            "auditor_fp_violation": 0.009759232263726802,
            "ave_precision_score": 0.5496445806991997,
            "fpr": 0.3765093304061471,
            "logloss": 0.6800197858170567,
            "mae": 0.48597577618257143,
            "precision": 0.526896551724138,
            "recall": 0.809322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.599661060004046,
            "auditor_fn_violation": 0.017375518672199174,
            "auditor_fp_violation": 0.008634230926152592,
            "ave_precision_score": 0.5958355194835977,
            "fpr": 0.04276315789473684,
            "logloss": 4.40834540483322,
            "mae": 0.4738618271835089,
            "precision": 0.7364864864864865,
            "recall": 0.22614107883817428
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5952764220609801,
            "auditor_fn_violation": 0.014381662914658876,
            "auditor_fp_violation": 0.009734227825439016,
            "ave_precision_score": 0.5912537956063545,
            "fpr": 0.054884742041712405,
            "logloss": 4.187067737278874,
            "mae": 0.46824918742800886,
            "precision": 0.6987951807228916,
            "recall": 0.2457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8325981343490202,
            "auditor_fn_violation": 0.007962073232874721,
            "auditor_fp_violation": 0.003983068135454917,
            "ave_precision_score": 0.8330192896859558,
            "fpr": 0.03728070175438596,
            "logloss": 0.8974572787451341,
            "mae": 0.36748739517374857,
            "precision": 0.8697318007662835,
            "recall": 0.470954356846473
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8385208700579826,
            "auditor_fn_violation": 0.011181603378667524,
            "auditor_fp_violation": 0.00448579622883062,
            "ave_precision_score": 0.8387667564036454,
            "fpr": 0.036223929747530186,
            "logloss": 0.8834414134058891,
            "mae": 0.36583372969204486,
            "precision": 0.8663967611336032,
            "recall": 0.4533898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6910512236861593,
            "auditor_fn_violation": 0.04020164519181773,
            "auditor_fp_violation": 0.009585373317013465,
            "ave_precision_score": 0.6927341073551885,
            "fpr": 0.06907894736842106,
            "logloss": 0.7836162990504854,
            "mae": 0.42210518407065184,
            "precision": 0.7717391304347826,
            "recall": 0.44190871369294604
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7195720403375143,
            "auditor_fn_violation": 0.03692394277102832,
            "auditor_fp_violation": 0.013712433957027375,
            "ave_precision_score": 0.7121918254935131,
            "fpr": 0.07354555433589462,
            "logloss": 0.7466871489781407,
            "mae": 0.4041979859851947,
            "precision": 0.7721088435374149,
            "recall": 0.4809322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7551326184896533,
            "auditor_fn_violation": 0.02365418213583753,
            "auditor_fp_violation": 0.017951856385148922,
            "ave_precision_score": 0.7555461527537556,
            "fpr": 0.15350877192982457,
            "logloss": 1.5000969452198847,
            "mae": 0.3539617954737716,
            "precision": 0.6902654867256637,
            "recall": 0.6473029045643154
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7597096932621755,
            "auditor_fn_violation": 0.016591006344304084,
            "auditor_fp_violation": 0.02607712869034254,
            "ave_precision_score": 0.7601324945844925,
            "fpr": 0.15148188803512624,
            "logloss": 1.1759071938651906,
            "mae": 0.3297393303624275,
            "precision": 0.7032258064516129,
            "recall": 0.6927966101694916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 22727,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7027427400487735,
            "auditor_fn_violation": 0.0055962000436776665,
            "auditor_fp_violation": 0.009276825785393718,
            "ave_precision_score": 0.7041362808493375,
            "fpr": 0.08552631578947369,
            "logloss": 0.6476040407032575,
            "mae": 0.4571900642231891,
            "precision": 0.7364864864864865,
            "recall": 0.45228215767634855
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6915689561223253,
            "auditor_fn_violation": 0.007479208915514728,
            "auditor_fp_violation": 0.004728339280222242,
            "ave_precision_score": 0.6927057724681178,
            "fpr": 0.0845225027442371,
            "logloss": 0.6459881060455622,
            "mae": 0.4573356239605617,
            "precision": 0.7259786476868327,
            "recall": 0.4322033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8412053728880587,
            "auditor_fn_violation": 0.0037717478343160865,
            "auditor_fp_violation": 0.008129334965320279,
            "ave_precision_score": 0.8413426620911129,
            "fpr": 0.09100877192982457,
            "logloss": 0.505862467201675,
            "mae": 0.3242775784323417,
            "precision": 0.8117913832199547,
            "recall": 0.7427385892116183
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.849732559381298,
            "auditor_fn_violation": 0.007651305140560754,
            "auditor_fp_violation": 0.004275758947213136,
            "ave_precision_score": 0.8494082595631749,
            "fpr": 0.10098792535675083,
            "logloss": 0.4975251486293613,
            "mae": 0.32713569618524363,
            "precision": 0.7880184331797235,
            "recall": 0.7245762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7994524202568843,
            "auditor_fn_violation": 0.03983766470117202,
            "auditor_fp_violation": 0.01578947368421053,
            "ave_precision_score": 0.795622482877185,
            "fpr": 0.09429824561403509,
            "logloss": 2.8767798511446387,
            "mae": 0.30179726097626114,
            "precision": 0.7828282828282829,
            "recall": 0.6431535269709544
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8182253706638307,
            "auditor_fn_violation": 0.03146105043814769,
            "auditor_fp_violation": 0.020193584361224124,
            "ave_precision_score": 0.8127444031921554,
            "fpr": 0.0845225027442371,
            "logloss": 2.6612603428964827,
            "mae": 0.26716359478519586,
            "precision": 0.8098765432098766,
            "recall": 0.6949152542372882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7761787718178306,
            "auditor_fn_violation": 0.016913718424692442,
            "auditor_fp_violation": 0.0196858425132599,
            "ave_precision_score": 0.6429592873821963,
            "fpr": 0.16776315789473684,
            "logloss": 0.629682481153033,
            "mae": 0.43347506460390595,
            "precision": 0.6902834008097166,
            "recall": 0.7074688796680498
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7774449372273806,
            "auditor_fn_violation": 0.008558298759046682,
            "auditor_fp_violation": 0.027099810216313403,
            "ave_precision_score": 0.6416812245424294,
            "fpr": 0.16794731064763996,
            "logloss": 0.6216733525112214,
            "mae": 0.4296871333431072,
            "precision": 0.6896551724137931,
            "recall": 0.7203389830508474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8452897682925824,
            "auditor_fn_violation": 0.03513321685957633,
            "auditor_fp_violation": 0.03384077927376582,
            "ave_precision_score": 0.8458613624858802,
            "fpr": 0.16776315789473684,
            "logloss": 0.5622210264917975,
            "mae": 0.31269247537951134,
            "precision": 0.7197802197802198,
            "recall": 0.8153526970954357
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8598530030015119,
            "auditor_fn_violation": 0.0253074475804201,
            "auditor_fp_violation": 0.030815469745879898,
            "ave_precision_score": 0.8600826536806752,
            "fpr": 0.14928649835345773,
            "logloss": 0.5092011233957477,
            "mae": 0.30293050003357513,
            "precision": 0.7433962264150943,
            "recall": 0.8347457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7313315497972692,
            "auditor_fn_violation": 0.003692127101987334,
            "auditor_fp_violation": 0.01509587923296614,
            "ave_precision_score": 0.7324396948655929,
            "fpr": 0.19736842105263158,
            "logloss": 0.6211963183117288,
            "mae": 0.3812500015227941,
            "precision": 0.6814159292035398,
            "recall": 0.7987551867219918
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7144494505279286,
            "auditor_fn_violation": 0.006716404026121415,
            "auditor_fp_violation": 0.015625273486043784,
            "ave_precision_score": 0.7153251055041719,
            "fpr": 0.19758507135016465,
            "logloss": 0.6329002269711886,
            "mae": 0.3862722789057,
            "precision": 0.6715328467153284,
            "recall": 0.7796610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7022057978288747,
            "auditor_fn_violation": 0.007784632743684954,
            "auditor_fp_violation": 0.008404732762137903,
            "ave_precision_score": 0.6904548645635128,
            "fpr": 0.02631578947368421,
            "logloss": 0.6752964938896306,
            "mae": 0.48507510150145544,
            "precision": 0.7777777777777778,
            "recall": 0.17427385892116182
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7031062458454734,
            "auditor_fn_violation": 0.014083982957822486,
            "auditor_fp_violation": 0.0005676007491329722,
            "ave_precision_score": 0.6911624125975255,
            "fpr": 0.025246981339187707,
            "logloss": 0.6720541097737943,
            "mae": 0.48383583424512694,
            "precision": 0.7766990291262136,
            "recall": 0.1694915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.759851814421635,
            "auditor_fn_violation": 0.0031211327072868896,
            "auditor_fp_violation": 0.0018104855161158835,
            "ave_precision_score": 0.5285006317685018,
            "fpr": 0.46271929824561403,
            "logloss": 0.6948041798241028,
            "mae": 0.4991154199825567,
            "precision": 0.5284916201117319,
            "recall": 0.9813278008298755
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7579802532039646,
            "auditor_fn_violation": 0.0001186068578020057,
            "auditor_fp_violation": 0.0016002840504189687,
            "ave_precision_score": 0.523031372996507,
            "fpr": 0.4654226125137212,
            "logloss": 0.6899255137033343,
            "mae": 0.49638256577838263,
            "precision": 0.5230596175478065,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8314008433124667,
            "auditor_fn_violation": 0.03853188469098056,
            "auditor_fp_violation": 0.03158914728682171,
            "ave_precision_score": 0.8318902184817034,
            "fpr": 0.14473684210526316,
            "logloss": 0.8068684612268693,
            "mae": 0.2960001402398877,
            "precision": 0.7349397590361446,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8487115904787015,
            "auditor_fn_violation": 0.030809875532568056,
            "auditor_fp_violation": 0.04004710836173422,
            "ave_precision_score": 0.8489316345305502,
            "fpr": 0.14050493962678376,
            "logloss": 0.6153002039557941,
            "mae": 0.2716488354899344,
            "precision": 0.746031746031746,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8228252073160273,
            "auditor_fn_violation": 0.020128121132707295,
            "auditor_fp_violation": 0.020858833129334967,
            "ave_precision_score": 0.7696076807642986,
            "fpr": 0.14364035087719298,
            "logloss": 0.5672204623011734,
            "mae": 0.3381924702165027,
            "precision": 0.7152173913043478,
            "recall": 0.6825726141078838
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8175863557577284,
            "auditor_fn_violation": 0.006790824015330523,
            "auditor_fp_violation": 0.021098745027242346,
            "ave_precision_score": 0.7608306410485958,
            "fpr": 0.14489571899012074,
            "logloss": 0.5597973384387097,
            "mae": 0.3382463322300157,
            "precision": 0.7155172413793104,
            "recall": 0.7033898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8064029951087059,
            "auditor_fn_violation": 0.04357983912062314,
            "auditor_fp_violation": 0.03130099959200327,
            "ave_precision_score": 0.793672430405583,
            "fpr": 0.14802631578947367,
            "logloss": 0.5678234047610077,
            "mae": 0.3628582072979362,
            "precision": 0.7289156626506024,
            "recall": 0.7531120331950207
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7921467174970217,
            "auditor_fn_violation": 0.032837820238516065,
            "auditor_fp_violation": 0.03830929990073238,
            "ave_precision_score": 0.8065559844159269,
            "fpr": 0.15587266739846323,
            "logloss": 0.5320844350987983,
            "mae": 0.3500264554185349,
            "precision": 0.7258687258687259,
            "recall": 0.7966101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7641147813386874,
            "auditor_fn_violation": 0.006842833224139188,
            "auditor_fp_violation": 0.012711648306813554,
            "ave_precision_score": 0.7657576954690781,
            "fpr": 0.18092105263157895,
            "logloss": 0.6159577668101386,
            "mae": 0.3430532952035336,
            "precision": 0.7032374100719424,
            "recall": 0.8112033195020747
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7212975996789718,
            "auditor_fn_violation": 0.00516753800070699,
            "auditor_fp_violation": 0.02411428028475055,
            "ave_precision_score": 0.7230291042840902,
            "fpr": 0.21075740944017562,
            "logloss": 0.665060243233456,
            "mae": 0.3595276479082822,
            "precision": 0.6672443674176777,
            "recall": 0.815677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7327311360897624,
            "auditor_fn_violation": 0.10243548445803306,
            "auditor_fp_violation": 0.09708537331701347,
            "ave_precision_score": 0.6487764233525621,
            "fpr": 0.28399122807017546,
            "logloss": 0.6440310674914282,
            "mae": 0.43925842695068895,
            "precision": 0.5668896321070234,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7539692711536403,
            "auditor_fn_violation": 0.08157361067182645,
            "auditor_fp_violation": 0.10327833190391295,
            "ave_precision_score": 0.6650968534720653,
            "fpr": 0.287596048298573,
            "logloss": 0.6234116467393813,
            "mae": 0.42980328630799125,
            "precision": 0.579454253611557,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6349347696493669,
            "auditor_fn_violation": 0.010644154473320233,
            "auditor_fp_violation": 0.01508057935536516,
            "ave_precision_score": 0.6360149578739025,
            "fpr": 0.0625,
            "logloss": 0.6978957810789881,
            "mae": 0.46837600453740413,
            "precision": 0.6481481481481481,
            "recall": 0.21784232365145229
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6379776865032545,
            "auditor_fn_violation": 0.0038977469348266992,
            "auditor_fp_violation": 0.018743326940531952,
            "ave_precision_score": 0.6393250483366696,
            "fpr": 0.07025246981339188,
            "logloss": 0.6759060947570044,
            "mae": 0.45791677739696107,
            "precision": 0.6097560975609756,
            "recall": 0.211864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6696398483286818,
            "auditor_fn_violation": 0.03725112833952101,
            "auditor_fp_violation": 0.03233374133006936,
            "ave_precision_score": 0.66610891573377,
            "fpr": 0.15570175438596492,
            "logloss": 0.6553063506080629,
            "mae": 0.4221441272090663,
            "precision": 0.7035490605427975,
            "recall": 0.6991701244813278
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.706713757984282,
            "auditor_fn_violation": 0.02511674635807178,
            "auditor_fp_violation": 0.03789922711281253,
            "ave_precision_score": 0.6928460984577558,
            "fpr": 0.1525795828759605,
            "logloss": 0.6223646799916608,
            "mae": 0.4094649876675412,
            "precision": 0.7163265306122449,
            "recall": 0.7436440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6941908064523132,
            "auditor_fn_violation": 0.0175620586736551,
            "auditor_fp_violation": 0.021486128110975118,
            "ave_precision_score": 0.6855017576422225,
            "fpr": 0.14035087719298245,
            "logloss": 0.6748438409756241,
            "mae": 0.4265389726170453,
            "precision": 0.6981132075471698,
            "recall": 0.6141078838174274
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6931002041642097,
            "auditor_fn_violation": 0.0034419245009209465,
            "auditor_fp_violation": 0.025344498648510117,
            "ave_precision_score": 0.6872769087020912,
            "fpr": 0.13830954994511527,
            "logloss": 0.6537367945807657,
            "mae": 0.41776305776494266,
            "precision": 0.6956521739130435,
            "recall": 0.6101694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.8366720752098716,
            "auditor_fn_violation": 0.003894591249909007,
            "auditor_fp_violation": 0.02601489188086497,
            "ave_precision_score": 0.8371090038983784,
            "fpr": 0.3574561403508772,
            "logloss": 0.8153393560731752,
            "mae": 0.36957529146833656,
            "precision": 0.5847133757961783,
            "recall": 0.9522821576763485
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.8565797922633427,
            "auditor_fn_violation": 0.0067117527767958495,
            "auditor_fp_violation": 0.01641791417976692,
            "ave_precision_score": 0.8567991683746705,
            "fpr": 0.3633369923161361,
            "logloss": 0.7794724533227998,
            "mae": 0.36456260479052277,
            "precision": 0.578343949044586,
            "recall": 0.961864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7763607165360056,
            "auditor_fn_violation": 0.02527617019727743,
            "auditor_fp_violation": 0.01973684210526316,
            "ave_precision_score": 0.7636098441065595,
            "fpr": 0.13706140350877194,
            "logloss": 2.5910147998275272,
            "mae": 0.2882491166421555,
            "precision": 0.7395833333333334,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8129983121237543,
            "auditor_fn_violation": 0.0168561275558615,
            "auditor_fp_violation": 0.02959525315743545,
            "ave_precision_score": 0.8021368935879891,
            "fpr": 0.13062568605927552,
            "logloss": 1.9255009575590656,
            "mae": 0.258414408359403,
            "precision": 0.7515657620041754,
            "recall": 0.7627118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7397240354626966,
            "auditor_fn_violation": 0.01638367183518964,
            "auditor_fp_violation": 0.02078998368013056,
            "ave_precision_score": 0.7011439415513628,
            "fpr": 0.18969298245614036,
            "logloss": 0.673597013562773,
            "mae": 0.42242401764598436,
            "precision": 0.6796296296296296,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7348911353241965,
            "auditor_fn_violation": 0.005121025507451303,
            "auditor_fp_violation": 0.02789995224152287,
            "ave_precision_score": 0.6971700125584639,
            "fpr": 0.19538968166849616,
            "logloss": 0.6641891483107655,
            "mae": 0.41990288663384606,
            "precision": 0.6745886654478976,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7394514684009205,
            "auditor_fn_violation": 0.01903162990463711,
            "auditor_fp_violation": 0.020833333333333336,
            "ave_precision_score": 0.7064941965819851,
            "fpr": 0.14144736842105263,
            "logloss": 0.6199865215483864,
            "mae": 0.4066238191648664,
            "precision": 0.7164835164835165,
            "recall": 0.6763485477178424
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7486094752805693,
            "auditor_fn_violation": 0.009395523637649075,
            "auditor_fp_violation": 0.029055157290419055,
            "ave_precision_score": 0.7122658725508562,
            "fpr": 0.1394072447859495,
            "logloss": 0.5906346239687117,
            "mae": 0.39543982579666226,
            "precision": 0.7158836689038032,
            "recall": 0.6779661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7759881805771441,
            "auditor_fn_violation": 0.017603006478852733,
            "auditor_fp_violation": 0.019313545491636074,
            "ave_precision_score": 0.776411220913487,
            "fpr": 0.17653508771929824,
            "logloss": 1.1820454334601946,
            "mae": 0.3082814913141586,
            "precision": 0.6939163498098859,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.790887600470427,
            "auditor_fn_violation": 0.00735595080838714,
            "auditor_fp_violation": 0.01749310502614215,
            "ave_precision_score": 0.7914472578235935,
            "fpr": 0.16355653128430298,
            "logloss": 1.0257522347693726,
            "mae": 0.28633573719460104,
            "precision": 0.7134615384615385,
            "recall": 0.7860169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7439234992767749,
            "auditor_fn_violation": 0.013358084006697255,
            "auditor_fp_violation": 0.012341901264789883,
            "ave_precision_score": 0.7443438973491179,
            "fpr": 0.06140350877192982,
            "logloss": 1.813470104122701,
            "mae": 0.397019922077238,
            "precision": 0.7837837837837838,
            "recall": 0.4211618257261411
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7374620365818663,
            "auditor_fn_violation": 0.005516381700124658,
            "auditor_fp_violation": 0.006066076728619331,
            "ave_precision_score": 0.7378586900964412,
            "fpr": 0.06256860592755215,
            "logloss": 1.6371927970260651,
            "mae": 0.3989427521380336,
            "precision": 0.7615062761506276,
            "recall": 0.3855932203389831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5421664584463681,
            "auditor_fn_violation": 0.009304251292130746,
            "auditor_fp_violation": 0.010159118727050186,
            "ave_precision_score": 0.5499219869072006,
            "fpr": 0.05592105263157895,
            "logloss": 7.077916253254302,
            "mae": 0.496031376601285,
            "precision": 0.6357142857142857,
            "recall": 0.18464730290456433
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5207172492237799,
            "auditor_fn_violation": 0.004581480585685306,
            "auditor_fp_violation": 0.007486328823366148,
            "ave_precision_score": 0.5332114743349623,
            "fpr": 0.06695938529088913,
            "logloss": 7.196736430059555,
            "mae": 0.49185496089271674,
            "precision": 0.5704225352112676,
            "recall": 0.1716101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7722099159646892,
            "auditor_fn_violation": 0.0014377229380505205,
            "auditor_fp_violation": 0.011666156670746643,
            "ave_precision_score": 0.5500178939541788,
            "fpr": 0.42653508771929827,
            "logloss": 0.6744711195050236,
            "mae": 0.47975803846738446,
            "precision": 0.5502890173410404,
            "recall": 0.9875518672199171
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.7695583327259684,
            "auditor_fn_violation": 0.0005488474204171241,
            "auditor_fp_violation": 0.010179306826961786,
            "ave_precision_score": 0.5400909501666,
            "fpr": 0.44017563117453345,
            "logloss": 0.6660773024228106,
            "mae": 0.47941248296759,
            "precision": 0.5401376146788991,
            "recall": 0.9978813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6281236835485102,
            "auditor_fn_violation": 0.01222291985149597,
            "auditor_fp_violation": 0.011232660138718892,
            "ave_precision_score": 0.6244736816482307,
            "fpr": 0.06469298245614036,
            "logloss": 2.038838439182311,
            "mae": 0.4744150937849873,
            "precision": 0.6861702127659575,
            "recall": 0.2676348547717842
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6493403567031713,
            "auditor_fn_violation": 0.011993246385979274,
            "auditor_fp_violation": 0.0094541781166157,
            "ave_precision_score": 0.6457303132768469,
            "fpr": 0.06366630076838639,
            "logloss": 1.8967572801250936,
            "mae": 0.46218265142154985,
            "precision": 0.6963350785340314,
            "recall": 0.2817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8063606434554612,
            "auditor_fn_violation": 0.018462910388003205,
            "auditor_fp_violation": 0.011686556507547938,
            "ave_precision_score": 0.7314444713659806,
            "fpr": 0.12171052631578948,
            "logloss": 0.6583439291614576,
            "mae": 0.3400770002984229,
            "precision": 0.7482993197278912,
            "recall": 0.6846473029045643
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7282532173934134,
            "auditor_fn_violation": 0.009767623583694587,
            "auditor_fp_violation": 0.01666295767498731,
            "ave_precision_score": 0.7631448115885436,
            "fpr": 0.10976948408342481,
            "logloss": 0.5738444489182188,
            "mae": 0.3227761100592249,
            "precision": 0.7706422018348624,
            "recall": 0.711864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.769068921074655,
            "auditor_fn_violation": 0.019163572832496183,
            "auditor_fp_violation": 0.005533455732354141,
            "ave_precision_score": 0.7563905856175196,
            "fpr": 0.125,
            "logloss": 0.5887038697532062,
            "mae": 0.3758695797439207,
            "precision": 0.7510917030567685,
            "recall": 0.7136929460580913
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7537574918132903,
            "auditor_fn_violation": 0.009023423691603567,
            "auditor_fp_violation": 0.011902112624990937,
            "ave_precision_score": 0.7382863864652421,
            "fpr": 0.12623490669593854,
            "logloss": 0.5831028988648854,
            "mae": 0.37384720570096003,
            "precision": 0.7558386411889597,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6319266605414562,
            "auditor_fn_violation": 0.01707978452354954,
            "auditor_fp_violation": 0.0196858425132599,
            "ave_precision_score": 0.6334306703927173,
            "fpr": 0.16776315789473684,
            "logloss": 0.6407925052942323,
            "mae": 0.45177964601469667,
            "precision": 0.6890243902439024,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6158172599359742,
            "auditor_fn_violation": 0.007669910137863035,
            "auditor_fp_violation": 0.027099810216313403,
            "ave_precision_score": 0.6179132306211581,
            "fpr": 0.16794731064763996,
            "logloss": 0.6393739117532256,
            "mae": 0.4515236342319673,
            "precision": 0.6883910386965377,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7373198658526106,
            "auditor_fn_violation": 0.007629941035160515,
            "auditor_fp_violation": 0.02030038759689924,
            "ave_precision_score": 0.5434494671675639,
            "fpr": 0.3980263157894737,
            "logloss": 13.159910448256396,
            "mae": 0.439368599004586,
            "precision": 0.5615942028985508,
            "recall": 0.9647302904564315
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7438870685847649,
            "auditor_fn_violation": 0.007748981376397702,
            "auditor_fp_violation": 0.02623715709538444,
            "ave_precision_score": 0.5537695981939433,
            "fpr": 0.38309549945115257,
            "logloss": 12.416517992791906,
            "mae": 0.42269167494188287,
            "precision": 0.5642946317103621,
            "recall": 0.9576271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 22727,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.836825307692222,
            "auditor_fn_violation": 0.004790893208124048,
            "auditor_fp_violation": 0.009108527131782946,
            "ave_precision_score": 0.7347874729869154,
            "fpr": 0.07785087719298246,
            "logloss": 0.5459256758424358,
            "mae": 0.3604195305522074,
            "precision": 0.8233830845771144,
            "recall": 0.6867219917012448
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.837087152181379,
            "auditor_fn_violation": 0.011869988278851704,
            "auditor_fp_violation": 0.001260223689704928,
            "ave_precision_score": 0.7360940145766304,
            "fpr": 0.07464324917672886,
            "logloss": 0.540254149029476,
            "mae": 0.3584598389860042,
            "precision": 0.8247422680412371,
            "recall": 0.6779661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7434506079922165,
            "auditor_fn_violation": 0.01114917740409114,
            "auditor_fp_violation": 0.008389432884536927,
            "ave_precision_score": 0.7438956812498086,
            "fpr": 0.05592105263157895,
            "logloss": 2.982330565298333,
            "mae": 0.3908637598563354,
            "precision": 0.8023255813953488,
            "recall": 0.42946058091286304
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7328756065746794,
            "auditor_fn_violation": 0.007944333848071602,
            "auditor_fp_violation": 0.005861040334659403,
            "ave_precision_score": 0.73330788287041,
            "fpr": 0.059275521405049394,
            "logloss": 2.645218336584951,
            "mae": 0.3995962918405225,
            "precision": 0.773109243697479,
            "recall": 0.3898305084745763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.760119993002547,
            "auditor_fn_violation": 0.07128785397102716,
            "auditor_fp_violation": 0.058958078335373316,
            "ave_precision_score": 0.630406418232904,
            "fpr": 0.19846491228070176,
            "logloss": 0.647102491772726,
            "mae": 0.4414232942896585,
            "precision": 0.6519230769230769,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7763688099373981,
            "auditor_fn_violation": 0.06120113862583491,
            "auditor_fp_violation": 0.05537232858832442,
            "ave_precision_score": 0.6477653019226728,
            "fpr": 0.18660812294182216,
            "logloss": 0.617646842708413,
            "mae": 0.42616896570939267,
            "precision": 0.6705426356589147,
            "recall": 0.7330508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5420294380042805,
            "auditor_fn_violation": 0.011560930334134101,
            "auditor_fp_violation": 0.003799469604243166,
            "ave_precision_score": 0.5426832562592558,
            "fpr": 0.05482456140350877,
            "logloss": 3.330452327217758,
            "mae": 0.4925077745131726,
            "precision": 0.6598639455782312,
            "recall": 0.2012448132780083
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5306888494837139,
            "auditor_fn_violation": 0.0083024800461404,
            "auditor_fp_violation": 0.0042182487391512,
            "ave_precision_score": 0.5315161424938766,
            "fpr": 0.054884742041712405,
            "logloss": 3.2824396575109107,
            "mae": 0.48812841140635577,
            "precision": 0.6402877697841727,
            "recall": 0.1885593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7642543859649122,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.47149122807017546,
            "logloss": 0.692262991508674,
            "mae": 0.4994722928917199,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7590559824368825,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.4818880351262349,
            "logloss": 0.6926479323783759,
            "mae": 0.4996647413423373,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7642543859649122,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5285087719298246,
            "fpr": 0.47149122807017546,
            "logloss": 0.6948959839980203,
            "mae": 0.4960472468744245,
            "precision": 0.5285087719298246,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.7590559824368825,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5181119648737651,
            "fpr": 0.4818880351262349,
            "logloss": 0.6977977178162252,
            "mae": 0.49748876851162455,
            "precision": 0.5181119648737651,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 22727,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8407851449686916,
            "auditor_fn_violation": 0.00931790056052996,
            "auditor_fp_violation": 0.004498164014687887,
            "ave_precision_score": 0.8411593749231244,
            "fpr": 0.12280701754385964,
            "logloss": 0.5567392518169999,
            "mae": 0.3126812760897896,
            "precision": 0.7656903765690377,
            "recall": 0.7593360995850622
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8557716667386088,
            "auditor_fn_violation": 0.009316452399114402,
            "auditor_fp_violation": 0.016427915955082025,
            "ave_precision_score": 0.8559682629646508,
            "fpr": 0.10867178924259056,
            "logloss": 0.5187794104212488,
            "mae": 0.2999120137268835,
            "precision": 0.7911392405063291,
            "recall": 0.7944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6927882076342708,
            "auditor_fn_violation": 0.02454138458178642,
            "auditor_fp_violation": 0.0018308853529171768,
            "ave_precision_score": 0.6914998173524612,
            "fpr": 0.041666666666666664,
            "logloss": 3.4264841713081915,
            "mae": 0.41877614465655816,
            "precision": 0.8118811881188119,
            "recall": 0.34024896265560167
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.6925550899469397,
            "auditor_fn_violation": 0.03537740237027666,
            "auditor_fp_violation": 0.002290406547162123,
            "ave_precision_score": 0.6924527814475667,
            "fpr": 0.04061470911086718,
            "logloss": 2.9199743448434785,
            "mae": 0.4006817461393081,
            "precision": 0.8238095238095238,
            "recall": 0.3665254237288136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8115481994354137,
            "auditor_fn_violation": 0.04379367765887749,
            "auditor_fp_violation": 0.018347103223174215,
            "ave_precision_score": 0.8061785690347112,
            "fpr": 0.08223684210526316,
            "logloss": 0.5419615778606969,
            "mae": 0.3422688231640087,
            "precision": 0.8067010309278351,
            "recall": 0.6493775933609959
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8479690977689593,
            "auditor_fn_violation": 0.02806098718115686,
            "auditor_fp_violation": 0.018870849575799705,
            "ave_precision_score": 0.8234117634112728,
            "fpr": 0.07464324917672886,
            "logloss": 0.5069517507844773,
            "mae": 0.3336904529895139,
            "precision": 0.8256410256410256,
            "recall": 0.6822033898305084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 22727,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.254046296433057,
            "mae": 0.5285087719298246,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.894953302302792,
            "mae": 0.5181119648737651,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.772380735876428,
            "auditor_fn_violation": 0.009208706413336246,
            "auditor_fp_violation": 0.01890554875560996,
            "ave_precision_score": 0.5662599839487314,
            "fpr": 0.3815789473684211,
            "logloss": 0.6696574372358577,
            "mae": 0.4681462459266186,
            "precision": 0.5682382133995038,
            "recall": 0.950207468879668
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.77790517908267,
            "auditor_fn_violation": 0.006679194031516866,
            "auditor_fp_violation": 0.02254650200410573,
            "ave_precision_score": 0.5703138989857895,
            "fpr": 0.3743139407244786,
            "logloss": 0.6480355279873092,
            "mae": 0.45823165057911963,
            "precision": 0.5721455457967378,
            "recall": 0.9661016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8149449238494026,
            "auditor_fn_violation": 0.02138157894736843,
            "auditor_fp_violation": 0.009047327621379025,
            "ave_precision_score": 0.8152952278321787,
            "fpr": 0.12390350877192982,
            "logloss": 1.1644882441917734,
            "mae": 0.2920764989575965,
            "precision": 0.7543478260869565,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8241453460758039,
            "auditor_fn_violation": 0.009374593015684014,
            "auditor_fp_violation": 0.01367992818725324,
            "ave_precision_score": 0.8246377645650043,
            "fpr": 0.1141602634467618,
            "logloss": 0.962389624902296,
            "mae": 0.27335534299227104,
            "precision": 0.7744034707158352,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.5192153875225632,
            "auditor_fn_violation": 0.003332696367474702,
            "auditor_fp_violation": 0.015865973072215423,
            "ave_precision_score": 0.5725142340497957,
            "fpr": 0.34210526315789475,
            "logloss": 0.6680972983280612,
            "mae": 0.47506660677231194,
            "precision": 0.5800807537012113,
            "recall": 0.8941908713692946
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5009902879741388,
            "auditor_fn_violation": 0.005841969152914475,
            "auditor_fp_violation": 0.00437827714419309,
            "ave_precision_score": 0.5482608204859822,
            "fpr": 0.36663007683863885,
            "logloss": 0.682303077170213,
            "mae": 0.48221213112939987,
            "precision": 0.5546666666666666,
            "recall": 0.8813559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7556707020008271,
            "auditor_fn_violation": 0.022562240663900418,
            "auditor_fp_violation": 0.019290595675234595,
            "ave_precision_score": 0.7733906341750445,
            "fpr": 0.11513157894736842,
            "logloss": 0.5525380207141957,
            "mae": 0.351427885493378,
            "precision": 0.7780126849894292,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8239909602510599,
            "auditor_fn_violation": 0.010121118532437814,
            "auditor_fp_violation": 0.016762975428138493,
            "ave_precision_score": 0.8196121795583383,
            "fpr": 0.11525795828759605,
            "logloss": 0.5294101093423191,
            "mae": 0.3436841645025526,
            "precision": 0.776595744680851,
            "recall": 0.7733050847457628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8459409649208873,
            "auditor_fn_violation": 0.009486241537453593,
            "auditor_fp_violation": 0.016567217462260298,
            "ave_precision_score": 0.8463467362294335,
            "fpr": 0.2225877192982456,
            "logloss": 0.7744243479613296,
            "mae": 0.2988946389809985,
            "precision": 0.6746794871794872,
            "recall": 0.8734439834024896
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8584652309266421,
            "auditor_fn_violation": 0.004739623062754655,
            "auditor_fp_violation": 0.026852266277264218,
            "ave_precision_score": 0.8587456176967255,
            "fpr": 0.2239297475301866,
            "logloss": 0.7220113822879057,
            "mae": 0.28300546357956635,
            "precision": 0.6797488226059655,
            "recall": 0.9173728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6106789557714316,
            "auditor_fn_violation": 0.03476468661279757,
            "auditor_fp_violation": 0.012303651570787433,
            "ave_precision_score": 0.6117360489724895,
            "fpr": 0.03179824561403509,
            "logloss": 0.7504277205959046,
            "mae": 0.4742634549426536,
            "precision": 0.6741573033707865,
            "recall": 0.12448132780082988
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6292975901221075,
            "auditor_fn_violation": 0.03372155761037415,
            "auditor_fp_violation": 0.008994096452120253,
            "ave_precision_score": 0.6300018783389654,
            "fpr": 0.025246981339187707,
            "logloss": 0.7251327953245441,
            "mae": 0.46311470486722583,
            "precision": 0.7294117647058823,
            "recall": 0.13135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 22727,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8113207036551404,
            "auditor_fn_violation": 0.0015378175729781004,
            "auditor_fp_violation": 0.013448592411260714,
            "ave_precision_score": 0.7775539594044398,
            "fpr": 0.08552631578947369,
            "logloss": 0.5298520137175977,
            "mae": 0.35772474374818175,
            "precision": 0.8173302107728337,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8105359377441358,
            "auditor_fn_violation": 0.006600122792982202,
            "auditor_fp_violation": 0.0058110314580838126,
            "ave_precision_score": 0.7739290918769948,
            "fpr": 0.09440175631174534,
            "logloss": 0.536802143088116,
            "mae": 0.35974090928303815,
            "precision": 0.7971698113207547,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 22727,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.76791491730161,
            "auditor_fn_violation": 0.0013990500109194084,
            "auditor_fp_violation": 0.0012341901264789881,
            "ave_precision_score": 0.7534201651556514,
            "fpr": 0.006578947368421052,
            "logloss": 0.961736706828187,
            "mae": 0.4326593359207771,
            "precision": 0.8181818181818182,
            "recall": 0.056016597510373446
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7933930584166137,
            "auditor_fn_violation": 0.005055908016893336,
            "auditor_fp_violation": 0.000530094091701277,
            "ave_precision_score": 0.7578240848129683,
            "fpr": 0.0010976948408342481,
            "logloss": 0.9100670653216761,
            "mae": 0.4222791228539481,
            "precision": 0.9615384615384616,
            "recall": 0.05296610169491525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8459152220020412,
            "auditor_fn_violation": 0.008608138603770837,
            "auditor_fp_violation": 0.010097919216646267,
            "ave_precision_score": 0.8386553643998595,
            "fpr": 0.08881578947368421,
            "logloss": 0.5108734806441051,
            "mae": 0.32136789390310777,
            "precision": 0.8111888111888111,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8597153029686535,
            "auditor_fn_violation": 0.00483962492325439,
            "auditor_fp_violation": 0.004923373898867054,
            "ave_precision_score": 0.8536365023737866,
            "fpr": 0.0889132821075741,
            "logloss": 0.4871536670287307,
            "mae": 0.315250439396584,
            "precision": 0.8107476635514018,
            "recall": 0.7351694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7860140762058978,
            "auditor_fn_violation": 0.019500254786343457,
            "auditor_fp_violation": 0.013596491228070174,
            "ave_precision_score": 0.7874479390336231,
            "fpr": 0.14144736842105263,
            "logloss": 1.0296201770043252,
            "mae": 0.30597295352756765,
            "precision": 0.7295597484276729,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7989732315643369,
            "auditor_fn_violation": 0.008486204394500367,
            "auditor_fp_violation": 0.025034443613741447,
            "ave_precision_score": 0.7994393075808179,
            "fpr": 0.145993413830955,
            "logloss": 0.890841522544319,
            "mae": 0.28969186998743984,
            "precision": 0.7274590163934426,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8286493301394346,
            "auditor_fn_violation": 0.009003967387348039,
            "auditor_fp_violation": 0.009338025295797636,
            "ave_precision_score": 0.7628092394314596,
            "fpr": 0.1074561403508772,
            "logloss": 0.56590654741025,
            "mae": 0.37178084724827815,
            "precision": 0.7726218097447796,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8056411688587823,
            "auditor_fn_violation": 0.0044745018511972365,
            "auditor_fp_violation": 0.01347739223712209,
            "ave_precision_score": 0.7357298860524994,
            "fpr": 0.11745334796926454,
            "logloss": 0.6004293374905602,
            "mae": 0.3826534197462312,
            "precision": 0.7523148148148148,
            "recall": 0.6885593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7580145802148709,
            "auditor_fn_violation": 0.012994103516051542,
            "auditor_fp_violation": 0.010189718482252147,
            "ave_precision_score": 0.758950843933778,
            "fpr": 0.06359649122807018,
            "logloss": 0.9891200312261582,
            "mae": 0.3513436695321424,
            "precision": 0.8253012048192772,
            "recall": 0.5684647302904564
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7851753520674282,
            "auditor_fn_violation": 0.0033884351336769124,
            "auditor_fp_violation": 0.013114827881949048,
            "ave_precision_score": 0.7858411523876911,
            "fpr": 0.07025246981339188,
            "logloss": 0.881493197089757,
            "mae": 0.34199210383600287,
            "precision": 0.8066465256797583,
            "recall": 0.565677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5434913709648093,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002422480620155043,
            "ave_precision_score": 0.5310364728530308,
            "fpr": 0.46600877192982454,
            "logloss": 0.6888146964113839,
            "mae": 0.49713590207689423,
            "precision": 0.5314222712238148,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.5436650138712307,
            "auditor_fn_violation": 0.0006348955329401478,
            "auditor_fp_violation": 0.003570633787497296,
            "ave_precision_score": 0.5223831463489896,
            "fpr": 0.47420417124039516,
            "logloss": 0.6896129166925703,
            "mae": 0.4969249547803703,
            "precision": 0.521594684385382,
            "recall": 0.9978813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8471835039273699,
            "auditor_fn_violation": 0.020068974302977362,
            "auditor_fp_violation": 0.007211342309261529,
            "ave_precision_score": 0.7796186922702122,
            "fpr": 0.07017543859649122,
            "logloss": 0.5319502881855399,
            "mae": 0.34186105447282134,
            "precision": 0.8387909319899244,
            "recall": 0.6908713692946058
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8376013771389681,
            "auditor_fn_violation": 0.00921645053861468,
            "auditor_fp_violation": 0.010026779753406231,
            "ave_precision_score": 0.7677235293577123,
            "fpr": 0.07464324917672886,
            "logloss": 0.5242974954803203,
            "mae": 0.34341659445957606,
            "precision": 0.8242894056847545,
            "recall": 0.6758474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 22727,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8527150295558494,
            "auditor_fn_violation": 0.012311640096090853,
            "auditor_fp_violation": 0.009904120767033866,
            "ave_precision_score": 0.8263400890753915,
            "fpr": 0.08114035087719298,
            "logloss": 0.533913010490019,
            "mae": 0.299120635235388,
            "precision": 0.8233890214797136,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.6936401805673704,
            "auditor_fn_violation": 0.008493181268488722,
            "auditor_fp_violation": 0.006306119336182171,
            "ave_precision_score": 0.8338866633933191,
            "fpr": 0.0801317233809001,
            "logloss": 0.5059185262315266,
            "mae": 0.2921001803207607,
            "precision": 0.8228155339805825,
            "recall": 0.7182203389830508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5908961326315332,
            "auditor_fn_violation": 0.007643590303559755,
            "auditor_fp_violation": 0.00557170542635659,
            "ave_precision_score": 0.6144706127001597,
            "fpr": 0.049342105263157895,
            "logloss": 0.7121391212121883,
            "mae": 0.47240285366250756,
            "precision": 0.6428571428571429,
            "recall": 0.16804979253112035
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.617852674956018,
            "auditor_fn_violation": 0.0014279335429496641,
            "auditor_fp_violation": 0.00038006746197450297,
            "ave_precision_score": 0.6154509561791088,
            "fpr": 0.048298572996706916,
            "logloss": 0.6986156621887896,
            "mae": 0.466303482308215,
            "precision": 0.6106194690265486,
            "recall": 0.1461864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 22727,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.5054273110983803,
            "auditor_fn_violation": 0.005728142971536742,
            "auditor_fp_violation": 0.0019558343533251743,
            "ave_precision_score": 0.5415388187638818,
            "fpr": 0.01206140350877193,
            "logloss": 17.200557636245886,
            "mae": 0.5171436627757717,
            "precision": 0.6666666666666666,
            "recall": 0.04564315352697095
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5266961815128252,
            "auditor_fn_violation": 0.0037489069564085073,
            "auditor_fp_violation": 0.0011527046050673995,
            "ave_precision_score": 0.5484499038800927,
            "fpr": 0.0043907793633369925,
            "logloss": 16.66710386933187,
            "mae": 0.49638477078885346,
            "precision": 0.8709677419354839,
            "recall": 0.057203389830508475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5525034157445403,
            "auditor_fn_violation": 0.0701162917667613,
            "auditor_fp_violation": 0.0851438188494492,
            "ave_precision_score": 0.5531138003449476,
            "fpr": 0.30153508771929827,
            "logloss": 2.661766780354685,
            "mae": 0.48277600052547986,
            "precision": 0.5795107033639144,
            "recall": 0.7863070539419087
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.5888525143951289,
            "auditor_fn_violation": 0.05621034809949953,
            "auditor_fp_violation": 0.08093936673759593,
            "ave_precision_score": 0.589616933865742,
            "fpr": 0.3029637760702525,
            "logloss": 1.8712620995020646,
            "mae": 0.46969320373696977,
            "precision": 0.5811836115326252,
            "recall": 0.8114406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7319483291400768,
            "auditor_fn_violation": 0.01803523331149451,
            "auditor_fp_violation": 0.020070889432884546,
            "ave_precision_score": 0.6860708961425785,
            "fpr": 0.13267543859649122,
            "logloss": 0.6838656375561556,
            "mae": 0.39066458190382836,
            "precision": 0.7186046511627907,
            "recall": 0.6410788381742739
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7340063461629249,
            "auditor_fn_violation": 0.013704906137788615,
            "auditor_fp_violation": 0.0231391071915265,
            "ave_precision_score": 0.6967789620544022,
            "fpr": 0.13830954994511527,
            "logloss": 0.6476451917777407,
            "mae": 0.3772777401638738,
            "precision": 0.7155756207674944,
            "recall": 0.6716101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8446602880294516,
            "auditor_fn_violation": 0.015077891824998182,
            "auditor_fp_violation": 0.014616483068135457,
            "ave_precision_score": 0.8334247358051838,
            "fpr": 0.18421052631578946,
            "logloss": 0.5632479811426244,
            "mae": 0.31743543106131256,
            "precision": 0.7031802120141343,
            "recall": 0.8257261410788381
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8663899226695487,
            "auditor_fn_violation": 0.010290889132821075,
            "auditor_fp_violation": 0.02581458208832068,
            "ave_precision_score": 0.8560097407827582,
            "fpr": 0.17892425905598244,
            "logloss": 0.5064097163308383,
            "mae": 0.2954787467325231,
            "precision": 0.7170138888888888,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8532210423474573,
            "auditor_fn_violation": 0.008947095435684645,
            "auditor_fp_violation": 0.0055385556915544705,
            "ave_precision_score": 0.8282997945966268,
            "fpr": 0.11293859649122807,
            "logloss": 0.5056075575521768,
            "mae": 0.325609620570679,
            "precision": 0.7751091703056768,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8426989126418275,
            "auditor_fn_violation": 0.00021395746897617256,
            "auditor_fp_violation": 0.007818887852593838,
            "ave_precision_score": 0.8187034365416451,
            "fpr": 0.12952799121844127,
            "logloss": 0.5135849756279769,
            "mae": 0.3312281856045503,
            "precision": 0.7541666666666667,
            "recall": 0.7669491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8243366734505566,
            "auditor_fn_violation": 0.0025637875809856737,
            "auditor_fp_violation": 0.005145858833129333,
            "ave_precision_score": 0.7831541538898812,
            "fpr": 0.09100877192982457,
            "logloss": 0.5514788717267667,
            "mae": 0.3489116647101024,
            "precision": 0.8014354066985646,
            "recall": 0.6950207468879668
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8369735882248861,
            "auditor_fn_violation": 0.00944668738023033,
            "auditor_fp_violation": 0.0009076611098470005,
            "ave_precision_score": 0.7882498698393744,
            "fpr": 0.08122941822173436,
            "logloss": 0.5277697335142502,
            "mae": 0.342070791383737,
            "precision": 0.8136020151133502,
            "recall": 0.684322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 22727,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8391483927436592,
            "auditor_fn_violation": 0.004790893208124048,
            "auditor_fp_violation": 0.009108527131782946,
            "ave_precision_score": 0.7492006189404051,
            "fpr": 0.07785087719298246,
            "logloss": 0.5480277066645349,
            "mae": 0.36882332573530446,
            "precision": 0.8233830845771144,
            "recall": 0.6867219917012448
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.839551729773854,
            "auditor_fn_violation": 0.011869988278851704,
            "auditor_fp_violation": 0.001260223689704928,
            "ave_precision_score": 0.7524972905344007,
            "fpr": 0.07464324917672886,
            "logloss": 0.5431728176885819,
            "mae": 0.3681063603949207,
            "precision": 0.8247422680412371,
            "recall": 0.6779661016949152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8441638794086089,
            "auditor_fn_violation": 0.022079966513794864,
            "auditor_fp_violation": 0.021618727050183605,
            "ave_precision_score": 0.8409165278735969,
            "fpr": 0.14583333333333334,
            "logloss": 0.535860287002662,
            "mae": 0.3462031282711235,
            "precision": 0.7345309381237525,
            "recall": 0.7634854771784232
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8278851383092984,
            "auditor_fn_violation": 0.009135053675417218,
            "auditor_fp_violation": 0.028325027692415405,
            "ave_precision_score": 0.8236962674929464,
            "fpr": 0.145993413830955,
            "logloss": 0.522232475785097,
            "mae": 0.3423190182821189,
            "precision": 0.7366336633663366,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8398742933543146,
            "auditor_fn_violation": 0.0018017034286962252,
            "auditor_fp_violation": 0.01216340269277846,
            "ave_precision_score": 0.7316868576118293,
            "fpr": 0.09320175438596491,
            "logloss": 0.5469124351252858,
            "mae": 0.36773683496734555,
            "precision": 0.8059360730593608,
            "recall": 0.7323651452282157
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8255357957329157,
            "auditor_fn_violation": 0.004716366816126812,
            "auditor_fp_violation": 0.00546847065354101,
            "ave_precision_score": 0.7112924440595654,
            "fpr": 0.09989023051591657,
            "logloss": 0.560261236364451,
            "mae": 0.3737660725606129,
            "precision": 0.7878787878787878,
            "recall": 0.7161016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.750563339908358,
            "auditor_fn_violation": 0.010655528863652905,
            "auditor_fp_violation": 0.015455426356589148,
            "ave_precision_score": 0.7524043778133915,
            "fpr": 0.16557017543859648,
            "logloss": 0.6690912803263594,
            "mae": 0.34771630640438833,
            "precision": 0.713472485768501,
            "recall": 0.7800829875518672
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7874746938283854,
            "auditor_fn_violation": 0.009283893653835423,
            "auditor_fp_violation": 0.023566683086247816,
            "ave_precision_score": 0.7882851896368207,
            "fpr": 0.1394072447859495,
            "logloss": 0.5826171993248875,
            "mae": 0.33262049046301095,
            "precision": 0.7514677103718199,
            "recall": 0.8135593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8444024055035408,
            "auditor_fn_violation": 0.010377993739535562,
            "auditor_fp_violation": 0.01268359853121175,
            "ave_precision_score": 0.8134978224254683,
            "fpr": 0.17434210526315788,
            "logloss": 0.5161976880624897,
            "mae": 0.33129749461403935,
            "precision": 0.7155635062611807,
            "recall": 0.8298755186721992
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8438220406983664,
            "auditor_fn_violation": 0.008097825075815367,
            "auditor_fp_violation": 0.015797804110229564,
            "ave_precision_score": 0.8119704111021941,
            "fpr": 0.16245883644346873,
            "logloss": 0.5014088818384282,
            "mae": 0.32676926485858815,
            "precision": 0.7323688969258589,
            "recall": 0.8580508474576272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7528526941283007,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002422480620155043,
            "ave_precision_score": 0.7529333708114923,
            "fpr": 0.46600877192982454,
            "logloss": 1.0286719538787863,
            "mae": 0.43372703057243445,
            "precision": 0.5314222712238148,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.761653920202942,
            "auditor_fn_violation": 0.0006348955329401478,
            "auditor_fp_violation": 0.003570633787497296,
            "ave_precision_score": 0.7619872420724305,
            "fpr": 0.47420417124039516,
            "logloss": 1.0346311491440534,
            "mae": 0.4359108936505628,
            "precision": 0.521594684385382,
            "recall": 0.9978813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6281890479242147,
            "auditor_fn_violation": 0.04329547936230618,
            "auditor_fp_violation": 0.04378314973480213,
            "ave_precision_score": 0.6290182176763142,
            "fpr": 0.2719298245614035,
            "logloss": 0.9733341999246616,
            "mae": 0.41238098983523697,
            "precision": 0.6075949367088608,
            "recall": 0.7966804979253111
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6410630379973536,
            "auditor_fn_violation": 0.0315633779233102,
            "auditor_fp_violation": 0.05336697263764319,
            "ave_precision_score": 0.6420564125941265,
            "fpr": 0.2689352360043908,
            "logloss": 0.8335745241435992,
            "mae": 0.39559137469164085,
            "precision": 0.6177847113884556,
            "recall": 0.8389830508474576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6685274918211814,
            "auditor_fn_violation": 0.042390077891825,
            "auditor_fp_violation": 0.015396776825785394,
            "ave_precision_score": 0.6561937849451593,
            "fpr": 0.1074561403508772,
            "logloss": 0.8659431324044575,
            "mae": 0.4600611273444405,
            "precision": 0.6487455197132617,
            "recall": 0.3755186721991701
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7043793247980121,
            "auditor_fn_violation": 0.0645477125155817,
            "auditor_fp_violation": 0.01338487581545725,
            "ave_precision_score": 0.6880355439186661,
            "fpr": 0.09549945115257959,
            "logloss": 0.8424273129761402,
            "mae": 0.44842879809480074,
            "precision": 0.6892857142857143,
            "recall": 0.4088983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7443862686289133,
            "auditor_fn_violation": 0.017441490136128713,
            "auditor_fp_violation": 0.021164830681354548,
            "ave_precision_score": 0.733689857264461,
            "fpr": 0.15899122807017543,
            "logloss": 2.467385560800888,
            "mae": 0.32503794846757433,
            "precision": 0.6991701244813278,
            "recall": 0.6991701244813278
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7824217392868721,
            "auditor_fn_violation": 0.011386258348992541,
            "auditor_fp_violation": 0.02554953504247004,
            "ave_precision_score": 0.7734704418619918,
            "fpr": 0.15806805708013172,
            "logloss": 1.9545468137066526,
            "mae": 0.3008077776266329,
            "precision": 0.7049180327868853,
            "recall": 0.7288135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6927748173214396,
            "auditor_fn_violation": 0.11671944383781029,
            "auditor_fp_violation": 0.11337209302325582,
            "ave_precision_score": 0.6023647560230466,
            "fpr": 0.20065789473684212,
            "logloss": 0.6672836248452777,
            "mae": 0.47356202486052845,
            "precision": 0.6047516198704104,
            "recall": 0.5809128630705395
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7156011830225445,
            "auditor_fn_violation": 0.11350676291651939,
            "auditor_fp_violation": 0.1142077718795086,
            "ave_precision_score": 0.6130523344982607,
            "fpr": 0.19538968166849616,
            "logloss": 0.65529838532969,
            "mae": 0.46851451048866716,
            "precision": 0.6155507559395248,
            "recall": 0.6038135593220338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.8101875133238763,
            "auditor_fn_violation": 0.02471427531484313,
            "auditor_fp_violation": 0.008654630762953896,
            "ave_precision_score": 0.7523050085148644,
            "fpr": 0.02631578947368421,
            "logloss": 8.252502647295909,
            "mae": 0.341891370328964,
            "precision": 0.8883720930232558,
            "recall": 0.3962655601659751
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.8131737002812707,
            "auditor_fn_violation": 0.02662375113955609,
            "auditor_fp_violation": 0.011221991903562885,
            "ave_precision_score": 0.7536800346095006,
            "fpr": 0.030735455543358946,
            "logloss": 7.797317528773056,
            "mae": 0.3401260799488962,
            "precision": 0.8666666666666667,
            "recall": 0.3855932203389831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6807461288888883,
            "auditor_fn_violation": 0.008860650069156293,
            "auditor_fp_violation": 0.006125050999592005,
            "ave_precision_score": 0.5146336300062858,
            "fpr": 0.4298245614035088,
            "logloss": 0.6963138778340072,
            "mae": 0.488445096001797,
            "precision": 0.5415204678362573,
            "recall": 0.9605809128630706
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6673243926448025,
            "auditor_fn_violation": 0.00995599918138012,
            "auditor_fp_violation": 0.008626531209289665,
            "ave_precision_score": 0.49814454966915755,
            "fpr": 0.43798024149286496,
            "logloss": 0.7087343844300381,
            "mae": 0.49292470032244956,
            "precision": 0.5272511848341233,
            "recall": 0.9427966101694916
        }
    }
]