[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5625930050393549,
            "auditor_fn_violation": 0.004318140712606259,
            "auditor_fp_violation": 0.015399667200788855,
            "ave_precision_score": 0.5727193680680964,
            "fpr": 0.08114035087719298,
            "logloss": 11.32519834488369,
            "mae": 0.4545542316840246,
            "precision": 0.6768558951965066,
            "recall": 0.31958762886597936
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.5852999050052885,
            "auditor_fn_violation": 0.005914445336435299,
            "auditor_fp_violation": 0.011930601844723368,
            "ave_precision_score": 0.591014893487283,
            "fpr": 0.07025246981339188,
            "logloss": 10.790428724184787,
            "mae": 0.42819952591133453,
            "precision": 0.7117117117117117,
            "recall": 0.3368869936034115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5908630644996444,
            "auditor_fn_violation": 0.0006262434436607016,
            "auditor_fp_violation": 0.013417252146760345,
            "ave_precision_score": 0.5913764179659379,
            "fpr": 0.06798245614035088,
            "logloss": 11.509558910769101,
            "mae": 0.4464589166276263,
            "precision": 0.7089201877934272,
            "recall": 0.311340206185567
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6041470834017308,
            "auditor_fn_violation": 0.007117462709972169,
            "auditor_fp_violation": 0.013877644277334344,
            "ave_precision_score": 0.6064377380099407,
            "fpr": 0.06915477497255763,
            "logloss": 11.267282009786916,
            "mae": 0.4265242972877388,
            "precision": 0.704225352112676,
            "recall": 0.31982942430703626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6033901715644328,
            "auditor_fn_violation": 0.006569904141797804,
            "auditor_fp_violation": 0.008574201898188095,
            "ave_precision_score": 0.5814121008043645,
            "fpr": 0.11513157894736842,
            "logloss": 12.327855218550797,
            "mae": 0.4558674929910666,
            "precision": 0.6354166666666666,
            "recall": 0.37731958762886597
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6061372554306887,
            "auditor_fn_violation": 0.012376567842924338,
            "auditor_fp_violation": 0.006139143996701955,
            "ave_precision_score": 0.5909558930963932,
            "fpr": 0.10428100987925357,
            "logloss": 11.918974935131333,
            "mae": 0.44145968298501365,
            "precision": 0.6428571428571429,
            "recall": 0.3646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5818294269081765,
            "auditor_fn_violation": 0.002547929101103284,
            "auditor_fp_violation": 0.019053781995973542,
            "ave_precision_score": 0.5823498712992994,
            "fpr": 0.07675438596491228,
            "logloss": 6.90141430856091,
            "mae": 0.45307106718962775,
            "precision": 0.6860986547085202,
            "recall": 0.3154639175257732
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6177490708311555,
            "auditor_fn_violation": 0.00999393810311779,
            "auditor_fp_violation": 0.011980271294534875,
            "ave_precision_score": 0.6196392120430136,
            "fpr": 0.06586169045005488,
            "logloss": 6.373147485722233,
            "mae": 0.4244578674644337,
            "precision": 0.7156398104265402,
            "recall": 0.32196162046908317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7525196508618657,
            "auditor_fn_violation": 0.027536625067824203,
            "auditor_fp_violation": 0.04662784009203337,
            "ave_precision_score": 0.7541820522454857,
            "fpr": 0.24561403508771928,
            "logloss": 1.0484005400723875,
            "mae": 0.3383359124147736,
            "precision": 0.6489028213166145,
            "recall": 0.8536082474226804
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8251507393396201,
            "auditor_fn_violation": 0.02711938192056809,
            "auditor_fp_violation": 0.045847385648509174,
            "ave_precision_score": 0.8254890707360207,
            "fpr": 0.23161361141602635,
            "logloss": 0.6626568019581539,
            "mae": 0.31584772656791543,
            "precision": 0.6624,
            "recall": 0.8827292110874201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5570111326138547,
            "auditor_fn_violation": 0.005290287574606621,
            "auditor_fp_violation": 0.018874029335634167,
            "ave_precision_score": 0.5436699874428936,
            "fpr": 0.10964912280701754,
            "logloss": 12.847087097928622,
            "mae": 0.46969417910491884,
            "precision": 0.6296296296296297,
            "recall": 0.35051546391752575
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5784005141782459,
            "auditor_fn_violation": 0.009191146353850946,
            "auditor_fp_violation": 0.008875930681315846,
            "ave_precision_score": 0.5658238218978179,
            "fpr": 0.08781558726673985,
            "logloss": 12.03849378192097,
            "mae": 0.4404225931978252,
            "precision": 0.6680497925311203,
            "recall": 0.34328358208955223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8194135049821107,
            "auditor_fn_violation": 0.012004883342376566,
            "auditor_fp_violation": 0.017962426558198775,
            "ave_precision_score": 0.8198070077493662,
            "fpr": 0.10197368421052631,
            "logloss": 0.9048892702431903,
            "mae": 0.2894139424386742,
            "precision": 0.7769784172661871,
            "recall": 0.668041237113402
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8399652727023253,
            "auditor_fn_violation": 0.012371886841470867,
            "auditor_fp_violation": 0.012702961789292264,
            "ave_precision_score": 0.8402173402662827,
            "fpr": 0.10867178924259056,
            "logloss": 0.7492555597207146,
            "mae": 0.27349712517169306,
            "precision": 0.7681498829039812,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6318980200348401,
            "auditor_fn_violation": 0.013309368782781696,
            "auditor_fp_violation": 0.018486277168330668,
            "ave_precision_score": 0.5458343774906911,
            "fpr": 0.2236842105263158,
            "logloss": 10.923434970269957,
            "mae": 0.4337868699658429,
            "precision": 0.5944333996023857,
            "recall": 0.6164948453608248
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6217444952080632,
            "auditor_fn_violation": 0.008776877725220535,
            "auditor_fp_violation": 0.01189334975736475,
            "ave_precision_score": 0.5342312346178225,
            "fpr": 0.22502744237102085,
            "logloss": 10.983986343462464,
            "mae": 0.42363284114399635,
            "precision": 0.5956607495069034,
            "recall": 0.6439232409381663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6178667643310811,
            "auditor_fn_violation": 0.0038546753481642397,
            "auditor_fp_violation": 0.01260066148979005,
            "ave_precision_score": 0.6025769376746931,
            "fpr": 0.08442982456140351,
            "logloss": 11.826035289253545,
            "mae": 0.44142048067940204,
            "precision": 0.6944444444444444,
            "recall": 0.36082474226804123
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6163854775897453,
            "auditor_fn_violation": 0.014024280354539058,
            "auditor_fp_violation": 0.009382559069393191,
            "ave_precision_score": 0.6061271988915045,
            "fpr": 0.08342480790340286,
            "logloss": 11.569279871357312,
            "mae": 0.429804994761494,
            "precision": 0.6872427983539094,
            "recall": 0.35607675906183367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 9292,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6880362577016783,
            "auditor_fn_violation": 0.0011575330077771755,
            "auditor_fp_violation": 0.002534512510785166,
            "ave_precision_score": 0.539006897454591,
            "fpr": 0.43201754385964913,
            "logloss": 11.219723493408999,
            "mae": 0.44978826176456843,
            "precision": 0.5460829493087558,
            "recall": 0.977319587628866
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6800716636960852,
            "auditor_fn_violation": 0.0017179275334164995,
            "auditor_fp_violation": 0.0005066283880773665,
            "ave_precision_score": 0.5307393831507201,
            "fpr": 0.4478594950603732,
            "logloss": 11.222866107992298,
            "mae": 0.4625092108246311,
            "precision": 0.5304948216340621,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6174444389390057,
            "auditor_fn_violation": 0.0038546753481642397,
            "auditor_fp_violation": 0.01260066148979005,
            "ave_precision_score": 0.6020365882789195,
            "fpr": 0.08442982456140351,
            "logloss": 11.849287975068002,
            "mae": 0.44170923412597757,
            "precision": 0.6944444444444444,
            "recall": 0.36082474226804123
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6150355690045777,
            "auditor_fn_violation": 0.013921298322563133,
            "auditor_fp_violation": 0.010741018521737838,
            "ave_precision_score": 0.6048300110466256,
            "fpr": 0.07793633369923161,
            "logloss": 11.580350999075195,
            "mae": 0.4289988047564985,
            "precision": 0.70042194092827,
            "recall": 0.35394456289978676
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6425056657170539,
            "auditor_fn_violation": 0.006701030927835062,
            "auditor_fp_violation": 0.007177266937836397,
            "ave_precision_score": 0.6479101035452237,
            "fpr": 0.043859649122807015,
            "logloss": 10.629020969073311,
            "mae": 0.4336405374574161,
            "precision": 0.7752808988764045,
            "recall": 0.2845360824742268
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6429735255072848,
            "auditor_fn_violation": 0.01024671218160414,
            "auditor_fp_violation": 0.01437185530295881,
            "ave_precision_score": 0.6467485514218874,
            "fpr": 0.04939626783754116,
            "logloss": 10.376708669285303,
            "mae": 0.4149436620962533,
            "precision": 0.7606382978723404,
            "recall": 0.3049040511727079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6087723540270775,
            "auditor_fn_violation": 0.004453789111955159,
            "auditor_fp_violation": 0.012359279345905751,
            "ave_precision_score": 0.5954396731800887,
            "fpr": 0.08771929824561403,
            "logloss": 11.944622794844534,
            "mae": 0.44579606572688935,
            "precision": 0.6862745098039216,
            "recall": 0.36082474226804123
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6120015159374014,
            "auditor_fn_violation": 0.013514051196112901,
            "auditor_fp_violation": 0.008856062901391246,
            "ave_precision_score": 0.6030107248138411,
            "fpr": 0.0845225027442371,
            "logloss": 11.592659045801863,
            "mae": 0.43183128527773523,
            "precision": 0.6869918699186992,
            "recall": 0.3603411513859275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6553589409265488,
            "auditor_fn_violation": 0.017975673720383435,
            "auditor_fp_violation": 0.013694584822712514,
            "ave_precision_score": 0.6397709087570554,
            "fpr": 0.2883771929824561,
            "logloss": 3.5513277879410228,
            "mae": 0.3628011520509171,
            "precision": 0.6154970760233918,
            "recall": 0.8680412371134021
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7101707385418498,
            "auditor_fn_violation": 0.0194308370332749,
            "auditor_fp_violation": 0.017786629977499743,
            "ave_precision_score": 0.6962446794603085,
            "fpr": 0.27661909989023054,
            "logloss": 2.832270266427351,
            "mae": 0.33870405757428396,
            "precision": 0.625,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6913027336992854,
            "auditor_fn_violation": 0.0028599204196057162,
            "auditor_fp_violation": 0.00011041949135133547,
            "ave_precision_score": 0.539757485693695,
            "fpr": 0.4342105263157895,
            "logloss": 11.414393596980958,
            "mae": 0.45010893468416296,
            "precision": 0.5453501722158438,
            "recall": 0.979381443298969
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6855119625902693,
            "auditor_fn_violation": 0.0036090521206106844,
            "auditor_fp_violation": 0.0019867779924601808,
            "ave_precision_score": 0.5325359584931433,
            "fpr": 0.4500548847420417,
            "logloss": 11.410351382643514,
            "mae": 0.4632439664406569,
            "precision": 0.5281933256616801,
            "recall": 0.9786780383795309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6433806850759622,
            "auditor_fn_violation": 0.012282962561041789,
            "auditor_fp_violation": 0.0036669542709232114,
            "ave_precision_score": 0.6439643244384307,
            "fpr": 0.06140350877192982,
            "logloss": 11.39010452584823,
            "mae": 0.4378385688645634,
            "precision": 0.7307692307692307,
            "recall": 0.3134020618556701
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6538472170436316,
            "auditor_fn_violation": 0.009912020577682392,
            "auditor_fp_violation": 0.013209590177369604,
            "ave_precision_score": 0.6546183367104423,
            "fpr": 0.06476399560922064,
            "logloss": 11.154851910819351,
            "mae": 0.41917932966549987,
            "precision": 0.728110599078341,
            "recall": 0.3368869936034115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6115930179724511,
            "auditor_fn_violation": 0.01106664858021343,
            "auditor_fp_violation": 0.009747729980689429,
            "ave_precision_score": 0.6081188329905354,
            "fpr": 0.043859649122807015,
            "logloss": 12.117458749996905,
            "mae": 0.44198437117198414,
            "precision": 0.7714285714285715,
            "recall": 0.27835051546391754
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6150903856048299,
            "auditor_fn_violation": 0.01834718519680102,
            "auditor_fp_violation": 0.00923603419244925,
            "ave_precision_score": 0.6123372082274972,
            "fpr": 0.04720087815587267,
            "logloss": 11.720079138693164,
            "mae": 0.426684275862418,
            "precision": 0.7570621468926554,
            "recall": 0.2857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6554289889916276,
            "auditor_fn_violation": 0.009610689093868696,
            "auditor_fp_violation": 0.00999424791486914,
            "ave_precision_score": 0.6560803520901954,
            "fpr": 0.08333333333333333,
            "logloss": 7.6072471248519795,
            "mae": 0.42082601705435746,
            "precision": 0.7110266159695817,
            "recall": 0.38556701030927837
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6718334997417074,
            "auditor_fn_violation": 0.017375877395209932,
            "auditor_fp_violation": 0.011553114026155933,
            "ave_precision_score": 0.6733351208612199,
            "fpr": 0.07574094401756312,
            "logloss": 7.1305565674198235,
            "mae": 0.39818744207212525,
            "precision": 0.7228915662650602,
            "recall": 0.3837953091684435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5591597733496942,
            "auditor_fn_violation": 0.007367968891300416,
            "auditor_fp_violation": 0.01813704342824274,
            "ave_precision_score": 0.5464324410745667,
            "fpr": 0.10855263157894737,
            "logloss": 12.744458338043017,
            "mae": 0.46847496208481554,
            "precision": 0.6305970149253731,
            "recall": 0.34845360824742266
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5833596954308283,
            "auditor_fn_violation": 0.00895241527972496,
            "auditor_fp_violation": 0.008115988099199825,
            "ave_precision_score": 0.5712588518909965,
            "fpr": 0.0867178924259056,
            "logloss": 11.93618960073641,
            "mae": 0.4382404015756301,
            "precision": 0.6721991701244814,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5778906254609458,
            "auditor_fn_violation": 0.004953427382890226,
            "auditor_fp_violation": 0.013992460659846342,
            "ave_precision_score": 0.5758641250131883,
            "fpr": 0.08223684210526316,
            "logloss": 11.812167568373205,
            "mae": 0.4537493585590518,
            "precision": 0.6767241379310345,
            "recall": 0.3237113402061856
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.5898922301928284,
            "auditor_fn_violation": 0.0072251257434015415,
            "auditor_fp_violation": 0.01094217979347443,
            "ave_precision_score": 0.589629395193122,
            "fpr": 0.07574094401756312,
            "logloss": 11.421520027756312,
            "mae": 0.4319022398249836,
            "precision": 0.6946902654867256,
            "recall": 0.3347547974413646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5736012783760774,
            "auditor_fn_violation": 0.0007121540965816637,
            "auditor_fp_violation": 0.019865236862648423,
            "ave_precision_score": 0.5696623553551028,
            "fpr": 0.09649122807017543,
            "logloss": 6.6786510318374965,
            "mae": 0.457155341313233,
            "precision": 0.6521739130434783,
            "recall": 0.3402061855670103
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.5916850636105793,
            "auditor_fn_violation": 0.007159591723053246,
            "auditor_fp_violation": 0.014150826251297622,
            "ave_precision_score": 0.5895002229544319,
            "fpr": 0.09220636663007684,
            "logloss": 6.060310415885477,
            "mae": 0.43140620168804894,
            "precision": 0.6666666666666666,
            "recall": 0.3582089552238806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6617058101367874,
            "auditor_fn_violation": 0.026568999819135467,
            "auditor_fp_violation": 0.010104667406220468,
            "ave_precision_score": 0.6545262054535241,
            "fpr": 0.23464912280701755,
            "logloss": 2.9500560503281483,
            "mae": 0.3497931098569544,
            "precision": 0.6508972267536705,
            "recall": 0.822680412371134
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.702396201818642,
            "auditor_fn_violation": 0.032652325638547114,
            "auditor_fp_violation": 0.013594528413408767,
            "ave_precision_score": 0.6970738782889823,
            "fpr": 0.2239297475301866,
            "logloss": 2.603645342655182,
            "mae": 0.32536467805946434,
            "precision": 0.6577181208053692,
            "recall": 0.835820895522388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8232800525451084,
            "auditor_fn_violation": 0.021488967263519627,
            "auditor_fp_violation": 0.01716381116726242,
            "ave_precision_score": 0.8235150530058835,
            "fpr": 0.09649122807017543,
            "logloss": 2.352905090005363,
            "mae": 0.30109648235124215,
            "precision": 0.7869249394673123,
            "recall": 0.6701030927835051
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.830888841424198,
            "auditor_fn_violation": 0.021181531576865562,
            "auditor_fp_violation": 0.018039944171538418,
            "ave_precision_score": 0.8307395503225453,
            "fpr": 0.09110867178924259,
            "logloss": 2.0282586429050937,
            "mae": 0.2874637710064718,
            "precision": 0.7980535279805353,
            "recall": 0.6993603411513859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6770292569355456,
            "auditor_fn_violation": 0.012683125339120997,
            "auditor_fp_violation": 0.01477310078474876,
            "ave_precision_score": 0.5599939475083262,
            "fpr": 0.3168859649122807,
            "logloss": 10.075714610794245,
            "mae": 0.4101441764953222,
            "precision": 0.586552217453505,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6693021831816289,
            "auditor_fn_violation": 0.007503645329881876,
            "auditor_fp_violation": 0.014625169496997478,
            "ave_precision_score": 0.5492623783723377,
            "fpr": 0.32821075740944017,
            "logloss": 10.103048059853867,
            "mae": 0.4046552247355674,
            "precision": 0.5746799431009957,
            "recall": 0.8614072494669509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6311433077825827,
            "auditor_fn_violation": 0.0034658166033640966,
            "auditor_fp_violation": 0.008006697070545219,
            "ave_precision_score": 0.6175591907081837,
            "fpr": 0.0625,
            "logloss": 11.639312143645224,
            "mae": 0.4330173413479934,
            "precision": 0.7397260273972602,
            "recall": 0.334020618556701
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6256098939725768,
            "auditor_fn_violation": 0.009354981404721744,
            "auditor_fp_violation": 0.009149112655279118,
            "ave_precision_score": 0.6162704837108707,
            "fpr": 0.059275521405049394,
            "logloss": 11.433980073723562,
            "mae": 0.41998671683328986,
            "precision": 0.7428571428571429,
            "recall": 0.3326226012793177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6987703177321823,
            "auditor_fn_violation": 0.008353680593235671,
            "auditor_fp_violation": 0.018789288795759897,
            "ave_precision_score": 0.5585069231014298,
            "fpr": 0.35635964912280704,
            "logloss": 10.924747513361725,
            "mae": 0.4164878196552723,
            "precision": 0.5723684210526315,
            "recall": 0.8969072164948454
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6933629136671888,
            "auditor_fn_violation": 0.006537018529744253,
            "auditor_fp_violation": 0.009779914667885227,
            "ave_precision_score": 0.5493573272147958,
            "fpr": 0.3677277716794731,
            "logloss": 11.113608128141415,
            "mae": 0.41797378158849746,
            "precision": 0.5574636723910171,
            "recall": 0.8997867803837953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5803810740313289,
            "auditor_fn_violation": 0.007035630312895649,
            "auditor_fp_violation": 0.009339434652204284,
            "ave_precision_score": 0.575360525901288,
            "fpr": 0.10416666666666667,
            "logloss": 12.083985715408142,
            "mae": 0.45477865726643996,
            "precision": 0.6441947565543071,
            "recall": 0.354639175257732
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5900345850893388,
            "auditor_fn_violation": 0.014628129542034225,
            "auditor_fp_violation": 0.01149847763136328,
            "ave_precision_score": 0.5873800593222152,
            "fpr": 0.09440175631174534,
            "logloss": 11.673544488004794,
            "mae": 0.43693597931080236,
            "precision": 0.6573705179282868,
            "recall": 0.35181236673773986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5580589935304416,
            "auditor_fn_violation": 0.007367968891300416,
            "auditor_fp_violation": 0.01896904145609927,
            "ave_precision_score": 0.5450162842128842,
            "fpr": 0.10526315789473684,
            "logloss": 12.799612409470065,
            "mae": 0.4682914449388096,
            "precision": 0.6377358490566037,
            "recall": 0.34845360824742266
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5790139638840719,
            "auditor_fn_violation": 0.009191146353850946,
            "auditor_fp_violation": 0.009238517664939825,
            "ave_precision_score": 0.5667310101372021,
            "fpr": 0.0889132821075741,
            "logloss": 12.013050359519317,
            "mae": 0.43942503565278324,
            "precision": 0.6652892561983471,
            "recall": 0.34328358208955223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.5561080980571069,
            "auditor_fn_violation": 0.008195424127328634,
            "auditor_fp_violation": 0.007765314926660913,
            "ave_precision_score": 0.5529267398309605,
            "fpr": 0.11403508771929824,
            "logloss": 11.956168938155916,
            "mae": 0.47394742317632527,
            "precision": 0.6133828996282528,
            "recall": 0.3402061855670103
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.56224714935873,
            "auditor_fn_violation": 0.012669130433765018,
            "auditor_fp_violation": 0.009943823852263188,
            "ave_precision_score": 0.5620414595379548,
            "fpr": 0.09989023051591657,
            "logloss": 11.533209721895215,
            "mae": 0.4505827258270475,
            "precision": 0.6459143968871596,
            "recall": 0.35394456289978676
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6484726869101491,
            "auditor_fn_violation": 0.009680774100198982,
            "auditor_fp_violation": 0.004866161304901602,
            "ave_precision_score": 0.6488817748212561,
            "fpr": 0.06469298245614036,
            "logloss": 11.30514415026789,
            "mae": 0.4395646241571963,
            "precision": 0.7293577981651376,
            "recall": 0.32783505154639175
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6528515657149689,
            "auditor_fn_violation": 0.009530518959226155,
            "auditor_fp_violation": 0.009022455558259783,
            "ave_precision_score": 0.6536508417633481,
            "fpr": 0.06037321624588365,
            "logloss": 11.150004059192344,
            "mae": 0.4188216683167543,
            "precision": 0.7417840375586855,
            "recall": 0.3368869936034115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.578250654103881,
            "auditor_fn_violation": 0.009719207813347829,
            "auditor_fp_violation": 0.014344262295081971,
            "ave_precision_score": 0.5762241176684805,
            "fpr": 0.08333333333333333,
            "logloss": 11.813824521722806,
            "mae": 0.45384812855678447,
            "precision": 0.680672268907563,
            "recall": 0.334020618556701
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5905445431791393,
            "auditor_fn_violation": 0.008882200257923186,
            "auditor_fp_violation": 0.010217005826226463,
            "ave_precision_score": 0.5901079598348508,
            "fpr": 0.07464324917672886,
            "logloss": 11.443733154836675,
            "mae": 0.4318396591890141,
            "precision": 0.7004405286343612,
            "recall": 0.3390191897654584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6433448757974956,
            "auditor_fn_violation": 0.010399710616748062,
            "auditor_fp_violation": 0.006596922634454993,
            "ave_precision_score": 0.6439316149950581,
            "fpr": 0.06140350877192982,
            "logloss": 11.38718444386911,
            "mae": 0.4377447940156053,
            "precision": 0.7294685990338164,
            "recall": 0.311340206185567
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6530158378368172,
            "auditor_fn_violation": 0.007901530453425225,
            "auditor_fp_violation": 0.013311412549483193,
            "ave_precision_score": 0.6537911814075823,
            "fpr": 0.06147091108671789,
            "logloss": 11.152451233152908,
            "mae": 0.41854095324423196,
            "precision": 0.7307692307692307,
            "recall": 0.32409381663113007
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6035996863156622,
            "auditor_fn_violation": 0.0102075420510038,
            "auditor_fp_violation": 0.008129956037635073,
            "ave_precision_score": 0.5810616721812322,
            "fpr": 0.11403508771929824,
            "logloss": 12.34891735338244,
            "mae": 0.4555666418582724,
            "precision": 0.6401384083044983,
            "recall": 0.38144329896907214
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6060821590068691,
            "auditor_fn_violation": 0.012376567842924338,
            "auditor_fp_violation": 0.00817062449399248,
            "ave_precision_score": 0.5908619994108356,
            "fpr": 0.10208562019758508,
            "logloss": 11.919951215041694,
            "mae": 0.4408146501493228,
            "precision": 0.6477272727272727,
            "recall": 0.3646055437100213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6350421766446113,
            "auditor_fn_violation": 0.0036127690359920414,
            "auditor_fp_violation": 0.0016537244751222294,
            "ave_precision_score": 0.5355752202072253,
            "fpr": 0.3793859649122807,
            "logloss": 8.317492782478329,
            "mae": 0.42193218466439125,
            "precision": 0.5675,
            "recall": 0.9360824742268041
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6410876767709155,
            "auditor_fn_violation": 0.009766909532625411,
            "auditor_fp_violation": 0.00996865857716894,
            "ave_precision_score": 0.5419816840172561,
            "fpr": 0.38309549945115257,
            "logloss": 7.870083463888431,
            "mae": 0.4227534341479974,
            "precision": 0.5610062893081761,
            "recall": 0.9509594882729211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5781961143565064,
            "auditor_fn_violation": 0.006732682221016479,
            "auditor_fp_violation": 0.014896359751838617,
            "ave_precision_score": 0.5761696566013765,
            "fpr": 0.08223684210526316,
            "logloss": 11.815263898150034,
            "mae": 0.4533934468651607,
            "precision": 0.6794871794871795,
            "recall": 0.32783505154639175
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.5904208356357832,
            "auditor_fn_violation": 0.008063025003569266,
            "auditor_fp_violation": 0.010217005826226463,
            "ave_precision_score": 0.5899851334625559,
            "fpr": 0.07464324917672886,
            "logloss": 11.444560405059631,
            "mae": 0.43147514513606855,
            "precision": 0.6991150442477876,
            "recall": 0.3368869936034115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6347425427140754,
            "auditor_fn_violation": 0.01200262253572076,
            "auditor_fp_violation": 0.008027240231726861,
            "ave_precision_score": 0.6353556910435427,
            "fpr": 0.0800438596491228,
            "logloss": 11.457454750622079,
            "mae": 0.4421237264270639,
            "precision": 0.6958333333333333,
            "recall": 0.3443298969072165
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6443193351656717,
            "auditor_fn_violation": 0.017116081814543403,
            "auditor_fp_violation": 0.01779159692248089,
            "ave_precision_score": 0.6451362302216526,
            "fpr": 0.07683863885839737,
            "logloss": 11.227764007493015,
            "mae": 0.425614772105429,
            "precision": 0.6982758620689655,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5804431158568422,
            "auditor_fn_violation": 0.007035630312895649,
            "auditor_fp_violation": 0.008507436624347756,
            "ave_precision_score": 0.5754223692385698,
            "fpr": 0.10307017543859649,
            "logloss": 12.083026076821493,
            "mae": 0.454679386069473,
            "precision": 0.6466165413533834,
            "recall": 0.354639175257732
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5905776175699853,
            "auditor_fn_violation": 0.014628129542034225,
            "auditor_fp_violation": 0.01149847763136328,
            "ave_precision_score": 0.5882356988399133,
            "fpr": 0.09440175631174534,
            "logloss": 11.652566392043877,
            "mae": 0.4368653089831252,
            "precision": 0.6573705179282868,
            "recall": 0.35181236673773986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 9292,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5592420237823369,
            "auditor_fn_violation": 0.0962561041779707,
            "auditor_fp_violation": 0.09000215703192409,
            "ave_precision_score": 0.5279931988753426,
            "fpr": 0.1611842105263158,
            "logloss": 6.593673453820346,
            "mae": 0.5204075256634696,
            "precision": 0.5180327868852459,
            "recall": 0.32577319587628867
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.5412355992085186,
            "auditor_fn_violation": 0.09314022642004033,
            "auditor_fp_violation": 0.09591667453099623,
            "ave_precision_score": 0.5076995462197926,
            "fpr": 0.16465422612513722,
            "logloss": 6.575759783892899,
            "mae": 0.5164951534865109,
            "precision": 0.494949494949495,
            "recall": 0.31343283582089554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6908462605878941,
            "auditor_fn_violation": 1.130403327907423e-05,
            "auditor_fp_violation": 0.001507354451703045,
            "ave_precision_score": 0.541448616221028,
            "fpr": 0.43201754385964913,
            "logloss": 11.186585444748657,
            "mae": 0.4496020760975386,
            "precision": 0.5466052934407365,
            "recall": 0.979381443298969
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.684979838271316,
            "auditor_fn_violation": 0.0017179275334164995,
            "auditor_fp_violation": 0.0005066283880773665,
            "ave_precision_score": 0.5350873651312624,
            "fpr": 0.4478594950603732,
            "logloss": 11.167267364566262,
            "mae": 0.4619655868347272,
            "precision": 0.5304948216340621,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5917539230792597,
            "auditor_fn_violation": 0.00766187375655635,
            "auditor_fp_violation": 0.0068511442540778195,
            "ave_precision_score": 0.5885512790788532,
            "fpr": 0.05921052631578947,
            "logloss": 12.283014850700914,
            "mae": 0.4435896654759072,
            "precision": 0.7157894736842105,
            "recall": 0.2804123711340206
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6032036958385172,
            "auditor_fn_violation": 0.01928806648894465,
            "auditor_fp_violation": 0.013127635585180623,
            "ave_precision_score": 0.6008797578338574,
            "fpr": 0.06147091108671789,
            "logloss": 11.836397909020098,
            "mae": 0.4271803740143929,
            "precision": 0.7052631578947368,
            "recall": 0.2857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6909947278417438,
            "auditor_fn_violation": 0.0028599204196057162,
            "auditor_fp_violation": 0.00011041949135133547,
            "ave_precision_score": 0.5391579669865052,
            "fpr": 0.4342105263157895,
            "logloss": 11.436990782579132,
            "mae": 0.45012546425008176,
            "precision": 0.5453501722158438,
            "recall": 0.979381443298969
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6855039648233946,
            "auditor_fn_violation": 0.0036090521206106844,
            "auditor_fp_violation": 0.0019867779924601808,
            "ave_precision_score": 0.5325329989197207,
            "fpr": 0.4500548847420417,
            "logloss": 11.413878663205086,
            "mae": 0.4632786041857628,
            "precision": 0.5281933256616801,
            "recall": 0.9786780383795309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5803748893516193,
            "auditor_fn_violation": 0.007035630312895649,
            "auditor_fp_violation": 0.009339434652204284,
            "ave_precision_score": 0.5753548793913752,
            "fpr": 0.10416666666666667,
            "logloss": 12.084073507993436,
            "mae": 0.45478722819289513,
            "precision": 0.6441947565543071,
            "recall": 0.354639175257732
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5900345850893388,
            "auditor_fn_violation": 0.014628129542034225,
            "auditor_fp_violation": 0.01149847763136328,
            "ave_precision_score": 0.5873800593222152,
            "fpr": 0.09440175631174534,
            "logloss": 11.673609588067924,
            "mae": 0.4369422589708306,
            "precision": 0.6573705179282868,
            "recall": 0.35181236673773986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7357281146074857,
            "auditor_fn_violation": 0.02439410381624164,
            "auditor_fp_violation": 0.026177123135708125,
            "ave_precision_score": 0.7012472782101407,
            "fpr": 0.12938596491228072,
            "logloss": 6.7158070693899194,
            "mae": 0.35387344020294,
            "precision": 0.707196029776675,
            "recall": 0.5876288659793815
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.739749395419836,
            "auditor_fn_violation": 0.029244556580434823,
            "auditor_fp_violation": 0.026121163655870187,
            "ave_precision_score": 0.7152308862712773,
            "fpr": 0.10757409440175632,
            "logloss": 6.103628472813213,
            "mae": 0.3395124403152046,
            "precision": 0.7307692307692307,
            "recall": 0.5671641791044776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5992242565190322,
            "auditor_fn_violation": 0.0029345270392476144,
            "auditor_fp_violation": 0.01173784872016106,
            "ave_precision_score": 0.5873088626493106,
            "fpr": 0.09100877192982457,
            "logloss": 12.167161831390958,
            "mae": 0.4472101908396693,
            "precision": 0.6732283464566929,
            "recall": 0.3525773195876289
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6080326724795337,
            "auditor_fn_violation": 0.010988650911976115,
            "auditor_fp_violation": 0.008091153374294077,
            "ave_precision_score": 0.6013581600218534,
            "fpr": 0.0845225027442371,
            "logloss": 11.702820240327378,
            "mae": 0.4318242893597335,
            "precision": 0.6844262295081968,
            "recall": 0.35607675906183367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 9292,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5535240190215813,
            "auditor_fn_violation": 0.001071622354856225,
            "auditor_fp_violation": 0.020799950696413168,
            "ave_precision_score": 0.5400843966062289,
            "fpr": 0.10635964912280702,
            "logloss": 12.901613291676556,
            "mae": 0.4659126503301147,
            "precision": 0.6311787072243346,
            "recall": 0.3422680412371134
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.5755159229291391,
            "auditor_fn_violation": 0.007814931926536383,
            "auditor_fp_violation": 0.009039839865693813,
            "ave_precision_score": 0.5622025929437156,
            "fpr": 0.08562019758507135,
            "logloss": 12.129973179603814,
            "mae": 0.43625051603022796,
            "precision": 0.675,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 9292,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5837224218138353,
            "auditor_fn_violation": 0.0013497015735214404,
            "auditor_fp_violation": 0.011940712436829782,
            "ave_precision_score": 0.5816095745421281,
            "fpr": 0.07785087719298246,
            "logloss": 11.776655777453897,
            "mae": 0.4479672290141362,
            "precision": 0.6801801801801802,
            "recall": 0.311340206185567
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.5935413144546011,
            "auditor_fn_violation": 0.008788580228854167,
            "auditor_fp_violation": 0.0131400529476335,
            "ave_precision_score": 0.5935820656874834,
            "fpr": 0.07135016465422613,
            "logloss": 11.438071093330725,
            "mae": 0.4277439995704532,
            "precision": 0.6976744186046512,
            "recall": 0.31982942430703626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5580432411426893,
            "auditor_fn_violation": 0.0020392476035449724,
            "auditor_fp_violation": 0.01823462344385554,
            "ave_precision_score": 0.5449995291694206,
            "fpr": 0.10416666666666667,
            "logloss": 12.800769339166743,
            "mae": 0.4669362832955493,
            "precision": 0.6303501945525292,
            "recall": 0.334020618556701
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5777558854333534,
            "auditor_fn_violation": 0.007634713370578508,
            "auditor_fp_violation": 0.008615166069805445,
            "ave_precision_score": 0.5651801039515485,
            "fpr": 0.0845225027442371,
            "logloss": 12.034251592255172,
            "mae": 0.4374063849872393,
            "precision": 0.6709401709401709,
            "recall": 0.3347547974413646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5363934994940109,
            "auditor_fn_violation": 0.017238650750587805,
            "auditor_fp_violation": 0.013332511606886071,
            "ave_precision_score": 0.5223015976195106,
            "fpr": 0.11403508771929824,
            "logloss": 13.032565802389575,
            "mae": 0.49891628888596967,
            "precision": 0.5737704918032787,
            "recall": 0.28865979381443296
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5167673869343313,
            "auditor_fn_violation": 0.0031362709738121403,
            "auditor_fp_violation": 0.00031291753381247855,
            "ave_precision_score": 0.5052401936327822,
            "fpr": 0.11855104281009879,
            "logloss": 12.838414580835693,
            "mae": 0.4927439829107182,
            "precision": 0.5537190082644629,
            "recall": 0.2857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8410156408925664,
            "auditor_fn_violation": 0.01358518719479111,
            "auditor_fp_violation": 0.01489379185669091,
            "ave_precision_score": 0.8412964301093774,
            "fpr": 0.09539473684210527,
            "logloss": 0.6959794944487543,
            "mae": 0.28125194039939017,
            "precision": 0.7972027972027972,
            "recall": 0.7051546391752578
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8529887158666423,
            "auditor_fn_violation": 0.020102560741845115,
            "auditor_fp_violation": 0.0150647441278293,
            "ave_precision_score": 0.8533722848826847,
            "fpr": 0.10318331503841932,
            "logloss": 0.6015066997893657,
            "mae": 0.26195237413382716,
            "precision": 0.7882882882882883,
            "recall": 0.746268656716418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.583147663643534,
            "auditor_fn_violation": 0.0012660517272562823,
            "auditor_fp_violation": 0.01336589424380624,
            "ave_precision_score": 0.5792386062908037,
            "fpr": 0.07346491228070176,
            "logloss": 11.976977808426438,
            "mae": 0.4535176803361984,
            "precision": 0.6981981981981982,
            "recall": 0.31958762886597936
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5977124947189395,
            "auditor_fn_violation": 0.007454494814620656,
            "auditor_fp_violation": 0.008195459218898237,
            "ave_precision_score": 0.5943971389663147,
            "fpr": 0.06695938529088913,
            "logloss": 11.438994494930373,
            "mae": 0.43135809614379306,
            "precision": 0.7136150234741784,
            "recall": 0.32409381663113007
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6041131482697095,
            "auditor_fn_violation": 0.007553355037077221,
            "auditor_fp_violation": 0.013163030527137515,
            "ave_precision_score": 0.5927764059030307,
            "fpr": 0.08223684210526316,
            "logloss": 12.10011542981833,
            "mae": 0.4488529827652025,
            "precision": 0.6887966804979253,
            "recall": 0.3422680412371134
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.610935843441465,
            "auditor_fn_violation": 0.010569701281892252,
            "auditor_fp_violation": 0.01078075408158704,
            "ave_precision_score": 0.604125254249245,
            "fpr": 0.0801317233809001,
            "logloss": 11.67103691813705,
            "mae": 0.43210489958786413,
            "precision": 0.6893617021276596,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.580685591316092,
            "auditor_fn_violation": 0.0002599927654186963,
            "auditor_fp_violation": 0.019978224249147462,
            "ave_precision_score": 0.5814260809118976,
            "fpr": 0.07785087719298246,
            "logloss": 6.888412315104516,
            "mae": 0.45326019505235604,
            "precision": 0.6858407079646017,
            "recall": 0.31958762886597936
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6170412357538148,
            "auditor_fn_violation": 0.005717843275390341,
            "auditor_fp_violation": 0.011980271294534875,
            "ave_precision_score": 0.618940604428168,
            "fpr": 0.06586169045005488,
            "logloss": 6.35571089927419,
            "mae": 0.42439204566398614,
            "precision": 0.719626168224299,
            "recall": 0.3283582089552239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6937356329717961,
            "auditor_fn_violation": 0.007539790197142342,
            "auditor_fp_violation": 0.021893874029335642,
            "ave_precision_score": 0.6842609894720577,
            "fpr": 0.31469298245614036,
            "logloss": 2.5063164358719736,
            "mae": 0.3649038137347832,
            "precision": 0.6111111111111112,
            "recall": 0.9298969072164949
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7150459215471625,
            "auditor_fn_violation": 0.004145026787030818,
            "auditor_fp_violation": 0.01355975979854073,
            "ave_precision_score": 0.7099762568883871,
            "fpr": 0.3402854006586169,
            "logloss": 2.362267990505784,
            "mae": 0.37483533955107656,
            "precision": 0.5910290237467019,
            "recall": 0.9552238805970149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5822155510995055,
            "auditor_fn_violation": 0.004182492313257385,
            "auditor_fp_violation": 0.013389005300135587,
            "ave_precision_score": 0.5814674416931925,
            "fpr": 0.0800438596491228,
            "logloss": 11.643643327426565,
            "mae": 0.44854728020432594,
            "precision": 0.683982683982684,
            "recall": 0.32577319587628867
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5972271467381975,
            "auditor_fn_violation": 0.009027311302980151,
            "auditor_fp_violation": 0.013520024238691508,
            "ave_precision_score": 0.5985018596710148,
            "fpr": 0.07683863885839737,
            "logloss": 11.326782878522566,
            "mae": 0.4273121998815068,
            "precision": 0.696969696969697,
            "recall": 0.34328358208955223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.5802631142242296,
            "auditor_fn_violation": 0.004768041237113413,
            "auditor_fp_violation": 0.008895188791651264,
            "ave_precision_score": 0.5752807302603653,
            "fpr": 0.10087719298245613,
            "logloss": 12.085458409145332,
            "mae": 0.4526475169298688,
            "precision": 0.6501901140684411,
            "recall": 0.3525773195876289
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.5899990669088573,
            "auditor_fn_violation": 0.014314502444653024,
            "auditor_fp_violation": 0.011438874291589475,
            "ave_precision_score": 0.5873092452227742,
            "fpr": 0.09549945115257959,
            "logloss": 11.676205412063135,
            "mae": 0.43548499233833493,
            "precision": 0.6533864541832669,
            "recall": 0.34968017057569295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6161309638377598,
            "auditor_fn_violation": 0.0032849520708989085,
            "auditor_fp_violation": 0.009796519988495829,
            "ave_precision_score": 0.6174629034259516,
            "fpr": 0.0537280701754386,
            "logloss": 11.676402108067421,
            "mae": 0.45051196162955204,
            "precision": 0.7292817679558011,
            "recall": 0.2721649484536082
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6238774142334182,
            "auditor_fn_violation": 0.013977470340004556,
            "auditor_fp_violation": 0.008724438859390752,
            "ave_precision_score": 0.6259873397966333,
            "fpr": 0.05378704720087816,
            "logloss": 11.435186657119997,
            "mae": 0.43508182584050786,
            "precision": 0.7247191011235955,
            "recall": 0.27505330490405117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7115832875373582,
            "auditor_fn_violation": 0.007876650388858746,
            "auditor_fp_violation": 0.021082419162660758,
            "ave_precision_score": 0.7115492148243864,
            "fpr": 0.18640350877192982,
            "logloss": 0.9227553546018836,
            "mae": 0.3170460478993431,
            "precision": 0.691470054446461,
            "recall": 0.7855670103092783
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7716817936189737,
            "auditor_fn_violation": 0.01698969477530023,
            "auditor_fp_violation": 0.020538317497057087,
            "ave_precision_score": 0.7731673497652756,
            "fpr": 0.1690450054884742,
            "logloss": 0.7556561821355071,
            "mae": 0.29400234087702587,
            "precision": 0.7158671586715867,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.5969984025224353,
            "auditor_fn_violation": 0.010377102550189903,
            "auditor_fp_violation": 0.011522145527753812,
            "ave_precision_score": 0.5973879005542148,
            "fpr": 0.08442982456140351,
            "logloss": 11.608429843008388,
            "mae": 0.4412329648809477,
            "precision": 0.6818181818181818,
            "recall": 0.3402061855670103
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6176614555728126,
            "auditor_fn_violation": 0.013982151341458002,
            "auditor_fp_violation": 0.009750112997998326,
            "ave_precision_score": 0.6197557603572383,
            "fpr": 0.08562019758507135,
            "logloss": 11.349894115841991,
            "mae": 0.4274349224385596,
            "precision": 0.675,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5836323046077507,
            "auditor_fn_violation": 0.005048381262434441,
            "auditor_fp_violation": 0.013756214306257447,
            "ave_precision_score": 0.5818204718981204,
            "fpr": 0.07456140350877193,
            "logloss": 11.71917754407339,
            "mae": 0.45102361009584885,
            "precision": 0.6977777777777778,
            "recall": 0.3237113402061856
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.597611639391213,
            "auditor_fn_violation": 0.008444526622025515,
            "auditor_fp_violation": 0.01281720152385872,
            "ave_precision_score": 0.5987142313605504,
            "fpr": 0.07135016465422613,
            "logloss": 11.334486905617565,
            "mae": 0.42945020620426944,
            "precision": 0.7085201793721974,
            "recall": 0.3368869936034115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5838095179373279,
            "auditor_fn_violation": 0.0011123168746608957,
            "auditor_fp_violation": 0.011940712436829782,
            "ave_precision_score": 0.5816966037849178,
            "fpr": 0.07785087719298246,
            "logloss": 11.778815977227106,
            "mae": 0.4480656502803687,
            "precision": 0.6772727272727272,
            "recall": 0.30721649484536084
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.5935881599799693,
            "auditor_fn_violation": 0.007690885388019923,
            "auditor_fp_violation": 0.0131400529476335,
            "ave_precision_score": 0.5936274834276618,
            "fpr": 0.07135016465422613,
            "logloss": 11.440063049736855,
            "mae": 0.42782410896671064,
            "precision": 0.6976744186046512,
            "recall": 0.31982942430703626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.653900671992481,
            "auditor_fn_violation": 0.00500768674262978,
            "auditor_fp_violation": 0.0052256666255803465,
            "ave_precision_score": 0.6541662417611873,
            "fpr": 0.043859649122807015,
            "logloss": 11.2809256466831,
            "mae": 0.4442010992124938,
            "precision": 0.7714285714285715,
            "recall": 0.27835051546391754
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6465468654192654,
            "auditor_fn_violation": 0.010759281840757029,
            "auditor_fp_violation": 0.008756724001768232,
            "ave_precision_score": 0.6473521214347295,
            "fpr": 0.048298572996706916,
            "logloss": 11.146637454560661,
            "mae": 0.4271073188667485,
            "precision": 0.7634408602150538,
            "recall": 0.302771855010661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6421493487963567,
            "auditor_fn_violation": 0.012594953879544239,
            "auditor_fp_violation": 0.012482538312995601,
            "ave_precision_score": 0.642623691252185,
            "fpr": 0.10635964912280702,
            "logloss": 11.330570883011093,
            "mae": 0.45567465586620465,
            "precision": 0.6472727272727272,
            "recall": 0.3670103092783505
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6495014753707005,
            "auditor_fn_violation": 0.007938978465052818,
            "auditor_fp_violation": 0.0053965857220199575,
            "ave_precision_score": 0.6503969482600167,
            "fpr": 0.09769484083424808,
            "logloss": 11.191446855674444,
            "mae": 0.43873548827826175,
            "precision": 0.6563706563706564,
            "recall": 0.3624733475479744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.763582675169054,
            "auditor_fn_violation": 0.004933080122987883,
            "auditor_fp_violation": 0.024264041250667657,
            "ave_precision_score": 0.7643476469060122,
            "fpr": 0.15570175438596492,
            "logloss": 0.9376187430468519,
            "mae": 0.2989331175676646,
            "precision": 0.727447216890595,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.839276218609634,
            "auditor_fn_violation": 0.010508848262997389,
            "auditor_fp_violation": 0.021347929528984615,
            "ave_precision_score": 0.8395472417797754,
            "fpr": 0.150384193194292,
            "logloss": 0.6009237480749804,
            "mae": 0.27987615472119604,
            "precision": 0.7400379506641366,
            "recall": 0.8315565031982942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.580693564473618,
            "auditor_fn_violation": 0.0002599927654186963,
            "auditor_fp_violation": 0.02146760343481655,
            "ave_precision_score": 0.5798384301444418,
            "fpr": 0.0800438596491228,
            "logloss": 6.955537202335992,
            "mae": 0.45413677210289305,
            "precision": 0.6798245614035088,
            "recall": 0.31958762886597936
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6152038983021695,
            "auditor_fn_violation": 0.009827762551520283,
            "auditor_fp_violation": 0.013574660633484165,
            "ave_precision_score": 0.6171195970653442,
            "fpr": 0.06805708013172337,
            "logloss": 6.371591937699139,
            "mae": 0.4246445994563731,
            "precision": 0.7142857142857143,
            "recall": 0.3304904051172708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 9292,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.5499836387392807,
            "auditor_fn_violation": 0.0019352504973774798,
            "auditor_fp_violation": 0.006401762603229386,
            "ave_precision_score": 0.5504400558802962,
            "fpr": 0.02631578947368421,
            "logloss": 14.164492160317131,
            "mae": 0.5397918204708687,
            "precision": 0.4,
            "recall": 0.032989690721649485
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5555727619578701,
            "auditor_fn_violation": 0.0011140783459213314,
            "auditor_fp_violation": 0.005001713596018496,
            "ave_precision_score": 0.5580432525853503,
            "fpr": 0.015367727771679473,
            "logloss": 13.604175631109584,
            "mae": 0.5141238199154518,
            "precision": 0.48148148148148145,
            "recall": 0.02771855010660981
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6429547734325658,
            "auditor_fn_violation": 0.00796708265509135,
            "auditor_fp_violation": 0.00471722338633469,
            "ave_precision_score": 0.6435428596667924,
            "fpr": 0.06359649122807018,
            "logloss": 11.385332321641886,
            "mae": 0.4388645151735723,
            "precision": 0.7184466019417476,
            "recall": 0.30515463917525776
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6543034441779411,
            "auditor_fn_violation": 0.008023236491214928,
            "auditor_fp_violation": 0.013544858963597263,
            "ave_precision_score": 0.6550726362804788,
            "fpr": 0.05817782656421515,
            "logloss": 11.146563142547851,
            "mae": 0.4189432581734075,
            "precision": 0.7401960784313726,
            "recall": 0.32196162046908317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.688587775429587,
            "auditor_fn_violation": 0.0028599204196057162,
            "auditor_fp_violation": 0.00011041949135133547,
            "ave_precision_score": 0.5390472252852011,
            "fpr": 0.4342105263157895,
            "logloss": 11.314087292695838,
            "mae": 0.44992446324370877,
            "precision": 0.5453501722158438,
            "recall": 0.979381443298969
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6789874338617012,
            "auditor_fn_violation": 0.0036090521206106844,
            "auditor_fp_violation": 0.004435481868167344,
            "ave_precision_score": 0.5284878968728964,
            "fpr": 0.4500548847420417,
            "logloss": 11.332006892530346,
            "mae": 0.4634231031585064,
            "precision": 0.5281933256616801,
            "recall": 0.9786780383795309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6948874862958918,
            "auditor_fn_violation": 0.011213601012841383,
            "auditor_fp_violation": 0.0143083117630141,
            "ave_precision_score": 0.559099933961981,
            "fpr": 0.3366228070175439,
            "logloss": 10.763824331029147,
            "mae": 0.40988232249806617,
            "precision": 0.584573748308525,
            "recall": 0.8907216494845361
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6937619583343003,
            "auditor_fn_violation": 0.013287022625620528,
            "auditor_fp_violation": 0.004599391052545308,
            "ave_precision_score": 0.5526990383544957,
            "fpr": 0.34577387486278816,
            "logloss": 10.917772104451643,
            "mae": 0.4076360624052686,
            "precision": 0.5714285714285714,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5593192256431809,
            "auditor_fn_violation": 0.0014469162597214843,
            "auditor_fp_violation": 0.019682916307161347,
            "ave_precision_score": 0.5464307916553897,
            "fpr": 0.09978070175438597,
            "logloss": 12.761768495411774,
            "mae": 0.4662885742370295,
            "precision": 0.631578947368421,
            "recall": 0.3216494845360825
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.5812278526049823,
            "auditor_fn_violation": 0.007487261824794804,
            "auditor_fp_violation": 0.011697155430609299,
            "ave_precision_score": 0.5689411689160021,
            "fpr": 0.07574094401756312,
            "logloss": 11.987524923241999,
            "mae": 0.433699089840581,
            "precision": 0.6973684210526315,
            "recall": 0.3390191897654584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.725250198301784,
            "auditor_fn_violation": 0.004842647856755292,
            "auditor_fp_violation": 0.028293068737417326,
            "ave_precision_score": 0.7069578997364898,
            "fpr": 0.2993421052631579,
            "logloss": 2.940609962789714,
            "mae": 0.35881384852498804,
            "precision": 0.6181818181818182,
            "recall": 0.911340206185567
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7191515991008819,
            "auditor_fn_violation": 0.006309989959251882,
            "auditor_fp_violation": 0.017950539161877728,
            "ave_precision_score": 0.6982892098568043,
            "fpr": 0.32821075740944017,
            "logloss": 3.1264790845267374,
            "mae": 0.370368502357347,
            "precision": 0.5943012211668928,
            "recall": 0.9339019189765458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.651027939501309,
            "auditor_fn_violation": 0.014331253391209992,
            "auditor_fp_violation": 0.014205595957105882,
            "ave_precision_score": 0.6513650781035814,
            "fpr": 0.06359649122807018,
            "logloss": 8.321154047614572,
            "mae": 0.43772926586080885,
            "precision": 0.7238095238095238,
            "recall": 0.3134020618556701
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6511002771636982,
            "auditor_fn_violation": 0.01850867974694507,
            "auditor_fp_violation": 0.018879357873352837,
            "ave_precision_score": 0.651614349652848,
            "fpr": 0.06147091108671789,
            "logloss": 7.970143161801732,
            "mae": 0.4208702129033465,
            "precision": 0.7345971563981043,
            "recall": 0.3304904051172708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6883659872363164,
            "auditor_fn_violation": 0.004333966359196976,
            "auditor_fp_violation": 0.0061860594108221366,
            "ave_precision_score": 0.6887410887932466,
            "fpr": 0.04276315789473684,
            "logloss": 8.403651794819691,
            "mae": 0.4017374136473297,
            "precision": 0.8194444444444444,
            "recall": 0.3649484536082474
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.692511845054397,
            "auditor_fn_violation": 0.006836602622765118,
            "auditor_fp_violation": 0.004748399401979825,
            "ave_precision_score": 0.690661778389694,
            "fpr": 0.03951701427003293,
            "logloss": 8.25566700834945,
            "mae": 0.3959741936599961,
            "precision": 0.8153846153846154,
            "recall": 0.3390191897654584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7920013318525561,
            "auditor_fn_violation": 0.026243443660698137,
            "auditor_fp_violation": 0.033888512264267236,
            "ave_precision_score": 0.7928473782413128,
            "fpr": 0.22039473684210525,
            "logloss": 0.8467881394139036,
            "mae": 0.3427403433373415,
            "precision": 0.665,
            "recall": 0.822680412371134
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8348964459225086,
            "auditor_fn_violation": 0.019585310081238778,
            "auditor_fp_violation": 0.029697364042298523,
            "ave_precision_score": 0.8351665457459081,
            "fpr": 0.21514818880351264,
            "logloss": 0.5792346226477901,
            "mae": 0.3250301644873095,
            "precision": 0.6711409395973155,
            "recall": 0.8528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 9292,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8071139036189394,
            "auditor_fn_violation": 0.0003685114848978121,
            "auditor_fp_violation": 0.017009737458400103,
            "ave_precision_score": 0.8074738106056111,
            "fpr": 0.18969298245614036,
            "logloss": 0.9020238384404938,
            "mae": 0.30028164061399076,
            "precision": 0.7102177554438861,
            "recall": 0.8742268041237113
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8318828334839024,
            "auditor_fn_violation": 0.005668692760129105,
            "auditor_fp_violation": 0.015079644962772748,
            "ave_precision_score": 0.8321424470423424,
            "fpr": 0.20417124039517015,
            "logloss": 0.8002382204398558,
            "mae": 0.29014548378598876,
            "precision": 0.693069306930693,
            "recall": 0.8955223880597015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5779019286678813,
            "auditor_fn_violation": 0.0019849882438053995,
            "auditor_fp_violation": 0.0077293643945930395,
            "ave_precision_score": 0.5746035346371553,
            "fpr": 0.08442982456140351,
            "logloss": 11.96694074679246,
            "mae": 0.4520284150642614,
            "precision": 0.6592920353982301,
            "recall": 0.30721649484536084
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.5864220300492551,
            "auditor_fn_violation": 0.00783131543162345,
            "auditor_fp_violation": 0.011798977802722882,
            "ave_precision_score": 0.5852819559549816,
            "fpr": 0.07793633369923161,
            "logloss": 11.57016198888612,
            "mae": 0.4327813513501795,
            "precision": 0.6743119266055045,
            "recall": 0.31343283582089554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6303752666945855,
            "auditor_fn_violation": 0.011837583649846292,
            "auditor_fp_violation": 0.004845618143719956,
            "ave_precision_score": 0.6216508613428845,
            "fpr": 0.05482456140350877,
            "logloss": 11.798352221392344,
            "mae": 0.43465012609707593,
            "precision": 0.7607655502392344,
            "recall": 0.32783505154639175
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6320205224545598,
            "auditor_fn_violation": 0.0166292576633845,
            "auditor_fp_violation": 0.013746020235333858,
            "ave_precision_score": 0.6239351995135933,
            "fpr": 0.06037321624588365,
            "logloss": 11.497511381285882,
            "mae": 0.4215169415397967,
            "precision": 0.7380952380952381,
            "recall": 0.3304904051172708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6184033930573999,
            "auditor_fn_violation": 0.0073928377645143895,
            "auditor_fp_violation": 0.011917601380500431,
            "ave_precision_score": 0.6072892438624578,
            "fpr": 0.05701754385964912,
            "logloss": 11.871786411333163,
            "mae": 0.4423265202243572,
            "precision": 0.7360406091370558,
            "recall": 0.29896907216494845
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6207468400507234,
            "auditor_fn_violation": 0.01570710037705466,
            "auditor_fp_violation": 0.016087934793946292,
            "ave_precision_score": 0.6132690898242699,
            "fpr": 0.059275521405049394,
            "logloss": 11.591371322991936,
            "mae": 0.41946545857972667,
            "precision": 0.7391304347826086,
            "recall": 0.326226012793177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6334867422134118,
            "auditor_fn_violation": 0.013393018629046845,
            "auditor_fp_violation": 0.016103270471260128,
            "ave_precision_score": 0.5490938371264622,
            "fpr": 0.22039473684210525,
            "logloss": 10.759740973552281,
            "mae": 0.43502116600447743,
            "precision": 0.593939393939394,
            "recall": 0.6061855670103092
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6220062722578341,
            "auditor_fn_violation": 0.008063025003569273,
            "auditor_fp_violation": 0.009402426849317802,
            "ave_precision_score": 0.5350277709996889,
            "fpr": 0.2217343578485181,
            "logloss": 10.923016314279646,
            "mae": 0.4250620995887425,
            "precision": 0.5935613682092555,
            "recall": 0.6289978678038379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5876931803747774,
            "auditor_fn_violation": 0.0023625429553264764,
            "auditor_fp_violation": 0.0177801060027117,
            "ave_precision_score": 0.5882576938594821,
            "fpr": 0.0756578947368421,
            "logloss": 5.840989447309968,
            "mae": 0.4529635513769978,
            "precision": 0.6877828054298643,
            "recall": 0.3134020618556701
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6238562304512925,
            "auditor_fn_violation": 0.012580191406149443,
            "auditor_fp_violation": 0.015854488379832218,
            "ave_precision_score": 0.625710992325285,
            "fpr": 0.06586169045005488,
            "logloss": 5.36975657018341,
            "mae": 0.42381641235733947,
            "precision": 0.7156398104265402,
            "recall": 0.32196162046908317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6421507917693725,
            "auditor_fn_violation": 0.006545035268583828,
            "auditor_fp_violation": 0.0018334771354616061,
            "ave_precision_score": 0.6427342239036131,
            "fpr": 0.043859649122807015,
            "logloss": 11.404970089078384,
            "mae": 0.44134582681837603,
            "precision": 0.7701149425287356,
            "recall": 0.27628865979381445
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6502349643747525,
            "auditor_fn_violation": 0.01235784383711053,
            "auditor_fp_violation": 0.01449106198250642,
            "ave_precision_score": 0.651020849283803,
            "fpr": 0.04500548847420417,
            "logloss": 11.148601147992585,
            "mae": 0.4199032492923167,
            "precision": 0.770949720670391,
            "recall": 0.2942430703624733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7971333005899846,
            "auditor_fn_violation": 0.03225492855850968,
            "auditor_fp_violation": 0.034155573359628585,
            "ave_precision_score": 0.7970985535645917,
            "fpr": 0.14144736842105263,
            "logloss": 2.3938943216834483,
            "mae": 0.2887456266457644,
            "precision": 0.736734693877551,
            "recall": 0.7443298969072165
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8067543398909448,
            "auditor_fn_violation": 0.044836972421879936,
            "auditor_fp_violation": 0.033079853574461957,
            "ave_precision_score": 0.8067049790724236,
            "fpr": 0.15148188803512624,
            "logloss": 2.1998858979808373,
            "mae": 0.2775585607576519,
            "precision": 0.7234468937875751,
            "recall": 0.7697228144989339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6549843568723264,
            "auditor_fn_violation": 0.026243443660698137,
            "auditor_fp_violation": 0.01691729323308273,
            "ave_precision_score": 0.6482387827365199,
            "fpr": 0.2675438596491228,
            "logloss": 3.0609164959829345,
            "mae": 0.3613237249731339,
            "precision": 0.6286149162861492,
            "recall": 0.8515463917525773
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6986000042009641,
            "auditor_fn_violation": 0.03269679515235489,
            "auditor_fp_violation": 0.015737765172775184,
            "ave_precision_score": 0.6931640448815117,
            "fpr": 0.2491767288693743,
            "logloss": 2.714610342594085,
            "mae": 0.3395416672943665,
            "precision": 0.6385350318471338,
            "recall": 0.8550106609808102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.766315176462901,
            "auditor_fn_violation": 0.01313076505697233,
            "auditor_fp_violation": 0.0281852171412137,
            "ave_precision_score": 0.7124791592568712,
            "fpr": 0.19188596491228072,
            "logloss": 3.4356264785644317,
            "mae": 0.31008254247570766,
            "precision": 0.6998284734133791,
            "recall": 0.8412371134020619
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7969051245292326,
            "auditor_fn_violation": 0.011028439424330442,
            "auditor_fp_violation": 0.025845498209416343,
            "ave_precision_score": 0.7520431752439688,
            "fpr": 0.2030735455543359,
            "logloss": 2.7618315037466514,
            "mae": 0.2935561434654355,
            "precision": 0.6901172529313233,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7242130090460159,
            "auditor_fn_violation": 0.004537438958220296,
            "auditor_fp_violation": 0.0269808743169399,
            "ave_precision_score": 0.7064209845910907,
            "fpr": 0.2982456140350877,
            "logloss": 2.926876672647103,
            "mae": 0.3578746410431657,
            "precision": 0.6195804195804195,
            "recall": 0.9134020618556701
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7204246078361648,
            "auditor_fn_violation": 0.004730151968712186,
            "auditor_fp_violation": 0.020200565238338877,
            "ave_precision_score": 0.7003552367283079,
            "fpr": 0.33040614709110866,
            "logloss": 3.0870823035876467,
            "mae": 0.36929764537819026,
            "precision": 0.5954301075268817,
            "recall": 0.9445628997867804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6172569043804532,
            "auditor_fn_violation": 0.0038546753481642397,
            "auditor_fp_violation": 0.012451723571223141,
            "ave_precision_score": 0.601455768084423,
            "fpr": 0.08223684210526316,
            "logloss": 11.844206421553428,
            "mae": 0.44105532813077925,
            "precision": 0.7,
            "recall": 0.36082474226804123
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6159007570134656,
            "auditor_fn_violation": 0.013921298322563133,
            "auditor_fp_violation": 0.010741018521737838,
            "ave_precision_score": 0.6056741989942143,
            "fpr": 0.07793633369923161,
            "logloss": 11.56380907614888,
            "mae": 0.42879010800478734,
            "precision": 0.70042194092827,
            "recall": 0.35394456289978676
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6193965152510139,
            "auditor_fn_violation": 0.023320220654729606,
            "auditor_fp_violation": 0.02089753071202597,
            "ave_precision_score": 0.620189036841462,
            "fpr": 0.09649122807017543,
            "logloss": 11.475686020066108,
            "mae": 0.45822287121105026,
            "precision": 0.6422764227642277,
            "recall": 0.32577319587628867
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6382561641570167,
            "auditor_fn_violation": 0.02233305793441449,
            "auditor_fp_violation": 0.024519323899449174,
            "ave_precision_score": 0.6390976203461278,
            "fpr": 0.0889132821075741,
            "logloss": 11.218629474824896,
            "mae": 0.4414285843395452,
            "precision": 0.6625,
            "recall": 0.3390191897654584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.754611026788099,
            "auditor_fn_violation": 0.011717760897088087,
            "auditor_fp_violation": 0.024749373433583965,
            "ave_precision_score": 0.7551284706486241,
            "fpr": 0.15460526315789475,
            "logloss": 0.7849237198201644,
            "mae": 0.3088761756778439,
            "precision": 0.7229862475442044,
            "recall": 0.7587628865979381
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8065724664963013,
            "auditor_fn_violation": 0.01137249303115909,
            "auditor_fp_violation": 0.0259796057239074,
            "ave_precision_score": 0.8079893477604132,
            "fpr": 0.141602634467618,
            "logloss": 0.5993270283466712,
            "mae": 0.28761688298796245,
            "precision": 0.7414829659318637,
            "recall": 0.7889125799573561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5599164693906657,
            "auditor_fn_violation": 0.009316784228612766,
            "auditor_fp_violation": 0.017882821808619914,
            "ave_precision_score": 0.5478793480053739,
            "fpr": 0.10855263157894737,
            "logloss": 12.675313045343795,
            "mae": 0.46698758709693755,
            "precision": 0.6333333333333333,
            "recall": 0.3525773195876289
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.578543341950319,
            "auditor_fn_violation": 0.0060080653655042995,
            "auditor_fp_violation": 0.009144145710297969,
            "ave_precision_score": 0.5665102274459739,
            "fpr": 0.09220636663007684,
            "logloss": 12.007682014823276,
            "mae": 0.4394611075906948,
            "precision": 0.6626506024096386,
            "recall": 0.35181236673773986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 9292,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5839377712844563,
            "auditor_fn_violation": 0.00027129679869777954,
            "auditor_fp_violation": 0.013247771067011794,
            "ave_precision_score": 0.581454315361225,
            "fpr": 0.07675438596491228,
            "logloss": 11.782130824796724,
            "mae": 0.4477413036861654,
            "precision": 0.6818181818181818,
            "recall": 0.30927835051546393
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.5904957789869025,
            "auditor_fn_violation": 0.008788580228854167,
            "auditor_fp_violation": 0.013808107047598236,
            "ave_precision_score": 0.5907695104671427,
            "fpr": 0.07025246981339188,
            "logloss": 11.443268109642748,
            "mae": 0.42738853366438534,
            "precision": 0.7009345794392523,
            "recall": 0.31982942430703626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5638129642590632,
            "auditor_fn_violation": 0.004356574425755136,
            "auditor_fp_violation": 0.013992460659846342,
            "ave_precision_score": 0.5745570446622991,
            "fpr": 0.08223684210526316,
            "logloss": 11.839914373954933,
            "mae": 0.4545882372583851,
            "precision": 0.6753246753246753,
            "recall": 0.3216494845360825
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5856520986656335,
            "auditor_fn_violation": 0.0073070432688369285,
            "auditor_fp_violation": 0.009928923017319739,
            "ave_precision_score": 0.5921419067197956,
            "fpr": 0.07244785949506037,
            "logloss": 11.410199034996152,
            "mae": 0.43243025894434023,
            "precision": 0.6986301369863014,
            "recall": 0.326226012793177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5713469638207505,
            "auditor_fn_violation": 0.00809142702116116,
            "auditor_fp_violation": 0.010443629565717576,
            "ave_precision_score": 0.557925136945481,
            "fpr": 0.09978070175438597,
            "logloss": 12.570717513750258,
            "mae": 0.4623933673893477,
            "precision": 0.6472868217054264,
            "recall": 0.3443298969072165
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.5801962865082811,
            "auditor_fn_violation": 0.01488324412124732,
            "auditor_fp_violation": 0.008115988099199825,
            "ave_precision_score": 0.5693498922099284,
            "fpr": 0.0867178924259056,
            "logloss": 12.010611681684697,
            "mae": 0.4405950495460031,
            "precision": 0.6735537190082644,
            "recall": 0.34754797441364604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6433124909767431,
            "auditor_fn_violation": 0.008281334780249604,
            "auditor_fp_violation": 0.009529458893134475,
            "ave_precision_score": 0.6438579108817075,
            "fpr": 0.06578947368421052,
            "logloss": 11.30405790286984,
            "mae": 0.4409703456969286,
            "precision": 0.7235023041474654,
            "recall": 0.3237113402061856
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6504781043159379,
            "auditor_fn_violation": 0.009715418516637478,
            "auditor_fp_violation": 0.008145789769086729,
            "ave_precision_score": 0.651319853918455,
            "fpr": 0.06147091108671789,
            "logloss": 11.152505066753728,
            "mae": 0.41963126124767125,
            "precision": 0.7358490566037735,
            "recall": 0.3326226012793177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6964231434889508,
            "auditor_fn_violation": 0.009897811539157171,
            "auditor_fp_violation": 0.013160462631989812,
            "ave_precision_score": 0.5597002611121145,
            "fpr": 0.3432017543859649,
            "logloss": 10.846357500781586,
            "mae": 0.413544767820577,
            "precision": 0.5809906291834003,
            "recall": 0.8948453608247423
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6947889487800458,
            "auditor_fn_violation": 0.012769771965014196,
            "auditor_fp_violation": 0.008483542027804974,
            "ave_precision_score": 0.5529560167694321,
            "fpr": 0.3556531284302964,
            "logloss": 10.988682601402258,
            "mae": 0.4124710346460146,
            "precision": 0.5651006711409396,
            "recall": 0.8976545842217484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5952926068078612,
            "auditor_fn_violation": 0.010377102550189903,
            "auditor_fp_violation": 0.012549303586835946,
            "ave_precision_score": 0.595006762954873,
            "fpr": 0.08114035087719298,
            "logloss": 11.631420227074674,
            "mae": 0.4417631564861287,
            "precision": 0.6903765690376569,
            "recall": 0.3402061855670103
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6141813898962997,
            "auditor_fn_violation": 0.014106197879974445,
            "auditor_fp_violation": 0.009380075596902614,
            "ave_precision_score": 0.6162966820851083,
            "fpr": 0.0845225027442371,
            "logloss": 11.348722345239395,
            "mae": 0.4274914741064485,
            "precision": 0.6764705882352942,
            "recall": 0.34328358208955223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.604232258864079,
            "auditor_fn_violation": 0.007171278712244548,
            "auditor_fp_violation": 0.01585418464193271,
            "ave_precision_score": 0.5875039497839322,
            "fpr": 0.08771929824561403,
            "logloss": 12.17457681744645,
            "mae": 0.4482826670614406,
            "precision": 0.678714859437751,
            "recall": 0.34845360824742266
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6066201840320201,
            "auditor_fn_violation": 0.010569701281892252,
            "auditor_fp_violation": 0.008900765406221596,
            "ave_precision_score": 0.5953639714630916,
            "fpr": 0.07683863885839737,
            "logloss": 11.720410429914136,
            "mae": 0.43019533130436377,
            "precision": 0.6982758620689655,
            "recall": 0.34541577825159914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 9292,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8086399217078876,
            "auditor_fn_violation": 0.004209621993127151,
            "auditor_fp_violation": 0.013024364189161424,
            "ave_precision_score": 0.8089452146462757,
            "fpr": 0.16337719298245615,
            "logloss": 0.8517420469846916,
            "mae": 0.29491743753488553,
            "precision": 0.7315315315315315,
            "recall": 0.8371134020618557
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8324246502703191,
            "auditor_fn_violation": 0.005582094233240263,
            "auditor_fp_violation": 0.017525865365989348,
            "ave_precision_score": 0.8327822519170807,
            "fpr": 0.17014270032930845,
            "logloss": 0.7486257995713669,
            "mae": 0.28266289325698835,
            "precision": 0.7256637168141593,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5574353260235104,
            "auditor_fn_violation": 0.004177970699945756,
            "auditor_fp_violation": 0.01925150992234685,
            "ave_precision_score": 0.5443922816374358,
            "fpr": 0.1118421052631579,
            "logloss": 12.807516708652532,
            "mae": 0.46854421667133767,
            "precision": 0.6236162361623616,
            "recall": 0.34845360824742266
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5784782713019131,
            "auditor_fn_violation": 0.009191146353850946,
            "auditor_fp_violation": 0.008478575082823809,
            "ave_precision_score": 0.5661960251818301,
            "fpr": 0.08781558726673985,
            "logloss": 12.022933214816875,
            "mae": 0.43957506595782603,
            "precision": 0.6680497925311203,
            "recall": 0.34328358208955223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6429814865341921,
            "auditor_fn_violation": 0.010184933984445659,
            "auditor_fp_violation": 0.0051511976662968915,
            "ave_precision_score": 0.64356940833972,
            "fpr": 0.0625,
            "logloss": 11.38802912012214,
            "mae": 0.4382439099883417,
            "precision": 0.7246376811594203,
            "recall": 0.30927835051546393
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6539176138123004,
            "auditor_fn_violation": 0.007618329865491416,
            "auditor_fp_violation": 0.013544858963597263,
            "ave_precision_score": 0.6546878416981088,
            "fpr": 0.05817782656421515,
            "logloss": 11.149357733840874,
            "mae": 0.41842223031621134,
            "precision": 0.7427184466019418,
            "recall": 0.326226012793177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6523260995543649,
            "auditor_fn_violation": 0.007521703743895837,
            "auditor_fp_violation": 0.01020224742183327,
            "ave_precision_score": 0.6526270928798799,
            "fpr": 0.05921052631578947,
            "logloss": 11.292207875027309,
            "mae": 0.438524778915994,
            "precision": 0.7378640776699029,
            "recall": 0.3134020618556701
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.6514197541979965,
            "auditor_fn_violation": 0.014007896849452002,
            "auditor_fp_violation": 0.01269302789932996,
            "ave_precision_score": 0.6522111049752528,
            "fpr": 0.05159165751920966,
            "logloss": 11.148268139106975,
            "mae": 0.41769067091871415,
            "precision": 0.7661691542288557,
            "recall": 0.3283582089552239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.644501550801283,
            "auditor_fn_violation": 0.009958853318864187,
            "auditor_fp_violation": 0.0036592505854800956,
            "ave_precision_score": 0.6450853651649527,
            "fpr": 0.06030701754385965,
            "logloss": 11.384469217232494,
            "mae": 0.43733910098113254,
            "precision": 0.729064039408867,
            "recall": 0.30515463917525776
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6541016989861481,
            "auditor_fn_violation": 0.008542827652547989,
            "auditor_fp_violation": 0.016728670696514698,
            "ave_precision_score": 0.6548702705031608,
            "fpr": 0.06147091108671789,
            "logloss": 11.149052649451402,
            "mae": 0.4187940382243348,
            "precision": 0.7294685990338164,
            "recall": 0.32196162046908317
        }
    }
]