[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8378012223581699,
            "auditor_fn_violation": 0.00710185389945452,
            "auditor_fp_violation": 0.017169141316594246,
            "ave_precision_score": 0.8380546122619303,
            "fpr": 0.1699561403508772,
            "logloss": 0.7864382527510525,
            "mae": 0.2683651645876156,
            "precision": 0.7181818181818181,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8423590516725479,
            "auditor_fn_violation": 0.015459585080535895,
            "auditor_fp_violation": 0.02506952489840619,
            "ave_precision_score": 0.8427297767603907,
            "fpr": 0.15806805708013172,
            "logloss": 0.7678670573646345,
            "mae": 0.2587181785549261,
            "precision": 0.7372262773722628,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.830897965116799,
            "auditor_fn_violation": 0.007293048798466757,
            "auditor_fp_violation": 0.010615342829550943,
            "ave_precision_score": 0.8321684122334094,
            "fpr": 0.13486842105263158,
            "logloss": 0.5717961934596828,
            "mae": 0.29341628706989514,
            "precision": 0.7564356435643564,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8342526635352447,
            "auditor_fn_violation": 0.005052151987103238,
            "auditor_fp_violation": 0.0011914932452473388,
            "ave_precision_score": 0.8354994572469503,
            "fpr": 0.1141602634467618,
            "logloss": 0.5740229803352387,
            "mae": 0.28415089512180486,
            "precision": 0.7833333333333333,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8516937493581749,
            "auditor_fn_violation": 0.007965686274509809,
            "auditor_fp_violation": 0.0012775631739900257,
            "ave_precision_score": 0.8522189392941993,
            "fpr": 0.1162280701754386,
            "logloss": 0.47741034252095754,
            "mae": 0.2998681154072473,
            "precision": 0.7823408624229979,
            "recall": 0.8004201680672269
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8743230042426715,
            "auditor_fn_violation": 0.01242829388827396,
            "auditor_fp_violation": 0.007792872842319813,
            "ave_precision_score": 0.8745102331336951,
            "fpr": 0.10647639956092206,
            "logloss": 0.4631171588809697,
            "mae": 0.29729600180181726,
            "precision": 0.7949260042283298,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8111481346748702,
            "auditor_fn_violation": 0.00395520050125314,
            "auditor_fp_violation": 0.01704088202156768,
            "ave_precision_score": 0.8114601836050095,
            "fpr": 0.14692982456140352,
            "logloss": 0.9261844763104247,
            "mae": 0.2810739658683135,
            "precision": 0.7303822937625755,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8272195264523603,
            "auditor_fn_violation": 0.010862126772271951,
            "auditor_fp_violation": 0.022491336323051853,
            "ave_precision_score": 0.8273065833679129,
            "fpr": 0.13391877058177826,
            "logloss": 0.8923254999147008,
            "mae": 0.26461858651022513,
            "precision": 0.7510204081632653,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 15860,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6810636213786019,
            "auditor_fn_violation": 0.0108359133126935,
            "auditor_fp_violation": 0.024862184130049907,
            "ave_precision_score": 0.6836354690632578,
            "fpr": 0.1699561403508772,
            "logloss": 0.6581477471442203,
            "mae": 0.4045904185760791,
            "precision": 0.6843177189409368,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7282055597692654,
            "auditor_fn_violation": 0.008048996688544016,
            "auditor_fp_violation": 0.03721515072389553,
            "ave_precision_score": 0.7295919838619858,
            "fpr": 0.17453347969264543,
            "logloss": 0.6225849590060902,
            "mae": 0.3925267531936242,
            "precision": 0.6832669322709163,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8209437428341595,
            "auditor_fn_violation": 0.014024030664897538,
            "auditor_fp_violation": 0.008676364075325927,
            "ave_precision_score": 0.8224909878376132,
            "fpr": 0.11074561403508772,
            "logloss": 0.5089835059273469,
            "mae": 0.29349131781552723,
            "precision": 0.7846481876332623,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8488338518921612,
            "auditor_fn_violation": 0.009270698896334436,
            "auditor_fp_violation": 0.009248015656728262,
            "ave_precision_score": 0.8491348085468551,
            "fpr": 0.09220636663007684,
            "logloss": 0.5093610401716862,
            "mae": 0.2909596715552853,
            "precision": 0.8129175946547884,
            "recall": 0.7635983263598326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8599328670783457,
            "auditor_fn_violation": 0.016661598850066343,
            "auditor_fp_violation": 0.007122163206180591,
            "ave_precision_score": 0.8601749867602307,
            "fpr": 0.09649122807017543,
            "logloss": 0.4995809601751822,
            "mae": 0.2924083879025012,
            "precision": 0.7995444191343963,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.866008933139685,
            "auditor_fn_violation": 0.017356438508421022,
            "auditor_fp_violation": 0.01042429834990861,
            "ave_precision_score": 0.8662345287289518,
            "fpr": 0.0801317233809001,
            "logloss": 0.5058015625068345,
            "mae": 0.2912511508878623,
            "precision": 0.8240963855421687,
            "recall": 0.7154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8494959921331736,
            "auditor_fn_violation": 0.0021745540321391733,
            "auditor_fp_violation": 0.010713423466924193,
            "ave_precision_score": 0.8495654109231641,
            "fpr": 0.09649122807017543,
            "logloss": 0.49825688492822523,
            "mae": 0.30912468950427546,
            "precision": 0.8035714285714286,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8694680232692676,
            "auditor_fn_violation": 0.005814567650611545,
            "auditor_fp_violation": 0.012485328154985388,
            "ave_precision_score": 0.8695915445496583,
            "fpr": 0.07683863885839737,
            "logloss": 0.4775829900790587,
            "mae": 0.30023766883968916,
            "precision": 0.8360655737704918,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8619927491292496,
            "auditor_fn_violation": 0.009011499336576736,
            "auditor_fp_violation": 0.007773519233864479,
            "ave_precision_score": 0.8622085225419813,
            "fpr": 0.11732456140350878,
            "logloss": 0.4812646700892236,
            "mae": 0.2982872946401282,
            "precision": 0.7811860940695297,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8704982102765196,
            "auditor_fn_violation": 0.00859784410896114,
            "auditor_fp_violation": 0.011405378958229294,
            "ave_precision_score": 0.8706922834840931,
            "fpr": 0.10428100987925357,
            "logloss": 0.47553040983756245,
            "mae": 0.29892282718516533,
            "precision": 0.7991543340380549,
            "recall": 0.7907949790794979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8275769859792773,
            "auditor_fn_violation": 0.00598463069438302,
            "auditor_fp_violation": 0.0035510220505391957,
            "ave_precision_score": 0.8288745903343782,
            "fpr": 0.1162280701754386,
            "logloss": 0.6217556344800216,
            "mae": 0.28258961065832183,
            "precision": 0.7680525164113785,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8447433435768097,
            "auditor_fn_violation": 0.014058761120475454,
            "auditor_fp_violation": 0.017859723218654224,
            "ave_precision_score": 0.84498394386248,
            "fpr": 0.10098792535675083,
            "logloss": 0.6170439066849273,
            "mae": 0.2784102443554282,
            "precision": 0.7932584269662921,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8217996673925116,
            "auditor_fn_violation": 0.005611455108359137,
            "auditor_fp_violation": 0.013831884757765976,
            "ave_precision_score": 0.822112924151881,
            "fpr": 0.1425438596491228,
            "logloss": 0.8621360642722085,
            "mae": 0.27519841859192645,
            "precision": 0.7368421052631579,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8365893417339189,
            "auditor_fn_violation": 0.012781944527371187,
            "auditor_fp_violation": 0.018952347875466145,
            "ave_precision_score": 0.8367953711057596,
            "fpr": 0.13611416026344675,
            "logloss": 0.8317370195570437,
            "mae": 0.2618149703412576,
            "precision": 0.75,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.862116196038438,
            "auditor_fn_violation": 0.00843100398053959,
            "auditor_fp_violation": 0.00904605263157895,
            "ave_precision_score": 0.8623335258313579,
            "fpr": 0.11951754385964912,
            "logloss": 0.48211325818623824,
            "mae": 0.30012325534756346,
            "precision": 0.7789046653144016,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8694544431310146,
            "auditor_fn_violation": 0.007401402661106243,
            "auditor_fp_violation": 0.011463686074486078,
            "ave_precision_score": 0.8696542798603527,
            "fpr": 0.10867178924259056,
            "logloss": 0.47672009831534606,
            "mae": 0.30101742101863893,
            "precision": 0.7946058091286307,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8480666837383175,
            "auditor_fn_violation": 0.009545923632610939,
            "auditor_fp_violation": 0.0017503621438918415,
            "ave_precision_score": 0.8487109245612916,
            "fpr": 0.1118421052631579,
            "logloss": 0.481147850736081,
            "mae": 0.30097272668596514,
            "precision": 0.7875,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8718717785172083,
            "auditor_fn_violation": 0.014667315791649259,
            "auditor_fp_violation": 0.008697900690305556,
            "ave_precision_score": 0.8720887293063722,
            "fpr": 0.10757409440175632,
            "logloss": 0.46945436822101777,
            "mae": 0.29846514971021043,
            "precision": 0.7919320594479831,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7976109591336384,
            "auditor_fn_violation": 0.01206140350877193,
            "auditor_fp_violation": 0.014913286657009497,
            "ave_precision_score": 0.7980540945871911,
            "fpr": 0.1337719298245614,
            "logloss": 0.9034267008080534,
            "mae": 0.2909628243441714,
            "precision": 0.7404255319148936,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8125351723091458,
            "auditor_fn_violation": 0.013927864455355052,
            "auditor_fp_violation": 0.022032484669031065,
            "ave_precision_score": 0.8128880760441424,
            "fpr": 0.13062568605927552,
            "logloss": 0.8791954425887597,
            "mae": 0.28014673238105425,
            "precision": 0.7468085106382979,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.841602047407117,
            "auditor_fn_violation": 0.01289759324782545,
            "auditor_fp_violation": 0.009541485594720752,
            "ave_precision_score": 0.8419032135900479,
            "fpr": 0.11732456140350878,
            "logloss": 0.6651436897026617,
            "mae": 0.26517716959945353,
            "precision": 0.7752100840336135,
            "recall": 0.7752100840336135
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8590806380764504,
            "auditor_fn_violation": 0.014701762282470417,
            "auditor_fp_violation": 0.014774516241066968,
            "ave_precision_score": 0.8593232900243164,
            "fpr": 0.10208562019758508,
            "logloss": 0.6308406830536273,
            "mae": 0.251139484044174,
            "precision": 0.7987012987012987,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8447830902479929,
            "auditor_fn_violation": 0.013461963732861574,
            "auditor_fp_violation": 0.007164916304522775,
            "ave_precision_score": 0.845117862674017,
            "fpr": 0.09978070175438597,
            "logloss": 0.6416074673219253,
            "mae": 0.2682697686956561,
            "precision": 0.7959641255605381,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8617846415754304,
            "auditor_fn_violation": 0.02185974307510713,
            "auditor_fp_violation": 0.01165128288331225,
            "ave_precision_score": 0.8619866770446545,
            "fpr": 0.08781558726673985,
            "logloss": 0.6147664718017071,
            "mae": 0.2595587470848858,
            "precision": 0.8135198135198135,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8251545078118523,
            "auditor_fn_violation": 0.020893225711337168,
            "auditor_fp_violation": 0.005241026879124415,
            "ave_precision_score": 0.825272176186542,
            "fpr": 0.10855263157894737,
            "logloss": 1.6150250229120595,
            "mae": 0.28032034261526767,
            "precision": 0.775,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8460983221994007,
            "auditor_fn_violation": 0.025410028062407854,
            "auditor_fp_violation": 0.020643254246912893,
            "ave_precision_score": 0.8460893881979141,
            "fpr": 0.08342480790340286,
            "logloss": 1.7313917992175,
            "mae": 0.268073366695566,
            "precision": 0.8177458033573142,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7384467417024556,
            "auditor_fn_violation": 0.014816452896948256,
            "auditor_fp_violation": 0.008238773539352973,
            "ave_precision_score": 0.7281290188567684,
            "fpr": 0.10635964912280702,
            "logloss": 2.241901964623805,
            "mae": 0.3199826598722945,
            "precision": 0.7820224719101123,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7170830110163632,
            "auditor_fn_violation": 0.012350215175745997,
            "auditor_fp_violation": 0.017907889966866354,
            "ave_precision_score": 0.7035405313495858,
            "fpr": 0.11086717892425905,
            "logloss": 2.6908024418935135,
            "mae": 0.3292639760768734,
            "precision": 0.7709750566893424,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8437775331176705,
            "auditor_fn_violation": 0.01024620374465576,
            "auditor_fp_violation": 0.015539493803315626,
            "ave_precision_score": 0.8440139615062667,
            "fpr": 0.15899122807017543,
            "logloss": 0.7700213948161303,
            "mae": 0.2643530039504634,
            "precision": 0.7274436090225563,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8480275449576278,
            "auditor_fn_violation": 0.014361890239701653,
            "auditor_fp_violation": 0.02056213130255563,
            "ave_precision_score": 0.8483819181227824,
            "fpr": 0.14818880351262348,
            "logloss": 0.7519218359876915,
            "mae": 0.25364005263296285,
            "precision": 0.7495361781076066,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8392332922445955,
            "auditor_fn_violation": 0.0059546845053811024,
            "auditor_fp_violation": 0.012554321583775953,
            "ave_precision_score": 0.83956316517329,
            "fpr": 0.1206140350877193,
            "logloss": 0.645732988943205,
            "mae": 0.2738773171894957,
            "precision": 0.7634408602150538,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8582228991583425,
            "auditor_fn_violation": 0.010304093620969195,
            "auditor_fp_violation": 0.015327166299500842,
            "ave_precision_score": 0.8581676440642978,
            "fpr": 0.08781558726673985,
            "logloss": 0.614948714106659,
            "mae": 0.2587902437135528,
            "precision": 0.8194130925507901,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8434646430232142,
            "auditor_fn_violation": 0.0005689775910364205,
            "auditor_fp_violation": 0.009893569934009337,
            "ave_precision_score": 0.843772927281224,
            "fpr": 0.09100877192982457,
            "logloss": 0.5002359847189499,
            "mae": 0.29906192864495607,
            "precision": 0.8087557603686636,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8625475160425295,
            "auditor_fn_violation": 0.007614970904197427,
            "auditor_fp_violation": 0.0070424856070151086,
            "ave_precision_score": 0.8627988467784696,
            "fpr": 0.07903402854006586,
            "logloss": 0.48511704185776455,
            "mae": 0.294237567587223,
            "precision": 0.8281622911694511,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.845331548666617,
            "auditor_fn_violation": 0.009202694235588985,
            "auditor_fp_violation": 0.007876629647513282,
            "ave_precision_score": 0.8456462056350083,
            "fpr": 0.08771929824561403,
            "logloss": 0.5705828904672099,
            "mae": 0.2844400072682587,
            "precision": 0.8081534772182254,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8536865237708343,
            "auditor_fn_violation": 0.010173196955848784,
            "auditor_fp_violation": 0.00960799872231363,
            "ave_precision_score": 0.8539785538962918,
            "fpr": 0.07244785949506037,
            "logloss": 0.5605223522389379,
            "mae": 0.27698689291994094,
            "precision": 0.835820895522388,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7402916385622726,
            "auditor_fn_violation": 0.01931529190623618,
            "auditor_fp_violation": 0.006619185578625462,
            "ave_precision_score": 0.7299743429600314,
            "fpr": 0.1074561403508772,
            "logloss": 2.2405435509781695,
            "mae": 0.3200171411940174,
            "precision": 0.7836644591611479,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7213248143519384,
            "auditor_fn_violation": 0.014961259179989805,
            "auditor_fp_violation": 0.01936810296529713,
            "ave_precision_score": 0.7077753463075295,
            "fpr": 0.10867178924259056,
            "logloss": 2.683915101668954,
            "mae": 0.3273925340410351,
            "precision": 0.7819383259911894,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8494402891719202,
            "auditor_fn_violation": 0.0050493881763231645,
            "auditor_fp_violation": 0.00993380814421375,
            "ave_precision_score": 0.8499294056446931,
            "fpr": 0.10635964912280702,
            "logloss": 0.5111840495818546,
            "mae": 0.2992338483444448,
            "precision": 0.7820224719101123,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8675294159726019,
            "auditor_fn_violation": 0.010935612619357098,
            "auditor_fp_violation": 0.01050035111024355,
            "ave_precision_score": 0.8677603610701723,
            "fpr": 0.07793633369923161,
            "logloss": 0.4995216512394206,
            "mae": 0.2884195789589488,
            "precision": 0.8325471698113207,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8527302714980696,
            "auditor_fn_violation": 0.0032802594722099398,
            "auditor_fp_violation": 0.005087618702720103,
            "ave_precision_score": 0.8530873178777656,
            "fpr": 0.0668859649122807,
            "logloss": 0.5149782898045686,
            "mae": 0.3024686190918529,
            "precision": 0.8447837150127226,
            "recall": 0.6974789915966386
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8598464599267528,
            "auditor_fn_violation": 0.006069471682688112,
            "auditor_fp_violation": 0.00706530143511559,
            "ave_precision_score": 0.8600959142774571,
            "fpr": 0.06037321624588365,
            "logloss": 0.5176351483128243,
            "mae": 0.3040813802916283,
            "precision": 0.8537234042553191,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 15860,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8430041599684803,
            "auditor_fn_violation": 0.00980392156862745,
            "auditor_fp_violation": 0.01658820215676807,
            "ave_precision_score": 0.8435593498870615,
            "fpr": 0.1118421052631579,
            "logloss": 0.5135550213867254,
            "mae": 0.30002445932538985,
            "precision": 0.7743362831858407,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8687864311788274,
            "auditor_fn_violation": 0.013156263060961114,
            "auditor_fp_violation": 0.011707054907557872,
            "ave_precision_score": 0.8690015266985697,
            "fpr": 0.08232711306256861,
            "logloss": 0.5004196491195749,
            "mae": 0.2888278344904996,
            "precision": 0.8255813953488372,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8124406466872048,
            "auditor_fn_violation": 0.0052336724163349595,
            "auditor_fp_violation": 0.010268288266537907,
            "ave_precision_score": 0.8126863832387041,
            "fpr": 0.14583333333333334,
            "logloss": 0.8247721050032393,
            "mae": 0.2824940081901253,
            "precision": 0.7302231237322515,
            "recall": 0.7563025210084033
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8257778901600954,
            "auditor_fn_violation": 0.008363607971377264,
            "auditor_fp_violation": 0.022012203932941746,
            "ave_precision_score": 0.8259013101473014,
            "fpr": 0.14050493962678376,
            "logloss": 0.8111151950354869,
            "mae": 0.27219806258024676,
            "precision": 0.7434869739478958,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8376176683366597,
            "auditor_fn_violation": 0.014166850950906688,
            "auditor_fp_violation": 0.00969740865926284,
            "ave_precision_score": 0.8351229638186588,
            "fpr": 0.07894736842105263,
            "logloss": 0.507599045408999,
            "mae": 0.31914513696213825,
            "precision": 0.8208955223880597,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8614685322214644,
            "auditor_fn_violation": 0.009874660702065424,
            "auditor_fp_violation": 0.005820571257633797,
            "ave_precision_score": 0.8552997742476636,
            "fpr": 0.06695938529088913,
            "logloss": 0.5021686167546359,
            "mae": 0.32008736077839206,
            "precision": 0.8459595959595959,
            "recall": 0.700836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 15860,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8551096192786709,
            "auditor_fn_violation": 0.010485773256671096,
            "auditor_fp_violation": 0.004531828424271701,
            "ave_precision_score": 0.8552549442523532,
            "fpr": 0.13048245614035087,
            "logloss": 0.5379166479460262,
            "mae": 0.27651659597512934,
            "precision": 0.7634194831013916,
            "recall": 0.8067226890756303
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8618650538199617,
            "auditor_fn_violation": 0.019143063165678438,
            "auditor_fp_violation": 0.01701807267094759,
            "ave_precision_score": 0.8619930105868119,
            "fpr": 0.12403951701427003,
            "logloss": 0.532947100122149,
            "mae": 0.2726320917833122,
            "precision": 0.7717171717171717,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8251118095635365,
            "auditor_fn_violation": 0.013855871295886786,
            "auditor_fp_violation": 0.005291324641879932,
            "ave_precision_score": 0.8254837289889302,
            "fpr": 0.09868421052631579,
            "logloss": 0.6871972279095616,
            "mae": 0.28104048268562065,
            "precision": 0.7902097902097902,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8394678492069598,
            "auditor_fn_violation": 0.014683390820699133,
            "auditor_fp_violation": 0.01891432149529867,
            "ave_precision_score": 0.8397572746695121,
            "fpr": 0.09001097694840834,
            "logloss": 0.6753954902875849,
            "mae": 0.2721849418558027,
            "precision": 0.8038277511961722,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8113028481511019,
            "auditor_fn_violation": 0.006984372696446999,
            "auditor_fp_violation": 0.009458494286174155,
            "ave_precision_score": 0.8116546733585939,
            "fpr": 0.13925438596491227,
            "logloss": 0.82287147033181,
            "mae": 0.28299194994482235,
            "precision": 0.7370600414078675,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8253226350943612,
            "auditor_fn_violation": 0.017811132187260312,
            "auditor_fp_violation": 0.019385848609375284,
            "ave_precision_score": 0.8254494815217712,
            "fpr": 0.13391877058177826,
            "logloss": 0.807931379360787,
            "mae": 0.27300179951328785,
            "precision": 0.7463617463617463,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8407973433958709,
            "auditor_fn_violation": 0.006461466165413538,
            "auditor_fp_violation": 0.012071463061323034,
            "ave_precision_score": 0.8410372482774935,
            "fpr": 0.16447368421052633,
            "logloss": 0.7443029516547005,
            "mae": 0.26952880247386923,
            "precision": 0.722735674676525,
            "recall": 0.8214285714285714
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.84228135229675,
            "auditor_fn_violation": 0.0121986506161329,
            "auditor_fp_violation": 0.025120226738629483,
            "ave_precision_score": 0.8426547350391388,
            "fpr": 0.15587266739846323,
            "logloss": 0.7350965865033345,
            "mae": 0.2595372426060048,
            "precision": 0.7389705882352942,
            "recall": 0.8410041841004184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.851042192982165,
            "auditor_fn_violation": 0.014457098628925254,
            "auditor_fp_violation": 0.010980001609528415,
            "ave_precision_score": 0.8513666158893369,
            "fpr": 0.1611842105263158,
            "logloss": 0.5008695799549788,
            "mae": 0.31200365785033474,
            "precision": 0.738898756660746,
            "recall": 0.8739495798319328
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8513687658362885,
            "auditor_fn_violation": 0.017080866581851754,
            "auditor_fp_violation": 0.016683440525473877,
            "ave_precision_score": 0.8517606990720681,
            "fpr": 0.17453347969264543,
            "logloss": 0.5002601628164097,
            "mae": 0.31254652359867396,
            "precision": 0.7225130890052356,
            "recall": 0.8661087866108786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.819853996305687,
            "auditor_fn_violation": 0.014411027568922314,
            "auditor_fp_violation": 0.005925076452599389,
            "ave_precision_score": 0.820190424700664,
            "fpr": 0.1074561403508772,
            "logloss": 0.8131881355384486,
            "mae": 0.28474766511682287,
            "precision": 0.776255707762557,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8306685076426172,
            "auditor_fn_violation": 0.015140380932259823,
            "auditor_fp_violation": 0.019657103454569884,
            "ave_precision_score": 0.8309606736311064,
            "fpr": 0.10098792535675083,
            "logloss": 0.8031619150167768,
            "mae": 0.2764938137829605,
            "precision": 0.7875288683602771,
            "recall": 0.7133891213389121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8225672658436205,
            "auditor_fn_violation": 0.018884527495208612,
            "auditor_fp_violation": 0.005703766296475134,
            "ave_precision_score": 0.8226581560527382,
            "fpr": 0.10964912280701754,
            "logloss": 1.638249677012699,
            "mae": 0.28082452021880805,
            "precision": 0.7722095671981777,
            "recall": 0.7121848739495799
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.842349481026784,
            "auditor_fn_violation": 0.026418162027107093,
            "auditor_fp_violation": 0.020643254246912893,
            "ave_precision_score": 0.8423539968513205,
            "fpr": 0.08342480790340286,
            "logloss": 1.7551921572946505,
            "mae": 0.2684499783145828,
            "precision": 0.8164251207729468,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8455112311744233,
            "auditor_fn_violation": 0.004791390240306653,
            "auditor_fp_violation": 0.007061805890873974,
            "ave_precision_score": 0.8457909489024779,
            "fpr": 0.08442982456140351,
            "logloss": 0.5887698904685952,
            "mae": 0.28263779373599773,
            "precision": 0.8098765432098766,
            "recall": 0.6890756302521008
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8600497234358719,
            "auditor_fn_violation": 0.01027423999559085,
            "auditor_fp_violation": 0.01727665205608638,
            "ave_precision_score": 0.8602923019140509,
            "fpr": 0.06695938529088913,
            "logloss": 0.5706076359659695,
            "mae": 0.2733499471948425,
            "precision": 0.8447837150127226,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8379726654530482,
            "auditor_fn_violation": 0.00791500810850656,
            "auditor_fp_violation": 0.011488009013359092,
            "ave_precision_score": 0.8382278576060844,
            "fpr": 0.18201754385964913,
            "logloss": 0.7973646057111639,
            "mae": 0.2698978055879025,
            "precision": 0.7077464788732394,
            "recall": 0.8445378151260504
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8422998044469089,
            "auditor_fn_violation": 0.015126602335931367,
            "auditor_fp_violation": 0.02520641986700907,
            "ave_precision_score": 0.8426218902232318,
            "fpr": 0.17014270032930845,
            "logloss": 0.7780687979051256,
            "mae": 0.26187877466183435,
            "precision": 0.726148409893993,
            "recall": 0.8598326359832636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8290998965429425,
            "auditor_fn_violation": 0.004911174996314326,
            "auditor_fp_violation": 0.003256780138419442,
            "ave_precision_score": 0.8294105074975333,
            "fpr": 0.08442982456140351,
            "logloss": 0.6920593108367685,
            "mae": 0.28802965575238704,
            "precision": 0.8065326633165829,
            "recall": 0.6743697478991597
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.83805261881044,
            "auditor_fn_violation": 0.012258357866889585,
            "auditor_fp_violation": 0.017086520155249037,
            "ave_precision_score": 0.8383264738436234,
            "fpr": 0.0845225027442371,
            "logloss": 0.682921348608246,
            "mae": 0.2788748953811707,
            "precision": 0.8108108108108109,
            "recall": 0.6903765690376569
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8613736256265145,
            "auditor_fn_violation": 0.01228024104378594,
            "auditor_fp_violation": 0.007589932399806858,
            "ave_precision_score": 0.8615732350249602,
            "fpr": 0.10307017543859649,
            "logloss": 0.5065579660314973,
            "mae": 0.3009926506130254,
            "precision": 0.7868480725623582,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.861855193136928,
            "auditor_fn_violation": 0.006648172728483579,
            "auditor_fp_violation": 0.010860334175828913,
            "ave_precision_score": 0.8621173551162572,
            "fpr": 0.07793633369923161,
            "logloss": 0.5006013854847147,
            "mae": 0.2914754644897076,
            "precision": 0.830952380952381,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.845216869533553,
            "auditor_fn_violation": 0.01688965059708094,
            "auditor_fp_violation": 0.008087880251086432,
            "ave_precision_score": 0.8455524193646379,
            "fpr": 0.10307017543859649,
            "logloss": 0.6390723459621284,
            "mae": 0.26678950163049,
            "precision": 0.7911111111111111,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8630820191476867,
            "auditor_fn_violation": 0.021889596700485472,
            "auditor_fp_violation": 0.014901270841625201,
            "ave_precision_score": 0.8632919320583701,
            "fpr": 0.09220636663007684,
            "logloss": 0.6090682112001873,
            "mae": 0.25842376581808757,
            "precision": 0.8095238095238095,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8267178052692299,
            "auditor_fn_violation": 0.017534645437122222,
            "auditor_fp_violation": 0.007250422501207151,
            "ave_precision_score": 0.8268436216402281,
            "fpr": 0.09978070175438597,
            "logloss": 1.618932060230358,
            "mae": 0.28248988892041177,
            "precision": 0.7838479809976246,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8474171618897557,
            "auditor_fn_violation": 0.02654676225950609,
            "auditor_fp_violation": 0.018470680393344877,
            "ave_precision_score": 0.8473903973383068,
            "fpr": 0.07574094401756312,
            "logloss": 1.7340043263412617,
            "mae": 0.2706745060726931,
            "precision": 0.827930174563591,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8293942435652228,
            "auditor_fn_violation": 0.003353973168214654,
            "auditor_fp_violation": 0.0062067439240302644,
            "ave_precision_score": 0.829676009653461,
            "fpr": 0.17763157894736842,
            "logloss": 0.8129718882094862,
            "mae": 0.27617908947853986,
            "precision": 0.7086330935251799,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8294517092066794,
            "auditor_fn_violation": 0.014022018196932889,
            "auditor_fp_violation": 0.0299166208237528,
            "ave_precision_score": 0.8298528795021158,
            "fpr": 0.17453347969264543,
            "logloss": 0.813089750066866,
            "mae": 0.26981971660641446,
            "precision": 0.7175843694493783,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8566884897749187,
            "auditor_fn_violation": 0.013556409405867616,
            "auditor_fp_violation": 0.0033397714469660424,
            "ave_precision_score": 0.856930472364832,
            "fpr": 0.10087719298245613,
            "logloss": 0.5040422521247754,
            "mae": 0.29468489129462877,
            "precision": 0.7932584269662921,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8586772209925166,
            "auditor_fn_violation": 0.011463792145281527,
            "auditor_fp_violation": 0.010921176384096865,
            "ave_precision_score": 0.8589207175442539,
            "fpr": 0.07683863885839737,
            "logloss": 0.5094879068768272,
            "mae": 0.2926788603369163,
            "precision": 0.8333333333333334,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8280323191934702,
            "auditor_fn_violation": 0.013777550493881761,
            "auditor_fp_violation": 0.006267101239336879,
            "ave_precision_score": 0.8235439837335852,
            "fpr": 0.08552631578947369,
            "logloss": 0.7271707988100098,
            "mae": 0.27707780395601794,
            "precision": 0.8198614318706697,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8232315511313573,
            "auditor_fn_violation": 0.008308493586063408,
            "auditor_fp_violation": 0.007853715050587762,
            "ave_precision_score": 0.8174015667657717,
            "fpr": 0.08122941822173436,
            "logloss": 0.8091309723981848,
            "mae": 0.28214194694519634,
            "precision": 0.8229665071770335,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8089840471047562,
            "auditor_fn_violation": 0.02119729470735663,
            "auditor_fp_violation": 0.013701110574601643,
            "ave_precision_score": 0.815699086808483,
            "fpr": 0.11842105263157894,
            "logloss": 0.5050866912604409,
            "mae": 0.3223402645784071,
            "precision": 0.777319587628866,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8383887788936752,
            "auditor_fn_violation": 0.016584837114027074,
            "auditor_fp_violation": 0.0183261801487085,
            "ave_precision_score": 0.8454210531108481,
            "fpr": 0.1163556531284303,
            "logloss": 0.48518598513862604,
            "mae": 0.31446403310594323,
            "precision": 0.7800829875518672,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8334208891721665,
            "auditor_fn_violation": 0.010117204776647504,
            "auditor_fp_violation": 0.01692519716723001,
            "ave_precision_score": 0.8336833243085479,
            "fpr": 0.15570175438596492,
            "logloss": 0.8182720355792308,
            "mae": 0.2723072303730227,
            "precision": 0.7263969171483622,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.840930609778042,
            "auditor_fn_violation": 0.017119905938115732,
            "auditor_fp_violation": 0.020349183573617806,
            "ave_precision_score": 0.8412179561906907,
            "fpr": 0.14818880351262348,
            "logloss": 0.8010716573729932,
            "mae": 0.26157361955995434,
            "precision": 0.7423664122137404,
            "recall": 0.8138075313807531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8455515122952763,
            "auditor_fn_violation": 0.033717105263157895,
            "auditor_fp_violation": 0.027216119427007884,
            "ave_precision_score": 0.8458177468578243,
            "fpr": 0.10635964912280702,
            "logloss": 0.5635858906475913,
            "mae": 0.3035282818312135,
            "precision": 0.7863436123348018,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8427162598252114,
            "auditor_fn_violation": 0.04049529460935384,
            "auditor_fp_violation": 0.024468708091760192,
            "ave_precision_score": 0.8432509234633431,
            "fpr": 0.10208562019758508,
            "logloss": 0.5639943297117465,
            "mae": 0.3119961311328805,
            "precision": 0.7886363636363637,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8406508229410394,
            "auditor_fn_violation": 0.012174277605779158,
            "auditor_fp_violation": 0.009599328021889592,
            "ave_precision_score": 0.8409091088297805,
            "fpr": 0.1875,
            "logloss": 0.7780242858496872,
            "mae": 0.27148059003603736,
            "precision": 0.7061855670103093,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8438877805599114,
            "auditor_fn_violation": 0.016350600976443194,
            "auditor_fp_violation": 0.033323784486757956,
            "ave_precision_score": 0.8442551352061092,
            "fpr": 0.18111964873765093,
            "logloss": 0.7643368809935961,
            "mae": 0.26349776414761455,
            "precision": 0.7155172413793104,
            "recall": 0.8682008368200836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8599100985631654,
            "auditor_fn_violation": 0.011089304142709719,
            "auditor_fp_violation": 0.008364517946241753,
            "ave_precision_score": 0.8601230022642925,
            "fpr": 0.10416666666666667,
            "logloss": 0.5070781549501205,
            "mae": 0.3011968044437501,
            "precision": 0.7845804988662132,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8616517446986434,
            "auditor_fn_violation": 0.007798685521910267,
            "auditor_fp_violation": 0.011897186808395212,
            "ave_precision_score": 0.8619142368349164,
            "fpr": 0.08232711306256861,
            "logloss": 0.4996879847819066,
            "mae": 0.29111082494769014,
            "precision": 0.8235294117647058,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 15860,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7946304727954843,
            "auditor_fn_violation": 0.007942650744508334,
            "auditor_fp_violation": 0.014183969097054567,
            "ave_precision_score": 0.7960699757886831,
            "fpr": 0.09868421052631579,
            "logloss": 0.5373298712531808,
            "mae": 0.31041810163010825,
            "precision": 0.797752808988764,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8212991818501911,
            "auditor_fn_violation": 0.011900114362349532,
            "auditor_fp_violation": 0.001442467354352625,
            "ave_precision_score": 0.8227654930637196,
            "fpr": 0.09001097694840834,
            "logloss": 0.5250544881652032,
            "mae": 0.30916741489137306,
            "precision": 0.8093023255813954,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.850249183987313,
            "auditor_fn_violation": 0.015318627450980395,
            "auditor_fp_violation": 0.005650953645581843,
            "ave_precision_score": 0.8505216924339516,
            "fpr": 0.10197368421052631,
            "logloss": 0.5121359041896995,
            "mae": 0.30090924623226256,
            "precision": 0.7900677200902935,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.851486047602874,
            "auditor_fn_violation": 0.015739749872547986,
            "auditor_fp_violation": 0.009534481053989855,
            "ave_precision_score": 0.8517914414431316,
            "fpr": 0.07683863885839737,
            "logloss": 0.5155794861380973,
            "mae": 0.3006960789864202,
            "precision": 0.8305084745762712,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8602593420397002,
            "auditor_fn_violation": 0.0005298171900339159,
            "auditor_fp_violation": 0.01281586995010462,
            "ave_precision_score": 0.8604601331174158,
            "fpr": 0.08662280701754387,
            "logloss": 0.49868749412858393,
            "mae": 0.29771270852315385,
            "precision": 0.8141176470588235,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8638054088726373,
            "auditor_fn_violation": 0.008154632593728905,
            "auditor_fp_violation": 0.008898172959187559,
            "ave_precision_score": 0.8640285968067866,
            "fpr": 0.07793633369923161,
            "logloss": 0.49275977686511346,
            "mae": 0.2966044815032284,
            "precision": 0.8268292682926829,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8365040341936998,
            "auditor_fn_violation": 0.03383458646616542,
            "auditor_fp_violation": 0.028845766940286496,
            "ave_precision_score": 0.8368101571588604,
            "fpr": 0.13048245614035087,
            "logloss": 0.5650894454656394,
            "mae": 0.30895226843908,
            "precision": 0.7586206896551724,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8329151548479604,
            "auditor_fn_violation": 0.03839635510198458,
            "auditor_fp_violation": 0.03490821699373579,
            "ave_precision_score": 0.8341669688266682,
            "fpr": 0.1437980241492865,
            "logloss": 0.5763594513484572,
            "mae": 0.3185873162848649,
            "precision": 0.7364185110663984,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.822050654214787,
            "auditor_fn_violation": 0.009640369305616982,
            "auditor_fp_violation": 0.005744004506679545,
            "ave_precision_score": 0.8236260537742836,
            "fpr": 0.09429824561403509,
            "logloss": 0.6772713985492207,
            "mae": 0.2848691413202503,
            "precision": 0.7957244655581948,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8398315761486554,
            "auditor_fn_violation": 0.012758980200157076,
            "auditor_fp_violation": 0.018483355853400697,
            "ave_precision_score": 0.8401204332094829,
            "fpr": 0.0889132821075741,
            "logloss": 0.6676161983505678,
            "mae": 0.2773075351430428,
            "precision": 0.8043478260869565,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7367358216944061,
            "auditor_fn_violation": 0.0214046144773699,
            "auditor_fp_violation": 0.004959359407693548,
            "ave_precision_score": 0.7264172870965752,
            "fpr": 0.09758771929824561,
            "logloss": 2.2563609781710916,
            "mae": 0.32874022370710837,
            "precision": 0.7865707434052758,
            "recall": 0.6890756302521008
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7148786508007703,
            "auditor_fn_violation": 0.015546849523949502,
            "auditor_fp_violation": 0.015370262863690637,
            "ave_precision_score": 0.7013386331084872,
            "fpr": 0.09769484083424808,
            "logloss": 2.7063050439990786,
            "mae": 0.33702046335618596,
            "precision": 0.7802469135802469,
            "recall": 0.6610878661087866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8442157826210355,
            "auditor_fn_violation": 0.03165542532802595,
            "auditor_fp_violation": 0.0236852164815709,
            "ave_precision_score": 0.8444418385537185,
            "fpr": 0.10855263157894737,
            "logloss": 0.5567024041068166,
            "mae": 0.30948286942819386,
            "precision": 0.7819383259911894,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.839286284405672,
            "auditor_fn_violation": 0.04074330934326617,
            "auditor_fp_violation": 0.024610673244385414,
            "ave_precision_score": 0.8397324302614719,
            "fpr": 0.10428100987925357,
            "logloss": 0.5614787666755747,
            "mae": 0.31783808792990664,
            "precision": 0.7855530474040632,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8058902300288819,
            "auditor_fn_violation": 0.015290984814978634,
            "auditor_fp_violation": 0.00748430709802028,
            "ave_precision_score": 0.8068614023864156,
            "fpr": 0.11842105263157894,
            "logloss": 0.9118177438202733,
            "mae": 0.284062159168953,
            "precision": 0.757847533632287,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8208763036793463,
            "auditor_fn_violation": 0.02227539739768244,
            "auditor_fp_violation": 0.025908640354101658,
            "ave_precision_score": 0.8212049882461523,
            "fpr": 0.12184412733260154,
            "logloss": 0.8843756254240768,
            "mae": 0.280636147834446,
            "precision": 0.7571115973741794,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 15860,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8216764026398791,
            "auditor_fn_violation": 0.01300125313283208,
            "auditor_fp_violation": 0.012202237244487367,
            "ave_precision_score": 0.8222784826434051,
            "fpr": 0.12719298245614036,
            "logloss": 0.787675426459944,
            "mae": 0.27542777186127543,
            "precision": 0.7552742616033755,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8359481965835063,
            "auditor_fn_violation": 0.015588185312934889,
            "auditor_fp_violation": 0.021355615102050127,
            "ave_precision_score": 0.8362518433223476,
            "fpr": 0.12733260153677278,
            "logloss": 0.7706264232259943,
            "mae": 0.2667124049401085,
            "precision": 0.7593360995850622,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8320815563634357,
            "auditor_fn_violation": 0.003989753796255352,
            "auditor_fp_violation": 0.002693445195557699,
            "ave_precision_score": 0.8323949522393236,
            "fpr": 0.10855263157894737,
            "logloss": 0.6348810357495802,
            "mae": 0.27995886642056095,
            "precision": 0.7785234899328859,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8455688240887229,
            "auditor_fn_violation": 0.011436234952624596,
            "auditor_fp_violation": 0.0144576297396714,
            "ave_precision_score": 0.845856541445946,
            "fpr": 0.09549945115257959,
            "logloss": 0.6157652788500739,
            "mae": 0.26924497644507334,
            "precision": 0.7995391705069125,
            "recall": 0.7259414225941423
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8509886731362216,
            "auditor_fn_violation": 0.014855613297950756,
            "auditor_fp_violation": 0.0036843111218413,
            "ave_precision_score": 0.8512392639040396,
            "fpr": 0.10416666666666667,
            "logloss": 0.5102343154614587,
            "mae": 0.30582924909800857,
            "precision": 0.7888888888888889,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.852427343114657,
            "auditor_fn_violation": 0.013530581594551025,
            "auditor_fp_violation": 0.011577765214988479,
            "ave_precision_score": 0.8527012092952841,
            "fpr": 0.08232711306256861,
            "logloss": 0.5106224133987441,
            "mae": 0.30432736230697216,
            "precision": 0.8226950354609929,
            "recall": 0.7280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8558424171650499,
            "auditor_fn_violation": 0.006214985994397757,
            "auditor_fp_violation": 0.008792048929663612,
            "ave_precision_score": 0.856075457433305,
            "fpr": 0.07894736842105263,
            "logloss": 0.5073975965132324,
            "mae": 0.2850036971473233,
            "precision": 0.8325581395348837,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8624656017498615,
            "auditor_fn_violation": 0.006090139577180817,
            "auditor_fp_violation": 0.011372422762084151,
            "ave_precision_score": 0.8626796786039901,
            "fpr": 0.07574094401756312,
            "logloss": 0.5060838243085087,
            "mae": 0.2864355823673251,
            "precision": 0.8353221957040573,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8540556098205538,
            "auditor_fn_violation": 0.0005275136370337613,
            "auditor_fp_violation": 0.007776034122002256,
            "ave_precision_score": 0.8544745678094889,
            "fpr": 0.07456140350877193,
            "logloss": 0.49968356403320224,
            "mae": 0.2975886324910741,
            "precision": 0.8320987654320988,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8648980828658789,
            "auditor_fn_violation": 0.007752756867482055,
            "auditor_fp_violation": 0.008457066949244927,
            "ave_precision_score": 0.8651472188459403,
            "fpr": 0.06476399560922064,
            "logloss": 0.5024491162325013,
            "mae": 0.2985199101813113,
            "precision": 0.8451443569553806,
            "recall": 0.6736401673640168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8324164572198272,
            "auditor_fn_violation": 0.01057791537667699,
            "auditor_fp_violation": 0.007494366650571384,
            "ave_precision_score": 0.8327736481311037,
            "fpr": 0.13486842105263158,
            "logloss": 0.7644489403054603,
            "mae": 0.26730415289670406,
            "precision": 0.7520161290322581,
            "recall": 0.7836134453781513
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8447618766812683,
            "auditor_fn_violation": 0.019489824506611426,
            "auditor_fp_violation": 0.021145202465123476,
            "ave_precision_score": 0.8450416712188673,
            "fpr": 0.13062568605927552,
            "logloss": 0.7463249496119962,
            "mae": 0.25707855807106783,
            "precision": 0.7600806451612904,
            "recall": 0.7887029288702929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7938800094061617,
            "auditor_fn_violation": 0.010172490048651051,
            "auditor_fp_violation": 0.006853070175438594,
            "ave_precision_score": 0.7954112377598815,
            "fpr": 0.11951754385964912,
            "logloss": 0.8914780111798843,
            "mae": 0.2942663138840948,
            "precision": 0.756152125279642,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8107298495383727,
            "auditor_fn_violation": 0.01408631831313239,
            "auditor_fp_violation": 0.019662173638592215,
            "ave_precision_score": 0.8110854751728591,
            "fpr": 0.10537870472008781,
            "logloss": 0.8818604833529528,
            "mae": 0.2864934680433777,
            "precision": 0.7757009345794392,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.839213066706736,
            "auditor_fn_violation": 0.00234040984814979,
            "auditor_fp_violation": 0.012587015129567041,
            "ave_precision_score": 0.8395256084546598,
            "fpr": 0.09758771929824561,
            "logloss": 0.5002313480782182,
            "mae": 0.3013631206438795,
            "precision": 0.8,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8586991972338547,
            "auditor_fn_violation": 0.0063519329074216225,
            "auditor_fp_violation": 0.009818411359240284,
            "ave_precision_score": 0.858961623583417,
            "fpr": 0.0845225027442371,
            "logloss": 0.48631626158965546,
            "mae": 0.2968548672104052,
            "precision": 0.819672131147541,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8407431506381353,
            "auditor_fn_violation": 0.009465299277605784,
            "auditor_fp_violation": 0.011377353935296965,
            "ave_precision_score": 0.8410009979837512,
            "fpr": 0.15570175438596492,
            "logloss": 0.7453307854924234,
            "mae": 0.2666705929462384,
            "precision": 0.7305502846299811,
            "recall": 0.8088235294117647
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.844476153444292,
            "auditor_fn_violation": 0.013328495515066898,
            "auditor_fp_violation": 0.0209930969444536,
            "ave_precision_score": 0.844824153203175,
            "fpr": 0.145993413830955,
            "logloss": 0.7360242994608679,
            "mae": 0.25633626014400207,
            "precision": 0.7504690431519699,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8489187390067324,
            "auditor_fn_violation": 0.009112855668583225,
            "auditor_fp_violation": 0.00938556253017866,
            "ave_precision_score": 0.8492509603312987,
            "fpr": 0.08442982456140351,
            "logloss": 0.5528992581612883,
            "mae": 0.2881096206922513,
            "precision": 0.8131067961165048,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.854030939848785,
            "auditor_fn_violation": 0.010848348175943486,
            "auditor_fp_violation": 0.01350190005146237,
            "ave_precision_score": 0.8545272168155883,
            "fpr": 0.06915477497255763,
            "logloss": 0.5423669630926166,
            "mae": 0.28108081907996424,
            "precision": 0.8401015228426396,
            "recall": 0.6924686192468619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8418737950704438,
            "auditor_fn_violation": 0.0067355889724310765,
            "auditor_fp_violation": 0.00872163206180589,
            "ave_precision_score": 0.842658380824151,
            "fpr": 0.10635964912280702,
            "logloss": 0.48643819812732814,
            "mae": 0.30151992121592913,
            "precision": 0.7940552016985138,
            "recall": 0.7857142857142857
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8603259284363609,
            "auditor_fn_violation": 0.009465895677654329,
            "auditor_fp_violation": 0.010614430250745951,
            "ave_precision_score": 0.8604886794716342,
            "fpr": 0.09989023051591657,
            "logloss": 0.4820498745240528,
            "mae": 0.3010225939604277,
            "precision": 0.8026030368763557,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8113840121378599,
            "auditor_fn_violation": 0.006984372696446999,
            "auditor_fp_violation": 0.009458494286174155,
            "ave_precision_score": 0.8117342700708714,
            "fpr": 0.13925438596491227,
            "logloss": 0.8226400951058408,
            "mae": 0.28298425727386733,
            "precision": 0.7370600414078675,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8253267847786916,
            "auditor_fn_violation": 0.017811132187260312,
            "auditor_fp_violation": 0.019385848609375284,
            "ave_precision_score": 0.8254583366589714,
            "fpr": 0.13391877058177826,
            "logloss": 0.8078966534523863,
            "mae": 0.27295288429886116,
            "precision": 0.7463617463617463,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8223582106581244,
            "auditor_fn_violation": 0.006258753501400561,
            "auditor_fp_violation": 0.013263520038628686,
            "ave_precision_score": 0.8226790194996664,
            "fpr": 0.14364035087719298,
            "logloss": 0.8612119249077694,
            "mae": 0.27571227232251766,
            "precision": 0.7348178137651822,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8356871082942573,
            "auditor_fn_violation": 0.01215272196170469,
            "auditor_fp_violation": 0.0202351044331154,
            "ave_precision_score": 0.8359278516361068,
            "fpr": 0.13391877058177826,
            "logloss": 0.8305510034953921,
            "mae": 0.2614604400871463,
            "precision": 0.7520325203252033,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 15860,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8174844169104667,
            "auditor_fn_violation": 0.007938043638508046,
            "auditor_fp_violation": 0.010341220022533399,
            "ave_precision_score": 0.830546181933299,
            "fpr": 0.08333333333333333,
            "logloss": 0.5183256037747471,
            "mae": 0.3252396942361405,
            "precision": 0.812807881773399,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8302296652085764,
            "auditor_fn_violation": 0.006694101382911789,
            "auditor_fp_violation": 0.010317824485439704,
            "ave_precision_score": 0.8406079355947098,
            "fpr": 0.07244785949506037,
            "logloss": 0.5067786764454904,
            "mae": 0.3208876470866502,
            "precision": 0.8294573643410853,
            "recall": 0.6715481171548117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.823483477453792,
            "auditor_fn_violation": 0.006899141235441549,
            "auditor_fp_violation": 0.004873853211009175,
            "ave_precision_score": 0.8238620022738137,
            "fpr": 0.09868421052631579,
            "logloss": 0.687543477937992,
            "mae": 0.28287987081760174,
            "precision": 0.7911832946635731,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8380108154184545,
            "auditor_fn_violation": 0.012694680083957587,
            "auditor_fp_violation": 0.017796345918375114,
            "ave_precision_score": 0.8383041647897678,
            "fpr": 0.09110867178924259,
            "logloss": 0.6756806621016203,
            "mae": 0.274234110031896,
            "precision": 0.8023809523809524,
            "recall": 0.7050209205020921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8713359481938643,
            "auditor_fn_violation": 0.007419744213474865,
            "auditor_fp_violation": 0.00010311041364880363,
            "ave_precision_score": 0.8715099955550828,
            "fpr": 0.12390350877192982,
            "logloss": 0.47959399031842515,
            "mae": 0.301299462266973,
            "precision": 0.774,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8634565022431033,
            "auditor_fn_violation": 0.006533351092413046,
            "auditor_fp_violation": 0.003693629060266745,
            "ave_precision_score": 0.8637490518561994,
            "fpr": 0.11855104281009879,
            "logloss": 0.4723607726252264,
            "mae": 0.30037233748286146,
            "precision": 0.7809330628803245,
            "recall": 0.805439330543933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8081842734727079,
            "auditor_fn_violation": 0.001676986584107335,
            "auditor_fp_violation": 0.0174835023338162,
            "ave_precision_score": 0.8085380799039605,
            "fpr": 0.18640350877192982,
            "logloss": 0.9080919853945506,
            "mae": 0.2887329566948457,
            "precision": 0.697508896797153,
            "recall": 0.8235294117647058
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8173771547525972,
            "auditor_fn_violation": 0.015055412921567637,
            "auditor_fp_violation": 0.03611492079105011,
            "ave_precision_score": 0.8177181569108349,
            "fpr": 0.1800219538968167,
            "logloss": 0.8963141976031356,
            "mae": 0.28097521497035766,
            "precision": 0.7066189624329159,
            "recall": 0.8263598326359832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8591642074406474,
            "auditor_fn_violation": 0.013323750552852726,
            "auditor_fp_violation": 0.008641155641397074,
            "ave_precision_score": 0.8593613011436565,
            "fpr": 0.10526315789473684,
            "logloss": 0.5051918435058768,
            "mae": 0.30168362404219806,
            "precision": 0.7857142857142857,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.857498481000688,
            "auditor_fn_violation": 0.006760697931832692,
            "auditor_fp_violation": 0.011560019570910329,
            "ave_precision_score": 0.8578932657394239,
            "fpr": 0.08232711306256861,
            "logloss": 0.4947867856428441,
            "mae": 0.29111142706728627,
            "precision": 0.8235294117647058,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8377176507383015,
            "auditor_fn_violation": 0.00440900044228218,
            "auditor_fp_violation": 0.010630432158377594,
            "ave_precision_score": 0.8378064112843793,
            "fpr": 0.09100877192982457,
            "logloss": 0.693281128932074,
            "mae": 0.2761937630598991,
            "precision": 0.8065268065268065,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8486483465109715,
            "auditor_fn_violation": 0.013769410597577728,
            "auditor_fp_violation": 0.018455469841277893,
            "ave_precision_score": 0.8487352439931186,
            "fpr": 0.09110867178924259,
            "logloss": 0.6838492076811773,
            "mae": 0.26650174717260083,
            "precision": 0.8028503562945368,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8570938877622961,
            "auditor_fn_violation": 0.0036073639982308744,
            "auditor_fp_violation": 0.0072730564944471264,
            "ave_precision_score": 0.8573590221702792,
            "fpr": 0.06907894736842106,
            "logloss": 0.513372896489764,
            "mae": 0.3076479953801537,
            "precision": 0.8380462724935732,
            "recall": 0.6848739495798319
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8602056026930224,
            "auditor_fn_violation": 0.010765676597972717,
            "auditor_fp_violation": 0.00859396191784781,
            "ave_precision_score": 0.8604705554527191,
            "fpr": 0.06256860592755215,
            "logloss": 0.511616011804613,
            "mae": 0.30644677932814796,
            "precision": 0.848404255319149,
            "recall": 0.6673640167364017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.862620036500836,
            "auditor_fn_violation": 0.00068185168804364,
            "auditor_fp_violation": 0.01054241107355545,
            "ave_precision_score": 0.8628522413654964,
            "fpr": 0.08881578947368421,
            "logloss": 0.49010843750461136,
            "mae": 0.30248742753010766,
            "precision": 0.8146453089244852,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8649066459586912,
            "auditor_fn_violation": 0.006140661097051843,
            "auditor_fp_violation": 0.008520444249524035,
            "ave_precision_score": 0.8651384562002644,
            "fpr": 0.07793633369923161,
            "logloss": 0.4874526133024626,
            "mae": 0.30246439104047157,
            "precision": 0.830952380952381,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8546644537962873,
            "auditor_fn_violation": 0.010891198584697037,
            "auditor_fp_violation": 0.00712719298245615,
            "ave_precision_score": 0.8549743408507795,
            "fpr": 0.12171052631578948,
            "logloss": 0.630626944526854,
            "mae": 0.262347391879872,
            "precision": 0.7701863354037267,
            "recall": 0.7815126050420168
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8601032398675845,
            "auditor_fn_violation": 0.011546463723252302,
            "auditor_fp_violation": 0.019852305539429554,
            "ave_precision_score": 0.8603309841960399,
            "fpr": 0.09440175631174534,
            "logloss": 0.6163892627089227,
            "mae": 0.25040531400127075,
            "precision": 0.8101545253863135,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8331425541049455,
            "auditor_fn_violation": 0.004683123249299721,
            "auditor_fp_violation": 0.00839972638017061,
            "ave_precision_score": 0.8334162690442856,
            "fpr": 0.17982456140350878,
            "logloss": 0.7874140422483232,
            "mae": 0.27522685149720433,
            "precision": 0.7076648841354723,
            "recall": 0.8340336134453782
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8316139675403564,
            "auditor_fn_violation": 0.014949777016382754,
            "auditor_fp_violation": 0.029878594443585337,
            "ave_precision_score": 0.8320294797773693,
            "fpr": 0.17233809001097694,
            "logloss": 0.7932013573377791,
            "mae": 0.26853594705671413,
            "precision": 0.7201426024955436,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8284192040640502,
            "auditor_fn_violation": 0.006643446852425184,
            "auditor_fp_violation": 0.011809914694994369,
            "ave_precision_score": 0.8291926342058282,
            "fpr": 0.12280701754385964,
            "logloss": 0.5035824364402124,
            "mae": 0.3009594824913636,
            "precision": 0.7681159420289855,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8638147941368456,
            "auditor_fn_violation": 0.005970725075667456,
            "auditor_fp_violation": 0.006915731006456882,
            "ave_precision_score": 0.8639571467712563,
            "fpr": 0.10867178924259056,
            "logloss": 0.48300698958021204,
            "mae": 0.295507336982028,
            "precision": 0.7898089171974523,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8370883796080532,
            "auditor_fn_violation": 0.007417440660474724,
            "auditor_fp_violation": 0.005266175760502172,
            "ave_precision_score": 0.8374524649426704,
            "fpr": 0.07675438596491228,
            "logloss": 0.5303955436038374,
            "mae": 0.3094689513499473,
            "precision": 0.828009828009828,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8430775713228098,
            "auditor_fn_violation": 0.012037900325634168,
            "auditor_fp_violation": 0.007072906711149083,
            "ave_precision_score": 0.8444546721963162,
            "fpr": 0.06695938529088913,
            "logloss": 0.5210248390066644,
            "mae": 0.304251133172919,
            "precision": 0.8447837150127226,
            "recall": 0.694560669456067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8583157901982861,
            "auditor_fn_violation": 0.013660069290874243,
            "auditor_fp_violation": 0.009795489296636086,
            "ave_precision_score": 0.8583366975717677,
            "fpr": 0.10635964912280702,
            "logloss": 0.5348871288692651,
            "mae": 0.29918057057422404,
            "precision": 0.7754629629629629,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8581851722795963,
            "auditor_fn_violation": 0.01391178942630518,
            "auditor_fp_violation": 0.012939109624983845,
            "ave_precision_score": 0.8582107868624432,
            "fpr": 0.08781558726673985,
            "logloss": 0.5389767257525944,
            "mae": 0.294053830787768,
            "precision": 0.8086124401913876,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.809175769755355,
            "auditor_fn_violation": 0.005890185021376974,
            "auditor_fp_violation": 0.009103895058747792,
            "ave_precision_score": 0.8103280068728952,
            "fpr": 0.13596491228070176,
            "logloss": 0.8127973736056088,
            "mae": 0.28433389712506935,
            "precision": 0.7443298969072165,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8193476837313409,
            "auditor_fn_violation": 0.017916768092445197,
            "auditor_fp_violation": 0.019535419038033987,
            "ave_precision_score": 0.819582862196696,
            "fpr": 0.13830954994511527,
            "logloss": 0.8108697195116364,
            "mae": 0.2763048086385009,
            "precision": 0.7391304347826086,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7972480995986388,
            "auditor_fn_violation": 0.009075998820580874,
            "auditor_fp_violation": 0.007926927410268795,
            "ave_precision_score": 0.7987735946767196,
            "fpr": 0.12280701754385964,
            "logloss": 0.8681740403751254,
            "mae": 0.2916783558611339,
            "precision": 0.7511111111111111,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.812234850645579,
            "auditor_fn_violation": 0.013401981362152036,
            "auditor_fp_violation": 0.018270408124462876,
            "ave_precision_score": 0.8125729299414682,
            "fpr": 0.11855104281009879,
            "logloss": 0.8656913387086582,
            "mae": 0.28539510799189133,
            "precision": 0.762114537444934,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8676458231974087,
            "auditor_fn_violation": 0.009776278932625686,
            "auditor_fp_violation": 0.002333816191855791,
            "ave_precision_score": 0.8679969384291959,
            "fpr": 0.09868421052631579,
            "logloss": 0.4729052298222444,
            "mae": 0.29039806975337695,
            "precision": 0.8043478260869565,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.861615326641905,
            "auditor_fn_violation": 0.012717644411171687,
            "auditor_fp_violation": 0.004426270651493298,
            "ave_precision_score": 0.8619755564279034,
            "fpr": 0.0889132821075741,
            "logloss": 0.47093794807640305,
            "mae": 0.2920264440571274,
            "precision": 0.82,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8590061590699603,
            "auditor_fn_violation": 0.013717658115877942,
            "auditor_fp_violation": 0.009777885079671656,
            "ave_precision_score": 0.8597291490261105,
            "fpr": 0.09978070175438597,
            "logloss": 0.5043200828732136,
            "mae": 0.296046862065212,
            "precision": 0.795045045045045,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8656462407599397,
            "auditor_fn_violation": 0.007908914292537976,
            "auditor_fp_violation": 0.011643677607278764,
            "ave_precision_score": 0.8659003886868559,
            "fpr": 0.07244785949506037,
            "logloss": 0.4942805022910912,
            "mae": 0.2895445740962162,
            "precision": 0.8390243902439024,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8395649382058351,
            "auditor_fn_violation": 0.024956693203597235,
            "auditor_fp_violation": 0.01540117495573797,
            "ave_precision_score": 0.8399572846355605,
            "fpr": 0.16337719298245615,
            "logloss": 0.5406108735147357,
            "mae": 0.30047868733616495,
            "precision": 0.7329749103942652,
            "recall": 0.8592436974789915
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8576582894019362,
            "auditor_fn_violation": 0.02633549044913631,
            "auditor_fp_violation": 0.03188638731642765,
            "ave_precision_score": 0.8579325497749296,
            "fpr": 0.16465422612513722,
            "logloss": 0.520744355830331,
            "mae": 0.2974369491334968,
            "precision": 0.7292418772563177,
            "recall": 0.8451882845188284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8399687827800318,
            "auditor_fn_violation": 0.006919873212442871,
            "auditor_fp_violation": 0.015798527281506516,
            "ave_precision_score": 0.8402229027495822,
            "fpr": 0.16447368421052633,
            "logloss": 0.755365695046373,
            "mae": 0.26833987775450957,
            "precision": 0.7222222222222222,
            "recall": 0.819327731092437
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8434588903529636,
            "auditor_fn_violation": 0.01276816593104272,
            "auditor_fp_violation": 0.025120226738629483,
            "ave_precision_score": 0.8438268832202975,
            "fpr": 0.15587266739846323,
            "logloss": 0.7449970739178778,
            "mae": 0.2585046040715433,
            "precision": 0.7380073800738007,
            "recall": 0.8368200836820083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.842239009885456,
            "auditor_fn_violation": 0.006910659000442283,
            "auditor_fp_violation": 0.005228452438435538,
            "ave_precision_score": 0.842286376831997,
            "fpr": 0.08662280701754387,
            "logloss": 0.6549387960690598,
            "mae": 0.28512109107980094,
            "precision": 0.8058968058968059,
            "recall": 0.6890756302521008
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8534185952332844,
            "auditor_fn_violation": 0.01384289644466287,
            "auditor_fp_violation": 0.013884698945148216,
            "ave_precision_score": 0.8534353446175054,
            "fpr": 0.0801317233809001,
            "logloss": 0.6397265938082208,
            "mae": 0.2762751444379169,
            "precision": 0.8151898734177215,
            "recall": 0.6736401673640168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8478910198468419,
            "auditor_fn_violation": 0.010835913312693499,
            "auditor_fp_violation": 0.007554723965878,
            "ave_precision_score": 0.8495333359199609,
            "fpr": 0.09320175438596491,
            "logloss": 0.48900192517882396,
            "mae": 0.30671224755790544,
            "precision": 0.8072562358276644,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8824938914411213,
            "auditor_fn_violation": 0.008101814641136467,
            "auditor_fp_violation": 0.0068371431541107835,
            "ave_precision_score": 0.8780344051239624,
            "fpr": 0.07244785949506037,
            "logloss": 0.46840269091120784,
            "mae": 0.2992169000535516,
            "precision": 0.8421052631578947,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8442609914687744,
            "auditor_fn_violation": 0.00980392156862745,
            "auditor_fp_violation": 0.012486419604056016,
            "ave_precision_score": 0.8447670089827719,
            "fpr": 0.10635964912280702,
            "logloss": 0.5125666242652502,
            "mae": 0.2986844160140639,
            "precision": 0.7829977628635347,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8698632995346085,
            "auditor_fn_violation": 0.004413743690551102,
            "auditor_fp_violation": 0.0116335372392341,
            "ave_precision_score": 0.8700739566247124,
            "fpr": 0.08122941822173436,
            "logloss": 0.4999496096123262,
            "mae": 0.2877665207778542,
            "precision": 0.8258823529411765,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.840760995600977,
            "auditor_fn_violation": 0.036925954592363266,
            "auditor_fp_violation": 0.01619587960727507,
            "ave_precision_score": 0.8410754211792227,
            "fpr": 0.06578947368421052,
            "logloss": 0.5707712034077331,
            "mae": 0.31493258210564007,
            "precision": 0.8457583547557841,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8420843816249926,
            "auditor_fn_violation": 0.0379646257503594,
            "auditor_fp_violation": 0.016645414145306403,
            "ave_precision_score": 0.8428119819961994,
            "fpr": 0.06366630076838639,
            "logloss": 0.5763949250559288,
            "mae": 0.3219351938288666,
            "precision": 0.8415300546448088,
            "recall": 0.6443514644351465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8073166993619534,
            "auditor_fn_violation": 0.007246977738463806,
            "auditor_fp_violation": 0.011759616932238865,
            "ave_precision_score": 0.8089031709007789,
            "fpr": 0.1337719298245614,
            "logloss": 0.8405564428475067,
            "mae": 0.28403035201267995,
            "precision": 0.7436974789915967,
            "recall": 0.7436974789915967
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8232559577116376,
            "auditor_fn_violation": 0.01623118647492985,
            "auditor_fp_violation": 0.018894040759209356,
            "ave_precision_score": 0.8232513497805016,
            "fpr": 0.132821075740944,
            "logloss": 0.8265727035301041,
            "mae": 0.2741853320684387,
            "precision": 0.7463312368972747,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8501704500049215,
            "auditor_fn_violation": 0.017866357069143447,
            "auditor_fp_violation": 0.016178275390310644,
            "ave_precision_score": 0.8504700229122147,
            "fpr": 0.10197368421052631,
            "logloss": 0.491017008537983,
            "mae": 0.29567967808862594,
            "precision": 0.802547770700637,
            "recall": 0.7941176470588235
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8605984352021872,
            "auditor_fn_violation": 0.02339146370028797,
            "auditor_fp_violation": 0.014019058821739934,
            "ave_precision_score": 0.8608628427592536,
            "fpr": 0.10647639956092206,
            "logloss": 0.49091480938305937,
            "mae": 0.30210022777973233,
            "precision": 0.7949260042283298,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8244661609186665,
            "auditor_fn_violation": 0.01673761609907121,
            "auditor_fp_violation": 0.0049090616449380346,
            "ave_precision_score": 0.8307005931262879,
            "fpr": 0.10964912280701754,
            "logloss": 0.4986142840535375,
            "mae": 0.3019581001880987,
            "precision": 0.7876857749469215,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8497897820710346,
            "auditor_fn_violation": 0.00925921673272738,
            "auditor_fp_violation": 0.011342001657950178,
            "ave_precision_score": 0.8530904515264536,
            "fpr": 0.09440175631174534,
            "logloss": 0.4780277341767306,
            "mae": 0.29354282885761246,
            "precision": 0.8105726872246696,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8291835773243144,
            "auditor_fn_violation": 0.007917311661506707,
            "auditor_fp_violation": 0.005814421374537265,
            "ave_precision_score": 0.8295460730711055,
            "fpr": 0.09210526315789473,
            "logloss": 0.6552360155646303,
            "mae": 0.2844177335348337,
            "precision": 0.7985611510791367,
            "recall": 0.6995798319327731
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8464341186122657,
            "auditor_fn_violation": 0.014614497839056814,
            "auditor_fp_violation": 0.01420665563056611,
            "ave_precision_score": 0.8467025399669281,
            "fpr": 0.0845225027442371,
            "logloss": 0.6390749086530945,
            "mae": 0.27472086950016317,
            "precision": 0.8126520681265207,
            "recall": 0.698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8232278978049178,
            "auditor_fn_violation": 0.006650357511425628,
            "auditor_fp_violation": 0.009003299533236763,
            "ave_precision_score": 0.8186295863241317,
            "fpr": 0.07456140350877193,
            "logloss": 0.7437119774238401,
            "mae": 0.2841040006422095,
            "precision": 0.8320987654320988,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8198469491288194,
            "auditor_fn_violation": 0.00961286737182461,
            "auditor_fp_violation": 0.012779398828280475,
            "ave_precision_score": 0.8140250340090563,
            "fpr": 0.06805708013172337,
            "logloss": 0.8218562778188183,
            "mae": 0.28809029089836924,
            "precision": 0.8430379746835444,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8257597634371145,
            "auditor_fn_violation": 0.005095459236326108,
            "auditor_fp_violation": 0.0015667753098342202,
            "ave_precision_score": 0.8261265378824065,
            "fpr": 0.08881578947368421,
            "logloss": 0.7152676095385867,
            "mae": 0.28561506945999726,
            "precision": 0.8014705882352942,
            "recall": 0.6869747899159664
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8359937118312046,
            "auditor_fn_violation": 0.01199656453664877,
            "auditor_fp_violation": 0.01933514676915199,
            "ave_precision_score": 0.8363023483405067,
            "fpr": 0.08781558726673985,
            "logloss": 0.7084719718998758,
            "mae": 0.27827109886602036,
            "precision": 0.80440097799511,
            "recall": 0.6882845188284519
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 15860,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8406682840761208,
            "auditor_fn_violation": 0.004590981129293824,
            "auditor_fp_violation": 0.00973764686946725,
            "ave_precision_score": 0.8410015523770037,
            "fpr": 0.10526315789473684,
            "logloss": 0.5023012081815948,
            "mae": 0.3028526797363731,
            "precision": 0.7926565874730022,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8629387408159499,
            "auditor_fn_violation": 0.012175686288918798,
            "auditor_fp_violation": 0.008596497009858975,
            "ave_precision_score": 0.8631986383165957,
            "fpr": 0.08781558726673985,
            "logloss": 0.48046806363309336,
            "mae": 0.29458629644581175,
            "precision": 0.8198198198198198,
            "recall": 0.7615062761506276
        }
    }
]