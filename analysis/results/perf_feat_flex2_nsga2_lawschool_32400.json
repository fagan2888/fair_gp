[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.48109102819031047,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5300687151763707,
            "fpr": 0.4692982456140351,
            "logloss": 0.6923153871059293,
            "mae": 0.49952372013215435,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5272990112503417,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.516174993714701,
            "fpr": 0.4840834248079034,
            "logloss": 0.6927722978792317,
            "mae": 0.4997520468368488,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6922965083567254,
            "mae": 0.49951137314762983,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6927671684725341,
            "mae": 0.499746683334807,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5005537029936102,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5143098546065423,
            "fpr": 0.4692982456140351,
            "logloss": 0.6977548702871967,
            "mae": 0.4966618352030453,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.4883609710573018,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.501079915439829,
            "fpr": 0.4840834248079034,
            "logloss": 0.7007764629219855,
            "mae": 0.49804716798529014,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 32400,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.6569890444015596,
            "auditor_fn_violation": 0.09728867623604467,
            "auditor_fp_violation": 0.04607568863748156,
            "ave_precision_score": 0.5367189052754358,
            "fpr": 0.24451754385964913,
            "logloss": 5.219627459366273,
            "mae": 0.5174042061626037,
            "precision": 0.514161220043573,
            "recall": 0.48760330578512395
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.6436709253542586,
            "auditor_fn_violation": 0.10330943316906836,
            "auditor_fp_violation": 0.0385761329778893,
            "ave_precision_score": 0.5240830968251884,
            "fpr": 0.23819978046103182,
            "logloss": 5.427091877062982,
            "mae": 0.49988500457653956,
            "precision": 0.510158013544018,
            "recall": 0.4808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7633916990803478,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.531621915510564,
            "fpr": 0.46271929824561403,
            "logloss": 15.990758086336212,
            "mae": 0.46857790037858904,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7611111111111111,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.5222222222222223,
            "fpr": 0.47200878155872666,
            "logloss": 16.30805622003837,
            "mae": 0.4761509293062627,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7633916990803478,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.531621915510564,
            "fpr": 0.46271929824561403,
            "logloss": 15.99067847882697,
            "mae": 0.46859368547927915,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7611111111111111,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.5222222222222223,
            "fpr": 0.47200878155872666,
            "logloss": 16.30832375676181,
            "mae": 0.4763247560133133,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6922965083567254,
            "mae": 0.49951137314762983,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6927671684725341,
            "mae": 0.499746683334807,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 32400,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5659388592683033,
            "auditor_fn_violation": 0.020774430911990726,
            "auditor_fp_violation": 0.01710321364158059,
            "ave_precision_score": 0.5669413411971576,
            "fpr": 0.19298245614035087,
            "logloss": 0.6899512917321267,
            "mae": 0.49272790025070046,
            "precision": 0.5440414507772021,
            "recall": 0.43388429752066116
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5811227445638796,
            "auditor_fn_violation": 0.015157530887264426,
            "auditor_fp_violation": 0.011992502818910223,
            "ave_precision_score": 0.5820781321561055,
            "fpr": 0.1756311745334797,
            "logloss": 0.6851509555303841,
            "mae": 0.49049572131374664,
            "precision": 0.5675675675675675,
            "recall": 0.44680851063829785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7633916990803478,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.531621915510564,
            "fpr": 0.46271929824561403,
            "logloss": 15.990531077081629,
            "mae": 0.4686333800813085,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7611111111111111,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.5222222222222223,
            "fpr": 0.47200878155872666,
            "logloss": 16.30902395170335,
            "mae": 0.47676187593379477,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.5934356005402746,
            "auditor_fn_violation": 0.006782840365376261,
            "auditor_fp_violation": 0.02125348417773406,
            "ave_precision_score": 0.5952886775421251,
            "fpr": 0.24561403508771928,
            "logloss": 0.680222172869601,
            "mae": 0.48556263896783713,
            "precision": 0.5675675675675675,
            "recall": 0.6074380165289256
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5716840903524081,
            "auditor_fn_violation": 0.007721232220846867,
            "auditor_fp_violation": 0.0010902275289918478,
            "ave_precision_score": 0.5726156726926707,
            "fpr": 0.25466520307354557,
            "logloss": 0.6835254146991209,
            "mae": 0.4880352703328975,
            "precision": 0.5433070866141733,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6472970934539087,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.5408238888306889,
            "fpr": 0.46271929824561403,
            "logloss": 0.7194829944020784,
            "mae": 0.49451557050748596,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6515636609253629,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.5340037149611617,
            "fpr": 0.47200878155872666,
            "logloss": 0.6792790970158954,
            "mae": 0.48885811127696194,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6852714421773528,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.6876056238604407,
            "fpr": 0.46271929824561403,
            "logloss": 1.3191333092821576,
            "mae": 0.4559641024080568,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7049267917725646,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.7060431976394876,
            "fpr": 0.47200878155872666,
            "logloss": 1.2769118155539645,
            "mae": 0.4567502098549738,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6243473699574036,
            "auditor_fn_violation": 0.004984051036682621,
            "auditor_fp_violation": 0.010155353336612561,
            "ave_precision_score": 0.5353890733065838,
            "fpr": 0.1787280701754386,
            "logloss": 6.575799594750259,
            "mae": 0.4870174658860554,
            "precision": 0.5342857142857143,
            "recall": 0.38636363636363635
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6087247149967926,
            "auditor_fn_violation": 0.007438634187355503,
            "auditor_fp_violation": 0.00530925871995341,
            "ave_precision_score": 0.519205885118351,
            "fpr": 0.1778265642151482,
            "logloss": 6.5277307913207405,
            "mae": 0.49310450973939945,
            "precision": 0.5192878338278932,
            "recall": 0.3723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6479764752791067,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5399267797593156,
            "fpr": 0.4692982456140351,
            "logloss": 0.6879347134495828,
            "mae": 0.4950671226047633,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6485181675725149,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5279127282554659,
            "fpr": 0.4840834248079034,
            "logloss": 0.687730075930039,
            "mae": 0.4949318441418209,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 32400,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6387020782114818,
            "auditor_fn_violation": 0.0112050529215601,
            "auditor_fp_violation": 0.01628596901131334,
            "ave_precision_score": 0.6393432254362474,
            "fpr": 0.24451754385964913,
            "logloss": 0.6845208644486483,
            "mae": 0.49442277894469727,
            "precision": 0.5285412262156448,
            "recall": 0.5165289256198347
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6183083967747112,
            "auditor_fn_violation": 0.008186000887497963,
            "auditor_fp_violation": 0.01055877894516754,
            "ave_precision_score": 0.6189388976213857,
            "fpr": 0.24807903402854006,
            "logloss": 0.6905402900518512,
            "mae": 0.4974558939002086,
            "precision": 0.5118790496760259,
            "recall": 0.5042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.674200594882867,
            "auditor_fn_violation": 0.004780158039727418,
            "auditor_fp_violation": 0.004847106082964418,
            "ave_precision_score": 0.6752129264510753,
            "fpr": 0.4342105263157895,
            "logloss": 0.9503618628821044,
            "mae": 0.433909369246988,
            "precision": 0.5432525951557093,
            "recall": 0.9731404958677686
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.69019469508346,
            "auditor_fn_violation": 0.002358876147324661,
            "auditor_fp_violation": 0.013112599595271718,
            "ave_precision_score": 0.6915881466513601,
            "fpr": 0.4270032930845225,
            "logloss": 0.8933516519831409,
            "mae": 0.42145758102245173,
            "precision": 0.544496487119438,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7633916990803478,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.531621915510564,
            "fpr": 0.46271929824561403,
            "logloss": 15.992864808670307,
            "mae": 0.4683976866827722,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7611111111111111,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.5222222222222223,
            "fpr": 0.47200878155872666,
            "logloss": 16.305360133144987,
            "mae": 0.474166402636192,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5934441923316802,
            "auditor_fn_violation": 0.006782840365376261,
            "auditor_fp_violation": 0.019667670929660607,
            "ave_precision_score": 0.595297261114093,
            "fpr": 0.24451754385964913,
            "logloss": 0.6802245501989477,
            "mae": 0.4855641228751394,
            "precision": 0.5686653771760155,
            "recall": 0.6074380165289256
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5716775135720519,
            "auditor_fn_violation": 0.007721232220846867,
            "auditor_fp_violation": 0.0010902275289918478,
            "ave_precision_score": 0.5726093161992405,
            "fpr": 0.25466520307354557,
            "logloss": 0.6835266794201466,
            "mae": 0.4880362096458314,
            "precision": 0.5433070866141733,
            "recall": 0.5872340425531914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.6975745604163142,
            "auditor_fn_violation": 0.0011214114832535959,
            "auditor_fp_violation": 0.0011682242990654207,
            "ave_precision_score": 0.5511504191822391,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6842442263784033,
            "mae": 0.4917803648532483,
            "precision": 0.8461538461538461,
            "recall": 0.022727272727272728
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6610026855634452,
            "auditor_fn_violation": 0.005371698157273982,
            "auditor_fp_violation": 0.0010628473855696689,
            "ave_precision_score": 0.5366306418247793,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6865053182954644,
            "mae": 0.49200525461122574,
            "precision": 0.7894736842105263,
            "recall": 0.031914893617021274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7653508771929824,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5307017543859649,
            "fpr": 0.4692982456140351,
            "logloss": 0.6922965083567254,
            "mae": 0.49951137314762983,
            "precision": 0.5307017543859649,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7579582875960482,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5159165751920965,
            "fpr": 0.4840834248079034,
            "logloss": 0.6927671684725341,
            "mae": 0.499746683334807,
            "precision": 0.5159165751920965,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6159466280123803,
            "auditor_fn_violation": 0.006370523415977962,
            "auditor_fp_violation": 0.01764889736022299,
            "ave_precision_score": 0.6165044079459614,
            "fpr": 0.15899122807017543,
            "logloss": 0.6763761132090576,
            "mae": 0.4821732860842818,
            "precision": 0.5722713864306784,
            "recall": 0.40082644628099173
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5897666059276151,
            "auditor_fn_violation": 0.004054464348272885,
            "auditor_fp_violation": 0.00937396546617184,
            "ave_precision_score": 0.5910138742805462,
            "fpr": 0.1690450054884742,
            "logloss": 0.6805787804899279,
            "mae": 0.48484351493328254,
            "precision": 0.5443786982248521,
            "recall": 0.39148936170212767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.6479764752791067,
            "auditor_fn_violation": 0.0015133391329563571,
            "auditor_fp_violation": 0.0010555009017871786,
            "ave_precision_score": 0.5399267797593156,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6906224144502543,
            "mae": 0.49632755666971207,
            "precision": 0.75,
            "recall": 0.024793388429752067
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6485181675725149,
            "auditor_fn_violation": 0.005908867973001388,
            "auditor_fp_violation": 0.0015780919026959484,
            "ave_precision_score": 0.5279127282554659,
            "fpr": 0.005488474204171241,
            "logloss": 0.6890787958550103,
            "mae": 0.4955354402277263,
            "precision": 0.7619047619047619,
            "recall": 0.03404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6899193117192508,
            "auditor_fn_violation": 0.0039509931854429465,
            "auditor_fp_violation": 0.00791113297261847,
            "ave_precision_score": 0.6921557975986028,
            "fpr": 0.43859649122807015,
            "logloss": 0.9950135467015142,
            "mae": 0.435671677879694,
            "precision": 0.54337899543379,
            "recall": 0.9834710743801653
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7143117559689807,
            "auditor_fn_violation": 0.003311768690006306,
            "auditor_fp_violation": 0.006924687181861417,
            "ave_precision_score": 0.7146709938843603,
            "fpr": 0.44017563117453345,
            "logloss": 0.9620604142014402,
            "mae": 0.4353748764258755,
            "precision": 0.5348027842227379,
            "recall": 0.9808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7807773465241662,
            "auditor_fn_violation": 0.008869345367551108,
            "auditor_fp_violation": 0.01564293326774882,
            "ave_precision_score": 0.6880518499813708,
            "fpr": 0.16557017543859648,
            "logloss": 8.153269175710994,
            "mae": 0.3103453608570003,
            "precision": 0.703921568627451,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7650572086588595,
            "auditor_fn_violation": 0.011051685078356726,
            "auditor_fp_violation": 0.025129993453656622,
            "ave_precision_score": 0.6684246226562368,
            "fpr": 0.16575192096597147,
            "logloss": 8.505912028222541,
            "mae": 0.30806197040801203,
            "precision": 0.6961770623742455,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7218885496897819,
            "auditor_fn_violation": 0.04842685225460346,
            "auditor_fp_violation": 0.0194652811936383,
            "ave_precision_score": 0.6115864922778022,
            "fpr": 0.1600877192982456,
            "logloss": 12.77714096225047,
            "mae": 0.3915791721921531,
            "precision": 0.6515513126491647,
            "recall": 0.5640495867768595
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.71502780074682,
            "auditor_fn_violation": 0.0403157624308102,
            "auditor_fp_violation": 0.01986304950081021,
            "ave_precision_score": 0.6036690555774452,
            "fpr": 0.15477497255762898,
            "logloss": 12.515789860044194,
            "mae": 0.38193410715521026,
            "precision": 0.650990099009901,
            "recall": 0.5595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6864084484595874,
            "auditor_fn_violation": 0.005264970276932002,
            "auditor_fp_violation": 0.005976901951139535,
            "ave_precision_score": 0.5639151034395464,
            "fpr": 0.2905701754385965,
            "logloss": 8.930119322556024,
            "mae": 0.3755527121583319,
            "precision": 0.6108663729809104,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6933036938125616,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008490333564820004,
            "ave_precision_score": 0.5680347790593308,
            "fpr": 0.27771679473106475,
            "logloss": 8.906671826145729,
            "mae": 0.35921737240425317,
            "precision": 0.6195488721804512,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.617855972326511,
            "auditor_fn_violation": 0.009401732637378578,
            "auditor_fp_violation": 0.015043449745859987,
            "ave_precision_score": 0.6184450903065402,
            "fpr": 0.21271929824561403,
            "logloss": 0.6737360525558987,
            "mae": 0.48079742430790995,
            "precision": 0.5456674473067916,
            "recall": 0.48140495867768596
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5842241098849207,
            "auditor_fn_violation": 0.0077072190952192105,
            "auditor_fp_violation": 0.01415802325320909,
            "ave_precision_score": 0.585494130736534,
            "fpr": 0.22941822173435786,
            "logloss": 0.6777552784183664,
            "mae": 0.48378567111348214,
            "precision": 0.5239179954441914,
            "recall": 0.48936170212765956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6864047298833831,
            "auditor_fn_violation": 0.005264970276932002,
            "auditor_fp_violation": 0.005976901951139535,
            "ave_precision_score": 0.5639113857395635,
            "fpr": 0.2905701754385965,
            "logloss": 8.93035383425051,
            "mae": 0.3756796799711813,
            "precision": 0.6108663729809104,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6933109292930739,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008490333564820004,
            "ave_precision_score": 0.5680420125335761,
            "fpr": 0.27771679473106475,
            "logloss": 8.906615962595957,
            "mae": 0.3592443098467872,
            "precision": 0.6195488721804512,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6908490899357659,
            "auditor_fn_violation": 0.005471128751631153,
            "auditor_fp_violation": 0.017057099524512218,
            "ave_precision_score": 0.5769085924205479,
            "fpr": 0.26096491228070173,
            "logloss": 8.682547044274433,
            "mae": 0.36565753064800577,
            "precision": 0.6275430359937402,
            "recall": 0.8285123966942148
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.700553313476196,
            "auditor_fn_violation": 0.018702851671065238,
            "auditor_fp_violation": 0.011875514933379128,
            "ave_precision_score": 0.5831311745762188,
            "fpr": 0.2557628979143798,
            "logloss": 8.541274822432506,
            "mae": 0.34611443447515805,
            "precision": 0.6342229199372057,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7046730018411692,
            "auditor_fn_violation": 0.007102272727272729,
            "auditor_fp_violation": 0.02062838170191835,
            "ave_precision_score": 0.6487180147052487,
            "fpr": 0.3081140350877193,
            "logloss": 0.6859313852273545,
            "mae": 0.4608726068481542,
            "precision": 0.6182065217391305,
            "recall": 0.9400826446280992
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6554470627772567,
            "auditor_fn_violation": 0.0034378868206553477,
            "auditor_fp_violation": 0.031093886511794643,
            "ave_precision_score": 0.6146956169782111,
            "fpr": 0.31613611416026344,
            "logloss": 0.6843368840210283,
            "mae": 0.47203737006621876,
            "precision": 0.5879828326180258,
            "recall": 0.874468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6035547564617898,
            "auditor_fn_violation": 0.008398125996810224,
            "auditor_fp_violation": 0.01252254467945565,
            "ave_precision_score": 0.6042232291265397,
            "fpr": 0.20614035087719298,
            "logloss": 0.6754915728368758,
            "mae": 0.4818692339682265,
            "precision": 0.5513126491646778,
            "recall": 0.4772727272727273
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5907167100841448,
            "auditor_fn_violation": 0.011373986967793178,
            "auditor_fp_violation": 0.011970100883382993,
            "ave_precision_score": 0.5918146327792643,
            "fpr": 0.21075740944017562,
            "logloss": 0.6791947716124507,
            "mae": 0.4845876657086068,
            "precision": 0.5450236966824644,
            "recall": 0.48936170212765956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7720932200795108,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.014387604525332028,
            "ave_precision_score": 0.6734740696286615,
            "fpr": 0.17982456140350878,
            "logloss": 8.5388313276562,
            "mae": 0.32004409467760414,
            "precision": 0.6876190476190476,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7541533048768206,
            "auditor_fn_violation": 0.012275498049840017,
            "auditor_fp_violation": 0.02317106864699777,
            "ave_precision_score": 0.6524906990662129,
            "fpr": 0.17453347969264543,
            "logloss": 8.95053171059021,
            "mae": 0.3200095839583117,
            "precision": 0.6863905325443787,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5038608985817582,
            "auditor_fn_violation": 0.0009809518631288961,
            "auditor_fp_violation": 0.0009427775045089353,
            "ave_precision_score": 0.48216138210816806,
            "fpr": 0.4166666666666667,
            "logloss": 5.4042654716868785,
            "mae": 0.46318822170468865,
            "precision": 0.5459976105137395,
            "recall": 0.9442148760330579
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.4735084719950785,
            "auditor_fn_violation": 0.0039937408038863064,
            "auditor_fp_violation": 0.006852503167384787,
            "ave_precision_score": 0.4512531520812233,
            "fpr": 0.41931942919868276,
            "logloss": 6.356300915796477,
            "mae": 0.47106766634243497,
            "precision": 0.5408653846153846,
            "recall": 0.9574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7059573512460182,
            "auditor_fn_violation": 0.0002152203856749313,
            "auditor_fp_violation": 0.017198003771110026,
            "ave_precision_score": 0.5910234303414073,
            "fpr": 0.2642543859649123,
            "logloss": 8.672619585251093,
            "mae": 0.35287600959724896,
            "precision": 0.6326219512195121,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.720496965252847,
            "auditor_fn_violation": 0.011567835205642623,
            "auditor_fp_violation": 0.011066556150451408,
            "ave_precision_score": 0.6018461500827255,
            "fpr": 0.25686059275521406,
            "logloss": 8.503265974014916,
            "mae": 0.33840498650249357,
            "precision": 0.6360808709175739,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6805554646504417,
            "auditor_fn_violation": 0.001882612005219661,
            "auditor_fp_violation": 0.0020802590588621093,
            "ave_precision_score": 0.6817198635585431,
            "fpr": 0.45394736842105265,
            "logloss": 0.9854329411290287,
            "mae": 0.4456540646282711,
            "precision": 0.5353535353535354,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7040177674360014,
            "auditor_fn_violation": 0.0006913141976317819,
            "auditor_fp_violation": 0.005274411264688831,
            "ave_precision_score": 0.704783105854007,
            "fpr": 0.4632272228320527,
            "logloss": 0.9443597426954916,
            "mae": 0.4421579182773121,
            "precision": 0.5263748597081931,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7087078490094544,
            "auditor_fn_violation": 0.0025418660287081386,
            "auditor_fp_violation": 0.014151910149204791,
            "ave_precision_score": 0.5951093243718476,
            "fpr": 0.25219298245614036,
            "logloss": 8.546939283371913,
            "mae": 0.34875581229055813,
            "precision": 0.6400625978090767,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7223897206033643,
            "auditor_fn_violation": 0.011771025527243857,
            "auditor_fp_violation": 0.019151165771833806,
            "ave_precision_score": 0.6062016978291734,
            "fpr": 0.24478594950603733,
            "logloss": 8.39394058474388,
            "mae": 0.33289497449544375,
            "precision": 0.6432,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.784652157416306,
            "auditor_fn_violation": 0.008216887777294478,
            "auditor_fp_violation": 0.016406378094769636,
            "ave_precision_score": 0.6764218752648379,
            "fpr": 0.16666666666666666,
            "logloss": 8.874958258715413,
            "mae": 0.3091229872864198,
            "precision": 0.7037037037037037,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7714551522816835,
            "auditor_fn_violation": 0.009846556274377,
            "auditor_fp_violation": 0.02631480693265232,
            "ave_precision_score": 0.6593815713925675,
            "fpr": 0.1668496158068057,
            "logloss": 9.145525415875332,
            "mae": 0.30761101883571085,
            "precision": 0.696,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6578607433449923,
            "auditor_fn_violation": 0.005432615629984051,
            "auditor_fp_violation": 0.004939334317101169,
            "ave_precision_score": 0.6602226617144022,
            "fpr": 0.4331140350877193,
            "logloss": 0.9387047360139673,
            "mae": 0.43457464219801023,
            "precision": 0.5433526011560693,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6737827677030281,
            "auditor_fn_violation": 0.002358876147324661,
            "auditor_fp_violation": 0.01159175708336757,
            "ave_precision_score": 0.6752801083687607,
            "fpr": 0.42590559824368823,
            "logloss": 0.8790259019859961,
            "mae": 0.4220806323321542,
            "precision": 0.5451348182883939,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5008345972480994,
            "auditor_fn_violation": 0.004829998550094244,
            "auditor_fp_violation": 0.0011887194622069244,
            "ave_precision_score": 0.48011698023041993,
            "fpr": 0.4342105263157895,
            "logloss": 5.110691626668301,
            "mae": 0.47469735338368957,
            "precision": 0.5427251732101617,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.4705113788598189,
            "auditor_fn_violation": 0.0009108531657986316,
            "auditor_fp_violation": 0.007482246466094671,
            "ave_precision_score": 0.450340855294914,
            "fpr": 0.4500548847420417,
            "logloss": 5.651848297811299,
            "mae": 0.4847342252167009,
            "precision": 0.529276693455798,
            "recall": 0.9808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6910355960125287,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.6929020287307224,
            "fpr": 0.46271929824561403,
            "logloss": 1.2734440444440123,
            "mae": 0.4544065572210712,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7031405311715802,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.7046260729050418,
            "fpr": 0.47200878155872666,
            "logloss": 1.2311180842018596,
            "mae": 0.45481219147643176,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6886191583901178,
            "auditor_fn_violation": 0.008463824851384662,
            "auditor_fp_violation": 0.021927262666010822,
            "ave_precision_score": 0.6609920849131993,
            "fpr": 0.30153508771929827,
            "logloss": 0.6895505219493844,
            "mae": 0.45912414527775947,
            "precision": 0.6217331499312242,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6385383123135084,
            "auditor_fn_violation": 0.004052128827334938,
            "auditor_fp_violation": 0.02899308278012998,
            "ave_precision_score": 0.6187082938967872,
            "fpr": 0.3150384193194292,
            "logloss": 0.6830708610160179,
            "mae": 0.4696744084031077,
            "precision": 0.5876436781609196,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6854504609218194,
            "auditor_fn_violation": 0.004673680585761932,
            "auditor_fp_violation": 0.006399614690932938,
            "ave_precision_score": 0.5629573569857188,
            "fpr": 0.28728070175438597,
            "logloss": 8.961062140744929,
            "mae": 0.3784108517123848,
            "precision": 0.6118518518518519,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6937014628086919,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008592386826666283,
            "ave_precision_score": 0.56875550356817,
            "fpr": 0.27552140504939626,
            "logloss": 8.888463433924372,
            "mae": 0.3584511383780647,
            "precision": 0.6214177978883861,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7088000272453704,
            "auditor_fn_violation": 0.004059736117152388,
            "auditor_fp_violation": 0.014151910149204791,
            "ave_precision_score": 0.5952014704380036,
            "fpr": 0.25219298245614036,
            "logloss": 8.544449340026743,
            "mae": 0.34856896471856047,
            "precision": 0.640625,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7224435364304556,
            "auditor_fn_violation": 0.011523460307821662,
            "auditor_fp_violation": 0.019151165771833806,
            "ave_precision_score": 0.6062554952286162,
            "fpr": 0.24478594950603733,
            "logloss": 8.392483956878621,
            "mae": 0.33301464893065863,
            "precision": 0.6437699680511182,
            "recall": 0.8574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5686118031928491,
            "auditor_fn_violation": 0.0075281825431347,
            "auditor_fp_violation": 0.004690830464010507,
            "ave_precision_score": 0.569503294395975,
            "fpr": 0.3651315789473684,
            "logloss": 0.6877239362145791,
            "mae": 0.4895901468892892,
            "precision": 0.5487804878048781,
            "recall": 0.8367768595041323
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.5836034566649553,
            "auditor_fn_violation": 0.007788962328047272,
            "auditor_fp_violation": 0.007370236788458526,
            "ave_precision_score": 0.5844144385553283,
            "fpr": 0.38529088913282106,
            "logloss": 0.6868118874182706,
            "mae": 0.48916997982170657,
            "precision": 0.5294906166219839,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7720979907197338,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.014387604525332028,
            "ave_precision_score": 0.673479139394983,
            "fpr": 0.17982456140350878,
            "logloss": 8.53853641259348,
            "mae": 0.3200413081641312,
            "precision": 0.6876190476190476,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7541512955183906,
            "auditor_fn_violation": 0.012275498049840017,
            "auditor_fp_violation": 0.02317106864699777,
            "ave_precision_score": 0.6524936640168602,
            "fpr": 0.17453347969264543,
            "logloss": 8.9503808949106,
            "mae": 0.32000803657119065,
            "precision": 0.6863905325443787,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6221662487016301,
            "auditor_fn_violation": 0.0018939393939393903,
            "auditor_fp_violation": 0.0008966633874405655,
            "ave_precision_score": 0.6227578898712862,
            "fpr": 0.044956140350877194,
            "logloss": 0.6745489473373179,
            "mae": 0.4842465591143098,
            "precision": 0.6693548387096774,
            "recall": 0.17148760330578514
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5970706887439055,
            "auditor_fn_violation": 0.008122941822173454,
            "auditor_fp_violation": 0.0023895397895711524,
            "ave_precision_score": 0.5981623949372665,
            "fpr": 0.052689352360043906,
            "logloss": 0.6809987157255545,
            "mae": 0.4876786761402953,
            "precision": 0.6220472440944882,
            "recall": 0.16808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6216158591041503,
            "auditor_fn_violation": 0.004041612295200811,
            "auditor_fp_violation": 0.002151992129857355,
            "ave_precision_score": 0.6223102588916984,
            "fpr": 0.046052631578947366,
            "logloss": 0.6747209283526232,
            "mae": 0.4843156914014304,
            "precision": 0.6557377049180327,
            "recall": 0.1652892561983471
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6009636352828673,
            "auditor_fn_violation": 0.005238573463811112,
            "auditor_fp_violation": 0.003138760077759609,
            "ave_precision_score": 0.6018088926330865,
            "fpr": 0.048298572996706916,
            "logloss": 0.6810621338427701,
            "mae": 0.4876951274311765,
            "precision": 0.648,
            "recall": 0.1723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 32400,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5659440380336428,
            "auditor_fn_violation": 0.025781136726112815,
            "auditor_fp_violation": 0.02282136415805871,
            "ave_precision_score": 0.5669372510502729,
            "fpr": 0.13596491228070176,
            "logloss": 0.690897940039408,
            "mae": 0.49290768625704867,
            "precision": 0.5602836879432624,
            "recall": 0.32644628099173556
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5810984930360124,
            "auditor_fn_violation": 0.02059929467267674,
            "auditor_fp_violation": 0.01630860906382312,
            "ave_precision_score": 0.5820234109299675,
            "fpr": 0.11745334796926454,
            "logloss": 0.6857835713031623,
            "mae": 0.49051935893905674,
            "precision": 0.6151079136690647,
            "recall": 0.3638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6988728570078172,
            "auditor_fn_violation": 0.0001427250978686408,
            "auditor_fp_violation": 0.009714707329070342,
            "ave_precision_score": 0.5890732100351957,
            "fpr": 0.25,
            "logloss": 8.223446098636725,
            "mae": 0.35772842258788035,
            "precision": 0.6363636363636364,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.709914761308275,
            "auditor_fn_violation": 0.01262115514865591,
            "auditor_fp_violation": 0.01853386799286125,
            "ave_precision_score": 0.5972560190990057,
            "fpr": 0.24039517014270034,
            "logloss": 8.016216270661124,
            "mae": 0.333783703284838,
            "precision": 0.6473429951690821,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.77213792535776,
            "auditor_fn_violation": 0.01135004349717268,
            "auditor_fp_violation": 0.014387604525332028,
            "ave_precision_score": 0.6735250754271934,
            "fpr": 0.17982456140350878,
            "logloss": 8.539275104895605,
            "mae": 0.31991858452614913,
            "precision": 0.688212927756654,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7547131677848948,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.023748540762810803,
            "ave_precision_score": 0.6529468821352771,
            "fpr": 0.17672886937431395,
            "logloss": 8.950922577488361,
            "mae": 0.32024232336991776,
            "precision": 0.6843137254901961,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6984488199021643,
            "auditor_fn_violation": 0.006354665071770336,
            "auditor_fp_violation": 0.015309886866699464,
            "ave_precision_score": 0.5893467246218763,
            "fpr": 0.2675438596491228,
            "logloss": 8.229673193121029,
            "mae": 0.35894234132642544,
            "precision": 0.6251920122887865,
            "recall": 0.8409090909090909
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7084019186848917,
            "auditor_fn_violation": 0.012836023074946868,
            "auditor_fp_violation": 0.018979417599458374,
            "ave_precision_score": 0.5969916679790891,
            "fpr": 0.2557628979143798,
            "logloss": 8.081901796101798,
            "mae": 0.3421989990868305,
            "precision": 0.6365054602184087,
            "recall": 0.8680851063829788
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7200251157086588,
            "auditor_fn_violation": 0.006841742786718866,
            "auditor_fp_violation": 0.015468724381046071,
            "ave_precision_score": 0.6264193750311271,
            "fpr": 0.17763157894736842,
            "logloss": 8.67875252984996,
            "mae": 0.32931660206859786,
            "precision": 0.6902485659655831,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.708392564784528,
            "auditor_fn_violation": 0.012413293785178784,
            "auditor_fp_violation": 0.02458736879310817,
            "ave_precision_score": 0.6128670407638156,
            "fpr": 0.17014270032930845,
            "logloss": 9.055211813189441,
            "mae": 0.32863304916279573,
            "precision": 0.6887550200803213,
            "recall": 0.7297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6984879990473957,
            "auditor_fn_violation": 0.002736697114687545,
            "auditor_fp_violation": 0.009417527463518625,
            "ave_precision_score": 0.5902886214673619,
            "fpr": 0.24561403508771928,
            "logloss": 8.27116279004528,
            "mae": 0.3612950129580732,
            "precision": 0.6363636363636364,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7062250514062086,
            "auditor_fn_violation": 0.013186351215638653,
            "auditor_fp_violation": 0.015143708416407184,
            "ave_precision_score": 0.5947272355553058,
            "fpr": 0.23710208562019758,
            "logloss": 8.293413986383404,
            "mae": 0.34481447163735923,
            "precision": 0.6459016393442623,
            "recall": 0.8382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7088117368245825,
            "auditor_fn_violation": 0.003543207191532549,
            "auditor_fp_violation": 0.013652340547630764,
            "ave_precision_score": 0.5952131762533819,
            "fpr": 0.2532894736842105,
            "logloss": 8.543185981143441,
            "mae": 0.34887130671610117,
            "precision": 0.6401869158878505,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7223812907820863,
            "auditor_fn_violation": 0.011771025527243857,
            "auditor_fp_violation": 0.019151165771833806,
            "ave_precision_score": 0.6061395175934019,
            "fpr": 0.24478594950603733,
            "logloss": 8.3911484295948,
            "mae": 0.3332711052352135,
            "precision": 0.6432,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6898306778082592,
            "auditor_fn_violation": 0.002451246918950268,
            "auditor_fp_violation": 0.002510657484833591,
            "ave_precision_score": 0.691633336347786,
            "fpr": 0.4605263157894737,
            "logloss": 1.0097565045821328,
            "mae": 0.4458503652029066,
            "precision": 0.532293986636971,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7017727631020996,
            "auditor_fn_violation": 0.0006913141976317819,
            "auditor_fp_violation": 0.004891089256778464,
            "ave_precision_score": 0.7034315698379134,
            "fpr": 0.4676180021953897,
            "logloss": 0.9730130467145461,
            "mae": 0.4437859382634496,
            "precision": 0.524022346368715,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7721248501432315,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.014777012625020503,
            "ave_precision_score": 0.6735094301251359,
            "fpr": 0.18092105263157895,
            "logloss": 8.54690476959966,
            "mae": 0.31984135692255683,
            "precision": 0.6863117870722434,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.75470603277711,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.023748540762810803,
            "ave_precision_score": 0.6529380333190248,
            "fpr": 0.17672886937431395,
            "logloss": 8.955269495026966,
            "mae": 0.3203299385396217,
            "precision": 0.6843137254901961,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6987918775098119,
            "auditor_fn_violation": 0.0019165941713788642,
            "auditor_fp_violation": 0.009714707329070342,
            "ave_precision_score": 0.5889922585114444,
            "fpr": 0.25,
            "logloss": 8.222326250252472,
            "mae": 0.35831392144651875,
            "precision": 0.6357827476038339,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7098406312645237,
            "auditor_fn_violation": 0.01262115514865591,
            "auditor_fp_violation": 0.01853386799286125,
            "ave_precision_score": 0.5971819168727961,
            "fpr": 0.24039517014270034,
            "logloss": 8.014894450473868,
            "mae": 0.3343029429375733,
            "precision": 0.6473429951690821,
            "recall": 0.8553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7582638148254351,
            "auditor_fn_violation": 0.007340147890387124,
            "auditor_fp_violation": 0.008925643548122655,
            "ave_precision_score": 0.6309198541280437,
            "fpr": 0.2642543859649123,
            "logloss": 8.777586083544206,
            "mae": 0.3466714013652028,
            "precision": 0.6331811263318112,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7495983726095294,
            "auditor_fn_violation": 0.00918326832800056,
            "auditor_fp_violation": 0.018093296594159078,
            "ave_precision_score": 0.6184947981477774,
            "fpr": 0.265642151481888,
            "logloss": 8.93055894487616,
            "mae": 0.3463443488230541,
            "precision": 0.6271186440677966,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7755621830963,
            "auditor_fn_violation": 0.008683576192547487,
            "auditor_fp_violation": 0.012940133628463682,
            "ave_precision_score": 0.6794881261561299,
            "fpr": 0.17214912280701755,
            "logloss": 8.390809575199505,
            "mae": 0.3147994892256494,
            "precision": 0.696911196911197,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.762127105239107,
            "auditor_fn_violation": 0.010428100987925357,
            "auditor_fp_violation": 0.02789538793929574,
            "ave_precision_score": 0.6636168115186772,
            "fpr": 0.1690450054884742,
            "logloss": 8.65590889589773,
            "mae": 0.31148602242672435,
            "precision": 0.6938369781312127,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.685427982754097,
            "auditor_fn_violation": 0.009197839640423375,
            "auditor_fp_violation": 0.009243318576815889,
            "ave_precision_score": 0.562934885578931,
            "fpr": 0.2850877192982456,
            "logloss": 8.934355922168752,
            "mae": 0.3877654371539625,
            "precision": 0.608433734939759,
            "recall": 0.8347107438016529
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6911320593982306,
            "auditor_fn_violation": 0.010474811406684263,
            "auditor_fp_violation": 0.010459214787268733,
            "ave_precision_score": 0.5658636508071506,
            "fpr": 0.2722283205268935,
            "logloss": 8.9381598235004,
            "mae": 0.3741895948151787,
            "precision": 0.614307931570762,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7059275315273654,
            "auditor_fn_violation": 0.0003647419167754117,
            "auditor_fp_violation": 0.016590834563043128,
            "ave_precision_score": 0.5909936217703391,
            "fpr": 0.26535087719298245,
            "logloss": 8.670736892477217,
            "mae": 0.35329042174884284,
            "precision": 0.6316590563165906,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7205106520985988,
            "auditor_fn_violation": 0.011567835205642623,
            "auditor_fp_violation": 0.016672018240153748,
            "ave_precision_score": 0.6018598346972917,
            "fpr": 0.2579582875960483,
            "logloss": 8.50149419167127,
            "mae": 0.3387926746064567,
            "precision": 0.6350931677018633,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 32400,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.771980872271585,
            "auditor_fn_violation": 0.010151605770624916,
            "auditor_fp_violation": 0.014387604525332028,
            "ave_precision_score": 0.6733637911350678,
            "fpr": 0.17982456140350878,
            "logloss": 8.569972384108933,
            "mae": 0.32043099764656685,
            "precision": 0.6852207293666027,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7535697203159144,
            "auditor_fn_violation": 0.012408622743302893,
            "auditor_fp_violation": 0.02317106864699777,
            "ave_precision_score": 0.652004771994203,
            "fpr": 0.17453347969264543,
            "logloss": 8.991003842003432,
            "mae": 0.31960437847432366,
            "precision": 0.6857707509881423,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7225163521121489,
            "auditor_fn_violation": 0.04842685225460346,
            "auditor_fp_violation": 0.01888885473028365,
            "ave_precision_score": 0.6120959418827899,
            "fpr": 0.15899122807017543,
            "logloss": 12.737876400897623,
            "mae": 0.39140373707178555,
            "precision": 0.65311004784689,
            "recall": 0.5640495867768595
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7150695083180225,
            "auditor_fn_violation": 0.0403157624308102,
            "auditor_fp_violation": 0.01986304950081021,
            "ave_precision_score": 0.603710741479311,
            "fpr": 0.15477497255762898,
            "logloss": 12.505763604725406,
            "mae": 0.38158387144965583,
            "precision": 0.6518518518518519,
            "recall": 0.5617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6554074476542433,
            "auditor_fn_violation": 0.001327569957952741,
            "auditor_fp_violation": 0.004798430070503365,
            "ave_precision_score": 0.6515600796974318,
            "fpr": 0.13706140350877194,
            "logloss": 4.084711510512284,
            "mae": 0.3432070235626051,
            "precision": 0.7222222222222222,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6395115195620715,
            "auditor_fn_violation": 0.01391036270640168,
            "auditor_fp_violation": 0.006294943883151505,
            "ave_precision_score": 0.6326323488609689,
            "fpr": 0.14928649835345773,
            "logloss": 4.897335410067403,
            "mae": 0.3533234606573579,
            "precision": 0.6894977168949772,
            "recall": 0.6425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7721268900162768,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.015929865551729802,
            "ave_precision_score": 0.6735097368011133,
            "fpr": 0.18201754385964913,
            "logloss": 8.546591025441653,
            "mae": 0.31987717484843675,
            "precision": 0.6850094876660342,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7547023379788355,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.023748540762810803,
            "ave_precision_score": 0.6529340931773532,
            "fpr": 0.17672886937431395,
            "logloss": 8.954539100143592,
            "mae": 0.320331020633211,
            "precision": 0.6843137254901961,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.677764398645081,
            "auditor_fn_violation": 0.001882612005219661,
            "auditor_fp_violation": 0.0020802590588621093,
            "ave_precision_score": 0.6797145386273022,
            "fpr": 0.45394736842105265,
            "logloss": 0.9816655503741242,
            "mae": 0.44539569818893177,
            "precision": 0.5353535353535354,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7015037630369645,
            "auditor_fn_violation": 0.0006913141976317819,
            "auditor_fp_violation": 0.005958914850243076,
            "ave_precision_score": 0.702897168407578,
            "fpr": 0.4610318331503842,
            "logloss": 0.9403403844568048,
            "mae": 0.44180244386490564,
            "precision": 0.5275590551181102,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6886191583901178,
            "auditor_fn_violation": 0.008463824851384662,
            "auditor_fp_violation": 0.021927262666010822,
            "ave_precision_score": 0.6609920849131993,
            "fpr": 0.30153508771929827,
            "logloss": 0.6895505268987969,
            "mae": 0.45912412789307144,
            "precision": 0.6217331499312242,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6385383123135084,
            "auditor_fn_violation": 0.004052128827334938,
            "auditor_fp_violation": 0.02899308278012998,
            "ave_precision_score": 0.6187082938967872,
            "fpr": 0.3150384193194292,
            "logloss": 0.6830709055158569,
            "mae": 0.46967439642983655,
            "precision": 0.5876436781609196,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7059000396497924,
            "auditor_fn_violation": 0.0002152203856749313,
            "auditor_fp_violation": 0.017198003771110026,
            "ave_precision_score": 0.5909661388406452,
            "fpr": 0.2642543859649123,
            "logloss": 8.67418151922162,
            "mae": 0.35285500105237705,
            "precision": 0.6326219512195121,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7204331989142233,
            "auditor_fn_violation": 0.011567835205642623,
            "auditor_fp_violation": 0.011066556150451408,
            "ave_precision_score": 0.6017824067430068,
            "fpr": 0.25686059275521406,
            "logloss": 8.504801941769097,
            "mae": 0.3383340991819412,
            "precision": 0.6360808709175739,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7574230098618847,
            "auditor_fn_violation": 0.007340147890387124,
            "auditor_fp_violation": 0.006986288735858355,
            "ave_precision_score": 0.6297360590787205,
            "fpr": 0.26644736842105265,
            "logloss": 8.85585353670652,
            "mae": 0.3489142673515963,
            "precision": 0.6312594840667678,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7483325465917547,
            "auditor_fn_violation": 0.00918326832800056,
            "auditor_fp_violation": 0.01663717078488917,
            "ave_precision_score": 0.6153204924201444,
            "fpr": 0.270032930845225,
            "logloss": 9.110795368737254,
            "mae": 0.34983963205073043,
            "precision": 0.6232771822358346,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.6479764752791067,
            "auditor_fn_violation": 0.0015133391329563571,
            "auditor_fp_violation": 0.0010555009017871786,
            "ave_precision_score": 0.5399267797593156,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6887092731843146,
            "mae": 0.4955151194804593,
            "precision": 0.75,
            "recall": 0.024793388429752067
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.6485181675725149,
            "auditor_fn_violation": 0.005908867973001388,
            "auditor_fp_violation": 0.0015780919026959484,
            "ave_precision_score": 0.5279127282554659,
            "fpr": 0.005488474204171241,
            "logloss": 0.6880115558198618,
            "mae": 0.4951365306793531,
            "precision": 0.7619047619047619,
            "recall": 0.03404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7794577822341495,
            "auditor_fn_violation": 0.008869345367551108,
            "auditor_fp_violation": 0.01564293326774882,
            "ave_precision_score": 0.6875867698287474,
            "fpr": 0.16557017543859648,
            "logloss": 8.112564243042899,
            "mae": 0.31021940478351856,
            "precision": 0.703921568627451,
            "recall": 0.7417355371900827
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7630616548111229,
            "auditor_fn_violation": 0.011051685078356726,
            "auditor_fp_violation": 0.025129993453656622,
            "ave_precision_score": 0.668028600004966,
            "fpr": 0.16575192096597147,
            "logloss": 8.447618826481197,
            "mae": 0.3082308691697035,
            "precision": 0.6961770623742455,
            "recall": 0.7361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7574230098618847,
            "auditor_fn_violation": 0.007340147890387124,
            "auditor_fp_violation": 0.006986288735858355,
            "ave_precision_score": 0.6297360590787205,
            "fpr": 0.26644736842105265,
            "logloss": 8.855848901197206,
            "mae": 0.3489144169287949,
            "precision": 0.6312594840667678,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7483325465917547,
            "auditor_fn_violation": 0.00918326832800056,
            "auditor_fp_violation": 0.01663717078488917,
            "ave_precision_score": 0.6153204924201444,
            "fpr": 0.270032930845225,
            "logloss": 9.11079098651454,
            "mae": 0.34983902589021487,
            "precision": 0.6232771822358346,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6910648380804708,
            "auditor_fn_violation": 0.0024127337973031755,
            "auditor_fp_violation": 0.0014961469093294156,
            "ave_precision_score": 0.6929596806790514,
            "fpr": 0.46271929824561403,
            "logloss": 1.271791338972263,
            "mae": 0.45431318992426606,
            "precision": 0.5316315205327414,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.703112224312774,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027280579264270786,
            "ave_precision_score": 0.7048624900760756,
            "fpr": 0.47200878155872666,
            "logloss": 1.229678590590308,
            "mae": 0.4547029606106706,
            "precision": 0.5222222222222223,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5003865969465298,
            "auditor_fn_violation": 0.004829998550094244,
            "auditor_fp_violation": 0.00023057058534187486,
            "ave_precision_score": 0.4796546996900882,
            "fpr": 0.43201754385964913,
            "logloss": 5.110616463851587,
            "mae": 0.4753185729414486,
            "precision": 0.5439814814814815,
            "recall": 0.9710743801652892
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.4701415798578216,
            "auditor_fn_violation": 0.0009108531657986316,
            "auditor_fp_violation": 0.007103902666079247,
            "ave_precision_score": 0.4499692998745602,
            "fpr": 0.4489571899012075,
            "logloss": 5.649702478607915,
            "mae": 0.48506265003990656,
            "precision": 0.5298850574712644,
            "recall": 0.9808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7721336430883949,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.015929865551729802,
            "ave_precision_score": 0.6735182138896622,
            "fpr": 0.18201754385964913,
            "logloss": 8.547176766715218,
            "mae": 0.319709435639297,
            "precision": 0.6850094876660342,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7552175432766979,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.022561238179867632,
            "ave_precision_score": 0.6533426485930387,
            "fpr": 0.17892425905598244,
            "logloss": 8.95941443819908,
            "mae": 0.3205903928115034,
            "precision": 0.681640625,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6886191583901178,
            "auditor_fn_violation": 0.008463824851384662,
            "auditor_fp_violation": 0.021927262666010822,
            "ave_precision_score": 0.6609920849131993,
            "fpr": 0.30153508771929827,
            "logloss": 0.6674607453862239,
            "mae": 0.45601000346385323,
            "precision": 0.6217331499312242,
            "recall": 0.9338842975206612
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6385383123135084,
            "auditor_fn_violation": 0.004052128827334938,
            "auditor_fp_violation": 0.02899308278012998,
            "ave_precision_score": 0.6187082938967872,
            "fpr": 0.3150384193194292,
            "logloss": 0.6759198133542579,
            "mae": 0.46693849403630217,
            "precision": 0.5876436781609196,
            "recall": 0.8702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7839073275970345,
            "auditor_fn_violation": 0.007557633753806006,
            "auditor_fp_violation": 0.020700114772913607,
            "ave_precision_score": 0.623790712397621,
            "fpr": 0.2543859649122807,
            "logloss": 11.523714322256781,
            "mae": 0.33507901122956946,
            "precision": 0.6386292834890965,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.770852296406299,
            "auditor_fn_violation": 0.008052876194035085,
            "auditor_fp_violation": 0.03714987641598902,
            "ave_precision_score": 0.6041033932974107,
            "fpr": 0.26344676180021953,
            "logloss": 12.018643275694098,
            "mae": 0.34796926848231,
            "precision": 0.6208530805687204,
            "recall": 0.8361702127659575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7720760577001022,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.014856431382193804,
            "ave_precision_score": 0.6734594735731129,
            "fpr": 0.18092105263157895,
            "logloss": 8.56709594084572,
            "mae": 0.3201674066737986,
            "precision": 0.6863117870722434,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7535049914623149,
            "auditor_fn_violation": 0.012896746619333443,
            "auditor_fp_violation": 0.023163601335155357,
            "ave_precision_score": 0.6519451651607112,
            "fpr": 0.1778265642151482,
            "logloss": 9.002918269641423,
            "mae": 0.32039453362429265,
            "precision": 0.6823529411764706,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6566870168999807,
            "auditor_fn_violation": 0.007988074525155871,
            "auditor_fp_violation": 0.009520003279226115,
            "ave_precision_score": 0.6526664766329568,
            "fpr": 0.12719298245614036,
            "logloss": 4.071940679289279,
            "mae": 0.35828183902193755,
            "precision": 0.7251184834123223,
            "recall": 0.6322314049586777
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.6391865147841318,
            "auditor_fn_violation": 0.011787374173809482,
            "auditor_fp_violation": 0.010822623963599346,
            "ave_precision_score": 0.6321163102476237,
            "fpr": 0.14050493962678376,
            "logloss": 4.836934017261609,
            "mae": 0.3658822779783515,
            "precision": 0.6885644768856448,
            "recall": 0.6021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7721336430883949,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.015929865551729802,
            "ave_precision_score": 0.6735182138896622,
            "fpr": 0.18201754385964913,
            "logloss": 8.547073673031802,
            "mae": 0.31970993539126263,
            "precision": 0.6850094876660342,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7552175432766979,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.022561238179867632,
            "ave_precision_score": 0.6533426485930387,
            "fpr": 0.17892425905598244,
            "logloss": 8.959426829327858,
            "mae": 0.32058987660263266,
            "precision": 0.681640625,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7720743723030117,
            "auditor_fn_violation": 0.009313379005364655,
            "auditor_fp_violation": 0.014856431382193804,
            "ave_precision_score": 0.6734594800697952,
            "fpr": 0.18092105263157895,
            "logloss": 8.567233539753069,
            "mae": 0.32016614624553946,
            "precision": 0.6863117870722434,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7535049914623149,
            "auditor_fn_violation": 0.012896746619333443,
            "auditor_fp_violation": 0.023163601335155357,
            "ave_precision_score": 0.6519451651607112,
            "fpr": 0.1778265642151482,
            "logloss": 9.00309882785678,
            "mae": 0.32039187428142485,
            "precision": 0.6823529411764706,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7097828890450478,
            "auditor_fn_violation": 0.0044856459330143575,
            "auditor_fp_violation": 0.014679660600098376,
            "ave_precision_score": 0.5960825989945199,
            "fpr": 0.25219298245614036,
            "logloss": 8.507300730326172,
            "mae": 0.34770820953191567,
            "precision": 0.640625,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7236578910043431,
            "auditor_fn_violation": 0.011537473433449333,
            "auditor_fp_violation": 0.019566846131061296,
            "ave_precision_score": 0.6068319348090807,
            "fpr": 0.24588364434687157,
            "logloss": 8.354247619936187,
            "mae": 0.331770373276078,
            "precision": 0.643879173290938,
            "recall": 0.8617021276595744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6850769109127118,
            "auditor_fn_violation": 0.006905176163549371,
            "auditor_fp_violation": 0.005390227906214135,
            "ave_precision_score": 0.5615627425833289,
            "fpr": 0.2817982456140351,
            "logloss": 8.965902425659866,
            "mae": 0.39409148355586693,
            "precision": 0.6052227342549923,
            "recall": 0.8140495867768595
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.693544511312436,
            "auditor_fn_violation": 0.011089053413363852,
            "auditor_fp_violation": 0.012928405903158921,
            "ave_precision_score": 0.5667970717347951,
            "fpr": 0.2711306256860593,
            "logloss": 8.894816811417266,
            "mae": 0.3745436341958393,
            "precision": 0.6134585289514867,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.698703400278776,
            "auditor_fn_violation": 0.004141293315934471,
            "auditor_fp_violation": 0.011402996392851288,
            "ave_precision_score": 0.5896012167271856,
            "fpr": 0.24451754385964913,
            "logloss": 8.238667992145194,
            "mae": 0.3641445680972549,
            "precision": 0.6373983739837399,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7084757109696436,
            "auditor_fn_violation": 0.013868323329518649,
            "auditor_fp_violation": 0.014962003828241869,
            "ave_precision_score": 0.5970654289616892,
            "fpr": 0.23600439077936333,
            "logloss": 8.079603068182285,
            "mae": 0.34274088016862764,
            "precision": 0.6457990115321252,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.6898750852703526,
            "auditor_fn_violation": 0.002451246918950268,
            "auditor_fp_violation": 0.002510657484833591,
            "ave_precision_score": 0.6917105861103718,
            "fpr": 0.4605263157894737,
            "logloss": 1.0097265957397088,
            "mae": 0.44584864172748784,
            "precision": 0.532293986636971,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7017682646344208,
            "auditor_fn_violation": 0.0006913141976317819,
            "auditor_fp_violation": 0.004891089256778464,
            "ave_precision_score": 0.7034135716708538,
            "fpr": 0.4676180021953897,
            "logloss": 0.972999623314796,
            "mae": 0.443785216966511,
            "precision": 0.524022346368715,
            "recall": 0.997872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7720720364935193,
            "auditor_fn_violation": 0.004111842105263159,
            "auditor_fp_violation": 0.014777012625020503,
            "ave_precision_score": 0.6735585055402415,
            "fpr": 0.18092105263157895,
            "logloss": 8.540999882264444,
            "mae": 0.32004008946570156,
            "precision": 0.6875,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.753824508176896,
            "auditor_fn_violation": 0.012896746619333443,
            "auditor_fp_violation": 0.023464782912799218,
            "ave_precision_score": 0.6530076592685903,
            "fpr": 0.1800219538968167,
            "logloss": 8.96072656364097,
            "mae": 0.3213249055631582,
            "precision": 0.6796875,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6864418442725478,
            "auditor_fn_violation": 0.005264970276932002,
            "auditor_fp_violation": 0.005976901951139535,
            "ave_precision_score": 0.5639484916187393,
            "fpr": 0.2905701754385965,
            "logloss": 8.929219736330657,
            "mae": 0.3755536122872228,
            "precision": 0.6108663729809104,
            "recall": 0.859504132231405
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6932816475408959,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008490333564820004,
            "ave_precision_score": 0.5680127376941878,
            "fpr": 0.27771679473106475,
            "logloss": 8.906085126332673,
            "mae": 0.35928116601648225,
            "precision": 0.6195488721804512,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6857817655115157,
            "auditor_fn_violation": 0.003307597506162103,
            "auditor_fp_violation": 0.008303102967699627,
            "ave_precision_score": 0.563288575039971,
            "fpr": 0.2883771929824561,
            "logloss": 8.952936047051457,
            "mae": 0.3773232874153344,
            "precision": 0.6115214180206795,
            "recall": 0.8553719008264463
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.693810593729275,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008592386826666283,
            "ave_precision_score": 0.5688646061706305,
            "fpr": 0.27552140504939626,
            "logloss": 8.885259698212161,
            "mae": 0.35831653541793484,
            "precision": 0.6214177978883861,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6971010807236225,
            "auditor_fn_violation": 0.00922955632883863,
            "auditor_fp_violation": 0.012245859977045425,
            "ave_precision_score": 0.586896804570958,
            "fpr": 0.24671052631578946,
            "logloss": 8.319946848387978,
            "mae": 0.36696243466330564,
            "precision": 0.6317512274959084,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7033946758839043,
            "auditor_fn_violation": 0.007543732629563028,
            "auditor_fp_violation": 0.0176676598191417,
            "ave_precision_score": 0.5910913804740183,
            "fpr": 0.23819978046103182,
            "logloss": 8.20832788968683,
            "mae": 0.3482942598810885,
            "precision": 0.6413223140495867,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6841485786885286,
            "auditor_fn_violation": 0.007172502537335077,
            "auditor_fp_violation": 0.005390227906214135,
            "ave_precision_score": 0.5606346493322457,
            "fpr": 0.2817982456140351,
            "logloss": 8.993268004967137,
            "mae": 0.39940603583836154,
            "precision": 0.6003110419906688,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6926760477464035,
            "auditor_fn_violation": 0.009883924609384127,
            "auditor_fp_violation": 0.012928405903158921,
            "ave_precision_score": 0.565928793511471,
            "fpr": 0.2711306256860593,
            "logloss": 8.933314134523405,
            "mae": 0.3783317503592575,
            "precision": 0.6110236220472441,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7721217876491782,
            "auditor_fn_violation": 0.007498731332463396,
            "auditor_fp_violation": 0.015929865551729802,
            "ave_precision_score": 0.6735077992430223,
            "fpr": 0.18201754385964913,
            "logloss": 8.542373032071621,
            "mae": 0.31997976406115874,
            "precision": 0.6856060606060606,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7552030075102683,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.023163601335155357,
            "ave_precision_score": 0.6533382894905554,
            "fpr": 0.1778265642151482,
            "logloss": 8.956428443105844,
            "mae": 0.32095607993952363,
            "precision": 0.6829745596868885,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6854435588927935,
            "auditor_fn_violation": 0.004673680585761932,
            "auditor_fp_violation": 0.0038633382521724917,
            "ave_precision_score": 0.5629504558637148,
            "fpr": 0.28618421052631576,
            "logloss": 8.961082622936276,
            "mae": 0.37844134458503953,
            "precision": 0.612759643916914,
            "recall": 0.8533057851239669
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6929436025569444,
            "auditor_fn_violation": 0.015148188803512626,
            "auditor_fp_violation": 0.008154304531911566,
            "ave_precision_score": 0.567674779342424,
            "fpr": 0.27661909989023054,
            "logloss": 8.928128934409425,
            "mae": 0.35953773795699967,
            "precision": 0.6204819277108434,
            "recall": 0.8765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 32400,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5659388592683033,
            "auditor_fn_violation": 0.020774430911990726,
            "auditor_fp_violation": 0.01710321364158059,
            "ave_precision_score": 0.5669413411971576,
            "fpr": 0.19298245614035087,
            "logloss": 0.6899526105579433,
            "mae": 0.4927286886397684,
            "precision": 0.5440414507772021,
            "recall": 0.43388429752066116
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5811227445638796,
            "auditor_fn_violation": 0.015157530887264426,
            "auditor_fp_violation": 0.011992502818910223,
            "ave_precision_score": 0.5820781321561055,
            "fpr": 0.1756311745334797,
            "logloss": 0.6851512839072866,
            "mae": 0.49049609304128705,
            "precision": 0.5675675675675675,
            "recall": 0.44680851063829785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7722893626338825,
            "auditor_fn_violation": 0.006732999855009426,
            "auditor_fp_violation": 0.01616812182324972,
            "ave_precision_score": 0.6736738597036294,
            "fpr": 0.18311403508771928,
            "logloss": 8.5237772450285,
            "mae": 0.31869967681900785,
            "precision": 0.6854990583804144,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7551754234059749,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.02482881187601275,
            "ave_precision_score": 0.6533043688958087,
            "fpr": 0.17892425905598244,
            "logloss": 8.9486153393976,
            "mae": 0.32100965544865656,
            "precision": 0.681640625,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7755220826915821,
            "auditor_fn_violation": 0.008683576192547487,
            "auditor_fp_violation": 0.012414945072962784,
            "ave_precision_score": 0.6794476839921297,
            "fpr": 0.17324561403508773,
            "logloss": 8.387748707264757,
            "mae": 0.3150297273787388,
            "precision": 0.6955684007707129,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7621000069122457,
            "auditor_fn_violation": 0.010407081299483856,
            "auditor_fp_violation": 0.02789538793929574,
            "ave_precision_score": 0.6635900436833306,
            "fpr": 0.1690450054884742,
            "logloss": 8.655131538414706,
            "mae": 0.3117701804576225,
            "precision": 0.6932270916334662,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7721200606688732,
            "auditor_fn_violation": 0.007498731332463396,
            "auditor_fp_violation": 0.015929865551729802,
            "ave_precision_score": 0.6735029080454971,
            "fpr": 0.18201754385964913,
            "logloss": 8.542365548181214,
            "mae": 0.319980644412201,
            "precision": 0.6856060606060606,
            "recall": 0.7479338842975206
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7552025458436282,
            "auditor_fn_violation": 0.012840694116822756,
            "auditor_fp_violation": 0.023163601335155357,
            "ave_precision_score": 0.6533414168402906,
            "fpr": 0.1778265642151482,
            "logloss": 8.956442036821029,
            "mae": 0.32095566044574614,
            "precision": 0.6829745596868885,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7846517287717044,
            "auditor_fn_violation": 0.008216887777294478,
            "auditor_fp_violation": 0.016406378094769636,
            "ave_precision_score": 0.6764214471827299,
            "fpr": 0.16666666666666666,
            "logloss": 8.87522141253767,
            "mae": 0.30912660643211537,
            "precision": 0.7037037037037037,
            "recall": 0.7458677685950413
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7714584234395616,
            "auditor_fn_violation": 0.009846556274377,
            "auditor_fp_violation": 0.02631480693265232,
            "ave_precision_score": 0.6593848404797351,
            "fpr": 0.1668496158068057,
            "logloss": 9.145833804793284,
            "mae": 0.3076056681415122,
            "precision": 0.696,
            "recall": 0.7404255319148936
        }
    }
]