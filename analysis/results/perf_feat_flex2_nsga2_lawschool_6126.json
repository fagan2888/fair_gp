[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6508501424236933,
            "auditor_fn_violation": 0.002539242843951995,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5999378695643578,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4128872643961439,
            "mae": 0.47476410478192155,
            "precision": 0.9696969696969697,
            "recall": 0.07017543859649122
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6808282482172592,
            "auditor_fn_violation": 0.008036536927071635,
            "auditor_fp_violation": 0.001507004781484307,
            "ave_precision_score": 0.6426806684047676,
            "fpr": 0.005488474204171241,
            "logloss": 1.5200494307151962,
            "mae": 0.4996751322953846,
            "precision": 0.9019607843137255,
            "recall": 0.09236947791164658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5889019945395275,
            "auditor_fn_violation": 0.00582150277008312,
            "auditor_fp_violation": 0.0011590104647583872,
            "ave_precision_score": 0.5742535895931993,
            "fpr": 0.0021929824561403508,
            "logloss": 1.4579873818970794,
            "mae": 0.4857732005097715,
            "precision": 0.8823529411764706,
            "recall": 0.03289473684210526
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.6544841992446279,
            "auditor_fn_violation": 0.0025194080383002877,
            "auditor_fp_violation": 0.0015388990625739216,
            "ave_precision_score": 0.615834551459157,
            "fpr": 0.003293084522502744,
            "logloss": 1.5652052623638548,
            "mae": 0.5127755909351557,
            "precision": 0.85,
            "recall": 0.03413654618473896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.645337397287685,
            "auditor_fn_violation": 0.004039704524469071,
            "auditor_fp_violation": 0.0012792397660818715,
            "ave_precision_score": 0.6127354228129789,
            "fpr": 0.0021929824561403508,
            "logloss": 1.2496473186329282,
            "mae": 0.47586273023115244,
            "precision": 0.9428571428571428,
            "recall": 0.07236842105263158
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6871350629170276,
            "auditor_fn_violation": 0.005567825638448424,
            "auditor_fp_violation": 0.001105668411106652,
            "ave_precision_score": 0.6634020711484407,
            "fpr": 0.006586169045005488,
            "logloss": 1.3184713282252394,
            "mae": 0.49613706527316676,
            "precision": 0.8909090909090909,
            "recall": 0.09839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6196360434736242,
            "auditor_fn_violation": 0.002539242843951995,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6065975337900721,
            "fpr": 0.0010964912280701754,
            "logloss": 1.3901210233203878,
            "mae": 0.4745924767204295,
            "precision": 0.9696969696969697,
            "recall": 0.07017543859649122
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6657387814392156,
            "auditor_fn_violation": 0.008036536927071635,
            "auditor_fp_violation": 0.001507004781484307,
            "ave_precision_score": 0.6540708433625149,
            "fpr": 0.005488474204171241,
            "logloss": 1.4970717983612845,
            "mae": 0.4991704857927102,
            "precision": 0.9019607843137255,
            "recall": 0.09236947791164658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6508501424236933,
            "auditor_fn_violation": 0.002539242843951995,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5999378695643578,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4116968201289162,
            "mae": 0.474776595372915,
            "precision": 0.9696969696969697,
            "recall": 0.07017543859649122
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6808282482172592,
            "auditor_fn_violation": 0.008036536927071635,
            "auditor_fp_violation": 0.001507004781484307,
            "ave_precision_score": 0.6426806684047676,
            "fpr": 0.005488474204171241,
            "logloss": 1.518631118384229,
            "mae": 0.49958849882576145,
            "precision": 0.9019607843137255,
            "recall": 0.09236947791164658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.7594809525619527,
            "auditor_fn_violation": 0.000403970452446907,
            "auditor_fp_violation": 0.006213450292397673,
            "ave_precision_score": 0.52428420290959,
            "fpr": 0.4583333333333333,
            "logloss": 15.519643342071843,
            "mae": 0.4707965942981996,
            "precision": 0.5195402298850574,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7759971303554514,
            "auditor_fn_violation": 0.0024576902560847123,
            "auditor_fp_violation": 0.0022884146681798737,
            "ave_precision_score": 0.5608580412984734,
            "fpr": 0.4281009879253567,
            "logloss": 14.508371975706371,
            "mae": 0.4375632119689108,
            "precision": 0.5583238958097395,
            "recall": 0.9899598393574297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6126838615772102,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5933881943819784,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4243457265186712,
            "mae": 0.46542278279115346,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6536641219164079,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.636381003304783,
            "fpr": 0.008781558726673985,
            "logloss": 1.5397742686742355,
            "mae": 0.4916263163216518,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 6126,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.759448519391507,
            "auditor_fn_violation": 0.000403970452446907,
            "auditor_fp_violation": 0.003751154201292727,
            "ave_precision_score": 0.5242669615484554,
            "fpr": 0.4517543859649123,
            "logloss": 15.519667887709174,
            "mae": 0.47096301834180687,
            "precision": 0.5231481481481481,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760281555359735,
            "auditor_fn_violation": 0.0024576902560847123,
            "auditor_fp_violation": 0.0053848177906299895,
            "ave_precision_score": 0.5609017705548268,
            "fpr": 0.42371020856201974,
            "logloss": 14.507881528533186,
            "mae": 0.4375135776240268,
            "precision": 0.5608646188850968,
            "recall": 0.9899598393574297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 6126,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7594917538585343,
            "auditor_fn_violation": 0.000403970452446907,
            "auditor_fp_violation": 0.003751154201292727,
            "ave_precision_score": 0.5243082575013912,
            "fpr": 0.4517543859649123,
            "logloss": 15.517478748529305,
            "mae": 0.4695554494923144,
            "precision": 0.5231481481481481,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7760162190816489,
            "auditor_fn_violation": 0.0024576902560847123,
            "auditor_fp_violation": 0.005190794247334842,
            "ave_precision_score": 0.560885683433206,
            "fpr": 0.4226125137211855,
            "logloss": 14.506765135257176,
            "mae": 0.43665109951004105,
            "precision": 0.5615034168564921,
            "recall": 0.9899598393574297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8202164635342912,
            "auditor_fn_violation": 0.006211045706371196,
            "auditor_fp_violation": 0.02481532779316713,
            "ave_precision_score": 0.8209821593840243,
            "fpr": 0.12171052631578948,
            "logloss": 0.6352001080624325,
            "mae": 0.25512051746068404,
            "precision": 0.76875,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8285478510985157,
            "auditor_fn_violation": 0.02377236718553688,
            "auditor_fp_violation": 0.01863157586985007,
            "ave_precision_score": 0.8288037151299023,
            "fpr": 0.14489571899012074,
            "logloss": 0.7409880082036407,
            "mae": 0.29347127060137385,
            "precision": 0.7456647398843931,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6126838615772102,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5933881943819784,
            "fpr": 0.0010964912280701754,
            "logloss": 1.42785954316601,
            "mae": 0.46551773617434183,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6536641219164079,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.636381003304783,
            "fpr": 0.008781558726673985,
            "logloss": 1.5434530694293638,
            "mae": 0.49170403067573587,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6665639996883196,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6639621988490279,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4410544841578512,
            "mae": 0.46580229878906576,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6864937457557525,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6854951532505353,
            "fpr": 0.008781558726673985,
            "logloss": 1.5570025795785787,
            "mae": 0.49206314311320887,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6665681833209591,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6639663815728625,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4312743961503036,
            "mae": 0.4655396677377499,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6864923961086129,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.685493803778205,
            "fpr": 0.008781558726673985,
            "logloss": 1.5467727062506786,
            "mae": 0.4918556671004853,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.5927724148809259,
            "auditor_fn_violation": 0.019376154201292708,
            "auditor_fp_violation": 0.027090066174207447,
            "ave_precision_score": 0.5934290204379475,
            "fpr": 0.16557017543859648,
            "logloss": 0.6574378381906157,
            "mae": 0.47534844122434916,
            "precision": 0.6695842450765864,
            "recall": 0.6710526315789473
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6461966109589019,
            "auditor_fn_violation": 0.026756862796961725,
            "auditor_fp_violation": 0.01947145860520993,
            "ave_precision_score": 0.6473448193623199,
            "fpr": 0.15587266739846323,
            "logloss": 0.6592641319799909,
            "mae": 0.47693556746719434,
            "precision": 0.7107942973523421,
            "recall": 0.7008032128514057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6181975583409938,
            "auditor_fn_violation": 0.004039704524469071,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6051489706269364,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4738416500576355,
            "mae": 0.4791460938153282,
            "precision": 0.9705882352941176,
            "recall": 0.07236842105263158
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6705333406716463,
            "auditor_fn_violation": 0.005567825638448424,
            "auditor_fp_violation": 0.001507004781484307,
            "ave_precision_score": 0.6592712433939578,
            "fpr": 0.005488474204171241,
            "logloss": 1.5617986608867278,
            "mae": 0.5018440305309536,
            "precision": 0.9074074074074074,
            "recall": 0.09839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5574264164301559,
            "auditor_fn_violation": 0.00815154662973223,
            "auditor_fp_violation": 0.014586218836565107,
            "ave_precision_score": 0.5589369285328853,
            "fpr": 0.22149122807017543,
            "logloss": 0.6884567007329391,
            "mae": 0.4933231930787626,
            "precision": 0.5608695652173913,
            "recall": 0.5657894736842105
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5912597197819862,
            "auditor_fn_violation": 0.011175326994035418,
            "auditor_fp_violation": 0.013929827265889335,
            "ave_precision_score": 0.5922003516653014,
            "fpr": 0.2327113062568606,
            "logloss": 0.6846202943156783,
            "mae": 0.4923816716500878,
            "precision": 0.55741127348643,
            "recall": 0.536144578313253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5140256468385354,
            "auditor_fn_violation": 0.012349953831948295,
            "auditor_fp_violation": 0.009118190212373051,
            "ave_precision_score": 0.513624511876812,
            "fpr": 0.2576754385964912,
            "logloss": 0.6924150051761678,
            "mae": 0.4972868078437291,
            "precision": 0.5213849287169042,
            "recall": 0.5614035087719298
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.585935813149647,
            "auditor_fn_violation": 0.008803600791750977,
            "auditor_fp_violation": 0.010756346297472642,
            "ave_precision_score": 0.585258971052738,
            "fpr": 0.2217343578485181,
            "logloss": 0.6887628038964742,
            "mae": 0.49548148389181895,
            "precision": 0.591919191919192,
            "recall": 0.5883534136546185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.7511305396699942,
            "auditor_fn_violation": 0.0014187057556171129,
            "auditor_fp_violation": 0.0012551939058171734,
            "ave_precision_score": 0.5044394743296801,
            "fpr": 0.48903508771929827,
            "logloss": 16.900928465731624,
            "mae": 0.49173321086798977,
            "precision": 0.5044444444444445,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7733365299437751,
            "auditor_fn_violation": 0.0015275151098356103,
            "auditor_fp_violation": 0.002939589573759529,
            "ave_precision_score": 0.549391249720051,
            "fpr": 0.4456641053787047,
            "logloss": 15.40749228486788,
            "mae": 0.44939515850497525,
            "precision": 0.5493895671476138,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8285391632414536,
            "auditor_fn_violation": 0.004963065558633427,
            "auditor_fp_violation": 0.015949619113573413,
            "ave_precision_score": 0.8290970877395403,
            "fpr": 0.10855263157894737,
            "logloss": 0.616081004214328,
            "mae": 0.25288102002368745,
            "precision": 0.7843137254901961,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8280395972346167,
            "auditor_fn_violation": 0.021067805800589853,
            "auditor_fp_violation": 0.018854835837477376,
            "ave_precision_score": 0.8283045918677983,
            "fpr": 0.13721185510428102,
            "logloss": 0.7357278497236506,
            "mae": 0.29544956866998023,
            "precision": 0.7484909456740443,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8236480899951865,
            "auditor_fn_violation": 0.009702504616805172,
            "auditor_fp_violation": 0.00995498614958449,
            "ave_precision_score": 0.8242205435081802,
            "fpr": 0.07675438596491228,
            "logloss": 0.6695006504995232,
            "mae": 0.26223649101933194,
            "precision": 0.8209718670076727,
            "recall": 0.7039473684210527
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8258306885988822,
            "auditor_fn_violation": 0.021517463928160514,
            "auditor_fp_violation": 0.010235406373008932,
            "ave_precision_score": 0.8260943983081381,
            "fpr": 0.10098792535675083,
            "logloss": 0.803485368601542,
            "mae": 0.3078731933027758,
            "precision": 0.7788461538461539,
            "recall": 0.6506024096385542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5187768247484816,
            "auditor_fn_violation": 0.012609649122807019,
            "auditor_fp_violation": 0.02278585718682672,
            "ave_precision_score": 0.5200884656842448,
            "fpr": 0.23903508771929824,
            "logloss": 0.6933117115830346,
            "mae": 0.49956709352370937,
            "precision": 0.5112107623318386,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5449783633907112,
            "auditor_fn_violation": 0.011250270015297196,
            "auditor_fp_violation": 0.023203089492694888,
            "ave_precision_score": 0.5465800625368405,
            "fpr": 0.22941822173435786,
            "logloss": 0.6928005375385599,
            "mae": 0.4992870835977904,
            "precision": 0.5476190476190477,
            "recall": 0.5080321285140562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8211291856530667,
            "auditor_fn_violation": 0.010753308710372424,
            "auditor_fp_violation": 0.024548418744229,
            "ave_precision_score": 0.821891529308693,
            "fpr": 0.12171052631578948,
            "logloss": 0.6275157465781996,
            "mae": 0.25518260359899647,
            "precision": 0.7682672233820459,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8291568204930169,
            "auditor_fn_violation": 0.02320147770004277,
            "auditor_fp_violation": 0.01863157586985007,
            "ave_precision_score": 0.8294110901626867,
            "fpr": 0.14489571899012074,
            "logloss": 0.7326334236779526,
            "mae": 0.2935578776533418,
            "precision": 0.7461538461538462,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7516971669150969,
            "auditor_fn_violation": 0.0014187057556171129,
            "auditor_fp_violation": 0.0027123730378578073,
            "ave_precision_score": 0.5055666169550735,
            "fpr": 0.4868421052631579,
            "logloss": 16.819507257111734,
            "mae": 0.4898799855523465,
            "precision": 0.5055679287305123,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7753549691480348,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031548759711144247,
            "ave_precision_score": 0.5516103211816631,
            "fpr": 0.4445664105378705,
            "logloss": 15.318736449233228,
            "mae": 0.4445601917578891,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.817117121652442,
            "auditor_fn_violation": 0.017796341181902126,
            "auditor_fp_violation": 0.02498845798707295,
            "ave_precision_score": 0.8177439669339693,
            "fpr": 0.12938596491228072,
            "logloss": 0.6455232607577348,
            "mae": 0.2619649233783279,
            "precision": 0.757700205338809,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8262889910497511,
            "auditor_fn_violation": 0.021067805800589846,
            "auditor_fp_violation": 0.020539917021712043,
            "ave_precision_score": 0.8265496259039924,
            "fpr": 0.145993413830955,
            "logloss": 0.7508060848213698,
            "mae": 0.29540120273416737,
            "precision": 0.7485822306238186,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7595285647977235,
            "auditor_fn_violation": 0.0007574445983379503,
            "auditor_fp_violation": 0.008036126500461689,
            "ave_precision_score": 0.5243482393339356,
            "fpr": 0.44956140350877194,
            "logloss": 15.513418207693029,
            "mae": 0.4568909327008441,
            "precision": 0.5249130938586327,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.776033912171122,
            "auditor_fn_violation": 0.003063847045702018,
            "auditor_fp_violation": 0.010195538521646914,
            "ave_precision_score": 0.560907138626895,
            "fpr": 0.42590559824368823,
            "logloss": 14.508986420792183,
            "mae": 0.4301182901909565,
            "precision": 0.5595913734392736,
            "recall": 0.9899598393574297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6665639996883196,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6639621988490279,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4397126160872924,
            "mae": 0.46581772196268983,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6864950870112855,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6854964927345049,
            "fpr": 0.008781558726673985,
            "logloss": 1.5554170596953831,
            "mae": 0.49197285676080604,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8207686941595937,
            "auditor_fn_violation": 0.009168686518928902,
            "auditor_fp_violation": 0.020270660203139428,
            "ave_precision_score": 0.8215475143791859,
            "fpr": 0.1206140350877193,
            "logloss": 0.6294675352027173,
            "mae": 0.2537770748750947,
            "precision": 0.7713097713097713,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8325878554757145,
            "auditor_fn_violation": 0.026798742720608015,
            "auditor_fp_violation": 0.018700680145544248,
            "ave_precision_score": 0.832835926643144,
            "fpr": 0.141602634467618,
            "logloss": 0.7306453657724464,
            "mae": 0.29041075774844,
            "precision": 0.750965250965251,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6509875592749772,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5920716765884491,
            "fpr": 0.0010964912280701754,
            "logloss": 1.416942571126226,
            "mae": 0.4651816805575468,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6813469455925819,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6336699836766512,
            "fpr": 0.008781558726673985,
            "logloss": 1.5321881740710375,
            "mae": 0.49143334492758883,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.759538498648631,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243581730136884,
            "fpr": 0.4506578947368421,
            "logloss": 15.509175604862158,
            "mae": 0.45672976572468515,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7760582435542718,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.006548959050400951,
            "ave_precision_score": 0.5609314669970913,
            "fpr": 0.4226125137211855,
            "logloss": 14.498540384718913,
            "mae": 0.42728329084892636,
            "precision": 0.5625,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8272512925981812,
            "auditor_fn_violation": 0.006117266851338875,
            "auditor_fp_violation": 0.02261753616497384,
            "ave_precision_score": 0.827733258044575,
            "fpr": 0.11293859649122807,
            "logloss": 0.6366388465580511,
            "mae": 0.2527366852329703,
            "precision": 0.7775377969762419,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8269968604335194,
            "auditor_fn_violation": 0.02119344557152871,
            "auditor_fp_violation": 0.01994189925128175,
            "ave_precision_score": 0.8272687006683335,
            "fpr": 0.14050493962678376,
            "logloss": 0.7576743491037585,
            "mae": 0.2944008851830536,
            "precision": 0.7455268389662028,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8140443228884444,
            "auditor_fn_violation": 0.01580534395198523,
            "auditor_fp_violation": 0.027412280701754388,
            "ave_precision_score": 0.8151191388167226,
            "fpr": 0.13157894736842105,
            "logloss": 0.6613409679416801,
            "mae": 0.25825251076582234,
            "precision": 0.7585513078470825,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8284087259689268,
            "auditor_fn_violation": 0.03138790066963794,
            "auditor_fp_violation": 0.022307391765428196,
            "ave_precision_score": 0.8286544032599752,
            "fpr": 0.15367727771679474,
            "logloss": 0.7571082065048313,
            "mae": 0.2925420229618479,
            "precision": 0.7407407407407407,
            "recall": 0.8032128514056225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8055393075831043,
            "auditor_fn_violation": 0.015117632348414898,
            "auditor_fp_violation": 0.01844798399507541,
            "ave_precision_score": 0.806265329090734,
            "fpr": 0.13596491228070176,
            "logloss": 0.6244478195722873,
            "mae": 0.2723305210040141,
            "precision": 0.7494949494949495,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.823707666749294,
            "auditor_fn_violation": 0.015275151098356105,
            "auditor_fp_violation": 0.017023572531581994,
            "ave_precision_score": 0.82399191385349,
            "fpr": 0.14818880351262348,
            "logloss": 0.6979621994812295,
            "mae": 0.2993334953155988,
            "precision": 0.7438330170777988,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 6126,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.33333333333333337,
            "auditor_fn_violation": 0.0006203831948291958,
            "auditor_fp_violation": 0.0001490843336411203,
            "ave_precision_score": 0.49999999999999994,
            "fpr": 0.0021929824561403508,
            "logloss": 17.198327531400476,
            "mae": 0.5010982107335447,
            "precision": 0.3333333333333333,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0.424858857309957,
            "auditor_fn_violation": 0.0005268053553401377,
            "auditor_fp_violation": 0.0005767549163705371,
            "ave_precision_score": 0.5477096824914,
            "fpr": 0.0010976948408342481,
            "logloss": 18.772540116225006,
            "mae": 0.5461654581402591,
            "precision": 0.5,
            "recall": 0.002008032128514056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8275879583723036,
            "auditor_fn_violation": 0.005746960603262543,
            "auditor_fp_violation": 0.019929208987380733,
            "ave_precision_score": 0.8282008370475819,
            "fpr": 0.10964912280701754,
            "logloss": 0.609082228278862,
            "mae": 0.2536373085228467,
            "precision": 0.7821350762527233,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8294434208246246,
            "auditor_fn_violation": 0.019414650919815386,
            "auditor_fp_violation": 0.01419029722812119,
            "ave_precision_score": 0.8297014721041053,
            "fpr": 0.1350164654226125,
            "logloss": 0.7214609040974516,
            "mae": 0.29534459758610143,
            "precision": 0.7525150905432596,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7519903832840553,
            "auditor_fn_violation": 0.0005410318559556786,
            "auditor_fp_violation": 0.0031884810710988165,
            "ave_precision_score": 0.5125637018483941,
            "fpr": 0.47039473684210525,
            "logloss": 16.18542182385179,
            "mae": 0.476289957338485,
            "precision": 0.5136054421768708,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7795171392797492,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004640617898538992,
            "ave_precision_score": 0.5634255414254318,
            "fpr": 0.4270032930845225,
            "logloss": 14.53321905483441,
            "mae": 0.4284944864840358,
            "precision": 0.5614430665163472,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.7595322803477932,
            "auditor_fn_violation": 0.0011878654970760233,
            "auditor_fp_violation": 0.004434056632810096,
            "ave_precision_score": 0.5243519548298854,
            "fpr": 0.46271929824561403,
            "logloss": 15.522537469053631,
            "mae": 0.4680227093263774,
            "precision": 0.5182648401826484,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7774180956501533,
            "auditor_fn_violation": 0.0014547762950815335,
            "auditor_fp_violation": 0.010389562064942084,
            "ave_precision_score": 0.5619040659205662,
            "fpr": 0.429198682766191,
            "logloss": 14.509669139985064,
            "mae": 0.4330970174329469,
            "precision": 0.5591882750845547,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 6126,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.488539096927198,
            "auditor_fn_violation": 0.05722914742997847,
            "auditor_fp_violation": 0.012881367343798094,
            "ave_precision_score": 0.4879424999112979,
            "fpr": 0.14364035087719298,
            "logloss": 0.7011030843103215,
            "mae": 0.5021747749037387,
            "precision": 0.48221343873517786,
            "recall": 0.2675438596491228
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5405611036643803,
            "auditor_fn_violation": 0.03954787316114076,
            "auditor_fp_violation": 0.016324556204367926,
            "ave_precision_score": 0.5395293534360408,
            "fpr": 0.1251372118551043,
            "logloss": 0.7042612511530267,
            "mae": 0.5037760780357503,
            "precision": 0.5169491525423728,
            "recall": 0.24497991967871485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595247299585154,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243444046201823,
            "fpr": 0.4506578947368421,
            "logloss": 15.514119598183907,
            "mae": 0.4575638137309906,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7760480104079048,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009004818694301291,
            "ave_precision_score": 0.560921235118808,
            "fpr": 0.4270032930845225,
            "logloss": 14.50530972345769,
            "mae": 0.4292658949379469,
            "precision": 0.5594563986409966,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6370411629056237,
            "auditor_fn_violation": 0.002539242843951995,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5873481018468278,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4137897722592339,
            "mae": 0.4747991155630811,
            "precision": 0.9696969696969697,
            "recall": 0.07017543859649122
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.6695356493198116,
            "auditor_fn_violation": 0.008036536927071635,
            "auditor_fp_violation": 0.001507004781484307,
            "ave_precision_score": 0.6312499140072511,
            "fpr": 0.005488474204171241,
            "logloss": 1.5214377818270934,
            "mae": 0.499832451528063,
            "precision": 0.9019607843137255,
            "recall": 0.09236947791164658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8398900311921472,
            "auditor_fn_violation": 0.010868728839642969,
            "auditor_fp_violation": 0.01837344182825485,
            "ave_precision_score": 0.8402990003380432,
            "fpr": 0.10635964912280702,
            "logloss": 0.5755032895667308,
            "mae": 0.25285177409035153,
            "precision": 0.7858719646799117,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8345405054856408,
            "auditor_fn_violation": 0.02119344557152871,
            "auditor_fp_violation": 0.017727904572310983,
            "ave_precision_score": 0.8347944158627301,
            "fpr": 0.132821075740944,
            "logloss": 0.6885332640571387,
            "mae": 0.29459935294895107,
            "precision": 0.7560483870967742,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5545974497364572,
            "auditor_fn_violation": 0.0010916820560172367,
            "auditor_fp_violation": 0.006578947368421061,
            "ave_precision_score": 0.5559918113654335,
            "fpr": 0.4473684210526316,
            "logloss": 0.6926732406998649,
            "mae": 0.49599237501490534,
            "precision": 0.5148632580261593,
            "recall": 0.9495614035087719
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6138050306669323,
            "auditor_fn_violation": 0.0021424887254837145,
            "auditor_fp_violation": 0.0019561825734964017,
            "ave_precision_score": 0.614588481832448,
            "fpr": 0.41602634467618005,
            "logloss": 0.681617475439937,
            "mae": 0.491620909598473,
            "precision": 0.5525383707201889,
            "recall": 0.9397590361445783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 6126,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.33333333333333337,
            "auditor_fn_violation": 0.0006203831948291958,
            "auditor_fp_violation": 0.0001490843336411203,
            "ave_precision_score": 0.49999999999999994,
            "fpr": 0.0021929824561403508,
            "logloss": 17.198241696713215,
            "mae": 0.5010643092953518,
            "precision": 0.3333333333333333,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0.4250596605228084,
            "auditor_fn_violation": 0.0005268053553401377,
            "auditor_fp_violation": 0.0005767549163705371,
            "ave_precision_score": 0.5479104857042514,
            "fpr": 0.0010976948408342481,
            "logloss": 18.772512655623718,
            "mae": 0.546171503476528,
            "precision": 0.5,
            "recall": 0.002008032128514056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7595310784850806,
            "auditor_fn_violation": 0.0007574445983379503,
            "auditor_fp_violation": 0.008937846260387823,
            "ave_precision_score": 0.5243507529609359,
            "fpr": 0.4506578947368421,
            "logloss": 15.511355668595868,
            "mae": 0.4575020845518839,
            "precision": 0.5243055555555556,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7760389900357538,
            "auditor_fn_violation": 0.002548062722900383,
            "auditor_fp_violation": 0.009004818694301291,
            "ave_precision_score": 0.5609122158853458,
            "fpr": 0.4270032930845225,
            "logloss": 14.507366485504395,
            "mae": 0.4301009756969909,
            "precision": 0.5594563986409966,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7595454485874251,
            "auditor_fn_violation": 0.0005362226839027393,
            "auditor_fp_violation": 0.004782721606648193,
            "ave_precision_score": 0.5243651224410423,
            "fpr": 0.4682017543859649,
            "logloss": 15.531021892843636,
            "mae": 0.47111557617557864,
            "precision": 0.5158730158730159,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7774345424994645,
            "auditor_fn_violation": 0.0006568535392943895,
            "auditor_fp_violation": 0.009004818694301297,
            "ave_precision_score": 0.5619205108110096,
            "fpr": 0.43029637760702527,
            "logloss": 14.514907910247432,
            "mae": 0.43349712368051174,
            "precision": 0.5590551181102362,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.7595308760476627,
            "auditor_fn_violation": 0.0018395083102493075,
            "auditor_fp_violation": 0.003145198522622356,
            "ave_precision_score": 0.5243505506362686,
            "fpr": 0.45723684210526316,
            "logloss": 15.516117238322408,
            "mae": 0.46546892553165536,
            "precision": 0.5206896551724138,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7774358857372471,
            "auditor_fn_violation": 0.0014547762950815335,
            "auditor_fp_violation": 0.010389562064942084,
            "ave_precision_score": 0.5619218538563028,
            "fpr": 0.429198682766191,
            "logloss": 14.503926782149108,
            "mae": 0.43149766755294416,
            "precision": 0.5591882750845547,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8398932561704804,
            "auditor_fn_violation": 0.010868728839642969,
            "auditor_fp_violation": 0.01837344182825485,
            "ave_precision_score": 0.840302223208542,
            "fpr": 0.10635964912280702,
            "logloss": 0.5754928686010718,
            "mae": 0.252851604630573,
            "precision": 0.7858719646799117,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.834548121097483,
            "auditor_fn_violation": 0.02119344557152871,
            "auditor_fp_violation": 0.017727904572310983,
            "ave_precision_score": 0.8348020245510217,
            "fpr": 0.132821075740944,
            "logloss": 0.688517596326423,
            "mae": 0.29459898404246954,
            "precision": 0.7560483870967742,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8051844616346379,
            "auditor_fn_violation": 0.011722356879039702,
            "auditor_fp_violation": 0.025171206525084644,
            "ave_precision_score": 0.8056868937703556,
            "fpr": 0.1162280701754386,
            "logloss": 0.6556433103653716,
            "mae": 0.27063597646449244,
            "precision": 0.7670329670329671,
            "recall": 0.7653508771929824
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8202140814152417,
            "auditor_fn_violation": 0.015698358747834377,
            "auditor_fp_violation": 0.013507228041451935,
            "ave_precision_score": 0.8204901410733924,
            "fpr": 0.13062568605927552,
            "logloss": 0.7553848572816101,
            "mae": 0.30506831946733437,
            "precision": 0.7546391752577319,
            "recall": 0.7349397590361446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8049862183542585,
            "auditor_fn_violation": 0.016497864727608495,
            "auditor_fp_violation": 0.022506925207756243,
            "ave_precision_score": 0.8057014172912522,
            "fpr": 0.14035087719298245,
            "logloss": 0.6327069887354649,
            "mae": 0.2755348285095639,
            "precision": 0.747534516765286,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8183677807623182,
            "auditor_fn_violation": 0.011287741525928083,
            "auditor_fp_violation": 0.016313924777338052,
            "ave_precision_score": 0.8186758176237218,
            "fpr": 0.15148188803512624,
            "logloss": 0.7185515006375656,
            "mae": 0.30379059486390175,
            "precision": 0.7371428571428571,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595259911050041,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243456657354583,
            "fpr": 0.4506578947368421,
            "logloss": 15.514209695857499,
            "mae": 0.4572577497911943,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760518520926866,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009230736518686061,
            "ave_precision_score": 0.5609250763275739,
            "fpr": 0.424807903402854,
            "logloss": 14.504928148887522,
            "mae": 0.4289904642906873,
            "precision": 0.5607264472190693,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7976671170093736,
            "auditor_fn_violation": 0.015213815789473683,
            "auditor_fp_violation": 0.022300130809479842,
            "ave_precision_score": 0.7987773397447444,
            "fpr": 0.11732456140350878,
            "logloss": 0.6618006883559958,
            "mae": 0.27380947683700785,
            "precision": 0.7663755458515283,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.817570693439063,
            "auditor_fn_violation": 0.01568513350878818,
            "auditor_fp_violation": 0.012130458241083558,
            "ave_precision_score": 0.8178735419053706,
            "fpr": 0.13062568605927552,
            "logloss": 0.7495904453676069,
            "mae": 0.30463043293890574,
            "precision": 0.7551440329218106,
            "recall": 0.7369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595246921432542,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243443668260843,
            "fpr": 0.4506578947368421,
            "logloss": 15.513826252804257,
            "mae": 0.45744400759672776,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760505934724399,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009230736518686061,
            "ave_precision_score": 0.5609238178526976,
            "fpr": 0.424807903402854,
            "logloss": 14.50465083495993,
            "mae": 0.42908600106604866,
            "precision": 0.5607264472190693,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 6126,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7595234006484834,
            "auditor_fn_violation": 0.0007574445983379503,
            "auditor_fp_violation": 0.006463527239150504,
            "ave_precision_score": 0.5243430753798528,
            "fpr": 0.45285087719298245,
            "logloss": 15.515404104972195,
            "mae": 0.45894406407122595,
            "precision": 0.523094688221709,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7760505603950963,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.0093024986511377,
            "ave_precision_score": 0.5609237847948415,
            "fpr": 0.4281009879253567,
            "logloss": 14.507515129716191,
            "mae": 0.4299185848326537,
            "precision": 0.559322033898305,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8270589107477087,
            "auditor_fn_violation": 0.005802266081871344,
            "auditor_fp_violation": 0.02261753616497384,
            "ave_precision_score": 0.8275600857733167,
            "fpr": 0.11293859649122807,
            "logloss": 0.6366255071653506,
            "mae": 0.25284197966831795,
            "precision": 0.7780172413793104,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8270571744813544,
            "auditor_fn_violation": 0.02160122377545308,
            "auditor_fp_violation": 0.01994189925128175,
            "ave_precision_score": 0.8273304185131287,
            "fpr": 0.14050493962678376,
            "logloss": 0.757475653268935,
            "mae": 0.2943734268148638,
            "precision": 0.746031746031746,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.814514511658408,
            "auditor_fn_violation": 0.00659337488457987,
            "auditor_fp_violation": 0.024622960911049555,
            "ave_precision_score": 0.8152957814721562,
            "fpr": 0.12719298245614036,
            "logloss": 0.6257630181887517,
            "mae": 0.2631242263545994,
            "precision": 0.7613168724279835,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8236618117851086,
            "auditor_fn_violation": 0.012273021834869667,
            "auditor_fp_violation": 0.023405086606262445,
            "ave_precision_score": 0.8239321592227313,
            "fpr": 0.14709110867178923,
            "logloss": 0.7258134372635627,
            "mae": 0.2980871285264809,
            "precision": 0.7418111753371869,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595398218257486,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243594961249619,
            "fpr": 0.4506578947368421,
            "logloss": 15.508198811301444,
            "mae": 0.4566492264147257,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7760595254528772,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.006615405469337644,
            "ave_precision_score": 0.5609327487354895,
            "fpr": 0.42151481888035125,
            "logloss": 14.498200385264903,
            "mae": 0.4270812418061454,
            "precision": 0.5631399317406144,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8210325568092032,
            "auditor_fn_violation": 0.010753308710372424,
            "auditor_fp_violation": 0.025676169590643276,
            "ave_precision_score": 0.8217954890770569,
            "fpr": 0.1206140350877193,
            "logloss": 0.6270659097562982,
            "mae": 0.25524351913743326,
            "precision": 0.7698744769874477,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8289955417522272,
            "auditor_fn_violation": 0.021319085342467566,
            "auditor_fp_violation": 0.01863157586985007,
            "ave_precision_score": 0.82925074848654,
            "fpr": 0.14489571899012074,
            "logloss": 0.7321725646778408,
            "mae": 0.2936582977343038,
            "precision": 0.7441860465116279,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.759539943774558,
            "auditor_fn_violation": 0.0012311480455524776,
            "auditor_fp_violation": 0.0037535587873191827,
            "ave_precision_score": 0.5243596180063055,
            "fpr": 0.4616228070175439,
            "logloss": 15.51852201715668,
            "mae": 0.46659997763396077,
            "precision": 0.5188571428571429,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7774358857372471,
            "auditor_fn_violation": 0.0006568535392943895,
            "auditor_fp_violation": 0.010389562064942084,
            "ave_precision_score": 0.5619218538563028,
            "fpr": 0.429198682766191,
            "logloss": 14.505809706854924,
            "mae": 0.4321487341449278,
            "precision": 0.5596846846846847,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5548865746735561,
            "auditor_fn_violation": 0.0004135887965527857,
            "auditor_fp_violation": 0.0065284510618652,
            "ave_precision_score": 0.5562646407003802,
            "fpr": 0.4616228070175439,
            "logloss": 0.6933227842234132,
            "mae": 0.49572000034937735,
            "precision": 0.5177548682703322,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6152534601428102,
            "auditor_fn_violation": 0.0011153284928958427,
            "auditor_fp_violation": 0.0006325699082773794,
            "ave_precision_score": 0.6160390331061021,
            "fpr": 0.43029637760702527,
            "logloss": 0.6810854036188723,
            "mae": 0.49087756283327727,
            "precision": 0.5585585585585585,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 6126,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.33333333333333337,
            "auditor_fn_violation": 0.0006203831948291958,
            "auditor_fp_violation": 0.0001490843336411203,
            "ave_precision_score": 0.49999999999999994,
            "fpr": 0.0021929824561403508,
            "logloss": 17.19844230540686,
            "mae": 0.5011374194556131,
            "precision": 0.3333333333333333,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0.424858857309957,
            "auditor_fn_violation": 0.0005268053553401377,
            "auditor_fp_violation": 0.0005767549163705371,
            "ave_precision_score": 0.5477096824914,
            "fpr": 0.0010976948408342481,
            "logloss": 18.772602820313903,
            "mae": 0.546227028063534,
            "precision": 0.5,
            "recall": 0.002008032128514056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8315838496996124,
            "auditor_fn_violation": 0.011715143120960298,
            "auditor_fp_violation": 0.0205664242843952,
            "ave_precision_score": 0.8324555468285664,
            "fpr": 0.13486842105263158,
            "logloss": 0.5819631462637102,
            "mae": 0.25762301965584483,
            "precision": 0.757396449704142,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8324899900254693,
            "auditor_fn_violation": 0.019095040976198973,
            "auditor_fp_violation": 0.02443899288491746,
            "ave_precision_score": 0.8327411250591537,
            "fpr": 0.15587266739846323,
            "logloss": 0.6809307231246071,
            "mae": 0.2926612982280241,
            "precision": 0.7365491651205937,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6665639996883196,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6639621988490279,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4387328497646947,
            "mae": 0.46577794231211955,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6864937457557525,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6854951532505353,
            "fpr": 0.008781558726673985,
            "logloss": 1.5544401575559712,
            "mae": 0.49196839297515405,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.759525925783482,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243456004507545,
            "fpr": 0.4506578947368421,
            "logloss": 15.51600698260541,
            "mae": 0.457371113219691,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.776049296054634,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.010195538521646914,
            "ave_precision_score": 0.560922520604933,
            "fpr": 0.42590559824368823,
            "logloss": 14.506788213299293,
            "mae": 0.4293052323079653,
            "precision": 0.5605889014722537,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6632955995443854,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6607800628897837,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4299814497823644,
            "mae": 0.46668823800798254,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6804864273602206,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6796123197019954,
            "fpr": 0.008781558726673985,
            "logloss": 1.544603571192846,
            "mae": 0.49323841035452953,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 6126,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7595259638085562,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.006357725453985847,
            "ave_precision_score": 0.52434563845742,
            "fpr": 0.4517543859649123,
            "logloss": 15.510677571667799,
            "mae": 0.4594144775481677,
            "precision": 0.5231481481481481,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7760658330862967,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.009592205037701706,
            "ave_precision_score": 0.5609390556231412,
            "fpr": 0.4270032930845225,
            "logloss": 14.497994707646457,
            "mae": 0.4285126474741692,
            "precision": 0.5599547511312217,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595462497284377,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243659237982506,
            "fpr": 0.4506578947368421,
            "logloss": 15.508373063006387,
            "mae": 0.4568797168803497,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.776062019341284,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.006548959050400951,
            "ave_precision_score": 0.5609352423430106,
            "fpr": 0.4226125137211855,
            "logloss": 14.498988250771646,
            "mae": 0.42746994718708603,
            "precision": 0.5625,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8210189607670823,
            "auditor_fn_violation": 0.011222202985534011,
            "auditor_fp_violation": 0.02394967682363804,
            "ave_precision_score": 0.8217850063181329,
            "fpr": 0.12280701754385964,
            "logloss": 0.6283507408987168,
            "mae": 0.25529060120640124,
            "precision": 0.7661795407098121,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8291868751274838,
            "auditor_fn_violation": 0.023483616133028278,
            "auditor_fp_violation": 0.01863157586985007,
            "ave_precision_score": 0.8294402199529747,
            "fpr": 0.14489571899012074,
            "logloss": 0.7341484712102777,
            "mae": 0.2937278916030351,
            "precision": 0.7451737451737451,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.7511342079912593,
            "auditor_fn_violation": 0.0014187057556171129,
            "auditor_fp_violation": 0.0012551939058171734,
            "ave_precision_score": 0.5044443797068845,
            "fpr": 0.48903508771929827,
            "logloss": 16.900883337901146,
            "mae": 0.4917300129533958,
            "precision": 0.5044444444444445,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7733383626944006,
            "auditor_fn_violation": 0.0015275151098356103,
            "auditor_fp_violation": 0.002939589573759529,
            "ave_precision_score": 0.5493929084366342,
            "fpr": 0.4456641053787047,
            "logloss": 15.407427822635382,
            "mae": 0.44939645931623573,
            "precision": 0.5493895671476138,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8203286538408623,
            "auditor_fn_violation": 0.006211045706371196,
            "auditor_fp_violation": 0.02481532779316713,
            "ave_precision_score": 0.8210940976812771,
            "fpr": 0.12171052631578948,
            "logloss": 0.6351384554415581,
            "mae": 0.25504733467879764,
            "precision": 0.76875,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8285583790454192,
            "auditor_fn_violation": 0.02377236718553688,
            "auditor_fp_violation": 0.01863157586985007,
            "ave_precision_score": 0.8288144003361773,
            "fpr": 0.14489571899012074,
            "logloss": 0.7411042235442754,
            "mae": 0.29342293027161775,
            "precision": 0.7456647398843931,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7595164397443348,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007353224068944294,
            "ave_precision_score": 0.5243361149850989,
            "fpr": 0.45285087719298245,
            "logloss": 15.525109126631317,
            "mae": 0.4594835137537998,
            "precision": 0.522543352601156,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7760518639334117,
            "auditor_fn_violation": 0.0014591847080969325,
            "auditor_fp_violation": 0.006548959050400951,
            "ave_precision_score": 0.5609250881612987,
            "fpr": 0.4226125137211855,
            "logloss": 14.500054222591457,
            "mae": 0.4280411342508447,
            "precision": 0.5620022753128555,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.759549169345263,
            "auditor_fn_violation": 0.0005362226839027393,
            "auditor_fp_violation": 0.005879212834718398,
            "ave_precision_score": 0.5243688431361503,
            "fpr": 0.4682017543859649,
            "logloss": 15.535177738844775,
            "mae": 0.47225838586018654,
            "precision": 0.5158730158730159,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7774294286264029,
            "auditor_fn_violation": 0.0006568535392943895,
            "auditor_fp_violation": 0.008420090207658368,
            "ave_precision_score": 0.5619153975721531,
            "fpr": 0.4313940724478595,
            "logloss": 14.516258956900254,
            "mae": 0.433729578726878,
            "precision": 0.5584269662921348,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7519879304988495,
            "auditor_fn_violation": 0.0005410318559556786,
            "auditor_fp_violation": 0.0031884810710988165,
            "ave_precision_score": 0.5125612490885486,
            "fpr": 0.47039473684210525,
            "logloss": 16.187730455657853,
            "mae": 0.4763222690009237,
            "precision": 0.5136054421768708,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7795145818643143,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.006070544834056725,
            "ave_precision_score": 0.5634229843308419,
            "fpr": 0.4281009879253567,
            "logloss": 14.535570978743126,
            "mae": 0.42862158697537717,
            "precision": 0.5608108108108109,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8060026775245568,
            "auditor_fn_violation": 0.014629501385041552,
            "auditor_fp_violation": 0.022622345337026787,
            "ave_precision_score": 0.8068490074369756,
            "fpr": 0.13157894736842105,
            "logloss": 0.6275860328196731,
            "mae": 0.2709368379338854,
            "precision": 0.7575757575757576,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8191758613669333,
            "auditor_fn_violation": 0.008724249357473806,
            "auditor_fp_violation": 0.01529330778247037,
            "ave_precision_score": 0.8194780704758712,
            "fpr": 0.145993413830955,
            "logloss": 0.7193240154202407,
            "mae": 0.302058025334176,
            "precision": 0.7407407407407407,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595259911050041,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243456657354583,
            "fpr": 0.4506578947368421,
            "logloss": 15.51474263270589,
            "mae": 0.45721632573191306,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760492839567481,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009230736518686061,
            "ave_precision_score": 0.5609225085130671,
            "fpr": 0.424807903402854,
            "logloss": 14.505585714332101,
            "mae": 0.4290670183529957,
            "precision": 0.5607264472190693,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6665639996883196,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.6639621988490279,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4389159947642625,
            "mae": 0.46579755200486705,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6864950870112855,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.6854964927345049,
            "fpr": 0.008781558726673985,
            "logloss": 1.5545803702585603,
            "mae": 0.4919549750778047,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 6126,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5589192386696047,
            "auditor_fn_violation": 0.05271333487226839,
            "auditor_fp_violation": 0.05713777316097261,
            "ave_precision_score": 0.5061287433717411,
            "fpr": 0.38048245614035087,
            "logloss": 0.6993207615204399,
            "mae": 0.4987681527344281,
            "precision": 0.4971014492753623,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5600070470582093,
            "auditor_fn_violation": 0.056035337838731436,
            "auditor_fp_violation": 0.0592755214050494,
            "ave_precision_score": 0.5756526939514386,
            "fpr": 0.3238199780461032,
            "logloss": 0.6847797840628613,
            "mae": 0.49149431250621406,
            "precision": 0.5655375552282769,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7595495595959024,
            "auditor_fn_violation": 0.0005362226839027393,
            "auditor_fp_violation": 0.005222760849492156,
            "ave_precision_score": 0.5243692331671522,
            "fpr": 0.4692982456140351,
            "logloss": 15.537379957818697,
            "mae": 0.47330528026418106,
            "precision": 0.5152887882219706,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.777424298317407,
            "auditor_fn_violation": 0.0006568535392943895,
            "auditor_fp_violation": 0.00703534683701758,
            "ave_precision_score": 0.5619102679018382,
            "fpr": 0.43249176728869376,
            "logloss": 14.518424648570843,
            "mae": 0.43422727571311176,
            "precision": 0.5578002244668911,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595246921432542,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243443668260843,
            "fpr": 0.4506578947368421,
            "logloss": 15.513893692798367,
            "mae": 0.45741853735501525,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760518670212831,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009230736518686061,
            "ave_precision_score": 0.5609250912469568,
            "fpr": 0.424807903402854,
            "logloss": 14.504658084245126,
            "mae": 0.4290645760290572,
            "precision": 0.5607264472190693,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 6126,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5580952995792644,
            "auditor_fn_violation": 0.0006059556786703602,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5595695282739357,
            "fpr": 0.5,
            "logloss": 0.6947699524115969,
            "mae": 0.49666405145667103,
            "precision": 0.4994511525795829,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6273655990473002,
            "auditor_fn_violation": 0.0007538386256331584,
            "auditor_fp_violation": 0.0005714392028556073,
            "ave_precision_score": 0.6281953498265087,
            "fpr": 0.4522502744237102,
            "logloss": 0.6815395315467861,
            "mae": 0.49152064905731924,
            "precision": 0.5462555066079295,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 6126,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7595234006484834,
            "auditor_fn_violation": 0.0007574445983379503,
            "auditor_fp_violation": 0.006463527239150504,
            "ave_precision_score": 0.5243430753798528,
            "fpr": 0.45285087719298245,
            "logloss": 15.515406555103004,
            "mae": 0.4589475139052915,
            "precision": 0.523094688221709,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7760505603950963,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.0093024986511377,
            "ave_precision_score": 0.5609237847948415,
            "fpr": 0.4281009879253567,
            "logloss": 14.507524245414087,
            "mae": 0.429922656449377,
            "precision": 0.559322033898305,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5057226625548685,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5272627516944526,
            "fpr": 0.5,
            "logloss": 0.6932409409524587,
            "mae": 0.49686845954050096,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5074148812363626,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5436631188104446,
            "fpr": 0.45334796926454446,
            "logloss": 0.6919515699088312,
            "mae": 0.49612017356996085,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595221423344415,
            "auditor_fn_violation": 0.0007574445983379503,
            "auditor_fp_violation": 0.006357725453985847,
            "ave_precision_score": 0.524341817095363,
            "fpr": 0.4517543859649123,
            "logloss": 15.515872617105874,
            "mae": 0.458665978401444,
            "precision": 0.5236994219653179,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7760505877522244,
            "auditor_fn_violation": 0.0016267044026820785,
            "auditor_fp_violation": 0.0093024986511377,
            "ave_precision_score": 0.5609238121376654,
            "fpr": 0.4281009879253567,
            "logloss": 14.507727621331824,
            "mae": 0.4298020676734806,
            "precision": 0.559322033898305,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8241420319638635,
            "auditor_fn_violation": 0.013419994613727306,
            "auditor_fp_violation": 0.02481532779316713,
            "ave_precision_score": 0.8251146237027855,
            "fpr": 0.12171052631578948,
            "logloss": 0.6180439549277847,
            "mae": 0.25366831029919856,
            "precision": 0.7706611570247934,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8355485873758348,
            "auditor_fn_violation": 0.02894123144609173,
            "auditor_fp_violation": 0.019973793532371366,
            "ave_precision_score": 0.8357844716963287,
            "fpr": 0.14270032930845225,
            "logloss": 0.7230065686130015,
            "mae": 0.2897295509411753,
            "precision": 0.7519083969465649,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.7455633302910456,
            "auditor_fn_violation": 0.0018851954447522317,
            "auditor_fp_violation": 0.0057421514312096175,
            "ave_precision_score": 0.5083662914511713,
            "fpr": 0.46600877192982454,
            "logloss": 16.701688836692373,
            "mae": 0.48355263157894735,
            "precision": 0.5086705202312138,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7748782023890254,
            "auditor_fn_violation": 0.001992602682960161,
            "auditor_fp_violation": 0.000236549251414646,
            "ave_precision_score": 0.5594803580624528,
            "fpr": 0.42041712403951703,
            "logloss": 14.93807260747593,
            "mae": 0.43249176728869376,
            "precision": 0.5597701149425287,
            "recall": 0.9779116465863453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8205860808997351,
            "auditor_fn_violation": 0.0094067405355494,
            "auditor_fp_violation": 0.020270660203139428,
            "ave_precision_score": 0.8213655905656209,
            "fpr": 0.1206140350877193,
            "logloss": 0.6295994256210133,
            "mae": 0.253979791853548,
            "precision": 0.7708333333333334,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8325203811506862,
            "auditor_fn_violation": 0.026798742720608015,
            "auditor_fp_violation": 0.01824087092650229,
            "ave_precision_score": 0.8327690106252074,
            "fpr": 0.14050493962678376,
            "logloss": 0.7304213385211901,
            "mae": 0.29045826608570785,
            "precision": 0.7524177949709865,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6126838615772102,
            "auditor_fn_violation": 0.0029408087103724436,
            "auditor_fp_violation": 0.0005722914742997846,
            "ave_precision_score": 0.5933881943819784,
            "fpr": 0.0010964912280701754,
            "logloss": 1.4215451808852335,
            "mae": 0.4653807771287495,
            "precision": 0.98,
            "recall": 0.1074561403508772
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6536641219164079,
            "auditor_fn_violation": 0.007873425645501881,
            "auditor_fp_violation": 0.0020784439843399083,
            "ave_precision_score": 0.636381003304783,
            "fpr": 0.008781558726673985,
            "logloss": 1.5367216989179076,
            "mae": 0.4915229617733034,
            "precision": 0.8840579710144928,
            "recall": 0.12248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7926298135193636,
            "auditor_fn_violation": 0.017572714681440442,
            "auditor_fp_violation": 0.02001096491228071,
            "ave_precision_score": 0.7932087302509784,
            "fpr": 0.12938596491228072,
            "logloss": 0.6709090373275555,
            "mae": 0.2741012911233852,
            "precision": 0.7546777546777547,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8137728005201577,
            "auditor_fn_violation": 0.012054805390607439,
            "auditor_fp_violation": 0.016733866145017977,
            "ave_precision_score": 0.8141083469646019,
            "fpr": 0.13721185510428102,
            "logloss": 0.7555221429567585,
            "mae": 0.3036309987261401,
            "precision": 0.75,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7595259911050041,
            "auditor_fn_violation": 0.0009618344105878733,
            "auditor_fp_violation": 0.007855782548476471,
            "ave_precision_score": 0.5243456657354583,
            "fpr": 0.4506578947368421,
            "logloss": 15.514234101020483,
            "mae": 0.4573477573860002,
            "precision": 0.5237543453070683,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7760492839567481,
            "auditor_fn_violation": 0.0024863449406848028,
            "auditor_fp_violation": 0.009230736518686061,
            "ave_precision_score": 0.5609225085130671,
            "fpr": 0.424807903402854,
            "logloss": 14.50513238757588,
            "mae": 0.4290789685737735,
            "precision": 0.5607264472190693,
            "recall": 0.9919678714859438
        }
    }
]