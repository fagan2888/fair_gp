[
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.001",
        "seed": 29759,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.8220282797892782,
            "auditor_fn_violation": 0.0006861912846632846,
            "auditor_fp_violation": 0.0003679500765336159,
            "ave_precision_score": 0.7053583056585295,
            "fpr": 0.003289473684210526,
            "logloss": 5.976291116227149,
            "mae": 0.48501461988303807,
            "precision": 0.25,
            "recall": 0.002150537634408602
        },
        "train": {
            "accuracy": 0.4544456641053787,
            "auc_prc": 0.870534954299496,
            "auditor_fn_violation": 0.0009562740331194121,
            "auditor_fp_violation": 0.0016751551599461043,
            "ave_precision_score": 0.7810795371453899,
            "fpr": 0.010976948408342482,
            "logloss": 4.62059454804969,
            "mae": 0.4591247269622652,
            "precision": 0.16666666666666666,
            "recall": 0.00408997955010225,
            "self_error": 0.459124726962268,
            "self_fairness_violation": 0.0006034457707271837
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.01108080808080808",
        "seed": 29759,
        "test": {
            "accuracy": 0.43859649122807015,
            "auc_prc": 0.8354751730543027,
            "auditor_fn_violation": 0.003065459347292971,
            "auditor_fp_violation": 0.01214971152714,
            "ave_precision_score": 0.7303739936647933,
            "fpr": 0.05701754385964912,
            "logloss": 5.541483610377016,
            "mae": 0.44397926634768625,
            "precision": 0.08771929824561403,
            "recall": 0.010752688172043012
        },
        "train": {
            "accuracy": 0.42151481888035125,
            "auc_prc": 0.8832117426982367,
            "auditor_fn_violation": 0.0016139930277297054,
            "auditor_fp_violation": 0.0065809666997882635,
            "ave_precision_score": 0.8058829719096069,
            "fpr": 0.04610318331503842,
            "logloss": 4.14294726926959,
            "mae": 0.41777822129084397,
            "precision": 0.08695652173913043,
            "recall": 0.0081799591002045,
            "self_error": 0.41777822129084474,
            "self_fairness_violation": 0.009699693834101674
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.021161616161616163",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.031242424242424245",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.041323232323232324",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.0514040404040404",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.06148484848484849",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.07156565656565657",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.08164646464646465",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.09172727272727273",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.1018080808080808",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.11188888888888888",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.12196969696969698",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.13205050505050506",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.14213131313131314",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.15221212121212122",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.1622929292929293",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.17237373737373737",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.18245454545454545",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.19253535353535353",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2026161616161616",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2126969696969697",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.22277777777777777",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.23285858585858585",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.24293939393939395",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.25302020202020203",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2631010101010101",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2731818181818182",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.28326262626262627",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.29334343434343435",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.30342424242424243",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3135050505050505",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3235858585858586",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.33366666666666667",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.34374747474747475",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3538282828282828",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3639090909090909",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.373989898989899",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.38407070707070706",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.39415151515151514",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4042323232323232",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4143131313131313",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4243939393939394",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.43447474747474746",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.44455555555555554",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4546363636363636",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4647171717171717",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4747979797979798",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4848787878787879",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.494959595959596",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5050404040404041",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5151212121212121",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5252020202020202",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5352828282828282",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5453636363636364",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5554444444444444",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5655252525252525",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5756060606060606",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5856868686868687",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5957676767676767",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6058484848484849",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6159292929292929",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.626010101010101",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.636090909090909",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6461717171717172",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6562525252525253",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6663333333333333",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6764141414141415",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6864949494949495",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6965757575757576",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7066565656565656",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7167373737373738",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7268181818181818",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7368989898989899",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.746979797979798",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7570606060606061",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7671414141414141",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7772222222222223",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7873030303030303",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7973838383838384",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8074646464646464",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8175454545454546",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8276262626262626",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8377070707070707",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8477878787878788",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8578686868686869",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8679494949494949",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.878030303030303",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8881111111111111",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8981919191919192",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9082727272727272",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9183535353535354",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9284343434343434",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9385151515151515",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9485959595959595",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9586767676767677",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9687575757575758",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9788383838383838",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.988919191919192",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.999",
        "seed": 29759,
        "test": {
            "accuracy": 0.2236842105263158,
            "auc_prc": 0.8359645507767091,
            "auditor_fn_violation": 0.01624693454065273,
            "auditor_fp_violation": 0.013937948899093383,
            "ave_precision_score": 0.7155216630204382,
            "fpr": 0.35964912280701755,
            "logloss": 7.725883263877162,
            "mae": 0.2236842105263158,
            "precision": 0.20581113801452786,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.1712403951701427,
            "auc_prc": 0.8826582581486854,
            "auditor_fn_violation": 0.015280181557379799,
            "auditor_fp_violation": 0.012701525847852224,
            "ave_precision_score": 0.7904141180820888,
            "fpr": 0.3743139407244786,
            "logloss": 5.914504813389586,
            "mae": 0.1712403951701427,
            "precision": 0.18028846153846154,
            "recall": 0.15337423312883436,
            "self_error": 0.1712403951701427,
            "self_fairness_violation": 0.01270152584785221
        }
    }
]