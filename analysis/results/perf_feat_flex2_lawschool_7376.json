[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8341052532073701,
            "auditor_fn_violation": 0.03954708017508274,
            "auditor_fp_violation": 0.032706318301720896,
            "ave_precision_score": 0.8344762184401833,
            "fpr": 0.1337719298245614,
            "logloss": 1.1253828957294474,
            "mae": 0.2707937359447584,
            "precision": 0.758893280632411,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8074645892815399,
            "auditor_fn_violation": 0.04158620476175736,
            "auditor_fp_violation": 0.03410659836565435,
            "ave_precision_score": 0.8078970554152979,
            "fpr": 0.14050493962678376,
            "logloss": 1.041187230209235,
            "mae": 0.28088545533923903,
            "precision": 0.7282377919320594,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 7376,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8046984176889236,
            "auditor_fn_violation": 0.05989110707803993,
            "auditor_fp_violation": 0.04975819620650673,
            "ave_precision_score": 0.8046776704879345,
            "fpr": 0.16885964912280702,
            "logloss": 1.8579358210472243,
            "mae": 0.2988043094993967,
            "precision": 0.7110694183864915,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7568973089483051,
            "auditor_fn_violation": 0.06419490869607665,
            "auditor_fp_violation": 0.055221368459568244,
            "ave_precision_score": 0.7567418607045506,
            "fpr": 0.16245883644346873,
            "logloss": 1.870946498383924,
            "mae": 0.3124812388545581,
            "precision": 0.689727463312369,
            "recall": 0.7136659436008677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7821586907981035,
            "auditor_fn_violation": 0.015626668090103563,
            "auditor_fp_violation": 0.008570426663317006,
            "ave_precision_score": 0.7801426753710492,
            "fpr": 0.12609649122807018,
            "logloss": 1.0799170509512566,
            "mae": 0.3064750011827157,
            "precision": 0.7594142259414226,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8137085045934161,
            "auditor_fn_violation": 0.019806129470844418,
            "auditor_fp_violation": 0.015436028783998045,
            "ave_precision_score": 0.8130360244616524,
            "fpr": 0.12294182217343579,
            "logloss": 0.8253904296570297,
            "mae": 0.2886192682427682,
            "precision": 0.7511111111111111,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8007029861468515,
            "auditor_fn_violation": 0.05861668623892388,
            "auditor_fp_violation": 0.0522678264874597,
            "ave_precision_score": 0.8011917380158224,
            "fpr": 0.1699561403508772,
            "logloss": 1.5451219427953828,
            "mae": 0.30029293490257797,
            "precision": 0.7097378277153558,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7697708462821082,
            "auditor_fn_violation": 0.05771827102347544,
            "auditor_fp_violation": 0.054884742041712405,
            "ave_precision_score": 0.7696468992104762,
            "fpr": 0.16465422612513722,
            "logloss": 1.458836408360535,
            "mae": 0.3016592019606905,
            "precision": 0.6975806451612904,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7269255833181312,
            "auditor_fn_violation": 0.08428525675242875,
            "auditor_fp_violation": 0.08398233052799063,
            "ave_precision_score": 0.6170326642884605,
            "fpr": 0.26535087719298245,
            "logloss": 10.386440879587857,
            "mae": 0.4031858732346272,
            "precision": 0.6032786885245902,
            "recall": 0.7464503042596349
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6990085902834277,
            "auditor_fn_violation": 0.09016574953984918,
            "auditor_fp_violation": 0.10313452860104892,
            "ave_precision_score": 0.5801955886571936,
            "fpr": 0.278814489571899,
            "logloss": 11.043773245108966,
            "mae": 0.4144525465213355,
            "precision": 0.5694915254237288,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.757358153832921,
            "auditor_fn_violation": 0.006367655955304091,
            "auditor_fp_violation": 0.004239417158648413,
            "ave_precision_score": 0.7576135101862875,
            "fpr": 0.03399122807017544,
            "logloss": 4.154662928643976,
            "mae": 0.404085929079724,
            "precision": 0.8385416666666666,
            "recall": 0.3265720081135903
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.735624521215021,
            "auditor_fn_violation": 0.023651633088951393,
            "auditor_fp_violation": 0.006486156848396147,
            "ave_precision_score": 0.7370163017616542,
            "fpr": 0.025246981339187707,
            "logloss": 3.9243439855255944,
            "mae": 0.3838432452089622,
            "precision": 0.8606060606060606,
            "recall": 0.3080260303687636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8297389290241013,
            "auditor_fn_violation": 0.05182644745738586,
            "auditor_fp_violation": 0.03864935309634469,
            "ave_precision_score": 0.830240244533889,
            "fpr": 0.13267543859649122,
            "logloss": 1.3995569554622092,
            "mae": 0.2788835890071947,
            "precision": 0.753061224489796,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7862435772404113,
            "auditor_fn_violation": 0.0507916022773001,
            "auditor_fp_violation": 0.0387047200878156,
            "ave_precision_score": 0.7867218380289025,
            "fpr": 0.1394072447859495,
            "logloss": 1.4063257726815075,
            "mae": 0.294744975015808,
            "precision": 0.7202643171806168,
            "recall": 0.7093275488069414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7894274329507707,
            "auditor_fn_violation": 0.06586509376890502,
            "auditor_fp_violation": 0.05198258175271113,
            "ave_precision_score": 0.7881905328376188,
            "fpr": 0.17763157894736842,
            "logloss": 2.156610784592211,
            "mae": 0.3095219424367472,
            "precision": 0.6977611940298507,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7424932395153476,
            "auditor_fn_violation": 0.061328044079234055,
            "auditor_fp_violation": 0.062314916453226,
            "ave_precision_score": 0.7420996503430164,
            "fpr": 0.1800219538968167,
            "logloss": 2.1502605406558994,
            "mae": 0.31904430315170274,
            "precision": 0.672,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8225343896076401,
            "auditor_fn_violation": 0.023493381018469102,
            "auditor_fp_violation": 0.010732006029393296,
            "ave_precision_score": 0.8229440609973994,
            "fpr": 0.08223684210526316,
            "logloss": 0.8934828251151918,
            "mae": 0.2981556440867746,
            "precision": 0.8091603053435115,
            "recall": 0.6450304259634888
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8241673501788376,
            "auditor_fn_violation": 0.00224777425107925,
            "auditor_fp_violation": 0.017185022563727285,
            "ave_precision_score": 0.8244219242203903,
            "fpr": 0.10428100987925357,
            "logloss": 0.8301768942908576,
            "mae": 0.295109524122536,
            "precision": 0.7545219638242894,
            "recall": 0.6334056399132321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7648860260948069,
            "auditor_fn_violation": 0.05564303761431979,
            "auditor_fp_violation": 0.0463195578444919,
            "ave_precision_score": 0.7617096103142209,
            "fpr": 0.17653508771929824,
            "logloss": 1.952510683750409,
            "mae": 0.30651157958431813,
            "precision": 0.7040441176470589,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7261355164148198,
            "auditor_fn_violation": 0.05764445640294211,
            "auditor_fp_violation": 0.045951945359190144,
            "ave_precision_score": 0.7217307769790793,
            "fpr": 0.1800219538968167,
            "logloss": 1.950275349884687,
            "mae": 0.3156471030876329,
            "precision": 0.6777996070726916,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8326077658978508,
            "auditor_fn_violation": 0.04099498238496851,
            "auditor_fp_violation": 0.035898965791567226,
            "ave_precision_score": 0.8330264184695677,
            "fpr": 0.14583333333333334,
            "logloss": 1.1535686586097122,
            "mae": 0.27218381936800745,
            "precision": 0.7432432432432432,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8031710403191413,
            "auditor_fn_violation": 0.039083651013998584,
            "auditor_fp_violation": 0.03616782534455421,
            "ave_precision_score": 0.8035939574053542,
            "fpr": 0.145993413830955,
            "logloss": 1.0770131556345786,
            "mae": 0.28043481484167926,
            "precision": 0.7246376811594203,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8429606661193203,
            "auditor_fn_violation": 0.021749670830219562,
            "auditor_fp_violation": 0.01102248461248587,
            "ave_precision_score": 0.843267152650876,
            "fpr": 0.09978070175438597,
            "logloss": 0.7310018028368084,
            "mae": 0.26932025038506036,
            "precision": 0.8,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8455967344707191,
            "auditor_fn_violation": 0.0040312307278359705,
            "auditor_fp_violation": 0.021075740944017568,
            "ave_precision_score": 0.8458646095033253,
            "fpr": 0.10867178924259056,
            "logloss": 0.6955248629346094,
            "mae": 0.2674087160908205,
            "precision": 0.7729357798165137,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.789307895341956,
            "auditor_fn_violation": 0.05664611579659088,
            "auditor_fp_violation": 0.05262372817485242,
            "ave_precision_score": 0.7888579160445661,
            "fpr": 0.17434210526315788,
            "logloss": 1.83469938393061,
            "mae": 0.3038133944984857,
            "precision": 0.708256880733945,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7432156055536232,
            "auditor_fn_violation": 0.060320831676472904,
            "auditor_fp_violation": 0.05881692889376753,
            "ave_precision_score": 0.7433981283420946,
            "fpr": 0.1734357848518112,
            "logloss": 1.8975290922020998,
            "mae": 0.31516353212073606,
            "precision": 0.6788617886178862,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8320555985047997,
            "auditor_fn_violation": 0.04265417600797126,
            "auditor_fp_violation": 0.038979085542017344,
            "ave_precision_score": 0.8323921693433547,
            "fpr": 0.14583333333333334,
            "logloss": 1.1761639901005225,
            "mae": 0.2710549182890909,
            "precision": 0.745697896749522,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8047596397935435,
            "auditor_fn_violation": 0.04434830023977847,
            "auditor_fp_violation": 0.039343822417367974,
            "ave_precision_score": 0.8052127531022497,
            "fpr": 0.150384193194292,
            "logloss": 1.0947393764788265,
            "mae": 0.2812224029048824,
            "precision": 0.7192622950819673,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7117864997457923,
            "auditor_fn_violation": 0.08405172413793104,
            "auditor_fp_violation": 0.08475694008290416,
            "ave_precision_score": 0.6013836030729118,
            "fpr": 0.2708333333333333,
            "logloss": 10.591508266611902,
            "mae": 0.4052509648147244,
            "precision": 0.6035313001605136,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6888011962688906,
            "auditor_fn_violation": 0.092063499622593,
            "auditor_fp_violation": 0.10347359434077327,
            "ave_precision_score": 0.5698026097243114,
            "fpr": 0.27552140504939626,
            "logloss": 11.201755772075064,
            "mae": 0.4133855920262617,
            "precision": 0.5724020442930153,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8360146240445053,
            "auditor_fn_violation": 0.039340237002241915,
            "auditor_fp_violation": 0.03302558305070553,
            "ave_precision_score": 0.8364343787235575,
            "fpr": 0.13157894736842105,
            "logloss": 1.1115354940964728,
            "mae": 0.26735946407292727,
            "precision": 0.7633136094674556,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8103451483474765,
            "auditor_fn_violation": 0.042276728631262646,
            "auditor_fp_violation": 0.03342114892060007,
            "ave_precision_score": 0.8107555885444535,
            "fpr": 0.141602634467618,
            "logloss": 1.0289128495673454,
            "mae": 0.27847702884498504,
            "precision": 0.7278481012658228,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7920391482246534,
            "auditor_fn_violation": 0.02463880288957689,
            "auditor_fp_violation": 0.011545869446886911,
            "ave_precision_score": 0.7905727084531675,
            "fpr": 0.1206140350877193,
            "logloss": 1.0138310235509247,
            "mae": 0.2902048375157607,
            "precision": 0.7741273100616016,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8282592441296228,
            "auditor_fn_violation": 0.019737077083893887,
            "auditor_fp_violation": 0.016172703988291258,
            "ave_precision_score": 0.8276538381715837,
            "fpr": 0.11525795828759605,
            "logloss": 0.7639652519234897,
            "mae": 0.27029792075921016,
            "precision": 0.7717391304347826,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8050127848178763,
            "auditor_fn_violation": 0.023030764029749837,
            "auditor_fp_violation": 0.011221370849558267,
            "ave_precision_score": 0.8034834386519486,
            "fpr": 0.12719298245614036,
            "logloss": 0.9590164879379254,
            "mae": 0.2833922311010229,
            "precision": 0.7675350701402806,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8345067810888842,
            "auditor_fn_violation": 0.01722976110255232,
            "auditor_fp_violation": 0.014074887181363583,
            "ave_precision_score": 0.8347697113138309,
            "fpr": 0.1207464324917673,
            "logloss": 0.7382826835929105,
            "mae": 0.2656993955653342,
            "precision": 0.7639484978540773,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7925672917104556,
            "auditor_fn_violation": 0.06124782036226469,
            "auditor_fp_violation": 0.0507055227567726,
            "ave_precision_score": 0.7912793674659644,
            "fpr": 0.17543859649122806,
            "logloss": 2.1899261933972465,
            "mae": 0.30554526056947934,
            "precision": 0.7009345794392523,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.745991703269606,
            "auditor_fn_violation": 0.06476637672601204,
            "auditor_fp_violation": 0.06096353213806562,
            "ave_precision_score": 0.7454579940803691,
            "fpr": 0.17672886937431395,
            "logloss": 2.186552581004398,
            "mae": 0.31971637170620676,
            "precision": 0.6754032258064516,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.816731115998343,
            "auditor_fn_violation": 0.027516814348243837,
            "auditor_fp_violation": 0.01090472302474564,
            "ave_precision_score": 0.8151443647570177,
            "fpr": 0.11732456140350878,
            "logloss": 0.9259673080019651,
            "mae": 0.2763233874136826,
            "precision": 0.7802874743326489,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8364028140398732,
            "auditor_fn_violation": 0.0143914698872065,
            "auditor_fp_violation": 0.01855104281009879,
            "ave_precision_score": 0.8366184401008768,
            "fpr": 0.10867178924259056,
            "logloss": 0.7586405563533498,
            "mae": 0.25931874944082217,
            "precision": 0.7809734513274337,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8061042262831872,
            "auditor_fn_violation": 0.055663054695562444,
            "auditor_fp_violation": 0.0479289662102751,
            "ave_precision_score": 0.8056719918346089,
            "fpr": 0.16447368421052633,
            "logloss": 1.8357757709017544,
            "mae": 0.29495128715753205,
            "precision": 0.715370018975332,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.763763204816127,
            "auditor_fn_violation": 0.05892073500313117,
            "auditor_fp_violation": 0.051147700939138924,
            "ave_precision_score": 0.7635493347398392,
            "fpr": 0.16245883644346873,
            "logloss": 1.8318581422313167,
            "mae": 0.30588914682166163,
            "precision": 0.6929460580912863,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.854213735384687,
            "auditor_fn_violation": 0.024060531653677806,
            "auditor_fp_violation": 0.014288405979148348,
            "ave_precision_score": 0.8544453402385894,
            "fpr": 0.08771929824561403,
            "logloss": 0.6542676572443294,
            "mae": 0.27596259040091764,
            "precision": 0.8148148148148148,
            "recall": 0.7139959432048681
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8593401651808782,
            "auditor_fn_violation": 0.0017429774913029763,
            "auditor_fp_violation": 0.02054884742041713,
            "ave_precision_score": 0.8596012323302027,
            "fpr": 0.09769484083424808,
            "logloss": 0.6011196139905507,
            "mae": 0.26697995222712473,
            "precision": 0.7865707434052758,
            "recall": 0.7114967462039046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7359203040980492,
            "auditor_fn_violation": 0.08441203160029892,
            "auditor_fp_violation": 0.08345109492107358,
            "ave_precision_score": 0.6372202194321686,
            "fpr": 0.2598684210526316,
            "logloss": 9.631335793884578,
            "mae": 0.3943989935714464,
            "precision": 0.6089108910891089,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7037837385491215,
            "auditor_fn_violation": 0.08853230342095049,
            "auditor_fp_violation": 0.09883156482497865,
            "ave_precision_score": 0.5953671034662987,
            "fpr": 0.2722283205268935,
            "logloss": 10.321191676297754,
            "mae": 0.4075261701532562,
            "precision": 0.576068376068376,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7664792592832609,
            "auditor_fn_violation": 0.019592274296288396,
            "auditor_fp_violation": 0.0029518904660218574,
            "ave_precision_score": 0.7667450699530681,
            "fpr": 0.04057017543859649,
            "logloss": 3.793891555483681,
            "mae": 0.386521439450385,
            "precision": 0.8318181818181818,
            "recall": 0.3711967545638945
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7453117105806524,
            "auditor_fn_violation": 0.02751856675818092,
            "auditor_fp_violation": 0.0031174533479692663,
            "ave_precision_score": 0.7467164498961277,
            "fpr": 0.03951701427003293,
            "logloss": 3.588466214041859,
            "mae": 0.367354460865015,
            "precision": 0.8181818181818182,
            "recall": 0.351409978308026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7699651853833723,
            "auditor_fn_violation": 0.057878278353083526,
            "auditor_fp_violation": 0.050451681112088094,
            "ave_precision_score": 0.7675179581236641,
            "fpr": 0.17653508771929824,
            "logloss": 1.8422902169104014,
            "mae": 0.3024297175744687,
            "precision": 0.7024029574861368,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7387948174667112,
            "auditor_fn_violation": 0.05703727162113574,
            "auditor_fp_violation": 0.05440907427735091,
            "ave_precision_score": 0.7352196084536335,
            "fpr": 0.17233809001097694,
            "logloss": 1.757580696657437,
            "mae": 0.30615085097109856,
            "precision": 0.6866267465069861,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8116193685334478,
            "auditor_fn_violation": 0.04798984021920928,
            "auditor_fp_violation": 0.03458526985722062,
            "ave_precision_score": 0.8123295269092156,
            "fpr": 0.13157894736842105,
            "logloss": 1.4169348149196668,
            "mae": 0.28934845129684106,
            "precision": 0.7505197505197505,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7777116083771711,
            "auditor_fn_violation": 0.046948479775984535,
            "auditor_fp_violation": 0.03604829857299671,
            "ave_precision_score": 0.7782031105975084,
            "fpr": 0.12952799121844127,
            "logloss": 1.3981100479557351,
            "mae": 0.3015881501716571,
            "precision": 0.728735632183908,
            "recall": 0.6876355748373102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8435978718145116,
            "auditor_fn_violation": 0.02153170705668838,
            "auditor_fp_violation": 0.012542917556420887,
            "ave_precision_score": 0.843903939412689,
            "fpr": 0.09100877192982457,
            "logloss": 0.7404416555094006,
            "mae": 0.2712537615879898,
            "precision": 0.8100686498855835,
            "recall": 0.718052738336714
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.846398763237749,
            "auditor_fn_violation": 0.007995790185512816,
            "auditor_fp_violation": 0.01868520551286743,
            "ave_precision_score": 0.8466581459345408,
            "fpr": 0.10428100987925357,
            "logloss": 0.6958635038016875,
            "mae": 0.2678792964549078,
            "precision": 0.7748815165876777,
            "recall": 0.7093275488069414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7247459466963136,
            "auditor_fn_violation": 0.08781048717127506,
            "auditor_fp_violation": 0.0836081103713939,
            "ave_precision_score": 0.6131682627607556,
            "fpr": 0.2642543859649123,
            "logloss": 10.565677819222634,
            "mae": 0.4030684879897621,
            "precision": 0.6023102310231023,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6962859972111592,
            "auditor_fn_violation": 0.09001335806519975,
            "auditor_fp_violation": 0.10033662641785583,
            "ave_precision_score": 0.5770556232545473,
            "fpr": 0.27332601536772777,
            "logloss": 11.213871516067593,
            "mae": 0.41373724915747717,
            "precision": 0.5736301369863014,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8418663296290471,
            "auditor_fn_violation": 0.021925376321127368,
            "auditor_fp_violation": 0.013385567139806556,
            "ave_precision_score": 0.8421834076130654,
            "fpr": 0.10307017543859649,
            "logloss": 0.7489709484671863,
            "mae": 0.2696252655520549,
            "precision": 0.793859649122807,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8428152177901069,
            "auditor_fn_violation": 0.009088722792764263,
            "auditor_fp_violation": 0.018733991950237835,
            "ave_precision_score": 0.8430952511078347,
            "fpr": 0.11306256860592755,
            "logloss": 0.7136387006917229,
            "mae": 0.268671637256975,
            "precision": 0.7643020594965675,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8185917834313339,
            "auditor_fn_violation": 0.025179264083128722,
            "auditor_fp_violation": 0.011074823095925973,
            "ave_precision_score": 0.8189795734713964,
            "fpr": 0.09868421052631579,
            "logloss": 0.6881044393186788,
            "mae": 0.293178424096703,
            "precision": 0.7940503432494279,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.807058362966956,
            "auditor_fn_violation": 0.009103009493512655,
            "auditor_fp_violation": 0.02075618977924137,
            "ave_precision_score": 0.8074266600104618,
            "fpr": 0.11086717892425905,
            "logloss": 0.6897955663186225,
            "mae": 0.2957423692351896,
            "precision": 0.7651162790697674,
            "recall": 0.7136659436008677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8028763177735867,
            "auditor_fn_violation": 0.051690776128963396,
            "auditor_fp_violation": 0.05174444165305867,
            "ave_precision_score": 0.7958641213778821,
            "fpr": 0.17982456140350878,
            "logloss": 2.4241217592636897,
            "mae": 0.3005381135594269,
            "precision": 0.7018181818181818,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7603835124627627,
            "auditor_fn_violation": 0.052344090425291284,
            "auditor_fp_violation": 0.05770947676545922,
            "ave_precision_score": 0.7507024850706459,
            "fpr": 0.18331503841931943,
            "logloss": 2.4045722155354214,
            "mae": 0.30386327498461707,
            "precision": 0.6776061776061776,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8452361314882212,
            "auditor_fn_violation": 0.028871303512330523,
            "auditor_fp_violation": 0.024732550349621078,
            "ave_precision_score": 0.845536597213018,
            "fpr": 0.12719298245614036,
            "logloss": 1.0927681853321283,
            "mae": 0.26543334252069967,
            "precision": 0.7613168724279835,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8101807818678525,
            "auditor_fn_violation": 0.029437746892047315,
            "auditor_fp_violation": 0.025325039638980362,
            "ave_precision_score": 0.8105501070694632,
            "fpr": 0.14050493962678376,
            "logloss": 1.1189445450755062,
            "mae": 0.28220643440205645,
            "precision": 0.7270788912579957,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7922422931572921,
            "auditor_fn_violation": 0.012137023593466433,
            "auditor_fp_violation": 0.010509567474772852,
            "ave_precision_score": 0.7880932032379544,
            "fpr": 0.10416666666666667,
            "logloss": 1.2663902635354818,
            "mae": 0.2913569764171401,
            "precision": 0.7907488986784141,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8145235205194794,
            "auditor_fn_violation": 0.012079405482759521,
            "auditor_fp_violation": 0.006766678863276013,
            "ave_precision_score": 0.8137504884648288,
            "fpr": 0.10098792535675083,
            "logloss": 0.9599921354898925,
            "mae": 0.2753507374546273,
            "precision": 0.784037558685446,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7849096615560506,
            "auditor_fn_violation": 0.050131667912173945,
            "auditor_fp_violation": 0.050498785747184194,
            "ave_precision_score": 0.7725360189310961,
            "fpr": 0.19407894736842105,
            "logloss": 2.331912135608963,
            "mae": 0.3097493820018151,
            "precision": 0.6894736842105263,
            "recall": 0.7971602434077079
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7633540548458081,
            "auditor_fn_violation": 0.04762709806153282,
            "auditor_fp_violation": 0.05788510793999268,
            "ave_precision_score": 0.7532700461925511,
            "fpr": 0.19099890230515917,
            "logloss": 2.0620388400718266,
            "mae": 0.3065273716904053,
            "precision": 0.6771799628942486,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7854981627213521,
            "auditor_fn_violation": 0.013858492580335226,
            "auditor_fp_violation": 0.0050532805761420285,
            "ave_precision_score": 0.7850269608841112,
            "fpr": 0.1118421052631579,
            "logloss": 0.9242547602344099,
            "mae": 0.30131063010390396,
            "precision": 0.7815845824411135,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.822021173058479,
            "auditor_fn_violation": 0.000504796759776271,
            "auditor_fp_violation": 0.003919990242712527,
            "ave_precision_score": 0.8215613942403445,
            "fpr": 0.11306256860592755,
            "logloss": 0.7135756447916208,
            "mae": 0.2836327558754541,
            "precision": 0.7669683257918553,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8401362832715684,
            "auditor_fn_violation": 0.021006814704103063,
            "auditor_fp_violation": 0.016112402127035977,
            "ave_precision_score": 0.8405437300233207,
            "fpr": 0.11951754385964912,
            "logloss": 0.7313856099383905,
            "mae": 0.2651390636174183,
            "precision": 0.7775510204081633,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8402039068709046,
            "auditor_fn_violation": 0.009057768274476092,
            "auditor_fp_violation": 0.019534089523112575,
            "ave_precision_score": 0.8404820882863582,
            "fpr": 0.13611416026344675,
            "logloss": 0.7202311811493707,
            "mae": 0.26972182432383063,
            "precision": 0.7372881355932204,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8302580621492957,
            "auditor_fn_violation": 0.04280096793708409,
            "auditor_fp_violation": 0.039895009002219164,
            "ave_precision_score": 0.8307270327517868,
            "fpr": 0.14802631578947367,
            "logloss": 1.1860581154770307,
            "mae": 0.27259811492408875,
            "precision": 0.7433460076045627,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8036981020457346,
            "auditor_fn_violation": 0.04327679768364958,
            "auditor_fp_violation": 0.040973289425539704,
            "ave_precision_score": 0.804152673267881,
            "fpr": 0.15477497255762898,
            "logloss": 1.0985045999162186,
            "mae": 0.28244060869054716,
            "precision": 0.7139959432048681,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8238827497000221,
            "auditor_fn_violation": 0.04665536813636525,
            "auditor_fp_violation": 0.039170121006573716,
            "ave_precision_score": 0.8243419209383842,
            "fpr": 0.14144736842105263,
            "logloss": 1.3198426326635162,
            "mae": 0.2799951485824384,
            "precision": 0.7440476190476191,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7938503897797882,
            "auditor_fn_violation": 0.046853235104328636,
            "auditor_fp_violation": 0.0391218441273326,
            "ave_precision_score": 0.794286872274063,
            "fpr": 0.14050493962678376,
            "logloss": 1.2377706131256603,
            "mae": 0.2881715604163939,
            "precision": 0.7241379310344828,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7266679112732655,
            "auditor_fn_violation": 0.08554633287071635,
            "auditor_fp_violation": 0.0836081103713939,
            "ave_precision_score": 0.6173086496798078,
            "fpr": 0.2642543859649123,
            "logloss": 10.373367334212539,
            "mae": 0.4031120687195963,
            "precision": 0.6036184210526315,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6986343256072218,
            "auditor_fn_violation": 0.09016574953984918,
            "auditor_fp_violation": 0.10271984388340044,
            "ave_precision_score": 0.5803793124672323,
            "fpr": 0.27771679473106475,
            "logloss": 11.030248148118982,
            "mae": 0.4144849247414098,
            "precision": 0.5704584040747029,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7427512260800383,
            "auditor_fn_violation": 0.07463702359346643,
            "auditor_fp_violation": 0.08253778838504376,
            "ave_precision_score": 0.6266303870251058,
            "fpr": 0.2675438596491228,
            "logloss": 10.319545793750246,
            "mae": 0.38866309073617383,
            "precision": 0.6108452950558214,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7200910604909555,
            "auditor_fn_violation": 0.08222472504053853,
            "auditor_fp_violation": 0.10058543724844493,
            "ave_precision_score": 0.5946740411359338,
            "fpr": 0.27991218441273324,
            "logloss": 10.862428458812595,
            "mae": 0.4053465771471897,
            "precision": 0.5764119601328903,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8076245489207823,
            "auditor_fn_violation": 0.019643429059464083,
            "auditor_fp_violation": 0.015722480425407196,
            "ave_precision_score": 0.8078959714322862,
            "fpr": 0.1118421052631579,
            "logloss": 0.9595932237757988,
            "mae": 0.2693583342856349,
            "precision": 0.7875,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8039631846616581,
            "auditor_fn_violation": 0.004740803531672428,
            "auditor_fp_violation": 0.016233687035004277,
            "ave_precision_score": 0.8042863248980088,
            "fpr": 0.12623490669593854,
            "logloss": 0.8269353861165771,
            "mae": 0.27252055748070353,
            "precision": 0.7489082969432315,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7275904581118372,
            "auditor_fn_violation": 0.08428525675242875,
            "auditor_fp_violation": 0.0836081103713939,
            "ave_precision_score": 0.6190519401033857,
            "fpr": 0.2642543859649123,
            "logloss": 10.314414633065473,
            "mae": 0.4029077751732286,
            "precision": 0.6042692939244664,
            "recall": 0.7464503042596349
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.697367372264952,
            "auditor_fn_violation": 0.09016574953984918,
            "auditor_fp_violation": 0.10271984388340044,
            "ave_precision_score": 0.5795041058096853,
            "fpr": 0.27771679473106475,
            "logloss": 11.004612315131151,
            "mae": 0.4143183034493984,
            "precision": 0.5704584040747029,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8165220741572125,
            "auditor_fn_violation": 0.021220330237358098,
            "auditor_fp_violation": 0.022340681656408328,
            "ave_precision_score": 0.7873625982824836,
            "fpr": 0.14035087719298245,
            "logloss": 3.657092707996516,
            "mae": 0.27138845924078514,
            "precision": 0.7465346534653465,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7735463210635354,
            "auditor_fn_violation": 0.013219960425838933,
            "auditor_fp_violation": 0.024310281741675818,
            "ave_precision_score": 0.7279995863778548,
            "fpr": 0.1437980241492865,
            "logloss": 4.208553144873315,
            "mae": 0.28051141865757095,
            "precision": 0.7270833333333333,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7658069114691997,
            "auditor_fn_violation": 0.05564303761431979,
            "auditor_fp_violation": 0.04726426747058578,
            "ave_precision_score": 0.7629442404219363,
            "fpr": 0.17982456140350878,
            "logloss": 1.9333366660136748,
            "mae": 0.306739599511856,
            "precision": 0.70018281535649,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7264591452231886,
            "auditor_fn_violation": 0.05613959059077888,
            "auditor_fp_violation": 0.047581412367361874,
            "ave_precision_score": 0.7222124724822556,
            "fpr": 0.18441273326015367,
            "logloss": 1.9506572864271678,
            "mae": 0.3160315229733804,
            "precision": 0.6737864077669903,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7936260998525483,
            "auditor_fn_violation": 0.05861668623892388,
            "auditor_fp_violation": 0.05503129841309719,
            "ave_precision_score": 0.7875025923808323,
            "fpr": 0.1787280701754386,
            "logloss": 2.562761687190513,
            "mae": 0.3071407406915397,
            "precision": 0.6992619926199262,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7490044568819066,
            "auditor_fn_violation": 0.05615149617473589,
            "auditor_fp_violation": 0.06315404317599707,
            "ave_precision_score": 0.7387294283456398,
            "fpr": 0.18111964873765093,
            "logloss": 2.5608518340234583,
            "mae": 0.3109164238874043,
            "precision": 0.677734375,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8383881334891804,
            "auditor_fn_violation": 0.020695437884772787,
            "auditor_fp_violation": 0.012762739186869324,
            "ave_precision_score": 0.8386736424399516,
            "fpr": 0.08991228070175439,
            "logloss": 0.7969788548161595,
            "mae": 0.2766008278161042,
            "precision": 0.8097447795823666,
            "recall": 0.7079107505070994
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8370172754669052,
            "auditor_fn_violation": 0.004059804129332751,
            "auditor_fp_violation": 0.01932430784241981,
            "ave_precision_score": 0.837332782917064,
            "fpr": 0.10757409440175632,
            "logloss": 0.754232775030704,
            "mae": 0.2730330322514182,
            "precision": 0.7649880095923262,
            "recall": 0.6919739696312365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7538141074606434,
            "auditor_fn_violation": 0.0684072630867229,
            "auditor_fp_violation": 0.06782805761420257,
            "ave_precision_score": 0.748143340178534,
            "fpr": 0.21052631578947367,
            "logloss": 2.993630783887577,
            "mae": 0.33160306266670875,
            "precision": 0.6672443674176777,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7162864032013816,
            "auditor_fn_violation": 0.07311219107986028,
            "auditor_fp_violation": 0.07745822661300159,
            "ave_precision_score": 0.7106366338645356,
            "fpr": 0.21295279912184412,
            "logloss": 2.955647047813904,
            "mae": 0.34496265208477006,
            "precision": 0.638733705772812,
            "recall": 0.7440347071583514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8169837386033034,
            "auditor_fn_violation": 0.01526191238745952,
            "auditor_fp_violation": 0.010763409119457354,
            "ave_precision_score": 0.815415070753312,
            "fpr": 0.10416666666666667,
            "logloss": 0.972777739277364,
            "mae": 0.2763613609276429,
            "precision": 0.7934782608695652,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8288039438215952,
            "auditor_fn_violation": 0.002281109886158809,
            "auditor_fp_violation": 0.015214050493962681,
            "ave_precision_score": 0.8290786934613039,
            "fpr": 0.10867178924259056,
            "logloss": 0.8527843184836299,
            "mae": 0.2661659299392512,
            "precision": 0.775,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8485146760672045,
            "auditor_fn_violation": 0.015955837870538416,
            "auditor_fp_violation": 0.025624921492274837,
            "ave_precision_score": 0.8487656544872861,
            "fpr": 0.24342105263157895,
            "logloss": 1.0626374524722877,
            "mae": 0.29514947703381744,
            "precision": 0.6740088105726872,
            "recall": 0.9310344827586207
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8437160658935257,
            "auditor_fn_violation": 0.006814756256979649,
            "auditor_fp_violation": 0.033894377363093066,
            "ave_precision_score": 0.8440849503837788,
            "fpr": 0.2623490669593853,
            "logloss": 1.0670583588080298,
            "mae": 0.3049840249270802,
            "precision": 0.6411411411411412,
            "recall": 0.9262472885032538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8042874579589887,
            "auditor_fn_violation": 0.023617931746201203,
            "auditor_fp_violation": 0.006448101159820804,
            "ave_precision_score": 0.8026531250219037,
            "fpr": 0.11732456140350878,
            "logloss": 0.9868918384599741,
            "mae": 0.2835904994351974,
            "precision": 0.7780082987551867,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.833293665921175,
            "auditor_fn_violation": 0.01792980943922319,
            "auditor_fp_violation": 0.009542627149652398,
            "ave_precision_score": 0.8336132584987005,
            "fpr": 0.10537870472008781,
            "logloss": 0.7577108489092573,
            "mae": 0.26487363044223544,
            "precision": 0.7828054298642534,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8142868371881025,
            "auditor_fn_violation": 0.01520186114373155,
            "auditor_fp_violation": 0.009475882426830796,
            "ave_precision_score": 0.8103294547304573,
            "fpr": 0.1074561403508772,
            "logloss": 1.099688520922012,
            "mae": 0.2760415339522113,
            "precision": 0.7850877192982456,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8230792764682636,
            "auditor_fn_violation": 0.005233694707491712,
            "auditor_fp_violation": 0.017421636784973788,
            "ave_precision_score": 0.82234929424932,
            "fpr": 0.10757409440175632,
            "logloss": 0.9394284295911999,
            "mae": 0.26623732047389775,
            "precision": 0.776255707762557,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8292236051932711,
            "auditor_fn_violation": 0.022984057506850293,
            "auditor_fp_violation": 0.00894202989574174,
            "ave_precision_score": 0.8296615000943599,
            "fpr": 0.09649122807017543,
            "logloss": 0.7985112130695043,
            "mae": 0.28572088513326915,
            "precision": 0.7972350230414746,
            "recall": 0.7018255578093306
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8240247326930186,
            "auditor_fn_violation": 0.0016858306883094384,
            "auditor_fp_violation": 0.019538968166849625,
            "ave_precision_score": 0.8247870229621805,
            "fpr": 0.1207464324917673,
            "logloss": 0.7449076168707421,
            "mae": 0.2826109676411626,
            "precision": 0.7441860465116279,
            "recall": 0.6941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 7376,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8258923724637336,
            "auditor_fn_violation": 0.04401533753247216,
            "auditor_fp_violation": 0.04240463928317213,
            "ave_precision_score": 0.8263880247495937,
            "fpr": 0.1513157894736842,
            "logloss": 1.2212965926945254,
            "mae": 0.27764966159934046,
            "precision": 0.7366412213740458,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.799669593882556,
            "auditor_fn_violation": 0.043474430377335574,
            "auditor_fp_violation": 0.039077936333699236,
            "ave_precision_score": 0.8001237530618985,
            "fpr": 0.14818880351262348,
            "logloss": 1.1303970365987541,
            "mae": 0.28572759036684425,
            "precision": 0.7216494845360825,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8436023513300652,
            "auditor_fn_violation": 0.021289277961638382,
            "auditor_fp_violation": 0.013576602604362937,
            "ave_precision_score": 0.8439064469243516,
            "fpr": 0.09978070175438597,
            "logloss": 0.7481970043509734,
            "mae": 0.26930354635153075,
            "precision": 0.7995594713656388,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8430126831603866,
            "auditor_fn_violation": 0.006009938781487305,
            "auditor_fp_violation": 0.019680448835223806,
            "ave_precision_score": 0.8433282434762626,
            "fpr": 0.11086717892425905,
            "logloss": 0.7147155697607088,
            "mae": 0.26828172439393316,
            "precision": 0.766743648960739,
            "recall": 0.720173535791757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.83045121791126,
            "auditor_fn_violation": 0.04280096793708409,
            "auditor_fp_violation": 0.039895009002219164,
            "ave_precision_score": 0.8307848505008414,
            "fpr": 0.14802631578947367,
            "logloss": 1.1869571260147764,
            "mae": 0.27287340745966665,
            "precision": 0.7433460076045627,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8031840399860593,
            "auditor_fn_violation": 0.04434830023977847,
            "auditor_fp_violation": 0.040973289425539704,
            "ave_precision_score": 0.8036393415116975,
            "fpr": 0.15477497255762898,
            "logloss": 1.0993216196055224,
            "mae": 0.28270589244396205,
            "precision": 0.7134146341463414,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8143550548763461,
            "auditor_fn_violation": 0.01526191238745952,
            "auditor_fp_violation": 0.010096093455596037,
            "ave_precision_score": 0.8114831999714,
            "fpr": 0.10307017543859649,
            "logloss": 1.0254606202472027,
            "mae": 0.2772189832772799,
            "precision": 0.7952069716775599,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8278613397460968,
            "auditor_fn_violation": 0.005167023437332578,
            "auditor_fp_violation": 0.015214050493962681,
            "ave_precision_score": 0.8281249984846504,
            "fpr": 0.10867178924259056,
            "logloss": 0.8637118243478009,
            "mae": 0.2663717469619222,
            "precision": 0.775,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 7376,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7209464586297474,
            "auditor_fn_violation": 0.07776858474787374,
            "auditor_fp_violation": 0.08722731650127707,
            "ave_precision_score": 0.6104198559069917,
            "fpr": 0.2642543859649123,
            "logloss": 10.331876412606949,
            "mae": 0.3848584149813803,
            "precision": 0.6156299840510366,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6928126147802973,
            "auditor_fn_violation": 0.08351290922468457,
            "auditor_fp_violation": 0.099939016953287,
            "ave_precision_score": 0.5753695917586513,
            "fpr": 0.2645444566410538,
            "logloss": 10.999765972649827,
            "mae": 0.39468174949718227,
            "precision": 0.5894378194207837,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 7376,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.801254555610262,
            "auditor_fn_violation": 0.06108768371232341,
            "auditor_fp_violation": 0.04883442197378889,
            "ave_precision_score": 0.801071792385577,
            "fpr": 0.1611842105263158,
            "logloss": 1.817886425544598,
            "mae": 0.2997438697333392,
            "precision": 0.7167630057803468,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7575488700430495,
            "auditor_fn_violation": 0.056937264715897065,
            "auditor_fp_violation": 0.0545042078302232,
            "ave_precision_score": 0.7574012222048696,
            "fpr": 0.16355653128430298,
            "logloss": 1.8026075358287872,
            "mae": 0.3063628737150528,
            "precision": 0.6927835051546392,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7862869930740644,
            "auditor_fn_violation": 0.06605859222091741,
            "auditor_fp_violation": 0.05155864003684629,
            "ave_precision_score": 0.7851187209887256,
            "fpr": 0.17763157894736842,
            "logloss": 2.229640142431066,
            "mae": 0.3126278922734599,
            "precision": 0.697196261682243,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7384918044708427,
            "auditor_fn_violation": 0.06352343376090254,
            "auditor_fp_violation": 0.06445420173191853,
            "ave_precision_score": 0.7381471192248563,
            "fpr": 0.18331503841931943,
            "logloss": 2.2262115194622294,
            "mae": 0.3221814871257682,
            "precision": 0.6679920477137177,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.805531540729848,
            "auditor_fn_violation": 0.05963755738229956,
            "auditor_fp_violation": 0.049454633002554114,
            "ave_precision_score": 0.8054782318855394,
            "fpr": 0.16557017543859648,
            "logloss": 1.8486102724991882,
            "mae": 0.29760566772351876,
            "precision": 0.7150943396226415,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7576609455777098,
            "auditor_fn_violation": 0.06285910217610265,
            "auditor_fp_violation": 0.054884742041712405,
            "ave_precision_score": 0.7575178692011091,
            "fpr": 0.16465422612513722,
            "logloss": 1.8633039266211469,
            "mae": 0.3115985310500762,
            "precision": 0.6881496881496881,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7445130401307615,
            "auditor_fn_violation": 0.07062915910465821,
            "auditor_fp_violation": 0.07113584976761714,
            "ave_precision_score": 0.7352133419223099,
            "fpr": 0.22039473684210525,
            "logloss": 3.402753794919104,
            "mae": 0.3423456381654987,
            "precision": 0.6564102564102564,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7048422802471221,
            "auditor_fn_violation": 0.07622192960942543,
            "auditor_fp_violation": 0.07927796072691791,
            "ave_precision_score": 0.6953282736668236,
            "fpr": 0.21953896816684962,
            "logloss": 3.3463760388451997,
            "mae": 0.35325989470349,
            "precision": 0.6323529411764706,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8177139598928629,
            "auditor_fn_violation": 0.02234573502722323,
            "auditor_fp_violation": 0.00971663945065528,
            "ave_precision_score": 0.8181498592751076,
            "fpr": 0.09978070175438597,
            "logloss": 0.9075296141380149,
            "mae": 0.28608769840087533,
            "precision": 0.7888631090487239,
            "recall": 0.6896551724137931
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8194177288376057,
            "auditor_fn_violation": 0.004986058561186368,
            "auditor_fp_violation": 0.020768386388583974,
            "ave_precision_score": 0.819724405031283,
            "fpr": 0.11855104281009879,
            "logloss": 0.8571020143380778,
            "mae": 0.28748666616845076,
            "precision": 0.7416267942583732,
            "recall": 0.6724511930585684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8003230493289157,
            "auditor_fn_violation": 0.03467180883242589,
            "auditor_fp_violation": 0.02230404471800025,
            "ave_precision_score": 0.7889410311202167,
            "fpr": 0.16228070175438597,
            "logloss": 1.4217936827387199,
            "mae": 0.2842908379005412,
            "precision": 0.725417439703154,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.804760695782433,
            "auditor_fn_violation": 0.022308683218603187,
            "auditor_fp_violation": 0.027603366264178565,
            "ave_precision_score": 0.797359897409045,
            "fpr": 0.15477497255762898,
            "logloss": 1.217898036909223,
            "mae": 0.27250010766331273,
            "precision": 0.7267441860465116,
            "recall": 0.8134490238611713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7716711980202231,
            "auditor_fn_violation": 0.021892014519056265,
            "auditor_fp_violation": 0.005487689988694888,
            "ave_precision_score": 0.7719235503926896,
            "fpr": 0.03618421052631579,
            "logloss": 3.663589740402129,
            "mae": 0.3844770170453638,
            "precision": 0.8493150684931506,
            "recall": 0.3772819472616633
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.751291232244798,
            "auditor_fn_violation": 0.02539937281383714,
            "auditor_fp_violation": 0.007244785949506038,
            "ave_precision_score": 0.7526841450409549,
            "fpr": 0.036223929747530186,
            "logloss": 3.47446753755674,
            "mae": 0.3634726062515966,
            "precision": 0.8324873096446701,
            "recall": 0.3557483731019523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7492864363849099,
            "auditor_fn_violation": 0.04916862389238818,
            "auditor_fp_violation": 0.05138330611732195,
            "ave_precision_score": 0.7428383318048926,
            "fpr": 0.2149122807017544,
            "logloss": 1.8527117904076826,
            "mae": 0.31294856106871316,
            "precision": 0.6760330578512397,
            "recall": 0.8296146044624746
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7060748571213393,
            "auditor_fn_violation": 0.041086170235563886,
            "auditor_fp_violation": 0.05544090742773509,
            "ave_precision_score": 0.700253099827481,
            "fpr": 0.22063666300768386,
            "logloss": 1.9117469542559642,
            "mae": 0.3251542580900941,
            "precision": 0.647985989492119,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7533385708770834,
            "auditor_fn_violation": 0.00068280488238853,
            "auditor_fp_violation": 0.003009462797805972,
            "ave_precision_score": 0.7536285125694867,
            "fpr": 0.03728070175438596,
            "logloss": 4.18698850623297,
            "mae": 0.3975622170006389,
            "precision": 0.8357487922705314,
            "recall": 0.3509127789046653
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.743345772203028,
            "auditor_fn_violation": 0.02373259105985891,
            "auditor_fp_violation": 0.0024881083058909638,
            "ave_precision_score": 0.7437392985304571,
            "fpr": 0.03293084522502744,
            "logloss": 3.894353295635214,
            "mae": 0.37792060452533066,
            "precision": 0.8324022346368715,
            "recall": 0.3232104121475054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8451601851838817,
            "auditor_fn_violation": 0.01894950357638519,
            "auditor_fp_violation": 0.01541106644893858,
            "ave_precision_score": 0.8454303086047905,
            "fpr": 0.10416666666666667,
            "logloss": 0.8008206016336198,
            "mae": 0.2671879199763567,
            "precision": 0.7939262472885033,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8306815552607822,
            "auditor_fn_violation": 0.005409897350055126,
            "auditor_fp_violation": 0.016131235516526406,
            "ave_precision_score": 0.8309794970505181,
            "fpr": 0.11745334796926454,
            "logloss": 0.7580771659884219,
            "mae": 0.2724562186370797,
            "precision": 0.759009009009009,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8075850320143484,
            "auditor_fn_violation": 0.05861001387850966,
            "auditor_fp_violation": 0.0479289662102751,
            "ave_precision_score": 0.8076382953329405,
            "fpr": 0.16447368421052633,
            "logloss": 1.7994198748326682,
            "mae": 0.2955736066633462,
            "precision": 0.714828897338403,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7606306919864292,
            "auditor_fn_violation": 0.062113812620395226,
            "auditor_fp_violation": 0.0545042078302232,
            "ave_precision_score": 0.7605020463557408,
            "fpr": 0.16355653128430298,
            "logloss": 1.8109604097738574,
            "mae": 0.3095622146926014,
            "precision": 0.6902286902286903,
            "recall": 0.720173535791757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7376268084045587,
            "auditor_fn_violation": 0.05557631401017757,
            "auditor_fp_violation": 0.06898997194657289,
            "ave_precision_score": 0.7235085373145369,
            "fpr": 0.2631578947368421,
            "logloss": 2.7339520025655735,
            "mae": 0.3496184030086924,
            "precision": 0.6335877862595419,
            "recall": 0.8417849898580122
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6799804551829025,
            "auditor_fn_violation": 0.05457043462524793,
            "auditor_fp_violation": 0.07774118794974998,
            "ave_precision_score": 0.6666838303866708,
            "fpr": 0.27552140504939626,
            "logloss": 2.90488465239876,
            "mae": 0.3634522707817963,
            "precision": 0.6009538950715422,
            "recall": 0.8199566160520607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7937466718533275,
            "auditor_fn_violation": 0.05036297640653358,
            "auditor_fp_violation": 0.049289766779717796,
            "ave_precision_score": 0.7721536015378592,
            "fpr": 0.19078947368421054,
            "logloss": 2.462495265148343,
            "mae": 0.300138886503239,
            "precision": 0.6968641114982579,
            "recall": 0.8113590263691683
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7708192169141032,
            "auditor_fn_violation": 0.044005419421817224,
            "auditor_fp_violation": 0.053874862788144906,
            "ave_precision_score": 0.7419672424785385,
            "fpr": 0.1877058177826564,
            "logloss": 2.6236815357340366,
            "mae": 0.2978746345967681,
            "precision": 0.6815642458100558,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.7350014549053286,
            "auditor_fn_violation": 0.08441203160029892,
            "auditor_fp_violation": 0.08323389021479713,
            "ave_precision_score": 0.6281792263382201,
            "fpr": 0.2631578947368421,
            "logloss": 10.213688146475695,
            "mae": 0.39791002413651005,
            "precision": 0.6059113300492611,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7032725116037415,
            "auditor_fn_violation": 0.08853230342095049,
            "auditor_fp_violation": 0.10005366508110745,
            "ave_precision_score": 0.5859948679959794,
            "fpr": 0.27552140504939626,
            "logloss": 10.98311273894884,
            "mae": 0.41043468638552966,
            "precision": 0.5731292517006803,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 7376,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7562044950330594,
            "auditor_fn_violation": 0.006365431835166016,
            "auditor_fp_violation": 0.004239417158648413,
            "ave_precision_score": 0.7564636333158089,
            "fpr": 0.03399122807017544,
            "logloss": 4.209045190883263,
            "mae": 0.40578990227323547,
            "precision": 0.8351063829787234,
            "recall": 0.3184584178498986
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.734422053253997,
            "auditor_fn_violation": 0.023534958366172913,
            "auditor_fp_violation": 0.0034833516282473482,
            "ave_precision_score": 0.7358158055063042,
            "fpr": 0.024149286498353458,
            "logloss": 3.9764126718990367,
            "mae": 0.3856750047196453,
            "precision": 0.8641975308641975,
            "recall": 0.3036876355748373
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7140777354889247,
            "auditor_fn_violation": 0.049531155474894145,
            "auditor_fp_violation": 0.027807436251727175,
            "ave_precision_score": 0.7053589509577103,
            "fpr": 0.21162280701754385,
            "logloss": 2.618019683661879,
            "mae": 0.32667127235755933,
            "precision": 0.6695205479452054,
            "recall": 0.7931034482758621
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.6960858326773293,
            "auditor_fn_violation": 0.047243738258117826,
            "auditor_fp_violation": 0.04054152945481157,
            "ave_precision_score": 0.6884495921155566,
            "fpr": 0.20856201975850713,
            "logloss": 2.372765003504075,
            "mae": 0.3317240005850846,
            "precision": 0.6513761467889908,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 7376,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7907769504449624,
            "auditor_fn_violation": 0.032463257535319034,
            "auditor_fp_violation": 0.02566417535485492,
            "ave_precision_score": 0.7911106213660675,
            "fpr": 0.14035087719298245,
            "logloss": 0.7192091182073876,
            "mae": 0.3416610670903354,
            "precision": 0.7276595744680852,
            "recall": 0.6937119675456389
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.77919560347192,
            "auditor_fn_violation": 0.026823280655092856,
            "auditor_fp_violation": 0.03256738626661788,
            "ave_precision_score": 0.780023522552487,
            "fpr": 0.132821075740944,
            "logloss": 0.6925817864821361,
            "mae": 0.3363565570304106,
            "precision": 0.7139479905437353,
            "recall": 0.6550976138828634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8241896264132753,
            "auditor_fn_violation": 0.025079178676915417,
            "auditor_fp_violation": 0.016497089980320737,
            "ave_precision_score": 0.8246073708139642,
            "fpr": 0.13596491228070176,
            "logloss": 0.7430103650825256,
            "mae": 0.2818868550571575,
            "precision": 0.756385068762279,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8384085715233708,
            "auditor_fn_violation": 0.013400925301985136,
            "auditor_fp_violation": 0.024998170508598615,
            "ave_precision_score": 0.8387571547224435,
            "fpr": 0.141602634467618,
            "logloss": 0.6758761605315966,
            "mae": 0.2769186071643265,
            "precision": 0.736734693877551,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8080467267647622,
            "auditor_fn_violation": 0.05558076225045372,
            "auditor_fp_violation": 0.043550852070510404,
            "ave_precision_score": 0.8080712631151102,
            "fpr": 0.1524122807017544,
            "logloss": 1.7893269265095724,
            "mae": 0.29258364075915344,
            "precision": 0.7300970873786408,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7649829285640598,
            "auditor_fn_violation": 0.05858975976912693,
            "auditor_fp_violation": 0.04971825832418588,
            "ave_precision_score": 0.7646642304374562,
            "fpr": 0.15697036223929747,
            "logloss": 1.794638373556096,
            "mae": 0.3045379685970243,
            "precision": 0.6976744186046512,
            "recall": 0.7158351409978309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7854390789016148,
            "auditor_fn_violation": 0.057237731753318394,
            "auditor_fp_violation": 0.05760896872252231,
            "ave_precision_score": 0.7842137671261855,
            "fpr": 0.18969298245614036,
            "logloss": 2.0244589338571686,
            "mae": 0.3103117031778306,
            "precision": 0.6921708185053381,
            "recall": 0.7890466531440162
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.746632927938182,
            "auditor_fn_violation": 0.06390203133073474,
            "auditor_fp_violation": 0.06461763629710941,
            "ave_precision_score": 0.7463476775639627,
            "fpr": 0.19099890230515917,
            "logloss": 1.9465603824397995,
            "mae": 0.3193781844196844,
            "precision": 0.6640926640926641,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 7376,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8051319217584473,
            "auditor_fn_violation": 0.021593982420554433,
            "auditor_fp_violation": 0.0104336766737847,
            "ave_precision_score": 0.803680849042382,
            "fpr": 0.13267543859649122,
            "logloss": 0.9567158590982862,
            "mae": 0.2833614373579723,
            "precision": 0.7613412228796844,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8350186077526955,
            "auditor_fn_violation": 0.013110429053434645,
            "auditor_fp_violation": 0.016109281619709728,
            "ave_precision_score": 0.8352887698954264,
            "fpr": 0.12952799121844127,
            "logloss": 0.7359080815458661,
            "mae": 0.26546732872473433,
            "precision": 0.7536534446764092,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.764957691539537,
            "auditor_fn_violation": 0.05564303761431979,
            "auditor_fp_violation": 0.0463195578444919,
            "ave_precision_score": 0.7617437007149689,
            "fpr": 0.17653508771929824,
            "logloss": 1.9530200232819945,
            "mae": 0.3065019587860255,
            "precision": 0.7040441176470589,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7261034810115823,
            "auditor_fn_violation": 0.05764445640294211,
            "auditor_fp_violation": 0.045951945359190144,
            "ave_precision_score": 0.7216881989246812,
            "fpr": 0.1800219538968167,
            "logloss": 1.9509448464597006,
            "mae": 0.3156259602589149,
            "precision": 0.6777996070726916,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8023515357266778,
            "auditor_fn_violation": 0.060665100886089465,
            "auditor_fp_violation": 0.050846836662060885,
            "ave_precision_score": 0.8023414387883601,
            "fpr": 0.17434210526315788,
            "logloss": 1.8698318049078382,
            "mae": 0.30056995878576037,
            "precision": 0.7060998151571165,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7578160929971449,
            "auditor_fn_violation": 0.05993270963947511,
            "auditor_fp_violation": 0.05646542261251373,
            "ave_precision_score": 0.7576242843870807,
            "fpr": 0.16794731064763996,
            "logloss": 1.8703476833835118,
            "mae": 0.31298899284761494,
            "precision": 0.6871165644171779,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 7376,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8422109348532382,
            "auditor_fn_violation": 0.021925376321127368,
            "auditor_fp_violation": 0.012480111376292765,
            "ave_precision_score": 0.842513878783252,
            "fpr": 0.09978070175438597,
            "logloss": 0.7477802458460809,
            "mae": 0.27011795475341693,
            "precision": 0.7991169977924945,
            "recall": 0.7342799188640974
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8432186936636461,
            "auditor_fn_violation": 0.009722099859276004,
            "auditor_fp_violation": 0.019270642761312354,
            "ave_precision_score": 0.8434902577641874,
            "fpr": 0.10976948408342481,
            "logloss": 0.7122128377043472,
            "mae": 0.26863496953180005,
            "precision": 0.76905311778291,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8062214348587083,
            "auditor_fn_violation": 0.05895252837977297,
            "auditor_fp_violation": 0.049454633002554114,
            "ave_precision_score": 0.8061830471395639,
            "fpr": 0.16557017543859648,
            "logloss": 1.8526556873587121,
            "mae": 0.29683887847133866,
            "precision": 0.7140151515151515,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7589402597346375,
            "auditor_fn_violation": 0.06246621790552206,
            "auditor_fp_violation": 0.05526527625320161,
            "ave_precision_score": 0.7586600920902522,
            "fpr": 0.16575192096597147,
            "logloss": 1.8673105142713682,
            "mae": 0.31110542028512944,
            "precision": 0.6880165289256198,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8410010355340276,
            "auditor_fn_violation": 0.021356001565780578,
            "auditor_fp_violation": 0.006612967382657122,
            "ave_precision_score": 0.8412995752955585,
            "fpr": 0.09758771929824561,
            "logloss": 0.7714579655980889,
            "mae": 0.2728333190787715,
            "precision": 0.8,
            "recall": 0.7221095334685599
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8404546166367514,
            "auditor_fn_violation": 0.005036062013805719,
            "auditor_fp_violation": 0.017563117453347973,
            "ave_precision_score": 0.8407924544447576,
            "fpr": 0.10537870472008781,
            "logloss": 0.7305363752415109,
            "mae": 0.27072429992985303,
            "precision": 0.7697841726618705,
            "recall": 0.6963123644251626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.836439554137422,
            "auditor_fn_violation": 0.013264652503469627,
            "auditor_fp_violation": 0.012665912992505138,
            "ave_precision_score": 0.8369474743996039,
            "fpr": 0.10964912280701754,
            "logloss": 0.7514770048745305,
            "mae": 0.2691323773294081,
            "precision": 0.7872340425531915,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8148144154593243,
            "auditor_fn_violation": 0.00042860102245155724,
            "auditor_fp_violation": 0.01828027808269301,
            "ave_precision_score": 0.8161167220599354,
            "fpr": 0.1350164654226125,
            "logloss": 0.8127486082703224,
            "mae": 0.2750736393870575,
            "precision": 0.7371794871794872,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7954339270317703,
            "auditor_fn_violation": 0.059713177466994054,
            "auditor_fp_violation": 0.05416771343633547,
            "ave_precision_score": 0.7957199503447571,
            "fpr": 0.17653508771929824,
            "logloss": 1.6996716291595801,
            "mae": 0.3030428252049288,
            "precision": 0.7018518518518518,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.764362592815387,
            "auditor_fn_violation": 0.058815965864309684,
            "auditor_fp_violation": 0.05640687888766924,
            "ave_precision_score": 0.7643271888566487,
            "fpr": 0.1690450054884742,
            "logloss": 1.5840431262733663,
            "mae": 0.3033156429807618,
            "precision": 0.692,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7515521045580578,
            "auditor_fn_violation": 0.05648375502651151,
            "auditor_fp_violation": 0.04969277310220659,
            "ave_precision_score": 0.7498960571441872,
            "fpr": 0.20285087719298245,
            "logloss": 2.1373229902245354,
            "mae": 0.31490734181634145,
            "precision": 0.6777003484320557,
            "recall": 0.7890466531440162
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.699283206830733,
            "auditor_fn_violation": 0.05033919008693458,
            "auditor_fp_violation": 0.05942919868276619,
            "ave_precision_score": 0.6951289690475443,
            "fpr": 0.2074643249176729,
            "logloss": 2.2398760353751417,
            "mae": 0.32506794385474064,
            "precision": 0.6512915129151291,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 7376,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7443445802927648,
            "auditor_fn_violation": 0.019127433187431056,
            "auditor_fp_violation": 0.003577335343131099,
            "ave_precision_score": 0.7412525814202114,
            "fpr": 0.04824561403508772,
            "logloss": 3.6767635014303797,
            "mae": 0.3815003135838748,
            "precision": 0.8158995815899581,
            "recall": 0.39553752535496955
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7183606721766553,
            "auditor_fn_violation": 0.026237525924409075,
            "auditor_fp_violation": 0.006086108061958775,
            "ave_precision_score": 0.7155773567468058,
            "fpr": 0.05159165751920966,
            "logloss": 3.6139577516863484,
            "mae": 0.3687757352515846,
            "precision": 0.7853881278538812,
            "recall": 0.37310195227765725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8019337928568556,
            "auditor_fn_violation": 0.025112540478986513,
            "auditor_fp_violation": 0.011616526399531047,
            "ave_precision_score": 0.8006066963637871,
            "fpr": 0.13706140350877194,
            "logloss": 0.9432408636792914,
            "mae": 0.28656159109173074,
            "precision": 0.7553816046966731,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.828371286619397,
            "auditor_fn_violation": 0.01729881348950285,
            "auditor_fp_violation": 0.016977680204903048,
            "ave_precision_score": 0.8286430869941265,
            "fpr": 0.13611416026344675,
            "logloss": 0.7499991381501874,
            "mae": 0.2720284692402594,
            "precision": 0.7459016393442623,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.820376930040528,
            "auditor_fn_violation": 0.014730347674459987,
            "auditor_fp_violation": 0.008332286563664535,
            "ave_precision_score": 0.8189492042859394,
            "fpr": 0.10197368421052631,
            "logloss": 0.9236722753116792,
            "mae": 0.27371179420623865,
            "precision": 0.7951541850220264,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8325230889529824,
            "auditor_fn_violation": 0.003883601486769328,
            "auditor_fp_violation": 0.016587388705939753,
            "ave_precision_score": 0.8327659498808939,
            "fpr": 0.10976948408342481,
            "logloss": 0.7995697490904989,
            "mae": 0.2639712732437612,
            "precision": 0.7737556561085973,
            "recall": 0.7418655097613883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8405604538556091,
            "auditor_fn_violation": 0.022334614426532864,
            "auditor_fp_violation": 0.011493530963446807,
            "ave_precision_score": 0.8408686764740697,
            "fpr": 0.09429824561403509,
            "logloss": 0.7804451822064751,
            "mae": 0.27361915100302026,
            "precision": 0.8036529680365296,
            "recall": 0.7139959432048681
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8404816295765751,
            "auditor_fn_violation": 0.000990544585221363,
            "auditor_fp_violation": 0.016319063300402496,
            "ave_precision_score": 0.8408193074619241,
            "fpr": 0.10428100987925357,
            "logloss": 0.7361187992223008,
            "mae": 0.27108627919977946,
            "precision": 0.7694174757281553,
            "recall": 0.6876355748373102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7649031560327622,
            "auditor_fn_violation": 0.027209885769189708,
            "auditor_fp_violation": 0.0039463216513838315,
            "ave_precision_score": 0.7651899713368485,
            "fpr": 0.05263157894736842,
            "logloss": 3.6051627842476606,
            "mae": 0.37383451103840576,
            "precision": 0.8117647058823529,
            "recall": 0.4198782961460446
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7484364630779692,
            "auditor_fn_violation": 0.027125682487600333,
            "auditor_fp_violation": 0.006617880229296258,
            "ave_precision_score": 0.7487326545319406,
            "fpr": 0.04720087815587267,
            "logloss": 3.409400320841709,
            "mae": 0.3546912724437132,
            "precision": 0.8130434782608695,
            "recall": 0.40563991323210413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8293123803833565,
            "auditor_fn_violation": 0.04386632148322124,
            "auditor_fp_violation": 0.038979085542017344,
            "ave_precision_score": 0.8298784886118095,
            "fpr": 0.14583333333333334,
            "logloss": 1.2095507020822927,
            "mae": 0.27339623954350306,
            "precision": 0.744721689059501,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8017548007660817,
            "auditor_fn_violation": 0.04189336882784764,
            "auditor_fp_violation": 0.04026344676180022,
            "ave_precision_score": 0.8022232012388368,
            "fpr": 0.14928649835345773,
            "logloss": 1.1239248696954376,
            "mae": 0.28345001382755813,
            "precision": 0.7184265010351967,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8183275770296727,
            "auditor_fn_violation": 0.018653695598021422,
            "auditor_fp_violation": 0.015861177406523482,
            "ave_precision_score": 0.7922332175857012,
            "fpr": 0.1162280701754386,
            "logloss": 1.9088624548994606,
            "mae": 0.2648853602384769,
            "precision": 0.7818930041152263,
            "recall": 0.77079107505071
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7789061484021872,
            "auditor_fn_violation": 0.0054122784668465245,
            "auditor_fp_violation": 0.020968410781802654,
            "ave_precision_score": 0.7369319426893489,
            "fpr": 0.12733260153677278,
            "logloss": 2.6039713950535495,
            "mae": 0.2773494304854156,
            "precision": 0.7478260869565218,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7943203876908869,
            "auditor_fn_violation": 0.056348083698089045,
            "auditor_fp_violation": 0.05288803751622493,
            "ave_precision_score": 0.7930090488119235,
            "fpr": 0.17434210526315788,
            "logloss": 1.9058423264609576,
            "mae": 0.3020242076160201,
            "precision": 0.7044609665427509,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7551015077862804,
            "auditor_fn_violation": 0.061006593312395385,
            "auditor_fp_violation": 0.058309549945115266,
            "ave_precision_score": 0.7549609233478757,
            "fpr": 0.17453347969264543,
            "logloss": 1.8258659009524771,
            "mae": 0.31156674708508464,
            "precision": 0.6794354838709677,
            "recall": 0.7310195227765727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7034446846552211,
            "auditor_fn_violation": 0.0755244475285577,
            "auditor_fp_violation": 0.08062481681530796,
            "ave_precision_score": 0.686555684268655,
            "fpr": 0.24671052631578946,
            "logloss": 4.50420903542908,
            "mae": 0.3678356385225708,
            "precision": 0.6323529411764706,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6642953871159221,
            "auditor_fn_violation": 0.08276761966897715,
            "auditor_fp_violation": 0.09510915965361628,
            "ave_precision_score": 0.6438664060827779,
            "fpr": 0.25466520307354557,
            "logloss": 4.706256329392389,
            "mae": 0.38388110253041724,
            "precision": 0.5993091537132987,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 7376,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7934912248034166,
            "auditor_fn_violation": 0.02540390021707413,
            "auditor_fp_violation": 0.013712682661307218,
            "ave_precision_score": 0.7921047037344962,
            "fpr": 0.13706140350877194,
            "logloss": 0.9669458342831121,
            "mae": 0.29074575593261526,
            "precision": 0.7544204322200393,
            "recall": 0.7789046653144016
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8323916202753829,
            "auditor_fn_violation": 0.016877355817425492,
            "auditor_fp_violation": 0.01599707281375778,
            "ave_precision_score": 0.8317675074480915,
            "fpr": 0.1251372118551043,
            "logloss": 0.7292860076613811,
            "mae": 0.2699000163408174,
            "precision": 0.762993762993763,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8009649300122711,
            "auditor_fn_violation": 0.03532125191274332,
            "auditor_fp_violation": 0.02084903487836537,
            "ave_precision_score": 0.7904805924954996,
            "fpr": 0.1513157894736842,
            "logloss": 1.3500617860918478,
            "mae": 0.283530240232008,
            "precision": 0.7371428571428571,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8083974956088196,
            "auditor_fn_violation": 0.020579992428048602,
            "auditor_fp_violation": 0.020795218929137698,
            "ave_precision_score": 0.8021396449889752,
            "fpr": 0.1437980241492865,
            "logloss": 1.1154323019278771,
            "mae": 0.26964547504880315,
            "precision": 0.7374749498997996,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8051372708934811,
            "auditor_fn_violation": 0.05989110707803993,
            "auditor_fp_violation": 0.050417661097852055,
            "ave_precision_score": 0.8051319727946025,
            "fpr": 0.16776315789473684,
            "logloss": 1.8609868032141341,
            "mae": 0.29824260707072997,
            "precision": 0.7124060150375939,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7575206599035829,
            "auditor_fn_violation": 0.06419490869607665,
            "auditor_fp_violation": 0.055221368459568244,
            "ave_precision_score": 0.7574030054505649,
            "fpr": 0.16245883644346873,
            "logloss": 1.8732968018991993,
            "mae": 0.31184910283179484,
            "precision": 0.689727463312369,
            "recall": 0.7136659436008677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 7376,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8385901166518137,
            "auditor_fn_violation": 0.03716727162734423,
            "auditor_fp_violation": 0.04123487417828582,
            "ave_precision_score": 0.8389278939622328,
            "fpr": 0.1611842105263158,
            "logloss": 1.112437974027217,
            "mae": 0.267946893514948,
            "precision": 0.7351351351351352,
            "recall": 0.8275862068965517
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7988964271792813,
            "auditor_fn_violation": 0.03418569377409393,
            "auditor_fp_violation": 0.03814123673618734,
            "ave_precision_score": 0.7991834811833823,
            "fpr": 0.1668496158068057,
            "logloss": 1.1192659986179228,
            "mae": 0.28200629227516044,
            "precision": 0.7076923076923077,
            "recall": 0.7982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 7376,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7363720995170588,
            "auditor_fn_violation": 0.0815829507846696,
            "auditor_fp_violation": 0.08256919147510783,
            "ave_precision_score": 0.6563463090133409,
            "fpr": 0.25877192982456143,
            "logloss": 8.515504371985578,
            "mae": 0.38937439261335993,
            "precision": 0.6124794745484401,
            "recall": 0.7565922920892495
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6989723985392685,
            "auditor_fn_violation": 0.08853230342095049,
            "auditor_fp_violation": 0.0980168313208928,
            "ave_precision_score": 0.609593136149081,
            "fpr": 0.270032930845225,
            "logloss": 9.146428919380995,
            "mae": 0.4035473309092491,
            "precision": 0.5780445969125214,
            "recall": 0.7310195227765727
        }
    }
]