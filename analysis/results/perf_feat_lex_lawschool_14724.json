[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7875561474070956,
            "auditor_fn_violation": 0.03268481795119164,
            "auditor_fp_violation": 0.005933033295828648,
            "ave_precision_score": 0.7879967509661773,
            "fpr": 0.047149122807017545,
            "logloss": 0.9211869383896465,
            "mae": 0.38452425642745575,
            "precision": 0.8200836820083682,
            "recall": 0.39918533604887985
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7653985863502909,
            "auditor_fn_violation": 0.03183789204657262,
            "auditor_fp_violation": 0.007306531284302965,
            "ave_precision_score": 0.7658438925403614,
            "fpr": 0.04610318331503842,
            "logloss": 0.8846906707232772,
            "mae": 0.37530320117400445,
            "precision": 0.8116591928251121,
            "recall": 0.39092872570194387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8366454136405734,
            "auditor_fn_violation": 0.01899542644799371,
            "auditor_fp_violation": 0.009785077301329334,
            "ave_precision_score": 0.8370749335301537,
            "fpr": 0.05592105263157895,
            "logloss": 0.6207372928592584,
            "mae": 0.32541575070775397,
            "precision": 0.8542857142857143,
            "recall": 0.6089613034623218
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8134068618039886,
            "auditor_fn_violation": 0.0089238085980564,
            "auditor_fp_violation": 0.0077941234122628185,
            "ave_precision_score": 0.8141015786215003,
            "fpr": 0.06476399560922064,
            "logloss": 0.5846301833305558,
            "mae": 0.3172103047179739,
            "precision": 0.8289855072463768,
            "recall": 0.6177105831533477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8689974854125637,
            "auditor_fn_violation": 0.01260183299389002,
            "auditor_fp_violation": 0.014517439679959998,
            "ave_precision_score": 0.8692331767475396,
            "fpr": 0.09649122807017543,
            "logloss": 0.4950316501100789,
            "mae": 0.290996253532189,
            "precision": 0.8135593220338984,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8362162921280265,
            "auditor_fn_violation": 0.003508830160766068,
            "auditor_fp_violation": 0.014274933354241806,
            "ave_precision_score": 0.8367114749531753,
            "fpr": 0.12184412733260154,
            "logloss": 0.5316059800301959,
            "mae": 0.2979997911514908,
            "precision": 0.7628205128205128,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8432079023593695,
            "auditor_fn_violation": 0.0162754135848787,
            "auditor_fp_violation": 0.008764116347876818,
            "ave_precision_score": 0.8434399002708588,
            "fpr": 0.06359649122807018,
            "logloss": 0.7142165717338486,
            "mae": 0.2978732031001981,
            "precision": 0.8440860215053764,
            "recall": 0.639511201629328
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.823266616205649,
            "auditor_fn_violation": 0.007145685205776296,
            "auditor_fp_violation": 0.007860279128116671,
            "ave_precision_score": 0.8235856280324003,
            "fpr": 0.07793633369923161,
            "logloss": 0.6719410019693844,
            "mae": 0.29534777573221543,
            "precision": 0.8011204481792717,
            "recall": 0.6177105831533477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7979636108558723,
            "auditor_fn_violation": 0.022849894593918615,
            "auditor_fp_violation": 0.004654227611784811,
            "ave_precision_score": 0.7982173283253424,
            "fpr": 0.08771929824561403,
            "logloss": 0.9450520044053277,
            "mae": 0.29524194242954155,
            "precision": 0.8034398034398035,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8047698117791668,
            "auditor_fn_violation": 0.016057639647884148,
            "auditor_fp_violation": 0.0027638387956719474,
            "ave_precision_score": 0.8052232073196388,
            "fpr": 0.10098792535675083,
            "logloss": 0.780240280620956,
            "mae": 0.295266680865387,
            "precision": 0.766497461928934,
            "recall": 0.652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8423518616533201,
            "auditor_fn_violation": 0.012717958337799694,
            "auditor_fp_violation": 0.0051568946118264805,
            "ave_precision_score": 0.8426376502565838,
            "fpr": 0.09758771929824561,
            "logloss": 0.7052210129846719,
            "mae": 0.27966393651557625,
            "precision": 0.7958715596330275,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8153373687374199,
            "auditor_fn_violation": 0.008617971374584222,
            "auditor_fp_violation": 0.011278324447232245,
            "ave_precision_score": 0.8156422573837532,
            "fpr": 0.11086717892425905,
            "logloss": 0.717248420001761,
            "mae": 0.2880800489623429,
            "precision": 0.7645687645687645,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8198894721065637,
            "auditor_fn_violation": 0.0022622110265480434,
            "auditor_fp_violation": 0.017267783472934117,
            "ave_precision_score": 0.820161216015346,
            "fpr": 0.08991228070175439,
            "logloss": 0.7940938205320088,
            "mae": 0.3166376241757217,
            "precision": 0.7892030848329049,
            "recall": 0.6252545824847251
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7870571342845506,
            "auditor_fn_violation": 0.0057943114276434145,
            "auditor_fp_violation": 0.016820703308765877,
            "ave_precision_score": 0.7874896223588859,
            "fpr": 0.10867178924259056,
            "logloss": 0.810779238040925,
            "mae": 0.32571071188196754,
            "precision": 0.7387862796833773,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8357275729509244,
            "auditor_fn_violation": 0.01490870761424948,
            "auditor_fp_violation": 0.014624223861316002,
            "ave_precision_score": 0.8360621788204199,
            "fpr": 0.09758771929824561,
            "logloss": 0.6580305775000737,
            "mae": 0.2888236788287087,
            "precision": 0.7890995260663507,
            "recall": 0.6782077393075356
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8031094637793722,
            "auditor_fn_violation": 0.0035846967588366806,
            "auditor_fp_violation": 0.008232711306256859,
            "ave_precision_score": 0.8035292119014713,
            "fpr": 0.11525795828759605,
            "logloss": 0.6698873861650531,
            "mae": 0.2963905212506322,
            "precision": 0.7511848341232228,
            "recall": 0.6846652267818575
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8163038979111445,
            "auditor_fn_violation": 0.02592274984814379,
            "auditor_fp_violation": 0.006443513772554906,
            "ave_precision_score": 0.8166840531983126,
            "fpr": 0.08223684210526316,
            "logloss": 0.9244558611358097,
            "mae": 0.3021124473157387,
            "precision": 0.8021108179419525,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7910510231218836,
            "auditor_fn_violation": 0.015038182236310236,
            "auditor_fp_violation": 0.0014603261721812795,
            "ave_precision_score": 0.7916587226893346,
            "fpr": 0.09330406147091108,
            "logloss": 0.8978389596772597,
            "mae": 0.30374525155493864,
            "precision": 0.7751322751322751,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8265249778625285,
            "auditor_fn_violation": 0.0004689677350198319,
            "auditor_fp_violation": 0.015968141851064713,
            "ave_precision_score": 0.826793556289163,
            "fpr": 0.08333333333333333,
            "logloss": 1.0433348267714835,
            "mae": 0.3122675362528372,
            "precision": 0.7929155313351499,
            "recall": 0.5926680244399185
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8105866223552582,
            "auditor_fn_violation": 0.007461005754007296,
            "auditor_fp_violation": 0.010016465422612517,
            "ave_precision_score": 0.8110182505198252,
            "fpr": 0.07464324917672886,
            "logloss": 1.0588224949631608,
            "mae": 0.29482922735592954,
            "precision": 0.8068181818181818,
            "recall": 0.6133909287257019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7872146083904566,
            "auditor_fn_violation": 0.022090613499124598,
            "auditor_fp_violation": 0.0074514522648664455,
            "ave_precision_score": 0.7874854776886968,
            "fpr": 0.0756578947368421,
            "logloss": 0.9742149808842467,
            "mae": 0.3183973542209697,
            "precision": 0.8056338028169014,
            "recall": 0.5824847250509165
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7957687667123795,
            "auditor_fn_violation": 0.01362753767843469,
            "auditor_fp_violation": 0.0009531323506350953,
            "ave_precision_score": 0.7962176578637781,
            "fpr": 0.09110867178924259,
            "logloss": 0.7917892887948921,
            "mae": 0.3120147080282189,
            "precision": 0.7688022284122563,
            "recall": 0.5961123110151187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8202759316070063,
            "auditor_fn_violation": 0.013501804409189985,
            "auditor_fp_violation": 0.010264303871317248,
            "ave_precision_score": 0.8223007655761232,
            "fpr": 0.13815789473684212,
            "logloss": 0.9147889123640152,
            "mae": 0.2505898774625113,
            "precision": 0.7627118644067796,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8238924609674986,
            "auditor_fn_violation": 0.0011166614903519037,
            "auditor_fp_violation": 0.007965638231143173,
            "ave_precision_score": 0.8242146095159938,
            "fpr": 0.1525795828759605,
            "logloss": 0.9418959329855792,
            "mae": 0.253410127980633,
            "precision": 0.7332053742802304,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8479277293063618,
            "auditor_fn_violation": 0.012257923321542146,
            "auditor_fp_violation": 0.005800204192190691,
            "ave_precision_score": 0.8482211854342854,
            "fpr": 0.09100877192982457,
            "logloss": 0.6311121575131263,
            "mae": 0.28397553957021676,
            "precision": 0.8042452830188679,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8144082473801499,
            "auditor_fn_violation": 0.0064486608360025,
            "auditor_fp_violation": 0.011650756625372434,
            "ave_precision_score": 0.8147419628585266,
            "fpr": 0.10208562019758508,
            "logloss": 0.6637566634140749,
            "mae": 0.295127619416059,
            "precision": 0.7759036144578313,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.82818283452118,
            "auditor_fn_violation": 0.0075124164790795755,
            "auditor_fp_violation": 0.00625859482435305,
            "ave_precision_score": 0.8282529537326059,
            "fpr": 0.14473684210526316,
            "logloss": 0.9681165011334955,
            "mae": 0.24668733691668274,
            "precision": 0.7582417582417582,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8270831015935107,
            "auditor_fn_violation": 0.0037245757990293834,
            "auditor_fp_violation": 8.330719774189027e-05,
            "ave_precision_score": 0.8273804989087776,
            "fpr": 0.15587266739846323,
            "logloss": 1.0031858065245665,
            "mae": 0.251883679898884,
            "precision": 0.7315689981096408,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8749638024814566,
            "auditor_fn_violation": 0.009368188801943764,
            "auditor_fp_violation": 0.011326936700420885,
            "ave_precision_score": 0.8752031959968634,
            "fpr": 0.08114035087719298,
            "logloss": 0.480621661316889,
            "mae": 0.3043502420689931,
            "precision": 0.8310502283105022,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8552861584706767,
            "auditor_fn_violation": 0.003620259226682283,
            "auditor_fp_violation": 0.009673435784851808,
            "ave_precision_score": 0.855545906144799,
            "fpr": 0.09220636663007684,
            "logloss": 0.4861381492061776,
            "mae": 0.29983408747301726,
            "precision": 0.8060046189376443,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6685135955959599,
            "auditor_fn_violation": 0.004316736341873013,
            "auditor_fp_violation": 0.019031024711422265,
            "ave_precision_score": 0.6699967035617921,
            "fpr": 0.20723684210526316,
            "logloss": 0.8216281641538989,
            "mae": 0.37627565544690905,
            "precision": 0.687603305785124,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6786537637755303,
            "auditor_fn_violation": 0.004924216381021022,
            "auditor_fp_violation": 0.01595577857926925,
            "ave_precision_score": 0.6806255241053315,
            "fpr": 0.21624588364434688,
            "logloss": 0.7342010882372981,
            "mae": 0.37119978162409933,
            "precision": 0.6626712328767124,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8691043520152614,
            "auditor_fn_violation": 0.012072569407224789,
            "auditor_fp_violation": 0.015106054923532107,
            "ave_precision_score": 0.869339864496306,
            "fpr": 0.09758771929824561,
            "logloss": 0.49431334939411936,
            "mae": 0.2909454667327768,
            "precision": 0.8134171907756813,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8368191216747507,
            "auditor_fn_violation": 0.001028940736332755,
            "auditor_fp_violation": 0.013691782970048616,
            "ave_precision_score": 0.8372777000135271,
            "fpr": 0.1251372118551043,
            "logloss": 0.5322026170781932,
            "mae": 0.2982963664350704,
            "precision": 0.758985200845666,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8183196768766445,
            "auditor_fn_violation": 0.018153517704648597,
            "auditor_fp_violation": 0.00700868858607326,
            "ave_precision_score": 0.8186618423067591,
            "fpr": 0.07236842105263158,
            "logloss": 0.964072316526058,
            "mae": 0.31262845033443337,
            "precision": 0.808695652173913,
            "recall": 0.5682281059063137
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7883519716673685,
            "auditor_fn_violation": 0.02001692773469451,
            "auditor_fp_violation": 0.007529500548847422,
            "ave_precision_score": 0.7890600047525821,
            "fpr": 0.0845225027442371,
            "logloss": 0.9340392339398047,
            "mae": 0.3096928701871819,
            "precision": 0.7824858757062146,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8295485219146479,
            "auditor_fn_violation": 0.015411173044627868,
            "auditor_fp_violation": 0.01517377172146519,
            "ave_precision_score": 0.8298725217640959,
            "fpr": 0.09100877192982457,
            "logloss": 0.6827275239336972,
            "mae": 0.2930309238132331,
            "precision": 0.8009592326139089,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.791607216324007,
            "auditor_fn_violation": 0.008423563217028255,
            "auditor_fp_violation": 0.006037321624588364,
            "ave_precision_score": 0.7920819559543073,
            "fpr": 0.11086717892425905,
            "logloss": 0.6947471369075088,
            "mae": 0.3027393003871152,
            "precision": 0.754257907542579,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 14724,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8347276432493284,
            "auditor_fn_violation": 0.015395540786793872,
            "auditor_fp_violation": 0.007659811643122056,
            "ave_precision_score": 0.8350060959776089,
            "fpr": 0.1337719298245614,
            "logloss": 0.836309894551813,
            "mae": 0.2517693459795844,
            "precision": 0.767175572519084,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8286154143772595,
            "auditor_fn_violation": 0.0001872956639868419,
            "auditor_fp_violation": 0.0058952093460875096,
            "ave_precision_score": 0.8289192594033309,
            "fpr": 0.15148188803512624,
            "logloss": 0.8711385444181704,
            "mae": 0.2577988569260473,
            "precision": 0.7330754352030948,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7998988456823375,
            "auditor_fn_violation": 0.017327241219137462,
            "auditor_fp_violation": 0.028620765095636963,
            "ave_precision_score": 0.8002818790675619,
            "fpr": 0.11842105263157894,
            "logloss": 0.6880659113036323,
            "mae": 0.31837420698269725,
            "precision": 0.7583892617449665,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7717792015676931,
            "auditor_fn_violation": 0.010858406848857142,
            "auditor_fp_violation": 0.03318566724164969,
            "ave_precision_score": 0.7721663852273596,
            "fpr": 0.14709110867178923,
            "logloss": 0.7089724281512388,
            "mae": 0.3318778366758162,
            "precision": 0.7035398230088495,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 14724,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8172064640350114,
            "auditor_fn_violation": 0.022289366491585392,
            "auditor_fp_violation": 0.002987352585739888,
            "ave_precision_score": 0.8175211354249413,
            "fpr": 0.06798245614035088,
            "logloss": 0.8175017326502488,
            "mae": 0.3253511662089949,
            "precision": 0.8154761904761905,
            "recall": 0.5580448065173116
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7869913966016081,
            "auditor_fn_violation": 0.015858489827948786,
            "auditor_fp_violation": 0.003959542104437823,
            "ave_precision_score": 0.7875296287913427,
            "fpr": 0.08562019758507135,
            "logloss": 0.7901833316868389,
            "mae": 0.32559258110856104,
            "precision": 0.7678571428571429,
            "recall": 0.5572354211663066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8189769969165599,
            "auditor_fn_violation": 0.020109783113588464,
            "auditor_fp_violation": 0.00700868858607326,
            "ave_precision_score": 0.8193163191962174,
            "fpr": 0.07236842105263158,
            "logloss": 0.9529409391490677,
            "mae": 0.31191259129013066,
            "precision": 0.8097982708933718,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7887160263820966,
            "auditor_fn_violation": 0.019258261753988332,
            "auditor_fp_violation": 0.0044201819037164814,
            "ave_precision_score": 0.7894232494102806,
            "fpr": 0.0867178924259056,
            "logloss": 0.9248935991740339,
            "mae": 0.3097124363270083,
            "precision": 0.7793296089385475,
            "recall": 0.6025917926565875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.826508589600051,
            "auditor_fn_violation": 0.01643620252259978,
            "auditor_fp_violation": 0.007162353627536776,
            "ave_precision_score": 0.8270530340517219,
            "fpr": 0.10635964912280702,
            "logloss": 0.8118085494571,
            "mae": 0.2734510856303328,
            "precision": 0.7834821428571429,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8214490306239013,
            "auditor_fn_violation": 0.005607015763656586,
            "auditor_fp_violation": 0.007046808844284149,
            "ave_precision_score": 0.8217652397924283,
            "fpr": 0.12733260153677278,
            "logloss": 0.7919689493119814,
            "mae": 0.2701844476296753,
            "precision": 0.7467248908296943,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7149744232164958,
            "auditor_fn_violation": 0.011002876335441468,
            "auditor_fp_violation": 0.0033311455598616507,
            "ave_precision_score": 0.7154359063455964,
            "fpr": 0.03508771929824561,
            "logloss": 1.6775637616447825,
            "mae": 0.43348310680378593,
            "precision": 0.803680981595092,
            "recall": 0.2668024439918534
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6463668724458832,
            "auditor_fn_violation": 0.006484223303848105,
            "auditor_fp_violation": 0.005468872510584916,
            "ave_precision_score": 0.6471366869274624,
            "fpr": 0.054884742041712405,
            "logloss": 1.7126565425216649,
            "mae": 0.4364851490468651,
            "precision": 0.6951219512195121,
            "recall": 0.24622030237580994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8400521533649377,
            "auditor_fn_violation": 0.03062582627648551,
            "auditor_fp_violation": 0.00885527357586365,
            "ave_precision_score": 0.8403250647638196,
            "fpr": 0.039473684210526314,
            "logloss": 0.715975490505588,
            "mae": 0.34523553077337565,
            "precision": 0.8745644599303136,
            "recall": 0.5112016293279023
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8108580597260207,
            "auditor_fn_violation": 0.030780501335963384,
            "auditor_fp_violation": 0.01290771522659558,
            "ave_precision_score": 0.8114586805512412,
            "fpr": 0.05598243688254665,
            "logloss": 0.6849695598619843,
            "mae": 0.33556284939326464,
            "precision": 0.8204225352112676,
            "recall": 0.5032397408207343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8379501802215745,
            "auditor_fn_violation": 0.012896612713045354,
            "auditor_fp_violation": 0.010959703296245371,
            "ave_precision_score": 0.8382675992893489,
            "fpr": 0.10307017543859649,
            "logloss": 0.6450220464631921,
            "mae": 0.28299196038207447,
            "precision": 0.7897091722595079,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8060567342549019,
            "auditor_fn_violation": 0.006047990364942044,
            "auditor_fp_violation": 0.007610357534891021,
            "ave_precision_score": 0.8064719473501838,
            "fpr": 0.11745334796926454,
            "logloss": 0.6653172261133924,
            "mae": 0.2917434799435918,
            "precision": 0.7562642369020501,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8346824569031492,
            "auditor_fn_violation": 0.01445313895737307,
            "auditor_fp_violation": 0.008334375130224614,
            "ave_precision_score": 0.8350020012443194,
            "fpr": 0.09320175438596491,
            "logloss": 0.6585532106049912,
            "mae": 0.2934251043690749,
            "precision": 0.7936893203883495,
            "recall": 0.6659877800407332
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8032360009721055,
            "auditor_fn_violation": 0.003449559381023404,
            "auditor_fp_violation": 0.008708052375725264,
            "ave_precision_score": 0.8036220591977339,
            "fpr": 0.10647639956092206,
            "logloss": 0.663532180479965,
            "mae": 0.3001639170965399,
            "precision": 0.7628361858190709,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8621372619005297,
            "auditor_fn_violation": 0.013758620073605607,
            "auditor_fp_violation": 0.013598053923407096,
            "ave_precision_score": 0.8623171569348554,
            "fpr": 0.07894736842105263,
            "logloss": 0.6032888812909715,
            "mae": 0.2882464987448124,
            "precision": 0.8269230769230769,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8158121588972073,
            "auditor_fn_violation": 0.0163871851832534,
            "auditor_fp_violation": 0.01463021405049396,
            "ave_precision_score": 0.8165966051448714,
            "fpr": 0.09989023051591657,
            "logloss": 0.6679394363327167,
            "mae": 0.3040444226346201,
            "precision": 0.7707808564231738,
            "recall": 0.6609071274298056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8077336925465959,
            "auditor_fn_violation": 0.0011523207203344415,
            "auditor_fp_violation": 0.012209859565779052,
            "ave_precision_score": 0.7761396361789015,
            "fpr": 0.20614035087719298,
            "logloss": 2.6557987038750817,
            "mae": 0.2582223182451227,
            "precision": 0.7067082683307332,
            "recall": 0.9226069246435845
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8020884420901838,
            "auditor_fn_violation": 0.005893886337611104,
            "auditor_fp_violation": 0.015465736239611108,
            "ave_precision_score": 0.763582135995075,
            "fpr": 0.21405049396267836,
            "logloss": 2.84345654199896,
            "mae": 0.27340767117851117,
            "precision": 0.6824104234527687,
            "recall": 0.9049676025917927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8576219921406099,
            "auditor_fn_violation": 0.012901079072426484,
            "auditor_fp_violation": 0.02035931574780181,
            "ave_precision_score": 0.8578968577884155,
            "fpr": 0.14802631578947367,
            "logloss": 0.6196582939918212,
            "mae": 0.2501096120052257,
            "precision": 0.7567567567567568,
            "recall": 0.8553971486761711
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8435920331688305,
            "auditor_fn_violation": 0.001680919313502123,
            "auditor_fp_violation": 0.008499784381370553,
            "ave_precision_score": 0.8438381692577226,
            "fpr": 0.15477497255762898,
            "logloss": 0.6671201251700055,
            "mae": 0.2612167846387235,
            "precision": 0.7374301675977654,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7986346379153141,
            "auditor_fn_violation": 0.021110247614964096,
            "auditor_fp_violation": 0.006563320415051883,
            "ave_precision_score": 0.7988864245196533,
            "fpr": 0.09320175438596491,
            "logloss": 0.9337361237152719,
            "mae": 0.293621484299631,
            "precision": 0.7961630695443646,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8054680197596582,
            "auditor_fn_violation": 0.01772907563662745,
            "auditor_fp_violation": 0.0019503685118394262,
            "ave_precision_score": 0.8059213602715292,
            "fpr": 0.10318331503841932,
            "logloss": 0.773135099819791,
            "mae": 0.293441873568608,
            "precision": 0.7667493796526055,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8616516133400673,
            "auditor_fn_violation": 0.012159663415157045,
            "auditor_fp_violation": 0.016522898695670293,
            "ave_precision_score": 0.8618860724577941,
            "fpr": 0.11732456140350878,
            "logloss": 0.5634645546759364,
            "mae": 0.26106761795927014,
            "precision": 0.7842741935483871,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8313763564187562,
            "auditor_fn_violation": 0.004774854016069494,
            "auditor_fp_violation": 0.007928885055668815,
            "ave_precision_score": 0.8316868422485149,
            "fpr": 0.12733260153677278,
            "logloss": 0.59912552979704,
            "mae": 0.27681493717236655,
            "precision": 0.7603305785123967,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 14724,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.848613774033389,
            "auditor_fn_violation": 0.012175295672991034,
            "auditor_fp_violation": 0.018666395799474936,
            "ave_precision_score": 0.8498383182426572,
            "fpr": 0.14912280701754385,
            "logloss": 0.7121494430616161,
            "mae": 0.24907192459001992,
            "precision": 0.7536231884057971,
            "recall": 0.8472505091649695
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8429557550063818,
            "auditor_fn_violation": 0.003961658918000064,
            "auditor_fp_violation": 0.011114160263446757,
            "ave_precision_score": 0.8432068478054795,
            "fpr": 0.16245883644346873,
            "logloss": 0.7665827538636332,
            "mae": 0.25900312570100653,
            "precision": 0.725417439703154,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7793945654816743,
            "auditor_fn_violation": 0.01506503019258943,
            "auditor_fp_violation": 0.003536900445889069,
            "ave_precision_score": 0.7797703279711754,
            "fpr": 0.051535087719298246,
            "logloss": 1.337518460204146,
            "mae": 0.37215355774187986,
            "precision": 0.8156862745098039,
            "recall": 0.42362525458248473
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7253789292707002,
            "auditor_fn_violation": 0.0069346812298923975,
            "auditor_fp_violation": 0.00559873373059433,
            "ave_precision_score": 0.72617588578446,
            "fpr": 0.06695938529088913,
            "logloss": 1.3512176534953577,
            "mae": 0.37808308782664235,
            "precision": 0.7520325203252033,
            "recall": 0.39956803455723544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8312133855763588,
            "auditor_fn_violation": 0.022713670632793802,
            "auditor_fp_violation": 0.006690940534233443,
            "ave_precision_score": 0.8315005500077204,
            "fpr": 0.07346491228070176,
            "logloss": 0.8669558568685152,
            "mae": 0.30217251040513354,
            "precision": 0.8169398907103825,
            "recall": 0.6089613034623218
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8030475021582317,
            "auditor_fn_violation": 0.01666931409482851,
            "auditor_fp_violation": 0.0006174533479692679,
            "ave_precision_score": 0.8036989730656675,
            "fpr": 0.09220636663007684,
            "logloss": 0.8453364443772475,
            "mae": 0.30231155743013605,
            "precision": 0.7723577235772358,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8106334744216245,
            "auditor_fn_violation": 0.020411262371815495,
            "auditor_fp_violation": 0.0077796182856190365,
            "ave_precision_score": 0.8110804434576322,
            "fpr": 0.1206140350877193,
            "logloss": 0.6412097650217061,
            "mae": 0.3142404560532764,
            "precision": 0.7603485838779956,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7855663175351031,
            "auditor_fn_violation": 0.002626880958195142,
            "auditor_fp_violation": 0.006576368198212329,
            "ave_precision_score": 0.7860216939551534,
            "fpr": 0.12952799121844127,
            "logloss": 0.6435942479704703,
            "mae": 0.31572335438432764,
            "precision": 0.7342342342342343,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8332638983873526,
            "auditor_fn_violation": 0.015018133419087438,
            "auditor_fp_violation": 0.02438325624036338,
            "ave_precision_score": 0.8345246355977165,
            "fpr": 0.13925438596491227,
            "logloss": 0.772348878594692,
            "mae": 0.26728482447878765,
            "precision": 0.7557692307692307,
            "recall": 0.8004073319755601
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8071926684613322,
            "auditor_fn_violation": 0.0037269466302190927,
            "auditor_fp_violation": 0.01624000313627098,
            "ave_precision_score": 0.8072368146481864,
            "fpr": 0.16794731064763996,
            "logloss": 0.8253234760109863,
            "mae": 0.28224610772595565,
            "precision": 0.7068965517241379,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.852699471727681,
            "auditor_fn_violation": 0.007686604494944081,
            "auditor_fp_violation": 0.012665645705713218,
            "ave_precision_score": 0.8529420875686735,
            "fpr": 0.09649122807017543,
            "logloss": 0.6140677536887744,
            "mae": 0.29868652679596813,
            "precision": 0.7972350230414746,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8245596868355046,
            "auditor_fn_violation": 0.006669148136645233,
            "auditor_fp_violation": 0.009359808687470595,
            "ave_precision_score": 0.8248771430767377,
            "fpr": 0.1163556531284303,
            "logloss": 0.6239769659814646,
            "mae": 0.30630984052848137,
            "precision": 0.7546296296296297,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8719937622482108,
            "auditor_fn_violation": 0.006561081930896484,
            "auditor_fp_violation": 0.004320852606575822,
            "ave_precision_score": 0.8722063215082445,
            "fpr": 0.02631578947368421,
            "logloss": 0.5982257100142103,
            "mae": 0.34907974439900563,
            "precision": 0.9136690647482014,
            "recall": 0.5173116089613035
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8468148651161878,
            "auditor_fn_violation": 0.00691334374918503,
            "auditor_fp_violation": 0.00568204092833621,
            "ave_precision_score": 0.8471239569702216,
            "fpr": 0.031833150384193196,
            "logloss": 0.5960653536547771,
            "mae": 0.3413037527139661,
            "precision": 0.8941605839416058,
            "recall": 0.5291576673866091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8211254843138575,
            "auditor_fn_violation": 0.022845428234537467,
            "auditor_fp_violation": 0.01711932741592699,
            "ave_precision_score": 0.8214527257862584,
            "fpr": 0.10855263157894737,
            "logloss": 0.8592319153944272,
            "mae": 0.28860340420114594,
            "precision": 0.7765237020316027,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7823102293139357,
            "auditor_fn_violation": 0.010308374012845165,
            "auditor_fp_violation": 0.003721871569703627,
            "ave_precision_score": 0.7837901487915498,
            "fpr": 0.12403951701427003,
            "logloss": 0.8728447335545579,
            "mae": 0.29272023472133424,
            "precision": 0.7390300230946882,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8141456677678496,
            "auditor_fn_violation": 0.0269321470682817,
            "auditor_fp_violation": 0.007977559694961871,
            "ave_precision_score": 0.8145046729083664,
            "fpr": 0.0712719298245614,
            "logloss": 0.841470128732927,
            "mae": 0.32056618437680107,
            "precision": 0.8104956268221575,
            "recall": 0.5661914460285132
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7923146074257437,
            "auditor_fn_violation": 0.01403057898068484,
            "auditor_fp_violation": 0.0009433315038419349,
            "ave_precision_score": 0.7928372301415584,
            "fpr": 0.0845225027442371,
            "logloss": 0.8077957885160927,
            "mae": 0.3219409192559209,
            "precision": 0.7694610778443114,
            "recall": 0.5550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8363889953812377,
            "auditor_fn_violation": 0.016628255975988854,
            "auditor_fp_violation": 0.010782597824728093,
            "ave_precision_score": 0.8368592613107901,
            "fpr": 0.05921052631578947,
            "logloss": 0.6067757720934528,
            "mae": 0.3257883323436672,
            "precision": 0.8491620111731844,
            "recall": 0.6191446028513238
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8129964444661939,
            "auditor_fn_violation": 0.012669721877793139,
            "auditor_fp_violation": 0.007139916888819196,
            "ave_precision_score": 0.8138705367940392,
            "fpr": 0.06695938529088913,
            "logloss": 0.5751374409885316,
            "mae": 0.3173181862164234,
            "precision": 0.827683615819209,
            "recall": 0.6328293736501079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7885501908521533,
            "auditor_fn_violation": 0.016760013577732526,
            "auditor_fp_violation": 0.0048052881610201326,
            "ave_precision_score": 0.7888201975663911,
            "fpr": 0.08333333333333333,
            "logloss": 0.9632005791165584,
            "mae": 0.3144283649968783,
            "precision": 0.7962466487935657,
            "recall": 0.604887983706721
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7977255650342839,
            "auditor_fn_violation": 0.012913917490332941,
            "auditor_fp_violation": 0.002023874862788145,
            "ave_precision_score": 0.7981686388973301,
            "fpr": 0.09330406147091108,
            "logloss": 0.7830812372396397,
            "mae": 0.30822926941323964,
            "precision": 0.7671232876712328,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.8044092333748698,
            "auditor_fn_violation": 0.008314127987994427,
            "auditor_fp_violation": 0.01248854023419594,
            "ave_precision_score": 0.8047080099033791,
            "fpr": 0.0625,
            "logloss": 0.9759673003400828,
            "mae": 0.3516218471582912,
            "precision": 0.8093645484949833,
            "recall": 0.49287169042769857
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7631837169551574,
            "auditor_fn_violation": 0.007389880818316118,
            "auditor_fp_violation": 0.009710188960326173,
            "ave_precision_score": 0.7638222677651818,
            "fpr": 0.06476399560922064,
            "logloss": 0.99026736808749,
            "mae": 0.3523814423969355,
            "precision": 0.7846715328467153,
            "recall": 0.46436285097192226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8509785760206554,
            "auditor_fn_violation": 0.014008736198949517,
            "auditor_fp_violation": 0.005680397549693714,
            "ave_precision_score": 0.851205215202788,
            "fpr": 0.039473684210526314,
            "logloss": 0.6008697429897114,
            "mae": 0.37846717285707165,
            "precision": 0.8714285714285714,
            "recall": 0.4969450101832994
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8397520187219291,
            "auditor_fn_violation": 0.011244852332779366,
            "auditor_fp_violation": 0.0015387329465265825,
            "ave_precision_score": 0.840020749993578,
            "fpr": 0.04500548847420417,
            "logloss": 0.5709202503801641,
            "mae": 0.3602675707002797,
            "precision": 0.8492647058823529,
            "recall": 0.49892008639308855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8532066558093425,
            "auditor_fn_violation": 0.012110533461964487,
            "auditor_fp_violation": 0.007576467891819814,
            "ave_precision_score": 0.8534714969776348,
            "fpr": 0.1118421052631579,
            "logloss": 0.5919890985259176,
            "mae": 0.26960022298063496,
            "precision": 0.7879417879417879,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8265865264771097,
            "auditor_fn_violation": 0.01067111118487031,
            "auditor_fp_violation": 0.010161027912811668,
            "ave_precision_score": 0.8269192696621445,
            "fpr": 0.11964873765093303,
            "logloss": 0.6065326364739474,
            "mae": 0.27774684300255187,
            "precision": 0.7640692640692641,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8387883410779619,
            "auditor_fn_violation": 0.02220003930396256,
            "auditor_fp_violation": 0.010957098804017172,
            "ave_precision_score": 0.8390888825784232,
            "fpr": 0.0668859649122807,
            "logloss": 0.6109497749865197,
            "mae": 0.31886864323748515,
            "precision": 0.8398950131233596,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8090943840586611,
            "auditor_fn_violation": 0.013271912999978664,
            "auditor_fp_violation": 0.007904382938685905,
            "ave_precision_score": 0.8104971465485897,
            "fpr": 0.08122941822173436,
            "logloss": 0.5892785530532072,
            "mae": 0.3133352352779703,
            "precision": 0.8047493403693932,
            "recall": 0.6587473002159827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7966317879743949,
            "auditor_fn_violation": 0.01977927251938401,
            "auditor_fp_violation": 0.01075915739467434,
            "ave_precision_score": 0.7972460466365717,
            "fpr": 0.0712719298245614,
            "logloss": 1.0025136458332777,
            "mae": 0.33433741767020914,
            "precision": 0.7975077881619937,
            "recall": 0.5213849287169042
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7711327533565581,
            "auditor_fn_violation": 0.020035894384212175,
            "auditor_fp_violation": 0.007649560922063669,
            "ave_precision_score": 0.771923875179011,
            "fpr": 0.07683863885839737,
            "logloss": 0.9428659108739931,
            "mae": 0.3248347346598645,
            "precision": 0.7846153846153846,
            "recall": 0.550755939524838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8346969123610315,
            "auditor_fn_violation": 0.008320827527066135,
            "auditor_fp_violation": 0.007743155394424303,
            "ave_precision_score": 0.8350153183502761,
            "fpr": 0.05701754385964912,
            "logloss": 0.8046361641130123,
            "mae": 0.3212844753730392,
            "precision": 0.8327974276527331,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.800490954536196,
            "auditor_fn_violation": 0.011560172881010364,
            "auditor_fp_violation": 0.006997804610318333,
            "ave_precision_score": 0.8009129823699678,
            "fpr": 0.06147091108671789,
            "logloss": 0.798352053264781,
            "mae": 0.32242037017214165,
            "precision": 0.8082191780821918,
            "recall": 0.509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8697458164073457,
            "auditor_fn_violation": 0.008524046878908075,
            "auditor_fp_violation": 0.0032321748551902324,
            "ave_precision_score": 0.8699639771529588,
            "fpr": 0.03179824561403509,
            "logloss": 0.5886030529814014,
            "mae": 0.34968375348188074,
            "precision": 0.9064516129032258,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8508199838563265,
            "auditor_fn_violation": 0.0015031069742741114,
            "auditor_fp_violation": 0.005704092833620826,
            "ave_precision_score": 0.8511799587043078,
            "fpr": 0.03951701427003293,
            "logloss": 0.5757261666857473,
            "mae": 0.3381893748073418,
            "precision": 0.8807947019867549,
            "recall": 0.5745140388768899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8498202610728433,
            "auditor_fn_violation": 0.006174741844427768,
            "auditor_fp_violation": 0.00578978622327791,
            "ave_precision_score": 0.8501790118516155,
            "fpr": 0.04057017543859649,
            "logloss": 0.5426594983179525,
            "mae": 0.34817081603850647,
            "precision": 0.8786885245901639,
            "recall": 0.5458248472505092
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8486445869970866,
            "auditor_fn_violation": 0.00622817353535976,
            "auditor_fp_violation": 0.005655088599655011,
            "ave_precision_score": 0.8488819714558075,
            "fpr": 0.042810098792535674,
            "logloss": 0.5209873307560797,
            "mae": 0.3361111417889153,
            "precision": 0.877742946708464,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7559467296268065,
            "auditor_fn_violation": 0.015080662450423422,
            "auditor_fp_violation": 0.012488540234195948,
            "ave_precision_score": 0.7564391429588134,
            "fpr": 0.07894736842105263,
            "logloss": 1.1926052488817758,
            "mae": 0.37169520195759326,
            "precision": 0.7647058823529411,
            "recall": 0.47657841140529533
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6987929931159369,
            "auditor_fn_violation": 0.008444900697735626,
            "auditor_fp_violation": 0.007678963462443156,
            "ave_precision_score": 0.6995164563935778,
            "fpr": 0.08562019758507135,
            "logloss": 1.2313716919591564,
            "mae": 0.38409787710679605,
            "precision": 0.7204301075268817,
            "recall": 0.43412526997840173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 14724,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8587350165860255,
            "auditor_fn_violation": 0.03740799299674849,
            "auditor_fp_violation": 0.03067310497145477,
            "ave_precision_score": 0.8589320384960095,
            "fpr": 0.13267543859649122,
            "logloss": 0.5302555709856918,
            "mae": 0.3172049467185596,
            "precision": 0.7632093933463796,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8369552559721056,
            "auditor_fn_violation": 0.03358045297100711,
            "auditor_fp_violation": 0.03221048298572997,
            "ave_precision_score": 0.8373104094235507,
            "fpr": 0.14709110867178923,
            "logloss": 0.5313568690806103,
            "mae": 0.31471691645503463,
            "precision": 0.7346534653465346,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8437691888009057,
            "auditor_fn_violation": 0.016934201593597032,
            "auditor_fp_violation": 0.00791505188148519,
            "ave_precision_score": 0.844133676031014,
            "fpr": 0.08662280701754387,
            "logloss": 0.6676598530151212,
            "mae": 0.2839659057170403,
            "precision": 0.8063725490196079,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8150257695632495,
            "auditor_fn_violation": 0.007340093363332252,
            "auditor_fp_violation": 0.011339579739689512,
            "ave_precision_score": 0.8153795183713212,
            "fpr": 0.10208562019758508,
            "logloss": 0.6786379449796203,
            "mae": 0.28944195191890565,
            "precision": 0.7742718446601942,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8359449048948535,
            "auditor_fn_violation": 0.015132025583306535,
            "auditor_fp_violation": 0.007526982539484105,
            "ave_precision_score": 0.8366816130894812,
            "fpr": 0.11513157894736842,
            "logloss": 0.7757852426672899,
            "mae": 0.2569536632785508,
            "precision": 0.7865853658536586,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8288897536638241,
            "auditor_fn_violation": 0.0004291204453369338,
            "auditor_fp_violation": 0.006926748471067897,
            "ave_precision_score": 0.8292278874333066,
            "fpr": 0.1394072447859495,
            "logloss": 0.7884836839837053,
            "mae": 0.2605993214688257,
            "precision": 0.7392197125256673,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8281380289234653,
            "auditor_fn_violation": 0.0054846893200414595,
            "auditor_fp_violation": 0.003114972704921454,
            "ave_precision_score": 0.8285326914048191,
            "fpr": 0.06798245614035088,
            "logloss": 0.573672716780561,
            "mae": 0.3540148163814784,
            "precision": 0.8333333333333334,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.820210888739141,
            "auditor_fn_violation": 0.003046518078773238,
            "auditor_fp_violation": 0.011182766190998903,
            "ave_precision_score": 0.8208760492773168,
            "fpr": 0.07683863885839737,
            "logloss": 0.5369587858774663,
            "mae": 0.3366399304235904,
            "precision": 0.8177083333333334,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8168470621645164,
            "auditor_fn_violation": 0.022226837460249407,
            "auditor_fp_violation": 0.005977309663707964,
            "ave_precision_score": 0.8171972704517454,
            "fpr": 0.0756578947368421,
            "logloss": 0.9641235705788733,
            "mae": 0.31124173294733876,
            "precision": 0.8061797752808989,
            "recall": 0.5845213849287169
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7893294835247023,
            "auditor_fn_violation": 0.02261535871861316,
            "auditor_fp_violation": 7.840677434530285e-05,
            "ave_precision_score": 0.7900222214088832,
            "fpr": 0.08781558726673985,
            "logloss": 0.9271068369099386,
            "mae": 0.30795753207592597,
            "precision": 0.7777777777777778,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8305578911163678,
            "auditor_fn_violation": 0.020813234716118206,
            "auditor_fp_violation": 0.005933033295828649,
            "ave_precision_score": 0.8308323141794526,
            "fpr": 0.06359649122807018,
            "logloss": 0.9305610090428386,
            "mae": 0.31663635087289643,
            "precision": 0.8242424242424242,
            "recall": 0.5539714867617108
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8004202566012236,
            "auditor_fn_violation": 0.021503438890640676,
            "auditor_fp_violation": 0.006493061000470446,
            "ave_precision_score": 0.8012539705795727,
            "fpr": 0.07793633369923161,
            "logloss": 0.8976996481766996,
            "mae": 0.31231030184554276,
            "precision": 0.7911764705882353,
            "recall": 0.5809935205183585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8081526055538313,
            "auditor_fn_violation": 0.015880140779647705,
            "auditor_fp_violation": 0.014619014876859612,
            "ave_precision_score": 0.8094719426711656,
            "fpr": 0.09100877192982457,
            "logloss": 0.941992335752047,
            "mae": 0.30545293632367027,
            "precision": 0.7893401015228426,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7872290383774658,
            "auditor_fn_violation": 0.018136858601257008,
            "auditor_fp_violation": 0.00612307903402854,
            "ave_precision_score": 0.787667866088831,
            "fpr": 0.09989023051591657,
            "logloss": 0.900263153906969,
            "mae": 0.3019936805604662,
            "precision": 0.7678571428571429,
            "recall": 0.6501079913606912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6539807970395286,
            "auditor_fn_violation": 0.004968824811519637,
            "auditor_fp_violation": 0.010209609534525155,
            "ave_precision_score": 0.6553994482483582,
            "fpr": 0.25,
            "logloss": 0.9298475579213722,
            "mae": 0.3777922197227701,
            "precision": 0.6550680786686838,
            "recall": 0.8818737270875764
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6624273939952552,
            "auditor_fn_violation": 0.0037079799807014364,
            "auditor_fp_violation": 0.012199604045789557,
            "ave_precision_score": 0.66420811530046,
            "fpr": 0.2645444566410538,
            "logloss": 0.8400009234580283,
            "mae": 0.37864088199462265,
            "precision": 0.6275115919629057,
            "recall": 0.8768898488120951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7873515313785596,
            "auditor_fn_violation": 0.0188748347447029,
            "auditor_fp_violation": 0.008748489394507647,
            "ave_precision_score": 0.787624649243312,
            "fpr": 0.08114035087719298,
            "logloss": 0.975671464813537,
            "mae": 0.31621988408827933,
            "precision": 0.7978142076502732,
            "recall": 0.594704684317719
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.796245688197041,
            "auditor_fn_violation": 0.013008750737921217,
            "auditor_fp_violation": 0.0035675082327113095,
            "ave_precision_score": 0.7966920204059618,
            "fpr": 0.09220636663007684,
            "logloss": 0.7943215916243372,
            "mae": 0.31039285742911243,
            "precision": 0.7673130193905817,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 14724,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8310405146297952,
            "auditor_fn_violation": 0.015761782256047463,
            "auditor_fp_violation": 0.012845355669458686,
            "ave_precision_score": 0.8313903379924741,
            "fpr": 0.09649122807017543,
            "logloss": 0.6382810357077404,
            "mae": 0.2937424192523754,
            "precision": 0.7914691943127962,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7960976458072349,
            "auditor_fn_violation": 0.005431574255618287,
            "auditor_fp_violation": 0.005998118237415717,
            "ave_precision_score": 0.7965296259711644,
            "fpr": 0.1141602634467618,
            "logloss": 0.6539053179213618,
            "mae": 0.30248089696922603,
            "precision": 0.7570093457943925,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 14724,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8182137268847954,
            "auditor_fn_violation": 0.0022666773859291818,
            "auditor_fp_violation": 0.01226976288702755,
            "ave_precision_score": 0.8186754666793404,
            "fpr": 0.16557017543859648,
            "logloss": 0.837826661191282,
            "mae": 0.26695542759957797,
            "precision": 0.7327433628318584,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8192316830914914,
            "auditor_fn_violation": 0.0059626404421126026,
            "auditor_fp_violation": 0.00582415320683708,
            "ave_precision_score": 0.8195410034351132,
            "fpr": 0.16794731064763996,
            "logloss": 0.8362405880233048,
            "mae": 0.26762691198753985,
            "precision": 0.7156133828996283,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8433727704017284,
            "auditor_fn_violation": 0.02330992961017616,
            "auditor_fp_violation": 0.0146763137058799,
            "ave_precision_score": 0.8437298152543931,
            "fpr": 0.08771929824561403,
            "logloss": 0.678662346746105,
            "mae": 0.2850211207151794,
            "precision": 0.8072289156626506,
            "recall": 0.6822810590631364
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8066042439901642,
            "auditor_fn_violation": 0.01886707460768671,
            "auditor_fp_violation": 0.016073388740787214,
            "ave_precision_score": 0.8069552853805834,
            "fpr": 0.10537870472008781,
            "logloss": 0.7153592150151322,
            "mae": 0.2924429047313193,
            "precision": 0.7703349282296651,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8363569266565214,
            "auditor_fn_violation": 0.01791680065744811,
            "auditor_fp_violation": 0.01048568571071384,
            "ave_precision_score": 0.836803316886533,
            "fpr": 0.0581140350877193,
            "logloss": 0.611486531286669,
            "mae": 0.3232773692675676,
            "precision": 0.8523676880222841,
            "recall": 0.6232179226069247
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8129298949841032,
            "auditor_fn_violation": 0.007003435334393885,
            "auditor_fp_violation": 0.007144817312215774,
            "ave_precision_score": 0.8136304090985912,
            "fpr": 0.06586169045005488,
            "logloss": 0.5774070438140265,
            "mae": 0.31540064861881417,
            "precision": 0.8285714285714286,
            "recall": 0.6263498920086393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 14724,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8577024075902681,
            "auditor_fn_violation": 0.01242541179833494,
            "auditor_fp_violation": 0.013710047089219487,
            "ave_precision_score": 0.8579541336445726,
            "fpr": 0.15350877192982457,
            "logloss": 0.6190778745005837,
            "mae": 0.2512433980458881,
            "precision": 0.75,
            "recall": 0.8553971486761711
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8449295158082323,
            "auditor_fn_violation": 0.002048398147906676,
            "auditor_fp_violation": 0.01169241022424338,
            "ave_precision_score": 0.845173078951838,
            "fpr": 0.1602634467618002,
            "logloss": 0.6615976580101349,
            "mae": 0.26029064419376996,
            "precision": 0.7335766423357665,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8216087333096894,
            "auditor_fn_violation": 0.020317468824811526,
            "auditor_fp_violation": 0.0061023252906613375,
            "ave_precision_score": 0.821934356777723,
            "fpr": 0.08991228070175439,
            "logloss": 0.8123850998006165,
            "mae": 0.3031184579694469,
            "precision": 0.7939698492462312,
            "recall": 0.6435845213849287
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.793653743441996,
            "auditor_fn_violation": 0.011294639787763195,
            "auditor_fp_violation": 0.00450348910145837,
            "ave_precision_score": 0.7943345944869139,
            "fpr": 0.10867178924259056,
            "logloss": 0.7960264657591866,
            "mae": 0.3058507992828595,
            "precision": 0.7506297229219143,
            "recall": 0.6436285097192225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 14724,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8813646081957425,
            "auditor_fn_violation": 0.028312252117054352,
            "auditor_fp_violation": 0.010282535316914615,
            "ave_precision_score": 0.8815553196238956,
            "fpr": 0.05482456140350877,
            "logloss": 0.521318184772484,
            "mae": 0.31338665763637674,
            "precision": 0.8622589531680441,
            "recall": 0.6374745417515275
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8510562186737302,
            "auditor_fn_violation": 0.02464241938581247,
            "auditor_fp_violation": 0.013799592284773407,
            "ave_precision_score": 0.8513440444458003,
            "fpr": 0.07025246981339188,
            "logloss": 0.5289046879956422,
            "mae": 0.31005459336256486,
            "precision": 0.8288770053475936,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8349025478562693,
            "auditor_fn_violation": 0.008026047807910818,
            "auditor_fp_violation": 0.010933658373963413,
            "ave_precision_score": 0.835249030757232,
            "fpr": 0.10855263157894737,
            "logloss": 0.7036958097434208,
            "mae": 0.2826157879242435,
            "precision": 0.7828947368421053,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8111215849420087,
            "auditor_fn_violation": 0.007138572712207176,
            "auditor_fp_violation": 0.002837345146620676,
            "ave_precision_score": 0.81157022009792,
            "fpr": 0.1251372118551043,
            "logloss": 0.7156305741174892,
            "mae": 0.28565643980940286,
            "precision": 0.7521739130434782,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8469938820270526,
            "auditor_fn_violation": 0.014801514989102088,
            "auditor_fp_violation": 0.009548068508563573,
            "ave_precision_score": 0.8473855065593479,
            "fpr": 0.08991228070175439,
            "logloss": 0.6248235356157037,
            "mae": 0.27788498811839835,
            "precision": 0.8119266055045872,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8189700952732516,
            "auditor_fn_violation": 0.004876799757226891,
            "auditor_fp_violation": 0.009715089383722753,
            "ave_precision_score": 0.8193487408476364,
            "fpr": 0.10647639956092206,
            "logloss": 0.6439634346161768,
            "mae": 0.28405475784300876,
            "precision": 0.7759815242494227,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8539170327954384,
            "auditor_fn_violation": 0.008457051488190951,
            "auditor_fp_violation": 0.012207255073550862,
            "ave_precision_score": 0.854179529104732,
            "fpr": 0.11513157894736842,
            "logloss": 0.5866214537789984,
            "mae": 0.2681564928678223,
            "precision": 0.7839506172839507,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8264699076718738,
            "auditor_fn_violation": 0.006194981898703867,
            "auditor_fp_violation": 0.004650501803355817,
            "ave_precision_score": 0.8268016778505398,
            "fpr": 0.1251372118551043,
            "logloss": 0.6056237254232936,
            "mae": 0.27767212757043136,
            "precision": 0.7584745762711864,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7900157554181589,
            "auditor_fn_violation": 0.01897979419015972,
            "auditor_fp_violation": 0.0056439346584989825,
            "ave_precision_score": 0.7903134680293379,
            "fpr": 0.09100877192982457,
            "logloss": 1.0008889703253272,
            "mae": 0.31120649871447403,
            "precision": 0.7871794871794872,
            "recall": 0.6252545824847251
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7867424573822327,
            "auditor_fn_violation": 0.014542678517661518,
            "auditor_fp_violation": 0.006341147875176418,
            "ave_precision_score": 0.787442590520218,
            "fpr": 0.09879253567508232,
            "logloss": 0.8649629630529169,
            "mae": 0.30987176906467684,
            "precision": 0.7606382978723404,
            "recall": 0.6177105831533477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 14724,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.820788811654074,
            "auditor_fn_violation": 0.02056758495015544,
            "auditor_fp_violation": 0.007865566529149479,
            "ave_precision_score": 0.8211145770082778,
            "fpr": 0.07456140350877193,
            "logloss": 0.8162963923690103,
            "mae": 0.3121490829720769,
            "precision": 0.8105849582172702,
            "recall": 0.5926680244399185
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7969368578349385,
            "auditor_fn_violation": 0.01507137387296612,
            "auditor_fp_violation": 0.00109769484083425,
            "ave_precision_score": 0.797397271331591,
            "fpr": 0.09220636663007684,
            "logloss": 0.7895650155906123,
            "mae": 0.31045855297683345,
            "precision": 0.766016713091922,
            "recall": 0.593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8468249865810837,
            "auditor_fn_violation": 0.009825990638510746,
            "auditor_fp_violation": 0.014561716047839318,
            "ave_precision_score": 0.8470718992925073,
            "fpr": 0.09649122807017543,
            "logloss": 0.74614797944906,
            "mae": 0.27736215422028315,
            "precision": 0.7948717948717948,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8054042413415282,
            "auditor_fn_violation": 0.010995915057860135,
            "auditor_fp_violation": 0.007882331033401288,
            "ave_precision_score": 0.8060448103356064,
            "fpr": 0.10647639956092206,
            "logloss": 0.7870422260876518,
            "mae": 0.2888826733829145,
            "precision": 0.7717647058823529,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6156267414945011,
            "auditor_fn_violation": 0.0015810912209239987,
            "auditor_fp_violation": 0.01466329124473894,
            "ave_precision_score": 0.5797211928676816,
            "fpr": 0.26864035087719296,
            "logloss": 3.9656609964499587,
            "mae": 0.43485374064613624,
            "precision": 0.5868465430016864,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6010875439226449,
            "auditor_fn_violation": 0.00990770354178472,
            "auditor_fp_violation": 0.02689352360043908,
            "ave_precision_score": 0.5657335697982746,
            "fpr": 0.28869374313940727,
            "logloss": 3.805273648609945,
            "mae": 0.43284392793091375,
            "precision": 0.5631229235880398,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8387635582887264,
            "auditor_fn_violation": 0.01789223568085183,
            "auditor_fp_violation": 0.009519419094053424,
            "ave_precision_score": 0.8391210658292846,
            "fpr": 0.05592105263157895,
            "logloss": 0.6111953542660375,
            "mae": 0.32926446134405796,
            "precision": 0.8559322033898306,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.819452192063112,
            "auditor_fn_violation": 0.0031721721318276933,
            "auditor_fp_violation": 0.006495511212168733,
            "ave_precision_score": 0.819967314789508,
            "fpr": 0.06695938529088913,
            "logloss": 0.5748397407414546,
            "mae": 0.3173467180525279,
            "precision": 0.8271954674220963,
            "recall": 0.6306695464362851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8209625605040952,
            "auditor_fn_violation": 0.01354423482331083,
            "auditor_fp_violation": 0.00599033212484894,
            "ave_precision_score": 0.8213111912657012,
            "fpr": 0.0537280701754386,
            "logloss": 1.143585562175683,
            "mae": 0.35561657937043906,
            "precision": 0.8205128205128205,
            "recall": 0.45621181262729127
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7851668122744593,
            "auditor_fn_violation": 0.023625332805428254,
            "auditor_fp_violation": 0.006635173278971305,
            "ave_precision_score": 0.7856849481259467,
            "fpr": 0.0570801317233809,
            "logloss": 1.112471525858246,
            "mae": 0.3463677263359618,
            "precision": 0.8074074074074075,
            "recall": 0.4708423326133909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.830653651122856,
            "auditor_fn_violation": 0.015306213599171049,
            "auditor_fp_violation": 0.009844980622577824,
            "ave_precision_score": 0.8311159646740189,
            "fpr": 0.08333333333333333,
            "logloss": 0.5653457260633049,
            "mae": 0.327968761600603,
            "precision": 0.812807881773399,
            "recall": 0.6720977596741344
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8112325926774817,
            "auditor_fn_violation": 0.007508422377801442,
            "auditor_fp_violation": 0.01230986357221264,
            "ave_precision_score": 0.8118394686100385,
            "fpr": 0.08781558726673985,
            "logloss": 0.5322410032194,
            "mae": 0.31208605468467404,
            "precision": 0.8062953995157385,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8321747025137054,
            "auditor_fn_violation": 0.024178636509808133,
            "auditor_fp_violation": 0.008524503062882863,
            "ave_precision_score": 0.8324707433143247,
            "fpr": 0.08442982456140351,
            "logloss": 0.8063259249267297,
            "mae": 0.2906859141282756,
            "precision": 0.8079800498753117,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8037959813341622,
            "auditor_fn_violation": 0.014412282802227642,
            "auditor_fp_violation": 0.002293398149600127,
            "ave_precision_score": 0.8046332434705722,
            "fpr": 0.11086717892425905,
            "logloss": 0.7956033115546244,
            "mae": 0.2933431584654219,
            "precision": 0.7536585365853659,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 14724,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8324579618990678,
            "auditor_fn_violation": 0.01482384678600779,
            "auditor_fp_violation": 0.009410030420469225,
            "ave_precision_score": 0.8332245063649883,
            "fpr": 0.13157894736842105,
            "logloss": 0.8518391713856258,
            "mae": 0.24934815807374197,
            "precision": 0.7692307692307693,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8305152310248904,
            "auditor_fn_violation": 0.002072106459803749,
            "auditor_fp_violation": 0.007598106476399558,
            "ave_precision_score": 0.830819779759197,
            "fpr": 0.145993413830955,
            "logloss": 0.8787956542696915,
            "mae": 0.2537695067789432,
            "precision": 0.740234375,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.836700317070378,
            "auditor_fn_violation": 0.017559491906956808,
            "auditor_fp_violation": 0.01661926490811352,
            "ave_precision_score": 0.8370083578487411,
            "fpr": 0.09539473684210527,
            "logloss": 0.6455171206107267,
            "mae": 0.2911282027854221,
            "precision": 0.7933491686460807,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.806235848884004,
            "auditor_fn_violation": 0.00743966827329994,
            "auditor_fp_violation": 0.012388270346557949,
            "ave_precision_score": 0.8066493889956721,
            "fpr": 0.10537870472008781,
            "logloss": 0.6479358478204553,
            "mae": 0.2978438250790066,
            "precision": 0.7681159420289855,
            "recall": 0.6868250539956804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8291773950582957,
            "auditor_fn_violation": 0.013794350948654737,
            "auditor_fp_violation": 0.01751260574238447,
            "ave_precision_score": 0.829963630800912,
            "fpr": 0.11842105263157894,
            "logloss": 0.7767961925418925,
            "mae": 0.272308503192991,
            "precision": 0.7740585774058577,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7982167312479279,
            "auditor_fn_violation": 0.0152349612250559,
            "auditor_fp_violation": 0.01025168574564843,
            "ave_precision_score": 0.7991302611978472,
            "fpr": 0.132821075740944,
            "logloss": 0.8207078958201357,
            "mae": 0.286132755775837,
            "precision": 0.7420042643923241,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8492458556919942,
            "auditor_fn_violation": 0.02553194340229393,
            "auditor_fp_violation": 0.017015147726799188,
            "ave_precision_score": 0.8495538810895025,
            "fpr": 0.08881578947368421,
            "logloss": 0.636503255671749,
            "mae": 0.2774037270998764,
            "precision": 0.8111888111888111,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8064278601001559,
            "auditor_fn_violation": 0.017608163245952404,
            "auditor_fp_violation": 0.022296926454445667,
            "ave_precision_score": 0.8069648389180624,
            "fpr": 0.11525795828759605,
            "logloss": 0.6804803314538976,
            "mae": 0.2887074790646294,
            "precision": 0.7602739726027398,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8220943806699822,
            "auditor_fn_violation": 0.021679708436059597,
            "auditor_fp_violation": 0.01648122682001917,
            "ave_precision_score": 0.8224293823587989,
            "fpr": 0.1074561403508772,
            "logloss": 0.8444880997069043,
            "mae": 0.28637184732603627,
            "precision": 0.7797752808988764,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7839702053899787,
            "auditor_fn_violation": 0.006569573226677547,
            "auditor_fp_violation": 0.0020287752861847265,
            "ave_precision_score": 0.7854372177266511,
            "fpr": 0.12623490669593854,
            "logloss": 0.8603504688728155,
            "mae": 0.2908581247521141,
            "precision": 0.7386363636363636,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 14724,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6526246637039234,
            "auditor_fn_violation": 0.006069782398970976,
            "auditor_fp_violation": 0.002784202191940659,
            "ave_precision_score": 0.6531689600591749,
            "fpr": 0.03618421052631579,
            "logloss": 2.9397226601114346,
            "mae": 0.4578447694940302,
            "precision": 0.777027027027027,
            "recall": 0.23421588594704684
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.592107130776662,
            "auditor_fn_violation": 0.008060826045003126,
            "auditor_fp_violation": 0.007429041869217501,
            "ave_precision_score": 0.5932511871459722,
            "fpr": 0.043907793633369926,
            "logloss": 2.998637728337221,
            "mae": 0.4443316840687195,
            "precision": 0.726027397260274,
            "recall": 0.22894168466522677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.776067908545875,
            "auditor_fn_violation": 0.0018044091899810622,
            "auditor_fp_violation": 0.017890257115472773,
            "ave_precision_score": 0.7750482872396292,
            "fpr": 0.20175438596491227,
            "logloss": 1.4322593580761929,
            "mae": 0.2862617026797747,
            "precision": 0.707936507936508,
            "recall": 0.9083503054989817
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7784943328066636,
            "auditor_fn_violation": 0.0031863971189659383,
            "auditor_fp_violation": 0.02112817547436099,
            "ave_precision_score": 0.7796473432700285,
            "fpr": 0.2052689352360044,
            "logloss": 1.4075103686789605,
            "mae": 0.2835250431972042,
            "precision": 0.6878130217028381,
            "recall": 0.8898488120950324
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8266913572096622,
            "auditor_fn_violation": 0.009808125200986182,
            "auditor_fp_violation": 0.016832833270825524,
            "ave_precision_score": 0.8269815475066269,
            "fpr": 0.09320175438596491,
            "logloss": 0.7644306086088812,
            "mae": 0.3010601769732305,
            "precision": 0.7926829268292683,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7938497978806127,
            "auditor_fn_violation": 0.012821455073934373,
            "auditor_fp_violation": 0.022615453975223458,
            "ave_precision_score": 0.794224564496213,
            "fpr": 0.10647639956092206,
            "logloss": 0.7832326785975484,
            "mae": 0.30718867072357137,
            "precision": 0.7575,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 14724,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8320155270473143,
            "auditor_fn_violation": 0.01914504948726195,
            "auditor_fp_violation": 0.007026920031670629,
            "ave_precision_score": 0.8321417248090449,
            "fpr": 0.08114035087719298,
            "logloss": 0.8798663351316461,
            "mae": 0.2865132165346689,
            "precision": 0.8121827411167513,
            "recall": 0.6517311608961304
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8123458177500462,
            "auditor_fn_violation": 0.013959454044993646,
            "auditor_fp_violation": 0.00012741100831111763,
            "ave_precision_score": 0.812707249039805,
            "fpr": 0.0889132821075741,
            "logloss": 0.8468589107151993,
            "mae": 0.2859346001300005,
            "precision": 0.7874015748031497,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8282469762408884,
            "auditor_fn_violation": 0.019274573909315054,
            "auditor_fp_violation": 0.004841751052214861,
            "ave_precision_score": 0.8286133335970545,
            "fpr": 0.0712719298245614,
            "logloss": 0.9524838764010821,
            "mae": 0.3016797251960643,
            "precision": 0.8199445983379502,
            "recall": 0.6028513238289206
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7993890313384946,
            "auditor_fn_violation": 0.02271256279739115,
            "auditor_fp_violation": 0.008164105378704723,
            "ave_precision_score": 0.7999318720895844,
            "fpr": 0.08562019758507135,
            "logloss": 0.9156282148327118,
            "mae": 0.3017748134170789,
            "precision": 0.7808988764044944,
            "recall": 0.6004319654427646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 14724,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8812929729750827,
            "auditor_fn_violation": 0.028312252117054352,
            "auditor_fp_violation": 0.010282535316914615,
            "ave_precision_score": 0.8814838170243942,
            "fpr": 0.05482456140350877,
            "logloss": 0.5217687287771213,
            "mae": 0.3136168026503583,
            "precision": 0.8622589531680441,
            "recall": 0.6374745417515275
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8510832152873111,
            "auditor_fn_violation": 0.02464241938581247,
            "auditor_fp_violation": 0.013799592284773407,
            "ave_precision_score": 0.8513698596516234,
            "fpr": 0.07025246981339188,
            "logloss": 0.5292498121801672,
            "mae": 0.3102355696532863,
            "precision": 0.8288770053475936,
            "recall": 0.6695464362850972
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8373035373891689,
            "auditor_fn_violation": 0.01039321827991568,
            "auditor_fp_violation": 0.011780118348126855,
            "ave_precision_score": 0.8376007718545773,
            "fpr": 0.10964912280701754,
            "logloss": 0.6758912049756824,
            "mae": 0.28109713195713165,
            "precision": 0.7821350762527233,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.805561394461234,
            "auditor_fn_violation": 0.006688114786162888,
            "auditor_fp_violation": 0.014015210914222996,
            "ave_precision_score": 0.8060445577670869,
            "fpr": 0.13611416026344675,
            "logloss": 0.7054154206911084,
            "mae": 0.29226047541881733,
            "precision": 0.734475374732334,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8329355960206424,
            "auditor_fn_violation": 0.015453603458748707,
            "auditor_fp_violation": 0.012327061716047838,
            "ave_precision_score": 0.8332709337508339,
            "fpr": 0.09429824561403509,
            "logloss": 0.6785936868091487,
            "mae": 0.29164605256723736,
            "precision": 0.7927710843373494,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7999288697410899,
            "auditor_fn_violation": 0.004955037186487211,
            "auditor_fp_violation": 0.007735318331503847,
            "ave_precision_score": 0.800358122614411,
            "fpr": 0.10867178924259056,
            "logloss": 0.6891455753021146,
            "mae": 0.2989424721404273,
            "precision": 0.7597087378640777,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8335511317444811,
            "auditor_fn_violation": 0.006485153821417089,
            "auditor_fp_violation": 0.0154394299287411,
            "ave_precision_score": 0.8338348243935861,
            "fpr": 0.1513157894736842,
            "logloss": 0.5684926470949421,
            "mae": 0.33864783422598665,
            "precision": 0.7463235294117647,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8303425725826865,
            "auditor_fn_violation": 0.005772973946936059,
            "auditor_fp_violation": 0.01405441430139565,
            "ave_precision_score": 0.8316855552330247,
            "fpr": 0.14928649835345773,
            "logloss": 0.5153802553265255,
            "mae": 0.3319439785598453,
            "precision": 0.7364341085271318,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7946274292455793,
            "auditor_fn_violation": 0.012050237610319071,
            "auditor_fp_violation": 0.017160999291578116,
            "ave_precision_score": 0.795111285047386,
            "fpr": 0.08552631578947369,
            "logloss": 0.8990941892898169,
            "mae": 0.327210162405397,
            "precision": 0.7839335180055401,
            "recall": 0.5763747454175153
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7727851019909546,
            "auditor_fn_violation": 0.01071852780866444,
            "auditor_fp_violation": 0.012486278814489575,
            "ave_precision_score": 0.7732175580505403,
            "fpr": 0.09220636663007684,
            "logloss": 0.8830599908433124,
            "mae": 0.32899437540698256,
            "precision": 0.7613636363636364,
            "recall": 0.5788336933045356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8243927169433107,
            "auditor_fn_violation": 0.023240701039768465,
            "auditor_fp_violation": 0.0023805058965704067,
            "ave_precision_score": 0.8247050739874586,
            "fpr": 0.07346491228070176,
            "logloss": 0.9002111620812323,
            "mae": 0.3123952428018511,
            "precision": 0.8074712643678161,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7974415824265848,
            "auditor_fn_violation": 0.01831467094048503,
            "auditor_fp_violation": 0.0062480398306413686,
            "ave_precision_score": 0.7980993542067545,
            "fpr": 0.0889132821075741,
            "logloss": 0.8643230097289364,
            "mae": 0.30926215901961046,
            "precision": 0.7718309859154929,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 14724,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8152470686099333,
            "auditor_fn_violation": 0.0269321470682817,
            "auditor_fp_violation": 0.008162478643163731,
            "ave_precision_score": 0.8155943569451334,
            "fpr": 0.07017543859649122,
            "logloss": 0.8317412139114229,
            "mae": 0.32109984728618995,
            "precision": 0.8128654970760234,
            "recall": 0.5661914460285132
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7927861453564304,
            "auditor_fn_violation": 0.012525101175221032,
            "auditor_fp_violation": 0.0013476164340599011,
            "ave_precision_score": 0.7932845945371358,
            "fpr": 0.08122941822173436,
            "logloss": 0.8014308620250261,
            "mae": 0.32270250498814873,
            "precision": 0.7716049382716049,
            "recall": 0.5399568034557235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 14724,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6603296527692237,
            "auditor_fn_violation": 0.003988458927359134,
            "auditor_fp_violation": 0.0185231487269242,
            "ave_precision_score": 0.6618162718667641,
            "fpr": 0.21052631578947367,
            "logloss": 0.8372501825091715,
            "mae": 0.37799460173527333,
            "precision": 0.6836902800658978,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6715800549786831,
            "auditor_fn_violation": 0.004924216381021022,
            "auditor_fp_violation": 0.016926062411792377,
            "ave_precision_score": 0.6735607393602024,
            "fpr": 0.21734357848518113,
            "logloss": 0.7484612590126126,
            "mae": 0.37361136056957145,
            "precision": 0.6615384615384615,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8364529529097506,
            "auditor_fn_violation": 0.012972540822524744,
            "auditor_fp_violation": 0.01991655206900863,
            "ave_precision_score": 0.8367836497810368,
            "fpr": 0.2138157894736842,
            "logloss": 1.0100254723091484,
            "mae": 0.27636970065481187,
            "precision": 0.6943573667711599,
            "recall": 0.9022403258655805
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8252205242252475,
            "auditor_fn_violation": 0.004514062585201747,
            "auditor_fp_violation": 0.023639642465108992,
            "ave_precision_score": 0.8255106610326157,
            "fpr": 0.25905598243688255,
            "logloss": 1.139514077974877,
            "mae": 0.3084439368775998,
            "precision": 0.6413373860182371,
            "recall": 0.9114470842332614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 14724,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8200827031514519,
            "auditor_fn_violation": 0.019826169292885994,
            "auditor_fp_violation": 0.008722444472225697,
            "ave_precision_score": 0.8204033590056482,
            "fpr": 0.08771929824561403,
            "logloss": 0.8731345236750453,
            "mae": 0.3032811344641291,
            "precision": 0.7964376590330788,
            "recall": 0.6374745417515275
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7943455143116303,
            "auditor_fn_violation": 0.010341565649501063,
            "auditor_fp_violation": 0.007735318331503843,
            "ave_precision_score": 0.7951828805140213,
            "fpr": 0.10428100987925357,
            "logloss": 0.8530273761339969,
            "mae": 0.3031081846585271,
            "precision": 0.76010101010101,
            "recall": 0.6501079913606912
        }
    }
]