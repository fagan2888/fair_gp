[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.769990987591269,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6766131176100226,
            "fpr": 0.1206140350877193,
            "logloss": 1.3967276748658686,
            "mae": 0.39640743857282296,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7573536256590524,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6661987441396211,
            "fpr": 0.1119648737650933,
            "logloss": 1.3510872813978108,
            "mae": 0.41043469470104715,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.769990987591269,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6766131176100226,
            "fpr": 0.1206140350877193,
            "logloss": 1.3387060104116704,
            "mae": 0.39648064856597204,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7573536256590524,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6661987441396211,
            "fpr": 0.1119648737650933,
            "logloss": 1.2996445860109018,
            "mae": 0.4104983841613933,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 1.4425092473263927,
            "mae": 0.39647939203209,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7570538617225675,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6661987441396211,
            "fpr": 0.1119648737650933,
            "logloss": 1.3917417996678019,
            "mae": 0.41053893363959965,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.8402897635613686,
            "mae": 0.3988675307482481,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.8488278014633869,
            "mae": 0.4119815062874628,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.8760528686794089,
            "mae": 0.39862542635385406,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.8831803657364657,
            "mae": 0.4119778361527247,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.7834667840941794,
            "mae": 0.4014436168302047,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.7923413063223786,
            "mae": 0.41387218747259363,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.800596724887819,
            "mae": 0.40050492804954974,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.8095854323493873,
            "mae": 0.4131779848351568,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.9447534241665444,
            "mae": 0.3974265561422758,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.9474429723634824,
            "mae": 0.4111023886470711,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.8857481320507733,
            "mae": 0.3984193105185241,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.8924307886471377,
            "mae": 0.41183927239754065,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.7871864268184021,
            "mae": 0.40122441682768495,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.7960996276994547,
            "mae": 0.4137089645692467,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6441401128232496,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6778422304662708,
            "fpr": 0.1206140350877193,
            "logloss": 1.0939270456673107,
            "mae": 0.39472092080273125,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6726279158334467,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6718291930025869,
            "fpr": 0.1119648737650933,
            "logloss": 1.0819236015566382,
            "mae": 0.4086906374089673,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.769990987591269,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6766131176100226,
            "fpr": 0.1206140350877193,
            "logloss": 1.2374264798653176,
            "mae": 0.3964056484728006,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7573536256590524,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6661987441396211,
            "fpr": 0.1119648737650933,
            "logloss": 1.2097784483115812,
            "mae": 0.4103997423018111,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7698946915643645,
            "auditor_fn_violation": 0.0049070247933884386,
            "auditor_fp_violation": 0.012233050500081985,
            "ave_precision_score": 0.6781035522360397,
            "fpr": 0.14144736842105263,
            "logloss": 0.7125102457890752,
            "mae": 0.4078662452663769,
            "precision": 0.7146017699115044,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7545020314249954,
            "auditor_fn_violation": 0.019520283999346057,
            "auditor_fp_violation": 0.02654878270371449,
            "ave_precision_score": 0.6629946084758414,
            "fpr": 0.13721185510428102,
            "logloss": 0.7196983688285111,
            "mae": 0.4188735914936966,
            "precision": 0.6995192307692307,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.8071363524729231,
            "mae": 0.4001895192879857,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.8161230500460886,
            "mae": 0.4129471226986886,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7713530818799602,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.68041208832474,
            "fpr": 0.1206140350877193,
            "logloss": 3.5682279428151373,
            "mae": 0.3941133638615148,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564739819483066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6655756632858172,
            "fpr": 0.1119648737650933,
            "logloss": 3.2848352816972777,
            "mae": 0.4087421998103547,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7594543132661122,
            "auditor_fn_violation": 0.0095240684355517,
            "auditor_fp_violation": 0.009525127070011482,
            "ave_precision_score": 0.6753486923259401,
            "fpr": 0.11293859649122807,
            "logloss": 0.9257871504146383,
            "mae": 0.4126452490883438,
            "precision": 0.7338501291989664,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532165875573864,
            "auditor_fn_violation": 0.01578812154050962,
            "auditor_fp_violation": 0.022197829003537024,
            "ave_precision_score": 0.6695631619980309,
            "fpr": 0.10757409440175632,
            "logloss": 0.8300720657315864,
            "mae": 0.4156618732597487,
            "precision": 0.7231638418079096,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.8331312552886674,
            "mae": 0.3991220899318394,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.8418343757518869,
            "mae": 0.41217008789205917,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7698946915643645,
            "auditor_fn_violation": 0.0049070247933884386,
            "auditor_fp_violation": 0.012233050500081985,
            "ave_precision_score": 0.6781035522360397,
            "fpr": 0.14144736842105263,
            "logloss": 0.7081498647853358,
            "mae": 0.4084205144134007,
            "precision": 0.7146017699115044,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7545020314249954,
            "auditor_fn_violation": 0.019520283999346057,
            "auditor_fp_violation": 0.02654878270371449,
            "ave_precision_score": 0.6629946084758414,
            "fpr": 0.13721185510428102,
            "logloss": 0.7152603135683877,
            "mae": 0.4193198991005036,
            "precision": 0.6995192307692307,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6930960647134491,
            "auditor_fn_violation": 0.004974989125706834,
            "auditor_fp_violation": 0.012233050500081985,
            "ave_precision_score": 0.6901650169944713,
            "fpr": 0.14144736842105263,
            "logloss": 0.7004532849441625,
            "mae": 0.4100748776670611,
            "precision": 0.7152317880794702,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6806261915722286,
            "auditor_fn_violation": 0.019394165868697022,
            "auditor_fp_violation": 0.02654878270371449,
            "ave_precision_score": 0.6686111746201124,
            "fpr": 0.13721185510428102,
            "logloss": 0.7071813166302844,
            "mae": 0.4207112802239595,
            "precision": 0.7009569377990431,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7660234675542514,
            "auditor_fn_violation": 0.03130437146585473,
            "auditor_fp_violation": 0.05580832923430073,
            "ave_precision_score": 0.6868690098436805,
            "fpr": 0.3717105263157895,
            "logloss": 3.650997686085507,
            "mae": 0.40180447702745403,
            "precision": 0.5659411011523687,
            "recall": 0.9132231404958677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7529019855802236,
            "auditor_fn_violation": 0.033736599948618544,
            "auditor_fp_violation": 0.041441091621427215,
            "ave_precision_score": 0.6752007428832545,
            "fpr": 0.3896816684961581,
            "logloss": 3.373900350706401,
            "mae": 0.4145332957760903,
            "precision": 0.5448717948717948,
            "recall": 0.9042553191489362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6772161656769234,
            "auditor_fn_violation": 0.004675946063505881,
            "auditor_fp_violation": 0.026664207247089684,
            "ave_precision_score": 0.6778313771704491,
            "fpr": 0.18859649122807018,
            "logloss": 1.212129275864106,
            "mae": 0.36099820890688755,
            "precision": 0.6634050880626223,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.703016596234776,
            "auditor_fn_violation": 0.018518345516967565,
            "auditor_fp_violation": 0.02879395446433238,
            "ave_precision_score": 0.7036218646919083,
            "fpr": 0.17892425905598244,
            "logloss": 1.0943742135049694,
            "mae": 0.3601591534951985,
            "precision": 0.6604166666666667,
            "recall": 0.674468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.668402441684676,
            "auditor_fn_violation": 0.01829826373785704,
            "auditor_fp_violation": 0.02414842597147073,
            "ave_precision_score": 0.6666185475850712,
            "fpr": 0.18640350877192982,
            "logloss": 1.6643283693399062,
            "mae": 0.3417148286927886,
            "precision": 0.6761904761904762,
            "recall": 0.7334710743801653
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.6782046190807747,
            "auditor_fn_violation": 0.029168320993997722,
            "auditor_fp_violation": 0.02179708326799436,
            "ave_precision_score": 0.6779623854405015,
            "fpr": 0.18221734357848518,
            "logloss": 1.432921123814225,
            "mae": 0.3501991822042289,
            "precision": 0.6699801192842942,
            "recall": 0.7170212765957447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.68716345058576,
            "auditor_fn_violation": 0.009508210091344064,
            "auditor_fp_violation": 0.02401008362026562,
            "ave_precision_score": 0.6825026182439632,
            "fpr": 0.2949561403508772,
            "logloss": 2.2506523510147365,
            "mae": 0.37467993845611836,
            "precision": 0.6032448377581121,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6891015596511813,
            "auditor_fn_violation": 0.011243197795268237,
            "auditor_fp_violation": 0.03416544078297254,
            "ave_precision_score": 0.6843381533344838,
            "fpr": 0.29527991218441274,
            "logloss": 2.0300609726177385,
            "mae": 0.3730096536189035,
            "precision": 0.5954887218045113,
            "recall": 0.8425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.7360006728953437,
            "mae": 0.40518993051036406,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.7438127031254151,
            "mae": 0.41674451374588894,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6388139123496243,
            "auditor_fn_violation": 0.019967920835145727,
            "auditor_fp_violation": 0.017308165272995574,
            "ave_precision_score": 0.6404348878622776,
            "fpr": 0.17105263157894737,
            "logloss": 1.197689797648408,
            "mae": 0.3803390944289469,
            "precision": 0.6586433260393874,
            "recall": 0.621900826446281
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6511502275885093,
            "auditor_fn_violation": 0.02882266389518183,
            "auditor_fp_violation": 0.01906404713367235,
            "ave_precision_score": 0.651740465614477,
            "fpr": 0.15477497255762898,
            "logloss": 1.123860497451115,
            "mae": 0.38025487854547185,
            "precision": 0.6642857142857143,
            "recall": 0.5936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6502331229379269,
            "auditor_fn_violation": 0.022378389154704952,
            "auditor_fp_violation": 0.013716387932447947,
            "ave_precision_score": 0.6519277248830551,
            "fpr": 0.17214912280701755,
            "logloss": 1.08478921417247,
            "mae": 0.3739159202046377,
            "precision": 0.6742738589211619,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6652522882057293,
            "auditor_fn_violation": 0.028505033047621288,
            "auditor_fp_violation": 0.02554318470893663,
            "ave_precision_score": 0.6669070221186222,
            "fpr": 0.1734357848518112,
            "logloss": 0.9978383782874305,
            "mae": 0.3775323982743212,
            "precision": 0.6542669584245077,
            "recall": 0.6361702127659574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.5787048779870805,
            "auditor_fn_violation": 0.009931854429462091,
            "auditor_fp_violation": 0.018117724217084775,
            "ave_precision_score": 0.5803079273088199,
            "fpr": 0.13596491228070176,
            "logloss": 0.7444607393391303,
            "mae": 0.4055912035206954,
            "precision": 0.7155963302752294,
            "recall": 0.6446280991735537
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.565386789797656,
            "auditor_fn_violation": 0.01953896816684962,
            "auditor_fp_violation": 0.026314806932652327,
            "ave_precision_score": 0.5670544450731486,
            "fpr": 0.1350164654226125,
            "logloss": 0.7514283675568317,
            "mae": 0.4169318689080415,
            "precision": 0.6962962962962963,
            "recall": 0.6
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.672058392113334,
            "auditor_fn_violation": 0.013271168624039452,
            "auditor_fp_violation": 0.021227865223807187,
            "ave_precision_score": 0.6737073560682977,
            "fpr": 0.17763157894736842,
            "logloss": 0.8934823043060801,
            "mae": 0.3738859085476991,
            "precision": 0.6733870967741935,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6907024760325045,
            "auditor_fn_violation": 0.02301889436438798,
            "auditor_fp_violation": 0.02392028893518623,
            "ave_precision_score": 0.6925843278202589,
            "fpr": 0.1756311745334797,
            "logloss": 0.8242698020937489,
            "mae": 0.3760852429280687,
            "precision": 0.6588486140724946,
            "recall": 0.6574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.5068104496008355,
            "auditor_fn_violation": 0.025371085254458463,
            "auditor_fp_violation": 0.013239875389408103,
            "ave_precision_score": 0.4692258019508587,
            "fpr": 0.3333333333333333,
            "logloss": 7.108998140171542,
            "mae": 0.4396565414526278,
            "precision": 0.5663338088445078,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.5075810469828759,
            "auditor_fn_violation": 0.031704696732606216,
            "auditor_fp_violation": 0.002912251618539864,
            "ave_precision_score": 0.4676818370820116,
            "fpr": 0.32821075740944017,
            "logloss": 6.952867844446199,
            "mae": 0.4420545692178137,
            "precision": 0.5628654970760234,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6463012834905568,
            "auditor_fn_violation": 0.02312599681020734,
            "auditor_fp_violation": 0.011925623052959506,
            "ave_precision_score": 0.6479989311805945,
            "fpr": 0.17214912280701755,
            "logloss": 1.1188714345517219,
            "mae": 0.3756015366830268,
            "precision": 0.6735966735966736,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6608308492860694,
            "auditor_fn_violation": 0.0308055211714973,
            "auditor_fp_violation": 0.026787736682671617,
            "ave_precision_score": 0.6624955551782286,
            "fpr": 0.1734357848518112,
            "logloss": 1.0414663694370512,
            "mae": 0.3785586878009312,
            "precision": 0.6519823788546255,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.918500182574609,
            "mae": 0.39778088788060767,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.9231546124216763,
            "mae": 0.4113550158350449,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 21353,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5339202929174454,
            "auditor_fn_violation": 0.006839477308974933,
            "auditor_fp_violation": 0.0060691301852762785,
            "ave_precision_score": 0.504981670192883,
            "fpr": 0.03179824561403509,
            "logloss": 5.421007578459212,
            "mae": 0.5751556153735169,
            "precision": 0.618421052631579,
            "recall": 0.09710743801652892
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.49451592826244706,
            "auditor_fn_violation": 0.005371698157273978,
            "auditor_fp_violation": 0.008445529693765544,
            "ave_precision_score": 0.47033216296506514,
            "fpr": 0.03293084522502744,
            "logloss": 5.103960801939704,
            "mae": 0.579498943671365,
            "precision": 0.53125,
            "recall": 0.07234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7728183669618571,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6862624726381117,
            "fpr": 0.1206140350877193,
            "logloss": 1.1003511214745556,
            "mae": 0.39759798099597293,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7571768644301858,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6724258575378343,
            "fpr": 0.1119648737650933,
            "logloss": 1.0884952934958523,
            "mae": 0.4115518642963615,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.764601382059799,
            "auditor_fn_violation": 0.0095240684355517,
            "auditor_fp_violation": 0.009525127070011482,
            "ave_precision_score": 0.6713147666722068,
            "fpr": 0.11293859649122807,
            "logloss": 0.9151152087796158,
            "mae": 0.413378616468164,
            "precision": 0.7338501291989664,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7596475022158233,
            "auditor_fn_violation": 0.01578812154050962,
            "auditor_fp_violation": 0.022197829003537024,
            "ave_precision_score": 0.668741051712983,
            "fpr": 0.10757409440175632,
            "logloss": 0.821433722849595,
            "mae": 0.41641184304574497,
            "precision": 0.7231638418079096,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.764601382059799,
            "auditor_fn_violation": 0.0095240684355517,
            "auditor_fp_violation": 0.009525127070011482,
            "ave_precision_score": 0.6713147666722068,
            "fpr": 0.11293859649122807,
            "logloss": 0.8562908178762058,
            "mae": 0.42056966278898084,
            "precision": 0.7338501291989664,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7596475022158233,
            "auditor_fn_violation": 0.01578812154050962,
            "auditor_fp_violation": 0.022197829003537024,
            "ave_precision_score": 0.668741051712983,
            "fpr": 0.10757409440175632,
            "logloss": 0.7726985677129083,
            "mae": 0.42341612852857907,
            "precision": 0.7231638418079096,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.5321325526378445,
            "auditor_fn_violation": 0.01668071262867914,
            "auditor_fp_violation": 0.004701078045581252,
            "ave_precision_score": 0.5181589417505748,
            "fpr": 0.26644736842105265,
            "logloss": 4.631112506365815,
            "mae": 0.40614393188250014,
            "precision": 0.6042345276872965,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.5141140571249969,
            "auditor_fn_violation": 0.021159819697783595,
            "auditor_fp_violation": 0.0033453557053996154,
            "ave_precision_score": 0.5028507484516362,
            "fpr": 0.27332601536772777,
            "logloss": 4.67900835726004,
            "mae": 0.42112226016929105,
            "precision": 0.5870646766169154,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7698988965587137,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6762192563307186,
            "fpr": 0.1206140350877193,
            "logloss": 3.567196917231219,
            "mae": 0.39670005042040557,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7554736148647041,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6620361445492304,
            "fpr": 0.1119648737650933,
            "logloss": 3.2809819163960334,
            "mae": 0.41080797876667896,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5250414086668981,
            "auditor_fn_violation": 0.009891075830071054,
            "auditor_fp_violation": 0.01382398753894081,
            "ave_precision_score": 0.540445116941362,
            "fpr": 0.09320175438596491,
            "logloss": 12.120897118067871,
            "mae": 0.5014889932750386,
            "precision": 0.5707070707070707,
            "recall": 0.2334710743801653
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5777058745232471,
            "auditor_fn_violation": 0.006684260924399191,
            "auditor_fp_violation": 0.009563137366179553,
            "ave_precision_score": 0.5768887932412315,
            "fpr": 0.09110867178924259,
            "logloss": 10.254108021773757,
            "mae": 0.4607788603997214,
            "precision": 0.6244343891402715,
            "recall": 0.2936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.5334054093295739,
            "auditor_fn_violation": 0.016116608670436426,
            "auditor_fp_violation": 0.002451733890801784,
            "ave_precision_score": 0.5195383843070391,
            "fpr": 0.2598684210526316,
            "logloss": 4.536538597027743,
            "mae": 0.4058408288773087,
            "precision": 0.6069651741293532,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.5149268265859734,
            "auditor_fn_violation": 0.027185463717682233,
            "auditor_fp_violation": 0.0019340337671841501,
            "ave_precision_score": 0.504484234129696,
            "fpr": 0.26344676180021953,
            "logloss": 4.639645424531518,
            "mae": 0.42022395642987764,
            "precision": 0.5918367346938775,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.8456695040440648,
            "mae": 0.39946735071900646,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.8538551869882974,
            "mae": 0.41258464333254735,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5224483696724146,
            "auditor_fn_violation": 0.013780901116427434,
            "auditor_fp_violation": 0.017159575340219706,
            "ave_precision_score": 0.5360736580252068,
            "fpr": 0.09320175438596491,
            "logloss": 12.125433219370121,
            "mae": 0.5018955720839036,
            "precision": 0.5792079207920792,
            "recall": 0.24173553719008264
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5752033084902016,
            "auditor_fn_violation": 0.008512973818810285,
            "auditor_fp_violation": 0.007930285176639266,
            "ave_precision_score": 0.5747077571141224,
            "fpr": 0.0889132821075741,
            "logloss": 10.204703262104738,
            "mae": 0.4612012169855311,
            "precision": 0.625,
            "recall": 0.2872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6744911623360728,
            "auditor_fn_violation": 0.005713534870233432,
            "auditor_fp_violation": 0.02693064436792917,
            "ave_precision_score": 0.6751351043079805,
            "fpr": 0.18969298245614036,
            "logloss": 1.241417013214843,
            "mae": 0.3612235671633926,
            "precision": 0.6614481409001957,
            "recall": 0.6983471074380165
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.7013563238679346,
            "auditor_fn_violation": 0.017226802438283863,
            "auditor_fp_violation": 0.02879395446433238,
            "ave_precision_score": 0.7019542220775183,
            "fpr": 0.17892425905598244,
            "logloss": 1.112985222660262,
            "mae": 0.3607516734693798,
            "precision": 0.6597077244258872,
            "recall": 0.6723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.5785175795879267,
            "auditor_fn_violation": 0.005040687980281287,
            "auditor_fp_violation": 0.018507132316773242,
            "ave_precision_score": 0.5801149294970244,
            "fpr": 0.13815789473684212,
            "logloss": 0.7331072646101857,
            "mae": 0.40671677766531183,
            "precision": 0.720620842572062,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.565054935824467,
            "auditor_fn_violation": 0.01784805100777729,
            "auditor_fp_violation": 0.026314806932652327,
            "ave_precision_score": 0.5667202840552427,
            "fpr": 0.1350164654226125,
            "logloss": 0.7397607548687526,
            "mae": 0.41781294427640353,
            "precision": 0.7028985507246377,
            "recall": 0.6191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.8596401753128563,
            "mae": 0.39906557577482443,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.8674380141535244,
            "mae": 0.4123063409367717,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 21353,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5232102601498796,
            "auditor_fn_violation": 0.013058213716108462,
            "auditor_fp_violation": 0.020771847843908845,
            "ave_precision_score": 0.5359624378779626,
            "fpr": 0.15570175438596492,
            "logloss": 12.367173639623665,
            "mae": 0.5113320837919968,
            "precision": 0.5298013245033113,
            "recall": 0.3305785123966942
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5755908929657059,
            "auditor_fn_violation": 0.006749655510661681,
            "auditor_fp_violation": 0.011795863607060099,
            "ave_precision_score": 0.5759021100847374,
            "fpr": 0.15916575192096596,
            "logloss": 10.358216867732086,
            "mae": 0.47159200916143335,
            "precision": 0.5606060606060606,
            "recall": 0.39361702127659576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6876857149532156,
            "auditor_fn_violation": 0.010593373930694509,
            "auditor_fp_violation": 0.02486063289063782,
            "ave_precision_score": 0.682719771869603,
            "fpr": 0.29385964912280704,
            "logloss": 2.24077966358164,
            "mae": 0.37381242612361637,
            "precision": 0.6035502958579881,
            "recall": 0.8429752066115702
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6894304613286211,
            "auditor_fn_violation": 0.01080178433799659,
            "auditor_fp_violation": 0.03395884515533255,
            "ave_precision_score": 0.684664562852964,
            "fpr": 0.29198682766191,
            "logloss": 2.0201620400801334,
            "mae": 0.3722804268082207,
            "precision": 0.5975794251134644,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6986920844025166,
            "auditor_fn_violation": 0.01184391764535306,
            "auditor_fp_violation": 0.01692131906869979,
            "ave_precision_score": 0.6987356967328896,
            "fpr": 0.16337719298245615,
            "logloss": 1.3605270082157763,
            "mae": 0.3437207003431062,
            "precision": 0.6869747899159664,
            "recall": 0.6756198347107438
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7189738798600362,
            "auditor_fn_violation": 0.021981923067940307,
            "auditor_fp_violation": 0.0266807052129304,
            "ave_precision_score": 0.7192512627073173,
            "fpr": 0.15806805708013172,
            "logloss": 1.2263175593971087,
            "mae": 0.34518813348087296,
            "precision": 0.6807095343680709,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6737946423284393,
            "auditor_fn_violation": 0.0006705814122082114,
            "auditor_fp_violation": 0.03580761190359076,
            "ave_precision_score": 0.6743313450845385,
            "fpr": 0.21600877192982457,
            "logloss": 1.2581185902538499,
            "mae": 0.3651016175600137,
            "precision": 0.6488413547237076,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7003453380474225,
            "auditor_fn_violation": 0.017906439031225917,
            "auditor_fp_violation": 0.028338448441945385,
            "ave_precision_score": 0.7010469906646171,
            "fpr": 0.20417124039517015,
            "logloss": 1.1495346084875577,
            "mae": 0.36604359335842324,
            "precision": 0.6523364485981309,
            "recall": 0.7425531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7123085078412823,
            "auditor_fn_violation": 0.0028137233579817312,
            "auditor_fp_violation": 0.020300459091654365,
            "ave_precision_score": 0.7133014293125174,
            "fpr": 0.4166666666666667,
            "logloss": 1.914139872857013,
            "mae": 0.432231425261993,
            "precision": 0.5550351288056206,
            "recall": 0.9793388429752066
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6970326134565407,
            "auditor_fn_violation": 0.010402410257607962,
            "auditor_fp_violation": 0.018556269928388488,
            "ave_precision_score": 0.6980995671146737,
            "fpr": 0.43798024149286496,
            "logloss": 1.9210884296223276,
            "mae": 0.45286647407961633,
            "precision": 0.5316901408450704,
            "recall": 0.9638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 1.1417936500128103,
            "mae": 0.39645722331969363,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7570538617225675,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6661987441396211,
            "fpr": 0.1119648737650933,
            "logloss": 1.1247168571639616,
            "mae": 0.4104103501293191,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7693428221083604,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6775664121287346,
            "fpr": 0.1206140350877193,
            "logloss": 0.7292386967486472,
            "mae": 0.40590024942107367,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7532794905826066,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6618336617647715,
            "fpr": 0.1119648737650933,
            "logloss": 0.73685426367683,
            "mae": 0.41730482305444033,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5233679871756447,
            "auditor_fn_violation": 0.009768740031897942,
            "auditor_fp_violation": 0.01807417199540909,
            "ave_precision_score": 0.5386644048840665,
            "fpr": 0.10416666666666667,
            "logloss": 12.190759838573696,
            "mae": 0.5023375088626514,
            "precision": 0.5581395348837209,
            "recall": 0.24793388429752067
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5768118135250921,
            "auditor_fn_violation": 0.0052222248172454945,
            "auditor_fp_violation": 0.010698168766225848,
            "ave_precision_score": 0.5757182521397044,
            "fpr": 0.09989023051591657,
            "logloss": 10.266082580606314,
            "mae": 0.4618202728128905,
            "precision": 0.6192468619246861,
            "recall": 0.3148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7022821309854035,
            "auditor_fn_violation": 0.04970458170218935,
            "auditor_fp_violation": 0.03204418757173308,
            "ave_precision_score": 0.6906259916107149,
            "fpr": 0.09210526315789473,
            "logloss": 0.730294338412975,
            "mae": 0.40799256819382046,
            "precision": 0.7529411764705882,
            "recall": 0.5289256198347108
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.7069729488121332,
            "auditor_fn_violation": 0.06002755914706777,
            "auditor_fp_violation": 0.025413751303668197,
            "ave_precision_score": 0.6843983480615098,
            "fpr": 0.07135016465422613,
            "logloss": 0.6932238550669978,
            "mae": 0.4147388682538147,
            "precision": 0.7750865051903114,
            "recall": 0.4765957446808511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7771326895308546,
            "auditor_fn_violation": 0.004974989125706834,
            "auditor_fp_violation": 0.012233050500081985,
            "ave_precision_score": 0.6675145600118091,
            "fpr": 0.14144736842105263,
            "logloss": 0.6849850719469222,
            "mae": 0.41185320600083,
            "precision": 0.7152317880794702,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7541132164917077,
            "auditor_fn_violation": 0.019394165868697022,
            "auditor_fp_violation": 0.02654878270371449,
            "ave_precision_score": 0.6423511895853309,
            "fpr": 0.13721185510428102,
            "logloss": 0.69208255285412,
            "mae": 0.4221770116644293,
            "precision": 0.7009569377990431,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5061099673795637,
            "auditor_fn_violation": 0.02446715963462375,
            "auditor_fp_violation": 0.014254385964912296,
            "ave_precision_score": 0.46848030904152427,
            "fpr": 0.33771929824561403,
            "logloss": 7.147927162964845,
            "mae": 0.4404847392710218,
            "precision": 0.5649717514124294,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5065896773828636,
            "auditor_fn_violation": 0.02870588784828456,
            "auditor_fp_violation": 0.008530159227979528,
            "ave_precision_score": 0.4666989375425377,
            "fpr": 0.33479692645444564,
            "logloss": 6.972757325285706,
            "mae": 0.44339725473807107,
            "precision": 0.5605187319884726,
            "recall": 0.8276595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5069003272509933,
            "auditor_fn_violation": 0.02552740321879078,
            "auditor_fp_violation": 0.013608788325955079,
            "ave_precision_score": 0.46931604020172446,
            "fpr": 0.33223684210526316,
            "logloss": 7.111955386570155,
            "mae": 0.4397999506321366,
            "precision": 0.5677603423680456,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5077991722031591,
            "auditor_fn_violation": 0.031704696732606216,
            "auditor_fp_violation": 0.006787786464750564,
            "ave_precision_score": 0.4679673758133406,
            "fpr": 0.3260153677277717,
            "logloss": 6.933585172130338,
            "mae": 0.4417343714488427,
            "precision": 0.5645161290322581,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6533289305130816,
            "auditor_fn_violation": 0.01864035087719298,
            "auditor_fp_violation": 0.015120306607640601,
            "ave_precision_score": 0.6550217797235494,
            "fpr": 0.17434210526315788,
            "logloss": 1.051647548344469,
            "mae": 0.3730954092544342,
            "precision": 0.6748466257668712,
            "recall": 0.6818181818181818
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6701232239079066,
            "auditor_fn_violation": 0.029100590886797315,
            "auditor_fp_violation": 0.02613559144843448,
            "ave_precision_score": 0.6717781437091087,
            "fpr": 0.17453347969264543,
            "logloss": 0.9309155273022698,
            "mae": 0.3768051725273131,
            "precision": 0.6535947712418301,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.770032822582029,
            "auditor_fn_violation": 0.007516855154414963,
            "auditor_fp_violation": 0.01435173798983441,
            "ave_precision_score": 0.6769988398206876,
            "fpr": 0.1206140350877193,
            "logloss": 0.8787744473210719,
            "mae": 0.39854616479000504,
            "precision": 0.7256857855361596,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7564299578069538,
            "auditor_fn_violation": 0.01641871219375482,
            "auditor_fp_violation": 0.023081460904888853,
            "ave_precision_score": 0.6649509363083936,
            "fpr": 0.1119648737650933,
            "logloss": 0.885769060825748,
            "mae": 0.4119104366467368,
            "precision": 0.7182320441988951,
            "recall": 0.5531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.5321325526378445,
            "auditor_fn_violation": 0.01668071262867914,
            "auditor_fp_violation": 0.004701078045581252,
            "ave_precision_score": 0.5181589417505748,
            "fpr": 0.26644736842105265,
            "logloss": 4.631110424234635,
            "mae": 0.4061437656721557,
            "precision": 0.6042345276872965,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.5141158556436849,
            "auditor_fn_violation": 0.021159819697783595,
            "auditor_fp_violation": 0.0033453557053996154,
            "ave_precision_score": 0.5028525465463602,
            "fpr": 0.27332601536772777,
            "logloss": 4.679007904377427,
            "mae": 0.42112216645173656,
            "precision": 0.5870646766169154,
            "recall": 0.7531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.5314725229389378,
            "auditor_fn_violation": 0.015033710308829929,
            "auditor_fp_violation": 0.006327881619937696,
            "ave_precision_score": 0.5190858924028894,
            "fpr": 0.2741228070175439,
            "logloss": 4.559794733555779,
            "mae": 0.40570507314991205,
            "precision": 0.6019108280254777,
            "recall": 0.78099173553719
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.516725891228715,
            "auditor_fn_violation": 0.021117780320900583,
            "auditor_fp_violation": 0.0057348954949707626,
            "ave_precision_score": 0.5054458256334831,
            "fpr": 0.283205268935236,
            "logloss": 4.608780952841023,
            "mae": 0.4194385941769332,
            "precision": 0.5852090032154341,
            "recall": 0.774468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5238879656663411,
            "auditor_fn_violation": 0.009104955052921575,
            "auditor_fp_violation": 0.01474626988030825,
            "ave_precision_score": 0.5387097543503919,
            "fpr": 0.09429824561403509,
            "logloss": 12.18124584948177,
            "mae": 0.501197967125919,
            "precision": 0.572139303482587,
            "recall": 0.23760330578512398
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.578449035704075,
            "auditor_fn_violation": 0.007693205969591515,
            "auditor_fp_violation": 0.005563147322595341,
            "ave_precision_score": 0.5773487190542297,
            "fpr": 0.09001097694840834,
            "logloss": 10.259359106331507,
            "mae": 0.4588078832808584,
            "precision": 0.6272727272727273,
            "recall": 0.2936170212765957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5076380039927154,
            "auditor_fn_violation": 0.025563650862693927,
            "auditor_fp_violation": 0.013378217740613214,
            "ave_precision_score": 0.4702220424366617,
            "fpr": 0.3344298245614035,
            "logloss": 7.0404884259915965,
            "mae": 0.44013788426489253,
            "precision": 0.5673758865248227,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5080476148926074,
            "auditor_fn_violation": 0.030151575308872646,
            "auditor_fp_violation": 0.004535147392290242,
            "ave_precision_score": 0.46821754921640835,
            "fpr": 0.3336992316136114,
            "logloss": 6.92643936979333,
            "mae": 0.44295931545765976,
            "precision": 0.5606936416184971,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.5785285169781021,
            "auditor_fn_violation": 0.005040687980281287,
            "auditor_fp_violation": 0.018507132316773242,
            "ave_precision_score": 0.5801260705160161,
            "fpr": 0.13815789473684212,
            "logloss": 0.724601294791104,
            "mae": 0.40764942843663066,
            "precision": 0.720620842572062,
            "recall": 0.6714876033057852
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.5649655450326727,
            "auditor_fn_violation": 0.019394165868697022,
            "auditor_fp_violation": 0.026314806932652327,
            "ave_precision_score": 0.5666291436646776,
            "fpr": 0.1350164654226125,
            "logloss": 0.731039704280667,
            "mae": 0.41855103156961804,
            "precision": 0.7043269230769231,
            "recall": 0.6234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6709555808650784,
            "auditor_fn_violation": 0.08440263882847618,
            "auditor_fp_violation": 0.012379078537465161,
            "ave_precision_score": 0.6726940299634827,
            "fpr": 0.043859649122807015,
            "logloss": 0.6476375630781532,
            "mae": 0.4443015740864128,
            "precision": 0.8095238095238095,
            "recall": 0.3512396694214876
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.6921121081051675,
            "auditor_fn_violation": 0.06973865520704393,
            "auditor_fp_violation": 0.009483486039860512,
            "ave_precision_score": 0.6926329194198391,
            "fpr": 0.036223929747530186,
            "logloss": 0.640976909948603,
            "mae": 0.44148870133627444,
            "precision": 0.8374384236453202,
            "recall": 0.3617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7332727519913751,
            "auditor_fn_violation": 0.014508119472234307,
            "auditor_fp_violation": 0.013252684866371552,
            "ave_precision_score": 0.7338652910463164,
            "fpr": 0.2774122807017544,
            "logloss": 1.2331466615831994,
            "mae": 0.3915961207433914,
            "precision": 0.6268436578171092,
            "recall": 0.878099173553719
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7244805857934916,
            "auditor_fn_violation": 0.00873251278697714,
            "auditor_fp_violation": 0.012545083895248542,
            "ave_precision_score": 0.7256740423649253,
            "fpr": 0.2864983534577388,
            "logloss": 1.2144915896865924,
            "mae": 0.40264202427818274,
            "precision": 0.612759643916914,
            "recall": 0.8787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4451754385964912,
            "auc_prc": 0.47410792112486283,
            "auditor_fn_violation": 0.018350369725967822,
            "auditor_fp_violation": 0.017262051155927202,
            "ave_precision_score": 0.4687363764756609,
            "fpr": 0.19517543859649122,
            "logloss": 15.470613291504064,
            "mae": 0.557214932878613,
            "precision": 0.46706586826347307,
            "recall": 0.32231404958677684
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.48659381236684485,
            "auditor_fn_violation": 0.013618422589158515,
            "auditor_fp_violation": 0.01822770820732245,
            "ave_precision_score": 0.4662160012049814,
            "fpr": 0.1942919868276619,
            "logloss": 13.788486840305735,
            "mae": 0.519236202233871,
            "precision": 0.5028089887640449,
            "recall": 0.38085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 21353,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5233245605144453,
            "auditor_fn_violation": 0.010593373930694506,
            "auditor_fp_violation": 0.01807417199540909,
            "ave_precision_score": 0.538621278197054,
            "fpr": 0.10416666666666667,
            "logloss": 12.184646290220256,
            "mae": 0.5022295961634691,
            "precision": 0.5581395348837209,
            "recall": 0.24793388429752067
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5768370969352832,
            "auditor_fn_violation": 0.0052222248172454945,
            "auditor_fp_violation": 0.009558159158284615,
            "ave_precision_score": 0.5757432000181151,
            "fpr": 0.10208562019758508,
            "logloss": 10.260666364969472,
            "mae": 0.46203770545858414,
            "precision": 0.6141078838174274,
            "recall": 0.3148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6502122071246346,
            "auditor_fn_violation": 0.0221042663476874,
            "auditor_fp_violation": 0.01072409411378915,
            "ave_precision_score": 0.6519811679983356,
            "fpr": 0.16447368421052633,
            "logloss": 1.0587104846602384,
            "mae": 0.37561642050388194,
            "precision": 0.6801705756929638,
            "recall": 0.6590909090909091
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6663172833306044,
            "auditor_fn_violation": 0.03381834318144662,
            "auditor_fp_violation": 0.021505858106140384,
            "ave_precision_score": 0.6679741510385182,
            "fpr": 0.16245883644346873,
            "logloss": 0.9629194850485598,
            "mae": 0.3759318629018347,
            "precision": 0.6597701149425287,
            "recall": 0.6106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.6357876778920208,
            "auditor_fn_violation": 0.020334928229665067,
            "auditor_fp_violation": 0.019326938842433194,
            "ave_precision_score": 0.6363775514915606,
            "fpr": 0.17324561403508773,
            "logloss": 1.2656363408677211,
            "mae": 0.3815189488754051,
            "precision": 0.6609442060085837,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6460393900247013,
            "auditor_fn_violation": 0.026592241399444147,
            "auditor_fp_violation": 0.02062471530873601,
            "ave_precision_score": 0.6465842458211413,
            "fpr": 0.15916575192096596,
            "logloss": 1.1846824353746737,
            "mae": 0.3812756923620874,
            "precision": 0.6596244131455399,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5587979745914848,
            "auditor_fn_violation": 0.0017194976076555025,
            "auditor_fp_violation": 0.010995655025414008,
            "ave_precision_score": 0.5604858096382558,
            "fpr": 0.4473684210526316,
            "logloss": 1.3407598168736585,
            "mae": 0.4578906138235572,
            "precision": 0.5410573678290214,
            "recall": 0.993801652892562
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5480818194434649,
            "auditor_fn_violation": 0.001275194432118084,
            "auditor_fp_violation": 0.0073179656055616625,
            "ave_precision_score": 0.5500637502717164,
            "fpr": 0.4676180021953897,
            "logloss": 1.4075668985179088,
            "mae": 0.47681855517475324,
            "precision": 0.5234899328859061,
            "recall": 0.9957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6859253154663056,
            "auditor_fn_violation": 0.012974391039582431,
            "auditor_fp_violation": 0.028657361862600435,
            "ave_precision_score": 0.6817356221539095,
            "fpr": 0.2741228070175439,
            "logloss": 2.085263723965173,
            "mae": 0.36985233102165943,
            "precision": 0.6147919876733436,
            "recall": 0.8243801652892562
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6898211178789542,
            "auditor_fn_violation": 0.013662797486979471,
            "auditor_fp_violation": 0.029856801849902064,
            "ave_precision_score": 0.6871543320323106,
            "fpr": 0.27552140504939626,
            "logloss": 1.8958448721510939,
            "mae": 0.3682264394699265,
            "precision": 0.6065830721003135,
            "recall": 0.823404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 21353,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.4798280970143871,
            "auditor_fn_violation": 0.017256143975641583,
            "auditor_fp_violation": 0.013803492375799316,
            "ave_precision_score": 0.47222320038819277,
            "fpr": 0.19298245614035087,
            "logloss": 15.386581371074893,
            "mae": 0.5545183330991612,
            "precision": 0.47147147147147145,
            "recall": 0.3243801652892562
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.48778918940108595,
            "auditor_fn_violation": 0.013036877875610167,
            "auditor_fp_violation": 0.016813897165159516,
            "ave_precision_score": 0.46702410403539607,
            "fpr": 0.19978046103183314,
            "logloss": 13.741051846086226,
            "mae": 0.5203300377958507,
            "precision": 0.5054347826086957,
            "recall": 0.39574468085106385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7009901942179466,
            "auditor_fn_violation": 0.004270425547339425,
            "auditor_fp_violation": 0.012906828988358746,
            "ave_precision_score": 0.7009974832365681,
            "fpr": 0.18201754385964913,
            "logloss": 0.6783192806175565,
            "mae": 0.40141024563069405,
            "precision": 0.6686626746506986,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6936946999972244,
            "auditor_fn_violation": 0.015904897587406874,
            "auditor_fp_violation": 0.030506457980191717,
            "ave_precision_score": 0.676794974748024,
            "fpr": 0.19319429198682767,
            "logloss": 0.6854032446558586,
            "mae": 0.4105404883328698,
            "precision": 0.6302521008403361,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.5323330455233103,
            "auditor_fn_violation": 0.01668071262867914,
            "auditor_fp_violation": 0.0031588170191834855,
            "ave_precision_score": 0.5184066274082177,
            "fpr": 0.26644736842105265,
            "logloss": 4.624255133893675,
            "mae": 0.4059551485775291,
            "precision": 0.6042345276872965,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5147488045888364,
            "auditor_fn_violation": 0.020447485811710308,
            "auditor_fp_violation": 0.0033453557053996154,
            "ave_precision_score": 0.5035082760191805,
            "fpr": 0.27332601536772777,
            "logloss": 4.670112945717543,
            "mae": 0.4204967370279207,
            "precision": 0.5877483443708609,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 21353,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.47380012563209695,
            "auditor_fn_violation": 0.019997372045817037,
            "auditor_fp_violation": 0.012932447942285628,
            "ave_precision_score": 0.4686573820297259,
            "fpr": 0.18859649122807018,
            "logloss": 15.395257611280309,
            "mae": 0.5558017797575175,
            "precision": 0.4674922600619195,
            "recall": 0.3119834710743802
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.48515705976798607,
            "auditor_fn_violation": 0.010353364317911125,
            "auditor_fp_violation": 0.01683380999673928,
            "ave_precision_score": 0.4661588251579631,
            "fpr": 0.18990120746432493,
            "logloss": 13.67572181322,
            "mae": 0.5178741665139422,
            "precision": 0.49415204678362573,
            "recall": 0.3595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.506903531689008,
            "auditor_fn_violation": 0.02552740321879078,
            "auditor_fp_violation": 0.013608788325955079,
            "ave_precision_score": 0.4693192541846361,
            "fpr": 0.33223684210526316,
            "logloss": 7.112027091175511,
            "mae": 0.4397991377357554,
            "precision": 0.5677603423680456,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5078018353578697,
            "auditor_fn_violation": 0.031704696732606216,
            "auditor_fp_violation": 0.006787786464750564,
            "ave_precision_score": 0.46796274322971243,
            "fpr": 0.3260153677277717,
            "logloss": 6.9336298069248175,
            "mae": 0.4417303143682313,
            "precision": 0.5645161290322581,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 21353,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.47826319991420013,
            "auditor_fn_violation": 0.014634986225895333,
            "auditor_fp_violation": 0.012712124938514516,
            "ave_precision_score": 0.4711184046453436,
            "fpr": 0.19078947368421054,
            "logloss": 15.361674500053711,
            "mae": 0.5543532503266495,
            "precision": 0.4727272727272727,
            "recall": 0.32231404958677684
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.4883057921928416,
            "auditor_fn_violation": 0.012371254408295769,
            "auditor_fp_violation": 0.017266914083599053,
            "ave_precision_score": 0.46707537266451354,
            "fpr": 0.19978046103183314,
            "logloss": 13.692544393614936,
            "mae": 0.5202531900015309,
            "precision": 0.5013698630136987,
            "recall": 0.3893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.700486521530045,
            "auditor_fn_violation": 0.004270425547339425,
            "auditor_fp_violation": 0.012906828988358746,
            "ave_precision_score": 0.7005388615024907,
            "fpr": 0.18201754385964913,
            "logloss": 0.6838042721285003,
            "mae": 0.40062562270057306,
            "precision": 0.6686626746506986,
            "recall": 0.6921487603305785
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6930318228914365,
            "auditor_fn_violation": 0.015904897587406874,
            "auditor_fp_violation": 0.030506457980191717,
            "ave_precision_score": 0.6762061168397304,
            "fpr": 0.19319429198682767,
            "logloss": 0.6907234718318351,
            "mae": 0.409842486242824,
            "precision": 0.6302521008403361,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6502122071246346,
            "auditor_fn_violation": 0.0221042663476874,
            "auditor_fp_violation": 0.01072409411378915,
            "ave_precision_score": 0.6519811679983356,
            "fpr": 0.16447368421052633,
            "logloss": 1.0587104513646082,
            "mae": 0.37561641916821853,
            "precision": 0.6801705756929638,
            "recall": 0.6590909090909091
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6663172833306044,
            "auditor_fn_violation": 0.03381834318144662,
            "auditor_fp_violation": 0.021505858106140384,
            "ave_precision_score": 0.6679741510385182,
            "fpr": 0.16245883644346873,
            "logloss": 0.9629194430408031,
            "mae": 0.375931863791655,
            "precision": 0.6597701149425287,
            "recall": 0.6106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 21353,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.4744421914707889,
            "auditor_fn_violation": 0.01764354066985647,
            "auditor_fp_violation": 0.013593416953598947,
            "ave_precision_score": 0.46829382179208523,
            "fpr": 0.19517543859649122,
            "logloss": 15.538798899233324,
            "mae": 0.5575697839890156,
            "precision": 0.463855421686747,
            "recall": 0.3181818181818182
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.4865141423099282,
            "auditor_fn_violation": 0.014386808977742497,
            "auditor_fp_violation": 0.017398836592814954,
            "ave_precision_score": 0.4661091838144449,
            "fpr": 0.19319429198682767,
            "logloss": 13.814204271776463,
            "mae": 0.5195077625636166,
            "precision": 0.5056179775280899,
            "recall": 0.3829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.5337517713156479,
            "auditor_fn_violation": 0.016116608670436426,
            "auditor_fp_violation": 0.002451733890801784,
            "ave_precision_score": 0.5198682903756535,
            "fpr": 0.2598684210526316,
            "logloss": 4.526214299282377,
            "mae": 0.40550597309057834,
            "precision": 0.6069651741293532,
            "recall": 0.756198347107438
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.5153628104489766,
            "auditor_fn_violation": 0.026823457972300725,
            "auditor_fp_violation": 0.0019340337671841501,
            "ave_precision_score": 0.5049072888835194,
            "fpr": 0.26344676180021953,
            "logloss": 4.630004432211641,
            "mae": 0.4198911529371543,
            "precision": 0.5911413969335605,
            "recall": 0.7382978723404255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6763912849294536,
            "auditor_fn_violation": 0.0033143939393939473,
            "auditor_fp_violation": 0.02804763075914084,
            "ave_precision_score": 0.6770176098282998,
            "fpr": 0.19078947368421054,
            "logloss": 1.2232341545440895,
            "mae": 0.3618573305738933,
            "precision": 0.6621359223300971,
            "recall": 0.7045454545454546
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7026517563863419,
            "auditor_fn_violation": 0.019057850853632912,
            "auditor_fp_violation": 0.02879395446433238,
            "ave_precision_score": 0.7032828400595301,
            "fpr": 0.17892425905598244,
            "logloss": 1.102063567137141,
            "mae": 0.3607607444402872,
            "precision": 0.6589958158995816,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5224431922149578,
            "auditor_fn_violation": 0.013780901116427434,
            "auditor_fp_violation": 0.017159575340219706,
            "ave_precision_score": 0.5360684829283072,
            "fpr": 0.09320175438596491,
            "logloss": 12.125435178203977,
            "mae": 0.5018954286651772,
            "precision": 0.5792079207920792,
            "recall": 0.24173553719008264
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5752033084902016,
            "auditor_fn_violation": 0.008512973818810285,
            "auditor_fp_violation": 0.007930285176639266,
            "ave_precision_score": 0.5747077571141224,
            "fpr": 0.0889132821075741,
            "logloss": 10.204704453342785,
            "mae": 0.461201232011088,
            "precision": 0.625,
            "recall": 0.2872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.521839353189752,
            "auditor_fn_violation": 0.009814049586776884,
            "auditor_fp_violation": 0.012087022462698806,
            "ave_precision_score": 0.5354649572888643,
            "fpr": 0.09429824561403509,
            "logloss": 12.124659649144501,
            "mae": 0.5024088571960262,
            "precision": 0.5742574257425742,
            "recall": 0.2396694214876033
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5746992825050896,
            "auditor_fn_violation": 0.008730177266039182,
            "auditor_fp_violation": 0.005087728468628585,
            "ave_precision_score": 0.5742069936018681,
            "fpr": 0.0867178924259056,
            "logloss": 10.20370578178265,
            "mae": 0.4614659893853712,
            "precision": 0.6325581395348837,
            "recall": 0.28936170212765955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 21353,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.47320672295122224,
            "auditor_fn_violation": 0.01764354066985647,
            "auditor_fp_violation": 0.015253525168060337,
            "ave_precision_score": 0.4676892797921457,
            "fpr": 0.19517543859649122,
            "logloss": 15.516912989708082,
            "mae": 0.558657346354795,
            "precision": 0.463855421686747,
            "recall": 0.3181818181818182
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.48673156306773574,
            "auditor_fn_violation": 0.010514515262629347,
            "auditor_fp_violation": 0.017533248205978336,
            "ave_precision_score": 0.4660696844882187,
            "fpr": 0.19099890230515917,
            "logloss": 13.788251587229595,
            "mae": 0.5191314095008057,
            "precision": 0.5042735042735043,
            "recall": 0.37659574468085105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6979438625032764,
            "auditor_fn_violation": 0.0049070247933884386,
            "auditor_fp_violation": 0.012233050500081985,
            "ave_precision_score": 0.6861196965331905,
            "fpr": 0.14144736842105263,
            "logloss": 0.6951593401303049,
            "mae": 0.4092347187627303,
            "precision": 0.7146017699115044,
            "recall": 0.6673553719008265
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6821805326933559,
            "auditor_fn_violation": 0.020006072354438662,
            "auditor_fp_violation": 0.02654878270371449,
            "ave_precision_score": 0.6651321090273601,
            "fpr": 0.13721185510428102,
            "logloss": 0.7023334974513357,
            "mae": 0.41984048659139356,
            "precision": 0.7002398081534772,
            "recall": 0.6212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.764601382059799,
            "auditor_fn_violation": 0.0095240684355517,
            "auditor_fp_violation": 0.009525127070011482,
            "ave_precision_score": 0.6713147666722068,
            "fpr": 0.11293859649122807,
            "logloss": 0.9049428191273817,
            "mae": 0.4141536362861333,
            "precision": 0.7338501291989664,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7596475022158233,
            "auditor_fn_violation": 0.01578812154050962,
            "auditor_fp_violation": 0.022197829003537024,
            "ave_precision_score": 0.668741051712983,
            "fpr": 0.10757409440175632,
            "logloss": 0.8126726826121153,
            "mae": 0.41712755202671614,
            "precision": 0.7231638418079096,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 21353,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.523481416637303,
            "auditor_fn_violation": 0.009104955052921575,
            "auditor_fp_violation": 0.014654041646171508,
            "ave_precision_score": 0.5383035818207957,
            "fpr": 0.09649122807017543,
            "logloss": 12.175876782786315,
            "mae": 0.5019284688966696,
            "precision": 0.5665024630541872,
            "recall": 0.23760330578512398
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5771076275801359,
            "auditor_fn_violation": 0.0066562346731438606,
            "auditor_fp_violation": 0.01053388790569283,
            "ave_precision_score": 0.5760109076771927,
            "fpr": 0.09330406147091108,
            "logloss": 10.259412832598557,
            "mae": 0.4606763363803025,
            "precision": 0.6222222222222222,
            "recall": 0.2978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.764601382059799,
            "auditor_fn_violation": 0.0095240684355517,
            "auditor_fp_violation": 0.009525127070011482,
            "ave_precision_score": 0.6713147666722068,
            "fpr": 0.11293859649122807,
            "logloss": 0.9114550041887538,
            "mae": 0.4136716716252921,
            "precision": 0.7338501291989664,
            "recall": 0.5867768595041323
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7596475022158233,
            "auditor_fn_violation": 0.01578812154050962,
            "auditor_fp_violation": 0.022197829003537024,
            "ave_precision_score": 0.668741051712983,
            "fpr": 0.10757409440175632,
            "logloss": 0.8182591931864979,
            "mae": 0.41667529884544774,
            "precision": 0.7231638418079096,
            "recall": 0.5446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 21353,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5067628715722975,
            "auditor_fn_violation": 0.023483942293750903,
            "auditor_fp_violation": 0.011805213969503202,
            "ave_precision_score": 0.46923939653849234,
            "fpr": 0.34100877192982454,
            "logloss": 7.092524841503924,
            "mae": 0.4420770108545601,
            "precision": 0.5638148667601683,
            "recall": 0.8305785123966942
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.5071519669881979,
            "auditor_fn_violation": 0.026076091272158257,
            "auditor_fp_violation": 0.002971990113279135,
            "ave_precision_score": 0.467322490863499,
            "fpr": 0.3402854006586169,
            "logloss": 6.939506867243372,
            "mae": 0.44449100640587424,
            "precision": 0.5602836879432624,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7638939364949959,
            "auditor_fn_violation": 0.02999492532985356,
            "auditor_fp_violation": 0.06620450073782587,
            "ave_precision_score": 0.6940380561936047,
            "fpr": 0.3607456140350877,
            "logloss": 0.7578229726896359,
            "mae": 0.40939655696785304,
            "precision": 0.574385510996119,
            "recall": 0.9173553719008265
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7429607371322203,
            "auditor_fn_violation": 0.03567508232711306,
            "auditor_fp_violation": 0.051534408128417857,
            "ave_precision_score": 0.6785848266638506,
            "fpr": 0.37980241492864986,
            "logloss": 0.7687672830710996,
            "mae": 0.42201254227878243,
            "precision": 0.5500650195058517,
            "recall": 0.9
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6724129217920622,
            "auditor_fn_violation": 0.013271168624039452,
            "auditor_fp_violation": 0.021604463846532217,
            "ave_precision_score": 0.674147405822564,
            "fpr": 0.17653508771929824,
            "logloss": 0.8935749974279634,
            "mae": 0.37371641984174114,
            "precision": 0.6747474747474748,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6910190964067051,
            "auditor_fn_violation": 0.02301889436438798,
            "auditor_fp_violation": 0.025246981339187704,
            "ave_precision_score": 0.692899427671466,
            "fpr": 0.17672886937431395,
            "logloss": 0.8244675761215284,
            "mae": 0.3760806379177686,
            "precision": 0.6574468085106383,
            "recall": 0.6574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5398607293250879,
            "auditor_fn_violation": 0.01751893939393941,
            "auditor_fp_violation": 0.013350036891293658,
            "ave_precision_score": 0.5548841480711575,
            "fpr": 0.09539473684210527,
            "logloss": 12.100856809210326,
            "mae": 0.4939158816737921,
            "precision": 0.5972222222222222,
            "recall": 0.2665289256198347
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5886935970083976,
            "auditor_fn_violation": 0.015697036223929758,
            "auditor_fp_violation": 0.008943350483259534,
            "ave_precision_score": 0.5875186646370002,
            "fpr": 0.09110867178924259,
            "logloss": 10.249343698015213,
            "mae": 0.4584848030963189,
            "precision": 0.6294642857142857,
            "recall": 0.3
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5223228109325885,
            "auditor_fn_violation": 0.011868837900536468,
            "auditor_fp_violation": 0.011159616330545994,
            "ave_precision_score": 0.5362064852577888,
            "fpr": 0.08442982456140351,
            "logloss": 12.080326154272425,
            "mae": 0.503028559002061,
            "precision": 0.5815217391304348,
            "recall": 0.22107438016528927
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5754569597242858,
            "auditor_fn_violation": 0.010967606324590705,
            "auditor_fp_violation": 0.002927186242224664,
            "ave_precision_score": 0.5749581547224265,
            "fpr": 0.07683863885839737,
            "logloss": 10.217430347159976,
            "mae": 0.46166845874545925,
            "precision": 0.6354166666666666,
            "recall": 0.25957446808510637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.5310975450449459,
            "auditor_fn_violation": 0.01682570320429172,
            "auditor_fp_violation": 0.003771110018035752,
            "ave_precision_score": 0.5171100630568221,
            "fpr": 0.26535087719298245,
            "logloss": 4.6623894780442,
            "mae": 0.406966980906306,
            "precision": 0.6052202283849919,
            "recall": 0.7665289256198347
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.5137143170313218,
            "auditor_fn_violation": 0.022145409533596474,
            "auditor_fp_violation": 0.006747960801591058,
            "ave_precision_score": 0.502448953621316,
            "fpr": 0.2722283205268935,
            "logloss": 4.681228134415169,
            "mae": 0.4215327549950989,
            "precision": 0.5873544093178037,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.5222882947416594,
            "auditor_fn_violation": 0.010493692909960859,
            "auditor_fp_violation": 0.017159575340219706,
            "ave_precision_score": 0.5359138210042935,
            "fpr": 0.09320175438596491,
            "logloss": 12.125128503087872,
            "mae": 0.5020318637776735,
            "precision": 0.5812807881773399,
            "recall": 0.24380165289256198
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.5749913013223467,
            "auditor_fn_violation": 0.006415676016535496,
            "auditor_fp_violation": 0.007930285176639266,
            "ave_precision_score": 0.5744981815450022,
            "fpr": 0.0889132821075741,
            "logloss": 10.204008712149752,
            "mae": 0.46129099367530146,
            "precision": 0.6284403669724771,
            "recall": 0.29148936170212764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 21353,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5087906019264782,
            "auditor_fn_violation": 0.023402385094968826,
            "auditor_fp_violation": 0.013168142318412873,
            "ave_precision_score": 0.4722281189836066,
            "fpr": 0.3355263157894737,
            "logloss": 6.899363215416184,
            "mae": 0.43678805188168585,
            "precision": 0.5702247191011236,
            "recall": 0.8388429752066116
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.5092124186466749,
            "auditor_fn_violation": 0.026554873064437025,
            "auditor_fp_violation": 0.005966382162085485,
            "ave_precision_score": 0.4701150851431631,
            "fpr": 0.33479692645444564,
            "logloss": 6.839291466208379,
            "mae": 0.43970193049474204,
            "precision": 0.566145092460882,
            "recall": 0.8468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 21353,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6802400920631363,
            "auditor_fn_violation": 0.01713607365521241,
            "auditor_fp_violation": 0.020067326610919835,
            "ave_precision_score": 0.6773371288311785,
            "fpr": 0.18311403508771928,
            "logloss": 1.6795756965300654,
            "mae": 0.3370906404025803,
            "precision": 0.6806883365200764,
            "recall": 0.7355371900826446
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6886589682736066,
            "auditor_fn_violation": 0.02751243664899456,
            "auditor_fp_violation": 0.02831604650641816,
            "ave_precision_score": 0.6869729337468391,
            "fpr": 0.1778265642151482,
            "logloss": 1.456852607536823,
            "mae": 0.34031462125874207,
            "precision": 0.6785714285714286,
            "recall": 0.7276595744680852
        }
    }
]