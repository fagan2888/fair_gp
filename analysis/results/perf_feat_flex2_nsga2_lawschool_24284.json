[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5915238115535812,
            "auditor_fn_violation": 0.08135561295877732,
            "auditor_fp_violation": 0.08645949981336322,
            "ave_precision_score": 0.5939594188410782,
            "fpr": 0.23903508771929824,
            "logloss": 0.6856331440790102,
            "mae": 0.4942521997972539,
            "precision": 0.57421875,
            "recall": 0.6012269938650306
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5290525464960919,
            "auditor_fn_violation": 0.07611156356597382,
            "auditor_fp_violation": 0.0934640394185663,
            "ave_precision_score": 0.5329044736862085,
            "fpr": 0.2689352360043908,
            "logloss": 0.6905788382720116,
            "mae": 0.49660513822385954,
            "precision": 0.5386064030131826,
            "recall": 0.6150537634408603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6321870197231758,
            "mae": 0.45571061001535046,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7143771456483042,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6861709382529693,
            "fpr": 0.15587266739846323,
            "logloss": 0.6478326641095989,
            "mae": 0.4635113307267722,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6325893857342161,
            "mae": 0.45621777763753607,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7143771456483042,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6861709382529693,
            "fpr": 0.15587266739846323,
            "logloss": 0.6480439143906531,
            "mae": 0.4639291134545361,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5082100712785899,
            "auditor_fn_violation": 0.003818659634772003,
            "auditor_fp_violation": 0.008637136576666253,
            "ave_precision_score": 0.5099819870667293,
            "fpr": 0.07346491228070176,
            "logloss": 0.9525680739335867,
            "mae": 0.5323734758258388,
            "precision": 0.5314685314685315,
            "recall": 0.1554192229038855
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.4889796360978622,
            "auditor_fn_violation": 0.006154173010870723,
            "auditor_fp_violation": 0.007292533213883134,
            "ave_precision_score": 0.49046087412524864,
            "fpr": 0.07574094401756312,
            "logloss": 0.9284727205146548,
            "mae": 0.5199641813856317,
            "precision": 0.5071428571428571,
            "recall": 0.15268817204301074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6304688235983932,
            "mae": 0.45344772572188,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7143771456483042,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6861709382529693,
            "fpr": 0.15587266739846323,
            "logloss": 0.6469809878638574,
            "mae": 0.46165025473033555,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6317819347762261,
            "mae": 0.4552060463384055,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7143771456483042,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6861709382529693,
            "fpr": 0.15587266739846323,
            "logloss": 0.6476212915448188,
            "mae": 0.4630971647120203,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.7728394358659064,
            "auditor_fn_violation": 0.000645786244752987,
            "auditor_fp_violation": 0.006151238024138368,
            "ave_precision_score": 0.5511835359893136,
            "fpr": 0.4309210526315789,
            "logloss": 0.6899243339452689,
            "mae": 0.4982539772203094,
            "precision": 0.5513698630136986,
            "recall": 0.9877300613496932
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7531807594651145,
            "auditor_fn_violation": 0.0016996565277433522,
            "auditor_fp_violation": 0.006266213149695056,
            "ave_precision_score": 0.5157324136901181,
            "fpr": 0.4698133918770582,
            "logloss": 0.6920706665821706,
            "mae": 0.4993569899338137,
            "precision": 0.5158371040723982,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.519146553850135,
            "mae": 0.5361842105263158,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.629562045700844,
            "mae": 0.5104281009879253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.758040241976937,
            "auditor_fn_violation": 0.010830373479711553,
            "auditor_fp_violation": 0.02385840487744184,
            "ave_precision_score": 0.7585795191223303,
            "fpr": 0.17214912280701755,
            "logloss": 0.7977647532398444,
            "mae": 0.35225793376832826,
            "precision": 0.6897233201581028,
            "recall": 0.7137014314928425
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7020389420924738,
            "auditor_fn_violation": 0.006989837470344534,
            "auditor_fp_violation": 0.017627108632410054,
            "ave_precision_score": 0.7027913967217387,
            "fpr": 0.21624588364434688,
            "logloss": 0.877264584643296,
            "mae": 0.3707783620091257,
            "precision": 0.645045045045045,
            "recall": 0.7698924731182796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5340366186733275,
            "auditor_fn_violation": 0.003323108384458071,
            "auditor_fp_violation": 0.0071181203600016625,
            "ave_precision_score": 0.5353245806817618,
            "fpr": 0.04824561403508772,
            "logloss": 0.9755085726321565,
            "mae": 0.5111621856656775,
            "precision": 0.5056179775280899,
            "recall": 0.09202453987730061
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.49091330260466964,
            "auditor_fn_violation": 0.004558384382045012,
            "auditor_fp_violation": 0.0043760121681688195,
            "ave_precision_score": 0.49244515886631485,
            "fpr": 0.0570801317233809,
            "logloss": 1.0298774240276458,
            "mae": 0.5066520459500155,
            "precision": 0.4157303370786517,
            "recall": 0.07956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6149910316224902,
            "auditor_fn_violation": 0.009928963513077179,
            "auditor_fp_violation": 0.0048395960350047776,
            "ave_precision_score": 0.6167089791125544,
            "fpr": 0.1337719298245614,
            "logloss": 0.6832969482079438,
            "mae": 0.4924632326879522,
            "precision": 0.6234567901234568,
            "recall": 0.4130879345603272
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5381050161310774,
            "auditor_fn_violation": 0.0039021281116107835,
            "auditor_fp_violation": 0.00655663465466914,
            "ave_precision_score": 0.5395850393275238,
            "fpr": 0.16245883644346873,
            "logloss": 0.6918760332447625,
            "mae": 0.49619623069967317,
            "precision": 0.5225806451612903,
            "recall": 0.34838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.5969080572627745,
            "auditor_fn_violation": 0.01418487425106736,
            "auditor_fp_violation": 0.007333271121065075,
            "ave_precision_score": 0.5978367497227894,
            "fpr": 0.12390350877192982,
            "logloss": 0.6881091438502963,
            "mae": 0.49494352998832863,
            "precision": 0.6089965397923875,
            "recall": 0.35991820040899797
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5297507193342925,
            "auditor_fn_violation": 0.0054294583525135,
            "auditor_fp_violation": 0.011757148553060993,
            "ave_precision_score": 0.531771618305064,
            "fpr": 0.14818880351262348,
            "logloss": 0.6945104618943079,
            "mae": 0.49754222131586756,
            "precision": 0.5178571428571429,
            "recall": 0.3118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7875008942137415,
            "auditor_fn_violation": 0.017555071215871992,
            "auditor_fp_violation": 0.0174738708473311,
            "ave_precision_score": 0.7396533779699247,
            "fpr": 0.1611842105263158,
            "logloss": 4.257718743754577,
            "mae": 0.3182379134839171,
            "precision": 0.7036290322580645,
            "recall": 0.7137014314928425
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7518823256606748,
            "auditor_fn_violation": 0.016238801742147948,
            "auditor_fp_violation": 0.027946916855768812,
            "ave_precision_score": 0.6933947862319598,
            "fpr": 0.18111964873765093,
            "logloss": 4.8832005365337,
            "mae": 0.3272387312875917,
            "precision": 0.6706586826347305,
            "recall": 0.7225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7556027496207368,
            "auditor_fn_violation": 0.010989577727549958,
            "auditor_fp_violation": 0.024791588901331346,
            "ave_precision_score": 0.7561440416026628,
            "fpr": 0.17434210526315788,
            "logloss": 0.799980525740074,
            "mae": 0.354803770283349,
            "precision": 0.68762278978389,
            "recall": 0.7157464212678937
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6989836134677497,
            "auditor_fn_violation": 0.00682459308570282,
            "auditor_fp_violation": 0.008478831225726432,
            "ave_precision_score": 0.69973804977358,
            "fpr": 0.22063666300768386,
            "logloss": 0.8800357771556341,
            "mae": 0.3732940467858472,
            "precision": 0.6404293381037567,
            "recall": 0.7698924731182796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 24284,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7864308108839372,
            "auditor_fn_violation": 0.012079342015570635,
            "auditor_fp_violation": 0.01792231761436689,
            "ave_precision_score": 0.7385841873713225,
            "fpr": 0.14364035087719298,
            "logloss": 4.382559223554173,
            "mae": 0.3236772579249395,
            "precision": 0.7152173913043478,
            "recall": 0.6728016359918201
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7520679661939021,
            "auditor_fn_violation": 0.017478134626960806,
            "auditor_fp_violation": 0.02525682613596649,
            "ave_precision_score": 0.6929189364098762,
            "fpr": 0.16245883644346873,
            "logloss": 5.034160761684887,
            "mae": 0.33191488128230323,
            "precision": 0.6824034334763949,
            "recall": 0.6838709677419355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7864541449352492,
            "auditor_fn_violation": 0.015610985541563522,
            "auditor_fp_violation": 0.016820642030608433,
            "ave_precision_score": 0.7386075923563348,
            "fpr": 0.13815789473684212,
            "logloss": 4.374779287357803,
            "mae": 0.3233618323299936,
            "precision": 0.7224669603524229,
            "recall": 0.6707566462167689
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7517895115451546,
            "auditor_fn_violation": 0.01855458376119826,
            "auditor_fp_violation": 0.026320064188074997,
            "ave_precision_score": 0.6926407082018646,
            "fpr": 0.1668496158068057,
            "logloss": 5.027310515771953,
            "mae": 0.33207950067056985,
            "precision": 0.6779661016949152,
            "recall": 0.6881720430107527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7581754701778564,
            "auditor_fn_violation": 0.019712176658414956,
            "auditor_fp_violation": 0.016989133590477375,
            "ave_precision_score": 0.758745234059742,
            "fpr": 0.11951754385964912,
            "logloss": 0.8256184846169081,
            "mae": 0.3525190312572046,
            "precision": 0.7386091127098321,
            "recall": 0.6298568507157464
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7050438072580996,
            "auditor_fn_violation": 0.01090612938635319,
            "auditor_fp_violation": 0.018404847577933887,
            "ave_precision_score": 0.7058005894720841,
            "fpr": 0.15587266739846323,
            "logloss": 0.8685295268066888,
            "mae": 0.3668546361444295,
            "precision": 0.6787330316742082,
            "recall": 0.6451612903225806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6321471855616636,
            "mae": 0.45540035734966133,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7142029088855919,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6860754386506096,
            "fpr": 0.15587266739846323,
            "logloss": 0.6479147414333574,
            "mae": 0.4632609046905677,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.49583821552228446,
            "auditor_fn_violation": 0.007527445915402014,
            "auditor_fp_violation": 0.006967774045041685,
            "ave_precision_score": 0.49714530147305525,
            "fpr": 0.0712719298245614,
            "logloss": 0.9952490795013607,
            "mae": 0.5371946720896583,
            "precision": 0.5255474452554745,
            "recall": 0.147239263803681
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.4837740346337247,
            "auditor_fn_violation": 0.006763216599978754,
            "auditor_fp_violation": 0.007292533213883134,
            "ave_precision_score": 0.48544052425515094,
            "fpr": 0.07574094401756312,
            "logloss": 0.9625373115721303,
            "mae": 0.5223654923893094,
            "precision": 0.5035971223021583,
            "recall": 0.15053763440860216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6490683672854867,
            "auditor_fn_violation": 0.004179672084095727,
            "auditor_fp_violation": 0.010451661067562535,
            "ave_precision_score": 0.6498757337890617,
            "fpr": 0.11842105263157894,
            "logloss": 0.7763723044826484,
            "mae": 0.44784999085472044,
            "precision": 0.6375838926174496,
            "recall": 0.3885480572597137
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6363092124463096,
            "auditor_fn_violation": 0.010450527011555319,
            "auditor_fp_violation": 0.00992355515301276,
            "ave_precision_score": 0.6373170480214351,
            "fpr": 0.13172338090010977,
            "logloss": 0.7711248873977673,
            "mae": 0.44073435353382534,
            "precision": 0.6103896103896104,
            "recall": 0.4043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6138650080692181,
            "auditor_fn_violation": 0.006094607684856323,
            "auditor_fp_violation": 0.006459707187590729,
            "ave_precision_score": 0.6146504487800765,
            "fpr": 0.11732456140350878,
            "logloss": 0.6852764448199784,
            "mae": 0.49380512310093955,
            "precision": 0.6348122866894198,
            "recall": 0.3803680981595092
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5238064751751724,
            "auditor_fn_violation": 0.005762307755863238,
            "auditor_fp_violation": 0.006583707845810799,
            "ave_precision_score": 0.5258770478101628,
            "fpr": 0.15916575192096596,
            "logloss": 0.6939581300389495,
            "mae": 0.4976676816180038,
            "precision": 0.5051194539249146,
            "recall": 0.31827956989247314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6132849352300164,
            "auditor_fn_violation": 0.006094607684856319,
            "auditor_fp_violation": 0.009090767699390318,
            "ave_precision_score": 0.6140799221706716,
            "fpr": 0.1118421052631579,
            "logloss": 0.685444547159654,
            "mae": 0.49376257799827217,
            "precision": 0.6344086021505376,
            "recall": 0.3619631901840491
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5248310761519628,
            "auditor_fn_violation": 0.005276017138203345,
            "auditor_fp_violation": 0.0015800898829945896,
            "ave_precision_score": 0.5269008392349912,
            "fpr": 0.14489571899012074,
            "logloss": 0.693909850018702,
            "mae": 0.4975259856583651,
            "precision": 0.5056179775280899,
            "recall": 0.2903225806451613
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7583060283715751,
            "auditor_fn_violation": 0.019712176658414956,
            "auditor_fp_violation": 0.013134565136244867,
            "ave_precision_score": 0.7588759937611672,
            "fpr": 0.11842105263157894,
            "logloss": 0.8321752915170821,
            "mae": 0.3519662449712035,
            "precision": 0.7403846153846154,
            "recall": 0.6298568507157464
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7050910028700645,
            "auditor_fn_violation": 0.01045996954782055,
            "auditor_fp_violation": 0.018564825525589093,
            "ave_precision_score": 0.7058518685817246,
            "fpr": 0.15477497255762898,
            "logloss": 0.8751584812590519,
            "mae": 0.366236211841532,
            "precision": 0.6795454545454546,
            "recall": 0.6430107526881721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5116734653200461,
            "auditor_fn_violation": 0.0007803250457432011,
            "auditor_fp_violation": 0.014137737961926095,
            "ave_precision_score": 0.5135308354585337,
            "fpr": 0.0756578947368421,
            "logloss": 0.9337356580743127,
            "mae": 0.5304223670493484,
            "precision": 0.5273972602739726,
            "recall": 0.1574642126789366
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.4915079333481699,
            "auditor_fn_violation": 0.005986567992162687,
            "auditor_fp_violation": 0.006861823354811399,
            "ave_precision_score": 0.4930140166435054,
            "fpr": 0.07574094401756312,
            "logloss": 0.9137836162811563,
            "mae": 0.5192050355129786,
            "precision": 0.5071428571428571,
            "recall": 0.15268817204301074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.757499448966158,
            "auditor_fn_violation": 0.006152907831952072,
            "auditor_fp_violation": 0.014803927667869447,
            "ave_precision_score": 0.75804522543532,
            "fpr": 0.18201754385964913,
            "logloss": 0.7913000929432471,
            "mae": 0.3529435089241133,
            "precision": 0.6819923371647509,
            "recall": 0.7280163599182005
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7052037525020938,
            "auditor_fn_violation": 0.009256046174002337,
            "auditor_fp_violation": 0.010418256191146589,
            "ave_precision_score": 0.7058139640143617,
            "fpr": 0.22941822173435786,
            "logloss": 0.8629730115012282,
            "mae": 0.37089697265200633,
            "precision": 0.6365217391304347,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7478833959610536,
            "auditor_fn_violation": 0.008895257058802423,
            "auditor_fp_violation": 0.014715793621168765,
            "ave_precision_score": 0.7403163676243882,
            "fpr": 0.13048245614035087,
            "logloss": 0.6321637109153726,
            "mae": 0.4555149362667611,
            "precision": 0.7301587301587301,
            "recall": 0.6584867075664622
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7046383714828097,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.699085635939358,
            "fpr": 0.15587266739846323,
            "logloss": 0.6478122864875479,
            "mae": 0.46340761661660396,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7533502922419356,
            "auditor_fn_violation": 0.01259955871273275,
            "auditor_fp_violation": 0.013909626311641986,
            "ave_precision_score": 0.7539229709477606,
            "fpr": 0.12609649122807018,
            "logloss": 0.8271860139343665,
            "mae": 0.3574705019813049,
            "precision": 0.7281323877068558,
            "recall": 0.6298568507157464
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6995077484887772,
            "auditor_fn_violation": 0.012492475478913637,
            "auditor_fp_violation": 0.012512736705832554,
            "ave_precision_score": 0.7002686566770007,
            "fpr": 0.16245883644346873,
            "logloss": 0.8669174274749003,
            "mae": 0.3722774162085256,
            "precision": 0.6674157303370787,
            "recall": 0.6387096774193548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7593647644350766,
            "auditor_fn_violation": 0.02305322354967173,
            "auditor_fp_violation": 0.009712890381983324,
            "ave_precision_score": 0.759934349277108,
            "fpr": 0.11513157894736842,
            "logloss": 0.8366975808530667,
            "mae": 0.3504153519908354,
            "precision": 0.7451456310679612,
            "recall": 0.6278118609406953
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7065633375815079,
            "auditor_fn_violation": 0.012712014447080486,
            "auditor_fp_violation": 0.016888748874001373,
            "ave_precision_score": 0.7073236016671467,
            "fpr": 0.15367727771679474,
            "logloss": 0.8812636019538194,
            "mae": 0.3642204413968405,
            "precision": 0.6818181818181818,
            "recall": 0.6451612903225806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5145118986060662,
            "auditor_fn_violation": 0.0064578624475298664,
            "auditor_fp_violation": 0.014137737961926095,
            "ave_precision_score": 0.5163780250492283,
            "fpr": 0.0756578947368421,
            "logloss": 0.9233980878997728,
            "mae": 0.5293636044993866,
            "precision": 0.5306122448979592,
            "recall": 0.15950920245398773
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.4923200118132728,
            "auditor_fn_violation": 0.005986567992162687,
            "auditor_fp_violation": 0.011700540971582995,
            "ave_precision_score": 0.49382806547503066,
            "fpr": 0.07793633369923161,
            "logloss": 0.9056890550109663,
            "mae": 0.5188060233657761,
            "precision": 0.5,
            "recall": 0.15268817204301074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6009336192361079,
            "auditor_fn_violation": 0.007897427618125064,
            "auditor_fp_violation": 0.008351997013811122,
            "ave_precision_score": 0.6019007453223184,
            "fpr": 0.11513157894736842,
            "logloss": 0.6881465082160749,
            "mae": 0.4947560221741074,
            "precision": 0.6167883211678832,
            "recall": 0.3456032719836401
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5291127720734597,
            "auditor_fn_violation": 0.005906306433908151,
            "auditor_fp_violation": 0.002446431999527453,
            "ave_precision_score": 0.5311287957535981,
            "fpr": 0.13172338090010977,
            "logloss": 0.6950972577980041,
            "mae": 0.4976090842819109,
            "precision": 0.5275590551181102,
            "recall": 0.28817204301075267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.5102937113126261,
            "auditor_fn_violation": 0.006578947368421054,
            "auditor_fp_violation": 0.014581000373273614,
            "ave_precision_score": 0.5121357728914105,
            "fpr": 0.07675438596491228,
            "logloss": 0.9425703975404015,
            "mae": 0.531927594661778,
            "precision": 0.527027027027027,
            "recall": 0.15950920245398773
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.49164011327295315,
            "auditor_fn_violation": 0.005986567992162687,
            "auditor_fp_violation": 0.008318853278071211,
            "ave_precision_score": 0.492944380133834,
            "fpr": 0.07903402854006586,
            "logloss": 0.9229025588251971,
            "mae": 0.5206898116515837,
            "precision": 0.4965034965034965,
            "recall": 0.15268817204301074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5763891591780981,
            "auditor_fn_violation": 0.06338795608653537,
            "auditor_fp_violation": 0.08394249512670565,
            "ave_precision_score": 0.5791202628812817,
            "fpr": 0.2576754385964912,
            "logloss": 0.6892791665589572,
            "mae": 0.4977282046160677,
            "precision": 0.5773381294964028,
            "recall": 0.656441717791411
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5183161976182646,
            "auditor_fn_violation": 0.06275745665285697,
            "auditor_fp_violation": 0.08979685261846986,
            "ave_precision_score": 0.5219311955442565,
            "fpr": 0.29308452250274425,
            "logloss": 0.6913745261254267,
            "mae": 0.49875572349970215,
            "precision": 0.5307557117750439,
            "recall": 0.6494623655913978
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5140811009744009,
            "auditor_fn_violation": 0.006377139166935746,
            "auditor_fp_violation": 0.013904441955953716,
            "ave_precision_score": 0.5158790695437521,
            "fpr": 0.07236842105263158,
            "logloss": 0.9417544338052233,
            "mae": 0.530974706847286,
            "precision": 0.5319148936170213,
            "recall": 0.15337423312883436
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.49318220623830644,
            "auditor_fn_violation": 0.005986567992162687,
            "auditor_fp_violation": 0.008707722750833119,
            "ave_precision_score": 0.49466484146311424,
            "fpr": 0.07464324917672886,
            "logloss": 0.9204230934001514,
            "mae": 0.5193859664999301,
            "precision": 0.5107913669064749,
            "recall": 0.15268817204301074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5143202580149702,
            "auditor_fn_violation": 0.02416989559789044,
            "auditor_fp_violation": 0.006376757496578327,
            "ave_precision_score": 0.5161968790873745,
            "fpr": 0.11732456140350878,
            "logloss": 0.9174266322454385,
            "mae": 0.529049801811772,
            "precision": 0.5091743119266054,
            "recall": 0.22699386503067484
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.49210226286633535,
            "auditor_fn_violation": 0.04133706313515811,
            "auditor_fp_violation": 0.019748662338237685,
            "ave_precision_score": 0.493600108461514,
            "fpr": 0.11086717892425905,
            "logloss": 0.9012791142610082,
            "mae": 0.5189564900900085,
            "precision": 0.495,
            "recall": 0.2129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 24284,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5233252426484745,
            "auditor_fn_violation": 0.022427618125067286,
            "auditor_fp_violation": 0.0025144125088134056,
            "ave_precision_score": 0.5249033528204553,
            "fpr": 0.09429824561403509,
            "logloss": 0.9069809026810944,
            "mae": 0.5244521331777307,
            "precision": 0.5425531914893617,
            "recall": 0.2085889570552147
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.49224637658621107,
            "auditor_fn_violation": 0.03708083991360079,
            "auditor_fp_violation": 0.024912258248709105,
            "ave_precision_score": 0.49459631792259917,
            "fpr": 0.09549945115257959,
            "logloss": 0.8905611071716708,
            "mae": 0.5150333354914097,
            "precision": 0.5396825396825397,
            "recall": 0.21935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7721636447978697,
            "auditor_fn_violation": 0.002334248197180069,
            "auditor_fp_violation": 0.01621925677076854,
            "ave_precision_score": 0.7725978228024323,
            "fpr": 0.3344298245614035,
            "logloss": 1.6286152116208654,
            "mae": 0.37585368600525626,
            "precision": 0.5949535192563081,
            "recall": 0.9161554192229039
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7293623707872208,
            "auditor_fn_violation": 0.004279829562220416,
            "auditor_fp_violation": 0.008446835636195383,
            "ave_precision_score": 0.7298071516396606,
            "fpr": 0.3512623490669594,
            "logloss": 1.8591461897532473,
            "mae": 0.39239600897679,
            "precision": 0.5698924731182796,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.4949079736288776,
            "auditor_fn_violation": 0.003491281885695842,
            "auditor_fp_violation": 0.006705964082783793,
            "ave_precision_score": 0.49644342261061536,
            "fpr": 0.07017543859649122,
            "logloss": 0.9896420829283773,
            "mae": 0.536547024170623,
            "precision": 0.5294117647058824,
            "recall": 0.147239263803681
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.4738551602769471,
            "auditor_fn_violation": 0.005013986756842886,
            "auditor_fp_violation": 0.010140140682145969,
            "ave_precision_score": 0.4760673468619917,
            "fpr": 0.07464324917672886,
            "logloss": 0.9598026037472015,
            "mae": 0.5221746603576988,
            "precision": 0.5036496350364964,
            "recall": 0.14838709677419354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7526081971761969,
            "auditor_fn_violation": 0.009101549886987413,
            "auditor_fp_violation": 0.020657065239931986,
            "ave_precision_score": 0.7531531566663512,
            "fpr": 0.15899122807017543,
            "logloss": 0.79671481597587,
            "mae": 0.35719405239637636,
            "precision": 0.6985446985446986,
            "recall": 0.6871165644171779
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6943675427166056,
            "auditor_fn_violation": 0.008852377748663298,
            "auditor_fp_violation": 0.009256570171250247,
            "ave_precision_score": 0.6951359722531987,
            "fpr": 0.2074643249176729,
            "logloss": 0.8688830484001755,
            "mae": 0.3746894556472107,
            "precision": 0.6460674157303371,
            "recall": 0.7419354838709677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5088583971969993,
            "auditor_fn_violation": 0.0025965988591109632,
            "auditor_fp_violation": 0.006540064700758992,
            "ave_precision_score": 0.5105414947517743,
            "fpr": 0.07017543859649122,
            "logloss": 0.9588873518303443,
            "mae": 0.5323528848882568,
            "precision": 0.539568345323741,
            "recall": 0.15337423312883436
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.4896700567955742,
            "auditor_fn_violation": 0.006763216599978754,
            "auditor_fp_violation": 0.007292533213883134,
            "ave_precision_score": 0.49117559371024383,
            "fpr": 0.07574094401756312,
            "logloss": 0.9333377054500939,
            "mae": 0.5195336858082551,
            "precision": 0.5035971223021583,
            "recall": 0.15053763440860216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7515377334381287,
            "auditor_fn_violation": 0.009101549886987413,
            "auditor_fp_violation": 0.01566712288996724,
            "ave_precision_score": 0.7520839420375123,
            "fpr": 0.1600877192982456,
            "logloss": 0.7965782361097126,
            "mae": 0.35789459592597905,
            "precision": 0.6970954356846473,
            "recall": 0.6871165644171779
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6931479003068507,
            "auditor_fn_violation": 0.0075044556968001655,
            "auditor_fp_violation": 0.004400624160115778,
            "ave_precision_score": 0.6939072303987713,
            "fpr": 0.20636663007683864,
            "logloss": 0.869232517454736,
            "mae": 0.37542484280578287,
            "precision": 0.6479400749063671,
            "recall": 0.7440860215053764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7536951988047942,
            "auditor_fn_violation": 0.003941986869013029,
            "auditor_fp_violation": 0.01647847455518229,
            "ave_precision_score": 0.7542398936966722,
            "fpr": 0.17982456140350878,
            "logloss": 0.8068170450482219,
            "mae": 0.3559628441691705,
            "precision": 0.6827852998065764,
            "recall": 0.721881390593047
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.6994664340830756,
            "auditor_fn_violation": 0.004851103006267481,
            "auditor_fp_violation": 0.013029588536718635,
            "ave_precision_score": 0.7002029371287192,
            "fpr": 0.23600439077936333,
            "logloss": 0.8838945000023642,
            "mae": 0.3741327555000459,
            "precision": 0.6305841924398625,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7589585689287716,
            "auditor_fn_violation": 0.00880556452480896,
            "auditor_fp_violation": 0.014645804819377047,
            "ave_precision_score": 0.7595152951132752,
            "fpr": 0.17982456140350878,
            "logloss": 0.8167894278054544,
            "mae": 0.3463304771357448,
            "precision": 0.6876190476190476,
            "recall": 0.7382413087934561
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7077718723951869,
            "auditor_fn_violation": 0.005618309077818303,
            "auditor_fp_violation": 0.008377922058743908,
            "ave_precision_score": 0.7084945946906637,
            "fpr": 0.2349066959385291,
            "logloss": 0.9029558232251833,
            "mae": 0.3655138157185192,
            "precision": 0.6335616438356164,
            "recall": 0.7956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7444049294369602,
            "auditor_fn_violation": 0.010727227065619065,
            "auditor_fp_violation": 0.017551636182655223,
            "ave_precision_score": 0.7449665198728197,
            "fpr": 0.14473684210526316,
            "logloss": 0.8104571162805603,
            "mae": 0.364726132287168,
            "precision": 0.7040358744394619,
            "recall": 0.6421267893660532
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6876778751857675,
            "auditor_fn_violation": 0.006848199426365925,
            "auditor_fp_violation": 0.013600586749888014,
            "ave_precision_score": 0.6884522614482913,
            "fpr": 0.18111964873765093,
            "logloss": 0.8610887731689809,
            "mae": 0.38076510677475867,
            "precision": 0.6518987341772152,
            "recall": 0.6645161290322581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7516581556923765,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7223650578188633,
            "fpr": 0.13157894736842105,
            "logloss": 0.6315651811104391,
            "mae": 0.4549737636392054,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7132977968900172,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6837602174208822,
            "fpr": 0.15587266739846323,
            "logloss": 0.6474693082392049,
            "mae": 0.4629015889505393,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6077795579804673,
            "auditor_fn_violation": 0.05351953503390379,
            "auditor_fp_violation": 0.01358819625896894,
            "ave_precision_score": 0.6085911720725166,
            "fpr": 0.09649122807017543,
            "logloss": 0.8302159439350569,
            "mae": 0.49488110645886574,
            "precision": 0.6286919831223629,
            "recall": 0.3047034764826176
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.5896835926875219,
            "auditor_fn_violation": 0.045942660198529335,
            "auditor_fp_violation": 0.017686177413082753,
            "ave_precision_score": 0.5903542352079318,
            "fpr": 0.09879253567508232,
            "logloss": 0.8214410090243438,
            "mae": 0.48833699663436503,
            "precision": 0.5927601809954751,
            "recall": 0.2817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.623852374181157,
            "auditor_fn_violation": 0.025042155490976936,
            "auditor_fp_violation": 0.005194724399651615,
            "ave_precision_score": 0.6122993251160067,
            "fpr": 0.09100877192982457,
            "logloss": 0.6915382209967464,
            "mae": 0.49911937656763355,
            "precision": 0.6925925925925925,
            "recall": 0.3824130879345603
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6092460755550625,
            "auditor_fn_violation": 0.014756323548505142,
            "auditor_fp_violation": 0.009766038404552231,
            "ave_precision_score": 0.5952495411424044,
            "fpr": 0.10318331503841932,
            "logloss": 0.6907667500290913,
            "mae": 0.49872817483482196,
            "precision": 0.6724738675958188,
            "recall": 0.4150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 24284,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7568242238966905,
            "auditor_fn_violation": 0.007872762171276864,
            "auditor_fp_violation": 0.015475301729501068,
            "ave_precision_score": 0.7573690526187361,
            "fpr": 0.18421052631578946,
            "logloss": 0.7934864684782469,
            "mae": 0.3538560455641952,
            "precision": 0.6787762906309751,
            "recall": 0.7259713701431493
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7053034876184421,
            "auditor_fn_violation": 0.005502638008569103,
            "auditor_fp_violation": 0.014693359192332871,
            "ave_precision_score": 0.7060246574202106,
            "fpr": 0.2283205268935236,
            "logloss": 0.8607961400621391,
            "mae": 0.37053358512922263,
            "precision": 0.6376306620209059,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7807507095945783,
            "auditor_fn_violation": 0.0017288235927241415,
            "auditor_fp_violation": 0.015693044668408606,
            "ave_precision_score": 0.7811152456282412,
            "fpr": 0.31798245614035087,
            "logloss": 1.5099758655992024,
            "mae": 0.36253606486252066,
            "precision": 0.6075778078484438,
            "recall": 0.918200408997955
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7358881180103407,
            "auditor_fn_violation": 0.004270387025955174,
            "auditor_fp_violation": 0.013834400673384092,
            "ave_precision_score": 0.7362874309902356,
            "fpr": 0.3413830954994512,
            "logloss": 1.7253403305642085,
            "mae": 0.37998328483787025,
            "precision": 0.5780189959294437,
            "recall": 0.9161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7746834742766036,
            "auditor_fn_violation": 0.0024912101316686428,
            "auditor_fp_violation": 0.013002364066193862,
            "ave_precision_score": 0.7750786697377102,
            "fpr": 0.3190789473684211,
            "logloss": 1.5508244655100385,
            "mae": 0.3670600480674038,
            "precision": 0.6078167115902965,
            "recall": 0.9222903885480572
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7324060525874346,
            "auditor_fn_violation": 0.005696210002006541,
            "auditor_fp_violation": 0.000910643702037382,
            "ave_precision_score": 0.7328141696372515,
            "fpr": 0.34796926454445665,
            "logloss": 1.7703775602961456,
            "mae": 0.3848345286551935,
            "precision": 0.5721997300944669,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6305242297810009,
            "mae": 0.453644593556722,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7143771456483042,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6861709382529693,
            "fpr": 0.15587266739846323,
            "logloss": 0.6469688351006928,
            "mae": 0.4618156324626324,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5823137291286599,
            "auditor_fn_violation": 0.008200139920353029,
            "auditor_fp_violation": 0.007781717888100873,
            "ave_precision_score": 0.5849980373933812,
            "fpr": 0.36951754385964913,
            "logloss": 0.6869557964420586,
            "mae": 0.4963185647012372,
            "precision": 0.5414965986394558,
            "recall": 0.8139059304703476
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.521930183049716,
            "auditor_fn_violation": 0.003930455720406502,
            "auditor_fp_violation": 0.010932646822837962,
            "ave_precision_score": 0.5255046673009172,
            "fpr": 0.3929747530186608,
            "logloss": 0.6907589541099678,
            "mae": 0.49810519111143375,
            "precision": 0.5102599179206566,
            "recall": 0.8021505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4550438596491228,
            "auc_prc": 0.5650727014073615,
            "auditor_fn_violation": 0.08434685896745955,
            "auditor_fp_violation": 0.061893430384471836,
            "ave_precision_score": 0.5659998792009912,
            "fpr": 0.23355263157894737,
            "logloss": 0.8113462435602061,
            "mae": 0.5113412095152103,
            "precision": 0.4904306220095694,
            "recall": 0.41922290388548056
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5402684759444789,
            "auditor_fn_violation": 0.09401225169080416,
            "auditor_fp_violation": 0.06734579356445634,
            "ave_precision_score": 0.5411567253557298,
            "fpr": 0.23600439077936333,
            "logloss": 0.8087489974427648,
            "mae": 0.5043824061170695,
            "precision": 0.47560975609756095,
            "recall": 0.41935483870967744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8278368487092158,
            "auditor_fn_violation": 0.007836885157679477,
            "auditor_fp_violation": 0.018806250259217786,
            "ave_precision_score": 0.8281606741636012,
            "fpr": 0.13925438596491227,
            "logloss": 0.885889535255692,
            "mae": 0.2764607097219029,
            "precision": 0.7454909819639278,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.794617031482704,
            "auditor_fn_violation": 0.00791284539027183,
            "auditor_fp_violation": 0.011306749100431703,
            "ave_precision_score": 0.7950860614512718,
            "fpr": 0.1712403951701427,
            "logloss": 0.8888976187372092,
            "mae": 0.2898935279257604,
            "precision": 0.7056603773584905,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4309210526315789,
            "auc_prc": 0.4701356109322323,
            "auditor_fn_violation": 0.00983702866573387,
            "auditor_fp_violation": 0.01221952635726432,
            "ave_precision_score": 0.4716978928930552,
            "fpr": 0.13048245614035087,
            "logloss": 0.9551767365635486,
            "mae": 0.5408288008419045,
            "precision": 0.42788461538461536,
            "recall": 0.18200408997955012
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0.44563031738937847,
            "auditor_fn_violation": 0.02340568676746575,
            "auditor_fp_violation": 0.017366221517772326,
            "ave_precision_score": 0.44751302340677146,
            "fpr": 0.14270032930845225,
            "logloss": 0.937423034676302,
            "mae": 0.5305521384486775,
            "precision": 0.4009216589861751,
            "recall": 0.1870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8250569474844083,
            "auditor_fn_violation": 0.008278620887597317,
            "auditor_fp_violation": 0.022069802164986933,
            "ave_precision_score": 0.8253164563479781,
            "fpr": 0.14144736842105263,
            "logloss": 0.9799263512324453,
            "mae": 0.27558336950661855,
            "precision": 0.7435387673956262,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7903632781914602,
            "auditor_fn_violation": 0.01032777404010718,
            "auditor_fp_violation": 0.021599484132648793,
            "ave_precision_score": 0.7907490871774718,
            "fpr": 0.15916575192096596,
            "logloss": 0.9914409419282452,
            "mae": 0.283217603309033,
            "precision": 0.7173489278752436,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.6253426574096016,
            "auditor_fn_violation": 0.010061260000717545,
            "auditor_fp_violation": 0.018671457011322643,
            "ave_precision_score": 0.6220822974830121,
            "fpr": 0.18859649122807018,
            "logloss": 10.967756494749686,
            "mae": 0.4828372502703566,
            "precision": 0.5612244897959183,
            "recall": 0.4498977505112474
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5857684705986548,
            "auditor_fn_violation": 0.010927375092949968,
            "auditor_fp_violation": 0.018111964873765093,
            "ave_precision_score": 0.581507423576707,
            "fpr": 0.1877058177826564,
            "logloss": 10.487910073625265,
            "mae": 0.4698764322950223,
            "precision": 0.5464190981432361,
            "recall": 0.443010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7589603513020413,
            "auditor_fn_violation": 0.020887148853729415,
            "auditor_fp_violation": 0.012450230185392562,
            "ave_precision_score": 0.7595296198490638,
            "fpr": 0.11513157894736842,
            "logloss": 0.8364634795424595,
            "mae": 0.350866413971334,
            "precision": 0.7445255474452555,
            "recall": 0.6257668711656442
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7064952823852785,
            "auditor_fn_violation": 0.012712014447080486,
            "auditor_fp_violation": 0.01775755218972893,
            "ave_precision_score": 0.7072516092499774,
            "fpr": 0.15477497255762898,
            "logloss": 0.8813064731012838,
            "mae": 0.36449780780042235,
            "precision": 0.6802721088435374,
            "recall": 0.6451612903225806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7758102521787482,
            "auditor_fn_violation": 0.0028320417608438298,
            "auditor_fp_violation": 0.017447949068889718,
            "ave_precision_score": 0.7761863605132143,
            "fpr": 0.3201754385964912,
            "logloss": 1.5706807619061909,
            "mae": 0.3659807982956875,
            "precision": 0.6069986541049798,
            "recall": 0.9222903885480572
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7329618254772218,
            "auditor_fn_violation": 0.005037593097505992,
            "auditor_fp_violation": 0.00887508429607244,
            "ave_precision_score": 0.733385057991432,
            "fpr": 0.3468715697036224,
            "logloss": 1.787329790425151,
            "mae": 0.3827881720128713,
            "precision": 0.5746971736204576,
            "recall": 0.9182795698924732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7603923535095263,
            "auditor_fn_violation": 0.02305322354967173,
            "auditor_fp_violation": 0.008924868317365518,
            "ave_precision_score": 0.7609608151508844,
            "fpr": 0.11403508771929824,
            "logloss": 0.8308725673385642,
            "mae": 0.3497160787259214,
            "precision": 0.7469586374695864,
            "recall": 0.6278118609406953
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7079847577355469,
            "auditor_fn_violation": 0.012712014447080486,
            "auditor_fp_violation": 0.014250343337287662,
            "ave_precision_score": 0.7087398813655931,
            "fpr": 0.1525795828759605,
            "logloss": 0.8755740804022195,
            "mae": 0.3631305447288974,
            "precision": 0.683371298405467,
            "recall": 0.6451612903225806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8414195924191987,
            "auditor_fn_violation": 0.009845997919133214,
            "auditor_fp_violation": 0.020444506656712703,
            "ave_precision_score": 0.8416813640341201,
            "fpr": 0.13486842105263158,
            "logloss": 0.8182166399034807,
            "mae": 0.2733155078430335,
            "precision": 0.7520161290322581,
            "recall": 0.7627811860940695
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.80777349256429,
            "auditor_fn_violation": 0.01136645302928367,
            "auditor_fp_violation": 0.016504801799628852,
            "ave_precision_score": 0.8082530162155501,
            "fpr": 0.1602634467618002,
            "logloss": 0.812596536109117,
            "mae": 0.2828815535771247,
            "precision": 0.7197696737044146,
            "recall": 0.8064516129032258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8458271763961481,
            "auditor_fn_violation": 0.010769831019265957,
            "auditor_fp_violation": 0.023905064078636306,
            "ave_precision_score": 0.8460710227465749,
            "fpr": 0.13596491228070176,
            "logloss": 0.7738522353791073,
            "mae": 0.27142091031969623,
            "precision": 0.75,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8121196964875601,
            "auditor_fn_violation": 0.010729081831379913,
            "auditor_fp_violation": 0.017437596294418496,
            "ave_precision_score": 0.812539280765162,
            "fpr": 0.16136114160263446,
            "logloss": 0.7780866596390262,
            "mae": 0.28060191558320013,
            "precision": 0.7178502879078695,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 24284,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.4131387059854635,
            "auditor_fn_violation": 0.0027961647472464564,
            "auditor_fp_violation": 0.005295819335572977,
            "ave_precision_score": 0.4147486399647897,
            "fpr": 0.029605263157894735,
            "logloss": 0.9786449305968564,
            "mae": 0.51490985641354,
            "precision": 0.22857142857142856,
            "recall": 0.016359918200409
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.4047224604132357,
            "auditor_fn_violation": 0.001133104351828931,
            "auditor_fp_violation": 0.005434327821887937,
            "ave_precision_score": 0.4064759394160029,
            "fpr": 0.019758507135016465,
            "logloss": 1.0255813550534774,
            "mae": 0.5073245460848385,
            "precision": 0.3333333333333333,
            "recall": 0.01935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8013279725734281,
            "auditor_fn_violation": 0.0008857137731855202,
            "auditor_fp_violation": 0.017440172535357318,
            "ave_precision_score": 0.8016425128092917,
            "fpr": 0.38596491228070173,
            "logloss": 1.9475153382667436,
            "mae": 0.3925074768290102,
            "precision": 0.5764139590854392,
            "recall": 0.9795501022494888
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7550714546288637,
            "auditor_fn_violation": 0.00022426023629947033,
            "auditor_fp_violation": 0.011528257027954302,
            "ave_precision_score": 0.7554183223642557,
            "fpr": 0.40065861690450055,
            "logloss": 2.1686501113692955,
            "mae": 0.4060723327629328,
            "precision": 0.5548780487804879,
            "recall": 0.978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.829047443033813,
            "auditor_fn_violation": 0.005744806802281783,
            "auditor_fp_violation": 0.017722719920368304,
            "ave_precision_score": 0.8293381234772048,
            "fpr": 0.1513157894736842,
            "logloss": 0.9367568042044101,
            "mae": 0.27672312368905627,
            "precision": 0.7371428571428571,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7945470763786215,
            "auditor_fn_violation": 0.008989294524509285,
            "auditor_fp_violation": 0.019886489493140636,
            "ave_precision_score": 0.7949044593608217,
            "fpr": 0.1800219538968167,
            "logloss": 0.9719571146397465,
            "mae": 0.28503010786262734,
            "precision": 0.6979742173112339,
            "recall": 0.8150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8478975568375146,
            "auditor_fn_violation": 0.015492142934022174,
            "auditor_fp_violation": 0.01247355978598981,
            "ave_precision_score": 0.8481213498308049,
            "fpr": 0.1162280701754386,
            "logloss": 0.7612191591319858,
            "mae": 0.2724989929280115,
            "precision": 0.7725321888412017,
            "recall": 0.7361963190184049
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8141100691633263,
            "auditor_fn_violation": 0.010410396232428034,
            "auditor_fp_violation": 0.021727466490772965,
            "ave_precision_score": 0.8144828072793633,
            "fpr": 0.14709110867178923,
            "logloss": 0.7566494599452264,
            "mae": 0.2795615324261442,
            "precision": 0.728744939271255,
            "recall": 0.7741935483870968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8321299861937417,
            "auditor_fn_violation": 0.006430954687331831,
            "auditor_fp_violation": 0.019371345029239765,
            "ave_precision_score": 0.832427120979433,
            "fpr": 0.15460526315789475,
            "logloss": 0.8799845079981673,
            "mae": 0.276813417391518,
            "precision": 0.7334593572778828,
            "recall": 0.7934560327198364
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7961194969010784,
            "auditor_fn_violation": 0.009071916716830143,
            "auditor_fp_violation": 0.01646050021412434,
            "ave_precision_score": 0.7965790108230906,
            "fpr": 0.18221734357848518,
            "logloss": 0.8905848097221467,
            "mae": 0.2887207106345755,
            "precision": 0.6954128440366972,
            "recall": 0.8150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.84450397152136,
            "auditor_fn_violation": 0.00887731855200374,
            "auditor_fp_violation": 0.016849155986893946,
            "ave_precision_score": 0.8447179429081979,
            "fpr": 0.12390350877192982,
            "logloss": 0.7774811324976622,
            "mae": 0.27291198226293506,
            "precision": 0.7645833333333333,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8122017444354188,
            "auditor_fn_violation": 0.011696941798567097,
            "auditor_fp_violation": 0.015104379457847046,
            "ave_precision_score": 0.8126236580169737,
            "fpr": 0.1525795828759605,
            "logloss": 0.7680249557663723,
            "mae": 0.2811449028218151,
            "precision": 0.7242063492063492,
            "recall": 0.7849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8399695565536198,
            "auditor_fn_violation": 0.006605855128619096,
            "auditor_fp_violation": 0.02061559039442578,
            "ave_precision_score": 0.8402372201559337,
            "fpr": 0.13596491228070176,
            "logloss": 0.8167713442632367,
            "mae": 0.273316513400281,
            "precision": 0.751004016064257,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8062203279420572,
            "auditor_fn_violation": 0.009895778005972408,
            "auditor_fp_violation": 0.01678537850782416,
            "ave_precision_score": 0.8067026428636469,
            "fpr": 0.16465422612513722,
            "logloss": 0.8152452315406122,
            "mae": 0.28346997195710427,
            "precision": 0.715370018975332,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.756018814953298,
            "auditor_fn_violation": 0.00953880099020558,
            "auditor_fp_violation": 0.014044419559537152,
            "ave_precision_score": 0.7565646556561114,
            "fpr": 0.1875,
            "logloss": 0.7942548070068084,
            "mae": 0.3547259243587417,
            "precision": 0.6755218216318786,
            "recall": 0.7280163599182005
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7043058571234306,
            "auditor_fn_violation": 0.005486113570104934,
            "auditor_fp_violation": 0.011833445728096562,
            "ave_precision_score": 0.7050278420343059,
            "fpr": 0.2305159165751921,
            "logloss": 0.8617940833535614,
            "mae": 0.371363272902257,
            "precision": 0.6360485268630849,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 24284,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.5651062870130127,
            "auditor_fn_violation": 0.08434685896745955,
            "auditor_fp_violation": 0.0612013189000871,
            "ave_precision_score": 0.5660342947693234,
            "fpr": 0.2324561403508772,
            "logloss": 0.811473259720871,
            "mae": 0.5113511021502251,
            "precision": 0.49160671462829736,
            "recall": 0.41922290388548056
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.540571886026221,
            "auditor_fn_violation": 0.09401225169080416,
            "auditor_fp_violation": 0.06716612602324357,
            "ave_precision_score": 0.541454752870545,
            "fpr": 0.2349066959385291,
            "logloss": 0.8087899370348939,
            "mae": 0.5043639901587913,
            "precision": 0.4767726161369193,
            "recall": 0.41935483870967744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8268509114467153,
            "auditor_fn_violation": 0.011247443762781192,
            "auditor_fp_violation": 0.02262971257932064,
            "ave_precision_score": 0.8272151120441469,
            "fpr": 0.14035087719298245,
            "logloss": 0.9490052166686016,
            "mae": 0.2754365184540118,
            "precision": 0.7450199203187251,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.792471393028617,
            "auditor_fn_violation": 0.01032777404010718,
            "auditor_fp_violation": 0.021599484132648793,
            "ave_precision_score": 0.7930394770874437,
            "fpr": 0.15916575192096596,
            "logloss": 0.956089472748001,
            "mae": 0.2834926969121611,
            "precision": 0.7173489278752436,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8246124778730095,
            "auditor_fn_violation": 0.008278620887597317,
            "auditor_fp_violation": 0.02086962382315126,
            "ave_precision_score": 0.8248987798845904,
            "fpr": 0.14035087719298245,
            "logloss": 0.9828184253000107,
            "mae": 0.2756805977394989,
            "precision": 0.7450199203187251,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7900061298758201,
            "auditor_fn_violation": 0.01032777404010718,
            "auditor_fp_violation": 0.01905952656372291,
            "ave_precision_score": 0.7904773308469599,
            "fpr": 0.15806805708013172,
            "logloss": 0.9941708740039644,
            "mae": 0.28337160189431326,
            "precision": 0.71875,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5667585411474403,
            "auditor_fn_violation": 0.006206723352348155,
            "auditor_fp_violation": 0.00869416448923728,
            "ave_precision_score": 0.5686963291061764,
            "fpr": 0.3366228070175439,
            "logloss": 0.684401932495494,
            "mae": 0.49341848955015866,
            "precision": 0.5550724637681159,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5071586851152861,
            "auditor_fn_violation": 0.0030641030180706547,
            "auditor_fp_violation": 0.006285902743252638,
            "ave_precision_score": 0.508695436525712,
            "fpr": 0.34357848518111966,
            "logloss": 0.6905745221372951,
            "mae": 0.4965553923001928,
            "precision": 0.533532041728763,
            "recall": 0.7698924731182796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7909059596091008,
            "auditor_fn_violation": 0.006130484698453703,
            "auditor_fp_violation": 0.006462299365434872,
            "ave_precision_score": 0.7912019636303498,
            "fpr": 0.3157894736842105,
            "logloss": 1.5106921831177924,
            "mae": 0.36163024072000755,
            "precision": 0.6123822341857336,
            "recall": 0.9304703476482618
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.7333417725090715,
            "auditor_fn_violation": 0.002398404211371174,
            "auditor_fp_violation": 0.011272292311705958,
            "ave_precision_score": 0.7337418916619549,
            "fpr": 0.34906695938529086,
            "logloss": 1.7410116705775238,
            "mae": 0.38077322301876376,
            "precision": 0.57543391188251,
            "recall": 0.9268817204301075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7558673397969108,
            "auditor_fn_violation": 0.004964481756538587,
            "auditor_fp_violation": 0.019687590726224554,
            "ave_precision_score": 0.7564026115440363,
            "fpr": 0.3344298245614035,
            "logloss": 1.609499909565043,
            "mae": 0.38383722348544397,
            "precision": 0.5917001338688086,
            "recall": 0.9038854805725971
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7174827155252868,
            "auditor_fn_violation": 0.006397318319700671,
            "auditor_fp_violation": 0.009421470517294861,
            "ave_precision_score": 0.7179750316461352,
            "fpr": 0.34906695938529086,
            "logloss": 1.8338436120691568,
            "mae": 0.40211441689041866,
            "precision": 0.5661664392905866,
            "recall": 0.8924731182795699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8458437508357952,
            "auditor_fn_violation": 0.010769831019265957,
            "auditor_fp_violation": 0.023905064078636306,
            "ave_precision_score": 0.8460868080899117,
            "fpr": 0.13596491228070176,
            "logloss": 0.7733140059431501,
            "mae": 0.27148369379322407,
            "precision": 0.75,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8123779179414914,
            "auditor_fn_violation": 0.010729081831379913,
            "auditor_fp_violation": 0.017437596294418496,
            "ave_precision_score": 0.8127964518462225,
            "fpr": 0.16136114160263446,
            "logloss": 0.7772567464539337,
            "mae": 0.2806244031946974,
            "precision": 0.7178502879078695,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 24284,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.5178912683187916,
            "auditor_fn_violation": 0.032013507695619434,
            "auditor_fp_violation": 0.013087905935050395,
            "ave_precision_score": 0.5192385409153681,
            "fpr": 0.1118421052631579,
            "logloss": 0.909639763052283,
            "mae": 0.5281100811502129,
            "precision": 0.5342465753424658,
            "recall": 0.2392638036809816
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.4935518384641199,
            "auditor_fn_violation": 0.04059110277020408,
            "auditor_fp_violation": 0.02158471693748062,
            "ave_precision_score": 0.4947832601002857,
            "fpr": 0.11855104281009879,
            "logloss": 0.8948712846653875,
            "mae": 0.5186695497315357,
            "precision": 0.49056603773584906,
            "recall": 0.22365591397849463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8282944480192226,
            "auditor_fn_violation": 0.007691134789940093,
            "auditor_fp_violation": 0.018502965451453697,
            "ave_precision_score": 0.8285569237725596,
            "fpr": 0.14035087719298245,
            "logloss": 0.8792827228963015,
            "mae": 0.2761836883722959,
            "precision": 0.7434869739478958,
            "recall": 0.7586912065439673
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7935373701624011,
            "auditor_fn_violation": 0.012393328848128608,
            "auditor_fp_violation": 0.01058807893558058,
            "ave_precision_score": 0.794011735383486,
            "fpr": 0.1734357848518112,
            "logloss": 0.8859598209326759,
            "mae": 0.2900052527530612,
            "precision": 0.7035647279549718,
            "recall": 0.8064516129032258
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8275579247249065,
            "auditor_fn_violation": 0.00526270943206688,
            "auditor_fp_violation": 0.01827485380116959,
            "ave_precision_score": 0.8278719769771887,
            "fpr": 0.15460526315789475,
            "logloss": 0.953291143205576,
            "mae": 0.2776707018642493,
            "precision": 0.7334593572778828,
            "recall": 0.7934560327198364
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7933510997487827,
            "auditor_fn_violation": 0.008200842746361675,
            "auditor_fp_violation": 0.01789291814543719,
            "ave_precision_score": 0.793596738124541,
            "fpr": 0.18221734357848518,
            "logloss": 0.9926604887240962,
            "mae": 0.2848270650507274,
            "precision": 0.696526508226691,
            "recall": 0.8193548387096774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8317969802333869,
            "auditor_fn_violation": 0.007379453234312777,
            "auditor_fp_violation": 0.020553378126166488,
            "ave_precision_score": 0.8320858973865983,
            "fpr": 0.13815789473684212,
            "logloss": 0.8773841453820014,
            "mae": 0.27756452299391543,
            "precision": 0.748,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7942276047816879,
            "auditor_fn_violation": 0.009289095050930686,
            "auditor_fp_violation": 0.012591495080062813,
            "ave_precision_score": 0.7945634616941595,
            "fpr": 0.17014270032930845,
            "logloss": 0.8838947740288565,
            "mae": 0.2894763268373238,
            "precision": 0.7080979284369114,
            "recall": 0.8086021505376344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5629573062089044,
            "auditor_fn_violation": 0.00026235066193090886,
            "auditor_fp_violation": 0.006356020073825234,
            "ave_precision_score": 0.5646514122666866,
            "fpr": 0.18859649122807018,
            "logloss": 0.6938338922648013,
            "mae": 0.49999363253121837,
            "precision": 0.5865384615384616,
            "recall": 0.49897750511247446
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5567776669396038,
            "auditor_fn_violation": 0.01340131959444308,
            "auditor_fp_violation": 0.010885884038138746,
            "ave_precision_score": 0.5582857154847571,
            "fpr": 0.20965971459934138,
            "logloss": 0.6923219483113585,
            "mae": 0.4992662394740317,
            "precision": 0.5547785547785548,
            "recall": 0.5118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7703950267546534,
            "auditor_fn_violation": 0.01738241308793456,
            "auditor_fp_violation": 0.011353738957322383,
            "ave_precision_score": 0.7709217174467454,
            "fpr": 0.11403508771929824,
            "logloss": 0.7933481071747013,
            "mae": 0.3356913423739203,
            "precision": 0.7570093457943925,
            "recall": 0.6625766871165644
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7204795521778679,
            "auditor_fn_violation": 0.017645739645668828,
            "auditor_fp_violation": 0.026881217604465598,
            "ave_precision_score": 0.7212165614692267,
            "fpr": 0.14709110867178923,
            "logloss": 0.8390368078788778,
            "mae": 0.3486800673974206,
            "precision": 0.70995670995671,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8399756229670521,
            "auditor_fn_violation": 0.008778656764610912,
            "auditor_fp_violation": 0.02061559039442578,
            "ave_precision_score": 0.8402393941455554,
            "fpr": 0.13596491228070176,
            "logloss": 0.8175756496790484,
            "mae": 0.27333785792466087,
            "precision": 0.751503006012024,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8061465295071782,
            "auditor_fn_violation": 0.009895778005972408,
            "auditor_fp_violation": 0.01678537850782416,
            "ave_precision_score": 0.8066291045634307,
            "fpr": 0.16465422612513722,
            "logloss": 0.8158010437319,
            "mae": 0.28347361410478994,
            "precision": 0.715370018975332,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7712210900022081,
            "auditor_fn_violation": 0.002775983927097908,
            "auditor_fp_violation": 0.016338496951598863,
            "ave_precision_score": 0.7716892195157965,
            "fpr": 0.33881578947368424,
            "logloss": 1.6752490609150341,
            "mae": 0.3791979024353643,
            "precision": 0.5923482849604221,
            "recall": 0.918200408997955
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7282463716303982,
            "auditor_fn_violation": 0.004279829562220416,
            "auditor_fp_violation": 0.010009697124827096,
            "ave_precision_score": 0.7286678146730523,
            "fpr": 0.3545554335894621,
            "logloss": 1.9123486238127447,
            "mae": 0.39513346025342494,
            "precision": 0.5676037483266398,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7669630655377575,
            "auditor_fn_violation": 0.002076382161948839,
            "auditor_fp_violation": 0.016385156152793335,
            "ave_precision_score": 0.7673118066421281,
            "fpr": 0.3223684210526316,
            "logloss": 1.474027421701284,
            "mae": 0.37449589054762394,
            "precision": 0.6005434782608695,
            "recall": 0.9038854805725971
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7311021820407833,
            "auditor_fn_violation": 0.007931730462802308,
            "auditor_fp_violation": 0.011661161784467864,
            "ave_precision_score": 0.7315248104446811,
            "fpr": 0.34357848518111966,
            "logloss": 1.6848637986531045,
            "mae": 0.39231275634506885,
            "precision": 0.5712328767123288,
            "recall": 0.896774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7716368113466896,
            "auditor_fn_violation": 0.002775983927097908,
            "auditor_fp_violation": 0.016278876861183702,
            "ave_precision_score": 0.7720581335790064,
            "fpr": 0.3366228070175439,
            "logloss": 1.666512470116609,
            "mae": 0.3781299668988332,
            "precision": 0.593915343915344,
            "recall": 0.918200408997955
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7290516236589999,
            "auditor_fn_violation": 0.00366134343684714,
            "auditor_fp_violation": 0.010189364666039893,
            "ave_precision_score": 0.729499605915521,
            "fpr": 0.3534577387486279,
            "logloss": 1.8998913720897799,
            "mae": 0.3940405893556116,
            "precision": 0.5677852348993289,
            "recall": 0.9096774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 24284,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7714723580116608,
            "auditor_fn_violation": 0.002775983927097908,
            "auditor_fp_violation": 0.016356642196507835,
            "ave_precision_score": 0.7719326267201463,
            "fpr": 0.33771929824561403,
            "logloss": 1.6771387884402909,
            "mae": 0.37906623989428884,
            "precision": 0.5931307793923382,
            "recall": 0.918200408997955
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7284307080401884,
            "auditor_fn_violation": 0.004279829562220416,
            "auditor_fp_violation": 0.010009697124827096,
            "ave_precision_score": 0.7288826298729284,
            "fpr": 0.3545554335894621,
            "logloss": 1.9131523446568797,
            "mae": 0.394739811554322,
            "precision": 0.5676037483266398,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 24284,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7708466027977479,
            "auditor_fn_violation": 0.002775983927097908,
            "auditor_fp_violation": 0.016356642196507835,
            "ave_precision_score": 0.7712628857546509,
            "fpr": 0.33771929824561403,
            "logloss": 1.674678250423572,
            "mae": 0.37924770709565236,
            "precision": 0.5931307793923382,
            "recall": 0.918200408997955
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7277930197182243,
            "auditor_fn_violation": 0.004279829562220416,
            "auditor_fp_violation": 0.002896831452156757,
            "ave_precision_score": 0.7282598580145445,
            "fpr": 0.3545554335894621,
            "logloss": 1.9124833208073688,
            "mae": 0.3952419652944973,
            "precision": 0.5676037483266398,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 24284,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8283198131404308,
            "auditor_fn_violation": 0.006704516916011918,
            "auditor_fp_violation": 0.02143471859317324,
            "ave_precision_score": 0.8286639151459301,
            "fpr": 0.13925438596491227,
            "logloss": 0.9331995428159783,
            "mae": 0.2755795470868497,
            "precision": 0.7449799196787149,
            "recall": 0.7586912065439673
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7946549860187313,
            "auditor_fn_violation": 0.011654450385373518,
            "auditor_fp_violation": 0.021545337750365493,
            "ave_precision_score": 0.7951513111990249,
            "fpr": 0.15916575192096596,
            "logloss": 0.936658946107559,
            "mae": 0.28324571891320455,
            "precision": 0.7173489278752436,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8462835948837568,
            "auditor_fn_violation": 0.010769831019265957,
            "auditor_fp_violation": 0.024791588901331353,
            "ave_precision_score": 0.8465233011205765,
            "fpr": 0.13486842105263158,
            "logloss": 0.7749266692530362,
            "mae": 0.27159664290403496,
            "precision": 0.7515151515151515,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8123977426524325,
            "auditor_fn_violation": 0.010729081831379913,
            "auditor_fp_violation": 0.017437596294418496,
            "ave_precision_score": 0.812835980765337,
            "fpr": 0.16136114160263446,
            "logloss": 0.7771490121200327,
            "mae": 0.2806304480971824,
            "precision": 0.7178502879078695,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8326861567046746,
            "auditor_fn_violation": 0.007727011803537476,
            "auditor_fp_violation": 0.024706047032474806,
            "ave_precision_score": 0.8329761049648485,
            "fpr": 0.14473684210526316,
            "logloss": 0.8776180271549072,
            "mae": 0.27604996873827686,
            "precision": 0.7406679764243614,
            "recall": 0.7709611451942741
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7947935478433621,
            "auditor_fn_violation": 0.01105484933253072,
            "auditor_fp_violation": 0.018778949855527607,
            "ave_precision_score": 0.7952792555223243,
            "fpr": 0.1756311745334797,
            "logloss": 0.88629579783197,
            "mae": 0.2878292715334891,
            "precision": 0.702048417132216,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8390994450028496,
            "auditor_fn_violation": 0.012767732213970512,
            "auditor_fp_violation": 0.02057929990460786,
            "ave_precision_score": 0.8393750103315515,
            "fpr": 0.1425438596491228,
            "logloss": 0.8223751774328268,
            "mae": 0.27399400450731365,
            "precision": 0.7455968688845401,
            "recall": 0.7791411042944786
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8036598486302436,
            "auditor_fn_violation": 0.011196487376509334,
            "auditor_fp_violation": 0.019473008028431778,
            "ave_precision_score": 0.8040730450676068,
            "fpr": 0.17233809001097694,
            "logloss": 0.8240497349561356,
            "mae": 0.2844261981484666,
            "precision": 0.7032136105860114,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8017349930269755,
            "auditor_fn_violation": 0.0008857137731855202,
            "auditor_fp_violation": 0.017440172535357318,
            "ave_precision_score": 0.8020756691821944,
            "fpr": 0.38596491228070173,
            "logloss": 1.9411047081128912,
            "mae": 0.3920331124611638,
            "precision": 0.5764139590854392,
            "recall": 0.9795501022494888
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.755159091976805,
            "auditor_fn_violation": 0.00022426023629947033,
            "auditor_fp_violation": 0.01106555157935154,
            "ave_precision_score": 0.7555271400846578,
            "fpr": 0.3995609220636663,
            "logloss": 2.1615201277910407,
            "mae": 0.4056144734170507,
            "precision": 0.5555555555555556,
            "recall": 0.978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7899872787295634,
            "auditor_fn_violation": 0.0030271230222796252,
            "auditor_fp_violation": 0.01715762515034632,
            "ave_precision_score": 0.7905131064522839,
            "fpr": 0.36403508771929827,
            "logloss": 1.6519415880950914,
            "mae": 0.37601868578654934,
            "precision": 0.5880893300248139,
            "recall": 0.9693251533742331
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7314709592600633,
            "auditor_fn_violation": 0.0021056855871487085,
            "auditor_fp_violation": 0.01718901517575424,
            "ave_precision_score": 0.7323485693353502,
            "fpr": 0.3721185510428101,
            "logloss": 1.8297303149162942,
            "mae": 0.3882936736992292,
            "precision": 0.5708860759493671,
            "recall": 0.9698924731182795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7860734953932484,
            "auditor_fn_violation": 0.003995802389409107,
            "auditor_fp_violation": 0.012722408859027,
            "ave_precision_score": 0.7866158360946326,
            "fpr": 0.3223684210526316,
            "logloss": 1.4375321057154036,
            "mae": 0.3518232474421995,
            "precision": 0.6095617529880478,
            "recall": 0.9386503067484663
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7312667454274877,
            "auditor_fn_violation": 0.0016996565277433528,
            "auditor_fp_violation": 0.011752226154671612,
            "ave_precision_score": 0.7322161864589494,
            "fpr": 0.33260153677277715,
            "logloss": 1.6058588978946169,
            "mae": 0.36842045062867934,
            "precision": 0.5877551020408164,
            "recall": 0.9290322580645162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7527194405938692,
            "auditor_fn_violation": 0.012509866178739287,
            "auditor_fp_violation": 0.014441022769690186,
            "ave_precision_score": 0.7244688519916582,
            "fpr": 0.13157894736842105,
            "logloss": 0.6318397496031171,
            "mae": 0.45526905498353015,
            "precision": 0.7291196388261851,
            "recall": 0.6605316973415133
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7136440078183922,
            "auditor_fn_violation": 0.01610424560036826,
            "auditor_fp_violation": 0.026142857846056917,
            "ave_precision_score": 0.6847046625931452,
            "fpr": 0.15587266739846323,
            "logloss": 0.6476492506427344,
            "mae": 0.46314607244945905,
            "precision": 0.6830357142857143,
            "recall": 0.6580645161290323
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8246347902470063,
            "auditor_fn_violation": 0.008278620887597317,
            "auditor_fp_violation": 0.02086962382315126,
            "ave_precision_score": 0.8249232203261372,
            "fpr": 0.14035087719298245,
            "logloss": 0.9830269925856336,
            "mae": 0.27565884338580005,
            "precision": 0.7450199203187251,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7899886255326319,
            "auditor_fn_violation": 0.01032777404010718,
            "auditor_fp_violation": 0.01905952656372291,
            "ave_precision_score": 0.7904699989919604,
            "fpr": 0.15806805708013172,
            "logloss": 0.9944318730073892,
            "mae": 0.28337404069021543,
            "precision": 0.71875,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7914491601870806,
            "auditor_fn_violation": 0.0015808309116349154,
            "auditor_fp_violation": 0.023765086475052884,
            "ave_precision_score": 0.7918146101990536,
            "fpr": 0.35855263157894735,
            "logloss": 1.714674137873108,
            "mae": 0.37574702030355267,
            "precision": 0.589711417816813,
            "recall": 0.9611451942740287
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7317498594311151,
            "auditor_fn_violation": 0.001914474227777581,
            "auditor_fp_violation": 0.00909659222359504,
            "ave_precision_score": 0.7326790233585828,
            "fpr": 0.3732162458836443,
            "logloss": 1.9074230201053082,
            "mae": 0.3894170919231576,
            "precision": 0.5690747782002535,
            "recall": 0.9655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.831302632111647,
            "auditor_fn_violation": 0.010321368349298608,
            "auditor_fp_violation": 0.01984052921902867,
            "ave_precision_score": 0.8316006219072057,
            "fpr": 0.13596491228070176,
            "logloss": 0.879791537642254,
            "mae": 0.2779429702953468,
            "precision": 0.7489878542510121,
            "recall": 0.7566462167689162
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7934129517511731,
            "auditor_fn_violation": 0.010896686850087935,
            "auditor_fp_violation": 0.013457837196595667,
            "ave_precision_score": 0.7939041937031419,
            "fpr": 0.1712403951701427,
            "logloss": 0.8850970263768472,
            "mae": 0.2902853210169362,
            "precision": 0.7056603773584905,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8290484247691982,
            "auditor_fn_violation": 0.005744806802281783,
            "auditor_fp_violation": 0.017722719920368304,
            "ave_precision_score": 0.8293599092118031,
            "fpr": 0.1513157894736842,
            "logloss": 0.9360322479757617,
            "mae": 0.27674422018462347,
            "precision": 0.7371428571428571,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7946095710262476,
            "auditor_fn_violation": 0.008989294524509285,
            "auditor_fp_violation": 0.019886489493140636,
            "ave_precision_score": 0.7949650691783069,
            "fpr": 0.1800219538968167,
            "logloss": 0.9715171925656877,
            "mae": 0.28503550382231874,
            "precision": 0.6979742173112339,
            "recall": 0.8150537634408602
        }
    }
]