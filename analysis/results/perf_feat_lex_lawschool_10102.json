[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7067097320411447,
            "auditor_fn_violation": 0.009600180709283937,
            "auditor_fp_violation": 0.02308531980174652,
            "ave_precision_score": 0.7062076776591454,
            "fpr": 0.18640350877192982,
            "logloss": 1.3948976322014885,
            "mae": 0.31896429719118086,
            "precision": 0.6705426356589147,
            "recall": 0.7424892703862661
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7579664743457988,
            "auditor_fn_violation": 0.014764895359090174,
            "auditor_fp_violation": 0.021056018767208248,
            "ave_precision_score": 0.7584636749835605,
            "fpr": 0.15587266739846323,
            "logloss": 1.2574439477452102,
            "mae": 0.29907288432293716,
            "precision": 0.7221135029354208,
            "recall": 0.7561475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7925556339897187,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.6090960406974403,
            "fpr": 0.4857456140350877,
            "logloss": 13.113651024909005,
            "mae": 0.4867670309909603,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.8094414321758059,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.6430588139349649,
            "fpr": 0.4544456641053787,
            "logloss": 11.924342964715837,
            "mae": 0.45436161062981767,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8609599434188979,
            "auditor_fn_violation": 0.007618966945260148,
            "auditor_fp_violation": 0.0073263315238769585,
            "ave_precision_score": 0.8612775059209954,
            "fpr": 0.07894736842105263,
            "logloss": 0.46727068318035686,
            "mae": 0.2939442753426224,
            "precision": 0.8248175182481752,
            "recall": 0.7274678111587983
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8863103320567705,
            "auditor_fn_violation": 0.014306022925626678,
            "auditor_fp_violation": 0.007907035886576723,
            "ave_precision_score": 0.8864547426763205,
            "fpr": 0.08781558726673985,
            "logloss": 0.46334407145557305,
            "mae": 0.29237753163939334,
            "precision": 0.8198198198198198,
            "recall": 0.7459016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.766401829045777,
            "auditor_fn_violation": 0.011882576613206837,
            "auditor_fp_violation": 0.030367398316418853,
            "ave_precision_score": 0.768068919186589,
            "fpr": 0.1337719298245614,
            "logloss": 0.6202167354120277,
            "mae": 0.3220411713320349,
            "precision": 0.7420718816067653,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8099389881932366,
            "auditor_fn_violation": 0.021645732486368797,
            "auditor_fp_violation": 0.021533503047854823,
            "ave_precision_score": 0.8115726977949655,
            "fpr": 0.12843029637760703,
            "logloss": 0.5656869609245775,
            "mae": 0.30289605608233994,
            "precision": 0.7650602409638554,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8456556590006095,
            "auditor_fn_violation": 0.008614279798207966,
            "auditor_fp_violation": 0.008656380300527107,
            "ave_precision_score": 0.8462340574661338,
            "fpr": 0.23574561403508773,
            "logloss": 0.6677340247463587,
            "mae": 0.33122621318575435,
            "precision": 0.6651090342679128,
            "recall": 0.9163090128755365
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8714086056288846,
            "auditor_fn_violation": 0.0050430980187507884,
            "auditor_fp_violation": 0.010011599753991803,
            "ave_precision_score": 0.8715699017154871,
            "fpr": 0.2217343578485181,
            "logloss": 0.602887212352076,
            "mae": 0.32088166266828705,
            "precision": 0.6906584992343032,
            "recall": 0.9241803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7802561430416526,
            "auditor_fn_violation": 0.013167306678713957,
            "auditor_fp_violation": 0.019790929116513267,
            "ave_precision_score": 0.7809809164539179,
            "fpr": 0.18421052631578946,
            "logloss": 0.9321366503975108,
            "mae": 0.3035008094242925,
            "precision": 0.6842105263157895,
            "recall": 0.7811158798283262
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8157633152470884,
            "auditor_fn_violation": 0.013847150492163179,
            "auditor_fp_violation": 0.027110208043015113,
            "ave_precision_score": 0.816064433879535,
            "fpr": 0.15697036223929747,
            "logloss": 0.8991296010841658,
            "mae": 0.28087904290478616,
            "precision": 0.731203007518797,
            "recall": 0.7971311475409836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.740340115395897,
            "auditor_fn_violation": 0.032908854754913036,
            "auditor_fp_violation": 0.018625599874124776,
            "ave_precision_score": 0.7412815011644364,
            "fpr": 0.16228070175438597,
            "logloss": 3.044368349641043,
            "mae": 0.34760043880199737,
            "precision": 0.6740088105726872,
            "recall": 0.6566523605150214
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7824235847551161,
            "auditor_fn_violation": 0.03231901531374278,
            "auditor_fp_violation": 0.027304834787843877,
            "ave_precision_score": 0.782654884330734,
            "fpr": 0.13391877058177826,
            "logloss": 3.01582652720313,
            "mae": 0.3306533759807362,
            "precision": 0.726457399103139,
            "recall": 0.6639344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7410969952842776,
            "auditor_fn_violation": 0.033911226564264735,
            "auditor_fp_violation": 0.020494060262764534,
            "ave_precision_score": 0.7421179346922263,
            "fpr": 0.1962719298245614,
            "logloss": 3.063807829293354,
            "mae": 0.3595194951360913,
            "precision": 0.6469428007889546,
            "recall": 0.703862660944206
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7835768515987537,
            "auditor_fn_violation": 0.03231001781504742,
            "auditor_fp_violation": 0.025270336548567158,
            "ave_precision_score": 0.7838200135746871,
            "fpr": 0.16794731064763996,
            "logloss": 3.005032100694307,
            "mae": 0.3377834693913629,
            "precision": 0.6927710843373494,
            "recall": 0.7069672131147541
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7612450979093954,
            "auditor_fn_violation": 0.01254611851517205,
            "auditor_fp_violation": 0.016144972858154357,
            "ave_precision_score": 0.7576600173484431,
            "fpr": 0.17653508771929824,
            "logloss": 1.4602786925245583,
            "mae": 0.2940878590119188,
            "precision": 0.6933333333333334,
            "recall": 0.7811158798283262
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7510079870035798,
            "auditor_fn_violation": 0.009505857371650685,
            "auditor_fp_violation": 0.020274916764628795,
            "ave_precision_score": 0.7444672290639209,
            "fpr": 0.16575192096597147,
            "logloss": 1.7795004184393648,
            "mae": 0.289886302973106,
            "precision": 0.7188081936685289,
            "recall": 0.7909836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7827047302529951,
            "auditor_fn_violation": 0.010993148106317302,
            "auditor_fp_violation": 0.01946640704901267,
            "ave_precision_score": 0.7558002965399786,
            "fpr": 0.1425438596491228,
            "logloss": 2.780222807468116,
            "mae": 0.2827565459513401,
            "precision": 0.7325102880658436,
            "recall": 0.7639484978540773
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8017259627454169,
            "auditor_fn_violation": 0.010590055964441883,
            "auditor_fp_violation": 0.022436571143860308,
            "ave_precision_score": 0.7772398725395782,
            "fpr": 0.13172338090010977,
            "logloss": 2.834709553900248,
            "mae": 0.27166426793763965,
            "precision": 0.7560975609756098,
            "recall": 0.7622950819672131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8018893975638207,
            "auditor_fn_violation": 0.009621357578495594,
            "auditor_fp_violation": 0.016540791440484627,
            "ave_precision_score": 0.8022393254703173,
            "fpr": 0.14912280701754385,
            "logloss": 0.9539818045683501,
            "mae": 0.2852883660022332,
            "precision": 0.7207392197125256,
            "recall": 0.7532188841201717
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8338950370548883,
            "auditor_fn_violation": 0.010036709794677084,
            "auditor_fp_violation": 0.02201617737503017,
            "ave_precision_score": 0.8341466696241351,
            "fpr": 0.12733260153677278,
            "logloss": 0.9317175407985276,
            "mae": 0.27008355588517774,
            "precision": 0.7627811860940695,
            "recall": 0.764344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7852678711248061,
            "auditor_fn_violation": 0.01112962126345908,
            "auditor_fp_violation": 0.01230233655888601,
            "ave_precision_score": 0.7863512736657436,
            "fpr": 0.15570175438596492,
            "logloss": 0.9872255713128808,
            "mae": 0.2874668806453847,
            "precision": 0.7171314741035857,
            "recall": 0.7725321888412017
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8223038295934609,
            "auditor_fn_violation": 0.006583919670331647,
            "auditor_fp_violation": 0.023209888076646614,
            "ave_precision_score": 0.8226492294960832,
            "fpr": 0.1394072447859495,
            "logloss": 0.9482039239947498,
            "mae": 0.2709750311878481,
            "precision": 0.7490118577075099,
            "recall": 0.7766393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7347540512112952,
            "auditor_fn_violation": 0.01380731872599955,
            "auditor_fp_violation": 0.00379592478955236,
            "ave_precision_score": 0.728065235014335,
            "fpr": 0.19188596491228072,
            "logloss": 1.5788925283203297,
            "mae": 0.31889287053695897,
            "precision": 0.6788990825688074,
            "recall": 0.7939914163090128
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7497717577131364,
            "auditor_fn_violation": 0.008844541217541526,
            "auditor_fp_violation": 0.008612882214489052,
            "ave_precision_score": 0.742147701522921,
            "fpr": 0.17672886937431395,
            "logloss": 1.7088263431058266,
            "mae": 0.3037558054447343,
            "precision": 0.7093862815884476,
            "recall": 0.805327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8620231138046367,
            "auditor_fn_violation": 0.013322603719599431,
            "auditor_fp_violation": 0.004061442844780112,
            "ave_precision_score": 0.8623802864187192,
            "fpr": 0.09758771929824561,
            "logloss": 0.46268712935326395,
            "mae": 0.29329839904420896,
            "precision": 0.802660753880266,
            "recall": 0.776824034334764
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8850317474808471,
            "auditor_fn_violation": 0.01497183782908351,
            "auditor_fp_violation": 0.004032666152852061,
            "ave_precision_score": 0.8851870634019335,
            "fpr": 0.10208562019758508,
            "logloss": 0.45878308002836726,
            "mae": 0.29187916624451793,
            "precision": 0.8037974683544303,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7609745398105134,
            "auditor_fn_violation": 0.026828740305699875,
            "auditor_fp_violation": 0.022979604279757693,
            "ave_precision_score": 0.7611425168352457,
            "fpr": 0.08662280701754387,
            "logloss": 1.5771004125845662,
            "mae": 0.317108241138089,
            "precision": 0.801007556675063,
            "recall": 0.6824034334763949
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8152831029901553,
            "auditor_fn_violation": 0.020289359558042865,
            "auditor_fp_violation": 0.012868720368078101,
            "ave_precision_score": 0.8131706790605898,
            "fpr": 0.09549945115257959,
            "logloss": 1.4688855779174526,
            "mae": 0.30129690567239376,
            "precision": 0.8013698630136986,
            "recall": 0.7192622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8600167120155284,
            "auditor_fn_violation": 0.013762612002108274,
            "auditor_fp_violation": 0.012813704665250576,
            "ave_precision_score": 0.8605250659225254,
            "fpr": 0.14035087719298245,
            "logloss": 0.48001678919844226,
            "mae": 0.2989489028430462,
            "precision": 0.7571157495256167,
            "recall": 0.8562231759656652
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.884730874397768,
            "auditor_fn_violation": 0.007989778841482071,
            "auditor_fp_violation": 0.018331244339605503,
            "ave_precision_score": 0.884872362133491,
            "fpr": 0.14270032930845225,
            "logloss": 0.4723214306696822,
            "mae": 0.2940225475999342,
            "precision": 0.7644927536231884,
            "recall": 0.8647540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8037794684681019,
            "auditor_fn_violation": 0.006329530908817107,
            "auditor_fp_violation": 0.02362618991424752,
            "ave_precision_score": 0.8052815604622028,
            "fpr": 0.27521929824561403,
            "logloss": 0.9838389398363276,
            "mae": 0.3257804617872576,
            "precision": 0.6372832369942196,
            "recall": 0.9463519313304721
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8462296377023366,
            "auditor_fn_violation": 0.009728545464360907,
            "auditor_fp_violation": 0.030782165962117847,
            "ave_precision_score": 0.8464340465192606,
            "fpr": 0.24698133918770582,
            "logloss": 0.9044891337892667,
            "mae": 0.2981609584173427,
            "precision": 0.668141592920354,
            "recall": 0.9282786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 10102,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.831776472969892,
            "auditor_fn_violation": 0.03046645583916875,
            "auditor_fp_violation": 0.011899142475021635,
            "ave_precision_score": 0.833107109487361,
            "fpr": 0.06140350877192982,
            "logloss": 0.5987802109231466,
            "mae": 0.30183936644619425,
            "precision": 0.8426966292134831,
            "recall": 0.6437768240343348
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.853414507346755,
            "auditor_fn_violation": 0.025487664429288667,
            "auditor_fp_violation": 0.014013125627671258,
            "ave_precision_score": 0.8546708180576579,
            "fpr": 0.06915477497255763,
            "logloss": 0.5864294841877198,
            "mae": 0.30566524692146246,
            "precision": 0.8359375,
            "recall": 0.6577868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 10102,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8038428272549555,
            "auditor_fn_violation": 0.011414332505082454,
            "auditor_fp_violation": 0.01647687042718905,
            "ave_precision_score": 0.8041695683568393,
            "fpr": 0.16228070175438597,
            "logloss": 1.177864284231756,
            "mae": 0.2834767335206821,
            "precision": 0.7137330754352031,
            "recall": 0.7918454935622318
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8352623054081284,
            "auditor_fn_violation": 0.010927462165517982,
            "auditor_fp_violation": 0.0240480805910425,
            "ave_precision_score": 0.8354860697215668,
            "fpr": 0.15148188803512624,
            "logloss": 1.21975071687094,
            "mae": 0.27002578280517137,
            "precision": 0.7351247600767754,
            "recall": 0.7848360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555343623545768,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121156892210746,
            "fpr": 0.4857456140350877,
            "logloss": 16.81399902346966,
            "mae": 0.4868421052631579,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360549757545,
            "mae": 0.454445664105379,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7790516146596164,
            "auditor_fn_violation": 0.011030795873804684,
            "auditor_fp_violation": 0.031832664621194245,
            "ave_precision_score": 0.78066415964615,
            "fpr": 0.1425438596491228,
            "logloss": 0.6085850453374391,
            "mae": 0.31770500387095746,
            "precision": 0.74,
            "recall": 0.7939914163090128
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8195368543261317,
            "auditor_fn_violation": 0.013770671753252601,
            "auditor_fp_violation": 0.022078457933375383,
            "ave_precision_score": 0.8210955176284629,
            "fpr": 0.13611416026344675,
            "logloss": 0.5639391763731337,
            "mae": 0.2999298255509319,
            "precision": 0.7610789980732178,
            "recall": 0.8094262295081968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8036401156982163,
            "auditor_fn_violation": 0.017487387997891724,
            "auditor_fp_violation": 0.012929254189284875,
            "ave_precision_score": 0.804066494763851,
            "fpr": 0.13925438596491227,
            "logloss": 1.0981331746667988,
            "mae": 0.2843778411724416,
            "precision": 0.7320675105485233,
            "recall": 0.7446351931330472
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8360905690560944,
            "auditor_fn_violation": 0.012540263806661747,
            "auditor_fp_violation": 0.0219798470493288,
            "ave_precision_score": 0.8363128246032561,
            "fpr": 0.12733260153677278,
            "logloss": 1.131217195658878,
            "mae": 0.270919364602528,
            "precision": 0.7608247422680412,
            "recall": 0.7561475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8611832308877043,
            "auditor_fn_violation": 0.013310838792259624,
            "auditor_fp_violation": 0.010517465187632758,
            "ave_precision_score": 0.8614743210122469,
            "fpr": 0.08771929824561403,
            "logloss": 0.4794140887836576,
            "mae": 0.2800353617331303,
            "precision": 0.815242494226328,
            "recall": 0.7575107296137339
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8846699613018427,
            "auditor_fn_violation": 0.005942847888287059,
            "auditor_fp_violation": 0.009212332588561658,
            "ave_precision_score": 0.8848237877185975,
            "fpr": 0.09659714599341383,
            "logloss": 0.46527025595039073,
            "mae": 0.2757537141907449,
            "precision": 0.8115631691648822,
            "recall": 0.7766393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7446088377733406,
            "auditor_fn_violation": 0.03813248249378812,
            "auditor_fp_violation": 0.013280819762410512,
            "ave_precision_score": 0.7456477505883472,
            "fpr": 0.11293859649122807,
            "logloss": 2.9499271891642938,
            "mae": 0.3819642153286611,
            "precision": 0.7365728900255755,
            "recall": 0.6180257510729614
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7857079265005706,
            "auditor_fn_violation": 0.03722265210271545,
            "auditor_fp_violation": 0.016953286986217835,
            "ave_precision_score": 0.7859350547598523,
            "fpr": 0.09989023051591657,
            "logloss": 2.9509557069688817,
            "mae": 0.37689695732815315,
            "precision": 0.7707808564231738,
            "recall": 0.6270491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6775165392653592,
            "auditor_fn_violation": 0.0422925608011445,
            "auditor_fp_violation": 0.03873121705609315,
            "ave_precision_score": 0.678717000447272,
            "fpr": 0.1118421052631579,
            "logloss": 3.010429339634047,
            "mae": 0.37811832581542154,
            "precision": 0.7205479452054795,
            "recall": 0.5643776824034334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7223760452429034,
            "auditor_fn_violation": 0.04720537690522035,
            "auditor_fp_violation": 0.029591050283765793,
            "ave_precision_score": 0.723791883395291,
            "fpr": 0.0889132821075741,
            "logloss": 2.968715964230795,
            "mae": 0.3676126372346998,
            "precision": 0.7743732590529248,
            "recall": 0.569672131147541
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.776099989261197,
            "auditor_fn_violation": 0.011070796626760032,
            "auditor_fp_violation": 0.01185488946581701,
            "ave_precision_score": 0.7410779318352786,
            "fpr": 0.13486842105263158,
            "logloss": 3.5764149239880894,
            "mae": 0.2891872043382755,
            "precision": 0.7382978723404255,
            "recall": 0.7446351931330472
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7970112424840885,
            "auditor_fn_violation": 0.013127350596534167,
            "auditor_fp_violation": 0.02176705514164935,
            "ave_precision_score": 0.7623615997059543,
            "fpr": 0.12733260153677278,
            "logloss": 3.742471423860672,
            "mae": 0.274756315646443,
            "precision": 0.7583333333333333,
            "recall": 0.7459016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7867493310655559,
            "auditor_fn_violation": 0.00645423913861908,
            "auditor_fp_violation": 0.02808345134135789,
            "ave_precision_score": 0.7870695063969236,
            "fpr": 0.31469298245614036,
            "logloss": 1.364729965309814,
            "mae": 0.3507972885860606,
            "precision": 0.6089918256130791,
            "recall": 0.9592274678111588
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8281443433637234,
            "auditor_fn_violation": 0.008428406902880999,
            "auditor_fp_violation": 0.024185616824054828,
            "ave_precision_score": 0.8283977820590485,
            "fpr": 0.2854006586169045,
            "logloss": 1.2346079302844022,
            "mae": 0.3201990291815065,
            "precision": 0.6383866481223922,
            "recall": 0.9405737704918032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8582067248271794,
            "auditor_fn_violation": 0.008468394699194338,
            "auditor_fp_violation": 0.01383152387695697,
            "ave_precision_score": 0.8586855274076552,
            "fpr": 0.19736842105263158,
            "logloss": 0.5211948113797589,
            "mae": 0.3147310897761041,
            "precision": 0.7024793388429752,
            "recall": 0.9120171673819742
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8864256560791295,
            "auditor_fn_violation": 0.009787029205880766,
            "auditor_fp_violation": 0.018806133596987705,
            "ave_precision_score": 0.8865712792815313,
            "fpr": 0.18221734357848518,
            "logloss": 0.4979038251840749,
            "mae": 0.30485183610614086,
            "precision": 0.7265238879736409,
            "recall": 0.9036885245901639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6862954137385278,
            "auditor_fn_violation": 0.008894285068895415,
            "auditor_fp_violation": 0.02423098104004405,
            "ave_precision_score": 0.6761632002633188,
            "fpr": 0.22587719298245615,
            "logloss": 1.7549869295557718,
            "mae": 0.3446968777829389,
            "precision": 0.6411149825783972,
            "recall": 0.7896995708154506
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7225492648119017,
            "auditor_fn_violation": 0.011665257058537729,
            "auditor_fp_violation": 0.016045028843683598,
            "ave_precision_score": 0.7136909042514904,
            "fpr": 0.2074643249176729,
            "logloss": 1.62234207516445,
            "mae": 0.32438457510229063,
            "precision": 0.6785714285714286,
            "recall": 0.8176229508196722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7791821708261959,
            "auditor_fn_violation": 0.012588472253595363,
            "auditor_fp_violation": 0.010738730233655895,
            "ave_precision_score": 0.7496141695559806,
            "fpr": 0.12390350877192982,
            "logloss": 3.226797460069519,
            "mae": 0.284896558800142,
            "precision": 0.7538126361655774,
            "recall": 0.7424892703862661
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8019108757927175,
            "auditor_fn_violation": 0.009604829857299671,
            "auditor_fp_violation": 0.023658827101384967,
            "ave_precision_score": 0.7740732194459026,
            "fpr": 0.11855104281009879,
            "logloss": 3.368880490276371,
            "mae": 0.271963113238694,
            "precision": 0.7721518987341772,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 10102,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8540579097343199,
            "auditor_fn_violation": 0.017167381974248927,
            "auditor_fp_violation": 0.009268546927857765,
            "ave_precision_score": 0.8548680534346698,
            "fpr": 0.1337719298245614,
            "logloss": 0.7352852627485366,
            "mae": 0.24265221300314752,
            "precision": 0.7555110220440882,
            "recall": 0.8090128755364807
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8813359087342256,
            "auditor_fn_violation": 0.008091000701804902,
            "auditor_fp_violation": 0.020736830905689074,
            "ave_precision_score": 0.8814854704872424,
            "fpr": 0.13062568605927552,
            "logloss": 0.7399892206021962,
            "mae": 0.2381193048632647,
            "precision": 0.7720306513409961,
            "recall": 0.8258196721311475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7167693169151871,
            "auditor_fn_violation": 0.012033167683156395,
            "auditor_fp_violation": 0.04154374164109827,
            "ave_precision_score": 0.7185942230569365,
            "fpr": 0.16337719298245615,
            "logloss": 0.7475401538175246,
            "mae": 0.33178693881634164,
            "precision": 0.708984375,
            "recall": 0.778969957081545
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7700529291801526,
            "auditor_fn_violation": 0.01267747566176603,
            "auditor_fp_violation": 0.02586200185284662,
            "ave_precision_score": 0.7715167187219127,
            "fpr": 0.150384193194292,
            "logloss": 0.6514344992593052,
            "mae": 0.30770220457814923,
            "precision": 0.740530303030303,
            "recall": 0.8012295081967213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 10102,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.736434826374901,
            "auditor_fn_violation": 0.010376665913711319,
            "auditor_fp_violation": 0.008176972700810322,
            "ave_precision_score": 0.7297016263976448,
            "fpr": 0.17763157894736842,
            "logloss": 1.5702932928091051,
            "mae": 0.3160405281836884,
            "precision": 0.6896551724137931,
            "recall": 0.7725321888412017
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7507619417578861,
            "auditor_fn_violation": 0.011273865865289447,
            "auditor_fp_violation": 0.006212485694934265,
            "ave_precision_score": 0.7432882556446823,
            "fpr": 0.17014270032930845,
            "logloss": 1.7011263745386287,
            "mae": 0.3042760151975563,
            "precision": 0.710820895522388,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8008840818152901,
            "auditor_fn_violation": 0.010299017393268581,
            "auditor_fp_violation": 0.011274683345134148,
            "ave_precision_score": 0.8013466530707222,
            "fpr": 0.13815789473684212,
            "logloss": 0.9085698929300249,
            "mae": 0.28407352826990967,
            "precision": 0.7313432835820896,
            "recall": 0.7360515021459227
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8310277121182055,
            "auditor_fn_violation": 0.008950261827212036,
            "auditor_fp_violation": 0.02194351672362743,
            "ave_precision_score": 0.8312777329373149,
            "fpr": 0.12733260153677278,
            "logloss": 0.933320430735453,
            "mae": 0.2755563421444574,
            "precision": 0.7598343685300207,
            "recall": 0.7520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7598308365516337,
            "auditor_fn_violation": 0.010028424064452984,
            "auditor_fp_violation": 0.012026984501612778,
            "ave_precision_score": 0.7615351410522926,
            "fpr": 0.08223684210526316,
            "logloss": 2.91950100523852,
            "mae": 0.353102609653739,
            "precision": 0.7794117647058824,
            "recall": 0.5686695278969958
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7877776239094038,
            "auditor_fn_violation": 0.012690971909809074,
            "auditor_fp_violation": 0.012188824272809607,
            "ave_precision_score": 0.7880324589519292,
            "fpr": 0.07683863885839737,
            "logloss": 2.927068330840526,
            "mae": 0.3520332633927219,
            "precision": 0.8005698005698005,
            "recall": 0.5758196721311475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8594333005139847,
            "auditor_fn_violation": 0.015454408553572772,
            "auditor_fp_violation": 0.008098300684446547,
            "ave_precision_score": 0.859751960897047,
            "fpr": 0.08223684210526316,
            "logloss": 0.4779837277782959,
            "mae": 0.282080801026671,
            "precision": 0.8243559718969555,
            "recall": 0.7553648068669528
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8837768217695043,
            "auditor_fn_violation": 0.012659480664375307,
            "auditor_fp_violation": 0.016203325262810986,
            "ave_precision_score": 0.8839455968578271,
            "fpr": 0.09659714599341383,
            "logloss": 0.4662431676716618,
            "mae": 0.27720922260963315,
            "precision": 0.8095238095238095,
            "recall": 0.7663934426229508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555343623545768,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121156892210746,
            "fpr": 0.4857456140350877,
            "logloss": 16.813970858842115,
            "mae": 0.4868421052631579,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360549757545,
            "mae": 0.45444566410537907,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7772227146267905,
            "auditor_fn_violation": 0.023435735260899027,
            "auditor_fp_violation": 0.024093305011407447,
            "ave_precision_score": 0.7775659121157945,
            "fpr": 0.13267543859649122,
            "logloss": 1.674412572127722,
            "mae": 0.2944163310527256,
            "precision": 0.7311111111111112,
            "recall": 0.7060085836909872
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8123382912589083,
            "auditor_fn_violation": 0.02069199762466035,
            "auditor_fp_violation": 0.026118909156020588,
            "ave_precision_score": 0.8126324646404031,
            "fpr": 0.11964873765093303,
            "logloss": 1.63789084545922,
            "mae": 0.2854827069097145,
            "precision": 0.7620087336244541,
            "recall": 0.7151639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8553903890599359,
            "auditor_fn_violation": 0.030122919960846317,
            "auditor_fp_violation": 0.01293417119030761,
            "ave_precision_score": 0.8557520406650138,
            "fpr": 0.0581140350877193,
            "logloss": 0.5344765366896488,
            "mae": 0.2970220512775146,
            "precision": 0.8539944903581267,
            "recall": 0.6652360515021459
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8644147319907469,
            "auditor_fn_violation": 0.029880693167299497,
            "auditor_fp_violation": 0.014573650652778101,
            "ave_precision_score": 0.8647056009881477,
            "fpr": 0.07135016465422613,
            "logloss": 0.5505678617777643,
            "mae": 0.3051345932424989,
            "precision": 0.8337595907928389,
            "recall": 0.6680327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7848939348078265,
            "auditor_fn_violation": 0.01916741962201642,
            "auditor_fp_violation": 0.012344131067579272,
            "ave_precision_score": 0.7856823720521126,
            "fpr": 0.13706140350877194,
            "logloss": 1.4417380520320178,
            "mae": 0.2963763421974727,
            "precision": 0.7276688453159041,
            "recall": 0.7167381974248928
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8205453939260943,
            "auditor_fn_violation": 0.010014216047938677,
            "auditor_fp_violation": 0.01786933019854523,
            "ave_precision_score": 0.8207980633438892,
            "fpr": 0.11964873765093303,
            "logloss": 1.4529454658615544,
            "mae": 0.28269813172664493,
            "precision": 0.7665952890792291,
            "recall": 0.7336065573770492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7579059051705983,
            "auditor_fn_violation": 0.0147885136661396,
            "auditor_fp_violation": 0.001981551412162694,
            "ave_precision_score": 0.7590529813740273,
            "fpr": 0.03070175438596491,
            "logloss": 3.2674500694400397,
            "mae": 0.36266701564429027,
            "precision": 0.8647342995169082,
            "recall": 0.38412017167381973
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7949007626395072,
            "auditor_fn_violation": 0.015529682748196015,
            "auditor_fp_violation": 0.0065394586262465864,
            "ave_precision_score": 0.7951345909654606,
            "fpr": 0.029637760702524697,
            "logloss": 3.319234304079449,
            "mae": 0.369463783119732,
            "precision": 0.875,
            "recall": 0.38729508196721313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8079472530054025,
            "auditor_fn_violation": 0.010776673443264821,
            "auditor_fp_violation": 0.02195932656753993,
            "ave_precision_score": 0.8087261137445445,
            "fpr": 0.16228070175438597,
            "logloss": 0.9863760056009315,
            "mae": 0.2788158001384795,
            "precision": 0.7148362235067437,
            "recall": 0.796137339055794
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.842010427444211,
            "auditor_fn_violation": 0.01549369275341455,
            "auditor_fp_violation": 0.030133410146021965,
            "ave_precision_score": 0.8422261608076191,
            "fpr": 0.150384193194292,
            "logloss": 0.9547740941691013,
            "mae": 0.2694579058637263,
            "precision": 0.7370441458733206,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7428598707494358,
            "auditor_fn_violation": 0.033078269708606285,
            "auditor_fp_violation": 0.019574581071512862,
            "ave_precision_score": 0.7438076131261611,
            "fpr": 0.12938596491228072,
            "logloss": 3.0016006837975326,
            "mae": 0.3427620939130934,
            "precision": 0.7100737100737101,
            "recall": 0.6201716738197425
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7839111054983935,
            "auditor_fn_violation": 0.03201310035810045,
            "auditor_fp_violation": 0.019486029692256192,
            "ave_precision_score": 0.7841359658011544,
            "fpr": 0.10208562019758508,
            "logloss": 2.9975678656523512,
            "mae": 0.3321829376364824,
            "precision": 0.7609254498714653,
            "recall": 0.6065573770491803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7377405561550796,
            "auditor_fn_violation": 0.03332768616821022,
            "auditor_fp_violation": 0.01997777515537724,
            "ave_precision_score": 0.7385601253500101,
            "fpr": 0.11732456140350878,
            "logloss": 3.1429875301443904,
            "mae": 0.34487866041906545,
            "precision": 0.7154255319148937,
            "recall": 0.5772532188841202
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7768591383096235,
            "auditor_fn_violation": 0.031621709164852164,
            "auditor_fp_violation": 0.019646921134647975,
            "ave_precision_score": 0.7771684526294804,
            "fpr": 0.09440175631174534,
            "logloss": 3.134510131883737,
            "mae": 0.33489039956392636,
            "precision": 0.7643835616438356,
            "recall": 0.5717213114754098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8540970333432842,
            "auditor_fn_violation": 0.014332034485355024,
            "auditor_fp_violation": 0.01136810636456613,
            "ave_precision_score": 0.854385292970334,
            "fpr": 0.08223684210526316,
            "logloss": 0.7559461399413803,
            "mae": 0.2937066952414713,
            "precision": 0.8161764705882353,
            "recall": 0.7145922746781116
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8843941936149864,
            "auditor_fn_violation": 0.0150865559374494,
            "auditor_fp_violation": 0.01122347561845892,
            "ave_precision_score": 0.8845216083653875,
            "fpr": 0.0845225027442371,
            "logloss": 0.8155214466263013,
            "mae": 0.2889357568803918,
            "precision": 0.8257918552036199,
            "recall": 0.7479508196721312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7999718044204194,
            "auditor_fn_violation": 0.012009637828476772,
            "auditor_fp_violation": 0.011938478483203526,
            "ave_precision_score": 0.800399521615177,
            "fpr": 0.13157894736842105,
            "logloss": 0.9016457412685385,
            "mae": 0.28356512159546154,
            "precision": 0.7435897435897436,
            "recall": 0.7467811158798283
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8303314979604013,
            "auditor_fn_violation": 0.011912688272660201,
            "auditor_fp_violation": 0.021754080025327426,
            "ave_precision_score": 0.8305983894289907,
            "fpr": 0.12403951701427003,
            "logloss": 0.905330976256917,
            "mae": 0.27434028118426956,
            "precision": 0.7650727650727651,
            "recall": 0.7540983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7783134365487179,
            "auditor_fn_violation": 0.012840241698667274,
            "auditor_fp_violation": 0.017175084572417596,
            "ave_precision_score": 0.7498974087424067,
            "fpr": 0.15350877192982457,
            "logloss": 2.8540804605961103,
            "mae": 0.2863838202842347,
            "precision": 0.7183098591549296,
            "recall": 0.7660944206008584
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7990957105566946,
            "auditor_fn_violation": 0.010441597235968407,
            "auditor_fp_violation": 0.020827656719942505,
            "ave_precision_score": 0.7744893882344056,
            "fpr": 0.13611416026344675,
            "logloss": 2.8580070223228513,
            "mae": 0.2735386712627451,
            "precision": 0.751004016064257,
            "recall": 0.7663934426229508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7692439112759695,
            "auditor_fn_violation": 0.015390877945937808,
            "auditor_fp_violation": 0.02329183384470145,
            "ave_precision_score": 0.7698707611934819,
            "fpr": 0.17105263157894737,
            "logloss": 1.1257232185804968,
            "mae": 0.3090547248966165,
            "precision": 0.691089108910891,
            "recall": 0.7489270386266095
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8040382455397197,
            "auditor_fn_violation": 0.012956398121322276,
            "auditor_fp_violation": 0.02076797118486167,
            "ave_precision_score": 0.8043631911489486,
            "fpr": 0.145993413830955,
            "logloss": 1.132299539086225,
            "mae": 0.2899394080451014,
            "precision": 0.7345309381237525,
            "recall": 0.7540983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7433996165923233,
            "auditor_fn_violation": 0.03531595888863791,
            "auditor_fp_violation": 0.01872148139406814,
            "ave_precision_score": 0.7443347652562962,
            "fpr": 0.12828947368421054,
            "logloss": 2.9711850597834153,
            "mae": 0.34345873952123934,
            "precision": 0.7103960396039604,
            "recall": 0.6158798283261803
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7846203118681958,
            "auditor_fn_violation": 0.033522430764247546,
            "auditor_fp_violation": 0.02064860011470003,
            "ave_precision_score": 0.7848598865224398,
            "fpr": 0.09989023051591657,
            "logloss": 2.968221157079378,
            "mae": 0.3325569391868657,
            "precision": 0.7642487046632125,
            "recall": 0.6045081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8543931629935099,
            "auditor_fn_violation": 0.01787798358557338,
            "auditor_fp_violation": 0.015545098733380539,
            "ave_precision_score": 0.8552235395808022,
            "fpr": 0.10855263157894737,
            "logloss": 0.48384181158972445,
            "mae": 0.28451772232687,
            "precision": 0.7898089171974523,
            "recall": 0.7982832618025751
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8787904154339136,
            "auditor_fn_violation": 0.01202965575569992,
            "auditor_fp_violation": 0.019052660807104136,
            "ave_precision_score": 0.8789461398679516,
            "fpr": 0.1163556531284303,
            "logloss": 0.4830377390032722,
            "mae": 0.28043907470390317,
            "precision": 0.7854251012145749,
            "recall": 0.7950819672131147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 10102,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8610268776387813,
            "auditor_fn_violation": 0.006235411490098639,
            "auditor_fp_violation": 0.0109698292817245,
            "ave_precision_score": 0.8617812521522499,
            "fpr": 0.20394736842105263,
            "logloss": 0.5207857591295297,
            "mae": 0.31114509718884764,
            "precision": 0.6950819672131148,
            "recall": 0.9098712446351931
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.885627061139626,
            "auditor_fn_violation": 0.008079753828435695,
            "auditor_fp_violation": 0.019595020669360308,
            "ave_precision_score": 0.8857742344747666,
            "fpr": 0.19758507135016465,
            "logloss": 0.5083262852826352,
            "mae": 0.30539801212704437,
            "precision": 0.7096774193548387,
            "recall": 0.9016393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7854070968231665,
            "auditor_fn_violation": 0.015590881710714556,
            "auditor_fp_violation": 0.014603493037526552,
            "ave_precision_score": 0.7861466292898981,
            "fpr": 0.14144736842105263,
            "logloss": 1.4073213076188769,
            "mae": 0.29684460725026446,
            "precision": 0.7237687366167024,
            "recall": 0.7253218884120172
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8200643397253101,
            "auditor_fn_violation": 0.011462813337892069,
            "auditor_fp_violation": 0.02046694848619318,
            "ave_precision_score": 0.820323158837877,
            "fpr": 0.12623490669593854,
            "logloss": 1.4197978666205884,
            "mae": 0.28263332689594967,
            "precision": 0.7578947368421053,
            "recall": 0.7377049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8454632033872913,
            "auditor_fn_violation": 0.03206648595738273,
            "auditor_fp_violation": 0.010689560223428528,
            "ave_precision_score": 0.8459881157869165,
            "fpr": 0.049342105263157895,
            "logloss": 0.5832619010064554,
            "mae": 0.30427782599012065,
            "precision": 0.8664688427299704,
            "recall": 0.6266094420600858
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8472817479670897,
            "auditor_fn_violation": 0.033560670133702834,
            "auditor_fp_violation": 0.01641871219375482,
            "ave_precision_score": 0.8485483498920479,
            "fpr": 0.06695938529088913,
            "logloss": 0.6153657043556144,
            "mae": 0.31324190610510455,
            "precision": 0.8364611260053619,
            "recall": 0.639344262295082
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7555343623545768,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121156892210746,
            "fpr": 0.4857456140350877,
            "logloss": 16.809676436751364,
            "mae": 0.48684210526315774,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360549757562,
            "mae": 0.45444566410539566,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8071435988226793,
            "auditor_fn_violation": 0.010743731646713356,
            "auditor_fp_violation": 0.024329321060498784,
            "ave_precision_score": 0.8076435047063321,
            "fpr": 0.17982456140350878,
            "logloss": 1.1333619397647228,
            "mae": 0.28535425086693456,
            "precision": 0.6974169741697417,
            "recall": 0.8111587982832618
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8380556085685105,
            "auditor_fn_violation": 0.007220492703028559,
            "auditor_fp_violation": 0.024603415569620587,
            "ave_precision_score": 0.8382802537121022,
            "fpr": 0.16355653128430298,
            "logloss": 1.1592236918732468,
            "mae": 0.27010764535490445,
            "precision": 0.7255985267034991,
            "recall": 0.8073770491803278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.831668082602794,
            "auditor_fn_violation": 0.010131955425043294,
            "auditor_fp_violation": 0.01947624105105815,
            "ave_precision_score": 0.8320898316731162,
            "fpr": 0.18640350877192982,
            "logloss": 0.64673417142605,
            "mae": 0.2822470283834806,
            "precision": 0.7017543859649122,
            "recall": 0.8583690987124464
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8589762751381945,
            "auditor_fn_violation": 0.016476669485882927,
            "auditor_fp_violation": 0.024341318219917845,
            "ave_precision_score": 0.8592173906786761,
            "fpr": 0.16355653128430298,
            "logloss": 0.6263289031268165,
            "mae": 0.2717313658754427,
            "precision": 0.7367491166077739,
            "recall": 0.8545081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8167986482591894,
            "auditor_fn_violation": 0.012762593178224538,
            "auditor_fp_violation": 0.021339784438675166,
            "ave_precision_score": 0.8172810024901824,
            "fpr": 0.16337719298245615,
            "logloss": 0.8394661969993163,
            "mae": 0.2805975471481971,
            "precision": 0.7084148727984344,
            "recall": 0.776824034334764
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8463616682365365,
            "auditor_fn_violation": 0.011075920893991472,
            "auditor_fp_violation": 0.02957288512091511,
            "ave_precision_score": 0.8465912613830215,
            "fpr": 0.14050493962678376,
            "logloss": 0.8247035922444518,
            "mae": 0.2644607343321908,
            "precision": 0.751937984496124,
            "recall": 0.7950819672131147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7794866376028832,
            "auditor_fn_violation": 0.006075408478277238,
            "auditor_fp_violation": 0.02617565494453624,
            "ave_precision_score": 0.7292630841544646,
            "fpr": 0.2598684210526316,
            "logloss": 3.058731044986147,
            "mae": 0.32345617966699103,
            "precision": 0.6478454680534919,
            "recall": 0.9356223175965666
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8053904567224508,
            "auditor_fn_violation": 0.009699303593600979,
            "auditor_fp_violation": 0.028547850931483605,
            "ave_precision_score": 0.7563992401483327,
            "fpr": 0.2349066959385291,
            "logloss": 2.9131582493664876,
            "mae": 0.2962785744455908,
            "precision": 0.6796407185628742,
            "recall": 0.930327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7942639003107217,
            "auditor_fn_violation": 0.005280099390106167,
            "auditor_fp_violation": 0.023704861930611304,
            "ave_precision_score": 0.7950190750286174,
            "fpr": 0.27631578947368424,
            "logloss": 1.1840724370592772,
            "mae": 0.32910873201701196,
            "precision": 0.6326530612244898,
            "recall": 0.9313304721030042
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8325191303794128,
            "auditor_fn_violation": 0.00923143366144212,
            "auditor_fp_violation": 0.025737440736156195,
            "ave_precision_score": 0.8327611259834008,
            "fpr": 0.24588364434687157,
            "logloss": 1.0852310663330205,
            "mae": 0.3004865583068442,
            "precision": 0.6681481481481482,
            "recall": 0.9241803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.6651565688429151,
            "auditor_fn_violation": 0.012230818462465178,
            "auditor_fp_violation": 0.005170226575407135,
            "ave_precision_score": 0.6540878170344597,
            "fpr": 0.23574561403508773,
            "logloss": 1.7795208113465142,
            "mae": 0.34601760603606213,
            "precision": 0.639261744966443,
            "recall": 0.8175965665236051
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6991846348539192,
            "auditor_fn_violation": 0.007971783844091345,
            "auditor_fp_violation": 0.018053576850316482,
            "ave_precision_score": 0.6860173234428615,
            "fpr": 0.2074643249176729,
            "logloss": 1.8096468842368818,
            "mae": 0.3226397518056102,
            "precision": 0.6812816188870152,
            "recall": 0.8278688524590164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7466973448479441,
            "auditor_fn_violation": 0.032162958361569155,
            "auditor_fp_violation": 0.018074895759578317,
            "ave_precision_score": 0.7475005199661153,
            "fpr": 0.11842105263157894,
            "logloss": 2.970004133882441,
            "mae": 0.34132984121586285,
            "precision": 0.7194805194805195,
            "recall": 0.5944206008583691
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.787420008270115,
            "auditor_fn_violation": 0.029871695668604127,
            "auditor_fp_violation": 0.019742936995430165,
            "ave_precision_score": 0.7876414181171243,
            "fpr": 0.09549945115257959,
            "logloss": 2.958780446701515,
            "mae": 0.33101444599730273,
            "precision": 0.7661290322580645,
            "recall": 0.5840163934426229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7552520667338156,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0011259932342065958,
            "ave_precision_score": 0.511552306954508,
            "fpr": 0.4868421052631579,
            "logloss": 16.84702790246381,
            "mae": 0.48793859649122784,
            "precision": 0.5115511551155115,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7702104097452935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0027429395904534455,
            "ave_precision_score": 0.540420819490587,
            "fpr": 0.45554335894621295,
            "logloss": 15.734274464128957,
            "mae": 0.4555433589462309,
            "precision": 0.540420819490587,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7372166343309126,
            "auditor_fn_violation": 0.032911207740381,
            "auditor_fp_violation": 0.01798147274014634,
            "ave_precision_score": 0.73814345220649,
            "fpr": 0.3618421052631579,
            "logloss": 3.1322696166327346,
            "mae": 0.44509374121915796,
            "precision": 0.5319148936170213,
            "recall": 0.8047210300429185
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7303377999755436,
            "auditor_fn_violation": 0.03302082021198107,
            "auditor_fp_violation": 0.014677451583353459,
            "ave_precision_score": 0.7315330124276829,
            "fpr": 0.33479692645444564,
            "logloss": 3.129054260480934,
            "mae": 0.42952904493046845,
            "precision": 0.5553935860058309,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7826530576714074,
            "auditor_fn_violation": 0.011659042993750472,
            "auditor_fp_violation": 0.016088427346392892,
            "ave_precision_score": 0.7613762690227126,
            "fpr": 0.14473684210526316,
            "logloss": 2.4710742341654393,
            "mae": 0.2820965582353354,
            "precision": 0.7311608961303462,
            "recall": 0.7703862660944206
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8041304420506546,
            "auditor_fn_violation": 0.010626045959223339,
            "auditor_fp_violation": 0.022971145936323323,
            "ave_precision_score": 0.7865539155692576,
            "fpr": 0.132821075740944,
            "logloss": 2.4697250910831237,
            "mae": 0.27047223409846627,
            "precision": 0.7555555555555555,
            "recall": 0.7663934426229508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7661927727466507,
            "auditor_fn_violation": 0.014367329267374445,
            "auditor_fp_violation": 0.012036818503658252,
            "ave_precision_score": 0.7625745850927498,
            "fpr": 0.13706140350877194,
            "logloss": 4.01560574810153,
            "mae": 0.3149554751020234,
            "precision": 0.7113163972286374,
            "recall": 0.6609442060085837
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8062845614071186,
            "auditor_fn_violation": 0.012110633243958181,
            "auditor_fp_violation": 0.02055517927718222,
            "ave_precision_score": 0.8022640507419959,
            "fpr": 0.11745334796926454,
            "logloss": 3.9330309430566133,
            "mae": 0.2988745738001673,
            "precision": 0.7540229885057471,
            "recall": 0.6721311475409836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8404341761882129,
            "auditor_fn_violation": 0.012362585648671036,
            "auditor_fp_violation": 0.014529738022185512,
            "ave_precision_score": 0.8254835137522287,
            "fpr": 0.15021929824561403,
            "logloss": 1.2074040216499042,
            "mae": 0.25862454065510554,
            "precision": 0.7395437262357415,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8410676434826526,
            "auditor_fn_violation": 0.012812438142196476,
            "auditor_fp_violation": 0.02385345384621373,
            "ave_precision_score": 0.820318091248633,
            "fpr": 0.14489571899012074,
            "logloss": 1.4784337379261003,
            "mae": 0.25026175228213926,
            "precision": 0.7555555555555555,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.789000642861375,
            "auditor_fn_violation": 0.027539341917024326,
            "auditor_fp_violation": 0.024501416096294547,
            "ave_precision_score": 0.7893298573277561,
            "fpr": 0.1162280701754386,
            "logloss": 1.6649311633359019,
            "mae": 0.2965085028573552,
            "precision": 0.7464114832535885,
            "recall": 0.6695278969957081
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8274803612815224,
            "auditor_fn_violation": 0.024767864533659652,
            "auditor_fp_violation": 0.023978014962904148,
            "ave_precision_score": 0.8276987332846346,
            "fpr": 0.10537870472008781,
            "logloss": 1.6537557954589475,
            "mae": 0.28742102100802136,
            "precision": 0.7782909930715936,
            "recall": 0.6905737704918032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7479643534094913,
            "auditor_fn_violation": 0.03421946766056773,
            "auditor_fp_violation": 0.01429863897411691,
            "ave_precision_score": 0.7488016870733548,
            "fpr": 0.12719298245614036,
            "logloss": 2.926443386329616,
            "mae": 0.3427595183810684,
            "precision": 0.7121588089330024,
            "recall": 0.6158798283261803
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.786889130586665,
            "auditor_fn_violation": 0.033952061326951125,
            "auditor_fp_violation": 0.02000243932186852,
            "ave_precision_score": 0.787121791047418,
            "fpr": 0.10318331503841932,
            "logloss": 2.9262069550192296,
            "mae": 0.33291892857091737,
            "precision": 0.7577319587628866,
            "recall": 0.6024590163934426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7595721462899659,
            "auditor_fn_violation": 0.024880468338227553,
            "auditor_fp_violation": 0.00510138856108882,
            "ave_precision_score": 0.7613125162020585,
            "fpr": 0.06907894736842106,
            "logloss": 2.6837461777644247,
            "mae": 0.35806254644906443,
            "precision": 0.8085106382978723,
            "recall": 0.5708154506437768
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7939857117739124,
            "auditor_fn_violation": 0.022399273002105414,
            "auditor_fp_violation": 0.009061821239227408,
            "ave_precision_score": 0.794207258497815,
            "fpr": 0.06915477497255763,
            "logloss": 2.672427226202821,
            "mae": 0.35899014443824323,
            "precision": 0.8108108108108109,
            "recall": 0.5532786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8272344752069385,
            "auditor_fn_violation": 0.002021214516979143,
            "auditor_fp_violation": 0.028587443946188344,
            "ave_precision_score": 0.8286060956086533,
            "fpr": 0.4166666666666667,
            "logloss": 1.0375107494412699,
            "mae": 0.3991713595919703,
            "precision": 0.5481569560047562,
            "recall": 0.9892703862660944
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.8615202306921361,
            "auditor_fn_violation": 0.003889168811070523,
            "auditor_fp_violation": 0.020448783323342497,
            "ave_precision_score": 0.8617008839572224,
            "fpr": 0.3809001097694841,
            "logloss": 0.936712572752926,
            "mae": 0.36725508076834984,
            "precision": 0.5809178743961353,
            "recall": 0.985655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7792802076025722,
            "auditor_fn_violation": 0.015110872675250358,
            "auditor_fp_violation": 0.009086617890016522,
            "ave_precision_score": 0.751858380436869,
            "fpr": 0.125,
            "logloss": 2.985681671557659,
            "mae": 0.28335558456930865,
            "precision": 0.7510917030567685,
            "recall": 0.7381974248927039
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7980135749229287,
            "auditor_fn_violation": 0.009681308596210251,
            "auditor_fp_violation": 0.019605400762417836,
            "ave_precision_score": 0.7731891408222292,
            "fpr": 0.1141602634467618,
            "logloss": 3.114530623141992,
            "mae": 0.27138385534488524,
            "precision": 0.7796610169491526,
            "recall": 0.7540983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7772404066553307,
            "auditor_fn_violation": 0.01714855809050524,
            "auditor_fp_violation": 0.012154826528203919,
            "ave_precision_score": 0.750022644832326,
            "fpr": 0.10964912280701754,
            "logloss": 2.959181507954411,
            "mae": 0.2865816788388571,
            "precision": 0.7679814385150812,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7980992588601395,
            "auditor_fn_violation": 0.012173615734825727,
            "auditor_fp_violation": 0.021652874118016467,
            "ave_precision_score": 0.77325633457458,
            "fpr": 0.10757409440175632,
            "logloss": 3.0812255610019825,
            "mae": 0.27559392843031416,
            "precision": 0.7841409691629956,
            "recall": 0.7295081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 10102,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8095366407555846,
            "auditor_fn_violation": 0.008546043219637077,
            "auditor_fp_violation": 0.00809830068444654,
            "ave_precision_score": 0.8100429264349351,
            "fpr": 0.13157894736842105,
            "logloss": 0.8511437616545784,
            "mae": 0.28008274262598915,
            "precision": 0.7457627118644068,
            "recall": 0.7553648068669528
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8395668012211168,
            "auditor_fn_violation": 0.012326573212646883,
            "auditor_fp_violation": 0.025924282411191827,
            "ave_precision_score": 0.8397979920472399,
            "fpr": 0.1163556531284303,
            "logloss": 0.8507707276817462,
            "mae": 0.2711366092658762,
            "precision": 0.7768421052631579,
            "recall": 0.7561475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8441870810708891,
            "auditor_fn_violation": 0.012315525939311801,
            "auditor_fp_violation": 0.0027830225788687004,
            "ave_precision_score": 0.8446705872971836,
            "fpr": 0.22916666666666666,
            "logloss": 0.6530436694059378,
            "mae": 0.3320262749709334,
            "precision": 0.6671974522292994,
            "recall": 0.8991416309012875
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8713759607020323,
            "auditor_fn_violation": 0.008871533713627613,
            "auditor_fp_violation": 0.010252936917579473,
            "ave_precision_score": 0.8715338687825369,
            "fpr": 0.2074643249176729,
            "logloss": 0.5915766150890388,
            "mae": 0.3217584450835575,
            "precision": 0.7014218009478673,
            "recall": 0.9098360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8237326588663765,
            "auditor_fn_violation": 0.007873089375800016,
            "auditor_fp_violation": 0.022101919597199277,
            "ave_precision_score": 0.8240575135742375,
            "fpr": 0.22587719298245615,
            "logloss": 0.8591226933075061,
            "mae": 0.30529936365052385,
            "precision": 0.6611842105263158,
            "recall": 0.8626609442060086
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8472233994097671,
            "auditor_fn_violation": 0.010500080977488262,
            "auditor_fp_violation": 0.026562658134230175,
            "ave_precision_score": 0.847423851430075,
            "fpr": 0.20087815587266739,
            "logloss": 0.8578782855168149,
            "mae": 0.2823356948174107,
            "precision": 0.698019801980198,
            "recall": 0.8668032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.750357783486396,
            "auditor_fn_violation": 0.0012941420073789623,
            "auditor_fp_violation": 0.011972897490362676,
            "ave_precision_score": 0.7351178928319293,
            "fpr": 0.4473684210526316,
            "logloss": 3.7572362069087926,
            "mae": 0.4448611362042138,
            "precision": 0.5299539170506913,
            "recall": 0.9871244635193133
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7679674764172643,
            "auditor_fn_violation": 0.0027779777221932306,
            "auditor_fp_violation": 0.008537626539821958,
            "ave_precision_score": 0.7527226802068666,
            "fpr": 0.4127332601536773,
            "logloss": 3.4841904808385986,
            "mae": 0.4139142941344277,
            "precision": 0.5622817229336438,
            "recall": 0.9897540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8390791903055901,
            "auditor_fn_violation": 0.012941420073789628,
            "auditor_fp_violation": 0.017246381087247263,
            "ave_precision_score": 0.8398649188325563,
            "fpr": 0.12828947368421054,
            "logloss": 0.5012272127290655,
            "mae": 0.30149463843758495,
            "precision": 0.7631578947368421,
            "recall": 0.8090128755364807
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8336976639219782,
            "auditor_fn_violation": 0.011519047704738083,
            "auditor_fp_violation": 0.00939398421706851,
            "ave_precision_score": 0.8340627838297644,
            "fpr": 0.12623490669593854,
            "logloss": 0.5203768843480584,
            "mae": 0.29978660154478415,
            "precision": 0.7727272727272727,
            "recall": 0.8012295081967213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8014236091792609,
            "auditor_fn_violation": 0.010047247948196671,
            "auditor_fp_violation": 0.011274683345134148,
            "ave_precision_score": 0.801885255401444,
            "fpr": 0.13815789473684212,
            "logloss": 0.9012116572346434,
            "mae": 0.28394313794573467,
            "precision": 0.7330508474576272,
            "recall": 0.7424892703862661
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8323365794935519,
            "auditor_fn_violation": 0.010311133504885642,
            "auditor_fp_violation": 0.021170199790841126,
            "ave_precision_score": 0.8325841047554374,
            "fpr": 0.12623490669593854,
            "logloss": 0.9228845922812886,
            "mae": 0.2745924224370819,
            "precision": 0.7614107883817427,
            "recall": 0.7520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8053260621657207,
            "auditor_fn_violation": 0.01867564565921241,
            "auditor_fp_violation": 0.01777741719770278,
            "ave_precision_score": 0.8060146898709619,
            "fpr": 0.14364035087719298,
            "logloss": 1.0829967154566027,
            "mae": 0.2823089972849603,
            "precision": 0.7270833333333333,
            "recall": 0.7489270386266095
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8389736662344631,
            "auditor_fn_violation": 0.009330406147091104,
            "auditor_fp_violation": 0.019379633738416464,
            "ave_precision_score": 0.8391874182260001,
            "fpr": 0.12623490669593854,
            "logloss": 1.1289260108831676,
            "mae": 0.2691861195328871,
            "precision": 0.760914760914761,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7339069162692423,
            "auditor_fn_violation": 0.025365183344627666,
            "auditor_fp_violation": 0.003063291637164664,
            "ave_precision_score": 0.7347561832801319,
            "fpr": 0.06907894736842106,
            "logloss": 2.9713600506874447,
            "mae": 0.3675638971032224,
            "precision": 0.8006329113924051,
            "recall": 0.5429184549356223
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7429837885314139,
            "auditor_fn_violation": 0.02774828597649853,
            "auditor_fp_violation": 0.00850908128391371,
            "ave_precision_score": 0.7435420162506228,
            "fpr": 0.07793633369923161,
            "logloss": 3.0101552635660656,
            "mae": 0.3724221526076575,
            "precision": 0.7917888563049853,
            "recall": 0.5532786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.755533153411049,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0006957556447171843,
            "ave_precision_score": 0.5121144803089747,
            "fpr": 0.4857456140350877,
            "logloss": 16.809940611824416,
            "mae": 0.4868421052631581,
            "precision": 0.512114537444934,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.770509977827051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002545717822360287,
            "ave_precision_score": 0.541019955654102,
            "fpr": 0.4544456641053787,
            "logloss": 15.696360549757552,
            "mae": 0.4544456641053849,
            "precision": 0.541019955654102,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8048200887293078,
            "auditor_fn_violation": 0.011586100444243658,
            "auditor_fp_violation": 0.016194142868381726,
            "ave_precision_score": 0.8062291435168255,
            "fpr": 0.17434210526315788,
            "logloss": 0.8177899405540139,
            "mae": 0.28629092234823156,
            "precision": 0.698292220113852,
            "recall": 0.7896995708154506
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8316178703747863,
            "auditor_fn_violation": 0.011552788324845697,
            "auditor_fp_violation": 0.0287372876297836,
            "ave_precision_score": 0.831868476269201,
            "fpr": 0.15367727771679474,
            "logloss": 0.8246358495710165,
            "mae": 0.2767718298825541,
            "precision": 0.732824427480916,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7940280403816566,
            "auditor_fn_violation": 0.007708380393042692,
            "auditor_fp_violation": 0.0275892927385729,
            "ave_precision_score": 0.7949683126766678,
            "fpr": 0.34978070175438597,
            "logloss": 1.4841892227132494,
            "mae": 0.3646722279893909,
            "precision": 0.5851755526657998,
            "recall": 0.9656652360515021
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8333615980461889,
            "auditor_fn_violation": 0.01023915351532274,
            "auditor_fp_violation": 0.02408960096327263,
            "ave_precision_score": 0.8335857827008264,
            "fpr": 0.3084522502744237,
            "logloss": 1.3393515339753566,
            "mae": 0.3313891610109794,
            "precision": 0.6228187919463087,
            "recall": 0.9508196721311475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8235824432946386,
            "auditor_fn_violation": 0.020534504178902194,
            "auditor_fp_violation": 0.024990657698056806,
            "ave_precision_score": 0.8240452435048181,
            "fpr": 0.11951754385964912,
            "logloss": 0.7580832982594373,
            "mae": 0.2706069043341934,
            "precision": 0.7588495575221239,
            "recall": 0.7360515021459227
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8331342786593765,
            "auditor_fn_violation": 0.020415324539777943,
            "auditor_fp_violation": 0.029445728980960317,
            "ave_precision_score": 0.8344211715707028,
            "fpr": 0.12403951701427003,
            "logloss": 0.8046185008579362,
            "mae": 0.2736923812666445,
            "precision": 0.7631027253668763,
            "recall": 0.7459016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7770588193214686,
            "auditor_fn_violation": 0.012160228898426328,
            "auditor_fp_violation": 0.010269156635984579,
            "ave_precision_score": 0.7419876543019976,
            "fpr": 0.13048245614035087,
            "logloss": 3.585395187641836,
            "mae": 0.28845840690600344,
            "precision": 0.7429805615550756,
            "recall": 0.7381974248927039
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7970791157899735,
            "auditor_fn_violation": 0.010284141008799557,
            "auditor_fp_violation": 0.02122729030265756,
            "ave_precision_score": 0.7624256905481586,
            "fpr": 0.12294182217343579,
            "logloss": 3.753025359661688,
            "mae": 0.27453143681083814,
            "precision": 0.7647058823529411,
            "recall": 0.7459016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.867288566904662,
            "auditor_fn_violation": 0.018400346359460883,
            "auditor_fp_violation": 0.010301117142632368,
            "ave_precision_score": 0.8675955205411705,
            "fpr": 0.0756578947368421,
            "logloss": 0.46779907735128795,
            "mae": 0.29193093239665724,
            "precision": 0.8333333333333334,
            "recall": 0.740343347639485
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8810273930190553,
            "auditor_fn_violation": 0.01740566122617912,
            "auditor_fp_violation": 0.013159362973689063,
            "ave_precision_score": 0.8811893692681259,
            "fpr": 0.08781558726673985,
            "logloss": 0.46808314106366455,
            "mae": 0.2915109778224346,
            "precision": 0.8210290827740492,
            "recall": 0.7520491803278688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7820916166966239,
            "auditor_fn_violation": 0.006329530908817107,
            "auditor_fp_violation": 0.020734993312878612,
            "ave_precision_score": 0.7836523483542601,
            "fpr": 0.2675438596491228,
            "logloss": 1.2423984290203984,
            "mae": 0.32069360886864534,
            "precision": 0.6363636363636364,
            "recall": 0.9163090128755365
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8235532139474792,
            "auditor_fn_violation": 0.008887279336344497,
            "auditor_fp_violation": 0.03161257340672059,
            "ave_precision_score": 0.8237977973792758,
            "fpr": 0.23600439077936333,
            "logloss": 1.1560279135246119,
            "mae": 0.29517562652748985,
            "precision": 0.675226586102719,
            "recall": 0.9159836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7476184282751963,
            "auditor_fn_violation": 0.03296062043520819,
            "auditor_fp_violation": 0.01916155298560302,
            "ave_precision_score": 0.7484191986497278,
            "fpr": 0.1162280701754386,
            "logloss": 2.966060470680998,
            "mae": 0.341141182773834,
            "precision": 0.7246753246753247,
            "recall": 0.5987124463519313
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7875770159682491,
            "auditor_fn_violation": 0.03159246729409225,
            "auditor_fp_violation": 0.01918760201685208,
            "ave_precision_score": 0.7877976413241816,
            "fpr": 0.09659714599341383,
            "logloss": 2.9550275103650003,
            "mae": 0.3310425283233137,
            "precision": 0.7640750670241286,
            "recall": 0.5840163934426229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 10102,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.7527630237462097,
            "auditor_fn_violation": 0.03620303441005949,
            "auditor_fp_violation": 0.018276492801510513,
            "ave_precision_score": 0.7534905058721111,
            "fpr": 0.44298245614035087,
            "logloss": 3.9315169014364257,
            "mae": 0.52365367109733,
            "precision": 0.4846938775510204,
            "recall": 0.8154506437768241
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.7849726869871655,
            "auditor_fn_violation": 0.032633927768080474,
            "auditor_fp_violation": 0.018144402664569896,
            "ave_precision_score": 0.7851711974364732,
            "fpr": 0.4138309549945115,
            "logloss": 3.7640200790670018,
            "mae": 0.4988346828996853,
            "precision": 0.5116580310880829,
            "recall": 0.8094262295081968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6664243661675555,
            "auditor_fn_violation": 0.015943829530908817,
            "auditor_fp_violation": 0.004243371882621351,
            "ave_precision_score": 0.6555974260907445,
            "fpr": 0.2324561403508772,
            "logloss": 1.7216608502623243,
            "mae": 0.34666475855775797,
            "precision": 0.6412859560067682,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.697672196629536,
            "auditor_fn_violation": 0.009609328606647352,
            "auditor_fp_violation": 0.01797313112912057,
            "ave_precision_score": 0.6850260080215849,
            "fpr": 0.2052689352360044,
            "logloss": 1.7743122386909693,
            "mae": 0.32488081039436306,
            "precision": 0.6825127334465195,
            "recall": 0.8237704918032787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.782688874698532,
            "auditor_fn_violation": 0.013574373164671333,
            "auditor_fp_violation": 0.016698135473212177,
            "ave_precision_score": 0.7581374222471126,
            "fpr": 0.13925438596491227,
            "logloss": 2.668865799311572,
            "mae": 0.2818048121345548,
            "precision": 0.7354166666666667,
            "recall": 0.7575107296137339
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8028334900756806,
            "auditor_fn_violation": 0.010104191034892301,
            "auditor_fp_violation": 0.018954049923057558,
            "ave_precision_score": 0.7813959603904027,
            "fpr": 0.12623490669593854,
            "logloss": 2.6883876466159267,
            "mae": 0.2707443891701916,
            "precision": 0.762396694214876,
            "recall": 0.7561475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8615097872533123,
            "auditor_fn_violation": 0.014616745726978395,
            "auditor_fp_violation": 0.009691409015813076,
            "ave_precision_score": 0.8618133663513821,
            "fpr": 0.08991228070175439,
            "logloss": 0.47585511442030776,
            "mae": 0.28091556980660626,
            "precision": 0.8127853881278538,
            "recall": 0.7639484978540773
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8847154289777097,
            "auditor_fn_violation": 0.011766478918860564,
            "auditor_fp_violation": 0.006850861417972615,
            "ave_precision_score": 0.8848746191301751,
            "fpr": 0.09989023051591657,
            "logloss": 0.4637212460426515,
            "mae": 0.27533213055716127,
            "precision": 0.8072033898305084,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7292060420503441,
            "auditor_fn_violation": 0.013600256004818916,
            "auditor_fp_violation": 0.008432656753992612,
            "ave_precision_score": 0.722420420407192,
            "fpr": 0.18092105263157895,
            "logloss": 1.4013252664493376,
            "mae": 0.31906113097060296,
            "precision": 0.6845124282982792,
            "recall": 0.7682403433476395
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7477770213105619,
            "auditor_fn_violation": 0.004885641791581944,
            "auditor_fp_violation": 0.009238282821205496,
            "ave_precision_score": 0.7397363360419954,
            "fpr": 0.16355653128430298,
            "logloss": 1.4383692605936442,
            "mae": 0.30664237597940747,
            "precision": 0.718336483931947,
            "recall": 0.7786885245901639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7849833688552847,
            "auditor_fn_violation": 0.014524979293727888,
            "auditor_fp_violation": 0.02091446385020848,
            "ave_precision_score": 0.783757371330648,
            "fpr": 0.17434210526315788,
            "logloss": 1.0947207628384656,
            "mae": 0.289677058282732,
            "precision": 0.6977186311787072,
            "recall": 0.7875536480686696
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.818074311608989,
            "auditor_fn_violation": 0.018555091684511704,
            "auditor_fp_violation": 0.02842069479152881,
            "ave_precision_score": 0.818376739791831,
            "fpr": 0.15367727771679474,
            "logloss": 1.0752682296761664,
            "mae": 0.2795895839755665,
            "precision": 0.7323135755258127,
            "recall": 0.7848360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 10102,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8002190669317344,
            "auditor_fn_violation": 0.014875574128454182,
            "auditor_fp_violation": 0.01307184721894423,
            "ave_precision_score": 0.8004371522344848,
            "fpr": 0.14583333333333334,
            "logloss": 1.5490661485411659,
            "mae": 0.28747220697503106,
            "precision": 0.7268993839835729,
            "recall": 0.759656652360515
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.832648105980951,
            "auditor_fn_violation": 0.012861924385020969,
            "auditor_fp_violation": 0.0207005005799877,
            "ave_precision_score": 0.8326594940236705,
            "fpr": 0.12184412733260154,
            "logloss": 1.3606145132901335,
            "mae": 0.27332223243685877,
            "precision": 0.76875,
            "recall": 0.7561475409836066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7773472536884546,
            "auditor_fn_violation": 0.01130844815902417,
            "auditor_fp_violation": 0.01675222248446228,
            "ave_precision_score": 0.7421802787631975,
            "fpr": 0.15021929824561403,
            "logloss": 3.6271466365045386,
            "mae": 0.28939249723745053,
            "precision": 0.7215447154471545,
            "recall": 0.7618025751072961
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7989960111737906,
            "auditor_fn_violation": 0.014470227276817044,
            "auditor_fp_violation": 0.02174888997879866,
            "ave_precision_score": 0.7634245500602672,
            "fpr": 0.12952799121844127,
            "logloss": 3.8024914919604362,
            "mae": 0.26919881260706013,
            "precision": 0.7616161616161616,
            "recall": 0.7725409836065574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7394596832391176,
            "auditor_fn_violation": 0.028537007755440102,
            "auditor_fp_violation": 0.019933522146172607,
            "ave_precision_score": 0.7404067017322473,
            "fpr": 0.11074561403508772,
            "logloss": 3.119116865680908,
            "mae": 0.34404479909992264,
            "precision": 0.7262872628726287,
            "recall": 0.575107296137339
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7795747666501252,
            "auditor_fn_violation": 0.035384912994187626,
            "auditor_fp_violation": 0.016800180613619205,
            "ave_precision_score": 0.7798695586007064,
            "fpr": 0.09220636663007684,
            "logloss": 3.1224989134923815,
            "mae": 0.3349323816233503,
            "precision": 0.768595041322314,
            "recall": 0.5717213114754098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.8216682759429006,
            "auditor_fn_violation": 0.0011717867630449514,
            "auditor_fp_violation": 0.013418495791047123,
            "ave_precision_score": 0.8220772588400975,
            "fpr": 0.44627192982456143,
            "logloss": 2.923003323752583,
            "mae": 0.44540460167576257,
            "precision": 0.5327210103329506,
            "recall": 0.9957081545064378
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.8538495485215314,
            "auditor_fn_violation": 0.000391391193248277,
            "auditor_fp_violation": 0.007637153467080846,
            "ave_precision_score": 0.8539093523210545,
            "fpr": 0.41712403951701427,
            "logloss": 2.61358438029546,
            "mae": 0.41417080352443725,
            "precision": 0.5612009237875288,
            "recall": 0.9959016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8005301442129137,
            "auditor_fn_violation": 0.015397936902341692,
            "auditor_fp_violation": 0.017061993548894663,
            "ave_precision_score": 0.8010518741961898,
            "fpr": 0.14473684210526316,
            "logloss": 0.9561898979402842,
            "mae": 0.27495142750986007,
            "precision": 0.7300613496932515,
            "recall": 0.7660944206008584
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8388028745470293,
            "auditor_fn_violation": 0.019322128448291377,
            "auditor_fp_violation": 0.02713875329892333,
            "ave_precision_score": 0.8390285018973574,
            "fpr": 0.12843029637760703,
            "logloss": 0.9795012201960144,
            "mae": 0.2688056438110037,
            "precision": 0.7631578947368421,
            "recall": 0.7725409836065574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7380817952449333,
            "auditor_fn_violation": 0.035294782019426256,
            "auditor_fp_violation": 0.018050310754464637,
            "ave_precision_score": 0.7389539049198763,
            "fpr": 0.13706140350877194,
            "logloss": 3.1093376433034408,
            "mae": 0.34624460267133056,
            "precision": 0.7016706443914081,
            "recall": 0.630901287553648
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7788055244425811,
            "auditor_fn_violation": 0.0381988807111623,
            "auditor_fp_violation": 0.023518695845108253,
            "ave_precision_score": 0.7791008835260698,
            "fpr": 0.11086717892425905,
            "logloss": 3.0979818408729574,
            "mae": 0.3343788533124867,
            "precision": 0.7468671679197995,
            "recall": 0.610655737704918
        }
    }
]