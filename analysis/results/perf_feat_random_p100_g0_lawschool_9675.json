[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8279396138654929,
            "auditor_fn_violation": 0.030710910888913312,
            "auditor_fp_violation": 0.03163364531420931,
            "ave_precision_score": 0.828416364977891,
            "fpr": 0.13706140350877194,
            "logloss": 0.8140419914551303,
            "mae": 0.26769050597172084,
            "precision": 0.7464503042596349,
            "recall": 0.7682672233820459
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8360831187630411,
            "auditor_fn_violation": 0.016710381882257788,
            "auditor_fp_violation": 0.02605766422622584,
            "ave_precision_score": 0.8364635605864328,
            "fpr": 0.13721185510428102,
            "logloss": 0.8165104307551894,
            "mae": 0.2727137363989707,
            "precision": 0.7433264887063655,
            "recall": 0.7621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6711447303293196,
            "auditor_fn_violation": 0.014423781269457574,
            "auditor_fp_violation": 0.015335683319152391,
            "ave_precision_score": 0.6718791761711573,
            "fpr": 0.20175438596491227,
            "logloss": 0.6689424623326525,
            "mae": 0.429762329195479,
            "precision": 0.6134453781512605,
            "recall": 0.6096033402922756
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6599208948161276,
            "auditor_fn_violation": 0.013872551851637877,
            "auditor_fp_violation": 0.020387919314393897,
            "ave_precision_score": 0.6606228941070051,
            "fpr": 0.20417124039517015,
            "logloss": 0.6782000051921145,
            "mae": 0.43303915204809473,
            "precision": 0.6042553191489362,
            "recall": 0.5978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8138242316129163,
            "auditor_fn_violation": 0.0014307035856865602,
            "auditor_fp_violation": 0.008450326161824886,
            "ave_precision_score": 0.7491018674861903,
            "fpr": 0.11293859649122807,
            "logloss": 0.5603629908985165,
            "mae": 0.3809044591330907,
            "precision": 0.7690582959641256,
            "recall": 0.7160751565762005
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8067190256543162,
            "auditor_fn_violation": 0.011381362297070893,
            "auditor_fp_violation": 0.006910945729564246,
            "ave_precision_score": 0.7436238723423528,
            "fpr": 0.11525795828759605,
            "logloss": 0.5712327243566655,
            "mae": 0.3869677596080447,
            "precision": 0.75177304964539,
            "recall": 0.6694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8481815027267656,
            "auditor_fn_violation": 0.009367102516207015,
            "auditor_fp_violation": 0.009648109882095541,
            "ave_precision_score": 0.8484365192368287,
            "fpr": 0.08991228070175439,
            "logloss": 0.6130665443365914,
            "mae": 0.2783408483797705,
            "precision": 0.8056872037914692,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8409905077529926,
            "auditor_fn_violation": 0.013354902074065514,
            "auditor_fp_violation": 0.009768477023937806,
            "ave_precision_score": 0.841401441790671,
            "fpr": 0.0889132821075741,
            "logloss": 0.6703429283421071,
            "mae": 0.2833578993614966,
            "precision": 0.8038740920096852,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7080094698264648,
            "auditor_fn_violation": 0.014627513460059334,
            "auditor_fp_violation": 0.019551983306997294,
            "ave_precision_score": 0.5684239251885675,
            "fpr": 0.2236842105263158,
            "logloss": 0.6936649147019615,
            "mae": 0.4755085821083763,
            "precision": 0.5944333996023857,
            "recall": 0.6242171189979123
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6855905863433124,
            "auditor_fn_violation": 0.009638916170778215,
            "auditor_fp_violation": 0.0193506480427799,
            "ave_precision_score": 0.5496539940843814,
            "fpr": 0.2305159165751921,
            "logloss": 0.7103113188361654,
            "mae": 0.48351617957313026,
            "precision": 0.569672131147541,
            "recall": 0.5852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5708362566818098,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5724209966756361,
            "fpr": 0.47478070175438597,
            "logloss": 1.0276691678405765,
            "mae": 0.4788366271215573,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5638517633811935,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5653243343064229,
            "fpr": 0.47859495060373214,
            "logloss": 1.0188512288049552,
            "mae": 0.48087700818686796,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.711592987773507,
            "auditor_fn_violation": 0.10975442259092408,
            "auditor_fp_violation": 0.11199404400145861,
            "ave_precision_score": 0.6344145943221862,
            "fpr": 0.20833333333333334,
            "logloss": 0.6509663556526365,
            "mae": 0.46258112807807167,
            "precision": 0.6090534979423868,
            "recall": 0.6179540709812108
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7072519218052291,
            "auditor_fn_violation": 0.10757871627477035,
            "auditor_fp_violation": 0.11280828608545908,
            "ave_precision_score": 0.6262965855041225,
            "fpr": 0.1942919868276619,
            "logloss": 0.6520398674167516,
            "mae": 0.464853824329952,
            "precision": 0.6217948717948718,
            "recall": 0.6126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 9675,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.4706372200635283,
            "auditor_fn_violation": 0.061824707907555954,
            "auditor_fp_violation": 0.07096298772334995,
            "ave_precision_score": 0.4836864707652056,
            "fpr": 0.26535087719298245,
            "logloss": 0.7156518206680007,
            "mae": 0.5032511474401281,
            "precision": 0.4829059829059829,
            "recall": 0.4718162839248434
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.527844612414421,
            "auditor_fn_violation": 0.05558264486683229,
            "auditor_fp_violation": 0.057228672997713975,
            "ave_precision_score": 0.5311395437077713,
            "fpr": 0.2535675082327113,
            "logloss": 0.7049848684597607,
            "mae": 0.4981218360846966,
            "precision": 0.510593220338983,
            "recall": 0.5073684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7566418970181193,
            "auditor_fn_violation": 0.003786213969160899,
            "auditor_fp_violation": 0.0040035857542239,
            "ave_precision_score": 0.5290117988080849,
            "fpr": 0.4517543859649123,
            "logloss": 0.6921294244133336,
            "mae": 0.4966067993327191,
            "precision": 0.5291428571428571,
            "recall": 0.9665970772442589
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7577954911687667,
            "auditor_fn_violation": 0.0015067306025766947,
            "auditor_fp_violation": 0.00393508494546774,
            "ave_precision_score": 0.5265522106068444,
            "fpr": 0.45773874862788144,
            "logloss": 0.6916767670771992,
            "mae": 0.4964608871321778,
            "precision": 0.5266742338251986,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8334378333180439,
            "auditor_fn_violation": 0.00785170127824781,
            "auditor_fp_violation": 0.0070980713909485045,
            "ave_precision_score": 0.8039248970192241,
            "fpr": 0.07017543859649122,
            "logloss": 0.5060453582178414,
            "mae": 0.34575658951673593,
            "precision": 0.8354755784061697,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.836601215140336,
            "auditor_fn_violation": 0.006736379917961762,
            "auditor_fp_violation": 0.005415462391363458,
            "ave_precision_score": 0.7993197469341352,
            "fpr": 0.06915477497255763,
            "logloss": 0.5138997141431358,
            "mae": 0.35159571643849236,
            "precision": 0.8333333333333334,
            "recall": 0.6631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8424065200609118,
            "auditor_fn_violation": 0.018079515071603852,
            "auditor_fp_violation": 0.01776163850735384,
            "ave_precision_score": 0.8397635349557913,
            "fpr": 0.10964912280701754,
            "logloss": 0.4969868884054113,
            "mae": 0.3134095975383708,
            "precision": 0.7899159663865546,
            "recall": 0.7849686847599165
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.846894208434589,
            "auditor_fn_violation": 0.012721705471142179,
            "auditor_fp_violation": 0.017767046999466254,
            "ave_precision_score": 0.8430574154690149,
            "fpr": 0.11306256860592755,
            "logloss": 0.5029091000107604,
            "mae": 0.32043342956195614,
            "precision": 0.7799145299145299,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.715802012716028,
            "auditor_fn_violation": 0.0045576493425630886,
            "auditor_fp_violation": 0.024652060289291365,
            "ave_precision_score": 0.7058930937195671,
            "fpr": 0.38048245614035087,
            "logloss": 0.6641524470669504,
            "mae": 0.47265384119134723,
            "precision": 0.5710754017305315,
            "recall": 0.964509394572025
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6804537667406575,
            "auditor_fn_violation": 0.009648159916806285,
            "auditor_fp_violation": 0.01647045790994876,
            "ave_precision_score": 0.6739434303560382,
            "fpr": 0.3787047200878156,
            "logloss": 0.6677834986231452,
            "mae": 0.47391410147450236,
            "precision": 0.5660377358490566,
            "recall": 0.9473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8414160480024842,
            "auditor_fn_violation": 0.00785170127824781,
            "auditor_fp_violation": 0.0070980713909485045,
            "ave_precision_score": 0.735727212759561,
            "fpr": 0.07017543859649122,
            "logloss": 0.5384574770794387,
            "mae": 0.3596090539113471,
            "precision": 0.8354755784061697,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8371664179242856,
            "auditor_fn_violation": 0.006736379917961762,
            "auditor_fp_violation": 0.0034441434455533297,
            "ave_precision_score": 0.729728619738003,
            "fpr": 0.06805708013172337,
            "logloss": 0.5429972199212855,
            "mae": 0.36253602869816853,
            "precision": 0.8355437665782494,
            "recall": 0.6631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8123543455701878,
            "auditor_fn_violation": 0.004427169175548475,
            "auditor_fp_violation": 0.007845103520927028,
            "ave_precision_score": 0.7868122006189248,
            "fpr": 0.06469298245614036,
            "logloss": 0.5541385535527539,
            "mae": 0.35321968512021396,
            "precision": 0.8361111111111111,
            "recall": 0.6283924843423799
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8386834298670044,
            "auditor_fn_violation": 0.005862845918308401,
            "auditor_fp_violation": 0.006928569270586814,
            "ave_precision_score": 0.8134397157101637,
            "fpr": 0.06586169045005488,
            "logloss": 0.5381471190148107,
            "mae": 0.3500166675392804,
            "precision": 0.8337950138504155,
            "recall": 0.6336842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5682014549363621,
            "auditor_fn_violation": 0.009174815954290752,
            "auditor_fp_violation": 0.00691068028037762,
            "ave_precision_score": 0.5554052661896676,
            "fpr": 0.0625,
            "logloss": 0.6939049909523134,
            "mae": 0.49361976285121945,
            "precision": 0.5714285714285714,
            "recall": 0.15866388308977036
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.567238671856211,
            "auditor_fn_violation": 0.005576289791437992,
            "auditor_fp_violation": 0.01336367939254172,
            "ave_precision_score": 0.5543787491320118,
            "fpr": 0.06147091108671789,
            "logloss": 0.6922744853953692,
            "mae": 0.49201915646227473,
            "precision": 0.5942028985507246,
            "recall": 0.1726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.5945196407917359,
            "auditor_fn_violation": 0.004523312456506611,
            "auditor_fp_violation": 0.010671164053320376,
            "ave_precision_score": 0.5434207855145845,
            "fpr": 0.40131578947368424,
            "logloss": 5.3938386953016915,
            "mae": 0.4372671300447301,
            "precision": 0.5552855407047388,
            "recall": 0.954070981210856
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6443087744488889,
            "auditor_fn_violation": 0.006505286267259806,
            "auditor_fp_violation": 0.00896534708305221,
            "ave_precision_score": 0.5901690287464081,
            "fpr": 0.3896816684961581,
            "logloss": 4.976276376580686,
            "mae": 0.4296451156057262,
            "precision": 0.5579078455790785,
            "recall": 0.9431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6429078730485448,
            "auditor_fn_violation": 0.00282935941105373,
            "auditor_fp_violation": 0.00428467242008023,
            "ave_precision_score": 0.6436226001135077,
            "fpr": 0.4440789473684211,
            "logloss": 0.7216380383055139,
            "mae": 0.46942302715360074,
            "precision": 0.5339470655926352,
            "recall": 0.9686847599164927
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6911491851760836,
            "auditor_fn_violation": 0.001987405396036745,
            "auditor_fp_violation": 0.0035599552865587933,
            "ave_precision_score": 0.6925986812367395,
            "fpr": 0.4544456641053787,
            "logloss": 0.7059865686116098,
            "mae": 0.46362256755158876,
            "precision": 0.5268571428571428,
            "recall": 0.9705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6729539096706262,
            "auditor_fn_violation": 0.026100611654396956,
            "auditor_fp_violation": 0.02539402779465986,
            "ave_precision_score": 0.6738524080406291,
            "fpr": 0.2532894736842105,
            "logloss": 1.1965427371873811,
            "mae": 0.4325661043005148,
            "precision": 0.60580204778157,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6738394984827835,
            "auditor_fn_violation": 0.01436015945461899,
            "auditor_fp_violation": 0.025669946323729355,
            "ave_precision_score": 0.6715934805113393,
            "fpr": 0.2349066959385291,
            "logloss": 1.1452061382237524,
            "mae": 0.42192644256228024,
            "precision": 0.6192170818505338,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.8502943143646595,
            "auditor_fn_violation": 0.0032848954327363298,
            "auditor_fp_violation": 0.016812021392974358,
            "ave_precision_score": 0.8505335408390021,
            "fpr": 0.4407894736842105,
            "logloss": 1.2917346014602045,
            "mae": 0.4239083677270205,
            "precision": 0.5405714285714286,
            "recall": 0.9874739039665971
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.8390420729394474,
            "auditor_fn_violation": 0.0010168120630885669,
            "auditor_fp_violation": 0.024798839867470997,
            "ave_precision_score": 0.8396234641007736,
            "fpr": 0.424807903402854,
            "logloss": 1.242831010444244,
            "mae": 0.4121552664171092,
            "precision": 0.5484247374562428,
            "recall": 0.9894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 9675,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8530324682170434,
            "auditor_fn_violation": 0.021288869355015935,
            "auditor_fp_violation": 0.02011415663870994,
            "ave_precision_score": 0.8452599618663967,
            "fpr": 0.1118421052631579,
            "logloss": 0.49240051157826176,
            "mae": 0.31433308508406443,
            "precision": 0.7787418655097614,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8643103075237314,
            "auditor_fn_violation": 0.010246692472124326,
            "auditor_fp_violation": 0.02127916696039236,
            "ave_precision_score": 0.8595373335686713,
            "fpr": 0.1251372118551043,
            "logloss": 0.5023245033854256,
            "mae": 0.3172185022576122,
            "precision": 0.7625,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8034162145228559,
            "auditor_fn_violation": 0.018470955572647697,
            "auditor_fp_violation": 0.011456180867874071,
            "ave_precision_score": 0.8039024587352765,
            "fpr": 0.13267543859649122,
            "logloss": 0.7900767930168423,
            "mae": 0.29820522917269204,
            "precision": 0.7463312368972747,
            "recall": 0.7432150313152401
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8108224940668637,
            "auditor_fn_violation": 0.007602981108094056,
            "auditor_fp_violation": 0.01876655354031763,
            "ave_precision_score": 0.8108141597569545,
            "fpr": 0.12403951701427003,
            "logloss": 0.7953824396229685,
            "mae": 0.2994669436842724,
            "precision": 0.7585470085470085,
            "recall": 0.7473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7846938952036575,
            "auditor_fn_violation": 0.012844284510859616,
            "auditor_fp_violation": 0.0033097321826506426,
            "ave_precision_score": 0.7848722635594831,
            "fpr": 0.3190789473684211,
            "logloss": 0.7927250047786312,
            "mae": 0.3839960574956709,
            "precision": 0.6013698630136987,
            "recall": 0.9164926931106472
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8116568035858891,
            "auditor_fn_violation": 0.00036974984112311517,
            "auditor_fp_violation": 0.016686975699654584,
            "ave_precision_score": 0.8130735625919884,
            "fpr": 0.29747530186608123,
            "logloss": 0.6355130744599303,
            "mae": 0.37664564934474315,
            "precision": 0.6188466947960619,
            "recall": 0.9263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6589438367264931,
            "auditor_fn_violation": 0.004651503497784142,
            "auditor_fp_violation": 0.00216512702078522,
            "ave_precision_score": 0.6594338764854712,
            "fpr": 0.01425438596491228,
            "logloss": 11.986256299600372,
            "mae": 0.46886355254728124,
            "precision": 0.8433734939759037,
            "recall": 0.14613778705636743
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5968343257116969,
            "auditor_fn_violation": 0.003466404760529213,
            "auditor_fp_violation": 0.001993977784267717,
            "ave_precision_score": 0.5976852827504288,
            "fpr": 0.013172338090010977,
            "logloss": 12.751532952476063,
            "mae": 0.4855386630171191,
            "precision": 0.8064516129032258,
            "recall": 0.10526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8512769720619698,
            "auditor_fn_violation": 0.010587206534080507,
            "auditor_fp_violation": 0.013821360560755244,
            "ave_precision_score": 0.8516651806036502,
            "fpr": 0.1337719298245614,
            "logloss": 0.5127658113082051,
            "mae": 0.28600226475279206,
            "precision": 0.758893280632411,
            "recall": 0.8016701461377871
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8492299337176142,
            "auditor_fn_violation": 0.009930094170662667,
            "auditor_fp_violation": 0.02050373115539935,
            "ave_precision_score": 0.8495327894378855,
            "fpr": 0.14489571899012074,
            "logloss": 0.5336189488816176,
            "mae": 0.29428846017599647,
            "precision": 0.7386138613861386,
            "recall": 0.7852631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8066125786586672,
            "auditor_fn_violation": 0.02700023806907666,
            "auditor_fp_violation": 0.01993436246505409,
            "ave_precision_score": 0.8069492085184116,
            "fpr": 0.13706140350877194,
            "logloss": 0.614496490093287,
            "mae": 0.2970871048399427,
            "precision": 0.7553816046966731,
            "recall": 0.8058455114822547
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8130298612946754,
            "auditor_fn_violation": 0.021480154832745967,
            "auditor_fp_violation": 0.0238748627881449,
            "ave_precision_score": 0.8137985046527583,
            "fpr": 0.11964873765093303,
            "logloss": 0.619772263742475,
            "mae": 0.29553330530393074,
            "precision": 0.7710084033613446,
            "recall": 0.7726315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 9675,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0.5805854023161052,
            "auditor_fn_violation": 0.047345987620408016,
            "auditor_fp_violation": 0.03767827478627284,
            "ave_precision_score": 0.5061147900478357,
            "fpr": 0.20614035087719298,
            "logloss": 2.2993855858332055,
            "mae": 0.5373940830646908,
            "precision": 0.4704225352112676,
            "recall": 0.348643006263048
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.6180639279803435,
            "auditor_fn_violation": 0.04456409960136346,
            "auditor_fp_violation": 0.03666955357052943,
            "ave_precision_score": 0.5255767723693556,
            "fpr": 0.17453347969264543,
            "logloss": 2.1700032920432952,
            "mae": 0.5083801055835145,
            "precision": 0.5323529411764706,
            "recall": 0.38105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 9675,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7833588778623577,
            "auditor_fn_violation": 0.03183258250009157,
            "auditor_fp_violation": 0.04063095093391678,
            "ave_precision_score": 0.7328067692354062,
            "fpr": 0.22916666666666666,
            "logloss": 3.143294308081563,
            "mae": 0.3205998915667232,
            "precision": 0.6677265500794912,
            "recall": 0.8768267223382046
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7925863140089023,
            "auditor_fn_violation": 0.022346756022878275,
            "auditor_fp_violation": 0.04858054965306801,
            "ave_precision_score": 0.7425419098766256,
            "fpr": 0.23380900109769484,
            "logloss": 2.9923939803635737,
            "mae": 0.30808437888983103,
            "precision": 0.6635071090047393,
            "recall": 0.8842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.787269340605159,
            "auditor_fn_violation": 0.018246621250412043,
            "auditor_fp_violation": 0.019506401685507074,
            "ave_precision_score": 0.7965982598256103,
            "fpr": 0.13048245614035087,
            "logloss": 0.5471724699437021,
            "mae": 0.3769462072666277,
            "precision": 0.7561475409836066,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8152916748397728,
            "auditor_fn_violation": 0.019028251198798314,
            "auditor_fp_violation": 0.032502844943050786,
            "ave_precision_score": 0.7928296361181548,
            "fpr": 0.132821075740944,
            "logloss": 0.5474148916522458,
            "mae": 0.38470547534239147,
            "precision": 0.7441860465116279,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7441989732046612,
            "auditor_fn_violation": 0.031782221733875404,
            "auditor_fp_violation": 0.01327944572748268,
            "ave_precision_score": 0.7458847705982036,
            "fpr": 0.06578947368421052,
            "logloss": 0.6360846684877317,
            "mae": 0.4369132402360009,
            "precision": 0.7931034482758621,
            "recall": 0.4801670146137787
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7461545780868927,
            "auditor_fn_violation": 0.03970188919059449,
            "auditor_fp_violation": 0.010717630590438978,
            "ave_precision_score": 0.7475894252850062,
            "fpr": 0.04500548847420417,
            "logloss": 0.6282034245295414,
            "mae": 0.43437389311616836,
            "precision": 0.8514492753623188,
            "recall": 0.49473684210526314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7291365555890454,
            "auditor_fn_violation": 0.017122660513496698,
            "auditor_fp_violation": 0.023193448401604477,
            "ave_precision_score": 0.7152988114668468,
            "fpr": 0.12719298245614036,
            "logloss": 2.555444246305265,
            "mae": 0.32520684406080475,
            "precision": 0.7516059957173448,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6737232144177139,
            "auditor_fn_violation": 0.01790051418337282,
            "auditor_fp_violation": 0.030103525715264003,
            "ave_precision_score": 0.6609267785835587,
            "fpr": 0.1350164654226125,
            "logloss": 3.2487017886925575,
            "mae": 0.3415689035563293,
            "precision": 0.7360515021459227,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 9675,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8436096446229969,
            "auditor_fn_violation": 0.008856627476834055,
            "auditor_fp_violation": 0.0047784733195575585,
            "ave_precision_score": 0.837434515973997,
            "fpr": 0.08114035087719298,
            "logloss": 0.4991300497049294,
            "mae": 0.335576577463367,
            "precision": 0.8221153846153846,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8632022729712678,
            "auditor_fn_violation": 0.006590790918019528,
            "auditor_fp_violation": 0.006936122216739342,
            "ave_precision_score": 0.8468595821703714,
            "fpr": 0.0801317233809001,
            "logloss": 0.5021339062900297,
            "mae": 0.3379265109790667,
            "precision": 0.8201970443349754,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 9.836724418286355,
            "mae": 0.523476667525677,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 10.898265305652957,
            "mae": 0.5201853892538737,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7138792953214593,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6161789840623535,
            "fpr": 0.47478070175438597,
            "logloss": 0.7823475015209699,
            "mae": 0.4802664303335181,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7010534292368493,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6038741778893246,
            "fpr": 0.47859495060373214,
            "logloss": 0.7871272785116874,
            "mae": 0.48295496513762404,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.7278097697837753,
            "auditor_fn_violation": 0.023406310661832037,
            "auditor_fp_violation": 0.011200417325067883,
            "ave_precision_score": 0.6873198560914691,
            "fpr": 0.22478070175438597,
            "logloss": 0.6328300664092086,
            "mae": 0.4242357935944343,
            "precision": 0.6326164874551972,
            "recall": 0.7369519832985386
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7423799934802904,
            "auditor_fn_violation": 0.013849442486567687,
            "auditor_fp_violation": 0.009922053595705896,
            "ave_precision_score": 0.6968030887565396,
            "fpr": 0.22063666300768386,
            "logloss": 0.618820411682014,
            "mae": 0.41572189917041624,
            "precision": 0.6473684210526316,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.717465997501708,
            "auditor_fn_violation": 0.04469518001684797,
            "auditor_fp_violation": 0.050643713787934044,
            "ave_precision_score": 0.5616594125541429,
            "fpr": 0.36951754385964913,
            "logloss": 3.035171786752686,
            "mae": 0.44794806202979903,
            "precision": 0.545822102425876,
            "recall": 0.8455114822546973
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7306293020817318,
            "auditor_fn_violation": 0.032607314114044716,
            "auditor_fp_violation": 0.06735717378825569,
            "ave_precision_score": 0.5804984881992399,
            "fpr": 0.3402854006586169,
            "logloss": 2.5166918774529363,
            "mae": 0.4017054675211116,
            "precision": 0.5765027322404371,
            "recall": 0.888421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.807251180969053,
            "auditor_fn_violation": 0.01777277222283266,
            "auditor_fp_violation": 0.018703658684818283,
            "ave_precision_score": 0.7393196718756516,
            "fpr": 0.21820175438596492,
            "logloss": 5.119667584271901,
            "mae": 0.29674471157919596,
            "precision": 0.6721581548599671,
            "recall": 0.8517745302713987
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7790101387789488,
            "auditor_fn_violation": 0.030883355479808194,
            "auditor_fp_violation": 0.011802737187685682,
            "ave_precision_score": 0.7020506925825214,
            "fpr": 0.2283205268935236,
            "logloss": 5.846016257158775,
            "mae": 0.31829956810136517,
            "precision": 0.654485049833887,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7334411636293485,
            "auditor_fn_violation": 0.015746895945500505,
            "auditor_fp_violation": 0.008414873789554715,
            "ave_precision_score": 0.73509662464794,
            "fpr": 0.12938596491228072,
            "logloss": 0.7520725646474612,
            "mae": 0.38676289959173454,
            "precision": 0.7223529411764706,
            "recall": 0.6409185803757829
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7567532013370017,
            "auditor_fn_violation": 0.009631983361257153,
            "auditor_fp_violation": 0.022089849847430496,
            "ave_precision_score": 0.757223017280076,
            "fpr": 0.13391877058177826,
            "logloss": 0.7336049296491315,
            "mae": 0.3810936469670577,
            "precision": 0.7156177156177156,
            "recall": 0.6463157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8488206918109804,
            "auditor_fn_violation": 0.005454986631505696,
            "auditor_fp_violation": 0.02174243345083263,
            "ave_precision_score": 0.8491233280806807,
            "fpr": 0.3826754385964912,
            "logloss": 1.1934098110284663,
            "mae": 0.3860955772096324,
            "precision": 0.5717791411042945,
            "recall": 0.9728601252609603
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.8426462703047142,
            "auditor_fn_violation": 0.006678606505286268,
            "auditor_fp_violation": 0.019282671527407137,
            "ave_precision_score": 0.8429656206869253,
            "fpr": 0.3765093304061471,
            "logloss": 1.198572647098704,
            "mae": 0.3874764663144807,
            "precision": 0.572851805728518,
            "recall": 0.968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.762609649122807,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5252192982456141,
            "fpr": 0.47478070175438597,
            "logloss": 16.398724127942543,
            "mae": 0.47478070175438597,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7607025246981339,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5214050493962679,
            "fpr": 0.47859495060373214,
            "logloss": 16.530466665928234,
            "mae": 0.47859495060373214,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7643576201714881,
            "auditor_fn_violation": 0.001611544518917341,
            "auditor_fp_violation": 0.009306247720918927,
            "ave_precision_score": 0.7383669743409887,
            "fpr": 0.09320175438596491,
            "logloss": 0.5740128838729303,
            "mae": 0.39685296232959155,
            "precision": 0.7880299251870324,
            "recall": 0.6597077244258872
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7714141970063653,
            "auditor_fn_violation": 0.008090588711075175,
            "auditor_fp_violation": 0.003912426107010142,
            "ave_precision_score": 0.7486535527814775,
            "fpr": 0.09440175631174534,
            "logloss": 0.5720646835909592,
            "mae": 0.3974717146217103,
            "precision": 0.7806122448979592,
            "recall": 0.6442105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7162426443758156,
            "auditor_fn_violation": 0.0055213712778815534,
            "auditor_fp_violation": 0.03438120416514728,
            "ave_precision_score": 0.7121909815896289,
            "fpr": 0.3267543859649123,
            "logloss": 1.0568527733774096,
            "mae": 0.39266965057792497,
            "precision": 0.6,
            "recall": 0.9331941544885177
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7389766868235972,
            "auditor_fn_violation": 0.009558033393032527,
            "auditor_fp_violation": 0.019559612886333202,
            "ave_precision_score": 0.7338651328362996,
            "fpr": 0.3238199780461032,
            "logloss": 1.1283535337795263,
            "mae": 0.39697343142297975,
            "precision": 0.597544338335607,
            "recall": 0.9221052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6949701425290133,
            "mae": 0.5006371386545269,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6947405973112841,
            "mae": 0.5005231728014647,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 9675,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.38778704305405265,
            "auditor_fn_violation": 0.000542522799692343,
            "auditor_fp_violation": 0.004375835663060654,
            "ave_precision_score": 0.5233946719245157,
            "fpr": 0.013157894736842105,
            "logloss": 18.025579354995912,
            "mae": 0.5320079344234903,
            "precision": 0.29411764705882354,
            "recall": 0.010438413361169102
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.4703664646320748,
            "auditor_fn_violation": 0.002994973713097237,
            "auditor_fp_violation": 0.0023162368201089644,
            "ave_precision_score": 0.5216566020825592,
            "fpr": 0.008781558726673985,
            "logloss": 17.700142632601143,
            "mae": 0.5240902639843695,
            "precision": 0.42857142857142855,
            "recall": 0.01263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5757504856593114,
            "auditor_fn_violation": 0.011317437644214935,
            "auditor_fp_violation": 0.01780215550423403,
            "ave_precision_score": 0.5851639257487727,
            "fpr": 0.11293859649122807,
            "logloss": 1.6097954423796907,
            "mae": 0.4872366624829163,
            "precision": 0.6068702290076335,
            "recall": 0.33194154488517746
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5457396219917647,
            "auditor_fn_violation": 0.0020590444277543553,
            "auditor_fp_violation": 0.017870270596884164,
            "ave_precision_score": 0.5441482354753303,
            "fpr": 0.1251372118551043,
            "logloss": 1.7241276719886403,
            "mae": 0.5106939182194558,
            "precision": 0.5346938775510204,
            "recall": 0.27578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.787626610852919,
            "auditor_fn_violation": 0.016433633666630046,
            "auditor_fp_violation": 0.016032069203030686,
            "ave_precision_score": 0.7031140788875048,
            "fpr": 0.1600877192982456,
            "logloss": 0.5996896940089861,
            "mae": 0.39035878608232005,
            "precision": 0.7038539553752535,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7723874037319971,
            "auditor_fn_violation": 0.012668553931480735,
            "auditor_fp_violation": 0.02574799343397215,
            "ave_precision_score": 0.6817132013552117,
            "fpr": 0.16575192096597147,
            "logloss": 0.6197233271425932,
            "mae": 0.3978087676954254,
            "precision": 0.6880165289256198,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7623379975025899,
            "auditor_fn_violation": 0.008371332820569167,
            "auditor_fp_violation": 0.019977411774239305,
            "ave_precision_score": 0.7424972786198576,
            "fpr": 0.36403508771929827,
            "logloss": 2.0991385085858,
            "mae": 0.40671348148599507,
            "precision": 0.5660130718954248,
            "recall": 0.9039665970772442
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.7540651861977956,
            "auditor_fn_violation": 0.008122941822173439,
            "auditor_fp_violation": 0.014491586017986087,
            "ave_precision_score": 0.7311956175489831,
            "fpr": 0.3940724478594951,
            "logloss": 2.4690969256907125,
            "mae": 0.420500659844634,
            "precision": 0.5455696202531646,
            "recall": 0.9073684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7492908798495657,
            "auditor_fn_violation": 0.027279511409002675,
            "auditor_fp_violation": 0.04546007049957458,
            "ave_precision_score": 0.7044649903045341,
            "fpr": 0.3026315789473684,
            "logloss": 0.6187332993708856,
            "mae": 0.4152914926545284,
            "precision": 0.6062767475035663,
            "recall": 0.8872651356993737
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7364985991987967,
            "auditor_fn_violation": 0.02717892425905598,
            "auditor_fp_violation": 0.04309207544889677,
            "ave_precision_score": 0.6982923100975735,
            "fpr": 0.27991218441273324,
            "logloss": 0.6065310433829579,
            "mae": 0.4135150779824567,
            "precision": 0.6199701937406855,
            "recall": 0.8757894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.733534504137049,
            "auditor_fn_violation": 0.0038228399809544806,
            "auditor_fp_violation": 0.007017037397188121,
            "ave_precision_score": 0.6435875214904313,
            "fpr": 0.18530701754385964,
            "logloss": 0.6392637119045568,
            "mae": 0.44106853882406366,
            "precision": 0.674373795761079,
            "recall": 0.7306889352818372
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7344749141880405,
            "auditor_fn_violation": 0.013405742677219945,
            "auditor_fp_violation": 0.016545987371474044,
            "ave_precision_score": 0.6450735628940079,
            "fpr": 0.1756311745334797,
            "logloss": 0.6399318216777127,
            "mae": 0.44083937601841633,
            "precision": 0.6780684104627767,
            "recall": 0.7094736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6235078773609158,
            "auditor_fn_violation": 0.005228363183532943,
            "auditor_fp_violation": 0.012390604108423487,
            "ave_precision_score": 0.6218788192161265,
            "fpr": 0.08442982456140351,
            "logloss": 2.043378275055928,
            "mae": 0.48783708499397843,
            "precision": 0.6225490196078431,
            "recall": 0.2651356993736952
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5941259361698594,
            "auditor_fn_violation": 0.0015252180946328604,
            "auditor_fp_violation": 0.015083233466600872,
            "ave_precision_score": 0.5863235201237214,
            "fpr": 0.09110867178924259,
            "logloss": 2.202771580057557,
            "mae": 0.506898252049136,
            "precision": 0.576530612244898,
            "recall": 0.23789473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7271496057907504,
            "auditor_fn_violation": 0.011024429549866332,
            "auditor_fp_violation": 0.009597463635995304,
            "ave_precision_score": 0.7217063484448935,
            "fpr": 0.0668859649122807,
            "logloss": 2.113834711943313,
            "mae": 0.447040790132824,
            "precision": 0.7095238095238096,
            "recall": 0.31106471816283926
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.68208397393193,
            "auditor_fn_violation": 0.006006123981743614,
            "auditor_fp_violation": 0.0057200978861821385,
            "ave_precision_score": 0.6793398895895847,
            "fpr": 0.06915477497255763,
            "logloss": 2.2598839724829505,
            "mae": 0.477127822047347,
            "precision": 0.6480446927374302,
            "recall": 0.24421052631578946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7365763062313098,
            "auditor_fn_violation": 0.12826429330110245,
            "auditor_fp_violation": 0.1157165430898262,
            "ave_precision_score": 0.7370263756612063,
            "fpr": 0.26096491228070173,
            "logloss": 2.2406847436735537,
            "mae": 0.4637181214640513,
            "precision": 0.5333333333333333,
            "recall": 0.5678496868475992
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7428113122407953,
            "auditor_fn_violation": 0.12726558437806923,
            "auditor_fp_violation": 0.11475442854409411,
            "ave_precision_score": 0.7431650226139023,
            "fpr": 0.2327113062568606,
            "logloss": 2.217549911767077,
            "mae": 0.44734597314809865,
            "precision": 0.5517970401691332,
            "recall": 0.5494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.7236233789796267,
            "auditor_fn_violation": 0.0014352818371607546,
            "auditor_fp_violation": 0.0006482719500830601,
            "ave_precision_score": 0.7523015883344562,
            "fpr": 0.006578947368421052,
            "logloss": 5.445676809821705,
            "mae": 0.5279286366541053,
            "precision": 0.3333333333333333,
            "recall": 0.006263048016701462
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.7066453239185365,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0014048479843704368,
            "ave_precision_score": 0.7485710386413995,
            "fpr": 0.0021953896816684962,
            "logloss": 5.48135236810802,
            "mae": 0.5237672876532897,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8138170572382564,
            "auditor_fn_violation": 0.02598386624180495,
            "auditor_fp_violation": 0.014601312750698921,
            "ave_precision_score": 0.8001202635713386,
            "fpr": 0.0800438596491228,
            "logloss": 0.5639343561077956,
            "mae": 0.35987739865014556,
            "precision": 0.7994505494505495,
            "recall": 0.6075156576200418
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8318525148773362,
            "auditor_fn_violation": 0.023707897625512737,
            "auditor_fp_violation": 0.011188430900613298,
            "ave_precision_score": 0.8128050202369015,
            "fpr": 0.06476399560922064,
            "logloss": 0.554060886496834,
            "mae": 0.35446785252161006,
            "precision": 0.8314285714285714,
            "recall": 0.6126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6210334160684821,
            "auditor_fn_violation": 0.011310570267003625,
            "auditor_fp_violation": 0.01509511365017625,
            "ave_precision_score": 0.6168414990384313,
            "fpr": 0.3355263157894737,
            "logloss": 0.7588565807330393,
            "mae": 0.45483688509761633,
            "precision": 0.5578034682080925,
            "recall": 0.8058455114822547
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6428494770039033,
            "auditor_fn_violation": 0.00423825755387371,
            "auditor_fp_violation": 0.010395371554597738,
            "ave_precision_score": 0.6365995571176449,
            "fpr": 0.3611416026344676,
            "logloss": 0.7760261479358478,
            "mae": 0.4673690526734968,
            "precision": 0.5366197183098591,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7055742618283314,
            "auditor_fn_violation": 0.00026782771124052345,
            "auditor_fp_violation": 0.008989708682792434,
            "ave_precision_score": 0.7035434705056188,
            "fpr": 0.12390350877192982,
            "logloss": 0.6618499446702983,
            "mae": 0.41296065379783775,
            "precision": 0.7315914489311164,
            "recall": 0.6430062630480167
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6840998772126335,
            "auditor_fn_violation": 0.000843491825062109,
            "auditor_fp_violation": 0.006477910150152579,
            "ave_precision_score": 0.6910503124410832,
            "fpr": 0.12184412733260154,
            "logloss": 0.6704324990075371,
            "mae": 0.4192125859959654,
            "precision": 0.7394366197183099,
            "recall": 0.6631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.6148524771077254,
            "auditor_fn_violation": 0.0072061678203860415,
            "auditor_fp_violation": 0.008022365382277871,
            "ave_precision_score": 0.540684826602029,
            "fpr": 0.0800438596491228,
            "logloss": 0.8581942647942841,
            "mae": 0.5002914181207878,
            "precision": 0.5989010989010989,
            "recall": 0.22755741127348644
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5742089612769791,
            "auditor_fn_violation": 0.0049407822520076495,
            "auditor_fp_violation": 0.00736915779615102,
            "ave_precision_score": 0.5238826332690569,
            "fpr": 0.0889132821075741,
            "logloss": 0.8759869781411604,
            "mae": 0.5075729870933602,
            "precision": 0.5344827586206896,
            "recall": 0.1957894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8306118974094115,
            "auditor_fn_violation": 0.007119181042376296,
            "auditor_fp_violation": 0.017328613103196788,
            "ave_precision_score": 0.7624863880578201,
            "fpr": 0.12171052631578948,
            "logloss": 0.5448683437440046,
            "mae": 0.3523921988937154,
            "precision": 0.758695652173913,
            "recall": 0.7286012526096033
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8273462982683659,
            "auditor_fn_violation": 0.008370212028424522,
            "auditor_fp_violation": 0.0125580318029386,
            "ave_precision_score": 0.7673546805405844,
            "fpr": 0.10976948408342481,
            "logloss": 0.5565668605848837,
            "mae": 0.3581428409244305,
            "precision": 0.771689497716895,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.8005404551119975,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.7446935949562088,
            "fpr": 0.4682017543859649,
            "logloss": 6.724527948628555,
            "mae": 0.469265274744415,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8038222048949529,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.7476673465009004,
            "fpr": 0.47200878155872666,
            "logloss": 6.706552922611834,
            "mae": 0.4719793212653921,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6105077108695615,
            "auditor_fn_violation": 0.02607314214555178,
            "auditor_fp_violation": 0.025034439447348168,
            "ave_precision_score": 0.5939247953733103,
            "fpr": 0.08223684210526316,
            "logloss": 0.7137086634638085,
            "mae": 0.48504554503188846,
            "precision": 0.6606334841628959,
            "recall": 0.3048016701461378
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5954352750558639,
            "auditor_fn_violation": 0.02771968340169855,
            "auditor_fp_violation": 0.02698415895426943,
            "ave_precision_score": 0.5841421686422762,
            "fpr": 0.0889132821075741,
            "logloss": 0.7145060698108566,
            "mae": 0.4854434753157828,
            "precision": 0.625,
            "recall": 0.28421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7671505502762497,
            "auditor_fn_violation": 0.006535453979416182,
            "auditor_fp_violation": 0.01780215550423404,
            "ave_precision_score": 0.7668883350716921,
            "fpr": 0.20065789473684212,
            "logloss": 0.5781635970498141,
            "mae": 0.3924239856076607,
            "precision": 0.6844827586206896,
            "recall": 0.8288100208768268
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7650957967884832,
            "auditor_fn_violation": 0.006948986076607549,
            "auditor_fp_violation": 0.01954702464274565,
            "ave_precision_score": 0.7648727799331203,
            "fpr": 0.21734357848518113,
            "logloss": 0.5925410534677755,
            "mae": 0.3995756137498647,
            "precision": 0.6649746192893401,
            "recall": 0.8273684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 9675,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.82600172798738,
            "auditor_fn_violation": 0.00918855070871333,
            "auditor_fp_violation": 0.0003292005996515553,
            "ave_precision_score": 0.7831196331854271,
            "fpr": 0.07017543859649122,
            "logloss": 0.5291270228685659,
            "mae": 0.3509195480463013,
            "precision": 0.8363171355498721,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8288505937892989,
            "auditor_fn_violation": 0.010140389392801433,
            "auditor_fp_violation": 0.004159155681326096,
            "ave_precision_score": 0.7885831097216791,
            "fpr": 0.07025246981339188,
            "logloss": 0.5269639241138846,
            "mae": 0.3509897278247628,
            "precision": 0.8328981723237598,
            "recall": 0.671578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6385114082848073,
            "auditor_fn_violation": 0.003019356847232905,
            "auditor_fp_violation": 0.004953202868603375,
            "ave_precision_score": 0.6389500898606508,
            "fpr": 0.40460526315789475,
            "logloss": 1.0423177775523884,
            "mae": 0.4271275851581442,
            "precision": 0.5564903846153846,
            "recall": 0.9665970772442589
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6294049066273593,
            "auditor_fn_violation": 0.001548327459703045,
            "auditor_fp_violation": 0.010110877249519128,
            "ave_precision_score": 0.6309406007358737,
            "fpr": 0.3918770581778266,
            "logloss": 1.0582152010946868,
            "mae": 0.4299447829421082,
            "precision": 0.5625,
            "recall": 0.9663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.5410988902125023,
            "auditor_fn_violation": 0.04557191517415669,
            "auditor_fp_violation": 0.09557706332806616,
            "ave_precision_score": 0.5302447454920389,
            "fpr": 0.29714912280701755,
            "logloss": 0.7338147951792342,
            "mae": 0.445020460376614,
            "precision": 0.5961251862891207,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.569030701092525,
            "auditor_fn_violation": 0.04416199664914207,
            "auditor_fp_violation": 0.10134039617720218,
            "ave_precision_score": 0.5558074051017139,
            "fpr": 0.2678375411635565,
            "logloss": 0.6971389570525677,
            "mae": 0.42957137137422446,
            "precision": 0.6193447737909517,
            "recall": 0.8357894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8078370644320478,
            "auditor_fn_violation": 0.0049994506098231,
            "auditor_fp_violation": 0.01418854584498197,
            "ave_precision_score": 0.799298670933817,
            "fpr": 0.14035087719298245,
            "logloss": 0.6555850971854842,
            "mae": 0.3711796907837769,
            "precision": 0.7282377919320594,
            "recall": 0.7160751565762005
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8348755185670549,
            "auditor_fn_violation": 0.01271015078860709,
            "auditor_fp_violation": 0.0088621234856343,
            "ave_precision_score": 0.8231309564348661,
            "fpr": 0.13172338090010977,
            "logloss": 0.6064152538569265,
            "mae": 0.3620811844500699,
            "precision": 0.7446808510638298,
            "recall": 0.7368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6829796046594904,
            "auditor_fn_violation": 0.0691682232721679,
            "auditor_fp_violation": 0.018308617965236418,
            "ave_precision_score": 0.6839732766074755,
            "fpr": 0.046052631578947366,
            "logloss": 0.7617923555040634,
            "mae": 0.44799714414361996,
            "precision": 0.7653631284916201,
            "recall": 0.2860125260960334
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6822194992385495,
            "auditor_fn_violation": 0.06523773759315965,
            "auditor_fp_violation": 0.017915588273799337,
            "ave_precision_score": 0.6965002604819588,
            "fpr": 0.042810098792535674,
            "logloss": 0.7349073162980871,
            "mae": 0.44045444869290135,
            "precision": 0.7784090909090909,
            "recall": 0.28842105263157897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7730270162467888,
            "auditor_fn_violation": 0.018866974325165743,
            "auditor_fp_violation": 0.011818301527490789,
            "ave_precision_score": 0.6463617654021483,
            "fpr": 0.14144736842105263,
            "logloss": 0.6247634098281126,
            "mae": 0.43576616816766256,
            "precision": 0.708803611738149,
            "recall": 0.6555323590814196
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7689387002740128,
            "auditor_fn_violation": 0.009680513027904559,
            "auditor_fp_violation": 0.022039496873080298,
            "ave_precision_score": 0.6404391983008343,
            "fpr": 0.145993413830955,
            "logloss": 0.6266760304667113,
            "mae": 0.4364518321210785,
            "precision": 0.701123595505618,
            "recall": 0.6568421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.45349924311583323,
            "auditor_fn_violation": 0.014936545434567631,
            "auditor_fp_violation": 0.004426481909160895,
            "ave_precision_score": 0.44374277950549224,
            "fpr": 0.38048245614035087,
            "logloss": 8.171568097414896,
            "mae": 0.4738466994780341,
            "precision": 0.535475234270415,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.4806161813319131,
            "auditor_fn_violation": 0.012095441677739908,
            "auditor_fp_violation": 0.014753421484607098,
            "ave_precision_score": 0.45954084454839556,
            "fpr": 0.36882546652030734,
            "logloss": 7.642631398908959,
            "mae": 0.4574957985687301,
            "precision": 0.5397260273972603,
            "recall": 0.8294736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.724322128585564,
            "auditor_fn_violation": 0.02657217155623924,
            "auditor_fp_violation": 0.022917426360358165,
            "ave_precision_score": 0.5831600627371859,
            "fpr": 0.2149122807017544,
            "logloss": 0.6727447701912633,
            "mae": 0.4745333079706159,
            "precision": 0.6141732283464567,
            "recall": 0.651356993736952
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.728241270677579,
            "auditor_fn_violation": 0.015182852851117925,
            "auditor_fp_violation": 0.00936565322913625,
            "ave_precision_score": 0.5884137893534499,
            "fpr": 0.2030735455543359,
            "logloss": 0.6670176235963416,
            "mae": 0.47186725670890933,
            "precision": 0.6247464503042597,
            "recall": 0.6484210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8158091124601351,
            "auditor_fn_violation": 0.0169555543346885,
            "auditor_fp_violation": 0.008893480815201978,
            "ave_precision_score": 0.816428500483104,
            "fpr": 0.08881578947368421,
            "logloss": 0.9312422837198273,
            "mae": 0.3633192598357417,
            "precision": 0.7949367088607595,
            "recall": 0.6555323590814196
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8198631072225759,
            "auditor_fn_violation": 0.013791669073892206,
            "auditor_fp_violation": 0.004662685424828045,
            "ave_precision_score": 0.820655808488892,
            "fpr": 0.07903402854006586,
            "logloss": 0.815351487230006,
            "mae": 0.35348448763597895,
            "precision": 0.8095238095238095,
            "recall": 0.6442105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6209701250063554,
            "auditor_fn_violation": 0.02227319342196828,
            "auditor_fp_violation": 0.020339532433856004,
            "ave_precision_score": 0.6228648031090905,
            "fpr": 0.08881578947368421,
            "logloss": 0.6848046742959284,
            "mae": 0.4809949908144118,
            "precision": 0.6538461538461539,
            "recall": 0.31941544885177453
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6124085922132155,
            "auditor_fn_violation": 0.021445490785140693,
            "auditor_fp_violation": 0.01443619774620087,
            "ave_precision_score": 0.6134848609085317,
            "fpr": 0.08122941822173436,
            "logloss": 0.6899871064606324,
            "mae": 0.482133917960325,
            "precision": 0.645933014354067,
            "recall": 0.28421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8327009877633573,
            "auditor_fn_violation": 0.005127641651100614,
            "auditor_fp_violation": 0.008863093067541836,
            "ave_precision_score": 0.7286886077072642,
            "fpr": 0.11732456140350878,
            "logloss": 0.5685335764010109,
            "mae": 0.36002327420566166,
            "precision": 0.7770833333333333,
            "recall": 0.778705636743215
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7988560309924705,
            "auditor_fn_violation": 0.011219596741579532,
            "auditor_fp_violation": 0.008489511475442862,
            "ave_precision_score": 0.6845429281477281,
            "fpr": 0.1350164654226125,
            "logloss": 0.5948612836644738,
            "mae": 0.3782390526043886,
            "precision": 0.7415966386554622,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.692852499847087,
            "auditor_fn_violation": 0.021394169138922465,
            "auditor_fp_violation": 0.015424314249827814,
            "ave_precision_score": 0.6751786151990515,
            "fpr": 0.14473684210526316,
            "logloss": 5.021770953852058,
            "mae": 0.3594991613000645,
            "precision": 0.6937354988399071,
            "recall": 0.6242171189979123
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.6733814684439563,
            "auditor_fn_violation": 0.016255127390374956,
            "auditor_fp_violation": 0.020380366368241372,
            "ave_precision_score": 0.6589315708791481,
            "fpr": 0.132821075740944,
            "logloss": 5.219789812487592,
            "mae": 0.3626817263436873,
            "precision": 0.6967418546365914,
            "recall": 0.5852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7445054556587204,
            "auditor_fn_violation": 0.017589642163864782,
            "auditor_fp_violation": 0.006282666828734659,
            "ave_precision_score": 0.7460637870209802,
            "fpr": 0.16776315789473684,
            "logloss": 0.7369381521927495,
            "mae": 0.3550768250848673,
            "precision": 0.6915322580645161,
            "recall": 0.7160751565762005
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7492229460142312,
            "auditor_fn_violation": 0.015529493327170844,
            "auditor_fp_violation": 0.0212388845809122,
            "ave_precision_score": 0.7501892401688813,
            "fpr": 0.1690450054884742,
            "logloss": 0.7306291828500174,
            "mae": 0.35238085078171627,
            "precision": 0.6850715746421268,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 9675,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7575469253731926,
            "auditor_fn_violation": 0.008153865875544813,
            "auditor_fp_violation": 0.018903711356914234,
            "ave_precision_score": 0.7568902219351827,
            "fpr": 0.21052631578947367,
            "logloss": 1.3565008774548388,
            "mae": 0.31936144461060356,
            "precision": 0.6643356643356644,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7625081659229884,
            "auditor_fn_violation": 0.009742908313594081,
            "auditor_fp_violation": 0.027694135892607184,
            "ave_precision_score": 0.7601406761778808,
            "fpr": 0.20197585071350166,
            "logloss": 1.4358876410569357,
            "mae": 0.32658618254133986,
            "precision": 0.6654545454545454,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7029574969704951,
            "auditor_fn_violation": 0.01605821704574589,
            "auditor_fp_violation": 0.002466472185081643,
            "ave_precision_score": 0.699194088185583,
            "fpr": 0.04824561403508772,
            "logloss": 0.8670922954886042,
            "mae": 0.44448585911825494,
            "precision": 0.7317073170731707,
            "recall": 0.25052192066805845
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6680182921688158,
            "auditor_fn_violation": 0.005842047489745234,
            "auditor_fp_violation": 0.004340426388986798,
            "ave_precision_score": 0.6659128795110442,
            "fpr": 0.050493962678375415,
            "logloss": 0.9235656548609747,
            "mae": 0.4576011791372412,
            "precision": 0.6933333333333334,
            "recall": 0.21894736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7968383132270359,
            "auditor_fn_violation": 0.009190839834450428,
            "auditor_fp_violation": 0.0027348972894129116,
            "ave_precision_score": 0.7937139883439881,
            "fpr": 0.10087719298245613,
            "logloss": 0.556207701038058,
            "mae": 0.37059755637228753,
            "precision": 0.77,
            "recall": 0.6430062630480167
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7632683036347145,
            "auditor_fn_violation": 0.00365359061759779,
            "auditor_fp_violation": 0.008756382239498888,
            "ave_precision_score": 0.7602355670116635,
            "fpr": 0.1163556531284303,
            "logloss": 0.5902541280508593,
            "mae": 0.3806871376792633,
            "precision": 0.7329974811083123,
            "recall": 0.6126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8560842576528671,
            "auditor_fn_violation": 0.02028852140790389,
            "auditor_fp_violation": 0.03814675256270006,
            "ave_precision_score": 0.8563510615984367,
            "fpr": 0.2565789473684211,
            "logloss": 0.5755555696065578,
            "mae": 0.343765474758887,
            "precision": 0.6517857142857143,
            "recall": 0.9144050104384134
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8488387889575892,
            "auditor_fn_violation": 0.01877635911953319,
            "auditor_fp_violation": 0.045851418443287446,
            "ave_precision_score": 0.8494121527215898,
            "fpr": 0.25905598243688255,
            "logloss": 0.5688870491135066,
            "mae": 0.3409000106971674,
            "precision": 0.6482861400894188,
            "recall": 0.9157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6833291826730512,
            "auditor_fn_violation": 0.01586135223235544,
            "auditor_fp_violation": 0.017212126737166246,
            "ave_precision_score": 0.6634430469995924,
            "fpr": 0.06469298245614036,
            "logloss": 1.8910365038904986,
            "mae": 0.47711025833549475,
            "precision": 0.700507614213198,
            "recall": 0.2881002087682672
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6312875850960141,
            "auditor_fn_violation": 0.004698133918770584,
            "auditor_fp_violation": 0.009984994813643644,
            "ave_precision_score": 0.6240929106491123,
            "fpr": 0.06805708013172337,
            "logloss": 2.0125287314184956,
            "mae": 0.49877245514653623,
            "precision": 0.6436781609195402,
            "recall": 0.23578947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8347045991881364,
            "auditor_fn_violation": 0.01612002344064755,
            "auditor_fp_violation": 0.005836979863052554,
            "ave_precision_score": 0.8351238910269488,
            "fpr": 0.06140350877192982,
            "logloss": 0.5338045964064948,
            "mae": 0.3459173271824655,
            "precision": 0.8386167146974063,
            "recall": 0.6075156576200418
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.844333108382883,
            "auditor_fn_violation": 0.010394592408573577,
            "auditor_fp_violation": 0.006908428080846738,
            "ave_precision_score": 0.8445852924080108,
            "fpr": 0.04939626783754116,
            "logloss": 0.5241892690167211,
            "mae": 0.34447865080166074,
            "precision": 0.8644578313253012,
            "recall": 0.6042105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 9675,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6574131064693695,
            "auditor_fn_violation": 0.006606416877266236,
            "auditor_fp_violation": 0.032411065191847985,
            "ave_precision_score": 0.6580482798631849,
            "fpr": 0.29276315789473684,
            "logloss": 1.509749047880377,
            "mae": 0.3578010755203495,
            "precision": 0.6119186046511628,
            "recall": 0.8789144050104384
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6364035940421153,
            "auditor_fn_violation": 0.01085909064648449,
            "auditor_fp_violation": 0.024433780803432063,
            "ave_precision_score": 0.6357275860532978,
            "fpr": 0.3062568605927552,
            "logloss": 1.680834072736729,
            "mae": 0.3720821032713492,
            "precision": 0.5962373371924746,
            "recall": 0.8673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7878817210466114,
            "auditor_fn_violation": 0.01764458118155514,
            "auditor_fp_violation": 0.018237713220696092,
            "ave_precision_score": 0.7171041668954579,
            "fpr": 0.1600877192982456,
            "logloss": 0.5934264364323771,
            "mae": 0.4096942588098739,
            "precision": 0.7026476578411406,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.761588213451489,
            "auditor_fn_violation": 0.014669824946559596,
            "auditor_fp_violation": 0.026372370315914564,
            "ave_precision_score": 0.6882825872326167,
            "fpr": 0.16794731064763996,
            "logloss": 0.6102142663627682,
            "mae": 0.41748499382863846,
            "precision": 0.6838842975206612,
            "recall": 0.6968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.762609649122807,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5252192982456141,
            "fpr": 0.47478070175438597,
            "logloss": 0.6920449499615675,
            "mae": 0.4991931100947815,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7607025246981339,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5214050493962679,
            "fpr": 0.47859495060373214,
            "logloss": 0.6922891066141565,
            "mae": 0.49931514675347655,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8418755258645199,
            "auditor_fn_violation": 0.006006665934146433,
            "auditor_fp_violation": 0.010038085977067382,
            "ave_precision_score": 0.7343568654190308,
            "fpr": 0.08991228070175439,
            "logloss": 0.5385338266360832,
            "mae": 0.3682855195774321,
            "precision": 0.8106235565819861,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8321945742980428,
            "auditor_fn_violation": 0.007371887457392115,
            "auditor_fp_violation": 0.008580146829273211,
            "ave_precision_score": 0.7212461848036258,
            "fpr": 0.09220636663007684,
            "logloss": 0.5502969699097983,
            "mae": 0.3738886577237712,
            "precision": 0.8014184397163121,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8359146219800032,
            "auditor_fn_violation": 0.014673295974801305,
            "auditor_fp_violation": 0.007460192050565213,
            "ave_precision_score": 0.7831560163812549,
            "fpr": 0.10635964912280702,
            "logloss": 0.5310273237828439,
            "mae": 0.3622526631674223,
            "precision": 0.7882096069868996,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8298643320761974,
            "auditor_fn_violation": 0.012571494598185922,
            "auditor_fp_violation": 0.010654689372501237,
            "ave_precision_score": 0.7799426218504955,
            "fpr": 0.1141602634467618,
            "logloss": 0.538732746900698,
            "mae": 0.36691799759864807,
            "precision": 0.7683741648106904,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8448865755508861,
            "auditor_fn_violation": 0.009449511042742558,
            "auditor_fp_violation": 0.000283618978161344,
            "ave_precision_score": 0.8451161751144785,
            "fpr": 0.0800438596491228,
            "logloss": 0.5209463149994241,
            "mae": 0.34932665408792163,
            "precision": 0.8201970443349754,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8488966527672656,
            "auditor_fn_violation": 0.0038084233635680875,
            "auditor_fp_violation": 0.008202499521646745,
            "ave_precision_score": 0.8491952349597526,
            "fpr": 0.08122941822173436,
            "logloss": 0.5072395141493709,
            "mae": 0.346378441910238,
            "precision": 0.8163771712158809,
            "recall": 0.6926315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7182616464896647,
            "auditor_fn_violation": 0.003371882210746072,
            "auditor_fp_violation": 0.00535077590049027,
            "ave_precision_score": 0.7173869283992205,
            "fpr": 0.39473684210526316,
            "logloss": 1.51833603396218,
            "mae": 0.40192173403046216,
            "precision": 0.5657418576598311,
            "recall": 0.9791231732776617
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7365211805975493,
            "auditor_fn_violation": 0.0022392974753018668,
            "auditor_fp_violation": 0.012673843643944064,
            "ave_precision_score": 0.7350953445013813,
            "fpr": 0.3929747530186608,
            "logloss": 1.468717623648591,
            "mae": 0.4011801671589194,
            "precision": 0.5644768856447688,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.5774923589040268,
            "auditor_fn_violation": 0.016021591033952308,
            "auditor_fp_violation": 0.028812649406426,
            "ave_precision_score": 0.5786901587419524,
            "fpr": 0.17324561403508773,
            "logloss": 0.6865882768741237,
            "mae": 0.49531574544023005,
            "precision": 0.5741239892183289,
            "recall": 0.44467640918580376
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.5176361963835716,
            "auditor_fn_violation": 0.007004448552776012,
            "auditor_fp_violation": 0.018117000171200114,
            "ave_precision_score": 0.5253104926250529,
            "fpr": 0.18880351262349068,
            "logloss": 0.6891279165575279,
            "mae": 0.49670350211381126,
            "precision": 0.5351351351351351,
            "recall": 0.4168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8354971231806821,
            "auditor_fn_violation": 0.010264439805149628,
            "auditor_fp_violation": 0.00954428507759005,
            "ave_precision_score": 0.8254409695181353,
            "fpr": 0.06469298245614036,
            "logloss": 0.5236529319966692,
            "mae": 0.3321830992823826,
            "precision": 0.8418230563002681,
            "recall": 0.6555323590814196
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8352134195926906,
            "auditor_fn_violation": 0.001719336761222483,
            "auditor_fp_violation": 0.006586169045005488,
            "ave_precision_score": 0.8253588763296121,
            "fpr": 0.06586169045005488,
            "logloss": 0.5369559907694167,
            "mae": 0.3353821557325962,
            "precision": 0.8319327731092437,
            "recall": 0.6252631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7767702124088791,
            "auditor_fn_violation": 0.0073274914844522554,
            "auditor_fp_violation": 0.006984117337222966,
            "ave_precision_score": 0.7784076936071074,
            "fpr": 0.09758771929824561,
            "logloss": 0.5684282371318433,
            "mae": 0.38801079452158566,
            "precision": 0.7807881773399015,
            "recall": 0.6617954070981211
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7389214957946865,
            "auditor_fn_violation": 0.01128892483679011,
            "auditor_fp_violation": 0.006712051480880976,
            "ave_precision_score": 0.7402193008334255,
            "fpr": 0.11306256860592755,
            "logloss": 0.5936737567264432,
            "mae": 0.3990302499205806,
            "precision": 0.7412060301507538,
            "recall": 0.6210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6528328813230011,
            "auditor_fn_violation": 0.05353807273925943,
            "auditor_fp_violation": 0.07589086746890321,
            "ave_precision_score": 0.559723309557554,
            "fpr": 0.22697368421052633,
            "logloss": 0.68363735357105,
            "mae": 0.49074626910059077,
            "precision": 0.5632911392405063,
            "recall": 0.55741127348643
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6426621394869241,
            "auditor_fn_violation": 0.048354035472875374,
            "auditor_fp_violation": 0.07469611979979657,
            "ave_precision_score": 0.5509729055494864,
            "fpr": 0.24698133918770582,
            "logloss": 0.680433568401471,
            "mae": 0.4884317356655548,
            "precision": 0.5351239669421488,
            "recall": 0.5452631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8486561823291848,
            "auditor_fn_violation": 0.04068463172545142,
            "auditor_fp_violation": 0.03065870507677971,
            "ave_precision_score": 0.8489773461359886,
            "fpr": 0.13815789473684212,
            "logloss": 0.5170566467535818,
            "mae": 0.3203756791465965,
            "precision": 0.7509881422924901,
            "recall": 0.7933194154488518
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8516289338426593,
            "auditor_fn_violation": 0.03648275463631637,
            "auditor_fp_violation": 0.035264705586158976,
            "ave_precision_score": 0.8520622842310723,
            "fpr": 0.132821075740944,
            "logloss": 0.5094458834175056,
            "mae": 0.31879868631534336,
            "precision": 0.7515400410677618,
            "recall": 0.7705263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.847120042763789,
            "auditor_fn_violation": 0.0006409552063875765,
            "auditor_fp_violation": 0.0028868360277136316,
            "ave_precision_score": 0.8474181323418607,
            "fpr": 0.4682017543859649,
            "logloss": 1.4313182935663966,
            "mae": 0.4518175411656761,
            "precision": 0.5281767955801105,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8434702856843785,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002134966112448282,
            "ave_precision_score": 0.8438588162218761,
            "fpr": 0.47200878155872666,
            "logloss": 1.4304848084182817,
            "mae": 0.454902376164198,
            "precision": 0.5248618784530387,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7468399120778392,
            "auditor_fn_violation": 0.006892557594403557,
            "auditor_fp_violation": 0.006373830071715087,
            "ave_precision_score": 0.7665527099773042,
            "fpr": 0.09210526315789473,
            "logloss": 0.5399590088438824,
            "mae": 0.3510103170318823,
            "precision": 0.8055555555555556,
            "recall": 0.7265135699373695
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7526000000059713,
            "auditor_fn_violation": 0.004547923045814328,
            "auditor_fp_violation": 0.009977441867491115,
            "ave_precision_score": 0.766031728296964,
            "fpr": 0.09549945115257959,
            "logloss": 0.5542060033886919,
            "mae": 0.358098755160226,
            "precision": 0.7952941176470588,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 9675,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.764815138214229,
            "auditor_fn_violation": 0.022334999816869937,
            "auditor_fp_violation": 0.01980014991288846,
            "ave_precision_score": 0.7517949299622415,
            "fpr": 0.05921052631578947,
            "logloss": 4.952114157072353,
            "mae": 0.34695360126816177,
            "precision": 0.8258064516129032,
            "recall": 0.534446764091858
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7420879147604013,
            "auditor_fn_violation": 0.030918019527413496,
            "auditor_fp_violation": 0.017875305894319182,
            "ave_precision_score": 0.7274817173250318,
            "fpr": 0.06805708013172337,
            "logloss": 5.2446673901645005,
            "mae": 0.359359029112231,
            "precision": 0.7919463087248322,
            "recall": 0.4968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7762719150647011,
            "auditor_fn_violation": 0.030264531370179103,
            "auditor_fp_violation": 0.06683025404157045,
            "ave_precision_score": 0.7292702958617344,
            "fpr": 0.3684210526315789,
            "logloss": 0.6947982476803811,
            "mae": 0.4028429669153297,
            "precision": 0.5670103092783505,
            "recall": 0.918580375782881
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7818262450161519,
            "auditor_fn_violation": 0.02278121208619793,
            "auditor_fp_violation": 0.07329882476157867,
            "ave_precision_score": 0.7374373031476555,
            "fpr": 0.36223929747530187,
            "logloss": 0.6872684069720659,
            "mae": 0.3999224729124461,
            "precision": 0.5736434108527132,
            "recall": 0.9347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.729192932790593,
            "auditor_fn_violation": 0.014274988096546185,
            "auditor_fp_violation": 0.0016206798752076501,
            "ave_precision_score": 0.7244383152083129,
            "fpr": 0.01644736842105263,
            "logloss": 2.4897622639231294,
            "mae": 0.4489270062930413,
            "precision": 0.8846153846153846,
            "recall": 0.24008350730688935
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.664377882393367,
            "auditor_fn_violation": 0.007924201282569767,
            "auditor_fp_violation": 0.0023942839303517658,
            "ave_precision_score": 0.6663036682388812,
            "fpr": 0.027442371020856202,
            "logloss": 2.6928428721692286,
            "mae": 0.47837331802594996,
            "precision": 0.7807017543859649,
            "recall": 0.18736842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 9675,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8055902018566071,
            "auditor_fn_violation": 0.006958942240779402,
            "auditor_fp_violation": 0.00641687938090029,
            "ave_precision_score": 0.6973735520581253,
            "fpr": 0.11842105263157894,
            "logloss": 0.5996569722147255,
            "mae": 0.40722951434102134,
            "precision": 0.7534246575342466,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7959222772272185,
            "auditor_fn_violation": 0.0033947657288116123,
            "auditor_fp_violation": 0.006495533691175143,
            "ave_precision_score": 0.6837393950882995,
            "fpr": 0.1163556531284303,
            "logloss": 0.5973511893964175,
            "mae": 0.41133062422765726,
            "precision": 0.7476190476190476,
            "recall": 0.6610526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 9675,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7700680180280529,
            "auditor_fn_violation": 0.0009454089294216755,
            "auditor_fp_violation": 0.006196568210364266,
            "ave_precision_score": 0.5439431274813021,
            "fpr": 0.43640350877192985,
            "logloss": 0.6754022962229908,
            "mae": 0.48566167198709753,
            "precision": 0.5441008018327605,
            "recall": 0.9916492693110647
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7639020823188596,
            "auditor_fn_violation": 0.002897914379802415,
            "auditor_fp_violation": 0.0036153435583439896,
            "ave_precision_score": 0.5346589014798246,
            "fpr": 0.446761800219539,
            "logloss": 0.6832487814667524,
            "mae": 0.48947494204690767,
            "precision": 0.5348571428571428,
            "recall": 0.9852631578947368
        }
    }
]