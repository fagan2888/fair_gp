[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5630453861793533,
            "auditor_fn_violation": 0.004905355493998153,
            "auditor_fp_violation": 0.007713911972914744,
            "ave_precision_score": 0.5638652928620507,
            "fpr": 0.4649122807017544,
            "logloss": 0.6920295934114812,
            "mae": 0.498893883994274,
            "precision": 0.5126436781609195,
            "recall": 0.9780701754385965
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5843976992738947,
            "auditor_fn_violation": 0.005043224489615984,
            "auditor_fp_violation": 0.0032505588143832594,
            "ave_precision_score": 0.5867294347161451,
            "fpr": 0.424807903402854,
            "logloss": 0.6900517451085647,
            "mae": 0.49796648374242397,
            "precision": 0.5526011560693641,
            "recall": 0.9598393574297188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6543182132407027,
            "mae": 0.428249123424553,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968854013955,
            "mae": 0.4232362835912359,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6543182139518603,
            "mae": 0.4282491247316724,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968839898503,
            "mae": 0.42323628375480515,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6543182140516627,
            "mae": 0.42824912384936686,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968869062365,
            "mae": 0.42323628427822685,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6543182150639075,
            "mae": 0.42824912545058813,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968851626399,
            "mae": 0.4232362844417961,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7048878980077175,
            "auditor_fn_violation": 0.06653970452446908,
            "auditor_fp_violation": 0.025161588180978762,
            "ave_precision_score": 0.6789211360189891,
            "fpr": 0.06140350877192982,
            "logloss": 0.6367532184066393,
            "mae": 0.4249380328937581,
            "precision": 0.7878787878787878,
            "recall": 0.45614035087719296
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7280278396345833,
            "auditor_fn_violation": 0.06576470536371612,
            "auditor_fp_violation": 0.017916612402091203,
            "ave_precision_score": 0.6990041010610419,
            "fpr": 0.05378704720087816,
            "logloss": 0.6322278373878358,
            "mae": 0.42454553137888107,
            "precision": 0.8136882129277566,
            "recall": 0.42971887550200805
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 19863,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7316665240022753,
            "auditor_fn_violation": 0.007675438596491228,
            "auditor_fp_violation": 0.04507156048014775,
            "ave_precision_score": 0.7197708130317187,
            "fpr": 0.34868421052631576,
            "logloss": 1.2740330997244091,
            "mae": 0.4158740885575737,
            "precision": 0.5793650793650794,
            "recall": 0.9605263157894737
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7689746173865472,
            "auditor_fn_violation": 0.011962228717284066,
            "auditor_fp_violation": 0.04223334387616515,
            "ave_precision_score": 0.7589782387168563,
            "fpr": 0.32491767288693746,
            "logloss": 1.1640988542348074,
            "mae": 0.401903538653275,
            "precision": 0.6130718954248366,
            "recall": 0.9417670682730924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7048878980077175,
            "auditor_fn_violation": 0.06653970452446908,
            "auditor_fp_violation": 0.025161588180978762,
            "ave_precision_score": 0.6789211360189891,
            "fpr": 0.06140350877192982,
            "logloss": 0.6367532120357656,
            "mae": 0.42493803400480956,
            "precision": 0.7878787878787878,
            "recall": 0.45614035087719296
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7296918945712869,
            "auditor_fn_violation": 0.06590136616719348,
            "auditor_fp_violation": 0.017916612402091203,
            "ave_precision_score": 0.7007806391745752,
            "fpr": 0.05378704720087816,
            "logloss": 0.6306975763013034,
            "mae": 0.42357107090766816,
            "precision": 0.8150943396226416,
            "recall": 0.43373493975903615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7992728356430365,
            "auditor_fn_violation": 0.017615997229916896,
            "auditor_fp_violation": 0.014946906740535558,
            "ave_precision_score": 0.799630755014578,
            "fpr": 0.15460526315789475,
            "logloss": 0.9126543485277169,
            "mae": 0.27947265311222974,
            "precision": 0.7128309572301426,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8282770456663696,
            "auditor_fn_violation": 0.009024021442520912,
            "auditor_fp_violation": 0.02228081319785352,
            "ave_precision_score": 0.828762938306214,
            "fpr": 0.11745334796926454,
            "logloss": 0.8978106672619413,
            "mae": 0.27661805950955554,
            "precision": 0.7775467775467776,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7831756259500622,
            "auditor_fn_violation": 0.007605705601723614,
            "auditor_fp_violation": 0.0004809172052939368,
            "ave_precision_score": 0.7839524234794922,
            "fpr": 0.007675438596491228,
            "logloss": 1.0633472991139934,
            "mae": 0.4201581888272393,
            "precision": 0.8409090909090909,
            "recall": 0.08114035087719298
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.7952493202495101,
            "auditor_fn_violation": 0.006592781664528588,
            "auditor_fp_violation": 0.0008478563056322643,
            "ave_precision_score": 0.7956816769079926,
            "fpr": 0.005488474204171241,
            "logloss": 1.1804310469540837,
            "mae": 0.4574396473459437,
            "precision": 0.8863636363636364,
            "recall": 0.0783132530120482
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.5622826714747621,
            "auditor_fn_violation": 0.0001947714681440493,
            "auditor_fp_violation": 0.005900854108956605,
            "ave_precision_score": 0.5438847943034596,
            "fpr": 0.3618421052631579,
            "logloss": 0.689714945905516,
            "mae": 0.4974899973981736,
            "precision": 0.5081967213114754,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6047303894371678,
            "auditor_fn_violation": 0.006744871913559843,
            "auditor_fp_violation": 0.01204009111132965,
            "ave_precision_score": 0.5803483660279776,
            "fpr": 0.3446761800219539,
            "logloss": 0.6889029214768989,
            "mae": 0.4970854893735683,
            "precision": 0.5416058394160584,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6543182105149336,
            "mae": 0.4282491237513329,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968853585726,
            "mae": 0.423236284245513,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.654318215135449,
            "mae": 0.4282491254832661,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968851626399,
            "mae": 0.4232362844417961,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8124385858383344,
            "auditor_fn_violation": 0.021172379963065563,
            "auditor_fp_violation": 0.02435364727608496,
            "ave_precision_score": 0.8127276871848739,
            "fpr": 0.15570175438596492,
            "logloss": 0.6200462618663465,
            "mae": 0.304208720622124,
            "precision": 0.7131313131313132,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8280274491014844,
            "auditor_fn_violation": 0.011115813418327538,
            "auditor_fp_violation": 0.023968552238845645,
            "ave_precision_score": 0.8284958563951939,
            "fpr": 0.12403951701427003,
            "logloss": 0.627308860235974,
            "mae": 0.3015636241550957,
            "precision": 0.7655601659751037,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 19863,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7354041991436495,
            "auditor_fn_violation": 0.02522651200369345,
            "auditor_fp_violation": 0.04813019390581718,
            "ave_precision_score": 0.7207608105891012,
            "fpr": 0.23464912280701755,
            "logloss": 1.362088883737576,
            "mae": 0.39434513056375814,
            "precision": 0.6391231028667791,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7639149439278906,
            "auditor_fn_violation": 0.03282504331265788,
            "auditor_fp_violation": 0.0449124634876928,
            "ave_precision_score": 0.7485317574236215,
            "fpr": 0.22283205268935236,
            "logloss": 1.4088705442693963,
            "mae": 0.3902698026393838,
            "precision": 0.6709886547811994,
            "recall": 0.8313253012048193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7089710021387091,
            "auditor_fn_violation": 0.018892832409972304,
            "auditor_fp_violation": 0.012335526315789477,
            "ave_precision_score": 0.6864147317599878,
            "fpr": 0.3618421052631579,
            "logloss": 0.6629878789358278,
            "mae": 0.42784309467268095,
            "precision": 0.541029207232267,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.736261306699505,
            "auditor_fn_violation": 0.021345535820559963,
            "auditor_fp_violation": 0.01355241160632891,
            "ave_precision_score": 0.7103939988934266,
            "fpr": 0.3402854006586169,
            "logloss": 0.64661325475771,
            "mae": 0.4217011173195425,
            "precision": 0.5765027322404371,
            "recall": 0.8473895582329317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6121477441969511,
            "auditor_fn_violation": 0.004078177900892593,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5548464584706423,
            "fpr": 0.0,
            "logloss": 0.6836409660787738,
            "mae": 0.4915684794909076,
            "precision": 1.0,
            "recall": 0.03508771929824561
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.625798977848311,
            "auditor_fn_violation": 0.0016862179783899665,
            "auditor_fp_violation": 0.00061130705421762,
            "ave_precision_score": 0.5776256289010758,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6944936385807783,
            "mae": 0.49688489367095623,
            "precision": 0.9375,
            "recall": 0.030120481927710843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6838884951025874,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6783304187092334,
            "fpr": 0.21162280701754385,
            "logloss": 0.662680881455898,
            "mae": 0.4254892601125073,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7293178379466976,
            "auditor_fn_violation": 0.047835689630090064,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.7032427810241385,
            "fpr": 0.20636663007683864,
            "logloss": 0.6481852229765676,
            "mae": 0.42118451169371995,
            "precision": 0.6284584980237155,
            "recall": 0.6385542168674698
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8123052451963645,
            "auditor_fn_violation": 0.01622374192059095,
            "auditor_fp_violation": 0.02418051708217913,
            "ave_precision_score": 0.8126034209433972,
            "fpr": 0.15789473684210525,
            "logloss": 0.6305561064788358,
            "mae": 0.30084008314659977,
            "precision": 0.7137176938369781,
            "recall": 0.7872807017543859
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8274984737446485,
            "auditor_fn_violation": 0.011254678428312601,
            "auditor_fp_violation": 0.02012529136754705,
            "ave_precision_score": 0.827928415485977,
            "fpr": 0.12184412733260154,
            "logloss": 0.641510579651517,
            "mae": 0.3017386831724623,
            "precision": 0.7692307692307693,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.823876177701836,
            "auditor_fn_violation": 0.011056286549707608,
            "auditor_fp_violation": 0.021872114496768236,
            "ave_precision_score": 0.824125126732803,
            "fpr": 0.17982456140350878,
            "logloss": 0.6437925980046092,
            "mae": 0.29886943377413755,
            "precision": 0.6968576709796673,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8294231557503925,
            "auditor_fn_violation": 0.00898875413839772,
            "auditor_fp_violation": 0.028388568026514783,
            "ave_precision_score": 0.8299991408416103,
            "fpr": 0.15587266739846323,
            "logloss": 0.649431601466757,
            "mae": 0.2977299964881875,
            "precision": 0.7350746268656716,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8148738106398731,
            "auditor_fn_violation": 0.01077735457063712,
            "auditor_fp_violation": 0.025382810095413974,
            "ave_precision_score": 0.8151683151100041,
            "fpr": 0.18859649122807018,
            "logloss": 0.6628855152989366,
            "mae": 0.301374690817068,
            "precision": 0.6889692585895117,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8285598717068247,
            "auditor_fn_violation": 0.005660402311771787,
            "auditor_fp_violation": 0.029954045656663382,
            "ave_precision_score": 0.8289879802390339,
            "fpr": 0.16355653128430298,
            "logloss": 0.6554195413571597,
            "mae": 0.2974018256177105,
            "precision": 0.7310469314079422,
            "recall": 0.8132530120481928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.799765547425058,
            "auditor_fn_violation": 0.017659279778393353,
            "auditor_fp_violation": 0.01260243536472761,
            "ave_precision_score": 0.8001090630668409,
            "fpr": 0.1611842105263158,
            "logloss": 0.9434286725048847,
            "mae": 0.28089741412432784,
            "precision": 0.7100591715976331,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8185050896969315,
            "auditor_fn_violation": 0.008519258152257769,
            "auditor_fp_violation": 0.017238858928936885,
            "ave_precision_score": 0.8190631474402569,
            "fpr": 0.132821075740944,
            "logloss": 0.9549449366559509,
            "mae": 0.28136060959191755,
            "precision": 0.7570281124497992,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.714697587588666,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.7156738902487272,
            "fpr": 0.21162280701754385,
            "logloss": 0.6545306698624791,
            "mae": 0.4283113196296127,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7341420139877023,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.02505295779589255,
            "ave_precision_score": 0.7331048885646368,
            "fpr": 0.2052689352360044,
            "logloss": 0.6401110512504871,
            "mae": 0.4232216278821001,
            "precision": 0.631163708086785,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7926997516308577,
            "auditor_fn_violation": 0.012609649122807015,
            "auditor_fp_violation": 0.017418821175746387,
            "ave_precision_score": 0.793144702808253,
            "fpr": 0.1600877192982456,
            "logloss": 0.9088029823913767,
            "mae": 0.2773516205288065,
            "precision": 0.7176015473887815,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.826298406825816,
            "auditor_fn_violation": 0.010639704812664491,
            "auditor_fp_violation": 0.017472750323594063,
            "ave_precision_score": 0.8265403550455899,
            "fpr": 0.12623490669593854,
            "logloss": 0.878636316030335,
            "mae": 0.2752834449081407,
            "precision": 0.7718253968253969,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8427372703658478,
            "auditor_fn_violation": 0.01579091643582641,
            "auditor_fp_violation": 0.0235168513388735,
            "ave_precision_score": 0.8429611501139506,
            "fpr": 0.21710526315789475,
            "logloss": 0.7738284509404071,
            "mae": 0.2909164812479427,
            "precision": 0.6727272727272727,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8535427844480628,
            "auditor_fn_violation": 0.007313557192546257,
            "auditor_fp_violation": 0.024114734360506374,
            "ave_precision_score": 0.8538525688400042,
            "fpr": 0.18880351262349068,
            "logloss": 0.7026133775478501,
            "mae": 0.27080178957584383,
            "precision": 0.7207792207792207,
            "recall": 0.891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 19863,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7992003156700161,
            "auditor_fn_violation": 0.017726608187134507,
            "auditor_fp_violation": 0.01667820867959373,
            "ave_precision_score": 0.7995556444871005,
            "fpr": 0.14802631578947367,
            "logloss": 0.9140526173861065,
            "mae": 0.2801352614525861,
            "precision": 0.7193347193347194,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8283995568887006,
            "auditor_fn_violation": 0.008085029470241012,
            "auditor_fp_violation": 0.02228081319785352,
            "ave_precision_score": 0.8288982145127776,
            "fpr": 0.11745334796926454,
            "logloss": 0.9056147641856166,
            "mae": 0.2776670777316571,
            "precision": 0.7761506276150628,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 19863,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7353953643433673,
            "auditor_fn_violation": 0.02522651200369345,
            "auditor_fp_violation": 0.04813019390581718,
            "ave_precision_score": 0.7207519891263264,
            "fpr": 0.23464912280701755,
            "logloss": 1.3620582673265715,
            "mae": 0.3943509969377244,
            "precision": 0.6391231028667791,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7639017768944913,
            "auditor_fn_violation": 0.03282504331265788,
            "auditor_fp_violation": 0.0449124634876928,
            "ave_precision_score": 0.7485186066127216,
            "fpr": 0.22283205268935236,
            "logloss": 1.4088383977283339,
            "mae": 0.390272691970635,
            "precision": 0.6709886547811994,
            "recall": 0.8313253012048193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8049153423695874,
            "auditor_fn_violation": 0.014574195906432752,
            "auditor_fp_violation": 0.0183133271775931,
            "ave_precision_score": 0.8052954910469305,
            "fpr": 0.14912280701754385,
            "logloss": 0.7928077867447993,
            "mae": 0.2763620610890345,
            "precision": 0.7263581488933601,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8326329229126861,
            "auditor_fn_violation": 0.008986549931890023,
            "auditor_fp_violation": 0.02145687760303847,
            "ave_precision_score": 0.8329764307385875,
            "fpr": 0.12184412733260154,
            "logloss": 0.7846247224864937,
            "mae": 0.2754478742266658,
            "precision": 0.774390243902439,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8559923186297693,
            "auditor_fn_violation": 0.0156490458602647,
            "auditor_fp_violation": 0.01681286549707603,
            "ave_precision_score": 0.8562059907346136,
            "fpr": 0.16666666666666666,
            "logloss": 0.5580944948433662,
            "mae": 0.2834350598716529,
            "precision": 0.7126654064272212,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8617450462512579,
            "auditor_fn_violation": 0.014481636755584355,
            "auditor_fp_violation": 0.016832206845044297,
            "ave_precision_score": 0.8619541966109073,
            "fpr": 0.12623490669593854,
            "logloss": 0.5541124307494155,
            "mae": 0.27492312216302955,
            "precision": 0.7784200385356455,
            "recall": 0.8112449799196787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.804197371287175,
            "auditor_fn_violation": 0.013487323022468457,
            "auditor_fp_violation": 0.016101108033241007,
            "ave_precision_score": 0.8045537563100943,
            "fpr": 0.16228070175438597,
            "logloss": 0.8692985804857124,
            "mae": 0.27620975154812855,
            "precision": 0.7115009746588694,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8316112784733382,
            "auditor_fn_violation": 0.0046023831880761265,
            "auditor_fp_violation": 0.01811329380214383,
            "ave_precision_score": 0.832123293407592,
            "fpr": 0.12623490669593854,
            "logloss": 0.8419091147389807,
            "mae": 0.27202205123509454,
            "precision": 0.7686116700201208,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8117741866309176,
            "auditor_fn_violation": 0.019700773314866114,
            "auditor_fp_violation": 0.021946656663588797,
            "ave_precision_score": 0.8120743004728738,
            "fpr": 0.15021929824561403,
            "logloss": 0.650207344714959,
            "mae": 0.2960254449900234,
            "precision": 0.7226720647773279,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.830823464765355,
            "auditor_fn_violation": 0.012603652811024562,
            "auditor_fp_violation": 0.01978242784583368,
            "ave_precision_score": 0.8312345405593091,
            "fpr": 0.1163556531284303,
            "logloss": 0.6582493512490935,
            "mae": 0.29493727074129383,
            "precision": 0.7773109243697479,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.7735033555829497,
            "auditor_fn_violation": 0.002221837488457994,
            "auditor_fp_violation": 0.0015870267774699906,
            "ave_precision_score": 0.7745279421097098,
            "fpr": 0.006578947368421052,
            "logloss": 1.3773940652612615,
            "mae": 0.44854171568164075,
            "precision": 0.75,
            "recall": 0.039473684210526314
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.7858493278747513,
            "auditor_fn_violation": 0.005338588161647694,
            "auditor_fp_violation": 0.002392071081721122,
            "ave_precision_score": 0.7863532160519302,
            "fpr": 0.0043907793633369925,
            "logloss": 1.5252557604408952,
            "mae": 0.4868701150375797,
            "precision": 0.875,
            "recall": 0.05622489959839357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8163884746742158,
            "auditor_fn_violation": 0.015016639735303167,
            "auditor_fp_violation": 0.015293167128347185,
            "ave_precision_score": 0.8167096922660231,
            "fpr": 0.15899122807017543,
            "logloss": 0.753265871763478,
            "mae": 0.27429248485008173,
            "precision": 0.716796875,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8380968087879503,
            "auditor_fn_violation": 0.009341427179629606,
            "auditor_fp_violation": 0.019444880037635254,
            "ave_precision_score": 0.8384738554137839,
            "fpr": 0.12733260153677278,
            "logloss": 0.7434606484466892,
            "mae": 0.2710266472004839,
            "precision": 0.7698412698412699,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7452170382832374,
            "auditor_fn_violation": 0.0017697753154816865,
            "auditor_fp_violation": 0.005306921360418613,
            "ave_precision_score": 0.7455873407590822,
            "fpr": 0.46600877192982454,
            "logloss": 1.107739557264523,
            "mae": 0.44236407201561095,
            "precision": 0.5131729667812142,
            "recall": 0.9824561403508771
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7289812378575681,
            "auditor_fn_violation": 0.002080770943268133,
            "auditor_fp_violation": 0.007795493869653401,
            "ave_precision_score": 0.7302818718003613,
            "fpr": 0.4226125137211855,
            "logloss": 1.1873117573626766,
            "mae": 0.42212205985470236,
            "precision": 0.5605022831050228,
            "recall": 0.9859437751004017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7951737865826449,
            "auditor_fn_violation": 0.009156663588796556,
            "auditor_fp_violation": 0.01581255771006464,
            "ave_precision_score": 0.7955290446400743,
            "fpr": 0.18640350877192982,
            "logloss": 0.8937190980127844,
            "mae": 0.28748192499035974,
            "precision": 0.6875,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8188432914529721,
            "auditor_fn_violation": 0.006079201548234652,
            "auditor_fp_violation": 0.025332032755426677,
            "ave_precision_score": 0.8192974751777344,
            "fpr": 0.15587266739846323,
            "logloss": 0.8590146790898033,
            "mae": 0.2852853155298802,
            "precision": 0.7325800376647834,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6592667785392596,
            "auditor_fn_violation": 0.07886801708217914,
            "auditor_fp_violation": 0.03348626500461681,
            "ave_precision_score": 0.6488863447677062,
            "fpr": 0.10197368421052631,
            "logloss": 4.160731917870631,
            "mae": 0.4531838210026174,
            "precision": 0.709375,
            "recall": 0.49780701754385964
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6871385926956202,
            "auditor_fn_violation": 0.07904725377911206,
            "auditor_fp_violation": 0.025619081285233214,
            "ave_precision_score": 0.6742860211112243,
            "fpr": 0.10098792535675083,
            "logloss": 4.5568776867944525,
            "mae": 0.46676490576003477,
            "precision": 0.7228915662650602,
            "recall": 0.4819277108433735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8261317328838756,
            "auditor_fn_violation": 0.012609649122807017,
            "auditor_fp_violation": 0.020140812557710077,
            "ave_precision_score": 0.8267009727939665,
            "fpr": 0.19956140350877194,
            "logloss": 0.6036812905157894,
            "mae": 0.31149523443564886,
            "precision": 0.6761565836298933,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8233448097245415,
            "auditor_fn_violation": 0.01454115033129224,
            "auditor_fp_violation": 0.026339360466507023,
            "ave_precision_score": 0.8237949319060172,
            "fpr": 0.17233809001097694,
            "logloss": 0.6145158855984456,
            "mae": 0.31040636161275814,
            "precision": 0.7176258992805755,
            "recall": 0.8012048192771084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8243400589315615,
            "auditor_fn_violation": 0.011311172668513392,
            "auditor_fp_violation": 0.022045244690674055,
            "ave_precision_score": 0.824590794139352,
            "fpr": 0.19298245614035087,
            "logloss": 0.6627507775487055,
            "mae": 0.2981146231661469,
            "precision": 0.6857142857142857,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.83123807582501,
            "auditor_fn_violation": 0.004077782039243693,
            "auditor_fp_violation": 0.02900253293748987,
            "ave_precision_score": 0.8317245550448998,
            "fpr": 0.16245883644346873,
            "logloss": 0.6549155206259505,
            "mae": 0.2944663375478885,
            "precision": 0.7328519855595668,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8236021876715451,
            "auditor_fn_violation": 0.018258021698984307,
            "auditor_fp_violation": 0.014557363804247473,
            "ave_precision_score": 0.823870148968508,
            "fpr": 0.15570175438596492,
            "logloss": 0.7084225891467061,
            "mae": 0.2790151930660674,
            "precision": 0.7221135029354208,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8266741259147998,
            "auditor_fn_violation": 0.012799827190209797,
            "auditor_fp_violation": 0.017140518228910575,
            "ave_precision_score": 0.8272026296649754,
            "fpr": 0.12623490669593854,
            "logloss": 0.7426543746223474,
            "mae": 0.280939115030321,
            "precision": 0.7690763052208835,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8268300515590874,
            "auditor_fn_violation": 0.011945983379501385,
            "auditor_fp_violation": 0.020167263004001228,
            "ave_precision_score": 0.8281365381609291,
            "fpr": 0.19846491228070176,
            "logloss": 0.5915117508207596,
            "mae": 0.31068540818064083,
            "precision": 0.6762075134168157,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8242861439318853,
            "auditor_fn_violation": 0.012469196214054911,
            "auditor_fp_violation": 0.027293531042438007,
            "ave_precision_score": 0.8247255228237155,
            "fpr": 0.1690450054884742,
            "logloss": 0.6093104939298103,
            "mae": 0.31150068269999603,
            "precision": 0.7194899817850637,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.654318212854361,
            "mae": 0.4282491239474008,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6400968845787915,
            "mae": 0.42323628378751904,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8015758380399175,
            "auditor_fn_violation": 0.016216528162511547,
            "auditor_fp_violation": 0.013874461372730086,
            "ave_precision_score": 0.801920247350379,
            "fpr": 0.15570175438596492,
            "logloss": 0.9351496976130382,
            "mae": 0.27807191560709904,
            "precision": 0.7154308617234469,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8258224900213975,
            "auditor_fn_violation": 0.007035827172576141,
            "auditor_fp_violation": 0.019960504248584032,
            "ave_precision_score": 0.8263628914380418,
            "fpr": 0.12623490669593854,
            "logloss": 0.929922579518583,
            "mae": 0.2768535453665871,
            "precision": 0.7657841140529531,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8538363661202418,
            "auditor_fn_violation": 0.018457602339181287,
            "auditor_fp_violation": 0.018928901200369355,
            "ave_precision_score": 0.8540685533685096,
            "fpr": 0.16337719298245615,
            "logloss": 0.5652280800128259,
            "mae": 0.2828873688040603,
            "precision": 0.718336483931947,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8615157743883484,
            "auditor_fn_violation": 0.015028279969493782,
            "auditor_fp_violation": 0.02353000587386344,
            "ave_precision_score": 0.8617242109272658,
            "fpr": 0.12623490669593854,
            "logloss": 0.5583397091887299,
            "mae": 0.2741132685530911,
            "precision": 0.7766990291262136,
            "recall": 0.8032128514056225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8527321523925486,
            "auditor_fn_violation": 0.01804882271468144,
            "auditor_fp_violation": 0.018738938904278243,
            "ave_precision_score": 0.8529703775497806,
            "fpr": 0.16557017543859648,
            "logloss": 0.5719304514383114,
            "mae": 0.28159203343847655,
            "precision": 0.7161654135338346,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8619457925005773,
            "auditor_fn_violation": 0.01526192585930991,
            "auditor_fp_violation": 0.02226752391406618,
            "ave_precision_score": 0.8621534255251473,
            "fpr": 0.12733260153677278,
            "logloss": 0.5618783997502627,
            "mae": 0.27209750696620555,
            "precision": 0.7760617760617761,
            "recall": 0.8072289156626506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8017813719538731,
            "auditor_fn_violation": 0.015985687903970456,
            "auditor_fp_violation": 0.014312096029547559,
            "ave_precision_score": 0.8021295108249307,
            "fpr": 0.15350877192982457,
            "logloss": 0.8904262749600743,
            "mae": 0.2788059086584165,
            "precision": 0.7154471544715447,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8296592385009249,
            "auditor_fn_violation": 0.009508946874214757,
            "auditor_fp_violation": 0.020510680597379885,
            "ave_precision_score": 0.8301434772864777,
            "fpr": 0.11855104281009879,
            "logloss": 0.8773095479715407,
            "mae": 0.2760067949606007,
            "precision": 0.7763975155279503,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7871146020122521,
            "auditor_fn_violation": 0.01339835333948908,
            "auditor_fp_violation": 0.012696214219759925,
            "ave_precision_score": 0.7875926257712873,
            "fpr": 0.1425438596491228,
            "logloss": 0.8989801277522278,
            "mae": 0.2808235353069258,
            "precision": 0.7325102880658436,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8213740683996376,
            "auditor_fn_violation": 0.006764709772129134,
            "auditor_fp_violation": 0.01925617220785503,
            "ave_precision_score": 0.8218299648197346,
            "fpr": 0.11525795828759605,
            "logloss": 0.8915485731169878,
            "mae": 0.282920337455551,
            "precision": 0.7784810126582279,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8231121500646761,
            "auditor_fn_violation": 0.009053266389658364,
            "auditor_fp_violation": 0.024863419513696524,
            "ave_precision_score": 0.8233610724908377,
            "fpr": 0.17982456140350878,
            "logloss": 0.6442230228471713,
            "mae": 0.3010152688278483,
            "precision": 0.6968576709796673,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8302410603640913,
            "auditor_fn_violation": 0.005700078028910376,
            "auditor_fp_violation": 0.02824238590485404,
            "ave_precision_score": 0.8306471720256792,
            "fpr": 0.16136114160263446,
            "logloss": 0.6476318487201331,
            "mae": 0.2991326070980841,
            "precision": 0.7292817679558011,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7993897278736123,
            "auditor_fn_violation": 0.017615997229916896,
            "auditor_fp_violation": 0.014946906740535558,
            "ave_precision_score": 0.7997452777405101,
            "fpr": 0.15460526315789475,
            "logloss": 0.9130311385306819,
            "mae": 0.2792914579318303,
            "precision": 0.7128309572301426,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8274988592528058,
            "auditor_fn_violation": 0.009575073069445732,
            "auditor_fp_violation": 0.02228081319785352,
            "ave_precision_score": 0.828050202079002,
            "fpr": 0.11745334796926454,
            "logloss": 0.8975981274181088,
            "mae": 0.27647162452946333,
            "precision": 0.7775467775467776,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8172122634439225,
            "auditor_fn_violation": 0.014081255771006463,
            "auditor_fp_violation": 0.022651200369344416,
            "ave_precision_score": 0.817538560749276,
            "fpr": 0.16337719298245615,
            "logloss": 0.6600695772773528,
            "mae": 0.288915380803652,
            "precision": 0.7161904761904762,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8350340167868608,
            "auditor_fn_violation": 0.009932154523693022,
            "auditor_fp_violation": 0.023716055846886193,
            "ave_precision_score": 0.8357905822762433,
            "fpr": 0.13172338090010977,
            "logloss": 0.6524167927704182,
            "mae": 0.28552589274349227,
            "precision": 0.7669902912621359,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7588797837639712,
            "auditor_fn_violation": 0.0017697753154816865,
            "auditor_fp_violation": 0.005306921360418613,
            "ave_precision_score": 0.7591813806185805,
            "fpr": 0.46600877192982454,
            "logloss": 1.1579683613902731,
            "mae": 0.44446038224122913,
            "precision": 0.5131729667812142,
            "recall": 0.9824561403508771
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7533720005274351,
            "auditor_fn_violation": 0.002080770943268133,
            "auditor_fp_violation": 0.005190794247334838,
            "ave_precision_score": 0.754622864001741,
            "fpr": 0.43029637760702527,
            "logloss": 1.2191358329363167,
            "mae": 0.41922990421973827,
            "precision": 0.5560588901472253,
            "recall": 0.9859437751004017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7725393194983595,
            "auditor_fn_violation": 0.009428381809787629,
            "auditor_fp_violation": 0.020044629116651273,
            "ave_precision_score": 0.7730373935994916,
            "fpr": 0.17543859649122806,
            "logloss": 1.037252928743028,
            "mae": 0.2909396040531424,
            "precision": 0.699812382739212,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8100664590724533,
            "auditor_fn_violation": 0.005462023726078851,
            "auditor_fp_violation": 0.023479506595471548,
            "ave_precision_score": 0.8098411101213154,
            "fpr": 0.15367727771679474,
            "logloss": 0.9930291020310072,
            "mae": 0.2912546203878546,
            "precision": 0.7348484848484849,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 19863,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8210376584449658,
            "auditor_fn_violation": 0.012075831024930747,
            "auditor_fp_violation": 0.023026315789473683,
            "ave_precision_score": 0.8213136468805295,
            "fpr": 0.16666666666666666,
            "logloss": 0.655026505885713,
            "mae": 0.2907417665982096,
            "precision": 0.7110266159695817,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8326465712902513,
            "auditor_fn_violation": 0.009284117810429423,
            "auditor_fp_violation": 0.021616349008486538,
            "ave_precision_score": 0.833195982687071,
            "fpr": 0.13391877058177826,
            "logloss": 0.6557030071465717,
            "mae": 0.28981609134044994,
            "precision": 0.7621832358674464,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7581058790783084,
            "auditor_fn_violation": 0.009435595567867034,
            "auditor_fp_violation": 0.020140812557710063,
            "ave_precision_score": 0.7465468819085149,
            "fpr": 0.1787280701754386,
            "logloss": 1.9998010349220676,
            "mae": 0.2913816326689249,
            "precision": 0.6970260223048327,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8045547656395133,
            "auditor_fn_violation": 0.006372361013758661,
            "auditor_fp_violation": 0.023479506595471548,
            "ave_precision_score": 0.7950227720171176,
            "fpr": 0.15367727771679474,
            "logloss": 1.8275602449277935,
            "mae": 0.29186127598202677,
            "precision": 0.736346516007533,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8314000073731502,
            "auditor_fn_violation": 0.013350261618959683,
            "auditor_fp_violation": 0.014196675900277013,
            "ave_precision_score": 0.8316452252342263,
            "fpr": 0.15899122807017543,
            "logloss": 0.6480669760368076,
            "mae": 0.2850452165701741,
            "precision": 0.7216890595009597,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8360981506753437,
            "auditor_fn_violation": 0.00765741340774735,
            "auditor_fp_violation": 0.01987545283234506,
            "ave_precision_score": 0.836548832625023,
            "fpr": 0.12623490669593854,
            "logloss": 0.6643334697202289,
            "mae": 0.28257309153774063,
            "precision": 0.7722772277227723,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7928275802755906,
            "auditor_fn_violation": 0.01168628808864266,
            "auditor_fp_violation": 0.015927977839335184,
            "ave_precision_score": 0.7932666006107314,
            "fpr": 0.1600877192982456,
            "logloss": 0.9073938261345094,
            "mae": 0.2772211352007506,
            "precision": 0.7170542635658915,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8263371941651841,
            "auditor_fn_violation": 0.008957895247289932,
            "auditor_fp_violation": 0.022304733908670733,
            "ave_precision_score": 0.8266589143452034,
            "fpr": 0.12733260153677278,
            "logloss": 0.8776846893587998,
            "mae": 0.27532392361068636,
            "precision": 0.7698412698412699,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.7801424291527637,
            "auditor_fn_violation": 0.002837411511234219,
            "auditor_fp_violation": 0.00023084025854108953,
            "ave_precision_score": 0.7810124456147345,
            "fpr": 0.006578947368421052,
            "logloss": 1.269080347074776,
            "mae": 0.4423077755570611,
            "precision": 0.7692307692307693,
            "recall": 0.043859649122807015
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.7921244596751895,
            "auditor_fn_violation": 0.0053694470527554895,
            "auditor_fp_violation": 0.0008478563056322643,
            "ave_precision_score": 0.792603602619703,
            "fpr": 0.005488474204171241,
            "logloss": 1.4062447758989907,
            "mae": 0.4799388025777263,
            "precision": 0.8571428571428571,
            "recall": 0.060240963855421686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7930478313595777,
            "auditor_fn_violation": 0.02116997537703909,
            "auditor_fp_violation": 0.013734995383194837,
            "ave_precision_score": 0.7934554628255164,
            "fpr": 0.13596491228070176,
            "logloss": 0.8538887391761327,
            "mae": 0.27895240764812324,
            "precision": 0.7416666666666667,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8251787223539683,
            "auditor_fn_violation": 0.008212873447687574,
            "auditor_fp_violation": 0.020603705583891265,
            "ave_precision_score": 0.8256060785293762,
            "fpr": 0.11745334796926454,
            "logloss": 0.8481482965377747,
            "mae": 0.28165100035183344,
            "precision": 0.7747368421052632,
            "recall": 0.7389558232931727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7120145482135829,
            "auditor_fn_violation": 0.007588873499538321,
            "auditor_fp_violation": 0.035376269621421985,
            "ave_precision_score": 0.6973983888750817,
            "fpr": 0.3717105263157895,
            "logloss": 1.4405564423246162,
            "mae": 0.4230481498030027,
            "precision": 0.5637065637065637,
            "recall": 0.9605263157894737
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7549266298161252,
            "auditor_fn_violation": 0.009429595439937577,
            "auditor_fp_violation": 0.03878344580497179,
            "ave_precision_score": 0.7395580770595119,
            "fpr": 0.34357848518111966,
            "logloss": 1.4560706311588578,
            "mae": 0.40581223299448765,
            "precision": 0.6012738853503184,
            "recall": 0.9477911646586346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.7774661510577532,
            "auditor_fn_violation": 0.002748441828254858,
            "auditor_fp_violation": 0.0015870267774699906,
            "ave_precision_score": 0.7784289166755598,
            "fpr": 0.006578947368421052,
            "logloss": 1.5256838226001204,
            "mae": 0.46239684170719153,
            "precision": 0.7391304347826086,
            "recall": 0.03728070175438596
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.7900426808366218,
            "auditor_fn_violation": 0.0024069935064076516,
            "auditor_fp_violation": 0.0024585175006578194,
            "ave_precision_score": 0.7905719722017608,
            "fpr": 0.006586169045005488,
            "logloss": 1.6888689499319074,
            "mae": 0.5000958077428443,
            "precision": 0.7777777777777778,
            "recall": 0.04216867469879518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.767595332815526,
            "auditor_fn_violation": 0.013903316405047704,
            "auditor_fp_violation": 0.021872114496768236,
            "ave_precision_score": 0.7681090489431428,
            "fpr": 0.15899122807017543,
            "logloss": 1.0542183177229851,
            "mae": 0.29300626606450053,
            "precision": 0.7117296222664016,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8082626809202871,
            "auditor_fn_violation": 0.009039450888074807,
            "auditor_fp_violation": 0.015107257809447619,
            "ave_precision_score": 0.8085102946898564,
            "fpr": 0.11855104281009879,
            "logloss": 1.0207946478888246,
            "mae": 0.2937688142703661,
            "precision": 0.7735849056603774,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8023982673325811,
            "auditor_fn_violation": 0.01626461988304094,
            "auditor_fp_violation": 0.014345760233918129,
            "ave_precision_score": 0.8027378020972686,
            "fpr": 0.1600877192982456,
            "logloss": 0.9207874633759181,
            "mae": 0.27852724361381886,
            "precision": 0.7125984251968503,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8245020169642966,
            "auditor_fn_violation": 0.008563342282411752,
            "auditor_fp_violation": 0.01833655376977113,
            "ave_precision_score": 0.8250752339047726,
            "fpr": 0.132821075740944,
            "logloss": 0.9174486506961084,
            "mae": 0.27796352628598786,
            "precision": 0.758,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.797763300353847,
            "auditor_fn_violation": 0.010964912280701754,
            "auditor_fp_violation": 0.022218374884579877,
            "ave_precision_score": 0.7981706399564994,
            "fpr": 0.2236842105263158,
            "logloss": 0.9804183970266361,
            "mae": 0.28990303301942344,
            "precision": 0.6666666666666666,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8283083378562616,
            "auditor_fn_violation": 0.007075502889714735,
            "auditor_fp_violation": 0.025528714155479304,
            "ave_precision_score": 0.8287690385865223,
            "fpr": 0.20417124039517015,
            "logloss": 0.9077651980834208,
            "mae": 0.2791262842321748,
            "precision": 0.7033492822966507,
            "recall": 0.8855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8263445654993369,
            "auditor_fn_violation": 0.01975607879347491,
            "auditor_fp_violation": 0.012580794090489386,
            "ave_precision_score": 0.8266034512014422,
            "fpr": 0.1524122807017544,
            "logloss": 0.6799890274023047,
            "mae": 0.28129880144949543,
            "precision": 0.7258382642998028,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8270917114500829,
            "auditor_fn_violation": 0.013410392392842498,
            "auditor_fp_violation": 0.0158381684177513,
            "ave_precision_score": 0.8276176556703991,
            "fpr": 0.12403951701427003,
            "logloss": 0.715430405057319,
            "mae": 0.28236266347640226,
            "precision": 0.772635814889336,
            "recall": 0.7710843373493976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7679070696499417,
            "auditor_fn_violation": 0.013903316405047704,
            "auditor_fp_violation": 0.021872114496768236,
            "ave_precision_score": 0.7684283050298829,
            "fpr": 0.15899122807017543,
            "logloss": 1.0514539584969684,
            "mae": 0.292853431125296,
            "precision": 0.7117296222664016,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8081129610696411,
            "auditor_fn_violation": 0.00935906083169121,
            "auditor_fp_violation": 0.015107257809447619,
            "ave_precision_score": 0.8079300693301916,
            "fpr": 0.11855104281009879,
            "logloss": 1.0188108551947983,
            "mae": 0.2936581130971255,
            "precision": 0.773109243697479,
            "recall": 0.7389558232931727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7654049902249765,
            "auditor_fn_violation": 0.0017697753154816865,
            "auditor_fp_violation": 0.005306921360418613,
            "ave_precision_score": 0.7656746940100555,
            "fpr": 0.46600877192982454,
            "logloss": 1.1541333195468066,
            "mae": 0.44020330120301837,
            "precision": 0.5131729667812142,
            "recall": 0.9824561403508771
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7523295287868691,
            "auditor_fn_violation": 0.002080770943268133,
            "auditor_fp_violation": 0.007242659664100069,
            "ave_precision_score": 0.7535893133743592,
            "fpr": 0.42371020856201974,
            "logloss": 1.2193421023939448,
            "mae": 0.41648897742053875,
            "precision": 0.5598631698973774,
            "recall": 0.9859437751004017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.854173545459795,
            "auditor_fn_violation": 0.017038896583564174,
            "auditor_fp_violation": 0.017909356725146205,
            "ave_precision_score": 0.8543944905414776,
            "fpr": 0.16666666666666666,
            "logloss": 0.5691543794652927,
            "mae": 0.28084384205297874,
            "precision": 0.7137476459510358,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8617907824621616,
            "auditor_fn_violation": 0.01292105854813326,
            "auditor_fp_violation": 0.02133461619219494,
            "ave_precision_score": 0.8620005972035034,
            "fpr": 0.12623490669593854,
            "logloss": 0.5623538827442977,
            "mae": 0.2717479877435972,
            "precision": 0.7788461538461539,
            "recall": 0.8132530120481928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7066708144766565,
            "auditor_fn_violation": 0.03766784010464759,
            "auditor_fp_violation": 0.019275161588180986,
            "ave_precision_score": 0.6810446754597349,
            "fpr": 0.21162280701754385,
            "logloss": 0.6538868372168322,
            "mae": 0.4282135887953796,
            "precision": 0.6093117408906883,
            "recall": 0.6600877192982456
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7315235166876305,
            "auditor_fn_violation": 0.047535917545042966,
            "auditor_fp_violation": 0.024359257182193433,
            "ave_precision_score": 0.70381699007495,
            "fpr": 0.20636663007683864,
            "logloss": 0.6397731934181524,
            "mae": 0.4232464004164862,
            "precision": 0.6299212598425197,
            "recall": 0.642570281124498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.79287763809857,
            "auditor_fn_violation": 0.01168628808864266,
            "auditor_fp_violation": 0.015927977839335184,
            "ave_precision_score": 0.7933165016036068,
            "fpr": 0.1600877192982456,
            "logloss": 0.9072765844169663,
            "mae": 0.2772132104238479,
            "precision": 0.7170542635658915,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8263357421238726,
            "auditor_fn_violation": 0.008957895247289932,
            "auditor_fp_violation": 0.022304733908670733,
            "ave_precision_score": 0.826658839762261,
            "fpr": 0.12733260153677278,
            "logloss": 0.8775847032673942,
            "mae": 0.275319292557825,
            "precision": 0.7698412698412699,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8307689054948247,
            "auditor_fn_violation": 0.01654836103416436,
            "auditor_fp_violation": 0.014970952600800252,
            "ave_precision_score": 0.831016100001487,
            "fpr": 0.15679824561403508,
            "logloss": 0.6487615131883567,
            "mae": 0.28418613697056605,
            "precision": 0.7212475633528265,
            "recall": 0.8114035087719298
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8352932351832334,
            "auditor_fn_violation": 0.009727163318476985,
            "auditor_fp_violation": 0.012180957519475453,
            "ave_precision_score": 0.8357492645875246,
            "fpr": 0.1251372118551043,
            "logloss": 0.6687549723610834,
            "mae": 0.28246412405822974,
            "precision": 0.7724550898203593,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8226466825612462,
            "auditor_fn_violation": 0.014802631578947373,
            "auditor_fp_violation": 0.021698984302862427,
            "ave_precision_score": 0.8229117049938992,
            "fpr": 0.15679824561403508,
            "logloss": 0.6366786552363394,
            "mae": 0.2917660222230089,
            "precision": 0.7190569744597249,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8316025300389407,
            "auditor_fn_violation": 0.012841707113856089,
            "auditor_fp_violation": 0.02083493912179098,
            "ave_precision_score": 0.8321829175188957,
            "fpr": 0.12623490669593854,
            "logloss": 0.6479211935483853,
            "mae": 0.29284871807944796,
            "precision": 0.7667342799188641,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 19863,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7059473895675071,
            "auditor_fn_violation": 0.036463142505386285,
            "auditor_fp_violation": 0.016098703447214535,
            "ave_precision_score": 0.679691732056928,
            "fpr": 0.21820175438596492,
            "logloss": 0.6629687024240015,
            "mae": 0.4256000939037716,
            "precision": 0.6067193675889329,
            "recall": 0.6732456140350878
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7301196185997538,
            "auditor_fn_violation": 0.041029099934314646,
            "auditor_fp_violation": 0.019925952110736948,
            "ave_precision_score": 0.7029028498891638,
            "fpr": 0.21185510428100987,
            "logloss": 0.6485573996878137,
            "mae": 0.4214381142780103,
            "precision": 0.6302681992337165,
            "recall": 0.6606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8155245632247718,
            "auditor_fn_violation": 0.011320791012619269,
            "auditor_fp_violation": 0.021429670667897815,
            "ave_precision_score": 0.8158171028849543,
            "fpr": 0.18859649122807018,
            "logloss": 0.6598490618170489,
            "mae": 0.3011095903971461,
            "precision": 0.6895306859205776,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8288423189485637,
            "auditor_fn_violation": 0.0035796313685036558,
            "auditor_fp_violation": 0.029954045656663382,
            "ave_precision_score": 0.8292688242675352,
            "fpr": 0.16355653128430298,
            "logloss": 0.654761672602896,
            "mae": 0.29740930009906147,
            "precision": 0.7320143884892086,
            "recall": 0.8172690763052208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7904478666989545,
            "auditor_fn_violation": 0.012941481994459837,
            "auditor_fp_violation": 0.01587026777469991,
            "ave_precision_score": 0.790846660646089,
            "fpr": 0.1524122807017544,
            "logloss": 0.9988318609735445,
            "mae": 0.2756747281227439,
            "precision": 0.7247524752475247,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8252510031364886,
            "auditor_fn_violation": 0.011382522405759155,
            "auditor_fp_violation": 0.0169225739747982,
            "ave_precision_score": 0.8250112832050384,
            "fpr": 0.11745334796926454,
            "logloss": 0.9638441312151648,
            "mae": 0.2746434296381564,
            "precision": 0.7784679089026915,
            "recall": 0.7550200803212851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7810561493812566,
            "auditor_fn_violation": 0.0031067251461988398,
            "auditor_fp_violation": 0.00023084025854108953,
            "ave_precision_score": 0.7819245860438312,
            "fpr": 0.006578947368421052,
            "logloss": 1.278171946597271,
            "mae": 0.44372252739626855,
            "precision": 0.76,
            "recall": 0.041666666666666664
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.7938554892493876,
            "auditor_fn_violation": 0.0053694470527554895,
            "auditor_fp_violation": 0.0008478563056322643,
            "ave_precision_score": 0.7943268154572566,
            "fpr": 0.005488474204171241,
            "logloss": 1.415579165353507,
            "mae": 0.4812388444250605,
            "precision": 0.8571428571428571,
            "recall": 0.060240963855421686
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.534936874232218,
            "auditor_fn_violation": 0.0024695098491843656,
            "auditor_fp_violation": 0.0035395506309633907,
            "ave_precision_score": 0.5313897086281262,
            "fpr": 0.36403508771929827,
            "logloss": 0.6912568669028484,
            "mae": 0.4981284829738893,
            "precision": 0.5081481481481481,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5809591565640102,
            "auditor_fn_violation": 0.007181304802084296,
            "auditor_fp_violation": 0.011763674008552981,
            "ave_precision_score": 0.570594491868246,
            "fpr": 0.34796926454445665,
            "logloss": 0.6894680241656418,
            "mae": 0.49726600717634584,
            "precision": 0.5412445730824892,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7069501750173472,
            "auditor_fn_violation": 0.003917070637119114,
            "auditor_fp_violation": 0.010791782086795963,
            "ave_precision_score": 0.6923417961955632,
            "fpr": 0.43859649122807015,
            "logloss": 1.496779304155749,
            "mae": 0.4300177863766166,
            "precision": 0.5266272189349113,
            "recall": 0.9758771929824561
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7460514267424081,
            "auditor_fn_violation": 0.0017038516304515542,
            "auditor_fp_violation": 0.011200208375969793,
            "ave_precision_score": 0.7306921783824232,
            "fpr": 0.3995609220636663,
            "logloss": 1.5041064182066197,
            "mae": 0.4104867335648265,
            "precision": 0.5712603062426383,
            "recall": 0.9738955823293173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7999050991345156,
            "auditor_fn_violation": 0.017659279778393353,
            "auditor_fp_violation": 0.013032856263465677,
            "ave_precision_score": 0.8002483457874683,
            "fpr": 0.1600877192982456,
            "logloss": 0.9397774522234446,
            "mae": 0.2808744290117351,
            "precision": 0.7114624505928854,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8186201758839904,
            "auditor_fn_violation": 0.008519258152257769,
            "auditor_fp_violation": 0.016824233274771887,
            "ave_precision_score": 0.819178092120519,
            "fpr": 0.13172338090010977,
            "logloss": 0.9517717105912477,
            "mae": 0.2813869058815082,
            "precision": 0.7585513078470825,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7967578875720038,
            "auditor_fn_violation": 0.0127539242843952,
            "auditor_fp_violation": 0.018524930747922445,
            "ave_precision_score": 0.7970706321967943,
            "fpr": 0.18421052631578946,
            "logloss": 0.8756677899043512,
            "mae": 0.289872543155225,
            "precision": 0.6900369003690037,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8177704078890824,
            "auditor_fn_violation": 0.004606791601091525,
            "auditor_fp_violation": 0.02839919945354465,
            "ave_precision_score": 0.81833956463598,
            "fpr": 0.15806805708013172,
            "logloss": 0.8467231296846522,
            "mae": 0.2877541442342558,
            "precision": 0.7293233082706767,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7977547450410153,
            "auditor_fn_violation": 0.010964912280701754,
            "auditor_fp_violation": 0.022218374884579877,
            "ave_precision_score": 0.7981706399564994,
            "fpr": 0.2236842105263158,
            "logloss": 0.9804201483253165,
            "mae": 0.28990328692445627,
            "precision": 0.6666666666666666,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8283083378562616,
            "auditor_fn_violation": 0.007075502889714735,
            "auditor_fp_violation": 0.025528714155479304,
            "ave_precision_score": 0.8287690385865223,
            "fpr": 0.20417124039517015,
            "logloss": 0.907766401285547,
            "mae": 0.27912642053299386,
            "precision": 0.7033492822966507,
            "recall": 0.8855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.796860346804214,
            "auditor_fn_violation": 0.012566366574330565,
            "auditor_fp_violation": 0.018558594952293016,
            "ave_precision_score": 0.7973015290350975,
            "fpr": 0.1600877192982456,
            "logloss": 0.8904444528435129,
            "mae": 0.2750061091971649,
            "precision": 0.7192307692307692,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8289236283213494,
            "auditor_fn_violation": 0.010454551466017753,
            "auditor_fp_violation": 0.02223031391946163,
            "ave_precision_score": 0.8292498904683064,
            "fpr": 0.12733260153677278,
            "logloss": 0.8606197310996168,
            "mae": 0.2721279133388649,
            "precision": 0.7712031558185405,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7999721478737918,
            "auditor_fn_violation": 0.017659279778393353,
            "auditor_fp_violation": 0.013032856263465677,
            "ave_precision_score": 0.8003161474802578,
            "fpr": 0.1600877192982456,
            "logloss": 0.9436414683058619,
            "mae": 0.28083271770004253,
            "precision": 0.7114624505928854,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.818621039530325,
            "auditor_fn_violation": 0.008519258152257769,
            "auditor_fp_violation": 0.017238858928936885,
            "ave_precision_score": 0.8191407867411457,
            "fpr": 0.132821075740944,
            "logloss": 0.9554048197135384,
            "mae": 0.2813287769643237,
            "precision": 0.7570281124497992,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8499582285354198,
            "auditor_fn_violation": 0.014413088642659283,
            "auditor_fp_violation": 0.01438904278239459,
            "ave_precision_score": 0.8501737580902491,
            "fpr": 0.1600877192982456,
            "logloss": 0.57906860104558,
            "mae": 0.2792400595645141,
            "precision": 0.7197696737044146,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8586391721269074,
            "auditor_fn_violation": 0.015453691825479747,
            "auditor_fp_violation": 0.015434174190616169,
            "ave_precision_score": 0.858852275004075,
            "fpr": 0.1251372118551043,
            "logloss": 0.5782031963202025,
            "mae": 0.2729269749290542,
            "precision": 0.7777777777777778,
            "recall": 0.8012048192771084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7977547450410153,
            "auditor_fn_violation": 0.010964912280701754,
            "auditor_fp_violation": 0.022218374884579877,
            "ave_precision_score": 0.7981706399564994,
            "fpr": 0.2236842105263158,
            "logloss": 0.9804208692593185,
            "mae": 0.2899033103041994,
            "precision": 0.6666666666666666,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8283083378562616,
            "auditor_fn_violation": 0.007075502889714735,
            "auditor_fp_violation": 0.025528714155479304,
            "ave_precision_score": 0.8287690385865223,
            "fpr": 0.20417124039517015,
            "logloss": 0.9077669807951556,
            "mae": 0.27912646645212297,
            "precision": 0.7033492822966507,
            "recall": 0.8855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7872270560587029,
            "auditor_fn_violation": 0.012061403508771933,
            "auditor_fp_violation": 0.010368574946137273,
            "ave_precision_score": 0.787691142803483,
            "fpr": 0.12719298245614036,
            "logloss": 0.8994167123682978,
            "mae": 0.28214472842419563,
            "precision": 0.7489177489177489,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8215537975543861,
            "auditor_fn_violation": 0.006960884151314368,
            "auditor_fp_violation": 0.016149137658375046,
            "ave_precision_score": 0.8219944296079562,
            "fpr": 0.10757409440175632,
            "logloss": 0.9004518165758161,
            "mae": 0.2849271309263516,
            "precision": 0.7850877192982456,
            "recall": 0.7188755020080321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8483086048943554,
            "auditor_fn_violation": 0.016447368421052634,
            "auditor_fp_violation": 0.018178670360110807,
            "ave_precision_score": 0.8485399071234825,
            "fpr": 0.16776315789473684,
            "logloss": 0.583281354548257,
            "mae": 0.28406778566314106,
            "precision": 0.7129455909943715,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8566523481323676,
            "auditor_fn_violation": 0.016262635613805393,
            "auditor_fp_violation": 0.021230959778653694,
            "ave_precision_score": 0.8568612819955963,
            "fpr": 0.13172338090010977,
            "logloss": 0.5801820925515894,
            "mae": 0.27830966995582734,
            "precision": 0.7678916827852998,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8309477512134877,
            "auditor_fn_violation": 0.01970798707294552,
            "auditor_fp_violation": 0.01587026777469991,
            "ave_precision_score": 0.8312132865883253,
            "fpr": 0.1524122807017544,
            "logloss": 0.6957095919356268,
            "mae": 0.27656889559339326,
            "precision": 0.7279843444227005,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8494132668687724,
            "auditor_fn_violation": 0.013741023368997397,
            "auditor_fp_violation": 0.020771150559611748,
            "ave_precision_score": 0.8496438564439749,
            "fpr": 0.12184412733260154,
            "logloss": 0.6873190675477208,
            "mae": 0.27323793707000243,
            "precision": 0.7797619047619048,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6121477441969511,
            "auditor_fn_violation": 0.004078177900892593,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5548464584706423,
            "fpr": 0.0,
            "logloss": 0.6836409653914615,
            "mae": 0.49156847971965345,
            "precision": 1.0,
            "recall": 0.03508771929824561
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.625798977848311,
            "auditor_fn_violation": 0.0016862179783899665,
            "auditor_fp_violation": 0.00061130705421762,
            "ave_precision_score": 0.5776256289010758,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6944936352771686,
            "mae": 0.49688489265682667,
            "precision": 0.9375,
            "recall": 0.030120481927710843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8181580385700755,
            "auditor_fn_violation": 0.015567289935364732,
            "auditor_fp_violation": 0.015581717451523555,
            "ave_precision_score": 0.8184707454716365,
            "fpr": 0.15570175438596492,
            "logloss": 0.7422163269972216,
            "mae": 0.27377775641984153,
            "precision": 0.7204724409448819,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8395745651653335,
            "auditor_fn_violation": 0.008173197730548979,
            "auditor_fp_violation": 0.018945202967231286,
            "ave_precision_score": 0.8399465309887222,
            "fpr": 0.12184412733260154,
            "logloss": 0.7359227640748544,
            "mae": 0.2709912454929662,
            "precision": 0.7766599597585513,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.800277159030454,
            "auditor_fn_violation": 0.010964912280701754,
            "auditor_fp_violation": 0.01569232840874115,
            "ave_precision_score": 0.8007022223434039,
            "fpr": 0.15899122807017543,
            "logloss": 0.8580169186705177,
            "mae": 0.27499913109188273,
            "precision": 0.7216890595009597,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8319581084967385,
            "auditor_fn_violation": 0.01171094917540635,
            "auditor_fp_violation": 0.021674821857150837,
            "ave_precision_score": 0.8324230558306401,
            "fpr": 0.13062568605927552,
            "logloss": 0.830624235361691,
            "mae": 0.27225075074975646,
            "precision": 0.7684824902723736,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8116262907095794,
            "auditor_fn_violation": 0.01646660510926439,
            "auditor_fp_violation": 0.015168128654970766,
            "ave_precision_score": 0.811905016328614,
            "fpr": 0.15350877192982457,
            "logloss": 0.9164329500593544,
            "mae": 0.2779954479867921,
            "precision": 0.7171717171717171,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8283284288179369,
            "auditor_fn_violation": 0.007882242471532673,
            "auditor_fp_violation": 0.018437552326554914,
            "ave_precision_score": 0.8287730273014843,
            "fpr": 0.12294182217343579,
            "logloss": 0.9240521407248732,
            "mae": 0.2773944126197334,
            "precision": 0.7700205338809035,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8244431844468681,
            "auditor_fn_violation": 0.012530297783933522,
            "auditor_fp_violation": 0.02291089566020315,
            "ave_precision_score": 0.8246886158840814,
            "fpr": 0.17214912280701755,
            "logloss": 0.6435635530315935,
            "mae": 0.29704234268716756,
            "precision": 0.7015209125475285,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8294620183076225,
            "auditor_fn_violation": 0.009978442860354696,
            "auditor_fp_violation": 0.023798449406367703,
            "ave_precision_score": 0.8300345691202722,
            "fpr": 0.150384193194292,
            "logloss": 0.6539994221634142,
            "mae": 0.29728155756229163,
            "precision": 0.7385496183206107,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7665392617443734,
            "auditor_fn_violation": 0.017615997229916896,
            "auditor_fp_violation": 0.02355051554324408,
            "ave_precision_score": 0.7670230093762301,
            "fpr": 0.1600877192982456,
            "logloss": 1.0433361767487102,
            "mae": 0.2944082087850006,
            "precision": 0.7056451612903226,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8084202889049518,
            "auditor_fn_violation": 0.009284117810429426,
            "auditor_fp_violation": 0.021709373994997914,
            "ave_precision_score": 0.808183921241414,
            "fpr": 0.11855104281009879,
            "logloss": 1.0058425760336,
            "mae": 0.2931599406379612,
            "precision": 0.7735849056603774,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8121258668407934,
            "auditor_fn_violation": 0.013285337796245002,
            "auditor_fp_violation": 0.010149757617728534,
            "ave_precision_score": 0.8124740018201799,
            "fpr": 0.0756578947368421,
            "logloss": 0.6256174566052887,
            "mae": 0.35012359768384477,
            "precision": 0.8028571428571428,
            "recall": 0.6162280701754386
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8154351190477165,
            "auditor_fn_violation": 0.008979937312366919,
            "auditor_fp_violation": 0.01785813955342691,
            "ave_precision_score": 0.8157440164613889,
            "fpr": 0.08122941822173436,
            "logloss": 0.6683252931072083,
            "mae": 0.37193897023866473,
            "precision": 0.7921348314606742,
            "recall": 0.5662650602409639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8181580808052007,
            "auditor_fn_violation": 0.012061403508771933,
            "auditor_fp_violation": 0.018647564635272396,
            "ave_precision_score": 0.8194681043293338,
            "fpr": 0.20723684210526316,
            "logloss": 0.6150443470538411,
            "mae": 0.31694244576277,
            "precision": 0.6701570680628273,
            "recall": 0.8421052631578947
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8127366878325717,
            "auditor_fn_violation": 0.012599244398009166,
            "auditor_fp_violation": 0.026256966907025527,
            "ave_precision_score": 0.8133599554667192,
            "fpr": 0.1800219538968167,
            "logloss": 0.6221172245855234,
            "mae": 0.31393220045672304,
            "precision": 0.7092198581560284,
            "recall": 0.8032128514056225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8170298286571629,
            "auditor_fn_violation": 0.011808921975992613,
            "auditor_fp_violation": 0.0217566943674977,
            "ave_precision_score": 0.8173202259852337,
            "fpr": 0.16447368421052633,
            "logloss": 0.6709390830783921,
            "mae": 0.289740353174923,
            "precision": 0.7120921305182342,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8313042267438785,
            "auditor_fn_violation": 0.00824593654530306,
            "auditor_fp_violation": 0.02265557100065649,
            "ave_precision_score": 0.8319277788109152,
            "fpr": 0.13172338090010977,
            "logloss": 0.6703395165830263,
            "mae": 0.2888153411700396,
            "precision": 0.7633136094674556,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8054889517563052,
            "auditor_fn_violation": 0.014574195906432752,
            "auditor_fp_violation": 0.01699561403508773,
            "ave_precision_score": 0.8058663463644762,
            "fpr": 0.14802631578947367,
            "logloss": 0.7874185286895217,
            "mae": 0.27628718841534483,
            "precision": 0.7278225806451613,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8330573767307412,
            "auditor_fn_violation": 0.008728657770489201,
            "auditor_fp_violation": 0.019378433618698555,
            "ave_precision_score": 0.8334391818101443,
            "fpr": 0.11855104281009879,
            "logloss": 0.7796732189554462,
            "mae": 0.27541120670115876,
            "precision": 0.7786885245901639,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7662885992823132,
            "auditor_fn_violation": 0.015502366112650046,
            "auditor_fp_violation": 0.021872114496768236,
            "ave_precision_score": 0.7667420012529138,
            "fpr": 0.15899122807017543,
            "logloss": 1.0757892356785819,
            "mae": 0.29330373812479693,
            "precision": 0.71,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8070279709178958,
            "auditor_fn_violation": 0.005673627550817993,
            "auditor_fp_violation": 0.015107257809447619,
            "ave_precision_score": 0.8068425373529329,
            "fpr": 0.11855104281009879,
            "logloss": 1.040643799728897,
            "mae": 0.29409831629024036,
            "precision": 0.7740585774058577,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 19863,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7978763940484768,
            "auditor_fn_violation": 0.011323195598645742,
            "auditor_fp_violation": 0.01783240997229918,
            "ave_precision_score": 0.7982951703646672,
            "fpr": 0.16337719298245615,
            "logloss": 0.8750410922766971,
            "mae": 0.27572331155150814,
            "precision": 0.7167300380228137,
            "recall": 0.8267543859649122
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8288071341754975,
            "auditor_fn_violation": 0.010123920489862857,
            "auditor_fp_violation": 0.021507376881430357,
            "ave_precision_score": 0.8293105300286086,
            "fpr": 0.13062568605927552,
            "logloss": 0.8488564841662233,
            "mae": 0.2748281374950401,
            "precision": 0.7684824902723736,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7341359131523835,
            "auditor_fn_violation": 0.007675438596491228,
            "auditor_fp_violation": 0.0435133887349954,
            "ave_precision_score": 0.7222373435500292,
            "fpr": 0.34978070175438597,
            "logloss": 1.274917845508161,
            "mae": 0.4154437121653891,
            "precision": 0.5785997357992074,
            "recall": 0.9605263157894737
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.769821228410366,
            "auditor_fn_violation": 0.012828481874809889,
            "auditor_fp_violation": 0.040173504889127507,
            "ave_precision_score": 0.7598237467369068,
            "fpr": 0.3216245883644347,
            "logloss": 1.1652253030712745,
            "mae": 0.40179714937100547,
            "precision": 0.6149802890932983,
            "recall": 0.9397590361445783
        }
    }
]