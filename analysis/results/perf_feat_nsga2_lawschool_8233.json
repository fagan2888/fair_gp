[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.32978922712365,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.767702429789642,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.690558801380663,
            "fpr": 0.10855263157894737,
            "logloss": 3.361523014991112,
            "mae": 0.4016111382985847,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7700051595006845,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.688931637279838,
            "fpr": 0.12403951701427003,
            "logloss": 3.5881265403663734,
            "mae": 0.40299386437062246,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.767702429789642,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.690558801380663,
            "fpr": 0.10855263157894737,
            "logloss": 3.3560568913836897,
            "mae": 0.4021709182610114,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7700051595006845,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.688931637279838,
            "fpr": 0.12403951701427003,
            "logloss": 3.580901633853181,
            "mae": 0.4037771309377333,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7782240398640528,
            "auditor_fn_violation": 0.008828566768160078,
            "auditor_fp_violation": 0.010824008034103952,
            "ave_precision_score": 0.6629672789384142,
            "fpr": 0.11074561403508772,
            "logloss": 0.6653586500605297,
            "mae": 0.4105765807785486,
            "precision": 0.7423469387755102,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7804457574681685,
            "auditor_fn_violation": 0.011296914776840979,
            "auditor_fp_violation": 0.01950461853237453,
            "ave_precision_score": 0.6594214374314309,
            "fpr": 0.12733260153677278,
            "logloss": 0.6768322663219846,
            "mae": 0.4084057427133085,
            "precision": 0.7257683215130024,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7787657146383866,
            "auditor_fn_violation": 0.008828566768160078,
            "auditor_fp_violation": 0.010824008034103952,
            "ave_precision_score": 0.6644491108146157,
            "fpr": 0.11074561403508772,
            "logloss": 0.6681206352280528,
            "mae": 0.40982351223366303,
            "precision": 0.7423469387755102,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.780974317579568,
            "auditor_fn_violation": 0.011296914776840979,
            "auditor_fp_violation": 0.01950461853237453,
            "ave_precision_score": 0.6604532106959821,
            "fpr": 0.12733260153677278,
            "logloss": 0.6803900278824934,
            "mae": 0.40777969468307285,
            "precision": 0.7257683215130024,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.76249839691399,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6977250473409945,
            "fpr": 0.10855263157894737,
            "logloss": 3.360889065786235,
            "mae": 0.40176122102951795,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7677113963656562,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.697794067691838,
            "fpr": 0.12403951701427003,
            "logloss": 3.5872527817029627,
            "mae": 0.4031834725032915,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.772919080650587,
            "auditor_fn_violation": 0.013597397419167757,
            "auditor_fp_violation": 0.01152852926709297,
            "ave_precision_score": 0.7163178972957328,
            "fpr": 0.11403508771929824,
            "logloss": 3.26988902766159,
            "mae": 0.3937170990792115,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.77311208283225,
            "auditor_fn_violation": 0.015904897587406874,
            "auditor_fp_violation": 0.01119350045177237,
            "ave_precision_score": 0.7115503096560337,
            "fpr": 0.1350164654226125,
            "logloss": 3.4187823912795956,
            "mae": 0.3929408008457492,
            "precision": 0.7092198581560284,
            "recall": 0.6382978723404256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7860192235266247,
            "auditor_fn_violation": 0.011930005799623025,
            "auditor_fp_violation": 0.012901705197573374,
            "ave_precision_score": 0.7818707889739728,
            "fpr": 0.07236842105263158,
            "logloss": 0.5651884325742035,
            "mae": 0.354785040560174,
            "precision": 0.8206521739130435,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7879687234853471,
            "auditor_fn_violation": 0.00993764159095687,
            "auditor_fp_violation": 0.011813287334692385,
            "ave_precision_score": 0.7887831651760483,
            "fpr": 0.07683863885839737,
            "logloss": 0.5526362690579786,
            "mae": 0.3473922076045191,
            "precision": 0.8123324396782842,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7491480124261446,
            "auditor_fn_violation": 0.002047991880527768,
            "auditor_fp_violation": 0.011215978029185114,
            "ave_precision_score": 0.7504873024977665,
            "fpr": 0.22039473684210525,
            "logloss": 0.6467811649646082,
            "mae": 0.41957161256945447,
            "precision": 0.6710310965630114,
            "recall": 0.8471074380165289
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.704314883333209,
            "auditor_fn_violation": 0.008069224840600698,
            "auditor_fp_violation": 0.008390769406921208,
            "ave_precision_score": 0.7059014188158688,
            "fpr": 0.2513721185510428,
            "logloss": 0.6623874139715544,
            "mae": 0.43125357862426994,
            "precision": 0.6330128205128205,
            "recall": 0.8404255319148937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7228624993577826,
            "auditor_fn_violation": 0.0062753733507322,
            "auditor_fp_violation": 0.010142543859649125,
            "ave_precision_score": 0.7228994842890745,
            "fpr": 0.11732456140350878,
            "logloss": 0.6436166577116911,
            "mae": 0.39878058087146073,
            "precision": 0.7458432304038005,
            "recall": 0.6487603305785123
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7257311730952578,
            "auditor_fn_violation": 0.011061027162108517,
            "auditor_fp_violation": 0.019487194804742244,
            "ave_precision_score": 0.7259248100682854,
            "fpr": 0.13391877058177826,
            "logloss": 0.6644001243648083,
            "mae": 0.40554486897198483,
            "precision": 0.7188940092165899,
            "recall": 0.6638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7841443773850747,
            "auditor_fn_violation": 0.010448383355081924,
            "auditor_fp_violation": 0.014905107394654865,
            "ave_precision_score": 0.7278322092150185,
            "fpr": 0.12828947368421054,
            "logloss": 3.2903463743596233,
            "mae": 0.3998915171740874,
            "precision": 0.7180722891566265,
            "recall": 0.6157024793388429
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.782048318390388,
            "auditor_fn_violation": 0.011385664572482895,
            "auditor_fp_violation": 0.018882342545507053,
            "ave_precision_score": 0.7201750362801483,
            "fpr": 0.14709110867178923,
            "logloss": 3.470038780428786,
            "mae": 0.40220066296543977,
            "precision": 0.7015590200445434,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7685395626122143,
            "auditor_fn_violation": 0.01005419022763521,
            "auditor_fp_violation": 0.014331242826692901,
            "ave_precision_score": 0.7119189458312345,
            "fpr": 0.125,
            "logloss": 3.3053323104201118,
            "mae": 0.3998612568043826,
            "precision": 0.7205882352941176,
            "recall": 0.6074380165289256
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7655558417373213,
            "auditor_fn_violation": 0.010960599761776864,
            "auditor_fp_violation": 0.014872396086132954,
            "ave_precision_score": 0.7021600249310512,
            "fpr": 0.150384193194292,
            "logloss": 3.5634860302491944,
            "mae": 0.4017433134509756,
            "precision": 0.6914414414414415,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7738919024402702,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.7126166315314818,
            "fpr": 0.10855263157894737,
            "logloss": 3.367161362732723,
            "mae": 0.4021095792975342,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7739181541313414,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.7067897141479433,
            "fpr": 0.12403951701427003,
            "logloss": 3.5961721838198346,
            "mae": 0.403854620672607,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.3649900300112385,
            "mae": 0.401083388676246,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7712258521620733,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6954042841191628,
            "fpr": 0.12403951701427003,
            "logloss": 3.592654830433895,
            "mae": 0.40225290800685026,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.767702429789642,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.690558801380663,
            "fpr": 0.10855263157894737,
            "logloss": 3.355781850188906,
            "mae": 0.40219439651098166,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7700051595006845,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.688931637279838,
            "fpr": 0.12403951701427003,
            "logloss": 3.580536431171828,
            "mae": 0.40380977602873885,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7737601408618909,
            "auditor_fn_violation": 0.012609649122807019,
            "auditor_fp_violation": 0.01152852926709297,
            "ave_precision_score": 0.7170824094710552,
            "fpr": 0.11403508771929824,
            "logloss": 3.2549316978393232,
            "mae": 0.3931348663943211,
            "precision": 0.7353689567430025,
            "recall": 0.5971074380165289
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7734600184065226,
            "auditor_fn_violation": 0.012597799939276457,
            "auditor_fp_violation": 0.010827602171494291,
            "ave_precision_score": 0.7118265446001671,
            "fpr": 0.13172338090010977,
            "logloss": 3.419675206754258,
            "mae": 0.39452256393052887,
            "precision": 0.7115384615384616,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7989311847349023,
            "auditor_fn_violation": 0.013103523270987384,
            "auditor_fp_violation": 0.016004160518117726,
            "ave_precision_score": 0.7666401191317542,
            "fpr": 0.12390350877192982,
            "logloss": 2.230475853614809,
            "mae": 0.2901788563826254,
            "precision": 0.7575107296137339,
            "recall": 0.7293388429752066
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7919739920501311,
            "auditor_fn_violation": 0.016909171590723318,
            "auditor_fp_violation": 0.019405054374475733,
            "ave_precision_score": 0.7545430075941104,
            "fpr": 0.12623490669593854,
            "logloss": 2.412495671276435,
            "mae": 0.2858684578793927,
            "precision": 0.7526881720430108,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7625937551585349,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6976925368784513,
            "fpr": 0.10855263157894737,
            "logloss": 3.363202718848412,
            "mae": 0.40145973759915743,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7676486066785014,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6976020632949083,
            "fpr": 0.12403951701427003,
            "logloss": 3.590291510483164,
            "mae": 0.4027601548855967,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7527131517067521,
            "auditor_fn_violation": 0.010804063360881553,
            "auditor_fp_violation": 0.012573782587309394,
            "ave_precision_score": 0.6898061780272757,
            "fpr": 0.10964912280701754,
            "logloss": 3.3131158011134385,
            "mae": 0.39897365339605845,
            "precision": 0.7361477572559367,
            "recall": 0.5764462809917356
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.761330117064007,
            "auditor_fn_violation": 0.013368521848798377,
            "auditor_fp_violation": 0.012955786046581092,
            "ave_precision_score": 0.6930689631982649,
            "fpr": 0.1251372118551043,
            "logloss": 3.507159629281082,
            "mae": 0.4008895778443011,
            "precision": 0.715,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.504758124404389,
            "auditor_fn_violation": 0.0076301290416122955,
            "auditor_fp_violation": 0.005249323659616333,
            "ave_precision_score": 0.5282435920318067,
            "fpr": 0.03179824561403509,
            "logloss": 9.089617738587732,
            "mae": 0.5675974716607732,
            "precision": 0.6741573033707865,
            "recall": 0.12396694214876033
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.4704014138009261,
            "auditor_fn_violation": 0.009169255202372906,
            "auditor_fp_violation": 0.006752939009485977,
            "ave_precision_score": 0.5007921251398635,
            "fpr": 0.04500548847420417,
            "logloss": 9.574304292367906,
            "mae": 0.5766158332199133,
            "precision": 0.6019417475728155,
            "recall": 0.13191489361702127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7521419612367316,
            "auditor_fn_violation": 0.010804063360881553,
            "auditor_fp_violation": 0.012573782587309394,
            "ave_precision_score": 0.6897045023977465,
            "fpr": 0.10964912280701754,
            "logloss": 3.3131992185121018,
            "mae": 0.3987296935386314,
            "precision": 0.7361477572559367,
            "recall": 0.5764462809917356
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7598235754384742,
            "auditor_fn_violation": 0.013368521848798377,
            "auditor_fp_violation": 0.012955786046581092,
            "ave_precision_score": 0.6921862751565282,
            "fpr": 0.1251372118551043,
            "logloss": 3.505214279169099,
            "mae": 0.4008011862111983,
            "precision": 0.715,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7827397077819005,
            "auditor_fn_violation": 0.010448383355081924,
            "auditor_fp_violation": 0.014905107394654865,
            "ave_precision_score": 0.7264255075056743,
            "fpr": 0.12828947368421054,
            "logloss": 3.2844745435213554,
            "mae": 0.39966241554602333,
            "precision": 0.7180722891566265,
            "recall": 0.6157024793388429
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7820432865243794,
            "auditor_fn_violation": 0.011385664572482895,
            "auditor_fp_violation": 0.017361500033602904,
            "ave_precision_score": 0.720783268155382,
            "fpr": 0.14818880351262348,
            "logloss": 3.4455359321871875,
            "mae": 0.4019329513859683,
            "precision": 0.7,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7543856166339372,
            "auditor_fn_violation": 0.0061077279976801445,
            "auditor_fp_violation": 0.01394952041318249,
            "ave_precision_score": 0.753632020622258,
            "fpr": 0.13706140350877194,
            "logloss": 0.672990175644388,
            "mae": 0.3918985136898986,
            "precision": 0.7216035634743875,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7279921299178224,
            "auditor_fn_violation": 0.008769881121984263,
            "auditor_fp_violation": 0.018446749354699806,
            "ave_precision_score": 0.7271942366932085,
            "fpr": 0.15587266739846323,
            "logloss": 0.7011151019409256,
            "mae": 0.3987877359439984,
            "precision": 0.69593147751606,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.797400896809035,
            "auditor_fn_violation": 0.014759587501812376,
            "auditor_fp_violation": 0.010934169535989509,
            "ave_precision_score": 0.7640659688637458,
            "fpr": 0.11513157894736842,
            "logloss": 2.3837518124992085,
            "mae": 0.29685678389541226,
            "precision": 0.7591743119266054,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7917942943392279,
            "auditor_fn_violation": 0.01915127169115071,
            "auditor_fp_violation": 0.018964482975773553,
            "ave_precision_score": 0.7538881565061363,
            "fpr": 0.11964873765093303,
            "logloss": 2.5385451781997315,
            "mae": 0.2910525903147139,
            "precision": 0.7517084282460137,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7731816408269984,
            "auditor_fn_violation": 0.01362458315209511,
            "auditor_fp_violation": 0.01292220036071487,
            "ave_precision_score": 0.7167494805376713,
            "fpr": 0.11403508771929824,
            "logloss": 3.3117754353491926,
            "mae": 0.389490170208416,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7751152644343327,
            "auditor_fn_violation": 0.012730924632739334,
            "auditor_fp_violation": 0.01603480762960143,
            "ave_precision_score": 0.7131973608451552,
            "fpr": 0.12733260153677278,
            "logloss": 3.4735155352741915,
            "mae": 0.38900829765017264,
            "precision": 0.7257683215130024,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7733975950267201,
            "auditor_fn_violation": 0.01383300710453821,
            "auditor_fp_violation": 0.013875225446794554,
            "ave_precision_score": 0.7167091494944176,
            "fpr": 0.11403508771929824,
            "logloss": 3.271000359120776,
            "mae": 0.3946832429879629,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7734368583290122,
            "auditor_fn_violation": 0.01232220846859892,
            "auditor_fp_violation": 0.015128773792722372,
            "ave_precision_score": 0.7117929079800202,
            "fpr": 0.1350164654226125,
            "logloss": 3.424469307423826,
            "mae": 0.396193145953531,
            "precision": 0.7112676056338029,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7842939571221061,
            "auditor_fn_violation": 0.010448383355081924,
            "auditor_fp_violation": 0.014905107394654865,
            "ave_precision_score": 0.7279766064166886,
            "fpr": 0.12828947368421054,
            "logloss": 3.290616908250915,
            "mae": 0.3999158901472888,
            "precision": 0.7180722891566265,
            "recall": 0.6157024793388429
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7823982108502654,
            "auditor_fn_violation": 0.011385664572482895,
            "auditor_fp_violation": 0.018882342545507053,
            "ave_precision_score": 0.7205237335270602,
            "fpr": 0.14709110867178923,
            "logloss": 3.469964494193853,
            "mae": 0.4022414100680472,
            "precision": 0.7015590200445434,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.774253089693713,
            "auditor_fn_violation": 0.011909616499927505,
            "auditor_fp_violation": 0.012886333825217249,
            "ave_precision_score": 0.7176028723964349,
            "fpr": 0.1162280701754386,
            "logloss": 3.2720810237739553,
            "mae": 0.39504944011903415,
            "precision": 0.7329974811083123,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.77399974547394,
            "auditor_fn_violation": 0.010495831095125767,
            "auditor_fp_violation": 0.01512628468877489,
            "ave_precision_score": 0.7117936985264782,
            "fpr": 0.1394072447859495,
            "logloss": 3.4418162879873533,
            "mae": 0.39434212850271305,
            "precision": 0.7066974595842956,
            "recall": 0.6510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.773770340733695,
            "auditor_fn_violation": 0.012609649122807019,
            "auditor_fp_violation": 0.01152852926709297,
            "ave_precision_score": 0.7171204432646288,
            "fpr": 0.11403508771929824,
            "logloss": 3.254931934280408,
            "mae": 0.39313481185088406,
            "precision": 0.7353689567430025,
            "recall": 0.5971074380165289
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7734554970589362,
            "auditor_fn_violation": 0.012597799939276457,
            "auditor_fp_violation": 0.010827602171494291,
            "ave_precision_score": 0.7118433262457318,
            "fpr": 0.13172338090010977,
            "logloss": 3.419675366981026,
            "mae": 0.39452249597762606,
            "precision": 0.7115384615384616,
            "recall": 0.6297872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7738967571192206,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.7125913702408949,
            "fpr": 0.10855263157894737,
            "logloss": 3.3488627325488753,
            "mae": 0.4029815626379691,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7738795562172672,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.019967591866603948,
            "ave_precision_score": 0.7067371425844278,
            "fpr": 0.12294182217343579,
            "logloss": 3.571523607020875,
            "mae": 0.4049702064593197,
            "precision": 0.7150127226463104,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 8233,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7459906050702259,
            "auditor_fn_violation": 0.014938560243584172,
            "auditor_fp_violation": 0.005472208558780134,
            "ave_precision_score": 0.6471246502176664,
            "fpr": 0.08552631578947369,
            "logloss": 0.6723492623318332,
            "mae": 0.42956345394384443,
            "precision": 0.7523809523809524,
            "recall": 0.4896694214876033
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7174607709016505,
            "auditor_fn_violation": 0.009587313450265087,
            "auditor_fp_violation": 0.01678153881384241,
            "ave_precision_score": 0.6404390063015106,
            "fpr": 0.09110867178924259,
            "logloss": 0.6736363316901074,
            "mae": 0.4266088868927877,
            "precision": 0.7469512195121951,
            "recall": 0.5212765957446809
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7695003310687742,
            "auditor_fn_violation": 0.00656082354646948,
            "auditor_fp_violation": 0.008054599114608957,
            "ave_precision_score": 0.7118695385006976,
            "fpr": 0.36403508771929827,
            "logloss": 3.328330135795022,
            "mae": 0.3959038474090528,
            "precision": 0.5808080808080808,
            "recall": 0.9504132231404959
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7686720885755414,
            "auditor_fn_violation": 0.007459653875796997,
            "auditor_fp_violation": 0.007424997075302867,
            "ave_precision_score": 0.7055320760288928,
            "fpr": 0.3677277716794731,
            "logloss": 3.5261751865561757,
            "mae": 0.39734614775418975,
            "precision": 0.5727040816326531,
            "recall": 0.9553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.86306766399244,
            "auditor_fn_violation": 0.01580850369725968,
            "auditor_fp_violation": 0.013275741924905724,
            "ave_precision_score": 0.8633190185386503,
            "fpr": 0.12390350877192982,
            "logloss": 0.4745239810859988,
            "mae": 0.30881678677172186,
            "precision": 0.7788649706457925,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8620156521306535,
            "auditor_fn_violation": 0.010925566947707691,
            "auditor_fp_violation": 0.018790245699450658,
            "ave_precision_score": 0.8622084677873287,
            "fpr": 0.14270032930845225,
            "logloss": 0.4778967841851507,
            "mae": 0.31603537166018847,
            "precision": 0.7470817120622568,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7677107590396401,
            "auditor_fn_violation": 0.0061077279976801445,
            "auditor_fp_violation": 0.012035784554845066,
            "ave_precision_score": 0.7098805278545165,
            "fpr": 0.1337719298245614,
            "logloss": 3.2809730500784307,
            "mae": 0.3759074696388684,
            "precision": 0.726457399103139,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7623918326355819,
            "auditor_fn_violation": 0.007419950019851934,
            "auditor_fp_violation": 0.016901015803320967,
            "ave_precision_score": 0.6990951299702639,
            "fpr": 0.1525795828759605,
            "logloss": 3.497130796802399,
            "mae": 0.3824038110697963,
            "precision": 0.6991341991341992,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7739099886468499,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.712613481952268,
            "fpr": 0.10855263157894737,
            "logloss": 3.356087471060096,
            "mae": 0.40265456574004993,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7739145887802765,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.7067774634291495,
            "fpr": 0.12403951701427003,
            "logloss": 3.581268675622569,
            "mae": 0.40455894864089664,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7739139503624991,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.7126214053835664,
            "fpr": 0.10855263157894737,
            "logloss": 3.359758992529284,
            "mae": 0.40248097436862035,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7739145887802765,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.7067774634291495,
            "fpr": 0.12403951701427003,
            "logloss": 3.586214392079242,
            "mae": 0.4043367703319512,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8606812623578013,
            "auditor_fn_violation": 0.009859359141655795,
            "auditor_fp_violation": 0.01939098622725037,
            "ave_precision_score": 0.8609361341587882,
            "fpr": 0.16337719298245615,
            "logloss": 0.49464343652211085,
            "mae": 0.32589990298443455,
            "precision": 0.7408695652173913,
            "recall": 0.8801652892561983
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8486351542164713,
            "auditor_fn_violation": 0.011934511992900016,
            "auditor_fp_violation": 0.029861780057796994,
            "ave_precision_score": 0.8488839206174255,
            "fpr": 0.18880351262349068,
            "logloss": 0.5118275962334239,
            "mae": 0.3360206435437587,
            "precision": 0.7074829931972789,
            "recall": 0.8851063829787233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8078458122729905,
            "auditor_fn_violation": 0.002211106278091924,
            "auditor_fp_violation": 0.018012686505984594,
            "ave_precision_score": 0.7659903101482071,
            "fpr": 0.18311403508771928,
            "logloss": 2.5836906798942105,
            "mae": 0.3114608929751915,
            "precision": 0.7202680067001676,
            "recall": 0.8884297520661157
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7964955391030497,
            "auditor_fn_violation": 0.008342480790340289,
            "auditor_fp_violation": 0.023850594024657064,
            "ave_precision_score": 0.7479512252532976,
            "fpr": 0.20087815587266739,
            "logloss": 2.8331426969468465,
            "mae": 0.3226609091324533,
            "precision": 0.6934673366834171,
            "recall": 0.8808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7410236215620964,
            "auditor_fn_violation": 0.003833188342757722,
            "auditor_fp_violation": 0.010708722741433025,
            "ave_precision_score": 0.742415213178288,
            "fpr": 0.3684210526315789,
            "logloss": 0.9425317189772816,
            "mae": 0.40567454730013486,
            "precision": 0.5778894472361809,
            "recall": 0.9504132231404959
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.7154651809274083,
            "auditor_fn_violation": 0.0009528925426816468,
            "auditor_fp_violation": 0.005122575923893162,
            "ave_precision_score": 0.7170757920152248,
            "fpr": 0.3765093304061471,
            "logloss": 0.8107135233990334,
            "mae": 0.4055140945246662,
            "precision": 0.5608194622279129,
            "recall": 0.9319148936170213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7284534748112019,
            "auditor_fn_violation": 0.007720748151370167,
            "auditor_fp_violation": 0.014871802754549931,
            "ave_precision_score": 0.7270757099056586,
            "fpr": 0.13048245614035087,
            "logloss": 0.6926224180058189,
            "mae": 0.4029498062047519,
            "precision": 0.7173396674584323,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7030109261712039,
            "auditor_fn_violation": 0.01041642338323564,
            "auditor_fp_violation": 0.017311717954653503,
            "ave_precision_score": 0.7015161771818043,
            "fpr": 0.14928649835345773,
            "logloss": 0.7113070750194299,
            "mae": 0.40126180504862746,
            "precision": 0.7017543859649122,
            "recall": 0.6808510638297872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8006659765941383,
            "auditor_fn_violation": 0.005772437291576043,
            "auditor_fp_violation": 0.014999897524184293,
            "ave_precision_score": 0.7673089734321352,
            "fpr": 0.11951754385964912,
            "logloss": 2.354475212046315,
            "mae": 0.2907555759667415,
            "precision": 0.7604395604395604,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7933288751413274,
            "auditor_fn_violation": 0.019805217553775366,
            "auditor_fp_violation": 0.021792105060099425,
            "ave_precision_score": 0.755400690355251,
            "fpr": 0.12623490669593854,
            "logloss": 2.519451522075779,
            "mae": 0.2873426749310676,
            "precision": 0.7494553376906318,
            "recall": 0.7319148936170212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7735409463281366,
            "auditor_fn_violation": 0.014122988255763374,
            "auditor_fp_violation": 0.012886333825217249,
            "ave_precision_score": 0.7168824112854842,
            "fpr": 0.1162280701754386,
            "logloss": 3.272585264613279,
            "mae": 0.3944929476435247,
            "precision": 0.7329974811083123,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.773858054545095,
            "auditor_fn_violation": 0.010031062428474681,
            "auditor_fp_violation": 0.013799592284773413,
            "ave_precision_score": 0.7122322689031236,
            "fpr": 0.13830954994511527,
            "logloss": 3.423515150719745,
            "mae": 0.39607638114108473,
            "precision": 0.7076566125290024,
            "recall": 0.648936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7691998378399519,
            "auditor_fn_violation": 0.0061077279976801445,
            "auditor_fp_violation": 0.013311608460403352,
            "ave_precision_score": 0.7111486479373745,
            "fpr": 0.13596491228070176,
            "logloss": 3.2851424994571383,
            "mae": 0.3782922709197329,
            "precision": 0.7232142857142857,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7636153665259753,
            "auditor_fn_violation": 0.00788471868650303,
            "auditor_fp_violation": 0.016901015803320967,
            "ave_precision_score": 0.7001473397353027,
            "fpr": 0.1525795828759605,
            "logloss": 3.5028031174868146,
            "mae": 0.3851400467553856,
            "precision": 0.6997840172786177,
            "recall": 0.6893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7969810531657894,
            "auditor_fn_violation": 0.011766891402058865,
            "auditor_fp_violation": 0.011518281685522214,
            "ave_precision_score": 0.7635988665249128,
            "fpr": 0.1162280701754386,
            "logloss": 2.3869143526622425,
            "mae": 0.29797141418844386,
            "precision": 0.7585421412300684,
            "recall": 0.6880165289256198
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7908398784174582,
            "auditor_fn_violation": 0.01915127169115071,
            "auditor_fp_violation": 0.02007960154424009,
            "ave_precision_score": 0.7529065624140905,
            "fpr": 0.12184412733260154,
            "logloss": 2.5436249022848703,
            "mae": 0.2927695681385974,
            "precision": 0.7482993197278912,
            "recall": 0.7021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7511510333255712,
            "auditor_fn_violation": 0.0032147129186603104,
            "auditor_fp_violation": 0.00396581406787998,
            "ave_precision_score": 0.7333785676610507,
            "fpr": 0.02850877192982456,
            "logloss": 0.8003386747076516,
            "mae": 0.41641857744751004,
            "precision": 0.8129496402877698,
            "recall": 0.2334710743801653
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7490237184502434,
            "auditor_fn_violation": 0.005726697339841665,
            "auditor_fp_violation": 0.004248900438331206,
            "ave_precision_score": 0.7349412477004522,
            "fpr": 0.024149286498353458,
            "logloss": 0.777137674438033,
            "mae": 0.411297884948418,
            "precision": 0.828125,
            "recall": 0.225531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8030387570671214,
            "auditor_fn_violation": 0.0071407858489198235,
            "auditor_fp_violation": 0.015950360714871298,
            "ave_precision_score": 0.7772604221733662,
            "fpr": 0.12938596491228072,
            "logloss": 1.9702181070832245,
            "mae": 0.2817535464777744,
            "precision": 0.7531380753138075,
            "recall": 0.743801652892562
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7923172532249011,
            "auditor_fn_violation": 0.01642571875656865,
            "auditor_fp_violation": 0.01884002777840006,
            "ave_precision_score": 0.7599816036745706,
            "fpr": 0.13172338090010977,
            "logloss": 2.205078813896108,
            "mae": 0.2778045496334765,
            "precision": 0.7515527950310559,
            "recall": 0.7723404255319148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8007701237365883,
            "auditor_fn_violation": 0.007326555023923445,
            "auditor_fp_violation": 0.013198885063125101,
            "ave_precision_score": 0.7676009386114524,
            "fpr": 0.1162280701754386,
            "logloss": 2.3525653990741278,
            "mae": 0.2924280182541176,
            "precision": 0.7628635346756152,
            "recall": 0.7045454545454546
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7928238002299239,
            "auditor_fn_violation": 0.013158324964383314,
            "auditor_fp_violation": 0.014658333146650536,
            "ave_precision_score": 0.7547573040201043,
            "fpr": 0.1251372118551043,
            "logloss": 2.526675752737524,
            "mae": 0.2914419824903592,
            "precision": 0.7477876106194691,
            "recall": 0.7191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7542794461709218,
            "auditor_fn_violation": 0.01063868348557344,
            "auditor_fp_violation": 0.013311608460403343,
            "ave_precision_score": 0.6959106365484192,
            "fpr": 0.11951754385964912,
            "logloss": 3.3628876557122966,
            "mae": 0.39462928637339356,
            "precision": 0.7295285359801489,
            "recall": 0.6074380165289256
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7620187921245479,
            "auditor_fn_violation": 0.011721979587547,
            "auditor_fp_violation": 0.01682634268489687,
            "ave_precision_score": 0.6982895313090618,
            "fpr": 0.13391877058177826,
            "logloss": 3.565585830540086,
            "mae": 0.39399638878330834,
            "precision": 0.7182448036951501,
            "recall": 0.6617021276595745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8627009366106236,
            "auditor_fn_violation": 0.01276370160939539,
            "auditor_fp_violation": 0.017490059845876375,
            "ave_precision_score": 0.8629454388210662,
            "fpr": 0.14144736842105263,
            "logloss": 0.4866319689020002,
            "mae": 0.318361293738953,
            "precision": 0.7588785046728972,
            "recall": 0.8388429752066116
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8625654468163041,
            "auditor_fn_violation": 0.012308195342971251,
            "auditor_fp_violation": 0.016171708346712273,
            "ave_precision_score": 0.8627816545509697,
            "fpr": 0.1602634467618002,
            "logloss": 0.4885224261181138,
            "mae": 0.3235223893419677,
            "precision": 0.7345454545454545,
            "recall": 0.8595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7771014778794658,
            "auditor_fn_violation": 0.00877192982456141,
            "auditor_fp_violation": 0.00774717166748647,
            "ave_precision_score": 0.7774378202025233,
            "fpr": 0.16776315789473684,
            "logloss": 0.6889332159351397,
            "mae": 0.3889037419412808,
            "precision": 0.697029702970297,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7416951996936547,
            "auditor_fn_violation": 0.013377863932550164,
            "auditor_fp_violation": 0.015218381534831288,
            "ave_precision_score": 0.7421893341316127,
            "fpr": 0.21075740944017562,
            "logloss": 0.7232706927208881,
            "mae": 0.39875905228416825,
            "precision": 0.6307692307692307,
            "recall": 0.6978723404255319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7892480342209859,
            "auditor_fn_violation": 0.009949978251413655,
            "auditor_fp_violation": 0.01391877766847024,
            "ave_precision_score": 0.7898905614665586,
            "fpr": 0.0756578947368421,
            "logloss": 0.5347325246418436,
            "mae": 0.34380744758697224,
            "precision": 0.8155080213903744,
            "recall": 0.6301652892561983
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7990867206620085,
            "auditor_fn_violation": 0.00912721582548988,
            "auditor_fp_violation": 0.009431214856963644,
            "ave_precision_score": 0.7996486671995005,
            "fpr": 0.07903402854006586,
            "logloss": 0.5290451792256045,
            "mae": 0.34022185520875203,
            "precision": 0.8100263852242744,
            "recall": 0.6531914893617021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7825305812755474,
            "auditor_fn_violation": 0.010448383355081924,
            "auditor_fp_violation": 0.014905107394654865,
            "ave_precision_score": 0.7262147578100354,
            "fpr": 0.12828947368421054,
            "logloss": 3.283252146349198,
            "mae": 0.39946794186375795,
            "precision": 0.7180722891566265,
            "recall": 0.6157024793388429
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7816400553482191,
            "auditor_fn_violation": 0.011385664572482895,
            "auditor_fp_violation": 0.017361500033602904,
            "ave_precision_score": 0.7203815994825158,
            "fpr": 0.14818880351262348,
            "logloss": 3.4433421969103275,
            "mae": 0.401687915938878,
            "precision": 0.7,
            "recall": 0.6702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.773431102511686,
            "auditor_fn_violation": 0.014122988255763374,
            "auditor_fp_violation": 0.012886333825217249,
            "ave_precision_score": 0.7167825892806251,
            "fpr": 0.1162280701754386,
            "logloss": 3.2716724021931403,
            "mae": 0.39461606773636054,
            "precision": 0.7329974811083123,
            "recall": 0.6012396694214877
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7735892252406409,
            "auditor_fn_violation": 0.010031062428474681,
            "auditor_fp_violation": 0.013799592284773413,
            "ave_precision_score": 0.7119700924287382,
            "fpr": 0.13830954994511527,
            "logloss": 3.4250110166685173,
            "mae": 0.39609487735908755,
            "precision": 0.7076566125290024,
            "recall": 0.648936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7615330223460341,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6943264946796637,
            "fpr": 0.10855263157894737,
            "logloss": 3.359209489266339,
            "mae": 0.4018352329077428,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7644201961628116,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6931705468205663,
            "fpr": 0.12403951701427003,
            "logloss": 3.5851628443738965,
            "mae": 0.4033282969380053,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6584288370341294,
            "auditor_fn_violation": 0.006187019718718286,
            "auditor_fp_violation": 0.0011477291359239224,
            "ave_precision_score": 0.5451382626592687,
            "fpr": 0.010964912280701754,
            "logloss": 0.691277138329938,
            "mae": 0.49845573508687185,
            "precision": 0.7560975609756098,
            "recall": 0.0640495867768595
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.6453178643996543,
            "auditor_fn_violation": 0.0028773617955485053,
            "auditor_fp_violation": 0.0018867407921822226,
            "ave_precision_score": 0.5278697713525001,
            "fpr": 0.008781558726673985,
            "logloss": 0.6913806070569158,
            "mae": 0.49858617605937955,
            "precision": 0.75,
            "recall": 0.05106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7860192235266247,
            "auditor_fn_violation": 0.011930005799623025,
            "auditor_fp_violation": 0.012901705197573374,
            "ave_precision_score": 0.7818707889739728,
            "fpr": 0.07236842105263158,
            "logloss": 0.5651875449340967,
            "mae": 0.35478453376360497,
            "precision": 0.8206521739130435,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7879687234853471,
            "auditor_fn_violation": 0.00993764159095687,
            "auditor_fp_violation": 0.011813287334692385,
            "ave_precision_score": 0.7887831651760483,
            "fpr": 0.07683863885839737,
            "logloss": 0.5526354774987828,
            "mae": 0.3473917960131011,
            "precision": 0.8123324396782842,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 8233,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7574804833738151,
            "auditor_fn_violation": 0.013563415253008556,
            "auditor_fp_violation": 0.008705320544351533,
            "ave_precision_score": 0.7267067737028847,
            "fpr": 0.23026315789473684,
            "logloss": 2.3933364158237813,
            "mae": 0.35275724545946313,
            "precision": 0.6574225122349103,
            "recall": 0.8326446280991735
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7533344773072315,
            "auditor_fn_violation": 0.012191419296073994,
            "auditor_fp_violation": 0.01085996052281139,
            "ave_precision_score": 0.714647830452573,
            "fpr": 0.23600439077936333,
            "logloss": 2.6970845946913222,
            "mae": 0.3465002118942096,
            "precision": 0.656,
            "recall": 0.8723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7888586643375781,
            "auditor_fn_violation": 0.016093953892996962,
            "auditor_fp_violation": 0.025342269224463036,
            "ave_precision_score": 0.7312159083288676,
            "fpr": 0.16666666666666666,
            "logloss": 3.2198205134238833,
            "mae": 0.3351390630235536,
            "precision": 0.7190388170055453,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.78770485533123,
            "auditor_fn_violation": 0.013373192890674268,
            "auditor_fp_violation": 0.0259513977563217,
            "ave_precision_score": 0.7244531471129527,
            "fpr": 0.17892425905598244,
            "logloss": 3.4117430115988503,
            "mae": 0.33640537825622624,
            "precision": 0.7020109689213894,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.697310834069979,
            "auditor_fn_violation": 0.004870777149485287,
            "auditor_fp_violation": 0.0016575463190687,
            "ave_precision_score": 0.5472476345489156,
            "fpr": 0.005482456140350877,
            "logloss": 0.6915073134336611,
            "mae": 0.49890631074576003,
            "precision": 0.8387096774193549,
            "recall": 0.05371900826446281
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6298343691014826,
            "auditor_fn_violation": 8.87497956419311e-05,
            "auditor_fp_violation": 0.0008363389263499032,
            "ave_precision_score": 0.52311167824165,
            "fpr": 0.006586169045005488,
            "logloss": 0.6926349065990673,
            "mae": 0.4995083113075219,
            "precision": 0.7272727272727273,
            "recall": 0.03404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7303946482538454,
            "auditor_fn_violation": 0.007720748151370167,
            "auditor_fp_violation": 0.013926463354648306,
            "ave_precision_score": 0.7290201305126389,
            "fpr": 0.12828947368421054,
            "logloss": 0.6992702146379068,
            "mae": 0.40212435499298804,
            "precision": 0.720763723150358,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7026162028881981,
            "auditor_fn_violation": 0.013555363523833994,
            "auditor_fp_violation": 0.016395727701984567,
            "ave_precision_score": 0.7009887939942558,
            "fpr": 0.14709110867178923,
            "logloss": 0.7020885128835195,
            "mae": 0.4007205684160078,
            "precision": 0.7035398230088495,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 8233,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5055085917443646,
            "auditor_fn_violation": 0.007034308394954341,
            "auditor_fp_violation": 0.005249323659616333,
            "ave_precision_score": 0.5274898883163892,
            "fpr": 0.03179824561403509,
            "logloss": 9.08870660035064,
            "mae": 0.5678461648228178,
            "precision": 0.6777777777777778,
            "recall": 0.12603305785123967
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.473172620713745,
            "auditor_fn_violation": 0.007226101782002492,
            "auditor_fp_violation": 0.007265694422664785,
            "ave_precision_score": 0.5021501691491521,
            "fpr": 0.04610318331503842,
            "logloss": 9.57515240949198,
            "mae": 0.5766675435103705,
            "precision": 0.6,
            "recall": 0.13404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7252269708281833,
            "auditor_fn_violation": 0.0061077279976801445,
            "auditor_fp_violation": 0.01394952041318249,
            "ave_precision_score": 0.7218592859766412,
            "fpr": 0.13706140350877194,
            "logloss": 0.6786361097555815,
            "mae": 0.3936036562449054,
            "precision": 0.7216035634743875,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7299875441694803,
            "auditor_fn_violation": 0.008769881121984263,
            "auditor_fp_violation": 0.018446749354699806,
            "ave_precision_score": 0.72605679520731,
            "fpr": 0.15587266739846323,
            "logloss": 0.7027019670888803,
            "mae": 0.39920958300845943,
            "precision": 0.69593147751606,
            "recall": 0.6914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7562031208483557,
            "auditor_fn_violation": 0.008250869943453682,
            "auditor_fp_violation": 0.013537055254959842,
            "ave_precision_score": 0.7378843401571353,
            "fpr": 0.12938596491228072,
            "logloss": 0.6798791078149494,
            "mae": 0.39184789486081273,
            "precision": 0.6793478260869565,
            "recall": 0.5165289256198347
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.754855960914313,
            "auditor_fn_violation": 0.007683863885839735,
            "auditor_fp_violation": 0.01655503035462264,
            "ave_precision_score": 0.7403858353637083,
            "fpr": 0.11855104281009879,
            "logloss": 0.6496974604580209,
            "mae": 0.38853524190579264,
            "precision": 0.685131195335277,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8008658798265437,
            "auditor_fn_violation": 0.008099082934609252,
            "auditor_fp_violation": 0.011787280701754386,
            "ave_precision_score": 0.74323756566307,
            "fpr": 0.11732456140350878,
            "logloss": 3.22029869837685,
            "mae": 0.29286340565094926,
            "precision": 0.7611607142857143,
            "recall": 0.7045454545454546
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7977477492053764,
            "auditor_fn_violation": 0.012836023074946874,
            "auditor_fp_violation": 0.013483476083444725,
            "ave_precision_score": 0.7345938584765919,
            "fpr": 0.12623490669593854,
            "logloss": 3.4018707876416943,
            "mae": 0.2918678019540824,
            "precision": 0.7450110864745011,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8138531402076823,
            "auditor_fn_violation": 0.014634986225895319,
            "auditor_fp_violation": 0.014185214789309725,
            "ave_precision_score": 0.8145530323029885,
            "fpr": 0.11074561403508772,
            "logloss": 0.6305969353702466,
            "mae": 0.4011380371108604,
            "precision": 0.7430025445292621,
            "recall": 0.6033057851239669
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8160785456882318,
            "auditor_fn_violation": 0.010792442254244805,
            "auditor_fp_violation": 0.015823233794066482,
            "ave_precision_score": 0.8163937073876845,
            "fpr": 0.12623490669593854,
            "logloss": 0.6262171211381221,
            "mae": 0.397575755278837,
            "precision": 0.7287735849056604,
            "recall": 0.6574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7691272997424247,
            "auditor_fn_violation": 0.002664201826881256,
            "auditor_fp_violation": 0.010549885227086416,
            "ave_precision_score": 0.7115121848807007,
            "fpr": 0.23026315789473684,
            "logloss": 3.3155913242269115,
            "mae": 0.3898518423533492,
            "precision": 0.6341463414634146,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7642804232318541,
            "auditor_fn_violation": 0.00661886633813672,
            "auditor_fp_violation": 0.009070294784580499,
            "ave_precision_score": 0.7011381787603672,
            "fpr": 0.2645444566410538,
            "logloss": 3.519028825005379,
            "mae": 0.39097533212273367,
            "precision": 0.6003316749585407,
            "recall": 0.7702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7806610267675835,
            "auditor_fn_violation": 0.00679416775409599,
            "auditor_fp_violation": 0.005710464830300046,
            "ave_precision_score": 0.7809869165303142,
            "fpr": 0.16557017543859648,
            "logloss": 0.6823726659053884,
            "mae": 0.38832493130885587,
            "precision": 0.6918367346938775,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7450372808303041,
            "auditor_fn_violation": 0.01281266786556742,
            "auditor_fp_violation": 0.008803960662201215,
            "ave_precision_score": 0.745527994859127,
            "fpr": 0.21295279912184412,
            "logloss": 0.715841194889729,
            "mae": 0.39841664074608313,
            "precision": 0.6196078431372549,
            "recall": 0.6723404255319149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 8233,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8008434032282143,
            "auditor_fn_violation": 0.008164781789183704,
            "auditor_fp_violation": 0.01347044597474996,
            "ave_precision_score": 0.7676187862373008,
            "fpr": 0.1206140350877193,
            "logloss": 2.3391963115986543,
            "mae": 0.28995643224296047,
            "precision": 0.7603485838779956,
            "recall": 0.7210743801652892
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7936268180974885,
            "auditor_fn_violation": 0.016556507929093585,
            "auditor_fp_violation": 0.018832560466557645,
            "ave_precision_score": 0.7558532538019372,
            "fpr": 0.12623490669593854,
            "logloss": 2.506359675637933,
            "mae": 0.2867993355660191,
            "precision": 0.7532188841201717,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7685740878562528,
            "auditor_fn_violation": 0.01362458315209511,
            "auditor_fp_violation": 0.01292220036071487,
            "ave_precision_score": 0.7122166065077318,
            "fpr": 0.11403508771929824,
            "logloss": 3.3141680056410134,
            "mae": 0.3908305999153016,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7720373764907463,
            "auditor_fn_violation": 0.012354905761730156,
            "auditor_fp_violation": 0.014538856157171981,
            "ave_precision_score": 0.7101219432871051,
            "fpr": 0.12843029637760703,
            "logloss": 3.471777096290319,
            "mae": 0.39027978016961157,
            "precision": 0.7259953161592506,
            "recall": 0.6595744680851063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8010151713262559,
            "auditor_fn_violation": 0.0112390350877193,
            "auditor_fp_violation": 0.013465322183964594,
            "ave_precision_score": 0.7723996273397425,
            "fpr": 0.11842105263157894,
            "logloss": 2.0431188005734593,
            "mae": 0.28314157142953617,
            "precision": 0.7707006369426752,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7957434842877479,
            "auditor_fn_violation": 0.01924469252866853,
            "auditor_fp_violation": 0.015820744690119005,
            "ave_precision_score": 0.7605267644444026,
            "fpr": 0.13062568605927552,
            "logloss": 2.252123209960267,
            "mae": 0.2736234029489324,
            "precision": 0.7546391752577319,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7888724739795128,
            "auditor_fn_violation": 0.016093953892996962,
            "auditor_fp_violation": 0.025342269224463036,
            "ave_precision_score": 0.731185914345077,
            "fpr": 0.16666666666666666,
            "logloss": 3.2200903129835963,
            "mae": 0.33512724366594565,
            "precision": 0.7190388170055453,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7877887278299658,
            "auditor_fn_violation": 0.013373192890674268,
            "auditor_fp_violation": 0.0259513977563217,
            "ave_precision_score": 0.7244351855856375,
            "fpr": 0.17892425905598244,
            "logloss": 3.4121064195632997,
            "mae": 0.33640741487365916,
            "precision": 0.7020109689213894,
            "recall": 0.8170212765957446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7514937506909984,
            "auditor_fn_violation": 0.010804063360881553,
            "auditor_fp_violation": 0.012573782587309394,
            "ave_precision_score": 0.6907057792131672,
            "fpr": 0.10964912280701754,
            "logloss": 3.31311577283193,
            "mae": 0.39897366470264206,
            "precision": 0.7361477572559367,
            "recall": 0.5764462809917356
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.76150873708318,
            "auditor_fn_violation": 0.013368521848798377,
            "auditor_fp_violation": 0.012955786046581092,
            "ave_precision_score": 0.6950042971623673,
            "fpr": 0.1251372118551043,
            "logloss": 3.5071597581534912,
            "mae": 0.4008895961967747,
            "precision": 0.715,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7969461449398637,
            "auditor_fn_violation": 0.012836196897201682,
            "auditor_fp_violation": 0.010934169535989509,
            "ave_precision_score": 0.7636946520156429,
            "fpr": 0.11513157894736842,
            "logloss": 2.3683336830873336,
            "mae": 0.29613250160917615,
            "precision": 0.7608200455580866,
            "recall": 0.6900826446280992
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7916949417018919,
            "auditor_fn_violation": 0.01967909942312633,
            "auditor_fp_violation": 0.018964482975773553,
            "ave_precision_score": 0.7538961760598044,
            "fpr": 0.11964873765093303,
            "logloss": 2.524566983255735,
            "mae": 0.2905880049560843,
            "precision": 0.7528344671201814,
            "recall": 0.7063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7384758497791222,
            "auditor_fn_violation": 0.011123495722778017,
            "auditor_fp_violation": 0.0032484833579275313,
            "ave_precision_score": 0.7398646152189308,
            "fpr": 0.16885964912280702,
            "logloss": 0.915656528265305,
            "mae": 0.40432645137045997,
            "precision": 0.6824742268041237,
            "recall": 0.6838842975206612
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7145706391974358,
            "auditor_fn_violation": 0.007020575939463312,
            "auditor_fp_violation": 0.008813917077991094,
            "ave_precision_score": 0.7161863552969938,
            "fpr": 0.21185510428100987,
            "logloss": 0.7798140053579553,
            "mae": 0.4033428496639239,
            "precision": 0.6351606805293005,
            "recall": 0.7148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.812687608931137,
            "auditor_fn_violation": 0.008531789183703066,
            "auditor_fp_violation": 0.012660887030660766,
            "ave_precision_score": 0.813902299072314,
            "fpr": 0.10855263157894737,
            "logloss": 0.7135908877738423,
            "mae": 0.4215605174553506,
            "precision": 0.7435233160621761,
            "recall": 0.5929752066115702
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8161856386790065,
            "auditor_fn_violation": 0.010663988602657833,
            "auditor_fp_violation": 0.014942090996662119,
            "ave_precision_score": 0.8165024005419316,
            "fpr": 0.12184412733260154,
            "logloss": 0.6663689104776024,
            "mae": 0.40939106074153586,
            "precision": 0.7325301204819277,
            "recall": 0.6468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8172196980964138,
            "auditor_fn_violation": 0.004587592431491954,
            "auditor_fp_violation": 0.02086407607804559,
            "ave_precision_score": 0.8175402852495348,
            "fpr": 0.16228070175438597,
            "logloss": 0.7185353547066906,
            "mae": 0.2866542624320222,
            "precision": 0.7243947858472998,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8069654549278484,
            "auditor_fn_violation": 0.012838358595884817,
            "auditor_fp_violation": 0.019554400611323935,
            "ave_precision_score": 0.8073233599358633,
            "fpr": 0.1800219538968167,
            "logloss": 0.7616574069283486,
            "mae": 0.2940861303688342,
            "precision": 0.6979742173112339,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8074061991090942,
            "auditor_fn_violation": 0.016238944468609542,
            "auditor_fp_violation": 0.02531152647975078,
            "ave_precision_score": 0.8081217110957879,
            "fpr": 0.16447368421052633,
            "logloss": 0.5446020701590788,
            "mae": 0.3655891655535813,
            "precision": 0.7201492537313433,
            "recall": 0.7975206611570248
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8255249538521328,
            "auditor_fn_violation": 0.01687180325571619,
            "auditor_fp_violation": 0.024510206570736603,
            "ave_precision_score": 0.8245631270283801,
            "fpr": 0.16575192096597147,
            "logloss": 0.536798868891764,
            "mae": 0.36435674875974655,
            "precision": 0.7161654135338346,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8237856762848769,
            "auditor_fn_violation": 0.014634986225895319,
            "auditor_fp_violation": 0.011682242990654209,
            "ave_precision_score": 0.8238798451826262,
            "fpr": 0.10964912280701754,
            "logloss": 0.6284038804910645,
            "mae": 0.399896308381828,
            "precision": 0.7448979591836735,
            "recall": 0.6033057851239669
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8160083514605991,
            "auditor_fn_violation": 0.010792442254244805,
            "auditor_fp_violation": 0.015823233794066482,
            "ave_precision_score": 0.8163233922982525,
            "fpr": 0.12623490669593854,
            "logloss": 0.6229152080684245,
            "mae": 0.39679737207685517,
            "precision": 0.7287735849056604,
            "recall": 0.6574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8012636406102694,
            "auditor_fn_violation": 0.009995287806292592,
            "auditor_fp_violation": 0.011771909329398264,
            "ave_precision_score": 0.7726446866783225,
            "fpr": 0.11951754385964912,
            "logloss": 2.041241485808972,
            "mae": 0.28276106111131905,
            "precision": 0.7695560253699789,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7953089521750651,
            "auditor_fn_violation": 0.02156152929911017,
            "auditor_fp_violation": 0.014511476013749811,
            "ave_precision_score": 0.7594372986666705,
            "fpr": 0.12952799121844127,
            "logloss": 2.2701340049489422,
            "mae": 0.2732845174554279,
            "precision": 0.757201646090535,
            "recall": 0.7829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7710086365145816,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6995247075366626,
            "fpr": 0.10855263157894737,
            "logloss": 3.3640500685795236,
            "mae": 0.4012500014678951,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7711442236841682,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6953955770815196,
            "fpr": 0.12403951701427003,
            "logloss": 3.5914340463878265,
            "mae": 0.4024866809894696,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8641511326237417,
            "auditor_fn_violation": 0.013166956647817897,
            "auditor_fp_violation": 0.020128812100344316,
            "ave_precision_score": 0.8643828332439951,
            "fpr": 0.15899122807017543,
            "logloss": 0.4902386868579669,
            "mae": 0.3239832270774059,
            "precision": 0.7438162544169611,
            "recall": 0.8698347107438017
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8533178910666966,
            "auditor_fn_violation": 0.014129901674568516,
            "auditor_fp_violation": 0.027101363780052824,
            "ave_precision_score": 0.8535305491506452,
            "fpr": 0.18660812294182216,
            "logloss": 0.5065863137588321,
            "mae": 0.3346084137104705,
            "precision": 0.7098976109215017,
            "recall": 0.8851063829787233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.770712638042671,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6983919686646893,
            "fpr": 0.10855263157894737,
            "logloss": 3.3651746584008957,
            "mae": 0.40104772996876326,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7709948216269775,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6943531649554948,
            "fpr": 0.12403951701427003,
            "logloss": 3.5928937850943408,
            "mae": 0.40220291606681147,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7993821703023172,
            "auditor_fn_violation": 0.011121230245034077,
            "auditor_fp_violation": 0.016145064764715538,
            "ave_precision_score": 0.7678677780111538,
            "fpr": 0.12938596491228072,
            "logloss": 2.1944115297212714,
            "mae": 0.2806501458788325,
            "precision": 0.757700205338809,
            "recall": 0.762396694214876
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7944343347464361,
            "auditor_fn_violation": 0.0160613774902492,
            "auditor_fp_violation": 0.016487824548040955,
            "ave_precision_score": 0.7569834292038864,
            "fpr": 0.1394072447859495,
            "logloss": 2.380858184206547,
            "mae": 0.2749449090525977,
            "precision": 0.7490118577075099,
            "recall": 0.8063829787234043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7733397985995644,
            "auditor_fn_violation": 0.01383300710453821,
            "auditor_fp_violation": 0.013875225446794554,
            "ave_precision_score": 0.7166691903824556,
            "fpr": 0.11403508771929824,
            "logloss": 3.272613541732996,
            "mae": 0.3948289417384321,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7729023038419177,
            "auditor_fn_violation": 0.01232220846859892,
            "auditor_fp_violation": 0.015128773792722372,
            "ave_precision_score": 0.7106701031387964,
            "fpr": 0.1350164654226125,
            "logloss": 3.4455493260917667,
            "mae": 0.39638146709029415,
            "precision": 0.7112676056338029,
            "recall": 0.6446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8614850411131798,
            "auditor_fn_violation": 0.010278472524285924,
            "auditor_fp_violation": 0.020013526807673387,
            "ave_precision_score": 0.8617127765450096,
            "fpr": 0.15789473684210525,
            "logloss": 0.48886298453713,
            "mae": 0.3173115467050178,
            "precision": 0.7396021699819169,
            "recall": 0.8450413223140496
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8609475381557057,
            "auditor_fn_violation": 0.010825139547376045,
            "auditor_fp_violation": 0.020567465917944203,
            "ave_precision_score": 0.8611289410222093,
            "fpr": 0.16575192096597147,
            "logloss": 0.4912450345681109,
            "mae": 0.32211364841479173,
            "precision": 0.7293906810035843,
            "recall": 0.8659574468085106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7543121529774723,
            "auditor_fn_violation": 0.0061077279976801445,
            "auditor_fp_violation": 0.014387604525332021,
            "ave_precision_score": 0.7535596012105865,
            "fpr": 0.13486842105263158,
            "logloss": 0.6645735381828852,
            "mae": 0.3946491248513523,
            "precision": 0.7248322147651006,
            "recall": 0.6694214876033058
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7274291567154649,
            "auditor_fn_violation": 0.010094121493799199,
            "auditor_fp_violation": 0.016744202254630358,
            "ave_precision_score": 0.7265390224584001,
            "fpr": 0.15367727771679474,
            "logloss": 0.6909715673156613,
            "mae": 0.40129012242368495,
            "precision": 0.6976241900647948,
            "recall": 0.6872340425531915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.80262991306639,
            "auditor_fn_violation": 0.008246338987965791,
            "auditor_fp_violation": 0.01606308411214953,
            "ave_precision_score": 0.7689819874936157,
            "fpr": 0.12171052631578948,
            "logloss": 2.3707714787424736,
            "mae": 0.290267868834185,
            "precision": 0.7581699346405228,
            "recall": 0.71900826446281
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7944676230227274,
            "auditor_fn_violation": 0.016885816381343864,
            "auditor_fp_violation": 0.019263175449469948,
            "ave_precision_score": 0.7563588681066965,
            "fpr": 0.12623490669593854,
            "logloss": 2.525866227923757,
            "mae": 0.2874989914685726,
            "precision": 0.7526881720430108,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.8127500424898588,
            "auditor_fn_violation": 0.008531789183703066,
            "auditor_fp_violation": 0.012660887030660766,
            "ave_precision_score": 0.8139647854068179,
            "fpr": 0.10855263157894737,
            "logloss": 0.7103557842027827,
            "mae": 0.4214672950999692,
            "precision": 0.7435233160621761,
            "recall": 0.5929752066115702
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8162074662664491,
            "auditor_fn_violation": 0.010031062428474681,
            "auditor_fp_violation": 0.014942090996662119,
            "ave_precision_score": 0.816524352330469,
            "fpr": 0.12184412733260154,
            "logloss": 0.663384395189959,
            "mae": 0.4089754313690809,
            "precision": 0.7331730769230769,
            "recall": 0.648936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7557894723814282,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.6918001710691654,
            "fpr": 0.10855263157894737,
            "logloss": 3.3589593028874463,
            "mae": 0.40185121838983734,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.760138438210785,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.6911977364885924,
            "fpr": 0.12403951701427003,
            "logloss": 3.5848561964591137,
            "mae": 0.40335767051260246,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7724723545816836,
            "auditor_fn_violation": 0.01362458315209511,
            "auditor_fp_violation": 0.01292220036071487,
            "ave_precision_score": 0.7161026682762314,
            "fpr": 0.11403508771929824,
            "logloss": 3.3110138845629895,
            "mae": 0.3891326241981376,
            "precision": 0.7360406091370558,
            "recall": 0.5991735537190083
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7749038447913001,
            "auditor_fn_violation": 0.011425368428427961,
            "auditor_fp_violation": 0.014538856157171981,
            "ave_precision_score": 0.7129858909907403,
            "fpr": 0.12843029637760703,
            "logloss": 3.4725541229681216,
            "mae": 0.38855727458653555,
            "precision": 0.7247058823529412,
            "recall": 0.6553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8028039888643099,
            "auditor_fn_violation": 0.009070972886762372,
            "auditor_fp_violation": 0.0138265494343335,
            "ave_precision_score": 0.7694863087767767,
            "fpr": 0.12171052631578948,
            "logloss": 2.3370276356886737,
            "mae": 0.2867373640820325,
            "precision": 0.7602591792656588,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7943910217927227,
            "auditor_fn_violation": 0.016909171590723318,
            "auditor_fp_violation": 0.017655214299404358,
            "ave_precision_score": 0.7564911966530505,
            "fpr": 0.12733260153677278,
            "logloss": 2.5050654477582373,
            "mae": 0.28511316993025376,
            "precision": 0.7510729613733905,
            "recall": 0.7446808510638298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7550512277802903,
            "auditor_fn_violation": 0.006918769030013061,
            "auditor_fp_violation": 0.013537055254959842,
            "ave_precision_score": 0.7367471460925249,
            "fpr": 0.12938596491228072,
            "logloss": 0.6834689448660914,
            "mae": 0.39277848903737156,
            "precision": 0.6802168021680217,
            "recall": 0.518595041322314
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7558134373356824,
            "auditor_fn_violation": 0.007763271597729882,
            "auditor_fp_violation": 0.01575602798748479,
            "ave_precision_score": 0.7400183225095399,
            "fpr": 0.11964873765093303,
            "logloss": 0.6519438233195483,
            "mae": 0.3887523067415633,
            "precision": 0.6840579710144927,
            "recall": 0.502127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 8233,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6955638710096748,
            "auditor_fn_violation": 0.004870777149485287,
            "auditor_fp_violation": 0.0016575463190687,
            "ave_precision_score": 0.5479039426953377,
            "fpr": 0.005482456140350877,
            "logloss": 0.6914920672096965,
            "mae": 0.4988920454001218,
            "precision": 0.8387096774193549,
            "recall": 0.05371900826446281
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.6287954546403034,
            "auditor_fn_violation": 8.87497956419311e-05,
            "auditor_fp_violation": 0.0008363389263499032,
            "ave_precision_score": 0.5232804397185256,
            "fpr": 0.006586169045005488,
            "logloss": 0.6926319567591586,
            "mae": 0.49950110068305525,
            "precision": 0.7272727272727273,
            "recall": 0.03404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7731239474992757,
            "auditor_fn_violation": 0.012104447585906918,
            "auditor_fp_violation": 0.014172405312346297,
            "ave_precision_score": 0.7744092948734405,
            "fpr": 0.1787280701754386,
            "logloss": 0.6559534480156607,
            "mae": 0.4436082852587692,
            "precision": 0.7089285714285715,
            "recall": 0.8202479338842975
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7762808218059815,
            "auditor_fn_violation": 0.01041642338323563,
            "auditor_fp_violation": 0.011240793426774295,
            "ave_precision_score": 0.7775974777549853,
            "fpr": 0.18331503841931943,
            "logloss": 0.6424474953104218,
            "mae": 0.441879470265265,
            "precision": 0.6958105646630237,
            "recall": 0.8127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7593533814464661,
            "auditor_fn_violation": 0.007720748151370167,
            "auditor_fp_violation": 0.013926463354648306,
            "ave_precision_score": 0.663594621182889,
            "fpr": 0.12828947368421054,
            "logloss": 0.6873359921465042,
            "mae": 0.4044867115781495,
            "precision": 0.720763723150358,
            "recall": 0.6239669421487604
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7646428071389736,
            "auditor_fn_violation": 0.013555363523833994,
            "auditor_fp_violation": 0.016395727701984567,
            "ave_precision_score": 0.6627324895729041,
            "fpr": 0.14709110867178923,
            "logloss": 0.7035723602856175,
            "mae": 0.40239264007195685,
            "precision": 0.7035398230088495,
            "recall": 0.676595744680851
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.818428200317439,
            "auditor_fn_violation": 0.004587592431491954,
            "auditor_fp_violation": 0.01930644367929169,
            "ave_precision_score": 0.8187432531711071,
            "fpr": 0.16228070175438597,
            "logloss": 0.7130139788731664,
            "mae": 0.2858375624815548,
            "precision": 0.7243947858472998,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8089054981386208,
            "auditor_fn_violation": 0.011373986967793168,
            "auditor_fp_violation": 0.019554400611323935,
            "ave_precision_score": 0.8092607760765054,
            "fpr": 0.1800219538968167,
            "logloss": 0.7542750502379751,
            "mae": 0.29314169466602347,
            "precision": 0.6985294117647058,
            "recall": 0.8085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 8233,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7739036830929718,
            "auditor_fn_violation": 0.012224517906336092,
            "auditor_fp_violation": 0.012438002131496964,
            "ave_precision_score": 0.7126254407761141,
            "fpr": 0.10855263157894737,
            "logloss": 3.370854446272622,
            "mae": 0.401909493563468,
            "precision": 0.7317073170731707,
            "recall": 0.5578512396694215
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7739106429269729,
            "auditor_fn_violation": 0.012037274914169619,
            "auditor_fp_violation": 0.015838168417751302,
            "ave_precision_score": 0.7067848625051164,
            "fpr": 0.12403951701427003,
            "logloss": 3.6011328769094715,
            "mae": 0.40359178322861144,
            "precision": 0.7131979695431472,
            "recall": 0.597872340425532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7976972815597637,
            "auditor_fn_violation": 0.010727037117587362,
            "auditor_fp_violation": 0.012883771929824563,
            "ave_precision_score": 0.7643541518055557,
            "fpr": 0.11732456140350878,
            "logloss": 2.3761032489827216,
            "mae": 0.2957259213112513,
            "precision": 0.7600896860986547,
            "recall": 0.7004132231404959
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7920216484998315,
            "auditor_fn_violation": 0.01845528645164305,
            "auditor_fp_violation": 0.01709267680727615,
            "ave_precision_score": 0.7541151641284912,
            "fpr": 0.12184412733260154,
            "logloss": 2.532180377027966,
            "mae": 0.290403874803633,
            "precision": 0.750561797752809,
            "recall": 0.7106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 8233,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8064477655515341,
            "auditor_fn_violation": 0.015276116427432223,
            "auditor_fp_violation": 0.025987866863420233,
            "ave_precision_score": 0.806364853014299,
            "fpr": 0.16337719298245615,
            "logloss": 0.5446457420163656,
            "mae": 0.3659317431187159,
            "precision": 0.7209737827715356,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8249883008475307,
            "auditor_fn_violation": 0.01687180325571619,
            "auditor_fp_violation": 0.026459174961605575,
            "ave_precision_score": 0.8240569260361573,
            "fpr": 0.1668496158068057,
            "logloss": 0.5370144256163342,
            "mae": 0.36477528415972,
            "precision": 0.7148217636022514,
            "recall": 0.8106382978723404
        }
    }
]