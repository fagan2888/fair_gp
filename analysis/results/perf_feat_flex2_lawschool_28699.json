[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8511671515461792,
            "auditor_fn_violation": 0.011677631578947368,
            "auditor_fp_violation": 0.026216800682261218,
            "ave_precision_score": 0.8513847784517177,
            "fpr": 0.20065789473684212,
            "logloss": 0.7198907216076829,
            "mae": 0.2822941625468133,
            "precision": 0.6985172981878089,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8487254160451143,
            "auditor_fn_violation": 0.017864173000412216,
            "auditor_fp_violation": 0.020077516848485463,
            "ave_precision_score": 0.8490614400820014,
            "fpr": 0.17233809001097694,
            "logloss": 0.6536606242990761,
            "mae": 0.27172398072606874,
            "precision": 0.718132854578097,
            "recall": 0.8438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8070953655363925,
            "auditor_fn_violation": 0.024264437134502922,
            "auditor_fp_violation": 0.025341130604288505,
            "ave_precision_score": 0.7719179215440464,
            "fpr": 0.14583333333333334,
            "logloss": 2.261967320183383,
            "mae": 0.2743543680337672,
            "precision": 0.7495291902071564,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7913910021623102,
            "auditor_fn_violation": 0.020369881476746936,
            "auditor_fp_violation": 0.020203111223866956,
            "ave_precision_score": 0.7576569677866394,
            "fpr": 0.12952799121844127,
            "logloss": 2.187563888079393,
            "mae": 0.2793923050378296,
            "precision": 0.7601626016260162,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8468133971896558,
            "auditor_fn_violation": 0.013555372807017544,
            "auditor_fp_violation": 0.023874065951916826,
            "ave_precision_score": 0.8470425567524398,
            "fpr": 0.21271929824561403,
            "logloss": 0.6976268556726202,
            "mae": 0.2878779694191187,
            "precision": 0.6835236541598695,
            "recall": 0.8729166666666667
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.841925790574988,
            "auditor_fn_violation": 0.015552992723719015,
            "auditor_fp_violation": 0.01927120095853628,
            "ave_precision_score": 0.8425238474734047,
            "fpr": 0.1800219538968167,
            "logloss": 0.6483792669473357,
            "mae": 0.27640792652106155,
            "precision": 0.708185053380783,
            "recall": 0.8396624472573839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8370106680648025,
            "auditor_fn_violation": 0.012280701754385968,
            "auditor_fp_violation": 0.027039169103313856,
            "ave_precision_score": 0.837286270957456,
            "fpr": 0.23135964912280702,
            "logloss": 0.7868141774938593,
            "mae": 0.29831343880416944,
            "precision": 0.671850699844479,
            "recall": 0.9
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8350784105195141,
            "auditor_fn_violation": 0.010819473199108875,
            "auditor_fp_violation": 0.025661442777946634,
            "ave_precision_score": 0.835595458666712,
            "fpr": 0.20087815587266739,
            "logloss": 0.7268818991742353,
            "mae": 0.2844723011241033,
            "precision": 0.6939799331103679,
            "recall": 0.8755274261603375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8489793580510943,
            "auditor_fn_violation": 0.01536229897660819,
            "auditor_fp_violation": 0.02864075698505524,
            "ave_precision_score": 0.8491969155821295,
            "fpr": 0.16228070175438597,
            "logloss": 0.7481730602197642,
            "mae": 0.2681533015259499,
            "precision": 0.728440366972477,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8346137515798692,
            "auditor_fn_violation": 0.020138300286697518,
            "auditor_fp_violation": 0.021383698352452987,
            "ave_precision_score": 0.8350436515708457,
            "fpr": 0.14050493962678376,
            "logloss": 0.738881262739682,
            "mae": 0.2660439172134068,
            "precision": 0.7465346534653465,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7314633687893694,
            "auditor_fn_violation": 0.08406432748538012,
            "auditor_fp_violation": 0.09387183235867447,
            "ave_precision_score": 0.5738584138222114,
            "fpr": 0.2894736842105263,
            "logloss": 14.089378527373633,
            "mae": 0.4189479766891485,
            "precision": 0.5802861685214626,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7220686040173229,
            "auditor_fn_violation": 0.09200257518283335,
            "auditor_fp_violation": 0.09821480154832747,
            "ave_precision_score": 0.5710776075279083,
            "fpr": 0.27552140504939626,
            "logloss": 14.071893532502429,
            "mae": 0.4262777452645638,
            "precision": 0.5738539898132428,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8421308933908604,
            "auditor_fn_violation": 0.00940241228070176,
            "auditor_fp_violation": 0.026853882391163097,
            "ave_precision_score": 0.8423619742555937,
            "fpr": 0.15350877192982457,
            "logloss": 0.7746771927010209,
            "mae": 0.2708111225809054,
            "precision": 0.7343453510436433,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8213393402139885,
            "auditor_fn_violation": 0.017813225138601344,
            "auditor_fp_violation": 0.022097074404619867,
            "ave_precision_score": 0.8221491233302523,
            "fpr": 0.1251372118551043,
            "logloss": 0.8079624704811613,
            "mae": 0.2713414078286739,
            "precision": 0.76,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8495747058593763,
            "auditor_fn_violation": 0.01768777412280702,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8498019054781147,
            "fpr": 0.1600877192982456,
            "logloss": 0.7393821367395129,
            "mae": 0.26688796340740845,
            "precision": 0.7321100917431193,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8321496135930054,
            "auditor_fn_violation": 0.016111103391738116,
            "auditor_fp_violation": 0.025729263740652646,
            "ave_precision_score": 0.8326513337012945,
            "fpr": 0.13611416026344675,
            "logloss": 0.7319778265245255,
            "mae": 0.26605001907980363,
            "precision": 0.7484787018255578,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8758890738587666,
            "auditor_fn_violation": 0.015088176169590647,
            "auditor_fp_violation": 0.009183114035087724,
            "ave_precision_score": 0.8760590247966533,
            "fpr": 0.10197368421052631,
            "logloss": 0.46378569027077343,
            "mae": 0.2891944870465076,
            "precision": 0.8004291845493562,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.880994167575532,
            "auditor_fn_violation": 0.004066565697267807,
            "auditor_fp_violation": 0.012737781551191015,
            "ave_precision_score": 0.8812265018808618,
            "fpr": 0.09440175631174534,
            "logloss": 0.4509037424693367,
            "mae": 0.284452585863567,
            "precision": 0.8114035087719298,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8228698559808838,
            "auditor_fn_violation": 0.03907163742690059,
            "auditor_fp_violation": 0.03275259909031839,
            "ave_precision_score": 0.8228144200612968,
            "fpr": 0.16228070175438597,
            "logloss": 2.0781854694800463,
            "mae": 0.2910099618873849,
            "precision": 0.7131782945736435,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8293970452318442,
            "auditor_fn_violation": 0.026386360794230852,
            "auditor_fp_violation": 0.03120769039479336,
            "ave_precision_score": 0.8295092437672567,
            "fpr": 0.14050493962678376,
            "logloss": 1.931592655381752,
            "mae": 0.2833170767600902,
            "precision": 0.7377049180327869,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8639947051289207,
            "auditor_fn_violation": 0.01839592470760234,
            "auditor_fp_violation": 0.025158382066276807,
            "ave_precision_score": 0.8641947547664866,
            "fpr": 0.14364035087719298,
            "logloss": 0.5766768985516826,
            "mae": 0.2700128383118996,
            "precision": 0.7518939393939394,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8587523758770643,
            "auditor_fn_violation": 0.022349900651669474,
            "auditor_fp_violation": 0.02328519719572879,
            "ave_precision_score": 0.8591148901083382,
            "fpr": 0.12733260153677278,
            "logloss": 0.5464941292139696,
            "mae": 0.26445208922306085,
            "precision": 0.7637474541751528,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7268160990913316,
            "auditor_fn_violation": 0.059112298976608205,
            "auditor_fp_violation": 0.03260284681611437,
            "ave_precision_score": 0.7207809589408414,
            "fpr": 0.13925438596491227,
            "logloss": 2.2911083940647985,
            "mae": 0.3388902715409609,
            "precision": 0.7152466367713004,
            "recall": 0.6645833333333333
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7241652854372882,
            "auditor_fn_violation": 0.04336589364865429,
            "auditor_fp_violation": 0.019627888984619715,
            "ave_precision_score": 0.7180613178602026,
            "fpr": 0.12184412733260154,
            "logloss": 2.197369217765644,
            "mae": 0.32911393855733356,
            "precision": 0.7357142857142858,
            "recall": 0.6518987341772152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8469270806855816,
            "auditor_fn_violation": 0.02036504020467837,
            "auditor_fp_violation": 0.0294301291423002,
            "ave_precision_score": 0.8471760199362535,
            "fpr": 0.15021929824561403,
            "logloss": 0.7173727979190391,
            "mae": 0.28796141396965125,
            "precision": 0.7375478927203065,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.855713534067758,
            "auditor_fn_violation": 0.018753444770201983,
            "auditor_fp_violation": 0.025548407840103295,
            "ave_precision_score": 0.8559133908650388,
            "fpr": 0.13062568605927552,
            "logloss": 0.6306315852060432,
            "mae": 0.2794073962816237,
            "precision": 0.7536231884057971,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8649044544932893,
            "auditor_fn_violation": 0.0050347222222222225,
            "auditor_fp_violation": 0.017668230181936327,
            "ave_precision_score": 0.8650956292632148,
            "fpr": 0.1962719298245614,
            "logloss": 0.5462888373907802,
            "mae": 0.3328366830103557,
            "precision": 0.7046204620462047,
            "recall": 0.8895833333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8639386190395189,
            "auditor_fn_violation": 0.007229964753342876,
            "auditor_fp_violation": 0.01980623299766144,
            "ave_precision_score": 0.8641616830279548,
            "fpr": 0.1942919868276619,
            "logloss": 0.5411753536611124,
            "mae": 0.32865106632767405,
            "precision": 0.7045075125208681,
            "recall": 0.890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8619685681147292,
            "auditor_fn_violation": 0.03315058479532164,
            "auditor_fp_violation": 0.026110197368421052,
            "ave_precision_score": 0.8621472875541276,
            "fpr": 0.14802631578947367,
            "logloss": 0.5542813884677389,
            "mae": 0.29655013794022606,
            "precision": 0.7438330170777988,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8658472773281018,
            "auditor_fn_violation": 0.029915658130584003,
            "auditor_fp_violation": 0.02819342538563753,
            "ave_precision_score": 0.8665573535517004,
            "fpr": 0.12623490669593854,
            "logloss": 0.49026245926095685,
            "mae": 0.2816871832419545,
            "precision": 0.7713717693836978,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7527188798511915,
            "auditor_fn_violation": 0.019944718567251465,
            "auditor_fp_violation": 0.015746832358674464,
            "ave_precision_score": 0.7204133181363457,
            "fpr": 0.08333333333333333,
            "logloss": 3.9357500321966423,
            "mae": 0.3506618499280454,
            "precision": 0.7540453074433657,
            "recall": 0.48541666666666666
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7433267699689177,
            "auditor_fn_violation": 0.012630438105295348,
            "auditor_fp_violation": 0.01384301205454815,
            "ave_precision_score": 0.7128405066863023,
            "fpr": 0.07903402854006586,
            "logloss": 3.6397729582415552,
            "mae": 0.3631154530890848,
            "precision": 0.7428571428571429,
            "recall": 0.4388185654008439
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8657438374045905,
            "auditor_fn_violation": 0.01242690058479533,
            "auditor_fp_violation": 0.006924139051332036,
            "ave_precision_score": 0.8659301233065217,
            "fpr": 0.06140350877192982,
            "logloss": 0.8153393682271133,
            "mae": 0.25445030232654964,
            "precision": 0.851063829787234,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8628118037344302,
            "auditor_fn_violation": 0.010543891582950075,
            "auditor_fp_violation": 0.008025480586877399,
            "ave_precision_score": 0.8630232534186668,
            "fpr": 0.06037321624588365,
            "logloss": 0.7829410943362103,
            "mae": 0.24002234254440535,
            "precision": 0.8567708333333334,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8518723015289271,
            "auditor_fn_violation": 0.013253837719298247,
            "auditor_fp_violation": 0.015472709551656921,
            "ave_precision_score": 0.8531064329917595,
            "fpr": 0.08662280701754387,
            "logloss": 0.9939576083709943,
            "mae": 0.2528921594244331,
            "precision": 0.8123515439429929,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8201723500887281,
            "auditor_fn_violation": 0.013357603042050517,
            "auditor_fp_violation": 0.014945730670397658,
            "ave_precision_score": 0.8204457535166324,
            "fpr": 0.08232711306256861,
            "logloss": 1.1344620315424299,
            "mae": 0.25975432220834793,
            "precision": 0.8138957816377171,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8499309678577359,
            "auditor_fn_violation": 0.01768777412280702,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8501565831260073,
            "fpr": 0.1600877192982456,
            "logloss": 0.7367166016451291,
            "mae": 0.2669380803209669,
            "precision": 0.7321100917431193,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.832687838404325,
            "auditor_fn_violation": 0.016111103391738116,
            "auditor_fp_violation": 0.025729263740652646,
            "ave_precision_score": 0.8331783475017717,
            "fpr": 0.13611416026344675,
            "logloss": 0.7288379680405357,
            "mae": 0.2659576016605606,
            "precision": 0.7484787018255578,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8740617203847623,
            "auditor_fn_violation": 0.035546875,
            "auditor_fp_violation": 0.025648249675113713,
            "ave_precision_score": 0.8742414006825557,
            "fpr": 0.12609649122807018,
            "logloss": 0.4820278538703669,
            "mae": 0.2934067952011359,
            "precision": 0.7709163346613546,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8701216839208609,
            "auditor_fn_violation": 0.02524234971538672,
            "auditor_fp_violation": 0.025982964378923258,
            "ave_precision_score": 0.8705374987651188,
            "fpr": 0.12294182217343579,
            "logloss": 0.4741311628531345,
            "mae": 0.2907611822005838,
            "precision": 0.7751004016064257,
            "recall": 0.8143459915611815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8667422532003463,
            "auditor_fn_violation": 0.007593201754385974,
            "auditor_fp_violation": 0.007020589668615984,
            "ave_precision_score": 0.8669307467732001,
            "fpr": 0.0712719298245614,
            "logloss": 0.49187238197999156,
            "mae": 0.30651569959968983,
            "precision": 0.8329048843187661,
            "recall": 0.675
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8682017473248879,
            "auditor_fn_violation": 0.01108810737956621,
            "auditor_fp_violation": 0.007327175859756298,
            "ave_precision_score": 0.8684366917122318,
            "fpr": 0.06586169045005488,
            "logloss": 0.47930865659563,
            "mae": 0.29862422799092486,
            "precision": 0.8461538461538461,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8339096024963811,
            "auditor_fn_violation": 0.011908351608187137,
            "auditor_fp_violation": 0.01659458252111761,
            "ave_precision_score": 0.8341719127984751,
            "fpr": 0.15021929824561403,
            "logloss": 0.9706018358018104,
            "mae": 0.2749301540907003,
            "precision": 0.7334630350194552,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8249304084116633,
            "auditor_fn_violation": 0.016896163626005642,
            "auditor_fp_violation": 0.009321614540814406,
            "ave_precision_score": 0.825372535235521,
            "fpr": 0.12403951701427003,
            "logloss": 0.8567554200480749,
            "mae": 0.270955803749269,
            "precision": 0.7575107296137339,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8358297726729683,
            "auditor_fn_violation": 0.0415889985380117,
            "auditor_fp_violation": 0.035361842105263164,
            "ave_precision_score": 0.8362423350792564,
            "fpr": 0.17324561403508773,
            "logloss": 0.6333474609809792,
            "mae": 0.3064609610502861,
            "precision": 0.7122040072859745,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.851037360274921,
            "auditor_fn_violation": 0.031182407240154326,
            "auditor_fp_violation": 0.03803248875302369,
            "ave_precision_score": 0.8513668452240345,
            "fpr": 0.14709110867178923,
            "logloss": 0.5509805147792741,
            "mae": 0.2903279241453608,
            "precision": 0.7447619047619047,
            "recall": 0.8248945147679325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8321426555507343,
            "auditor_fn_violation": 0.009525767543859653,
            "auditor_fp_violation": 0.021632858187134507,
            "ave_precision_score": 0.8324060916678397,
            "fpr": 0.15460526315789475,
            "logloss": 0.9873232438062738,
            "mae": 0.2756321492434474,
            "precision": 0.7298850574712644,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8216491713425744,
            "auditor_fn_violation": 0.015617835456932848,
            "auditor_fp_violation": 0.009688350116928363,
            "ave_precision_score": 0.8220588831491067,
            "fpr": 0.1251372118551043,
            "logloss": 0.8746694681677558,
            "mae": 0.2724919339211967,
            "precision": 0.7574468085106383,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8486239618533264,
            "auditor_fn_violation": 0.0058982090643274875,
            "auditor_fp_violation": 0.01422138970110462,
            "ave_precision_score": 0.8488349521120058,
            "fpr": 0.1524122807017544,
            "logloss": 0.7022449735040344,
            "mae": 0.27243754535259523,
            "precision": 0.7352380952380952,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8370160465263836,
            "auditor_fn_violation": 0.008809348469479922,
            "auditor_fp_violation": 0.0157821892104384,
            "ave_precision_score": 0.8373698731957264,
            "fpr": 0.132821075740944,
            "logloss": 0.6833707343654165,
            "mae": 0.2665754993779622,
            "precision": 0.7545638945233266,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8422016802342278,
            "auditor_fn_violation": 0.014533077485380122,
            "auditor_fp_violation": 0.010660331384015601,
            "ave_precision_score": 0.8424374658599361,
            "fpr": 0.0668859649122807,
            "logloss": 0.798313549559452,
            "mae": 0.2948222399570437,
            "precision": 0.827683615819209,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8362779729784946,
            "auditor_fn_violation": 0.009253984354374807,
            "auditor_fp_violation": 0.004805240802095917,
            "ave_precision_score": 0.8366337004285802,
            "fpr": 0.05817782656421515,
            "logloss": 0.8383920105628982,
            "mae": 0.29847308329336286,
            "precision": 0.8374233128834356,
            "recall": 0.5759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6630569075866353,
            "auditor_fn_violation": 0.011970029239766082,
            "auditor_fp_violation": 0.015221430311890837,
            "ave_precision_score": 0.5760984093660977,
            "fpr": 0.25548245614035087,
            "logloss": 6.99963684453456,
            "mae": 0.3594095832970678,
            "precision": 0.6266025641025641,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.6743928446048459,
            "auditor_fn_violation": 0.01832965119241155,
            "auditor_fp_violation": 0.008997581052330164,
            "ave_precision_score": 0.5950783524882091,
            "fpr": 0.2414928649835346,
            "logloss": 6.134404569561243,
            "mae": 0.36318741265936316,
            "precision": 0.6239316239316239,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8381075455448785,
            "auditor_fn_violation": 0.022583150584795323,
            "auditor_fp_violation": 0.027155925113710205,
            "ave_precision_score": 0.8383540805584657,
            "fpr": 0.15021929824561403,
            "logloss": 0.7911557483663954,
            "mae": 0.2718319301311669,
            "precision": 0.7344961240310077,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8242043581536566,
            "auditor_fn_violation": 0.021386522901063885,
            "auditor_fp_violation": 0.021737874491028795,
            "ave_precision_score": 0.8246921953026726,
            "fpr": 0.12403951701427003,
            "logloss": 0.8072368104113405,
            "mae": 0.2691687374340489,
            "precision": 0.760593220338983,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8636557166773876,
            "auditor_fn_violation": 0.035953490497076024,
            "auditor_fp_violation": 0.019351039636127356,
            "ave_precision_score": 0.8638313681241194,
            "fpr": 0.09429824561403509,
            "logloss": 0.5564896251584964,
            "mae": 0.2990135291945901,
            "precision": 0.8022988505747126,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8680652274086128,
            "auditor_fn_violation": 0.030184292311041333,
            "auditor_fp_violation": 0.016656326063093592,
            "ave_precision_score": 0.8683766524483709,
            "fpr": 0.08122941822173436,
            "logloss": 0.531170830089848,
            "mae": 0.29399368167603795,
            "precision": 0.8254716981132075,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8485621394703131,
            "auditor_fn_violation": 0.01326297514619883,
            "auditor_fp_violation": 0.02202119883040936,
            "ave_precision_score": 0.8487763456043546,
            "fpr": 0.1600877192982456,
            "logloss": 0.7069196574194376,
            "mae": 0.27434628009861906,
            "precision": 0.7281191806331471,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8363574644772297,
            "auditor_fn_violation": 0.013686448331920693,
            "auditor_fp_violation": 0.0178092824290957,
            "ave_precision_score": 0.8368310020631677,
            "fpr": 0.12952799121844127,
            "logloss": 0.6805549759292364,
            "mae": 0.26555660057104535,
            "precision": 0.7620967741935484,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.865026265740648,
            "auditor_fn_violation": 0.01393457602339181,
            "auditor_fp_violation": 0.012340602664067578,
            "ave_precision_score": 0.8652234814899009,
            "fpr": 0.07785087719298246,
            "logloss": 0.5893067801570435,
            "mae": 0.28078755860821236,
            "precision": 0.8233830845771144,
            "recall": 0.6895833333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8614914684188895,
            "auditor_fn_violation": 0.009022403164325381,
            "auditor_fp_violation": 0.006751953620509059,
            "ave_precision_score": 0.8618100451127053,
            "fpr": 0.06695938529088913,
            "logloss": 0.574277194792109,
            "mae": 0.2757980722810153,
            "precision": 0.8398950131233596,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8532616515458972,
            "auditor_fn_violation": 0.03757538377192983,
            "auditor_fp_violation": 0.028973257797270956,
            "ave_precision_score": 0.8534748261402512,
            "fpr": 0.15021929824561403,
            "logloss": 0.5797037359144621,
            "mae": 0.30222144060368056,
            "precision": 0.7395437262357415,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8655093676212466,
            "auditor_fn_violation": 0.02933207353165947,
            "auditor_fp_violation": 0.03688455616203684,
            "ave_precision_score": 0.8658427663800261,
            "fpr": 0.13391877058177826,
            "logloss": 0.505289632011114,
            "mae": 0.28392585800953346,
            "precision": 0.758893280632411,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8656740483803276,
            "auditor_fn_violation": 0.011504020467836258,
            "auditor_fp_violation": 0.014802631578947368,
            "ave_precision_score": 0.8658483890618833,
            "fpr": 0.13486842105263158,
            "logloss": 0.588627969990345,
            "mae": 0.26687246258041086,
            "precision": 0.7564356435643564,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8497921948166662,
            "auditor_fn_violation": 0.00928408990908123,
            "auditor_fp_violation": 0.016591016987895214,
            "ave_precision_score": 0.8501960675011662,
            "fpr": 0.11745334796926454,
            "logloss": 0.6031755502590114,
            "mae": 0.26604196593454055,
            "precision": 0.7733050847457628,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8025357554310371,
            "auditor_fn_violation": 0.007127192982456144,
            "auditor_fp_violation": 0.02665844298245614,
            "ave_precision_score": 0.8029060075903944,
            "fpr": 0.20723684210526316,
            "logloss": 1.0159321659568035,
            "mae": 0.2946664721196374,
            "precision": 0.6791171477079796,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7920344237178233,
            "auditor_fn_violation": 0.016173630313051454,
            "auditor_fp_violation": 0.024500950749421643,
            "ave_precision_score": 0.7928085885900289,
            "fpr": 0.18111964873765093,
            "logloss": 0.9821256940124544,
            "mae": 0.2900944311939959,
            "precision": 0.6994535519125683,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 28699,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8374510152918769,
            "auditor_fn_violation": 0.003481359649122811,
            "auditor_fp_violation": 0.016665651397011046,
            "ave_precision_score": 0.8376948804451975,
            "fpr": 0.15899122807017543,
            "logloss": 0.7654024666068759,
            "mae": 0.2747813409964088,
            "precision": 0.7294776119402985,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8264780235157219,
            "auditor_fn_violation": 0.007331860476964624,
            "auditor_fp_violation": 0.015043694283195222,
            "ave_precision_score": 0.8269177917907998,
            "fpr": 0.1394072447859495,
            "logloss": 0.7550085972814001,
            "mae": 0.27059577338716273,
            "precision": 0.746,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8456659673249378,
            "auditor_fn_violation": 0.04039199561403509,
            "auditor_fp_violation": 0.03501918859649123,
            "ave_precision_score": 0.8459249683265887,
            "fpr": 0.15460526315789475,
            "logloss": 0.6042921902639642,
            "mae": 0.30389228091042386,
            "precision": 0.7339622641509433,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8566808287472666,
            "auditor_fn_violation": 0.03032324102507098,
            "auditor_fp_violation": 0.04117234813756101,
            "ave_precision_score": 0.8570450445299256,
            "fpr": 0.1394072447859495,
            "logloss": 0.5296770300469809,
            "mae": 0.28617598030397595,
            "precision": 0.7524366471734892,
            "recall": 0.8143459915611815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8072744443822719,
            "auditor_fn_violation": 0.02192982456140351,
            "auditor_fp_violation": 0.025341130604288505,
            "ave_precision_score": 0.7721005423270395,
            "fpr": 0.14583333333333334,
            "logloss": 2.2624922428992233,
            "mae": 0.275153607885027,
            "precision": 0.7504690431519699,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7915376510059815,
            "auditor_fn_violation": 0.021736210498038512,
            "auditor_fp_violation": 0.01964798408468076,
            "ave_precision_score": 0.7577978782162935,
            "fpr": 0.13611416026344675,
            "logloss": 2.185169876339044,
            "mae": 0.2797309396740062,
            "precision": 0.7524950099800399,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8471031079470959,
            "auditor_fn_violation": 0.01961120248538012,
            "auditor_fp_violation": 0.025584795321637436,
            "ave_precision_score": 0.8473280232784087,
            "fpr": 0.15789473684210525,
            "logloss": 0.7420063322790764,
            "mae": 0.2689681401020187,
            "precision": 0.7328385899814471,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8296301108035238,
            "auditor_fn_violation": 0.021967791688087927,
            "auditor_fp_violation": 0.024068906098109306,
            "ave_precision_score": 0.8301330627505732,
            "fpr": 0.13721185510428102,
            "logloss": 0.7436247427568294,
            "mae": 0.268553332338624,
            "precision": 0.7459349593495935,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8702103538001196,
            "auditor_fn_violation": 0.006375639619883039,
            "auditor_fp_violation": 0.008355669265756989,
            "ave_precision_score": 0.8703913956113655,
            "fpr": 0.10964912280701754,
            "logloss": 0.47264538038878906,
            "mae": 0.2937521223364839,
            "precision": 0.7876857749469215,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.878246895656488,
            "auditor_fn_violation": 0.012354856489136527,
            "auditor_fp_violation": 0.012559437538149292,
            "ave_precision_score": 0.878480198626427,
            "fpr": 0.09220636663007684,
            "logloss": 0.45655269318564307,
            "mae": 0.286604969396535,
            "precision": 0.8161925601750547,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8464844393055264,
            "auditor_fn_violation": 0.01214135599415205,
            "auditor_fp_violation": 0.02548834470435348,
            "ave_precision_score": 0.8467129326307425,
            "fpr": 0.20833333333333334,
            "logloss": 0.7004945806553594,
            "mae": 0.2861349245119755,
            "precision": 0.6859504132231405,
            "recall": 0.8645833333333334
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8396325396078896,
            "auditor_fn_violation": 0.015552992723719015,
            "auditor_fp_violation": 0.01830412426809878,
            "ave_precision_score": 0.840238073688335,
            "fpr": 0.17453347969264543,
            "logloss": 0.6578977433078173,
            "mae": 0.2758013945379572,
            "precision": 0.7145421903052065,
            "recall": 0.8396624472573839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8598482130886238,
            "auditor_fn_violation": 0.02196637426900585,
            "auditor_fp_violation": 0.021716617933723203,
            "ave_precision_score": 0.8600698692298419,
            "fpr": 0.14473684210526316,
            "logloss": 0.5508839930792683,
            "mae": 0.27887292978828937,
            "precision": 0.7480916030534351,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8621696734453713,
            "auditor_fn_violation": 0.024529079650034508,
            "auditor_fp_violation": 0.02362932578427408,
            "ave_precision_score": 0.862514436835918,
            "fpr": 0.12623490669593854,
            "logloss": 0.5107423588323716,
            "mae": 0.2715706192135621,
            "precision": 0.766260162601626,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8224955490788789,
            "auditor_fn_violation": 0.03907163742690059,
            "auditor_fp_violation": 0.03116877842755036,
            "ave_precision_score": 0.8224508522098686,
            "fpr": 0.1600877192982456,
            "logloss": 2.0810893483783737,
            "mae": 0.29120826563151725,
            "precision": 0.7159533073929961,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8293234034355339,
            "auditor_fn_violation": 0.027456265892259173,
            "auditor_fp_violation": 0.03120769039479336,
            "ave_precision_score": 0.8294813175598625,
            "fpr": 0.14050493962678376,
            "logloss": 1.9339764852518426,
            "mae": 0.28339816815879054,
            "precision": 0.7360824742268042,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8393935221507811,
            "auditor_fn_violation": 0.004043311403508776,
            "auditor_fp_violation": 0.017757066276803124,
            "ave_precision_score": 0.839621394732665,
            "fpr": 0.1699561403508772,
            "logloss": 0.7878467811041837,
            "mae": 0.27645966570216773,
            "precision": 0.7197106690777577,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8283331260408784,
            "auditor_fn_violation": 0.009615251010851894,
            "auditor_fp_violation": 0.018698490606796674,
            "ave_precision_score": 0.8287801681258176,
            "fpr": 0.15367727771679474,
            "logloss": 0.7646947365237783,
            "mae": 0.2710949640202189,
            "precision": 0.7312859884836852,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8583064045453673,
            "auditor_fn_violation": 0.03757538377192983,
            "auditor_fp_violation": 0.031013949805068223,
            "ave_precision_score": 0.8585482551947513,
            "fpr": 0.14144736842105263,
            "logloss": 0.5289445980660858,
            "mae": 0.2995932180931145,
            "precision": 0.750965250965251,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8666211380278599,
            "auditor_fn_violation": 0.029758182921350393,
            "auditor_fp_violation": 0.03111726244451868,
            "ave_precision_score": 0.8670050721133306,
            "fpr": 0.1251372118551043,
            "logloss": 0.4920579229655823,
            "mae": 0.2873123696570476,
            "precision": 0.7747035573122529,
            "recall": 0.8270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8427539671594055,
            "auditor_fn_violation": 0.03821728801169591,
            "auditor_fp_violation": 0.037727420402859,
            "ave_precision_score": 0.8432857207541233,
            "fpr": 0.1699561403508772,
            "logloss": 0.7763437964368956,
            "mae": 0.274322167444638,
            "precision": 0.7181818181818181,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8358980435648607,
            "auditor_fn_violation": 0.028213536383720768,
            "auditor_fp_violation": 0.038366569791538456,
            "ave_precision_score": 0.8363830828053098,
            "fpr": 0.14928649835345773,
            "logloss": 0.7317245486017838,
            "mae": 0.26774561286434506,
            "precision": 0.7338551859099804,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8353319621977875,
            "auditor_fn_violation": 0.020454130116959065,
            "auditor_fp_violation": 0.0009543534762833035,
            "ave_precision_score": 0.8355696672731538,
            "fpr": 0.06140350877192982,
            "logloss": 0.920747667570604,
            "mae": 0.31133451533018053,
            "precision": 0.8238993710691824,
            "recall": 0.5458333333333333
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.8232039250649645,
            "auditor_fn_violation": 0.0025427614667426226,
            "auditor_fp_violation": 0.00213008060647012,
            "ave_precision_score": 0.8236296428875453,
            "fpr": 0.05159165751920966,
            "logloss": 1.0200241549337505,
            "mae": 0.3197024309607127,
            "precision": 0.8368055555555556,
            "recall": 0.5084388185654009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8253572546279324,
            "auditor_fn_violation": 0.0382858187134503,
            "auditor_fp_violation": 0.02955703784925277,
            "ave_precision_score": 0.8253092060765086,
            "fpr": 0.15679824561403508,
            "logloss": 2.061260642774535,
            "mae": 0.2916830049483301,
            "precision": 0.7212475633528265,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8329901725017483,
            "auditor_fn_violation": 0.026219622337395273,
            "auditor_fp_violation": 0.030439052817458626,
            "ave_precision_score": 0.8331396556412367,
            "fpr": 0.1394072447859495,
            "logloss": 1.911137418279627,
            "mae": 0.2830947994198677,
            "precision": 0.7381443298969073,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8668251056596363,
            "auditor_fn_violation": 0.012198464912280705,
            "auditor_fp_violation": 0.00974658869395712,
            "ave_precision_score": 0.8670847723568668,
            "fpr": 0.07017543859649122,
            "logloss": 0.492377019060454,
            "mae": 0.29383848900978227,
            "precision": 0.8375634517766497,
            "recall": 0.6875
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8728734700540814,
            "auditor_fn_violation": 0.000910114076894226,
            "auditor_fp_violation": 0.007319640197233407,
            "ave_precision_score": 0.873256669915726,
            "fpr": 0.05378704720087816,
            "logloss": 0.4766748057074899,
            "mae": 0.282158735535863,
            "precision": 0.8730569948186528,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8522498731079701,
            "auditor_fn_violation": 0.01567068713450293,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8524589072457412,
            "fpr": 0.1600877192982456,
            "logloss": 0.7216127741355717,
            "mae": 0.26727915158219656,
            "precision": 0.7301293900184843,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8380904840893528,
            "auditor_fn_violation": 0.01924439689310676,
            "auditor_fp_violation": 0.019602770109543418,
            "ave_precision_score": 0.8385036488072835,
            "fpr": 0.13611416026344675,
            "logloss": 0.7100801997254303,
            "mae": 0.26454638632596666,
            "precision": 0.7529880478087649,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8484996728105122,
            "auditor_fn_violation": 0.011325840643274854,
            "auditor_fp_violation": 0.013833049057829762,
            "ave_precision_score": 0.8487383871292331,
            "fpr": 0.13925438596491227,
            "logloss": 0.5474971759595315,
            "mae": 0.309037868062656,
            "precision": 0.75049115913556,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8657932580513213,
            "auditor_fn_violation": 0.007609757905023926,
            "auditor_fp_violation": 0.015736975235301064,
            "ave_precision_score": 0.8660524239776606,
            "fpr": 0.12403951701427003,
            "logloss": 0.48060360241785427,
            "mae": 0.29266775443548193,
            "precision": 0.77079107505071,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.855241918909443,
            "auditor_fn_violation": 0.007871893274853803,
            "auditor_fp_violation": 0.014132553606237825,
            "ave_precision_score": 0.8554373016894772,
            "fpr": 0.14473684210526316,
            "logloss": 0.6218869138126103,
            "mae": 0.27599056070060707,
            "precision": 0.7416829745596869,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8443824988535362,
            "auditor_fn_violation": 0.01454329873510354,
            "auditor_fp_violation": 0.014234866505738408,
            "ave_precision_score": 0.8448361560165731,
            "fpr": 0.11855104281009879,
            "logloss": 0.6072085547588889,
            "mae": 0.26928681854285025,
            "precision": 0.7716701902748414,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8408940661408433,
            "auditor_fn_violation": 0.015522203947368425,
            "auditor_fp_violation": 0.02703663092917479,
            "ave_precision_score": 0.8411658473813817,
            "fpr": 0.1337719298245614,
            "logloss": 0.7215791758023533,
            "mae": 0.2700426481977849,
            "precision": 0.7545271629778671,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8236637260328368,
            "auditor_fn_violation": 0.009184509997359976,
            "auditor_fp_violation": 0.0197861378976004,
            "ave_precision_score": 0.8241329805388355,
            "fpr": 0.1141602634467618,
            "logloss": 0.7651812834003612,
            "mae": 0.2740127177845812,
            "precision": 0.7714285714285715,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8466775814930958,
            "auditor_fn_violation": 0.018457602339181287,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.8469126832484108,
            "fpr": 0.13596491228070176,
            "logloss": 0.7302501779707847,
            "mae": 0.2690414650901226,
            "precision": 0.752,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8256061976974137,
            "auditor_fn_violation": 0.023820441208483284,
            "auditor_fp_violation": 0.01862815775658304,
            "ave_precision_score": 0.8260615171290564,
            "fpr": 0.11745334796926454,
            "logloss": 0.7660346637430714,
            "mae": 0.27305958075730535,
            "precision": 0.7622222222222222,
            "recall": 0.7236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.860101502494905,
            "auditor_fn_violation": 0.02196637426900585,
            "auditor_fp_violation": 0.02255421539961015,
            "ave_precision_score": 0.8603233227538262,
            "fpr": 0.14583333333333334,
            "logloss": 0.5511319543429741,
            "mae": 0.2788611823799536,
            "precision": 0.7466666666666667,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8622890134900982,
            "auditor_fn_violation": 0.024529079650034508,
            "auditor_fp_violation": 0.023712218072025868,
            "ave_precision_score": 0.862633794347508,
            "fpr": 0.12843029637760703,
            "logloss": 0.5114091771393241,
            "mae": 0.2713961091552912,
            "precision": 0.7631578947368421,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8356733363890685,
            "auditor_fn_violation": 0.00836074561403509,
            "auditor_fp_violation": 0.01774437540610787,
            "ave_precision_score": 0.8359305826282654,
            "fpr": 0.15679824561403508,
            "logloss": 0.9574878394469868,
            "mae": 0.2743920081028548,
            "precision": 0.7291666666666666,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8260604904912412,
            "auditor_fn_violation": 0.016956374735418493,
            "auditor_fp_violation": 0.008784070614181617,
            "ave_precision_score": 0.826465106735373,
            "fpr": 0.13062568605927552,
            "logloss": 0.8368814618068308,
            "mae": 0.27064149351715,
            "precision": 0.750524109014675,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8643453391880658,
            "auditor_fn_violation": 0.01721262792397661,
            "auditor_fp_violation": 0.03062560916179338,
            "ave_precision_score": 0.8645471686895998,
            "fpr": 0.15460526315789475,
            "logloss": 0.5727405973927735,
            "mae": 0.26858882544461504,
            "precision": 0.7349624060150376,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8517343551891527,
            "auditor_fn_violation": 0.01560625639743038,
            "auditor_fp_violation": 0.02290339029456905,
            "ave_precision_score": 0.8524343726378473,
            "fpr": 0.12952799121844127,
            "logloss": 0.586632912459771,
            "mae": 0.27133925391074104,
            "precision": 0.7556935817805382,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8606682562901127,
            "auditor_fn_violation": 0.020422149122807022,
            "auditor_fp_violation": 0.022523757309941533,
            "ave_precision_score": 0.8608682892177888,
            "fpr": 0.1513157894736842,
            "logloss": 0.594165088212313,
            "mae": 0.27314485042762626,
            "precision": 0.7391304347826086,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8539725095347392,
            "auditor_fn_violation": 0.020448619081363736,
            "auditor_fp_violation": 0.019620353322096825,
            "ave_precision_score": 0.8543780325904865,
            "fpr": 0.12952799121844127,
            "logloss": 0.5697215028072417,
            "mae": 0.26769912460170736,
            "precision": 0.7581967213114754,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8528740793277867,
            "auditor_fn_violation": 0.015309758771929827,
            "auditor_fp_violation": 0.027404666179337237,
            "ave_precision_score": 0.8530829345849646,
            "fpr": 0.1611842105263158,
            "logloss": 0.7315681886626213,
            "mae": 0.26586973738563363,
            "precision": 0.7307692307692307,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8381153666095171,
            "auditor_fn_violation": 0.017697434543576637,
            "auditor_fp_violation": 0.01840711165591161,
            "ave_precision_score": 0.8385108913561397,
            "fpr": 0.14270032930845225,
            "logloss": 0.7181643187926507,
            "mae": 0.26374450257633764,
            "precision": 0.7445972495088409,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8371514024415148,
            "auditor_fn_violation": 0.005726882309941523,
            "auditor_fp_violation": 0.018503289473684213,
            "ave_precision_score": 0.8373947056518423,
            "fpr": 0.17763157894736842,
            "logloss": 0.7969979891501938,
            "mae": 0.27678113423675793,
            "precision": 0.7122557726465364,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8266219264439092,
            "auditor_fn_violation": 0.010935263794133588,
            "auditor_fp_violation": 0.020112683273592277,
            "ave_precision_score": 0.8270347427599041,
            "fpr": 0.16136114160263446,
            "logloss": 0.7720055038407142,
            "mae": 0.27086828965454063,
            "precision": 0.7262569832402235,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8750213098154807,
            "auditor_fn_violation": 0.010827850877192997,
            "auditor_fp_violation": 0.009573992852501627,
            "ave_precision_score": 0.8751843111470119,
            "fpr": 0.07456140350877193,
            "logloss": 0.48518681948320014,
            "mae": 0.2918414431110968,
            "precision": 0.8333333333333334,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8834059472843716,
            "auditor_fn_violation": 0.004613097305784437,
            "auditor_fp_violation": 0.0016377506549746688,
            "ave_precision_score": 0.8836267157045409,
            "fpr": 0.05598243688254665,
            "logloss": 0.463709062841934,
            "mae": 0.2792499422203825,
            "precision": 0.8661417322834646,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8593367251166022,
            "auditor_fn_violation": 0.020422149122807022,
            "auditor_fp_violation": 0.027945297270955165,
            "ave_precision_score": 0.859541895635954,
            "fpr": 0.1425438596491228,
            "logloss": 0.579802757636378,
            "mae": 0.27554037816053534,
            "precision": 0.7504798464491362,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8564618133733006,
            "auditor_fn_violation": 0.020939571204268505,
            "auditor_fp_violation": 0.019452056859085624,
            "ave_precision_score": 0.856836504385291,
            "fpr": 0.12294182217343579,
            "logloss": 0.5513491648586348,
            "mae": 0.26923068674189965,
            "precision": 0.7666666666666667,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8434083939125312,
            "auditor_fn_violation": 0.03982547514619883,
            "auditor_fp_violation": 0.03615882878492528,
            "ave_precision_score": 0.8436674834574593,
            "fpr": 0.1524122807017544,
            "logloss": 0.6128855223612679,
            "mae": 0.30502782111066035,
            "precision": 0.7367424242424242,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.854293090100473,
            "auditor_fn_violation": 0.0302769247870611,
            "auditor_fp_violation": 0.04012740293438699,
            "ave_precision_score": 0.8546489619447833,
            "fpr": 0.1437980241492865,
            "logloss": 0.5383764921262112,
            "mae": 0.2886269655716198,
            "precision": 0.7461240310077519,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8651275660520724,
            "auditor_fn_violation": 0.018642635233918136,
            "auditor_fp_violation": 0.02656453053931124,
            "ave_precision_score": 0.8653117741086136,
            "fpr": 0.1600877192982456,
            "logloss": 0.611497164284667,
            "mae": 0.2687219542914351,
            "precision": 0.7340619307832422,
            "recall": 0.8395833333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8550972584072462,
            "auditor_fn_violation": 0.018271755894899197,
            "auditor_fp_violation": 0.020286003511618737,
            "ave_precision_score": 0.8555050362072606,
            "fpr": 0.13611416026344675,
            "logloss": 0.5777357264419616,
            "mae": 0.2621539215246312,
            "precision": 0.7559055118110236,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8495363369103743,
            "auditor_fn_violation": 0.02510508040935673,
            "auditor_fp_violation": 0.025957906920077975,
            "ave_precision_score": 0.8497674852948292,
            "fpr": 0.14364035087719298,
            "logloss": 0.7567554773398204,
            "mae": 0.26464300379505057,
            "precision": 0.7461240310077519,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8373094424263832,
            "auditor_fn_violation": 0.021541682298396998,
            "auditor_fp_violation": 0.02556347916514907,
            "ave_precision_score": 0.8377729337423097,
            "fpr": 0.13062568605927552,
            "logloss": 0.7382857240621061,
            "mae": 0.261867736004173,
            "precision": 0.7551440329218106,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8629039514184955,
            "auditor_fn_violation": 0.017900219298245614,
            "auditor_fp_violation": 0.024239563027940222,
            "ave_precision_score": 0.8631093804545151,
            "fpr": 0.14583333333333334,
            "logloss": 0.5716358495042109,
            "mae": 0.2720189968984897,
            "precision": 0.7485822306238186,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8588626508772926,
            "auditor_fn_violation": 0.022333689968366013,
            "auditor_fp_violation": 0.022740117606573115,
            "ave_precision_score": 0.8591962127414952,
            "fpr": 0.132821075740944,
            "logloss": 0.5420005840307359,
            "mae": 0.26655826082521467,
            "precision": 0.7570281124497992,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8573728854235434,
            "auditor_fn_violation": 0.011095120614035094,
            "auditor_fp_violation": 0.022975552306692664,
            "ave_precision_score": 0.8575626678867521,
            "fpr": 0.1337719298245614,
            "logloss": 0.6581837268328337,
            "mae": 0.26724456961937354,
            "precision": 0.757455268389662,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8479010297947676,
            "auditor_fn_violation": 0.009976517667328993,
            "auditor_fp_violation": 0.00833946652533113,
            "ave_precision_score": 0.8482985173762446,
            "fpr": 0.1141602634467618,
            "logloss": 0.631051848972052,
            "mae": 0.2615132943897211,
            "precision": 0.776824034334764,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8375068555079753,
            "auditor_fn_violation": 0.023759594298245614,
            "auditor_fp_violation": 0.029338754873294348,
            "ave_precision_score": 0.837730168492373,
            "fpr": 0.22478070175438597,
            "logloss": 0.7422590970630605,
            "mae": 0.3124761694540579,
            "precision": 0.6725239616613419,
            "recall": 0.8770833333333333
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8310882546965197,
            "auditor_fn_violation": 0.013987503878984935,
            "auditor_fp_violation": 0.027763892621832823,
            "ave_precision_score": 0.8315162436353283,
            "fpr": 0.2239297475301866,
            "logloss": 0.6875849435497859,
            "mae": 0.29886349189507966,
            "precision": 0.6720257234726688,
            "recall": 0.8818565400843882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8669896962151479,
            "auditor_fn_violation": 0.010268183479532168,
            "auditor_fp_violation": 0.009388706140350879,
            "ave_precision_score": 0.867208756576467,
            "fpr": 0.08881578947368421,
            "logloss": 0.48355277424216225,
            "mae": 0.2885625008560039,
            "precision": 0.8159090909090909,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.870645425320616,
            "auditor_fn_violation": 0.007440703636287848,
            "auditor_fp_violation": 0.010105323443194923,
            "ave_precision_score": 0.8711788200084838,
            "fpr": 0.08122941822173436,
            "logloss": 0.4678307449064703,
            "mae": 0.2809193443829494,
            "precision": 0.8290993071593533,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8566366421548541,
            "auditor_fn_violation": 0.024396929824561406,
            "auditor_fp_violation": 0.02488933560753737,
            "ave_precision_score": 0.8568511770799807,
            "fpr": 0.1524122807017544,
            "logloss": 0.5634136223738397,
            "mae": 0.2826783735361045,
            "precision": 0.7397003745318352,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.859465188868517,
            "auditor_fn_violation": 0.025626774490868753,
            "auditor_fp_violation": 0.02244622676818041,
            "ave_precision_score": 0.8598422829821947,
            "fpr": 0.13172338090010977,
            "logloss": 0.5177878332400049,
            "mae": 0.2741526383767154,
            "precision": 0.7585513078470825,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 28699,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8501432265674309,
            "auditor_fn_violation": 0.009046052631578948,
            "auditor_fp_violation": 0.016881396198830417,
            "ave_precision_score": 0.8503504167407931,
            "fpr": 0.14144736842105263,
            "logloss": 0.6363528505605649,
            "mae": 0.27892964170804385,
            "precision": 0.7440476190476191,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8463542898065938,
            "auditor_fn_violation": 0.007405966457780438,
            "auditor_fp_violation": 0.01538028720921762,
            "ave_precision_score": 0.8466950020891978,
            "fpr": 0.11306256860592755,
            "logloss": 0.6055922665393818,
            "mae": 0.26911443566000576,
            "precision": 0.7775377969762419,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8391551080741813,
            "auditor_fn_violation": 0.01677631578947368,
            "auditor_fp_violation": 0.026772660818713455,
            "ave_precision_score": 0.8403858508147706,
            "fpr": 0.14473684210526316,
            "logloss": 0.6160000904717833,
            "mae": 0.27306873056742814,
            "precision": 0.7485714285714286,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8558232308318982,
            "auditor_fn_violation": 0.020207774643712345,
            "auditor_fp_violation": 0.017816818091618586,
            "ave_precision_score": 0.8562259662714724,
            "fpr": 0.12733260153677278,
            "logloss": 0.5667664794548443,
            "mae": 0.2669664106300249,
            "precision": 0.7613168724279835,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8433491459703315,
            "auditor_fn_violation": 0.00654925073099415,
            "auditor_fp_violation": 0.021637934535412615,
            "ave_precision_score": 0.8435818072400343,
            "fpr": 0.13925438596491227,
            "logloss": 0.753339408275959,
            "mae": 0.26784525654626123,
            "precision": 0.7490118577075099,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8264785461288147,
            "auditor_fn_violation": 0.011657797107087779,
            "auditor_fp_violation": 0.008344490300346395,
            "ave_precision_score": 0.8269640307624732,
            "fpr": 0.1207464324917673,
            "logloss": 0.7698130579115823,
            "mae": 0.2682689674410869,
            "precision": 0.7659574468085106,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8508270031016558,
            "auditor_fn_violation": 0.015606725146198834,
            "auditor_fp_violation": 0.02530559616634178,
            "ave_precision_score": 0.8510307022562806,
            "fpr": 0.20285087719298245,
            "logloss": 0.8043058196974947,
            "mae": 0.27632295794868766,
            "precision": 0.693200663349917,
            "recall": 0.8708333333333333
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8355485239295868,
            "auditor_fn_violation": 0.014923091886784591,
            "auditor_fp_violation": 0.022820498006817267,
            "ave_precision_score": 0.8360489073860924,
            "fpr": 0.1734357848518112,
            "logloss": 0.7662519742834151,
            "mae": 0.2696716895036194,
            "precision": 0.7137681159420289,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8235835161432009,
            "auditor_fn_violation": 0.011161366959064329,
            "auditor_fp_violation": 0.022356237816764133,
            "ave_precision_score": 0.8242056415753959,
            "fpr": 0.14912280701754385,
            "logloss": 0.7897444044000661,
            "mae": 0.2711299134244057,
            "precision": 0.7379576107899807,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.822660633244179,
            "auditor_fn_violation": 0.016479317483916688,
            "auditor_fp_violation": 0.015370239659187105,
            "ave_precision_score": 0.823144412483318,
            "fpr": 0.12294182217343579,
            "logloss": 0.7540111980199522,
            "mae": 0.26600659575532076,
            "precision": 0.7661795407098121,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8313445304952547,
            "auditor_fn_violation": 0.009623994883040936,
            "auditor_fp_violation": 0.017269736842105265,
            "ave_precision_score": 0.8316135563668985,
            "fpr": 0.12828947368421054,
            "logloss": 0.5746703711550116,
            "mae": 0.31990940102261184,
            "precision": 0.7542016806722689,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8520659592302776,
            "auditor_fn_violation": 0.004775204138819033,
            "auditor_fp_violation": 0.013752584104273477,
            "ave_precision_score": 0.8523765841938733,
            "fpr": 0.09769484083424808,
            "logloss": 0.5074716278847843,
            "mae": 0.3023214529168856,
            "precision": 0.7954022988505747,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8553789600978132,
            "auditor_fn_violation": 0.03289473684210526,
            "auditor_fp_violation": 0.024488304093567254,
            "ave_precision_score": 0.8555783506724476,
            "fpr": 0.14035087719298245,
            "logloss": 0.5422926085634124,
            "mae": 0.302650302622887,
            "precision": 0.7514563106796116,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8669819888000299,
            "auditor_fn_violation": 0.028560908168794898,
            "auditor_fp_violation": 0.029348893639147274,
            "ave_precision_score": 0.8675727354449831,
            "fpr": 0.12184412733260154,
            "logloss": 0.47808225863015563,
            "mae": 0.28358374303156486,
            "precision": 0.7753036437246964,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 28699,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7319858466948442,
            "auditor_fn_violation": 0.03579586988304094,
            "auditor_fp_violation": 0.011061362897985705,
            "ave_precision_score": 0.7327251621214456,
            "fpr": 0.16885964912280702,
            "logloss": 1.063503730051392,
            "mae": 0.33118489830738435,
            "precision": 0.6974459724950884,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7238089123538263,
            "auditor_fn_violation": 0.02889438508246606,
            "auditor_fp_violation": 0.013707370129136143,
            "ave_precision_score": 0.7257184537990411,
            "fpr": 0.1602634467618002,
            "logloss": 1.0056852586846299,
            "mae": 0.3268223166276185,
            "precision": 0.705050505050505,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8074195332594685,
            "auditor_fn_violation": 0.019293676900584793,
            "auditor_fp_violation": 0.03136421783625731,
            "ave_precision_score": 0.8050918639735146,
            "fpr": 0.15460526315789475,
            "logloss": 1.3253446745314181,
            "mae": 0.2722023799167326,
            "precision": 0.7288461538461538,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7966286736896175,
            "auditor_fn_violation": 0.019411135349942342,
            "auditor_fp_violation": 0.02343088667117132,
            "ave_precision_score": 0.7941559645315377,
            "fpr": 0.13611416026344675,
            "logloss": 1.378809211868348,
            "mae": 0.27189793760660846,
            "precision": 0.7416666666666667,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8490450736044508,
            "auditor_fn_violation": 0.015944809941520467,
            "auditor_fp_violation": 0.026924951267056536,
            "ave_precision_score": 0.8492684633950303,
            "fpr": 0.15679824561403508,
            "logloss": 0.7409262705895793,
            "mae": 0.26712012294408394,
            "precision": 0.7356746765249538,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8304002218153483,
            "auditor_fn_violation": 0.021967791688087927,
            "auditor_fp_violation": 0.02343339855867895,
            "ave_precision_score": 0.8309165431785792,
            "fpr": 0.13391877058177826,
            "logloss": 0.7414918103489906,
            "mae": 0.26644697569780906,
            "precision": 0.7505112474437627,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8496876889173465,
            "auditor_fn_violation": 0.015149853801169594,
            "auditor_fp_violation": 0.030701754385964918,
            "ave_precision_score": 0.8499006415944971,
            "fpr": 0.15789473684210525,
            "logloss": 0.9408236904057362,
            "mae": 0.2668718608151325,
            "precision": 0.7313432835820896,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8329373776351412,
            "auditor_fn_violation": 0.02087472847105467,
            "auditor_fp_violation": 0.019906708497966635,
            "ave_precision_score": 0.8335700606483804,
            "fpr": 0.12952799121844127,
            "logloss": 0.8351497827416571,
            "mae": 0.2647828710604343,
            "precision": 0.7586912065439673,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8474177192169734,
            "auditor_fn_violation": 0.015286915204678366,
            "auditor_fp_violation": 0.025224374593892145,
            "ave_precision_score": 0.8476482386217293,
            "fpr": 0.20942982456140352,
            "logloss": 0.6861951447282804,
            "mae": 0.28765946560608785,
            "precision": 0.6863711001642037,
            "recall": 0.8708333333333333
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8425111724774075,
            "auditor_fn_violation": 0.014142663276318046,
            "auditor_fp_violation": 0.01960277010954342,
            "ave_precision_score": 0.8430373407933947,
            "fpr": 0.17453347969264543,
            "logloss": 0.6369212973104303,
            "mae": 0.2759358728973688,
            "precision": 0.7160714285714286,
            "recall": 0.8459915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8522409875474527,
            "auditor_fn_violation": 0.01567068713450293,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8524500404415934,
            "fpr": 0.1600877192982456,
            "logloss": 0.7216270097617928,
            "mae": 0.2672772287649061,
            "precision": 0.7301293900184843,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8380864693101326,
            "auditor_fn_violation": 0.01924439689310676,
            "auditor_fp_violation": 0.019602770109543418,
            "ave_precision_score": 0.8384996375955491,
            "fpr": 0.13611416026344675,
            "logloss": 0.7101124558491355,
            "mae": 0.26454660177652933,
            "precision": 0.7529880478087649,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8221007559479561,
            "auditor_fn_violation": 0.038301809210526325,
            "auditor_fp_violation": 0.03116877842755036,
            "ave_precision_score": 0.8220460182543233,
            "fpr": 0.1600877192982456,
            "logloss": 2.084025413125528,
            "mae": 0.2910500075591439,
            "precision": 0.7165048543689321,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8291931147020932,
            "auditor_fn_violation": 0.02646509839884766,
            "auditor_fp_violation": 0.0311348456570721,
            "ave_precision_score": 0.829352916258053,
            "fpr": 0.141602634467618,
            "logloss": 1.9360567606863979,
            "mae": 0.28303596728553243,
            "precision": 0.7351129363449692,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8571416852803362,
            "auditor_fn_violation": 0.02141812865497077,
            "auditor_fp_violation": 0.030874350227420407,
            "ave_precision_score": 0.8573614664991926,
            "fpr": 0.15021929824561403,
            "logloss": 0.5610179025363817,
            "mae": 0.2823139345795996,
            "precision": 0.7410207939508506,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8600099071542221,
            "auditor_fn_violation": 0.024593922383248347,
            "auditor_fp_violation": 0.02513143451383673,
            "ave_precision_score": 0.8603341395054148,
            "fpr": 0.12623490669593854,
            "logloss": 0.5167239883796648,
            "mae": 0.27487752739649274,
            "precision": 0.7638603696098563,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8509216249121416,
            "auditor_fn_violation": 0.011325840643274854,
            "auditor_fp_violation": 0.013690911306042882,
            "ave_precision_score": 0.8511542386665054,
            "fpr": 0.13486842105263158,
            "logloss": 0.5441323727444968,
            "mae": 0.30413739159224096,
            "precision": 0.7564356435643564,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8675626559049066,
            "auditor_fn_violation": 0.009781989467687477,
            "auditor_fp_violation": 0.015480762709522818,
            "ave_precision_score": 0.8678216500205664,
            "fpr": 0.12294182217343579,
            "logloss": 0.4772473022911709,
            "mae": 0.2877163692839609,
            "precision": 0.7718940936863544,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8508968244407809,
            "auditor_fn_violation": 0.010142543859649128,
            "auditor_fp_violation": 0.01644736842105263,
            "ave_precision_score": 0.8511075506767821,
            "fpr": 0.14035087719298245,
            "logloss": 0.7080266744184829,
            "mae": 0.27059784918226315,
            "precision": 0.7455268389662028,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8378755778693832,
            "auditor_fn_violation": 0.012574858619683481,
            "auditor_fp_violation": 0.019283760396074427,
            "ave_precision_score": 0.8383252028269916,
            "fpr": 0.11525795828759605,
            "logloss": 0.7081410292814982,
            "mae": 0.2665569736389096,
            "precision": 0.7707423580786026,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.800246817575972,
            "auditor_fn_violation": 0.012360654239766077,
            "auditor_fp_violation": 0.011462394411955823,
            "ave_precision_score": 0.7693572212633726,
            "fpr": 0.1206140350877193,
            "logloss": 3.2372347550527403,
            "mae": 0.27528375306549596,
            "precision": 0.7654584221748401,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7824988495749545,
            "auditor_fn_violation": 0.00999041253873196,
            "auditor_fp_violation": 0.013418503065758708,
            "ave_precision_score": 0.7534545751419549,
            "fpr": 0.10537870472008781,
            "logloss": 3.538397772123297,
            "mae": 0.28520767589253343,
            "precision": 0.7746478873239436,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 28699,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8233700844509837,
            "auditor_fn_violation": 0.010320723684210525,
            "auditor_fp_violation": 0.023168453541260563,
            "ave_precision_score": 0.8239940508296033,
            "fpr": 0.14912280701754385,
            "logloss": 0.7911856537836354,
            "mae": 0.2710805220446589,
            "precision": 0.7374517374517374,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8227523850930343,
            "auditor_fn_violation": 0.016479317483916688,
            "auditor_fp_violation": 0.015460667609461782,
            "ave_precision_score": 0.8232384745424359,
            "fpr": 0.1207464324917673,
            "logloss": 0.7537056910284334,
            "mae": 0.2651843400791134,
            "precision": 0.7693920335429769,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8602386109456437,
            "auditor_fn_violation": 0.020399305555555556,
            "auditor_fp_violation": 0.028478313840155943,
            "ave_precision_score": 0.860448777552922,
            "fpr": 0.1513157894736842,
            "logloss": 0.5811923416925813,
            "mae": 0.2740383537102947,
            "precision": 0.7420560747663552,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8581595289424594,
            "auditor_fn_violation": 0.022333689968366013,
            "auditor_fp_violation": 0.021406305340021657,
            "ave_precision_score": 0.8584564691663756,
            "fpr": 0.132821075740944,
            "logloss": 0.547979647474602,
            "mae": 0.26822848967688534,
            "precision": 0.7570281124497992,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8623572149823902,
            "auditor_fn_violation": 0.022861842105263163,
            "auditor_fp_violation": 0.023148148148148154,
            "ave_precision_score": 0.8625713001273448,
            "fpr": 0.14473684210526316,
            "logloss": 0.5576129175769838,
            "mae": 0.2739191495588864,
            "precision": 0.7476099426386233,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8617448880687103,
            "auditor_fn_violation": 0.025691617224082596,
            "auditor_fp_violation": 0.022275418417661584,
            "ave_precision_score": 0.86206146508838,
            "fpr": 0.12733260153677278,
            "logloss": 0.522823270434117,
            "mae": 0.2677362066017607,
            "precision": 0.7622950819672131,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8522498731079701,
            "auditor_fn_violation": 0.01567068713450293,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8524589072457412,
            "fpr": 0.1600877192982456,
            "logloss": 0.7216079859309159,
            "mae": 0.2672789543403375,
            "precision": 0.7301293900184843,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8381010992191857,
            "auditor_fn_violation": 0.01924439689310676,
            "auditor_fp_violation": 0.019602770109543418,
            "ave_precision_score": 0.8385142374294143,
            "fpr": 0.13611416026344675,
            "logloss": 0.7100700230112706,
            "mae": 0.26454557708460713,
            "precision": 0.7529880478087649,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8482668680563149,
            "auditor_fn_violation": 0.036686769005847955,
            "auditor_fp_violation": 0.013827972709551658,
            "ave_precision_score": 0.8485073477428826,
            "fpr": 0.08552631578947369,
            "logloss": 0.5885918746449827,
            "mae": 0.30521786892571373,
            "precision": 0.8177570093457944,
            "recall": 0.7291666666666666
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8738438176922316,
            "auditor_fn_violation": 0.026539204379663475,
            "auditor_fp_violation": 0.015995699648586936,
            "ave_precision_score": 0.8740555885705197,
            "fpr": 0.0801317233809001,
            "logloss": 0.5017521473087407,
            "mae": 0.28534390473797927,
            "precision": 0.8253588516746412,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8615963707767611,
            "auditor_fn_violation": 0.02414108187134503,
            "auditor_fp_violation": 0.02255421539961015,
            "ave_precision_score": 0.8618182612949795,
            "fpr": 0.14583333333333334,
            "logloss": 0.5567754097232672,
            "mae": 0.2738378664212656,
            "precision": 0.7466666666666667,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8620938350094849,
            "auditor_fn_violation": 0.02502003177293928,
            "auditor_fp_violation": 0.021780576578658502,
            "ave_precision_score": 0.8624318260387229,
            "fpr": 0.12623490669593854,
            "logloss": 0.5200315005249307,
            "mae": 0.267389919731725,
            "precision": 0.764344262295082,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8519769972461555,
            "auditor_fn_violation": 0.010816429093567252,
            "auditor_fp_violation": 0.020589668615984408,
            "ave_precision_score": 0.8521935506329301,
            "fpr": 0.18859649122807018,
            "logloss": 0.7055277007064895,
            "mae": 0.27591534869331386,
            "precision": 0.706984667802385,
            "recall": 0.8645833333333334
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8478477210088201,
            "auditor_fn_violation": 0.01248222614366371,
            "auditor_fp_violation": 0.018479956393632868,
            "ave_precision_score": 0.8481679650807316,
            "fpr": 0.17233809001097694,
            "logloss": 0.6565671798677436,
            "mae": 0.26592134693741576,
            "precision": 0.718132854578097,
            "recall": 0.8438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8523090830819771,
            "auditor_fn_violation": 0.01567068713450293,
            "auditor_fp_violation": 0.028386939571150103,
            "ave_precision_score": 0.8525182163563012,
            "fpr": 0.1600877192982456,
            "logloss": 0.7212740840775049,
            "mae": 0.26721274519558363,
            "precision": 0.7301293900184843,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8382580707915337,
            "auditor_fn_violation": 0.01924439689310676,
            "auditor_fp_violation": 0.019602770109543418,
            "ave_precision_score": 0.8386709490293859,
            "fpr": 0.13611416026344675,
            "logloss": 0.7096885315141679,
            "mae": 0.2644770139273571,
            "precision": 0.7529880478087649,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8273228257411775,
            "auditor_fn_violation": 0.011348684210526332,
            "auditor_fp_violation": 0.010622258771929828,
            "ave_precision_score": 0.8275881691498198,
            "fpr": 0.09539473684210527,
            "logloss": 0.8164023602082413,
            "mae": 0.28984924024343384,
            "precision": 0.7857142857142857,
            "recall": 0.6645833333333333
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8183935350786073,
            "auditor_fn_violation": 0.007822812599869389,
            "auditor_fp_violation": 0.005940613955544615,
            "ave_precision_score": 0.819027610388725,
            "fpr": 0.0801317233809001,
            "logloss": 0.8535862383917879,
            "mae": 0.29372763105246047,
            "precision": 0.7988980716253443,
            "recall": 0.6118143459915611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8622338556418329,
            "auditor_fn_violation": 0.030254020467836262,
            "auditor_fp_violation": 0.016485441033138405,
            "ave_precision_score": 0.8624093824741588,
            "fpr": 0.14364035087719298,
            "logloss": 0.5619176739417311,
            "mae": 0.3000769222254127,
            "precision": 0.7475915221579962,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8705909955242352,
            "auditor_fn_violation": 0.031231039290064707,
            "auditor_fp_violation": 0.018879346507346018,
            "ave_precision_score": 0.871014234852194,
            "fpr": 0.12403951701427003,
            "logloss": 0.4876079387251661,
            "mae": 0.28138461095110107,
            "precision": 0.7730923694779116,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8597474534516761,
            "auditor_fn_violation": 0.02355171783625731,
            "auditor_fp_violation": 0.021716617933723203,
            "ave_precision_score": 0.859972187625203,
            "fpr": 0.14473684210526316,
            "logloss": 0.5514899886492358,
            "mae": 0.2784373842718667,
            "precision": 0.7476099426386233,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8622323773357237,
            "auditor_fn_violation": 0.024102970260343574,
            "auditor_fp_violation": 0.022880783307000382,
            "ave_precision_score": 0.8625791567385201,
            "fpr": 0.12952799121844127,
            "logloss": 0.5113910391430188,
            "mae": 0.27098646035569857,
            "precision": 0.7611336032388664,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8441739174094162,
            "auditor_fn_violation": 0.015019645467836257,
            "auditor_fp_violation": 0.026924951267056536,
            "ave_precision_score": 0.8443985734471137,
            "fpr": 0.15679824561403508,
            "logloss": 0.7435105514781786,
            "mae": 0.2709908445145718,
            "precision": 0.7322097378277154,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8298053155741499,
            "auditor_fn_violation": 0.020870096847253678,
            "auditor_fp_violation": 0.021054641088953475,
            "ave_precision_score": 0.830319678912436,
            "fpr": 0.13062568605927552,
            "logloss": 0.7342729771408003,
            "mae": 0.26766489750374955,
            "precision": 0.7551440329218106,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8156728748865709,
            "auditor_fn_violation": 0.025863486842105265,
            "auditor_fp_violation": 0.03611567982456142,
            "ave_precision_score": 0.8159174833686309,
            "fpr": 0.18530701754385964,
            "logloss": 0.6227160307862954,
            "mae": 0.3490484255050604,
            "precision": 0.6910420475319927,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8213631049484431,
            "auditor_fn_violation": 0.03271315890638099,
            "auditor_fp_violation": 0.03894430391829333,
            "ave_precision_score": 0.8217189969355868,
            "fpr": 0.150384193194292,
            "logloss": 0.564759115485661,
            "mae": 0.32975184795994866,
            "precision": 0.7287128712871287,
            "recall": 0.7763713080168776
        }
    }
]