[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7665972137398566,
            "auditor_fn_violation": 0.014571791320406282,
            "auditor_fp_violation": 0.020895852570021557,
            "ave_precision_score": 0.6460922495902284,
            "fpr": 0.19188596491228072,
            "logloss": 10.448745310258534,
            "mae": 0.33329909801058744,
            "precision": 0.651394422310757,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7887751920371122,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.01828605449137924,
            "ave_precision_score": 0.6783366169851922,
            "fpr": 0.18551042810098792,
            "logloss": 10.689566339494267,
            "mae": 0.3379521796666323,
            "precision": 0.6799242424242424,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7636620960761568,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6498071220698902,
            "fpr": 0.16776315789473684,
            "logloss": 10.080680546757106,
            "mae": 0.317454965290891,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7877776906198922,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.028571960142780066,
            "ave_precision_score": 0.6865882520968514,
            "fpr": 0.16245883644346873,
            "logloss": 10.212375868513037,
            "mae": 0.32168719145693236,
            "precision": 0.705765407554672,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7733942839120425,
            "auditor_fn_violation": 0.011349646044936913,
            "auditor_fp_violation": 0.010948080178516475,
            "ave_precision_score": 0.7748442220595486,
            "fpr": 0.15679824561403508,
            "logloss": 0.869373058463076,
            "mae": 0.28502263608927075,
            "precision": 0.7111111111111111,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7916314649694727,
            "auditor_fn_violation": 0.010868942289465222,
            "auditor_fp_violation": 0.026785880401761625,
            "ave_precision_score": 0.7919075753606997,
            "fpr": 0.15477497255762898,
            "logloss": 0.8885942680918237,
            "mae": 0.28619761888971795,
            "precision": 0.7398523985239852,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.843662130107929,
            "auditor_fn_violation": 0.036299630655586335,
            "auditor_fp_violation": 0.024800900277008313,
            "ave_precision_score": 0.8440286087824456,
            "fpr": 0.1074561403508772,
            "logloss": 0.5158157083912595,
            "mae": 0.3048194370172464,
            "precision": 0.7741935483870968,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8629229013806794,
            "auditor_fn_violation": 0.030828032216682316,
            "auditor_fp_violation": 0.025042326368862677,
            "ave_precision_score": 0.8632173592105934,
            "fpr": 0.09659714599341383,
            "logloss": 0.5379355954007332,
            "mae": 0.3066050795362009,
            "precision": 0.8048780487804879,
            "recall": 0.7289156626506024
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8364928740395017,
            "auditor_fn_violation": 0.010193040166204986,
            "auditor_fp_violation": 0.020282683133271775,
            "ave_precision_score": 0.8367427481498206,
            "fpr": 0.13048245614035087,
            "logloss": 0.6787239869308768,
            "mae": 0.2700904257295005,
            "precision": 0.7435344827586207,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8357760340100173,
            "auditor_fn_violation": 0.008543504423842462,
            "auditor_fp_violation": 0.021284116913803053,
            "ave_precision_score": 0.8361817298582742,
            "fpr": 0.1207464324917673,
            "logloss": 0.7371576850377594,
            "mae": 0.27282567298317373,
            "precision": 0.779559118236473,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 18998,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6470337514222528,
            "auditor_fn_violation": 0.0029047399199753844,
            "auditor_fp_violation": 0.008483379501385046,
            "ave_precision_score": 0.6403588021325026,
            "fpr": 0.07346491228070176,
            "logloss": 2.1704582551652085,
            "mae": 0.39887214060279796,
            "precision": 0.70995670995671,
            "recall": 0.35964912280701755
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6323423388522016,
            "auditor_fn_violation": 0.007027010346545368,
            "auditor_fp_violation": 0.00010099855678378361,
            "ave_precision_score": 0.6287481747803552,
            "fpr": 0.07574094401756312,
            "logloss": 2.5227550874012685,
            "mae": 0.4583116874389854,
            "precision": 0.6745283018867925,
            "recall": 0.28714859437751006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7708660945793018,
            "auditor_fn_violation": 0.007834141274238229,
            "auditor_fp_violation": 0.01224415204678363,
            "ave_precision_score": 0.7723229688785305,
            "fpr": 0.1600877192982456,
            "logloss": 0.8680868647783232,
            "mae": 0.2888269092672901,
            "precision": 0.708,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7899013315308823,
            "auditor_fn_violation": 0.00833410480561103,
            "auditor_fp_violation": 0.022426995319514254,
            "ave_precision_score": 0.7901627400771087,
            "fpr": 0.15806805708013172,
            "logloss": 0.8858690508780095,
            "mae": 0.28887854626525006,
            "precision": 0.7357798165137615,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7642770491203211,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.020924707602339186,
            "ave_precision_score": 0.6243143382728071,
            "fpr": 0.17653508771929824,
            "logloss": 10.950272738745078,
            "mae": 0.32005545957700204,
            "precision": 0.668724279835391,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7862392752910592,
            "auditor_fn_violation": 0.01776149603904091,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.6590503945454506,
            "fpr": 0.16575192096597147,
            "logloss": 11.072899972923642,
            "mae": 0.32225375957010083,
            "precision": 0.702755905511811,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7964238005569867,
            "auditor_fn_violation": 0.012696214219759928,
            "auditor_fp_violation": 0.034183594952293034,
            "ave_precision_score": 0.6584698198915536,
            "fpr": 0.2982456140350877,
            "logloss": 10.163698941767558,
            "mae": 0.3517712660884063,
            "precision": 0.6,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.8106722397247971,
            "auditor_fn_violation": 0.006890349543067992,
            "auditor_fp_violation": 0.04096023048933802,
            "ave_precision_score": 0.6818885294718617,
            "fpr": 0.283205268935236,
            "logloss": 10.07417856293162,
            "mae": 0.3451137255294473,
            "precision": 0.630901287553648,
            "recall": 0.8855421686746988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8556952929478604,
            "auditor_fn_violation": 0.009923726531240388,
            "auditor_fp_violation": 0.014379424438288706,
            "ave_precision_score": 0.8559164437200288,
            "fpr": 0.12719298245614036,
            "logloss": 0.5959946773377287,
            "mae": 0.2663960006285053,
            "precision": 0.7526652452025586,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8660761771433545,
            "auditor_fn_violation": 0.013189971742072579,
            "auditor_fp_violation": 0.02647491116113788,
            "ave_precision_score": 0.8663781005919663,
            "fpr": 0.11964873765093303,
            "logloss": 0.6594861175136422,
            "mae": 0.2676521667146784,
            "precision": 0.7837301587301587,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7682942716949317,
            "auditor_fn_violation": 0.014571791320406282,
            "auditor_fp_violation": 0.020895852570021557,
            "ave_precision_score": 0.6420992510075925,
            "fpr": 0.19188596491228072,
            "logloss": 10.67263005067826,
            "mae": 0.3333032412784843,
            "precision": 0.651394422310757,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7874424482184951,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.01828605449137924,
            "ave_precision_score": 0.6715033050954636,
            "fpr": 0.18551042810098792,
            "logloss": 10.935552777323487,
            "mae": 0.3379786829676305,
            "precision": 0.6799242424242424,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 18998,
        "test": {
            "accuracy": 0.3223684210526316,
            "auc_prc": 0.4829026617821077,
            "auditor_fn_violation": 0.01609870344721454,
            "auditor_fp_violation": 0.018548976608187145,
            "ave_precision_score": 0.4246097549847417,
            "fpr": 0.32127192982456143,
            "logloss": 22.72514332684335,
            "mae": 0.6776299200154307,
            "precision": 0.3089622641509434,
            "recall": 0.28728070175438597
        },
        "train": {
            "accuracy": 0.32491767288693746,
            "auc_prc": 0.5212270205664479,
            "auditor_fn_violation": 0.0177614960390409,
            "auditor_fp_violation": 0.02367884585228164,
            "ave_precision_score": 0.46947293744138363,
            "fpr": 0.283205268935236,
            "logloss": 22.601095796277985,
            "mae": 0.6750801370986753,
            "precision": 0.3533834586466165,
            "recall": 0.28313253012048195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7946442542102875,
            "auditor_fn_violation": 0.006388985072329948,
            "auditor_fp_violation": 0.013629193598030163,
            "ave_precision_score": 0.7872720896852395,
            "fpr": 0.16228070175438597,
            "logloss": 1.057165531246698,
            "mae": 0.28988411857368956,
            "precision": 0.7191650853889943,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8003950041003358,
            "auditor_fn_violation": 0.004910972099154026,
            "auditor_fp_violation": 0.028447040875179075,
            "ave_precision_score": 0.7863506975657023,
            "fpr": 0.15477497255762898,
            "logloss": 1.3602807633011746,
            "mae": 0.28123279698203296,
            "precision": 0.7441016333938294,
            "recall": 0.8232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7836225791310346,
            "auditor_fn_violation": 0.008093836565096955,
            "auditor_fp_violation": 0.014848318713450296,
            "ave_precision_score": 0.7826837363204906,
            "fpr": 0.14583333333333334,
            "logloss": 1.6868344071977104,
            "mae": 0.28871442022543,
            "precision": 0.7145922746781116,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7995269314617615,
            "auditor_fn_violation": 0.02257989146487157,
            "auditor_fp_violation": 0.02513269349861659,
            "ave_precision_score": 0.7959083072555913,
            "fpr": 0.14709110867178923,
            "logloss": 1.7584451482725993,
            "mae": 0.2903225684539136,
            "precision": 0.7341269841269841,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.8387182591479732,
            "auditor_fn_violation": 0.010599415204678365,
            "auditor_fp_violation": 0.004058941212680825,
            "ave_precision_score": 0.838944463748369,
            "fpr": 0.01425438596491228,
            "logloss": 1.1684920690881826,
            "mae": 0.35834316305556163,
            "precision": 0.9212121212121213,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8575996463371782,
            "auditor_fn_violation": 0.02083195570426602,
            "auditor_fp_violation": 0.005629340612317041,
            "ave_precision_score": 0.8578432421922733,
            "fpr": 0.01756311745334797,
            "logloss": 1.2165912487049142,
            "mae": 0.3698773681600739,
            "precision": 0.9211822660098522,
            "recall": 0.3755020080321285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7614909263366427,
            "auditor_fn_violation": 0.01627183364112035,
            "auditor_fp_violation": 0.006944444444444445,
            "ave_precision_score": 0.7618949344864476,
            "fpr": 0.05701754385964912,
            "logloss": 1.4268624452833998,
            "mae": 0.36351218149701087,
            "precision": 0.7976653696498055,
            "recall": 0.44956140350877194
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.798055241585883,
            "auditor_fn_violation": 0.0018647587055136148,
            "auditor_fp_violation": 0.011766331865310453,
            "ave_precision_score": 0.7983389803893964,
            "fpr": 0.050493962678375415,
            "logloss": 1.532841720032195,
            "mae": 0.3742637514755538,
            "precision": 0.8339350180505415,
            "recall": 0.463855421686747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6955991021451804,
            "auditor_fn_violation": 0.009846779778393353,
            "auditor_fp_violation": 0.006896352723915057,
            "ave_precision_score": 0.6949261845697354,
            "fpr": 0.20614035087719298,
            "logloss": 1.2544966057131386,
            "mae": 0.3041555378346474,
            "precision": 0.6730434782608695,
            "recall": 0.8486842105263158
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7092176604244105,
            "auditor_fn_violation": 0.009114393909336584,
            "auditor_fp_violation": 0.02258646672496233,
            "ave_precision_score": 0.7066152845430905,
            "fpr": 0.19538968166849616,
            "logloss": 1.3606254022724078,
            "mae": 0.3023344853135903,
            "precision": 0.7028380634390651,
            "recall": 0.8453815261044176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7911494306805614,
            "auditor_fn_violation": 0.00539589104339797,
            "auditor_fp_violation": 0.013533010156971382,
            "ave_precision_score": 0.7798114713756371,
            "fpr": 0.1611842105263158,
            "logloss": 1.2786061657565344,
            "mae": 0.2881455685409364,
            "precision": 0.72,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8033946856021278,
            "auditor_fn_violation": 0.004855866936461545,
            "auditor_fp_violation": 0.02809620378319331,
            "ave_precision_score": 0.7867930515650613,
            "fpr": 0.15697036223929747,
            "logloss": 1.519659464767406,
            "mae": 0.2813315817377807,
            "precision": 0.74,
            "recall": 0.8172690763052208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7637588665840237,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.02375730994152048,
            "ave_precision_score": 0.6498898163245103,
            "fpr": 0.16666666666666666,
            "logloss": 10.060086496736835,
            "mae": 0.3168104829332022,
            "precision": 0.68,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7878222661678349,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.027944705948017644,
            "ave_precision_score": 0.6866203876834394,
            "fpr": 0.16136114160263446,
            "logloss": 10.18286326881816,
            "mae": 0.3212430301468928,
            "precision": 0.7071713147410359,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7651271225793308,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.02110745614035088,
            "ave_precision_score": 0.6262107090643275,
            "fpr": 0.17434210526315788,
            "logloss": 10.839863641854375,
            "mae": 0.3179728331354757,
            "precision": 0.6714876033057852,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7859050656617902,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.02387021153881933,
            "ave_precision_score": 0.6581304278282264,
            "fpr": 0.1690450054884742,
            "logloss": 11.075632215828666,
            "mae": 0.3235803314215789,
            "precision": 0.6980392156862745,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7642000908779206,
            "auditor_fn_violation": 0.01307613881194214,
            "auditor_fp_violation": 0.020907875500153897,
            "ave_precision_score": 0.6240482654394927,
            "fpr": 0.2050438596491228,
            "logloss": 11.11191164027348,
            "mae": 0.32912319437827214,
            "precision": 0.6471698113207547,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7836847057169944,
            "auditor_fn_violation": 0.02047267004351104,
            "auditor_fp_violation": 0.02733074103704256,
            "ave_precision_score": 0.6529803129309877,
            "fpr": 0.2052689352360044,
            "logloss": 11.148457179570347,
            "mae": 0.3346547467373211,
            "precision": 0.6696113074204947,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7642157252017322,
            "auditor_fn_violation": 0.01592797783933518,
            "auditor_fp_violation": 0.021078601108033237,
            "ave_precision_score": 0.6502575978724733,
            "fpr": 0.1699561403508772,
            "logloss": 10.081966829971778,
            "mae": 0.3183563933585231,
            "precision": 0.6764091858037579,
            "recall": 0.7105263157894737
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7874103092721685,
            "auditor_fn_violation": 0.020230207327664118,
            "auditor_fp_violation": 0.02606560122048783,
            "ave_precision_score": 0.6862131855619098,
            "fpr": 0.1690450054884742,
            "logloss": 10.243496510131799,
            "mae": 0.32539703032874906,
            "precision": 0.6980392156862745,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 18998,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7659247395234148,
            "auditor_fn_violation": 0.01392255309325947,
            "auditor_fp_violation": 0.019409818405663287,
            "ave_precision_score": 0.6516506832735969,
            "fpr": 0.18859649122807018,
            "logloss": 10.12161796692689,
            "mae": 0.3272660066978172,
            "precision": 0.6546184738955824,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.78718835540333,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.020106686370244767,
            "ave_precision_score": 0.6842215234545097,
            "fpr": 0.18111964873765093,
            "logloss": 10.346708936795011,
            "mae": 0.33126062462688893,
            "precision": 0.6851145038167938,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8521687458280818,
            "auditor_fn_violation": 0.01974646044936904,
            "auditor_fp_violation": 0.015235457063711913,
            "ave_precision_score": 0.8524237883858586,
            "fpr": 0.12171052631578948,
            "logloss": 0.5951551987762702,
            "mae": 0.26288378360478665,
            "precision": 0.753880266075388,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8541781647272653,
            "auditor_fn_violation": 0.017563117453347966,
            "auditor_fp_violation": 0.026326071182719683,
            "ave_precision_score": 0.854615064357574,
            "fpr": 0.10757409440175632,
            "logloss": 0.6461750089021422,
            "mae": 0.2661493433228426,
            "precision": 0.797938144329897,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7642929605973127,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6503454913684066,
            "fpr": 0.16776315789473684,
            "logloss": 10.122121331172295,
            "mae": 0.3175630275315295,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7882046497712241,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.028571960142780066,
            "ave_precision_score": 0.6870015689322123,
            "fpr": 0.16245883644346873,
            "logloss": 10.255339245657742,
            "mae": 0.3223030942233543,
            "precision": 0.705765407554672,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7654518977883934,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6568002926631589,
            "fpr": 0.16776315789473684,
            "logloss": 9.881577074203861,
            "mae": 0.3136907490455869,
            "precision": 0.6799163179916318,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7908037847061897,
            "auditor_fn_violation": 0.01941465091981538,
            "auditor_fp_violation": 0.02540379488787832,
            "ave_precision_score": 0.6939776976775355,
            "fpr": 0.16355653128430298,
            "logloss": 10.004744518255414,
            "mae": 0.32200217113156904,
            "precision": 0.7037773359840954,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7640999459145044,
            "auditor_fn_violation": 0.01307613881194214,
            "auditor_fp_violation": 0.020907875500153897,
            "ave_precision_score": 0.6236913655060414,
            "fpr": 0.2050438596491228,
            "logloss": 11.240881236570635,
            "mae": 0.3289478555265112,
            "precision": 0.6471698113207547,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7835563896978589,
            "auditor_fn_violation": 0.02047267004351104,
            "auditor_fp_violation": 0.02733074103704256,
            "ave_precision_score": 0.652339669436875,
            "fpr": 0.2052689352360044,
            "logloss": 11.319167382248247,
            "mae": 0.33588344687963295,
            "precision": 0.6696113074204947,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7651271225793308,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.022131809787626962,
            "ave_precision_score": 0.6262107090643275,
            "fpr": 0.1699561403508772,
            "logloss": 10.832118335683596,
            "mae": 0.3142718568210911,
            "precision": 0.6770833333333334,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7859078179272166,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.6581331785571696,
            "fpr": 0.16575192096597147,
            "logloss": 11.075349695920767,
            "mae": 0.32189061664122554,
            "precision": 0.7021696252465484,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6773305111321555,
            "auditor_fn_violation": 0.0007430170821791363,
            "auditor_fp_violation": 0.0028927169898430296,
            "ave_precision_score": 0.6778917421265069,
            "fpr": 0.24013157894736842,
            "logloss": 0.964368831658064,
            "mae": 0.3586998665919772,
            "precision": 0.635,
            "recall": 0.8355263157894737
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7150635127092067,
            "auditor_fn_violation": 0.004853662729953848,
            "auditor_fp_violation": 0.010950369840767804,
            "ave_precision_score": 0.7148116907601523,
            "fpr": 0.2030735455543359,
            "logloss": 0.9711827487476897,
            "mae": 0.33698158557951025,
            "precision": 0.6952224052718287,
            "recall": 0.8473895582329317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5340895700224975,
            "auditor_fn_violation": 0.06918234456755924,
            "auditor_fp_violation": 0.05159279778393352,
            "ave_precision_score": 0.49930157347842385,
            "fpr": 0.23793859649122806,
            "logloss": 6.836829348728978,
            "mae": 0.4967098029018656,
            "precision": 0.5045662100456622,
            "recall": 0.48464912280701755
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5924233314184506,
            "auditor_fn_violation": 0.06229528432059743,
            "auditor_fp_violation": 0.04318219873858119,
            "ave_precision_score": 0.5637300822770268,
            "fpr": 0.19319429198682767,
            "logloss": 6.083667576374677,
            "mae": 0.4708288524150828,
            "precision": 0.5925925925925926,
            "recall": 0.5140562248995983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8479487213496815,
            "auditor_fn_violation": 0.010604224376731307,
            "auditor_fp_violation": 0.011888273314866117,
            "ave_precision_score": 0.8481834742404162,
            "fpr": 0.13157894736842105,
            "logloss": 0.6016339255021431,
            "mae": 0.2653078289740464,
            "precision": 0.7489539748953975,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8545074482910986,
            "auditor_fn_violation": 0.011422198122897746,
            "auditor_fp_violation": 0.013172338090010985,
            "ave_precision_score": 0.8548986251524967,
            "fpr": 0.11525795828759605,
            "logloss": 0.6474735510904669,
            "mae": 0.26640982701408966,
            "precision": 0.7887323943661971,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 18998,
        "test": {
            "accuracy": 0.3223684210526316,
            "auc_prc": 0.4802395699894347,
            "auditor_fn_violation": 0.01609870344721454,
            "auditor_fp_violation": 0.018548976608187145,
            "ave_precision_score": 0.4338113801954402,
            "fpr": 0.32127192982456143,
            "logloss": 22.78320228404703,
            "mae": 0.67763136373021,
            "precision": 0.3089622641509434,
            "recall": 0.28728070175438597
        },
        "train": {
            "accuracy": 0.32491767288693746,
            "auc_prc": 0.517094994849131,
            "auditor_fn_violation": 0.0177614960390409,
            "auditor_fp_violation": 0.02367884585228164,
            "ave_precision_score": 0.4800443981556496,
            "fpr": 0.283205268935236,
            "logloss": 22.662583869684777,
            "mae": 0.6750820466810509,
            "precision": 0.3533834586466165,
            "recall": 0.28313253012048195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7244420354199441,
            "auditor_fn_violation": 0.009401931363496466,
            "auditor_fp_violation": 0.007420552477685445,
            "ave_precision_score": 0.7189943600257634,
            "fpr": 0.09100877192982457,
            "logloss": 1.7285603399657956,
            "mae": 0.30723158324960825,
            "precision": 0.7655367231638418,
            "recall": 0.5942982456140351
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6999378163564043,
            "auditor_fn_violation": 0.008808009204766376,
            "auditor_fp_violation": 0.007261264661402341,
            "ave_precision_score": 0.6963044542382248,
            "fpr": 0.09659714599341383,
            "logloss": 2.0517981685676556,
            "mae": 0.35347997428574696,
            "precision": 0.7582417582417582,
            "recall": 0.5542168674698795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.763555506749005,
            "auditor_fn_violation": 0.012203274084333643,
            "auditor_fp_violation": 0.016663781163434904,
            "ave_precision_score": 0.6496866949749662,
            "fpr": 0.17763157894736842,
            "logloss": 10.063545568799602,
            "mae": 0.32120123492004066,
            "precision": 0.6673511293634496,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7875114661197168,
            "auditor_fn_violation": 0.019500614973615656,
            "auditor_fp_violation": 0.025228376341885433,
            "ave_precision_score": 0.6863137421355994,
            "fpr": 0.17453347969264543,
            "logloss": 10.209010892109724,
            "mae": 0.32929945734094834,
            "precision": 0.6918604651162791,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5815418369502867,
            "auditor_fn_violation": 0.05001538935056942,
            "auditor_fp_violation": 0.02882617728531857,
            "ave_precision_score": 0.5073423436925443,
            "fpr": 0.19188596491228072,
            "logloss": 12.550006894919724,
            "mae": 0.4659110064377388,
            "precision": 0.5406824146981627,
            "recall": 0.4517543859649123
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6557716381742056,
            "auditor_fn_violation": 0.05206335771185731,
            "auditor_fp_violation": 0.024000446519935256,
            "ave_precision_score": 0.5922786960677313,
            "fpr": 0.15477497255762898,
            "logloss": 11.766533863889379,
            "mae": 0.4554233616935705,
            "precision": 0.6158038147138964,
            "recall": 0.4538152610441767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7651271225793308,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.02368998153277932,
            "ave_precision_score": 0.6262107090643275,
            "fpr": 0.17105263157894737,
            "logloss": 10.834968146563831,
            "mae": 0.31620200298595846,
            "precision": 0.6756756756756757,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7859133549972177,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.6581387125039804,
            "fpr": 0.16575192096597147,
            "logloss": 11.072818842128417,
            "mae": 0.3221136610443846,
            "precision": 0.7021696252465484,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8249812228117204,
            "auditor_fn_violation": 0.015824580640196987,
            "auditor_fp_violation": 0.010135330101569716,
            "ave_precision_score": 0.8253814027009748,
            "fpr": 0.12171052631578948,
            "logloss": 0.520183385793926,
            "mae": 0.32125553874637963,
            "precision": 0.754424778761062,
            "recall": 0.7478070175438597
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8821861059438025,
            "auditor_fn_violation": 0.01805906391758031,
            "auditor_fp_violation": 0.015870062698840913,
            "ave_precision_score": 0.8823899072175811,
            "fpr": 0.0889132821075741,
            "logloss": 0.47545607509993043,
            "mae": 0.3007675674789954,
            "precision": 0.8269230769230769,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 18998,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.847651841072722,
            "auditor_fn_violation": 0.01051285010772546,
            "auditor_fp_violation": 0.013549842259156671,
            "ave_precision_score": 0.8478678036143082,
            "fpr": 0.13267543859649122,
            "logloss": 0.7100109739953734,
            "mae": 0.26915310622061434,
            "precision": 0.7457983193277311,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8514035471928155,
            "auditor_fn_violation": 0.016333170222051763,
            "auditor_fp_violation": 0.022931988103433155,
            "ave_precision_score": 0.8517537410499657,
            "fpr": 0.12184412733260154,
            "logloss": 0.8888334889356736,
            "mae": 0.2696877635580527,
            "precision": 0.7788844621513944,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7280600237085518,
            "auditor_fn_violation": 0.009623153277931671,
            "auditor_fp_violation": 0.007199330563250244,
            "ave_precision_score": 0.7286315165447771,
            "fpr": 0.20065789473684212,
            "logloss": 0.9967749895648246,
            "mae": 0.28875851965679095,
            "precision": 0.6789473684210526,
            "recall": 0.8486842105263158
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7517070223029786,
            "auditor_fn_violation": 0.007915305569148164,
            "auditor_fp_violation": 0.02272999098986559,
            "ave_precision_score": 0.7514970518372194,
            "fpr": 0.1877058177826564,
            "logloss": 1.0666319004769924,
            "mae": 0.29158752867491144,
            "precision": 0.7101694915254237,
            "recall": 0.8413654618473896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7659172293053582,
            "auditor_fn_violation": 0.01392255309325947,
            "auditor_fp_violation": 0.01946271929824562,
            "ave_precision_score": 0.6516627712716883,
            "fpr": 0.19078947368421054,
            "logloss": 10.116624577141389,
            "mae": 0.329302046611359,
            "precision": 0.652,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7867827959776085,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.02079772912718643,
            "ave_precision_score": 0.6844863542257268,
            "fpr": 0.18221734357848518,
            "logloss": 10.321289302365455,
            "mae": 0.33272274706252414,
            "precision": 0.6838095238095238,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 18998,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7712506662621135,
            "auditor_fn_violation": 0.0137686595875654,
            "auditor_fp_violation": 0.023052766235764854,
            "ave_precision_score": 0.6502676343938817,
            "fpr": 0.17653508771929824,
            "logloss": 10.373995962789367,
            "mae": 0.3226133813722092,
            "precision": 0.6694045174537988,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7934206751095481,
            "auditor_fn_violation": 0.020230207327664118,
            "auditor_fp_violation": 0.02094125339208969,
            "ave_precision_score": 0.6844534796938052,
            "fpr": 0.17453347969264543,
            "logloss": 10.540644020096538,
            "mae": 0.32861887744569623,
            "precision": 0.6912621359223301,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7651271225793308,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.022131809787626962,
            "ave_precision_score": 0.6262107090643275,
            "fpr": 0.1699561403508772,
            "logloss": 10.833225134188838,
            "mae": 0.31513625696677255,
            "precision": 0.6770833333333334,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7859050656617902,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.6581304278282264,
            "fpr": 0.16575192096597147,
            "logloss": 11.073671003304712,
            "mae": 0.3223547714013038,
            "precision": 0.7021696252465484,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7700524112558126,
            "auditor_fn_violation": 0.0060042513080948,
            "auditor_fp_violation": 0.006925207756232688,
            "ave_precision_score": 0.7399939800956465,
            "fpr": 0.17324561403508773,
            "logloss": 3.375650633769541,
            "mae": 0.28459936220936866,
            "precision": 0.6978967495219885,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7850482016913354,
            "auditor_fn_violation": 0.004397391982860094,
            "auditor_fp_violation": 0.027721445980390336,
            "ave_precision_score": 0.7496660508057409,
            "fpr": 0.1690450054884742,
            "logloss": 3.5947433580227903,
            "mae": 0.2917959565575535,
            "precision": 0.7225225225225225,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8477486914168776,
            "auditor_fn_violation": 0.0025007694675284707,
            "auditor_fp_violation": 0.011676669744536801,
            "ave_precision_score": 0.8480049646106396,
            "fpr": 0.33114035087719296,
            "logloss": 0.6636289994680372,
            "mae": 0.36809379772462864,
            "precision": 0.5929919137466307,
            "recall": 0.9649122807017544
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8761756381857242,
            "auditor_fn_violation": 0.0023232336591150564,
            "auditor_fp_violation": 0.006293804801684014,
            "ave_precision_score": 0.8764147181528652,
            "fpr": 0.29747530186608123,
            "logloss": 0.5995748690584182,
            "mae": 0.3414488404776603,
            "precision": 0.6352624495289367,
            "recall": 0.9477911646586346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7935569335619874,
            "auditor_fn_violation": 0.008637273007079102,
            "auditor_fp_violation": 0.012234533702677741,
            "ave_precision_score": 0.7861961813464041,
            "fpr": 0.1600877192982456,
            "logloss": 1.0773408659613746,
            "mae": 0.287605897374912,
            "precision": 0.7203065134099617,
            "recall": 0.8245614035087719
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7998535849863386,
            "auditor_fn_violation": 0.01002032278400099,
            "auditor_fp_violation": 0.025321401328396814,
            "ave_precision_score": 0.785952190884774,
            "fpr": 0.14818880351262348,
            "logloss": 1.378793102325504,
            "mae": 0.27926613521275573,
            "precision": 0.7504621072088724,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7658576930518969,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.015548053247152973,
            "ave_precision_score": 0.6491744105620476,
            "fpr": 0.1699561403508772,
            "logloss": 10.272359237446627,
            "mae": 0.3191240529403123,
            "precision": 0.6757322175732218,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7930442814059337,
            "auditor_fn_violation": 0.020203756849571725,
            "auditor_fp_violation": 0.029047716502366826,
            "ave_precision_score": 0.6886200641335846,
            "fpr": 0.16794731064763996,
            "logloss": 10.330614165486258,
            "mae": 0.32275824085425925,
            "precision": 0.700587084148728,
            "recall": 0.7188755020080321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8457231633346767,
            "auditor_fn_violation": 0.018871191135734072,
            "auditor_fp_violation": 0.024851396583564177,
            "ave_precision_score": 0.846004631632918,
            "fpr": 0.13486842105263158,
            "logloss": 0.6552845140878572,
            "mae": 0.2628405294807575,
            "precision": 0.7421383647798742,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8445167491302006,
            "auditor_fn_violation": 0.02241237177028642,
            "auditor_fp_violation": 0.02953144643222599,
            "ave_precision_score": 0.844984304960678,
            "fpr": 0.12184412733260154,
            "logloss": 0.7116548436553637,
            "mae": 0.27097551435865774,
            "precision": 0.7762096774193549,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7817606126029352,
            "auditor_fn_violation": 0.008569944598337955,
            "auditor_fp_violation": 0.006838642659279775,
            "ave_precision_score": 0.7832681964682782,
            "fpr": 0.1513157894736842,
            "logloss": 0.8382891269458151,
            "mae": 0.2846257486056303,
            "precision": 0.7177914110429447,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8036595094006009,
            "auditor_fn_violation": 0.01109597555975824,
            "auditor_fp_violation": 0.029310844321356146,
            "ave_precision_score": 0.8043964621088111,
            "fpr": 0.15587266739846323,
            "logloss": 0.8491814760808736,
            "mae": 0.28669342740671594,
            "precision": 0.7340823970037453,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.725104972850326,
            "auditor_fn_violation": 0.009291320406278858,
            "auditor_fp_violation": 0.009493305632502313,
            "ave_precision_score": 0.7196566261062587,
            "fpr": 0.09210526315789473,
            "logloss": 1.7253473621211375,
            "mae": 0.306054880268696,
            "precision": 0.7627118644067796,
            "recall": 0.5921052631578947
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7007469107447507,
            "auditor_fn_violation": 0.006581760631990093,
            "auditor_fp_violation": 0.0074047889263056076,
            "ave_precision_score": 0.6971126795466305,
            "fpr": 0.09769484083424808,
            "logloss": 2.047839084533448,
            "mae": 0.3517438704879071,
            "precision": 0.7574931880108992,
            "recall": 0.5582329317269076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8442166455228625,
            "auditor_fn_violation": 0.004948638042474608,
            "auditor_fp_violation": 0.01633194829178209,
            "ave_precision_score": 0.8444472076319743,
            "fpr": 0.12938596491228072,
            "logloss": 0.6105511831877135,
            "mae": 0.26903956674494306,
            "precision": 0.75,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8499216066538523,
            "auditor_fn_violation": 0.007392908626823432,
            "auditor_fp_violation": 0.024601122147123008,
            "ave_precision_score": 0.8502443318460546,
            "fpr": 0.1163556531284303,
            "logloss": 0.6596214969834665,
            "mae": 0.2694572509575292,
            "precision": 0.7849898580121704,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7671016842523875,
            "auditor_fn_violation": 0.012830871037242236,
            "auditor_fp_violation": 0.02223761157279164,
            "ave_precision_score": 0.6526048220383021,
            "fpr": 0.16557017543859648,
            "logloss": 10.151346820706847,
            "mae": 0.3156427513675768,
            "precision": 0.6787234042553192,
            "recall": 0.6995614035087719
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7900790855219059,
            "auditor_fn_violation": 0.019379383615692188,
            "auditor_fp_violation": 0.02791546952368549,
            "ave_precision_score": 0.6879941756366562,
            "fpr": 0.15916575192096596,
            "logloss": 10.296731241011845,
            "mae": 0.3191871626354226,
            "precision": 0.7082494969818913,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7639721269225022,
            "auditor_fn_violation": 0.013157894736842113,
            "auditor_fp_violation": 0.021564327485380126,
            "ave_precision_score": 0.6508676287204865,
            "fpr": 0.16666666666666666,
            "logloss": 9.895568908566638,
            "mae": 0.3134289106130469,
            "precision": 0.680672268907563,
            "recall": 0.7105263157894737
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7896372815986957,
            "auditor_fn_violation": 0.01941465091981538,
            "auditor_fp_violation": 0.027118112496445124,
            "ave_precision_score": 0.6894165077251231,
            "fpr": 0.16245883644346873,
            "logloss": 10.023801768099991,
            "mae": 0.3213244437142309,
            "precision": 0.7051792828685259,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.530105127849506,
            "auditor_fn_violation": 0.06792474607571561,
            "auditor_fp_violation": 0.05748884272083718,
            "ave_precision_score": 0.494547747552665,
            "fpr": 0.21820175438596492,
            "logloss": 7.3628065430755445,
            "mae": 0.49777429794681743,
            "precision": 0.5012531328320802,
            "recall": 0.43859649122807015
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5866643329640802,
            "auditor_fn_violation": 0.0751766671515921,
            "auditor_fp_violation": 0.051368397551582366,
            "ave_precision_score": 0.5575526919362219,
            "fpr": 0.18441273326015367,
            "logloss": 6.605866528333778,
            "mae": 0.4776612321031684,
            "precision": 0.5778894472361809,
            "recall": 0.46184738955823296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7642640687913387,
            "auditor_fn_violation": 0.013157894736842113,
            "auditor_fp_violation": 0.02285559018159434,
            "ave_precision_score": 0.6503000795223999,
            "fpr": 0.1699561403508772,
            "logloss": 10.065000860607352,
            "mae": 0.32028973935858124,
            "precision": 0.6764091858037579,
            "recall": 0.7105263157894737
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7874873899632544,
            "auditor_fn_violation": 0.019811408091201257,
            "auditor_fp_violation": 0.027336056750557492,
            "ave_precision_score": 0.6862852335745131,
            "fpr": 0.16794731064763996,
            "logloss": 10.225902250175029,
            "mae": 0.32577224728231097,
            "precision": 0.7,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7682328541856518,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.653543988743075,
            "fpr": 0.16776315789473684,
            "logloss": 10.139641602864089,
            "mae": 0.3173142550063826,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.791481705357425,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.028571960142780066,
            "ave_precision_score": 0.6891466075397654,
            "fpr": 0.16245883644346873,
            "logloss": 10.289780770391564,
            "mae": 0.32247814495406807,
            "precision": 0.705765407554672,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 18998,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8337576094136777,
            "auditor_fn_violation": 0.01737072945521699,
            "auditor_fp_violation": 0.017543859649122813,
            "ave_precision_score": 0.8340225359194666,
            "fpr": 0.125,
            "logloss": 0.7546264340019236,
            "mae": 0.2669817143403394,
            "precision": 0.7466666666666667,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8382930848492709,
            "auditor_fn_violation": 0.02022359470814102,
            "auditor_fp_violation": 0.025092825647254565,
            "ave_precision_score": 0.838720791395798,
            "fpr": 0.10867178924259056,
            "logloss": 0.8149850929983774,
            "mae": 0.2698696865482657,
            "precision": 0.792016806722689,
            "recall": 0.7570281124497992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 18998,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8419195646404817,
            "auditor_fn_violation": 0.007848568790397047,
            "auditor_fp_violation": 0.016043397968605724,
            "ave_precision_score": 0.8421531981595907,
            "fpr": 0.13157894736842105,
            "logloss": 0.6497863682824875,
            "mae": 0.270070148415936,
            "precision": 0.7468354430379747,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8488829604571065,
            "auditor_fn_violation": 0.010606641715049001,
            "auditor_fp_violation": 0.01957777287550865,
            "ave_precision_score": 0.8492436677136768,
            "fpr": 0.1163556531284303,
            "logloss": 0.6756641019582951,
            "mae": 0.26828541811264,
            "precision": 0.7858585858585858,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7651271225793308,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.02368998153277932,
            "ave_precision_score": 0.6262107090643275,
            "fpr": 0.17105263157894737,
            "logloss": 10.833240462123912,
            "mae": 0.31512807645189594,
            "precision": 0.6756756756756757,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7859050656617902,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.6581304278282264,
            "fpr": 0.16575192096597147,
            "logloss": 11.073647752023852,
            "mae": 0.3223153251488044,
            "precision": 0.7021696252465484,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8018640614544452,
            "auditor_fn_violation": 0.004424438288704221,
            "auditor_fp_violation": 0.003472222222222223,
            "ave_precision_score": 0.8027279835362235,
            "fpr": 0.10416666666666667,
            "logloss": 0.5341134888679387,
            "mae": 0.3158120284870006,
            "precision": 0.7806004618937644,
            "recall": 0.7412280701754386
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8622891621234576,
            "auditor_fn_violation": 0.0017721820321902335,
            "auditor_fp_violation": 0.013071339533227198,
            "ave_precision_score": 0.8631226395207223,
            "fpr": 0.07025246981339188,
            "logloss": 0.4902249841248108,
            "mae": 0.2988771182055811,
            "precision": 0.8552036199095022,
            "recall": 0.7590361445783133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 18998,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8140936434991699,
            "auditor_fn_violation": 0.011537203755001542,
            "auditor_fp_violation": 0.008774334410587883,
            "ave_precision_score": 0.8122147136700845,
            "fpr": 0.15021929824561403,
            "logloss": 0.7814069248127576,
            "mae": 0.28226139921676613,
            "precision": 0.7360308285163777,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8118244402914463,
            "auditor_fn_violation": 0.00853027918479627,
            "auditor_fp_violation": 0.020622310581193543,
            "ave_precision_score": 0.8030303469930256,
            "fpr": 0.13172338090010977,
            "logloss": 1.0798266826915992,
            "mae": 0.27322460966017076,
            "precision": 0.7740112994350282,
            "recall": 0.8253012048192772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7721780580442765,
            "auditor_fn_violation": 0.01393457602339182,
            "auditor_fp_violation": 0.025469375192366896,
            "ave_precision_score": 0.6487608647222401,
            "fpr": 0.15679824561403508,
            "logloss": 9.912871958874996,
            "mae": 0.30532149227167543,
            "precision": 0.6931330472103004,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7873225046113086,
            "auditor_fn_violation": 0.024916350363032812,
            "auditor_fp_violation": 0.026722091839582403,
            "ave_precision_score": 0.6753094924405081,
            "fpr": 0.150384193194292,
            "logloss": 10.354714019175992,
            "mae": 0.3233372259773994,
            "precision": 0.7151767151767152,
            "recall": 0.6907630522088354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 18998,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5454240112972759,
            "auditor_fn_violation": 0.019813788858110193,
            "auditor_fp_violation": 0.02598155201600493,
            "ave_precision_score": 0.5065985051498402,
            "fpr": 0.32127192982456143,
            "logloss": 7.7537614943271524,
            "mae": 0.46024245335495656,
            "precision": 0.5400313971742543,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6012939282518784,
            "auditor_fn_violation": 0.024360890323092594,
            "auditor_fp_violation": 0.01719899107757487,
            "ave_precision_score": 0.5686064101222149,
            "fpr": 0.283205268935236,
            "logloss": 6.906285831259803,
            "mae": 0.41134056591744705,
            "precision": 0.6067073170731707,
            "recall": 0.7991967871485943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.764092853487739,
            "auditor_fn_violation": 0.01307613881194214,
            "auditor_fp_violation": 0.020907875500153897,
            "ave_precision_score": 0.6236817762590182,
            "fpr": 0.2050438596491228,
            "logloss": 11.238631315231942,
            "mae": 0.32894828091914685,
            "precision": 0.6471698113207547,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7830977695834318,
            "auditor_fn_violation": 0.02047267004351104,
            "auditor_fp_violation": 0.02733074103704256,
            "ave_precision_score": 0.651428372180932,
            "fpr": 0.2052689352360044,
            "logloss": 11.332245722843195,
            "mae": 0.33587147159422587,
            "precision": 0.6696113074204947,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7931549248372949,
            "auditor_fn_violation": 0.013311788242536166,
            "auditor_fp_violation": 0.015379732225300095,
            "ave_precision_score": 0.7934629700833145,
            "fpr": 0.14473684210526316,
            "logloss": 1.9058775678207285,
            "mae": 0.2918825185758471,
            "precision": 0.7111597374179431,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7922640100297945,
            "auditor_fn_violation": 0.018028205026472524,
            "auditor_fp_violation": 0.026031049082640742,
            "ave_precision_score": 0.7926324615187823,
            "fpr": 0.141602634467618,
            "logloss": 1.9555160810190666,
            "mae": 0.30092623904648474,
            "precision": 0.7323651452282157,
            "recall": 0.7088353413654619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7642673085075691,
            "auditor_fn_violation": 0.01392255309325947,
            "auditor_fp_violation": 0.01891447368421053,
            "ave_precision_score": 0.6503019522318851,
            "fpr": 0.1875,
            "logloss": 10.089172313733927,
            "mae": 0.32699242668843975,
            "precision": 0.6559356136820925,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.786278249763195,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.022961224527765306,
            "ave_precision_score": 0.6840216508744271,
            "fpr": 0.1800219538968167,
            "logloss": 10.292044894997776,
            "mae": 0.33117552391125704,
            "precision": 0.6864244741873805,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8426095287882407,
            "auditor_fn_violation": 0.0043282548476454305,
            "auditor_fp_violation": 0.015379732225300091,
            "ave_precision_score": 0.8428468339546837,
            "fpr": 0.10964912280701754,
            "logloss": 0.6226611600043909,
            "mae": 0.27030949461447595,
            "precision": 0.7706422018348624,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8499690044541125,
            "auditor_fn_violation": 0.017316246324485654,
            "auditor_fp_violation": 0.01886546726450725,
            "ave_precision_score": 0.8503097549611818,
            "fpr": 0.09549945115257959,
            "logloss": 0.6717610744558543,
            "mae": 0.27153858463931413,
            "precision": 0.8100436681222707,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8316069889260939,
            "auditor_fn_violation": 0.008781548168667282,
            "auditor_fp_violation": 0.004277758541089571,
            "ave_precision_score": 0.8318763112626983,
            "fpr": 0.25548245614035087,
            "logloss": 0.6215592936079721,
            "mae": 0.348131625183956,
            "precision": 0.6387596899224807,
            "recall": 0.9035087719298246
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8667043248202451,
            "auditor_fn_violation": 0.007873425645501874,
            "auditor_fp_violation": 0.013929827265889335,
            "ave_precision_score": 0.867064676191652,
            "fpr": 0.2283205268935236,
            "logloss": 0.5571356532904848,
            "mae": 0.32446077416122415,
            "precision": 0.6819571865443425,
            "recall": 0.8955823293172691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.6733324261643342,
            "auditor_fn_violation": 0.0016230955678670361,
            "auditor_fp_violation": 0.0029432132963989085,
            "ave_precision_score": 0.6722431401483319,
            "fpr": 0.49122807017543857,
            "logloss": 4.960112314560954,
            "mae": 0.4941208519484654,
            "precision": 0.5027746947835738,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7140844822455585,
            "auditor_fn_violation": 0.0010756527757572552,
            "auditor_fp_violation": 0.0005554920623108028,
            "ave_precision_score": 0.710153535966112,
            "fpr": 0.4445664105378705,
            "logloss": 4.597619777276782,
            "mae": 0.44651601060911505,
            "precision": 0.5504994450610433,
            "recall": 0.9959839357429718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.752212389380531,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0023661126500461828,
            "ave_precision_score": 0.504424778761062,
            "fpr": 0.49122807017543857,
            "logloss": 16.966809278715587,
            "mae": 0.4912280894954021,
            "precision": 0.504424778761062,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7741310642625011,
            "auditor_fn_violation": 0.0006524451262789908,
            "auditor_fp_violation": 0.002158179687063958,
            "ave_precision_score": 0.549169838748476,
            "fpr": 0.4489571899012075,
            "logloss": 15.502735401416828,
            "mae": 0.4500548911788533,
            "precision": 0.5485651214128036,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 18998,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8381050078746108,
            "auditor_fn_violation": 0.00894506001846722,
            "auditor_fp_violation": 0.013013619575253927,
            "ave_precision_score": 0.8383430752544948,
            "fpr": 0.11842105263157894,
            "logloss": 0.6525057825222204,
            "mae": 0.27336791752580564,
            "precision": 0.7567567567567568,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8424864567812945,
            "auditor_fn_violation": 0.01717958552100829,
            "auditor_fp_violation": 0.02044689203520066,
            "ave_precision_score": 0.8428300262669801,
            "fpr": 0.10976948408342481,
            "logloss": 0.7202906519208011,
            "mae": 0.2724227287116403,
            "precision": 0.791231732776618,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7251730335747079,
            "auditor_fn_violation": 0.009291320406278858,
            "auditor_fp_violation": 0.011347241458910433,
            "ave_precision_score": 0.7197245408100155,
            "fpr": 0.09320175438596491,
            "logloss": 1.7246199748839273,
            "mae": 0.3060024356673581,
            "precision": 0.7605633802816901,
            "recall": 0.5921052631578947
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7007554561585772,
            "auditor_fn_violation": 0.006581760631990093,
            "auditor_fp_violation": 0.0074047889263056076,
            "ave_precision_score": 0.6971212228454857,
            "fpr": 0.09769484083424808,
            "logloss": 2.046951497895745,
            "mae": 0.3516621940868892,
            "precision": 0.7574931880108992,
            "recall": 0.5582329317269076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7628903153832318,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023536088027085258,
            "ave_precision_score": 0.6478658069825083,
            "fpr": 0.1699561403508772,
            "logloss": 10.158280582028164,
            "mae": 0.31800615999913007,
            "precision": 0.6757322175732218,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7882094225613658,
            "auditor_fn_violation": 0.01941465091981538,
            "auditor_fp_violation": 0.028837745818526862,
            "ave_precision_score": 0.6856389390923614,
            "fpr": 0.16245883644346873,
            "logloss": 10.262938562881237,
            "mae": 0.32130200368516826,
            "precision": 0.7051792828685259,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7935546777698049,
            "auditor_fn_violation": 0.007838950446291166,
            "auditor_fp_violation": 0.009276892890120047,
            "ave_precision_score": 0.7830647354963534,
            "fpr": 0.15570175438596492,
            "logloss": 1.2473713696831519,
            "mae": 0.2849856707054099,
            "precision": 0.7248062015503876,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8044844283449797,
            "auditor_fn_violation": 0.005541375160356023,
            "auditor_fp_violation": 0.026124074069152122,
            "ave_precision_score": 0.7879253297182609,
            "fpr": 0.14928649835345773,
            "logloss": 1.5116871559927203,
            "mae": 0.27808747458978095,
            "precision": 0.7486136783733827,
            "recall": 0.8132530120481928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8173009777705109,
            "auditor_fn_violation": 0.007713911972914741,
            "auditor_fp_violation": 0.015697137580794093,
            "ave_precision_score": 0.8176556057009918,
            "fpr": 0.13815789473684212,
            "logloss": 0.6609225418032941,
            "mae": 0.27862250088789886,
            "precision": 0.7364016736401674,
            "recall": 0.7719298245614035
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8361879164783933,
            "auditor_fn_violation": 0.008867522780474264,
            "auditor_fp_violation": 0.024112076503748917,
            "ave_precision_score": 0.8365241238619872,
            "fpr": 0.13391877058177826,
            "logloss": 0.6960026522737626,
            "mae": 0.279438705512911,
            "precision": 0.7631067961165049,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6003802879933198,
            "auditor_fn_violation": 0.025219298245614034,
            "auditor_fp_violation": 0.06557306094182826,
            "ave_precision_score": 0.6010971365292648,
            "fpr": 0.29714912280701755,
            "logloss": 1.5332970226487406,
            "mae": 0.46103615485664984,
            "precision": 0.5351629502572899,
            "recall": 0.6842105263157895
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.6307606712879018,
            "auditor_fn_violation": 0.03509978442860355,
            "auditor_fp_violation": 0.06356264435484515,
            "ave_precision_score": 0.6317426435230196,
            "fpr": 0.27771679473106475,
            "logloss": 1.4828342482149732,
            "mae": 0.4577998223373829,
            "precision": 0.56,
            "recall": 0.6465863453815262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8451868542398255,
            "auditor_fn_violation": 0.01970798707294552,
            "auditor_fp_violation": 0.024430594028931978,
            "ave_precision_score": 0.8454663293110712,
            "fpr": 0.12719298245614036,
            "logloss": 0.6450495862010129,
            "mae": 0.2631242945001419,
            "precision": 0.7531914893617021,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8461279373967089,
            "auditor_fn_violation": 0.02098845436631267,
            "auditor_fp_violation": 0.02772676169390527,
            "ave_precision_score": 0.8465800583071957,
            "fpr": 0.12184412733260154,
            "logloss": 0.7041440084395931,
            "mae": 0.27018040539770116,
            "precision": 0.7771084337349398,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5310145268704934,
            "auditor_fn_violation": 0.06891062634656818,
            "auditor_fp_violation": 0.05294898430286243,
            "ave_precision_score": 0.4962264745226791,
            "fpr": 0.2324561403508772,
            "logloss": 7.243179874240717,
            "mae": 0.49761046133703707,
            "precision": 0.5035128805620609,
            "recall": 0.47149122807017546
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.588493920884257,
            "auditor_fn_violation": 0.06441132256798876,
            "auditor_fp_violation": 0.04570184694466077,
            "ave_precision_score": 0.5593897772843193,
            "fpr": 0.19319429198682767,
            "logloss": 6.532938978927925,
            "mae": 0.47419887009869205,
            "precision": 0.5868544600938967,
            "recall": 0.5020080321285141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 18998,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.854351898131245,
            "auditor_fn_violation": 0.017495767928593416,
            "auditor_fp_violation": 0.024084333641120344,
            "ave_precision_score": 0.8547051667029025,
            "fpr": 0.14035087719298245,
            "logloss": 0.565777856776254,
            "mae": 0.2646631990642961,
            "precision": 0.7387755102040816,
            "recall": 0.793859649122807
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8609611399401802,
            "auditor_fn_violation": 0.02160122377545308,
            "auditor_fp_violation": 0.02589815624476735,
            "ave_precision_score": 0.8613355386174711,
            "fpr": 0.12294182217343579,
            "logloss": 0.5938187259007706,
            "mae": 0.26582920875943333,
            "precision": 0.7803921568627451,
            "recall": 0.7991967871485943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8553309692158932,
            "auditor_fn_violation": 0.0067520775623268765,
            "auditor_fp_violation": 0.004775507848568797,
            "ave_precision_score": 0.8556497761491709,
            "fpr": 0.13486842105263158,
            "logloss": 0.48359489648891024,
            "mae": 0.2833155208405642,
            "precision": 0.7453416149068323,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8795587845857485,
            "auditor_fn_violation": 0.012286247073915867,
            "auditor_fp_violation": 0.0231685373548478,
            "ave_precision_score": 0.8797732641298152,
            "fpr": 0.11306256860592755,
            "logloss": 0.48060510237089277,
            "mae": 0.27727214933416994,
            "precision": 0.7919191919191919,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7675854736017322,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6529882971020602,
            "fpr": 0.16776315789473684,
            "logloss": 10.131835089900536,
            "mae": 0.31721894006784024,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7918595885849026,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.02726429461810586,
            "ave_precision_score": 0.6894331328456023,
            "fpr": 0.16465422612513722,
            "logloss": 10.283221489005829,
            "mae": 0.32214196050451693,
            "precision": 0.7029702970297029,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7642157252017322,
            "auditor_fn_violation": 0.01592797783933518,
            "auditor_fp_violation": 0.021078601108033237,
            "ave_precision_score": 0.6502575978724733,
            "fpr": 0.1699561403508772,
            "logloss": 10.081966828487857,
            "mae": 0.3183563935014893,
            "precision": 0.6764091858037579,
            "recall": 0.7105263157894737
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7874103092721685,
            "auditor_fn_violation": 0.020230207327664118,
            "auditor_fp_violation": 0.02606560122048783,
            "ave_precision_score": 0.6862131855619098,
            "fpr": 0.1690450054884742,
            "logloss": 10.243496507145938,
            "mae": 0.3253970297603458,
            "precision": 0.6980392156862745,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7705912840928185,
            "auditor_fn_violation": 0.016098703447214528,
            "auditor_fp_violation": 0.022131809787626962,
            "ave_precision_score": 0.6672119050683247,
            "fpr": 0.1699561403508772,
            "logloss": 9.44014932943817,
            "mae": 0.31379030935490326,
            "precision": 0.6770833333333334,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7926209606187312,
            "auditor_fn_violation": 0.02022579891464872,
            "auditor_fp_violation": 0.025265586336489988,
            "ave_precision_score": 0.7004128527702338,
            "fpr": 0.16575192096597147,
            "logloss": 9.554544682747213,
            "mae": 0.3207830828626941,
            "precision": 0.7021696252465484,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8100279962561958,
            "auditor_fn_violation": 0.0095654432132964,
            "auditor_fp_violation": 0.0016110726377347,
            "ave_precision_score": 0.8115481467687704,
            "fpr": 0.12938596491228072,
            "logloss": 0.5567501237828331,
            "mae": 0.3262570061078964,
            "precision": 0.7484008528784648,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8738920673921537,
            "auditor_fn_violation": 0.003094705936809807,
            "auditor_fp_violation": 0.01075900415423011,
            "ave_precision_score": 0.8741132188289912,
            "fpr": 0.11086717892425905,
            "logloss": 0.49214658929159094,
            "mae": 0.3053151373996017,
            "precision": 0.7967806841046278,
            "recall": 0.7951807228915663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7677989823878536,
            "auditor_fn_violation": 0.014571791320406282,
            "auditor_fp_violation": 0.020895852570021557,
            "ave_precision_score": 0.640754454668539,
            "fpr": 0.19188596491228072,
            "logloss": 10.689387427359682,
            "mae": 0.33329359696780814,
            "precision": 0.651394422310757,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7860586165603543,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.01828605449137924,
            "ave_precision_score": 0.6699104648864296,
            "fpr": 0.18551042810098792,
            "logloss": 10.930700106279168,
            "mae": 0.337946306859269,
            "precision": 0.6799242424242424,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 18998,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.834865577796821,
            "auditor_fn_violation": 0.0145862188365651,
            "auditor_fp_violation": 0.01794783010156972,
            "ave_precision_score": 0.8351586453732901,
            "fpr": 0.13815789473684212,
            "logloss": 0.6674063690270434,
            "mae": 0.2656585630080134,
            "precision": 0.7375,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8419426834496919,
            "auditor_fn_violation": 0.012969551091302649,
            "auditor_fp_violation": 0.019160489364586183,
            "ave_precision_score": 0.842444335334123,
            "fpr": 0.12733260153677278,
            "logloss": 0.7053161491024134,
            "mae": 0.26258818777054793,
            "precision": 0.7738791423001949,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7466091403149442,
            "auditor_fn_violation": 0.011279913050169286,
            "auditor_fp_violation": 0.008822426131117266,
            "ave_precision_score": 0.7469694487989897,
            "fpr": 0.049342105263157895,
            "logloss": 1.1982401225894208,
            "mae": 0.3820070767492552,
            "precision": 0.8008849557522124,
            "recall": 0.3969298245614035
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7677779825816435,
            "auditor_fn_violation": 0.0037736015411812098,
            "auditor_fp_violation": 0.004382805793064591,
            "ave_precision_score": 0.7681645088753516,
            "fpr": 0.04061470911086718,
            "logloss": 1.3426543314210664,
            "mae": 0.4027979952248794,
            "precision": 0.8438818565400844,
            "recall": 0.40160642570281124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.8349734549109475,
            "auditor_fn_violation": 0.004126269621421977,
            "auditor_fp_violation": 0.016505078485687906,
            "ave_precision_score": 0.8352496219312573,
            "fpr": 0.3048245614035088,
            "logloss": 0.646003721022188,
            "mae": 0.36469890966423246,
            "precision": 0.6017191977077364,
            "recall": 0.9210526315789473
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8556627720969169,
            "auditor_fn_violation": 0.005653789692248687,
            "auditor_fp_violation": 0.01469794786879758,
            "ave_precision_score": 0.8560037521136483,
            "fpr": 0.2678375411635565,
            "logloss": 0.6007054355851642,
            "mae": 0.3454062074328784,
            "precision": 0.6468885672937771,
            "recall": 0.8975903614457831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.8151095962802587,
            "auditor_fn_violation": 0.0020198522622345335,
            "auditor_fp_violation": 0.029085872576177296,
            "ave_precision_score": 0.81540626443627,
            "fpr": 0.37609649122807015,
            "logloss": 0.8671802946120433,
            "mae": 0.3830181297515313,
            "precision": 0.5636132315521628,
            "recall": 0.9714912280701754
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.8681592204046508,
            "auditor_fn_violation": 0.007181304802084297,
            "auditor_fp_violation": 0.0278490231047488,
            "ave_precision_score": 0.8683543930690845,
            "fpr": 0.3413830954994512,
            "logloss": 0.7665245998653546,
            "mae": 0.3444913460821281,
            "precision": 0.606826801517067,
            "recall": 0.963855421686747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 18998,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8319877335179836,
            "auditor_fn_violation": 0.004272949369036629,
            "auditor_fp_violation": 0.01141937903970454,
            "ave_precision_score": 0.8322539154171379,
            "fpr": 0.24013157894736842,
            "logloss": 0.5996517381167213,
            "mae": 0.3440721781327994,
            "precision": 0.6501597444089456,
            "recall": 0.8925438596491229
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8712860454353852,
            "auditor_fn_violation": 0.008190831382610576,
            "auditor_fp_violation": 0.014607580739043646,
            "ave_precision_score": 0.8715536453324605,
            "fpr": 0.20965971459934138,
            "logloss": 0.5409442976542841,
            "mae": 0.3208279978692466,
            "precision": 0.69826224328594,
            "recall": 0.8875502008032129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 18998,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.5317343820177681,
            "auditor_fn_violation": 0.06567405355493999,
            "auditor_fp_violation": 0.038571964450600196,
            "ave_precision_score": 0.4963879614947454,
            "fpr": 0.27521929824561403,
            "logloss": 7.419565945460791,
            "mae": 0.5083778992499793,
            "precision": 0.4949698189134809,
            "recall": 0.5394736842105263
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5895895847258075,
            "auditor_fn_violation": 0.06986893788105221,
            "auditor_fp_violation": 0.03471958282280335,
            "ave_precision_score": 0.5604991072971385,
            "fpr": 0.2414928649835346,
            "logloss": 6.640137486596382,
            "mae": 0.4736216239293534,
            "precision": 0.5677799607072691,
            "recall": 0.5803212851405622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.5433567897242014,
            "auditor_fn_violation": 0.06684749153585719,
            "auditor_fp_violation": 0.060710987996306566,
            "ave_precision_score": 0.5076383287969797,
            "fpr": 0.21052631578947367,
            "logloss": 6.951925851254592,
            "mae": 0.47763093341112356,
            "precision": 0.5235732009925558,
            "recall": 0.46271929824561403
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6029864181584269,
            "auditor_fn_violation": 0.06726576999545936,
            "auditor_fp_violation": 0.05250330238702115,
            "ave_precision_score": 0.57296320495511,
            "fpr": 0.17014270032930845,
            "logloss": 6.158602149704328,
            "mae": 0.45289687379402443,
            "precision": 0.6085858585858586,
            "recall": 0.4839357429718876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 18998,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8386488929137857,
            "auditor_fn_violation": 0.016622903200984925,
            "auditor_fp_violation": 0.024086738227146822,
            "ave_precision_score": 0.8389342501572972,
            "fpr": 0.13267543859649122,
            "logloss": 0.6989606381365473,
            "mae": 0.2644978127399485,
            "precision": 0.7425531914893617,
            "recall": 0.7653508771929824
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8390273692614675,
            "auditor_fn_violation": 0.019815816504216655,
            "auditor_fp_violation": 0.028056335931831298,
            "ave_precision_score": 0.839500838938716,
            "fpr": 0.12184412733260154,
            "logloss": 0.7624938109859046,
            "mae": 0.27006708998828804,
            "precision": 0.7753036437246964,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7688602724258712,
            "auditor_fn_violation": 0.014571791320406282,
            "auditor_fp_violation": 0.020895852570021557,
            "ave_precision_score": 0.6436735373215207,
            "fpr": 0.19188596491228072,
            "logloss": 10.624980760599875,
            "mae": 0.3332881205923276,
            "precision": 0.651394422310757,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7883013104634117,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.01828605449137924,
            "ave_precision_score": 0.6738967506992533,
            "fpr": 0.18551042810098792,
            "logloss": 10.867198047084607,
            "mae": 0.3379583604055519,
            "precision": 0.6799242424242424,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8527226117325778,
            "auditor_fn_violation": 0.011736784395198525,
            "auditor_fp_violation": 0.01423034010464759,
            "ave_precision_score": 0.8529331968905198,
            "fpr": 0.13048245614035087,
            "logloss": 0.6726033670395253,
            "mae": 0.26811505233603095,
            "precision": 0.75,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8586976438734462,
            "auditor_fn_violation": 0.016394888004267347,
            "auditor_fp_violation": 0.023492795879258885,
            "ave_precision_score": 0.8590166829069816,
            "fpr": 0.11745334796926454,
            "logloss": 0.8440110455922971,
            "mae": 0.2674577808614457,
            "precision": 0.7864271457085829,
            "recall": 0.7911646586345381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 18998,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7293007954432855,
            "auditor_fn_violation": 0.0022122191443521115,
            "auditor_fp_violation": 0.007747576177285322,
            "ave_precision_score": 0.5789545520895868,
            "fpr": 0.2565789473684211,
            "logloss": 12.646753584689883,
            "mae": 0.39091059974618103,
            "precision": 0.5858407079646017,
            "recall": 0.7258771929824561
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7492785246559267,
            "auditor_fn_violation": 0.012608061224039967,
            "auditor_fp_violation": 0.004202071533556771,
            "ave_precision_score": 0.6065948243087824,
            "fpr": 0.2491767288693743,
            "logloss": 12.95362865109593,
            "mae": 0.3944984874445529,
            "precision": 0.6184873949579832,
            "recall": 0.7389558232931727
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7637796245053531,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6499109366859397,
            "fpr": 0.16776315789473684,
            "logloss": 10.025572502221756,
            "mae": 0.31549835270433957,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7878413201502658,
            "auditor_fn_violation": 0.01941465091981538,
            "auditor_fp_violation": 0.027944705948017644,
            "ave_precision_score": 0.6866309436080817,
            "fpr": 0.16136114160263446,
            "logloss": 10.148428633597002,
            "mae": 0.32126384960849247,
            "precision": 0.7065868263473054,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7677342274405068,
            "auditor_fn_violation": 0.014571791320406282,
            "auditor_fp_violation": 0.020895852570021557,
            "ave_precision_score": 0.6413081422151917,
            "fpr": 0.19188596491228072,
            "logloss": 10.66939494373269,
            "mae": 0.3332954247113353,
            "precision": 0.651394422310757,
            "recall": 0.7171052631578947
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7860725048211494,
            "auditor_fn_violation": 0.019465347669492473,
            "auditor_fp_violation": 0.01828605449137924,
            "ave_precision_score": 0.6699243470837617,
            "fpr": 0.18551042810098792,
            "logloss": 10.930152584396463,
            "mae": 0.3379732616338835,
            "precision": 0.6799242424242424,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 18998,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.8357822629064902,
            "auditor_fn_violation": 0.0016230955678670361,
            "auditor_fp_violation": 0.004770698676515852,
            "ave_precision_score": 0.8360043134439894,
            "fpr": 0.4824561403508772,
            "logloss": 3.4538163706256504,
            "mae": 0.48414669872687455,
            "precision": 0.5072788353863382,
            "recall": 0.993421052631579
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.8749160720306891,
            "auditor_fn_violation": 0.0008927036356182139,
            "auditor_fp_violation": 0.0002976799568364119,
            "ave_precision_score": 0.8752878426692595,
            "fpr": 0.43907793633369924,
            "logloss": 3.074593728671722,
            "mae": 0.43858955315992854,
            "precision": 0.553072625698324,
            "recall": 0.9939759036144579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 18998,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7665144713425588,
            "auditor_fn_violation": 0.015122441520467845,
            "auditor_fp_violation": 0.023076812096029558,
            "ave_precision_score": 0.6521391669806778,
            "fpr": 0.16776315789473684,
            "logloss": 10.133329209686854,
            "mae": 0.3169981518703137,
            "precision": 0.6785714285714286,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7900702443993177,
            "auditor_fn_violation": 0.019480777115046363,
            "auditor_fp_violation": 0.028571960142780066,
            "ave_precision_score": 0.6879838791611335,
            "fpr": 0.16245883644346873,
            "logloss": 10.283443085853248,
            "mae": 0.3222467362692602,
            "precision": 0.705765407554672,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 18998,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8435862670163543,
            "auditor_fn_violation": 0.007858187134502925,
            "auditor_fp_violation": 0.01322762773160973,
            "ave_precision_score": 0.8438209841026787,
            "fpr": 0.14364035087719298,
            "logloss": 0.5886914359487233,
            "mae": 0.2742817091661971,
            "precision": 0.733739837398374,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8528929296750506,
            "auditor_fn_violation": 0.008137930426425794,
            "auditor_fp_violation": 0.027059639647780832,
            "ave_precision_score": 0.8531993090281145,
            "fpr": 0.13611416026344675,
            "logloss": 0.613729316748505,
            "mae": 0.27251384129961437,
            "precision": 0.7624521072796935,
            "recall": 0.7991967871485943
        }
    }
]