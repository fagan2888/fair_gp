[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.5288037141905396,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4810040528536531,
            "fpr": 0.47368421052631576,
            "logloss": 0.6949862816142569,
            "mae": 0.5008185941137766,
            "precision": 0.5263157894736842,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.557868805422769,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4746420194007541,
            "fpr": 0.4796926454445664,
            "logloss": 0.6950072428055801,
            "mae": 0.5008145509907234,
            "precision": 0.5203073545554336,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5405410102228526,
            "auditor_fn_violation": 0.012774122807017554,
            "auditor_fp_violation": 0.004314896036387264,
            "ave_precision_score": 0.5543963532335665,
            "fpr": 0.05701754385964912,
            "logloss": 0.7320293807569012,
            "mae": 0.5006780979599346,
            "precision": 0.5806451612903226,
            "recall": 0.15
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.543733214777314,
            "auditor_fn_violation": 0.0035848768219650198,
            "auditor_fp_violation": 0.006357587281811172,
            "ave_precision_score": 0.554792728420767,
            "fpr": 0.05598243688254665,
            "logloss": 0.7267981632262782,
            "mae": 0.4974261255675168,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5474310737913478,
            "auditor_fn_violation": 0.008931834795321655,
            "auditor_fp_violation": 0.017488019818063683,
            "ave_precision_score": 0.5466980673930737,
            "fpr": 0.17324561403508773,
            "logloss": 10.45009304029821,
            "mae": 0.5046690863541368,
            "precision": 0.5393586005830904,
            "recall": 0.3854166666666667
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5550727532793458,
            "auditor_fn_violation": 0.003939196042740628,
            "auditor_fp_violation": 0.019251105858475236,
            "ave_precision_score": 0.5481170771721231,
            "fpr": 0.1778265642151482,
            "logloss": 9.923456590416828,
            "mae": 0.4934308800426013,
            "precision": 0.5410764872521246,
            "recall": 0.4029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5136280858226359,
            "auditor_fn_violation": 0.0011924342105263156,
            "auditor_fp_violation": 0.0024366471734892895,
            "ave_precision_score": 0.5141433111444288,
            "fpr": 0.4682017543859649,
            "logloss": 0.6919080098322954,
            "mae": 0.49920026696564856,
            "precision": 0.5281767955801105,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5174548402924585,
            "auditor_fn_violation": 0.0010235888600184338,
            "auditor_fp_violation": 0.0015146681671008016,
            "ave_precision_score": 0.5188828682408375,
            "fpr": 0.47530186608122943,
            "logloss": 0.6923783683575945,
            "mae": 0.4994476549122912,
            "precision": 0.5204872646733112,
            "recall": 0.9915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 10197,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.54352515852583,
            "auditor_fn_violation": 0.012129934210526324,
            "auditor_fp_violation": 0.004314896036387264,
            "ave_precision_score": 0.5528253729423427,
            "fpr": 0.05701754385964912,
            "logloss": 0.7338708401572711,
            "mae": 0.5008064213519295,
            "precision": 0.5772357723577236,
            "recall": 0.14791666666666667
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5435929699660068,
            "auditor_fn_violation": 0.0035848768219650198,
            "auditor_fp_violation": 0.006357587281811172,
            "ave_precision_score": 0.5555503071521619,
            "fpr": 0.05598243688254665,
            "logloss": 0.7286855449527478,
            "mae": 0.4976012225699346,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5494546011763585,
            "auditor_fn_violation": 0.0027229532163742694,
            "auditor_fp_violation": 0.00528955490578298,
            "ave_precision_score": 0.5648924418421442,
            "fpr": 0.4517543859649123,
            "logloss": 0.6916360817614122,
            "mae": 0.49904131225980164,
            "precision": 0.5339366515837104,
            "recall": 0.9833333333333333
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5403094513898967,
            "auditor_fn_violation": 0.0019638084916190767,
            "auditor_fp_violation": 0.004322958400630989,
            "ave_precision_score": 0.5568096564835195,
            "fpr": 0.45993413830954993,
            "logloss": 0.6914749845929288,
            "mae": 0.498955610031354,
            "precision": 0.5286839145106862,
            "recall": 0.9915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5401304229812876,
            "auditor_fn_violation": 0.013521107456140363,
            "auditor_fp_violation": 0.004314896036387264,
            "ave_precision_score": 0.5551321185904856,
            "fpr": 0.05701754385964912,
            "logloss": 0.7322813088340946,
            "mae": 0.500505879570387,
            "precision": 0.5702479338842975,
            "recall": 0.14375
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.5368084828030601,
            "auditor_fn_violation": 0.0035848768219650198,
            "auditor_fp_violation": 0.006357587281811172,
            "ave_precision_score": 0.5524993750978963,
            "fpr": 0.05598243688254665,
            "logloss": 0.7273090594448024,
            "mae": 0.4974706098519094,
            "precision": 0.5277777777777778,
            "recall": 0.12025316455696203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5356383589186022,
            "auditor_fn_violation": 0.009617141812865505,
            "auditor_fp_violation": 0.007309941520467837,
            "ave_precision_score": 0.5367024990306748,
            "fpr": 0.08333333333333333,
            "logloss": 0.7057761860234045,
            "mae": 0.4955613818550646,
            "precision": 0.5706214689265536,
            "recall": 0.21041666666666667
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5423108733820405,
            "auditor_fn_violation": 0.0030939246990602473,
            "auditor_fp_violation": 0.006704227757864092,
            "ave_precision_score": 0.5457790502435167,
            "fpr": 0.08232711306256861,
            "logloss": 0.7061989397068257,
            "mae": 0.49367842287986524,
            "precision": 0.5508982035928144,
            "recall": 0.1940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5926787522625314,
            "auditor_fn_violation": 0.011307565789473695,
            "auditor_fp_violation": 0.015452404158544512,
            "ave_precision_score": 0.5943026554558215,
            "fpr": 0.17324561403508773,
            "logloss": 0.6858906886242787,
            "mae": 0.49062129502233703,
            "precision": 0.5524079320113314,
            "recall": 0.40625
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5358149269976509,
            "auditor_fn_violation": 0.00427962039211329,
            "auditor_fp_violation": 0.00502628690276735,
            "ave_precision_score": 0.537466571752481,
            "fpr": 0.19099890230515917,
            "logloss": 0.6910793951846286,
            "mae": 0.4950626212142563,
            "precision": 0.4695121951219512,
            "recall": 0.32489451476793246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.5964780559352927,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6099948023467759,
            "fpr": 0.47368421052631576,
            "logloss": 0.692975649732565,
            "mae": 0.4977802988468555,
            "precision": 0.5263157894736842,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5141478177378863,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5979140353126798,
            "fpr": 0.4796926454445664,
            "logloss": 0.6954601359877155,
            "mae": 0.4993556516754117,
            "precision": 0.5203073545554336,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5218742560828386,
            "auditor_fn_violation": 0.01059484649122807,
            "auditor_fp_violation": 0.002314814814814825,
            "ave_precision_score": 0.6075534609651932,
            "fpr": 0.2719298245614035,
            "logloss": 0.6908207135533562,
            "mae": 0.4974897015970527,
            "precision": 0.5424354243542435,
            "recall": 0.6125
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5251160863704689,
            "auditor_fn_violation": 0.004904889605246718,
            "auditor_fp_violation": 0.007204093371882442,
            "ave_precision_score": 0.5945580676424489,
            "fpr": 0.2864983534577388,
            "logloss": 0.6925254171473635,
            "mae": 0.4982837666271808,
            "precision": 0.5297297297297298,
            "recall": 0.620253164556962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 10197,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6061555137003225,
            "auditor_fn_violation": 0.007867324561403516,
            "auditor_fp_violation": 0.018477907732293707,
            "ave_precision_score": 0.6075872035535177,
            "fpr": 0.31798245614035087,
            "logloss": 0.8864006478411927,
            "mae": 0.45795914393302317,
            "precision": 0.5722713864306784,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.6876049590395701,
            "auditor_fn_violation": 0.010245151847786314,
            "auditor_fp_violation": 0.027949772297397448,
            "ave_precision_score": 0.6879927424065835,
            "fpr": 0.2678375411635565,
            "logloss": 0.816439667979212,
            "mae": 0.43405873020221486,
            "precision": 0.6139240506329114,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.5052881122844275,
            "auditor_fn_violation": 0.007497258771929824,
            "auditor_fp_violation": 0.011355791098115667,
            "ave_precision_score": 0.5068308290012499,
            "fpr": 0.36293859649122806,
            "logloss": 0.6900821912769408,
            "mae": 0.4969534576265958,
            "precision": 0.5357643758765779,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5394138330846329,
            "auditor_fn_violation": 0.00230654865289222,
            "auditor_fp_violation": 0.0047951932520654125,
            "ave_precision_score": 0.5404488725889472,
            "fpr": 0.3787047200878156,
            "logloss": 0.6910171707064795,
            "mae": 0.4973174386568834,
            "precision": 0.5208333333333334,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6765954546352609,
            "auditor_fn_violation": 0.01651589912280703,
            "auditor_fp_violation": 0.00019797758284601465,
            "ave_precision_score": 0.538687027956072,
            "fpr": 0.26206140350877194,
            "logloss": 0.6908973945170844,
            "mae": 0.49793098517285106,
            "precision": 0.5482041587901701,
            "recall": 0.6041666666666666
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6714160102367286,
            "auditor_fn_violation": 0.003422769988930428,
            "auditor_fp_violation": 0.005968244718128544,
            "ave_precision_score": 0.5266756331110104,
            "fpr": 0.2854006586169045,
            "logloss": 0.6928144489238368,
            "mae": 0.49886778383040403,
            "precision": 0.5289855072463768,
            "recall": 0.6160337552742616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6068440920043672,
            "auditor_fn_violation": 0.010896381578947368,
            "auditor_fp_violation": 0.017498172514619898,
            "ave_precision_score": 0.6083894983369632,
            "fpr": 0.375,
            "logloss": 0.8868727479242373,
            "mae": 0.48219937045257866,
            "precision": 0.5334242837653479,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.654171076264916,
            "auditor_fn_violation": 0.010775472772999487,
            "auditor_fp_violation": 0.009256305465616019,
            "ave_precision_score": 0.6546437704783867,
            "fpr": 0.34796926454445665,
            "logloss": 0.8464738522148865,
            "mae": 0.4736042142601359,
            "precision": 0.5645604395604396,
            "recall": 0.8670886075949367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.504867926118538,
            "auditor_fn_violation": 0.006069535818713453,
            "auditor_fp_violation": 0.012228923001949327,
            "ave_precision_score": 0.6407689808813184,
            "fpr": 0.40131578947368424,
            "logloss": 0.6957658527035713,
            "mae": 0.498409495345856,
            "precision": 0.5277419354838709,
            "recall": 0.8520833333333333
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5369689827377494,
            "auditor_fn_violation": 0.004008670399755451,
            "auditor_fp_violation": 0.007068451446470418,
            "ave_precision_score": 0.6315587177652732,
            "fpr": 0.40065861690450055,
            "logloss": 0.6884839281074567,
            "mae": 0.49489785490391935,
            "precision": 0.5368020304568528,
            "recall": 0.8924050632911392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6000610137742914,
            "auditor_fn_violation": 0.01302083333333334,
            "auditor_fp_violation": 0.013482781026640673,
            "ave_precision_score": 0.601633101830791,
            "fpr": 0.16557017543859648,
            "logloss": 0.6848374960763327,
            "mae": 0.49009324022029577,
            "precision": 0.5817174515235457,
            "recall": 0.4375
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.5360830762007454,
            "auditor_fn_violation": 0.0057640558203300605,
            "auditor_fp_violation": 0.00046972296392678746,
            "ave_precision_score": 0.5376617503745438,
            "fpr": 0.18990120746432493,
            "logloss": 0.6901943197900379,
            "mae": 0.4946575168393446,
            "precision": 0.4851190476190476,
            "recall": 0.3438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6710189213054659,
            "auditor_fn_violation": 0.00020559210526315818,
            "auditor_fp_violation": 0.002398574561403509,
            "ave_precision_score": 0.6727001284873253,
            "fpr": 0.46381578947368424,
            "logloss": 0.69338689113758,
            "mae": 0.49786725708920704,
            "precision": 0.5289532293986637,
            "recall": 0.9895833333333334
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6683279416041128,
            "auditor_fn_violation": 0.002325075148096171,
            "auditor_fp_violation": 0.0009067913902543991,
            "ave_precision_score": 0.670848030072142,
            "fpr": 0.47091108671789245,
            "logloss": 0.695417970461523,
            "mae": 0.4992555557830928,
            "precision": 0.5206703910614525,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8212862598190867,
            "auditor_fn_violation": 0.009639985380116962,
            "auditor_fp_violation": 0.016290001624431453,
            "ave_precision_score": 0.8216403640049175,
            "fpr": 0.1524122807017544,
            "logloss": 0.7979804303548393,
            "mae": 0.2741257230107007,
            "precision": 0.7392120075046904,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8589798756047153,
            "auditor_fn_violation": 0.013772133372238973,
            "auditor_fp_violation": 0.019293807946104944,
            "ave_precision_score": 0.8591810577859836,
            "fpr": 0.1394072447859495,
            "logloss": 0.7177230040607177,
            "mae": 0.26028252621674786,
            "precision": 0.7576335877862596,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7386686206520596,
            "auditor_fn_violation": 0.020906432748538005,
            "auditor_fp_violation": 0.025965521442495133,
            "ave_precision_score": 0.7398560206749427,
            "fpr": 0.17214912280701755,
            "logloss": 1.1614400711441528,
            "mae": 0.3225285522559887,
            "precision": 0.6915520628683693,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7547142848579982,
            "auditor_fn_violation": 0.005154997290500079,
            "auditor_fp_violation": 0.021391234014975877,
            "ave_precision_score": 0.7552978733816776,
            "fpr": 0.1778265642151482,
            "logloss": 1.0428532737081346,
            "mae": 0.3105025171413993,
            "precision": 0.6896551724137931,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5594908989132434,
            "auditor_fn_violation": 0.0008908991228070176,
            "auditor_fp_violation": 0.0026879264132553746,
            "ave_precision_score": 0.5610287958848008,
            "fpr": 0.46600877192982454,
            "logloss": 1.3740271864597888,
            "mae": 0.4688679890270305,
            "precision": 0.5293466223698782,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6143451739723136,
            "auditor_fn_violation": 0.0009448512554016313,
            "auditor_fp_violation": 0.0002938908383926921,
            "ave_precision_score": 0.6149395171289709,
            "fpr": 0.4774972557628979,
            "logloss": 1.3500919527957407,
            "mae": 0.47378866707560585,
            "precision": 0.5198675496688742,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.793494925958458,
            "auditor_fn_violation": 0.007641173245614034,
            "auditor_fp_violation": 0.023584714100064987,
            "ave_precision_score": 0.7937566018570024,
            "fpr": 0.2412280701754386,
            "logloss": 1.4220356985994793,
            "mae": 0.3077856110763549,
            "precision": 0.6589147286821705,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8143184594643346,
            "auditor_fn_violation": 0.010261362531089778,
            "auditor_fp_violation": 0.023699658634487718,
            "ave_precision_score": 0.8145057491169325,
            "fpr": 0.2305159165751921,
            "logloss": 1.2960960286008631,
            "mae": 0.2939495007595962,
            "precision": 0.6713615023474179,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.565924709415554,
            "auditor_fn_violation": 0.09107044956140353,
            "auditor_fp_violation": 0.0877421418128655,
            "ave_precision_score": 0.5678169704870355,
            "fpr": 0.16776315789473684,
            "logloss": 1.9141636975440675,
            "mae": 0.49382293142642514,
            "precision": 0.5677966101694916,
            "recall": 0.41875
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5961989315168552,
            "auditor_fn_violation": 0.09324848198529923,
            "auditor_fp_violation": 0.08081998055799068,
            "ave_precision_score": 0.5981150314162653,
            "fpr": 0.16355653128430298,
            "logloss": 1.5819733589948832,
            "mae": 0.47146281290333736,
            "precision": 0.595108695652174,
            "recall": 0.4620253164556962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.548932764272637,
            "auditor_fn_violation": 0.0008315058479532163,
            "auditor_fp_violation": 0.003878330084470449,
            "ave_precision_score": 0.5505327972418619,
            "fpr": 0.4649122807017544,
            "logloss": 1.1834272797290837,
            "mae": 0.4702876660192018,
            "precision": 0.5288888888888889,
            "recall": 0.9916666666666667
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5956774595710372,
            "auditor_fn_violation": 0.0009448512554016313,
            "auditor_fp_violation": 0.0002938908383926921,
            "ave_precision_score": 0.5973437997648345,
            "fpr": 0.4774972557628979,
            "logloss": 1.201447865422674,
            "mae": 0.4745559598258916,
            "precision": 0.5198675496688742,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.5663164310263927,
            "auditor_fn_violation": 0.013354349415204681,
            "auditor_fp_violation": 0.03463338612735545,
            "ave_precision_score": 0.5678420812422268,
            "fpr": 0.37609649122807015,
            "logloss": 0.9619396249697645,
            "mae": 0.47175727952621527,
            "precision": 0.5669191919191919,
            "recall": 0.9354166666666667
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6123164760360135,
            "auditor_fn_violation": 0.015182462819639937,
            "auditor_fp_violation": 0.0375954203266961,
            "ave_precision_score": 0.6128946757405982,
            "fpr": 0.3809001097694841,
            "logloss": 0.8783411748948288,
            "mae": 0.4657360030725112,
            "precision": 0.562421185372005,
            "recall": 0.9409282700421941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6627764018110953,
            "auditor_fn_violation": 0.0059553179824561415,
            "auditor_fp_violation": 0.02085363872644575,
            "ave_precision_score": 0.659984301702369,
            "fpr": 0.2719298245614035,
            "logloss": 2.589502401334336,
            "mae": 0.33540516149441135,
            "precision": 0.6336779911373708,
            "recall": 0.89375
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.69836878506365,
            "auditor_fn_violation": 0.0126443329766983,
            "auditor_fp_violation": 0.025503193864965967,
            "ave_precision_score": 0.6968941057154131,
            "fpr": 0.2689352360043908,
            "logloss": 2.2359615704625737,
            "mae": 0.31985135588326785,
            "precision": 0.6391752577319587,
            "recall": 0.9156118143459916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5479291653495886,
            "auditor_fn_violation": 0.030927905701754386,
            "auditor_fp_violation": 0.025645711500974673,
            "ave_precision_score": 0.5500032344166317,
            "fpr": 0.12171052631578948,
            "logloss": 0.7980497189609508,
            "mae": 0.4927979730325481,
            "precision": 0.5256410256410257,
            "recall": 0.25625
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5762566109317334,
            "auditor_fn_violation": 0.02662952104378274,
            "auditor_fp_violation": 0.017997673992167937,
            "ave_precision_score": 0.5777135285261761,
            "fpr": 0.10647639956092206,
            "logloss": 0.7306975714794806,
            "mae": 0.48630705914505107,
            "precision": 0.5818965517241379,
            "recall": 0.2848101265822785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8026198661197479,
            "auditor_fn_violation": 0.013128198099415208,
            "auditor_fp_violation": 0.01643721572449643,
            "ave_precision_score": 0.8030086777252763,
            "fpr": 0.15350877192982457,
            "logloss": 1.0969868587970357,
            "mae": 0.279576530513303,
            "precision": 0.7302504816955684,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8411027151259336,
            "auditor_fn_violation": 0.01932313449772356,
            "auditor_fp_violation": 0.020916487276033832,
            "ave_precision_score": 0.8413275982234543,
            "fpr": 0.1437980241492865,
            "logloss": 0.9588432249580683,
            "mae": 0.26306464370759725,
            "precision": 0.7405940594059406,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.5557704445328977,
            "auditor_fn_violation": 0.019686586257309943,
            "auditor_fp_violation": 0.027016325536062372,
            "ave_precision_score": 0.5572717682758902,
            "fpr": 0.32894736842105265,
            "logloss": 0.9159503813552445,
            "mae": 0.46766175553257777,
            "precision": 0.5844875346260388,
            "recall": 0.8791666666666667
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.5960943308132429,
            "auditor_fn_violation": 0.020346723357741993,
            "auditor_fp_violation": 0.027575501058760592,
            "ave_precision_score": 0.5967182400691897,
            "fpr": 0.3172338090010977,
            "logloss": 0.8526253706498679,
            "mae": 0.4553305772628991,
            "precision": 0.5912305516265912,
            "recall": 0.8818565400843882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5749074872031938,
            "auditor_fn_violation": 0.011430921052631583,
            "auditor_fp_violation": 0.014051332033788175,
            "ave_precision_score": 0.5761035304148037,
            "fpr": 0.09100877192982457,
            "logloss": 0.7216761940237729,
            "mae": 0.4878816592112544,
            "precision": 0.6139534883720931,
            "recall": 0.275
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.5183828931782235,
            "auditor_fn_violation": 0.007880707897381748,
            "auditor_fp_violation": 0.015224550183744573,
            "ave_precision_score": 0.5198973626058984,
            "fpr": 0.1251372118551043,
            "logloss": 0.7410371658600552,
            "mae": 0.4918404537696017,
            "precision": 0.48878923766816146,
            "recall": 0.229957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 10197,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6790525010177728,
            "auditor_fn_violation": 0.05440652412280701,
            "auditor_fp_violation": 0.0687946718648473,
            "ave_precision_score": 0.6446978068699314,
            "fpr": 0.18640350877192982,
            "logloss": 3.5641103957031293,
            "mae": 0.4293022132019685,
            "precision": 0.631236442516269,
            "recall": 0.60625
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6807305016073959,
            "auditor_fn_violation": 0.0500632216648835,
            "auditor_fp_violation": 0.06906434702228295,
            "ave_precision_score": 0.6466507205268108,
            "fpr": 0.19209659714599342,
            "logloss": 3.252326439634068,
            "mae": 0.41479928013884776,
            "precision": 0.6346555323590815,
            "recall": 0.6413502109704642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6112095826428834,
            "auditor_fn_violation": 0.01370614035087719,
            "auditor_fp_violation": 0.007137345679012359,
            "ave_precision_score": 0.5539357370642852,
            "fpr": 0.34649122807017546,
            "logloss": 0.6911394194360903,
            "mae": 0.498431242250821,
            "precision": 0.5325443786982249,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5969552497539456,
            "auditor_fn_violation": 0.008137763018336597,
            "auditor_fp_violation": 0.01091917499566701,
            "ave_precision_score": 0.5359751047373827,
            "fpr": 0.3567508232711306,
            "logloss": 0.6920692335304267,
            "mae": 0.49890253009963637,
            "precision": 0.5163690476190477,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.606842466045348,
            "auditor_fn_violation": 0.010896381578947368,
            "auditor_fp_violation": 0.017498172514619898,
            "ave_precision_score": 0.6083953913622069,
            "fpr": 0.375,
            "logloss": 0.8868725682083756,
            "mae": 0.48219934587873386,
            "precision": 0.5334242837653479,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.654174209446956,
            "auditor_fn_violation": 0.010775472772999487,
            "auditor_fp_violation": 0.009256305465616019,
            "ave_precision_score": 0.6546481445064213,
            "fpr": 0.34796926454445665,
            "logloss": 0.8464737723463983,
            "mae": 0.47360423321781514,
            "precision": 0.5645604395604396,
            "recall": 0.8670886075949367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5681226868888426,
            "auditor_fn_violation": 0.08692205774853802,
            "auditor_fp_violation": 0.0799144127680312,
            "ave_precision_score": 0.5696382781787833,
            "fpr": 0.15460526315789475,
            "logloss": 1.2867239404100232,
            "mae": 0.4886636924327731,
            "precision": 0.5778443113772455,
            "recall": 0.40208333333333335
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5962235808557538,
            "auditor_fn_violation": 0.08992760771999056,
            "auditor_fp_violation": 0.07481656941475533,
            "ave_precision_score": 0.5984457306336868,
            "fpr": 0.15148188803512624,
            "logloss": 1.1082695289609525,
            "mae": 0.4744130128638223,
            "precision": 0.603448275862069,
            "recall": 0.4430379746835443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5290890868611003,
            "auditor_fn_violation": 0.016207510964912283,
            "auditor_fp_violation": 0.005939327485380132,
            "ave_precision_score": 0.6211389940711125,
            "fpr": 0.24890350877192982,
            "logloss": 0.6890709434851955,
            "mae": 0.4968226381103721,
            "precision": 0.556640625,
            "recall": 0.59375
        },
        "train": {
            "accuracy": 0.5181119648737651,
            "auc_prc": 0.5241684874982421,
            "auditor_fn_violation": 0.003070766580055301,
            "auditor_fp_violation": 0.00439077936333699,
            "ave_precision_score": 0.5971513300462519,
            "fpr": 0.27771679473106475,
            "logloss": 0.6919931094212655,
            "mae": 0.4982783900395968,
            "precision": 0.532347504621072,
            "recall": 0.6075949367088608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6104279786468139,
            "auditor_fn_violation": 0.011033442982456143,
            "auditor_fp_violation": 0.01809971978557506,
            "ave_precision_score": 0.6118747313350987,
            "fpr": 0.3782894736842105,
            "logloss": 0.8892248609028168,
            "mae": 0.48167355296512443,
            "precision": 0.532520325203252,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.644405493907125,
            "auditor_fn_violation": 0.009184509997359981,
            "auditor_fp_violation": 0.011092495233693453,
            "ave_precision_score": 0.6449097963081563,
            "fpr": 0.35016465422612514,
            "logloss": 0.8476939080778224,
            "mae": 0.4726488227770959,
            "precision": 0.563013698630137,
            "recall": 0.8670886075949367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7933424130613004,
            "auditor_fn_violation": 0.00831048976608187,
            "auditor_fp_violation": 0.024681205328135156,
            "ave_precision_score": 0.7937861347481758,
            "fpr": 0.2412280701754386,
            "logloss": 1.4251591303589644,
            "mae": 0.3072727331504766,
            "precision": 0.6599690880989181,
            "recall": 0.8895833333333333
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8126338053840846,
            "auditor_fn_violation": 0.010261362531089778,
            "auditor_fp_violation": 0.02078586912563708,
            "ave_precision_score": 0.812882653372369,
            "fpr": 0.2327113062568606,
            "logloss": 1.3026452634494723,
            "mae": 0.29397065128147915,
            "precision": 0.6692667706708268,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7948631737657647,
            "auditor_fn_violation": 0.008278508771929824,
            "auditor_fp_violation": 0.023079617446393755,
            "ave_precision_score": 0.79513918344088,
            "fpr": 0.24013157894736842,
            "logloss": 1.382616236918408,
            "mae": 0.3066571298970287,
            "precision": 0.6594090202177294,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8164634954730414,
            "auditor_fn_violation": 0.010879684308521726,
            "auditor_fp_violation": 0.022669784756359473,
            "ave_precision_score": 0.8167950489636085,
            "fpr": 0.22941822173435786,
            "logloss": 1.2583766793784648,
            "mae": 0.2931308298760709,
            "precision": 0.6718995290423861,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6765954546352609,
            "auditor_fn_violation": 0.01651589912280703,
            "auditor_fp_violation": 0.00019797758284601465,
            "ave_precision_score": 0.538687027956072,
            "fpr": 0.26206140350877194,
            "logloss": 0.6908973945170844,
            "mae": 0.49793098517285106,
            "precision": 0.5482041587901701,
            "recall": 0.6041666666666666
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.6714160102367286,
            "auditor_fn_violation": 0.003422769988930428,
            "auditor_fp_violation": 0.005968244718128544,
            "ave_precision_score": 0.5266756331110104,
            "fpr": 0.2854006586169045,
            "logloss": 0.6928144489238368,
            "mae": 0.49886778383040403,
            "precision": 0.5289855072463768,
            "recall": 0.6160337552742616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7541466816455453,
            "auditor_fn_violation": 0.018096673976608187,
            "auditor_fp_violation": 0.019508406432748537,
            "ave_precision_score": 0.754970878819117,
            "fpr": 0.16557017543859648,
            "logloss": 1.1244184309765197,
            "mae": 0.3207860931815775,
            "precision": 0.694331983805668,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7663467770992912,
            "auditor_fn_violation": 0.008100710027928695,
            "auditor_fp_violation": 0.020665298525270846,
            "ave_precision_score": 0.7668685932337144,
            "fpr": 0.1668496158068057,
            "logloss": 1.0275357497937103,
            "mae": 0.31029268211305955,
            "precision": 0.6996047430830039,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5978863624630799,
            "auditor_fn_violation": 1.3706140350877115e-05,
            "auditor_fp_violation": 0.0013198505523067071,
            "ave_precision_score": 0.6001031106602084,
            "fpr": 0.4692982456140351,
            "logloss": 0.692529605900119,
            "mae": 0.4994891175444712,
            "precision": 0.5275938189845475,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6082605527603864,
            "auditor_fn_violation": 0.0008128499770734622,
            "auditor_fp_violation": 0.0014644304169482236,
            "ave_precision_score": 0.6107429358316105,
            "fpr": 0.47530186608122943,
            "logloss": 0.6923696978317043,
            "mae": 0.49943929877945936,
            "precision": 0.5210176991150443,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7551102546546034,
            "auditor_fn_violation": 0.015337171052631576,
            "auditor_fp_violation": 0.018102257959714103,
            "ave_precision_score": 0.7559630244699114,
            "fpr": 0.16228070175438597,
            "logloss": 1.0855813808159243,
            "mae": 0.320368299354855,
            "precision": 0.6979591836734694,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7704441723163902,
            "auditor_fn_violation": 0.0026678153093693167,
            "auditor_fp_violation": 0.023255054545637237,
            "ave_precision_score": 0.7709237046680145,
            "fpr": 0.17014270032930845,
            "logloss": 0.9878313321788783,
            "mae": 0.30993212403877873,
            "precision": 0.6954813359528488,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.543705372849822,
            "auditor_fn_violation": 0.01154742324561403,
            "auditor_fp_violation": 0.019234283625731003,
            "ave_precision_score": 0.5453776197533338,
            "fpr": 0.18530701754385964,
            "logloss": 0.6937664889311017,
            "mae": 0.4986519123378553,
            "precision": 0.5357142857142857,
            "recall": 0.40625
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5440489469569381,
            "auditor_fn_violation": 0.005655212661006821,
            "auditor_fp_violation": 0.023071686757580246,
            "ave_precision_score": 0.5479917491651517,
            "fpr": 0.1734357848518112,
            "logloss": 0.6910225528920874,
            "mae": 0.497147163594986,
            "precision": 0.5485714285714286,
            "recall": 0.4050632911392405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 10197,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8181734437603396,
            "auditor_fn_violation": 0.014768366228070182,
            "auditor_fp_violation": 0.0184626786874594,
            "ave_precision_score": 0.8184732385227995,
            "fpr": 0.15679824561403508,
            "logloss": 0.8909895189751464,
            "mae": 0.2786756685204802,
            "precision": 0.7342007434944238,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8536280915381386,
            "auditor_fn_violation": 0.021097046413502112,
            "auditor_fp_violation": 0.019881589622890335,
            "ave_precision_score": 0.8537334072324996,
            "fpr": 0.15477497255762898,
            "logloss": 0.9786208857440043,
            "mae": 0.2707016711457887,
            "precision": 0.7364485981308411,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8038559863551087,
            "auditor_fn_violation": 0.013459429824561407,
            "auditor_fp_violation": 0.01655397173489279,
            "ave_precision_score": 0.8042477010910213,
            "fpr": 0.1513157894736842,
            "logloss": 1.1042184737203629,
            "mae": 0.27729042899854006,
            "precision": 0.7325581395348837,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8405640513301187,
            "auditor_fn_violation": 0.01932313449772356,
            "auditor_fp_violation": 0.019977041348180267,
            "ave_precision_score": 0.8407921290619249,
            "fpr": 0.14270032930845225,
            "logloss": 0.9773081541849089,
            "mae": 0.2615584370113081,
            "precision": 0.7420634920634921,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7800667906387224,
            "auditor_fn_violation": 0.015264071637426905,
            "auditor_fp_violation": 0.013449784762833008,
            "ave_precision_score": 0.78065666882715,
            "fpr": 0.16557017543859648,
            "logloss": 1.0041786471202414,
            "mae": 0.29073483650580473,
            "precision": 0.7166979362101313,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7783664249301744,
            "auditor_fn_violation": 0.017206482420671864,
            "auditor_fp_violation": 0.007394996822462308,
            "ave_precision_score": 0.7797958880668353,
            "fpr": 0.15697036223929747,
            "logloss": 1.0789188335263726,
            "mae": 0.28257261240972786,
            "precision": 0.7276190476190476,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5868995610954443,
            "auditor_fn_violation": 0.0052311769005848,
            "auditor_fp_violation": 0.01051819363222873,
            "ave_precision_score": 0.5991625560453014,
            "fpr": 0.40350877192982454,
            "logloss": 0.6974523885099942,
            "mae": 0.49726176830498797,
            "precision": 0.5269922879177378,
            "recall": 0.8541666666666666
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5266573003770164,
            "auditor_fn_violation": 0.004008670399755451,
            "auditor_fp_violation": 0.009982240955321058,
            "ave_precision_score": 0.6083997883690464,
            "fpr": 0.40285400658616904,
            "logloss": 0.6919000702876249,
            "mae": 0.4950418344378864,
            "precision": 0.5354430379746835,
            "recall": 0.8924050632911392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7540192874204228,
            "auditor_fn_violation": 0.016694078947368424,
            "auditor_fp_violation": 0.02503147335932424,
            "ave_precision_score": 0.7548675799658046,
            "fpr": 0.17324561403508773,
            "logloss": 1.049420434581715,
            "mae": 0.3225823897284882,
            "precision": 0.6883629191321499,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.761986710921043,
            "auditor_fn_violation": 0.0019174922536091931,
            "auditor_fp_violation": 0.021838349991333994,
            "ave_precision_score": 0.7625998877106186,
            "fpr": 0.17233809001097694,
            "logloss": 0.9637750741254608,
            "mae": 0.310956924769208,
            "precision": 0.6945525291828794,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 10197,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.607455964884889,
            "auditor_fn_violation": 0.008182565789473685,
            "auditor_fp_violation": 0.0198662889863548,
            "ave_precision_score": 0.6088870831610083,
            "fpr": 0.3190789473684211,
            "logloss": 0.884488952577868,
            "mae": 0.454949014058353,
            "precision": 0.5720588235294117,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6880331596495413,
            "auditor_fn_violation": 0.0130032838212749,
            "auditor_fp_violation": 0.029605106164925506,
            "ave_precision_score": 0.6884300818852547,
            "fpr": 0.265642151481888,
            "logloss": 0.8144133617843745,
            "mae": 0.4306936593446165,
            "precision": 0.6164817749603804,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7933446509408822,
            "auditor_fn_violation": 0.00831048976608187,
            "auditor_fp_violation": 0.024681205328135156,
            "ave_precision_score": 0.7937906105073393,
            "fpr": 0.2412280701754386,
            "logloss": 1.4251550864395417,
            "mae": 0.307272515508638,
            "precision": 0.6599690880989181,
            "recall": 0.8895833333333333
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8126338053840846,
            "auditor_fn_violation": 0.010261362531089778,
            "auditor_fp_violation": 0.02078586912563708,
            "ave_precision_score": 0.812882653372369,
            "fpr": 0.2327113062568606,
            "logloss": 1.302642223943276,
            "mae": 0.2939705202674983,
            "precision": 0.6692667706708268,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.5553657027346075,
            "auditor_fn_violation": 0.01699561403508772,
            "auditor_fp_violation": 0.025518802794022084,
            "ave_precision_score": 0.5568656702268008,
            "fpr": 0.33114035087719296,
            "logloss": 0.9167533151790023,
            "mae": 0.46760820480091725,
            "precision": 0.5851648351648352,
            "recall": 0.8875
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.596499299607895,
            "auditor_fn_violation": 0.020346723357741993,
            "auditor_fp_violation": 0.028715897987224542,
            "ave_precision_score": 0.5971225775794442,
            "fpr": 0.3194291986827662,
            "logloss": 0.8533236342547622,
            "mae": 0.4553579740383704,
            "precision": 0.5895627644569816,
            "recall": 0.8818565400843882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6507407843012574,
            "auditor_fn_violation": 0.00865999634502924,
            "auditor_fp_violation": 0.015706221572449646,
            "ave_precision_score": 0.6488768862555769,
            "fpr": 0.19956140350877194,
            "logloss": 2.200413853584662,
            "mae": 0.3170286753504648,
            "precision": 0.6856649395509499,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7083142735870673,
            "auditor_fn_violation": 0.01590268032069363,
            "auditor_fp_violation": 0.022747653269096,
            "ave_precision_score": 0.7032624629111851,
            "fpr": 0.18331503841931943,
            "logloss": 1.855869262441828,
            "mae": 0.29091839266802777,
            "precision": 0.708041958041958,
            "recall": 0.8544303797468354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5561656566201935,
            "auditor_fn_violation": 0.0008315058479532163,
            "auditor_fp_violation": 0.003878330084470449,
            "ave_precision_score": 0.557775699150844,
            "fpr": 0.4649122807017544,
            "logloss": 1.1820196670713687,
            "mae": 0.4708509991358714,
            "precision": 0.5288888888888889,
            "recall": 0.9916666666666667
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6020904115455172,
            "auditor_fn_violation": 0.0009448512554016313,
            "auditor_fp_violation": 0.0002938908383926921,
            "ave_precision_score": 0.6037406846146258,
            "fpr": 0.4774972557628979,
            "logloss": 1.2011993823910119,
            "mae": 0.47520187804240294,
            "precision": 0.5198675496688742,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.788325802787962,
            "auditor_fn_violation": 0.009436677631578946,
            "auditor_fp_violation": 0.023599943144899296,
            "ave_precision_score": 0.7882448291471574,
            "fpr": 0.23574561403508773,
            "logloss": 1.4779894330440375,
            "mae": 0.3076808307544116,
            "precision": 0.6630094043887147,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8062185591845982,
            "auditor_fn_violation": 0.01099084327974545,
            "auditor_fp_violation": 0.023172162257885452,
            "ave_precision_score": 0.8062516158264266,
            "fpr": 0.2305159165751921,
            "logloss": 1.33687155352807,
            "mae": 0.2930699056699297,
            "precision": 0.6713615023474179,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7547410762865194,
            "auditor_fn_violation": 0.020614035087719307,
            "auditor_fp_violation": 0.01616309291747888,
            "ave_precision_score": 0.755467541817772,
            "fpr": 0.16228070175438597,
            "logloss": 1.075482193836325,
            "mae": 0.3186034407393288,
            "precision": 0.7016129032258065,
            "recall": 0.725
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.769845132363546,
            "auditor_fn_violation": 0.002649288814165363,
            "auditor_fp_violation": 0.02276523648164941,
            "ave_precision_score": 0.770467783537222,
            "fpr": 0.16355653128430298,
            "logloss": 0.9553194835607264,
            "mae": 0.30448908530607394,
            "precision": 0.707843137254902,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7948042328083063,
            "auditor_fn_violation": 0.008278508771929824,
            "auditor_fp_violation": 0.023079617446393755,
            "ave_precision_score": 0.7951242805414365,
            "fpr": 0.24013157894736842,
            "logloss": 1.3837366327584202,
            "mae": 0.30684578922301436,
            "precision": 0.6594090202177294,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8163379340508427,
            "auditor_fn_violation": 0.010879684308521726,
            "auditor_fp_violation": 0.022669784756359473,
            "ave_precision_score": 0.8166778837718431,
            "fpr": 0.22941822173435786,
            "logloss": 1.2601228076154218,
            "mae": 0.29341272554955766,
            "precision": 0.6718995290423861,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5805319401436801,
            "auditor_fn_violation": 0.006485288742690061,
            "auditor_fp_violation": 0.006424118745938936,
            "ave_precision_score": 0.5820529655460988,
            "fpr": 0.40021929824561403,
            "logloss": 0.6933354497189648,
            "mae": 0.4899442146221797,
            "precision": 0.520997375328084,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5339388980557236,
            "auditor_fn_violation": 0.0017785435395795443,
            "auditor_fp_violation": 0.007166415059267998,
            "ave_precision_score": 0.5353936350503914,
            "fpr": 0.407244785949506,
            "logloss": 0.697645063526818,
            "mae": 0.49426061261760157,
            "precision": 0.5200517464424321,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.743782533304493,
            "auditor_fn_violation": 0.02147980628654971,
            "auditor_fp_violation": 0.015594541910331383,
            "ave_precision_score": 0.744408603884213,
            "fpr": 0.1611842105263158,
            "logloss": 1.1279480588361865,
            "mae": 0.31855490791644536,
            "precision": 0.7036290322580645,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7671267678398344,
            "auditor_fn_violation": 0.002649288814165363,
            "auditor_fp_violation": 0.022584380581100055,
            "ave_precision_score": 0.7677385881881091,
            "fpr": 0.16465422612513722,
            "logloss": 0.9685822241896302,
            "mae": 0.304760592570957,
            "precision": 0.7064579256360078,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7853605283524441,
            "auditor_fn_violation": 0.01068622076023392,
            "auditor_fp_violation": 0.021980588044184544,
            "ave_precision_score": 0.7845495678378941,
            "fpr": 0.23464912280701755,
            "logloss": 1.5362280871233562,
            "mae": 0.30729802892252017,
            "precision": 0.6635220125786163,
            "recall": 0.8791666666666667
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8080862650548721,
            "auditor_fn_violation": 0.00978198946768748,
            "auditor_fp_violation": 0.026113582529320015,
            "ave_precision_score": 0.8078282919186239,
            "fpr": 0.22722283205268934,
            "logloss": 1.3643381415837574,
            "mae": 0.2921262151113452,
            "precision": 0.6740157480314961,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5804522299443814,
            "auditor_fn_violation": 0.006485288742690061,
            "auditor_fp_violation": 0.006424118745938936,
            "ave_precision_score": 0.5820216650717122,
            "fpr": 0.40021929824561403,
            "logloss": 0.6933269309987989,
            "mae": 0.48993947102051033,
            "precision": 0.520997375328084,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5339248486563581,
            "auditor_fn_violation": 0.0017785435395795443,
            "auditor_fp_violation": 0.007166415059267998,
            "ave_precision_score": 0.5353549336321418,
            "fpr": 0.407244785949506,
            "logloss": 0.6976377977027658,
            "mae": 0.4942569546197039,
            "precision": 0.5200517464424321,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6417753772474795,
            "auditor_fn_violation": 0.011878654970760233,
            "auditor_fp_violation": 0.029138239116309292,
            "ave_precision_score": 0.6399537195438362,
            "fpr": 0.21929824561403508,
            "logloss": 2.3437994601714536,
            "mae": 0.3207519537105318,
            "precision": 0.6666666666666666,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7006928569011811,
            "auditor_fn_violation": 0.014121820969213602,
            "auditor_fp_violation": 0.027894510772229576,
            "ave_precision_score": 0.69565991712072,
            "fpr": 0.19099890230515917,
            "logloss": 1.9239570152164733,
            "mae": 0.2885704996083868,
            "precision": 0.6968641114982579,
            "recall": 0.8438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8193736561871521,
            "auditor_fn_violation": 0.014768366228070182,
            "auditor_fp_violation": 0.020021117608836913,
            "ave_precision_score": 0.8196680432104426,
            "fpr": 0.15570175438596492,
            "logloss": 0.8851406120480017,
            "mae": 0.2785994815810002,
            "precision": 0.7355679702048417,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.854311780473672,
            "auditor_fn_violation": 0.021097046413502112,
            "auditor_fp_violation": 0.019881589622890335,
            "ave_precision_score": 0.8544154162347449,
            "fpr": 0.15477497255762898,
            "logloss": 0.9710870167660596,
            "mae": 0.27026913953323006,
            "precision": 0.7364485981308411,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6504763610513975,
            "auditor_fn_violation": 0.006770833333333337,
            "auditor_fp_violation": 0.015706221572449646,
            "ave_precision_score": 0.6486127080614239,
            "fpr": 0.19956140350877194,
            "logloss": 2.2013280233177484,
            "mae": 0.3169738259222822,
            "precision": 0.6851211072664359,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7083051766690059,
            "auditor_fn_violation": 0.01590268032069363,
            "auditor_fp_violation": 0.020562311137458024,
            "ave_precision_score": 0.7032300910875411,
            "fpr": 0.18221734357848518,
            "logloss": 1.8568020443244075,
            "mae": 0.2909428899959574,
            "precision": 0.7092819614711033,
            "recall": 0.8544303797468354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8016582216272017,
            "auditor_fn_violation": 0.011499451754385964,
            "auditor_fp_violation": 0.017858593242365176,
            "ave_precision_score": 0.8020189990116453,
            "fpr": 0.15350877192982457,
            "logloss": 1.1207419414094562,
            "mae": 0.2810242906896248,
            "precision": 0.7297297297297297,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8389522146219043,
            "auditor_fn_violation": 0.019040605445863265,
            "auditor_fp_violation": 0.018758775906979788,
            "ave_precision_score": 0.8391830761019152,
            "fpr": 0.14489571899012074,
            "logloss": 0.9869270387139116,
            "mae": 0.2646851096286667,
            "precision": 0.7391304347826086,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5804676173725314,
            "auditor_fn_violation": 0.006485288742690061,
            "auditor_fp_violation": 0.006424118745938936,
            "ave_precision_score": 0.5819919344463692,
            "fpr": 0.40021929824561403,
            "logloss": 0.6933253430554455,
            "mae": 0.48993859139450807,
            "precision": 0.520997375328084,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.5339436172938167,
            "auditor_fn_violation": 0.0017785435395795443,
            "auditor_fp_violation": 0.007166415059267998,
            "ave_precision_score": 0.5353668344185963,
            "fpr": 0.407244785949506,
            "logloss": 0.6976364416440644,
            "mae": 0.49425627027856006,
            "precision": 0.5200517464424321,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7413381598665797,
            "auditor_fn_violation": 0.020202850877192983,
            "auditor_fp_violation": 0.021181063190383365,
            "ave_precision_score": 0.7424864796585247,
            "fpr": 0.1699561403508772,
            "logloss": 1.149050817376683,
            "mae": 0.321894197816588,
            "precision": 0.6954813359528488,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7566439444736239,
            "auditor_fn_violation": 0.004890994733843737,
            "auditor_fp_violation": 0.02218499046738691,
            "ave_precision_score": 0.7573005722471082,
            "fpr": 0.17672886937431395,
            "logloss": 1.0328865938389808,
            "mae": 0.30989939267425104,
            "precision": 0.690978886756238,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6547343655524749,
            "auditor_fn_violation": 0.006633771929824561,
            "auditor_fp_violation": 0.019127680311890844,
            "ave_precision_score": 0.6528481074798993,
            "fpr": 0.2236842105263158,
            "logloss": 2.1966297916070583,
            "mae": 0.31878086843078546,
            "precision": 0.6666666666666666,
            "recall": 0.85
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7115718700443485,
            "auditor_fn_violation": 0.012709175709912143,
            "auditor_fp_violation": 0.024166869710906872,
            "ave_precision_score": 0.7064993167855418,
            "fpr": 0.18880351262349068,
            "logloss": 1.7558002011372231,
            "mae": 0.289681601649125,
            "precision": 0.705982905982906,
            "recall": 0.8713080168776371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5868995610954443,
            "auditor_fn_violation": 0.0052311769005848,
            "auditor_fp_violation": 0.01051819363222873,
            "ave_precision_score": 0.5991625560453014,
            "fpr": 0.40350877192982454,
            "logloss": 0.6974794514221373,
            "mae": 0.4972542724980597,
            "precision": 0.5269922879177378,
            "recall": 0.8541666666666666
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5266573003770164,
            "auditor_fn_violation": 0.004008670399755451,
            "auditor_fp_violation": 0.009982240955321058,
            "ave_precision_score": 0.6083997883690464,
            "fpr": 0.40285400658616904,
            "logloss": 0.6919315742469986,
            "mae": 0.4950390944889165,
            "precision": 0.5354430379746835,
            "recall": 0.8924050632911392
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6506915997493015,
            "auditor_fn_violation": 0.00865999634502924,
            "auditor_fp_violation": 0.015708759746588707,
            "ave_precision_score": 0.6488147193060843,
            "fpr": 0.20065789473684212,
            "logloss": 2.2429015900353635,
            "mae": 0.31704455082635324,
            "precision": 0.6844827586206896,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7081522987578394,
            "auditor_fn_violation": 0.01590268032069363,
            "auditor_fp_violation": 0.022747653269096,
            "ave_precision_score": 0.7030775141324905,
            "fpr": 0.18331503841931943,
            "logloss": 1.8569250948521023,
            "mae": 0.2909106598879934,
            "precision": 0.708041958041958,
            "recall": 0.8544303797468354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7523033038263955,
            "auditor_fn_violation": 0.01738623903508772,
            "auditor_fp_violation": 0.017769757147498375,
            "ave_precision_score": 0.7531486261465237,
            "fpr": 0.15899122807017543,
            "logloss": 1.126811427041931,
            "mae": 0.32146062793682595,
            "precision": 0.7004132231404959,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7676153740244065,
            "auditor_fn_violation": 0.009015455728623896,
            "auditor_fp_violation": 0.02022571821143563,
            "ave_precision_score": 0.7681580480991129,
            "fpr": 0.16245883644346873,
            "logloss": 1.0397487407537667,
            "mae": 0.3110827862517718,
            "precision": 0.701010101010101,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7947931352716506,
            "auditor_fn_violation": 0.008278508771929824,
            "auditor_fp_violation": 0.023079617446393755,
            "ave_precision_score": 0.7950755109986206,
            "fpr": 0.24013157894736842,
            "logloss": 1.3848184797050545,
            "mae": 0.3069031771010152,
            "precision": 0.6594090202177294,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8163270783407128,
            "auditor_fn_violation": 0.010879684308521726,
            "auditor_fp_violation": 0.022669784756359473,
            "ave_precision_score": 0.8166789484181931,
            "fpr": 0.22941822173435786,
            "logloss": 1.261057123356363,
            "mae": 0.2934665990737308,
            "precision": 0.6718995290423861,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7622210831813656,
            "auditor_fn_violation": 0.020157163742690058,
            "auditor_fp_violation": 0.016122482131254067,
            "ave_precision_score": 0.7629313513157987,
            "fpr": 0.1600877192982456,
            "logloss": 1.0659159569784695,
            "mae": 0.31428676203299516,
            "precision": 0.7074148296593187,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7807773683650133,
            "auditor_fn_violation": 0.005465316085166303,
            "auditor_fp_violation": 0.020680369850316627,
            "ave_precision_score": 0.7812807242146638,
            "fpr": 0.1602634467618002,
            "logloss": 0.9448643740057484,
            "mae": 0.3012245658624718,
            "precision": 0.7125984251968503,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6498792619889582,
            "auditor_fn_violation": 0.006770833333333337,
            "auditor_fp_violation": 0.015107212475633536,
            "ave_precision_score": 0.6480324499238055,
            "fpr": 0.20394736842105263,
            "logloss": 2.2020214389482193,
            "mae": 0.3206024794999666,
            "precision": 0.6804123711340206,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7060486455999881,
            "auditor_fn_violation": 0.016340368769887034,
            "auditor_fp_violation": 0.018263934067976703,
            "ave_precision_score": 0.7009742076658856,
            "fpr": 0.18660812294182216,
            "logloss": 1.8634391514522979,
            "mae": 0.296125094185977,
            "precision": 0.7048611111111112,
            "recall": 0.8565400843881856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7947717773743275,
            "auditor_fn_violation": 0.007641173245614034,
            "auditor_fp_violation": 0.023115151884340487,
            "ave_precision_score": 0.7951214683774301,
            "fpr": 0.23793859649122806,
            "logloss": 1.4180332697435067,
            "mae": 0.3063033812425709,
            "precision": 0.661993769470405,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8107623851869586,
            "auditor_fn_violation": 0.01063883987087033,
            "auditor_fp_violation": 0.027733749971741266,
            "ave_precision_score": 0.8112558166095656,
            "fpr": 0.23929747530186607,
            "logloss": 1.3384346451004736,
            "mae": 0.2967394352855823,
            "precision": 0.6635802469135802,
            "recall": 0.9071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7880849875527582,
            "auditor_fn_violation": 0.009436677631578946,
            "auditor_fp_violation": 0.023599943144899296,
            "ave_precision_score": 0.7882137760180632,
            "fpr": 0.23574561403508773,
            "logloss": 1.4821497860588624,
            "mae": 0.3091850022573581,
            "precision": 0.6630094043887147,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8008456025250258,
            "auditor_fn_violation": 0.011454005659844287,
            "auditor_fp_violation": 0.02392572851017441,
            "ave_precision_score": 0.800686551301783,
            "fpr": 0.23819978046103182,
            "logloss": 1.351583829187498,
            "mae": 0.29527907000348885,
            "precision": 0.6646058732612056,
            "recall": 0.9071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5994736460762771,
            "auditor_fn_violation": 0.012541118421052638,
            "auditor_fp_violation": 0.01054103719948019,
            "ave_precision_score": 0.6010003736212968,
            "fpr": 0.13925438596491227,
            "logloss": 0.6856074986305245,
            "mae": 0.4904833390263089,
            "precision": 0.5822368421052632,
            "recall": 0.36875
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.5427659680616639,
            "auditor_fn_violation": 0.006822381858855908,
            "auditor_fp_violation": 0.007658745010763438,
            "ave_precision_score": 0.5441544999526408,
            "fpr": 0.16465422612513722,
            "logloss": 0.6909651882039336,
            "mae": 0.4949980840724857,
            "precision": 0.4880546075085324,
            "recall": 0.30168776371308015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7541085209368266,
            "auditor_fn_violation": 0.018096673976608187,
            "auditor_fp_violation": 0.019508406432748537,
            "ave_precision_score": 0.754942130882101,
            "fpr": 0.16557017543859648,
            "logloss": 1.1245042840286767,
            "mae": 0.32081810925166926,
            "precision": 0.694331983805668,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7663148792114666,
            "auditor_fn_violation": 0.008100710027928695,
            "auditor_fp_violation": 0.020665298525270846,
            "ave_precision_score": 0.7668368948564703,
            "fpr": 0.1668496158068057,
            "logloss": 1.02757927481145,
            "mae": 0.31032075077197746,
            "precision": 0.6996047430830039,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.5437381287985334,
            "auditor_fn_violation": 0.01154742324561403,
            "auditor_fp_violation": 0.019234283625731003,
            "ave_precision_score": 0.5454103376355254,
            "fpr": 0.18530701754385964,
            "logloss": 0.6937553869126283,
            "mae": 0.49864599062946807,
            "precision": 0.5357142857142857,
            "recall": 0.40625
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5440609246309934,
            "auditor_fn_violation": 0.005655212661006821,
            "auditor_fp_violation": 0.023071686757580246,
            "ave_precision_score": 0.5480036734024206,
            "fpr": 0.1734357848518112,
            "logloss": 0.6910137001704663,
            "mae": 0.497142279056503,
            "precision": 0.5485714285714286,
            "recall": 0.4050632911392405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5947095024490632,
            "auditor_fn_violation": 0.02658991228070176,
            "auditor_fp_violation": 0.0217115415854451,
            "ave_precision_score": 0.5958315047477349,
            "fpr": 0.15899122807017543,
            "logloss": 0.6855197804571707,
            "mae": 0.4899152439708511,
            "precision": 0.5845272206303725,
            "recall": 0.425
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5516941085848345,
            "auditor_fn_violation": 0.01473782693474506,
            "auditor_fp_violation": 0.011775728635768774,
            "ave_precision_score": 0.5527469147177254,
            "fpr": 0.17233809001097694,
            "logloss": 0.6887676804397372,
            "mae": 0.4931395749196525,
            "precision": 0.5109034267912772,
            "recall": 0.3459915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6418323188740248,
            "auditor_fn_violation": 0.011878654970760233,
            "auditor_fp_violation": 0.029138239116309292,
            "ave_precision_score": 0.6400594023661974,
            "fpr": 0.21929824561403508,
            "logloss": 2.3434045916285755,
            "mae": 0.3207093495216638,
            "precision": 0.6666666666666666,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7007053666681627,
            "auditor_fn_violation": 0.014121820969213602,
            "auditor_fp_violation": 0.027894510772229576,
            "ave_precision_score": 0.6956547448266024,
            "fpr": 0.19099890230515917,
            "logloss": 1.9236228373486535,
            "mae": 0.2885525498961314,
            "precision": 0.6968641114982579,
            "recall": 0.8438818565400844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5594975943296585,
            "auditor_fn_violation": 0.0008908991228070176,
            "auditor_fp_violation": 0.0026879264132553746,
            "ave_precision_score": 0.5610322914789503,
            "fpr": 0.46600877192982454,
            "logloss": 1.3740069202391938,
            "mae": 0.46886779707011744,
            "precision": 0.5293466223698782,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6143354832061365,
            "auditor_fn_violation": 0.0009448512554016313,
            "auditor_fp_violation": 0.0002938908383926921,
            "ave_precision_score": 0.6149298337585687,
            "fpr": 0.4774972557628979,
            "logloss": 1.3500731571564113,
            "mae": 0.47378848561389386,
            "precision": 0.5198675496688742,
            "recall": 0.9936708860759493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.5635432449137661,
            "auditor_fn_violation": 0.0006007858187134503,
            "auditor_fp_violation": 0.0012081708901884377,
            "ave_precision_score": 0.5651480934595854,
            "fpr": 0.4682017543859649,
            "logloss": 1.7673328725051247,
            "mae": 0.4678062662248151,
            "precision": 0.5286975717439294,
            "recall": 0.9979166666666667
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.608615858900128,
            "auditor_fn_violation": 0.0005418999847156415,
            "auditor_fp_violation": 0.0002938908383926921,
            "ave_precision_score": 0.6102674333249938,
            "fpr": 0.4774972557628979,
            "logloss": 1.8181116244499285,
            "mae": 0.4764262522876459,
            "precision": 0.5209251101321586,
            "recall": 0.9978902953586498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 10197,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8198508478640573,
            "auditor_fn_violation": 0.009639985380116962,
            "auditor_fp_violation": 0.016086947693307346,
            "ave_precision_score": 0.8202083830767513,
            "fpr": 0.15570175438596492,
            "logloss": 0.8005022787382579,
            "mae": 0.2770864216554617,
            "precision": 0.7350746268656716,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8582032959953502,
            "auditor_fn_violation": 0.013584552608298947,
            "auditor_fp_violation": 0.019225986983398943,
            "ave_precision_score": 0.858404546211006,
            "fpr": 0.141602634467618,
            "logloss": 0.7189244073894128,
            "mae": 0.26317653652455386,
            "precision": 0.7552182163187856,
            "recall": 0.8396624472573839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8060821822313944,
            "auditor_fn_violation": 0.012828947368421054,
            "auditor_fp_violation": 0.01723420240415855,
            "ave_precision_score": 0.8064889955879833,
            "fpr": 0.14692982456140352,
            "logloss": 1.1041383484086615,
            "mae": 0.2783142830910945,
            "precision": 0.73828125,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.842976456539268,
            "auditor_fn_violation": 0.017009638409129862,
            "auditor_fp_violation": 0.01673168268832249,
            "ave_precision_score": 0.8431911568222624,
            "fpr": 0.1394072447859495,
            "logloss": 0.966804097299592,
            "mae": 0.2608161675158534,
            "precision": 0.7449799196787149,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7853525290760222,
            "auditor_fn_violation": 0.01068622076023392,
            "auditor_fp_violation": 0.02140696068875894,
            "ave_precision_score": 0.7844856293133228,
            "fpr": 0.23574561403508773,
            "logloss": 1.5394749856900949,
            "mae": 0.3074360808828034,
            "precision": 0.6624803767660911,
            "recall": 0.8791666666666667
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8075983647590308,
            "auditor_fn_violation": 0.00978198946768748,
            "auditor_fp_violation": 0.025407742139676025,
            "ave_precision_score": 0.8072952508957156,
            "fpr": 0.2283205268935236,
            "logloss": 1.3673926201929976,
            "mae": 0.292153432356778,
            "precision": 0.6729559748427673,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7948821740914596,
            "auditor_fn_violation": 0.008278508771929824,
            "auditor_fp_violation": 0.023079617446393755,
            "ave_precision_score": 0.7951656792235415,
            "fpr": 0.24013157894736842,
            "logloss": 1.383092636665404,
            "mae": 0.3067944797620704,
            "precision": 0.6594090202177294,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8163311853216605,
            "auditor_fn_violation": 0.010879684308521726,
            "auditor_fp_violation": 0.022669784756359473,
            "ave_precision_score": 0.8166723820850768,
            "fpr": 0.22941822173435786,
            "logloss": 1.2600797236757082,
            "mae": 0.29347321564583595,
            "precision": 0.6718995290423861,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7422318751245859,
            "auditor_fn_violation": 0.02110745614035088,
            "auditor_fp_violation": 0.01896523716699156,
            "ave_precision_score": 0.7428590631214734,
            "fpr": 0.16557017543859648,
            "logloss": 1.1017174686037785,
            "mae": 0.32062568434045313,
            "precision": 0.6973947895791583,
            "recall": 0.725
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7626633541443001,
            "auditor_fn_violation": 0.007091016039313225,
            "auditor_fp_violation": 0.02371975373454875,
            "ave_precision_score": 0.7632822856154773,
            "fpr": 0.1668496158068057,
            "logloss": 0.9658091699188983,
            "mae": 0.30426442258421293,
            "precision": 0.7037037037037037,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7943346230945436,
            "auditor_fn_violation": 0.007641173245614034,
            "auditor_fp_violation": 0.024244639376218333,
            "ave_precision_score": 0.794755085155486,
            "fpr": 0.23903508771929824,
            "logloss": 1.3967091995680638,
            "mae": 0.3067989294797672,
            "precision": 0.6609642301710731,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8165282688903058,
            "auditor_fn_violation": 0.010261362531089778,
            "auditor_fp_violation": 0.023787574697254767,
            "ave_precision_score": 0.8168002995576658,
            "fpr": 0.2283205268935236,
            "logloss": 1.2703950737440615,
            "mae": 0.2932218684647863,
            "precision": 0.673469387755102,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7948102801754695,
            "auditor_fn_violation": 0.008278508771929824,
            "auditor_fp_violation": 0.023079617446393755,
            "ave_precision_score": 0.7951330501337668,
            "fpr": 0.24013157894736842,
            "logloss": 1.383586651092572,
            "mae": 0.3067997138227436,
            "precision": 0.6594090202177294,
            "recall": 0.8833333333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8163303120411207,
            "auditor_fn_violation": 0.010879684308521726,
            "auditor_fp_violation": 0.022669784756359473,
            "ave_precision_score": 0.8166618552601894,
            "fpr": 0.22941822173435786,
            "logloss": 1.2604346252460505,
            "mae": 0.29345763636975397,
            "precision": 0.6718995290423861,
            "recall": 0.9029535864978903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7402033723881207,
            "auditor_fn_violation": 0.019915021929824563,
            "auditor_fp_violation": 0.025006091617933726,
            "ave_precision_score": 0.7407072341515403,
            "fpr": 0.17105263157894737,
            "logloss": 1.1838752743897787,
            "mae": 0.3212039587817708,
            "precision": 0.6941176470588235,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7581422482556798,
            "auditor_fn_violation": 0.006204060081423948,
            "auditor_fp_violation": 0.021574601803032865,
            "ave_precision_score": 0.7587818704985538,
            "fpr": 0.17892425905598244,
            "logloss": 1.0464866058718207,
            "mae": 0.3095794625982635,
            "precision": 0.6889312977099237,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8075627382159094,
            "auditor_fn_violation": 0.012031706871345025,
            "auditor_fp_violation": 0.018538823911630933,
            "ave_precision_score": 0.8079429497167454,
            "fpr": 0.14912280701754385,
            "logloss": 1.081874358196382,
            "mae": 0.27803942859710656,
            "precision": 0.7359223300970874,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8436831645454892,
            "auditor_fn_violation": 0.01620142005585739,
            "auditor_fp_violation": 0.01673168268832249,
            "ave_precision_score": 0.8438948472581782,
            "fpr": 0.1394072447859495,
            "logloss": 0.9646717794565307,
            "mae": 0.26017711923370856,
            "precision": 0.7465069860279441,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.513124589448662,
            "auditor_fn_violation": 0.0011924342105263156,
            "auditor_fp_violation": 0.001218323586744652,
            "ave_precision_score": 0.5136397652618568,
            "fpr": 0.4649122807017544,
            "logloss": 0.6921295181588059,
            "mae": 0.49937271225478563,
            "precision": 0.5299334811529933,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5170341303299042,
            "auditor_fn_violation": 0.0007665337390635784,
            "auditor_fp_violation": 0.0015146681671008016,
            "ave_precision_score": 0.5184611287241012,
            "fpr": 0.47530186608122943,
            "logloss": 0.6925136746753914,
            "mae": 0.4995775105335579,
            "precision": 0.5199556541019955,
            "recall": 0.989451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7863014147042624,
            "auditor_fn_violation": 0.010208790204678367,
            "auditor_fp_violation": 0.02312784275503574,
            "ave_precision_score": 0.7855005447557679,
            "fpr": 0.2324561403508772,
            "logloss": 1.5004849045517659,
            "mae": 0.30653552860596883,
            "precision": 0.665086887835703,
            "recall": 0.8770833333333333
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8073516608799538,
            "auditor_fn_violation": 0.01099084327974545,
            "auditor_fp_violation": 0.026113582529320015,
            "ave_precision_score": 0.8074705316564575,
            "fpr": 0.22722283205268934,
            "logloss": 1.3329272468316085,
            "mae": 0.2913103965594212,
            "precision": 0.6745283018867925,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7405351800818039,
            "auditor_fn_violation": 0.02254660087719299,
            "auditor_fp_violation": 0.01896523716699156,
            "ave_precision_score": 0.7411819906545615,
            "fpr": 0.16557017543859648,
            "logloss": 1.1392474035029416,
            "mae": 0.32136898664129415,
            "precision": 0.6937119675456389,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7611701308299383,
            "auditor_fn_violation": 0.007961761313899045,
            "auditor_fp_violation": 0.020898904063480418,
            "ave_precision_score": 0.7617861934327718,
            "fpr": 0.16575192096597147,
            "logloss": 0.99763651204582,
            "mae": 0.30494197764874514,
            "precision": 0.7045009784735812,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.790504513846128,
            "auditor_fn_violation": 0.009436677631578946,
            "auditor_fp_violation": 0.022554215399610146,
            "ave_precision_score": 0.7905120547404723,
            "fpr": 0.23355263157894737,
            "logloss": 1.4576438394960904,
            "mae": 0.30690036419712297,
            "precision": 0.6650943396226415,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8080496684604035,
            "auditor_fn_violation": 0.011454005659844287,
            "auditor_fp_violation": 0.0243879158115783,
            "ave_precision_score": 0.8083294246218409,
            "fpr": 0.22941822173435786,
            "logloss": 1.3219477386541827,
            "mae": 0.29278571554456817,
            "precision": 0.672926447574335,
            "recall": 0.9071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8208665380301547,
            "auditor_fn_violation": 0.012369791666666668,
            "auditor_fp_violation": 0.017102217348927883,
            "ave_precision_score": 0.8212232316720882,
            "fpr": 0.1513157894736842,
            "logloss": 0.8023509643651255,
            "mae": 0.2735054124002862,
            "precision": 0.7361376673040153,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8566951408252808,
            "auditor_fn_violation": 0.018646917422779255,
            "auditor_fp_violation": 0.01582740318557574,
            "ave_precision_score": 0.8569012310054889,
            "fpr": 0.1350164654226125,
            "logloss": 0.7286748048914417,
            "mae": 0.2607782764169937,
            "precision": 0.7602339181286549,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7526396654838425,
            "auditor_fn_violation": 0.016694078947368424,
            "auditor_fp_violation": 0.02599597953216375,
            "ave_precision_score": 0.7535035753008444,
            "fpr": 0.17434210526315788,
            "logloss": 1.0579539265486948,
            "mae": 0.32277529948447015,
            "precision": 0.687007874015748,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7609328236679117,
            "auditor_fn_violation": 0.0032328734130898963,
            "auditor_fp_violation": 0.021916218504070516,
            "ave_precision_score": 0.7614826090632832,
            "fpr": 0.17453347969264543,
            "logloss": 0.97089768623749,
            "mae": 0.3107484374277072,
            "precision": 0.6948176583493282,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8191285249005207,
            "auditor_fn_violation": 0.010983187134502928,
            "auditor_fp_violation": 0.01955916991552957,
            "ave_precision_score": 0.8194249315401029,
            "fpr": 0.15679824561403508,
            "logloss": 0.883516689162754,
            "mae": 0.27896297591682834,
            "precision": 0.7337057728119181,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8546099461121397,
            "auditor_fn_violation": 0.021097046413502112,
            "auditor_fp_violation": 0.020404062224477344,
            "ave_precision_score": 0.854713605769492,
            "fpr": 0.15587266739846323,
            "logloss": 0.9682774902272938,
            "mae": 0.2703134828399844,
            "precision": 0.7350746268656716,
            "recall": 0.8312236286919831
        }
    }
]