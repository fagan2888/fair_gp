[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.519146553850135,
            "mae": 0.5361842105263158,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.629562045700844,
            "mae": 0.5104281009879253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.519146553850135,
            "mae": 0.5361842105263158,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.629562045700844,
            "mae": 0.5104281009879253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.700035664644859,
            "mae": 0.5004908507853224,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.701194633491543,
            "mae": 0.5009946233289302,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.675018023169019,
            "auditor_fn_violation": 0.0057986223226778625,
            "auditor_fp_violation": 0.008670834888640035,
            "ave_precision_score": 0.5744974260513964,
            "fpr": 0.3190789473684211,
            "logloss": 7.36457185773318,
            "mae": 0.409356419683287,
            "precision": 0.592436974789916,
            "recall": 0.8650306748466258
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6436002700534796,
            "auditor_fn_violation": 0.004964413441450373,
            "auditor_fp_violation": 0.008072733358601659,
            "ave_precision_score": 0.5382154444194218,
            "fpr": 0.3413830954994512,
            "logloss": 8.02530970838407,
            "mae": 0.41748031103139094,
            "precision": 0.5739726027397261,
            "recall": 0.9010752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5782636984610776,
            "auditor_fn_violation": 0.006800936390054892,
            "auditor_fp_violation": 0.0017341669777280076,
            "ave_precision_score": 0.5803420431477505,
            "fpr": 0.013157894736842105,
            "logloss": 0.6952085294168558,
            "mae": 0.49996717159816045,
            "precision": 0.6,
            "recall": 0.03680981595092025
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5909565526941135,
            "auditor_fn_violation": 0.001827130767324119,
            "auditor_fp_violation": 0.0042135730213189075,
            "ave_precision_score": 0.5931095284046927,
            "fpr": 0.013172338090010977,
            "logloss": 0.6922686139405981,
            "mae": 0.49831665743195525,
            "precision": 0.6666666666666666,
            "recall": 0.05161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6883912659995298,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5504995558997936,
            "fpr": 0.44846491228070173,
            "logloss": 0.7879791662527119,
            "mae": 0.47590391259444387,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5719277890742732,
            "auditor_fn_violation": 0.0013455614177968205,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5164265721278272,
            "fpr": 0.47310647639956094,
            "logloss": 0.8255264681105999,
            "mae": 0.49188493112046944,
            "precision": 0.5135440180586908,
            "recall": 0.978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5656972228061266,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5432736378352725,
            "fpr": 0.44846491228070173,
            "logloss": 0.7947832087634621,
            "mae": 0.47725540497585345,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5845953011993315,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5166433041553166,
            "fpr": 0.47310647639956094,
            "logloss": 0.8243954564907748,
            "mae": 0.491681135904645,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 24284,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6337455852158675,
            "auditor_fn_violation": 0.0024284253578732108,
            "auditor_fp_violation": 0.005034009373315095,
            "ave_precision_score": 0.63548113674839,
            "fpr": 0.44956140350877194,
            "logloss": 0.7438822620092039,
            "mae": 0.4583107805239004,
            "precision": 0.5408734602463606,
            "recall": 0.9877300613496932
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6713469546717853,
            "auditor_fn_violation": 0.002483387037758342,
            "auditor_fp_violation": 0.003947763508291787,
            "ave_precision_score": 0.672391918877172,
            "fpr": 0.47859495060373214,
            "logloss": 0.7396074618068941,
            "mae": 0.4621392665788711,
            "precision": 0.5139353400222966,
            "recall": 0.9913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 24284,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6281971902060939,
            "auditor_fn_violation": 0.028907903706095514,
            "auditor_fp_violation": 0.04816266434407533,
            "ave_precision_score": 0.629929862887737,
            "fpr": 0.23464912280701755,
            "logloss": 0.6913976364860324,
            "mae": 0.47050660466285127,
            "precision": 0.6316695352839932,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6650627429468298,
            "auditor_fn_violation": 0.008148908796902846,
            "auditor_fp_violation": 0.02844654029229202,
            "ave_precision_score": 0.6662735435802422,
            "fpr": 0.25686059275521406,
            "logloss": 0.6675598553598622,
            "mae": 0.4647709644848377,
            "precision": 0.610648918469218,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.643909395295398,
            "auditor_fn_violation": 0.004986904890036954,
            "auditor_fp_violation": 0.025037845796524426,
            "ave_precision_score": 0.6456992679080285,
            "fpr": 0.40021929824561403,
            "logloss": 0.6961381418308846,
            "mae": 0.48081818285087746,
            "precision": 0.5685579196217494,
            "recall": 0.983640081799591
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6506730065078747,
            "auditor_fn_violation": 0.0064091214900322225,
            "auditor_fp_violation": 0.019778196728574043,
            "ave_precision_score": 0.652336897098351,
            "fpr": 0.442371020856202,
            "logloss": 0.6896518959878187,
            "mae": 0.4820730720864431,
            "precision": 0.5275498241500586,
            "recall": 0.967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6401145921635529,
            "auditor_fn_violation": 0.004789581315251319,
            "auditor_fp_violation": 0.015936709385757537,
            "ave_precision_score": 0.6417835735215697,
            "fpr": 0.42543859649122806,
            "logloss": 0.6971537739674202,
            "mae": 0.4814477670088149,
            "precision": 0.5535097813578826,
            "recall": 0.983640081799591
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6521317041906809,
            "auditor_fn_violation": 0.005901585165775528,
            "auditor_fp_violation": 0.017248083956426945,
            "ave_precision_score": 0.6536862690557579,
            "fpr": 0.4500548847420417,
            "logloss": 0.6894593294231784,
            "mae": 0.4820266633604282,
            "precision": 0.5238095238095238,
            "recall": 0.9698924731182795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5213715719912992,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5405673530515063,
            "fpr": 0.44846491228070173,
            "logloss": 0.7665339807435925,
            "mae": 0.48053506794467304,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5152625218486047,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5130188586733446,
            "fpr": 0.47310647639956094,
            "logloss": 0.7929255793345679,
            "mae": 0.49332979651889736,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5206195446313083,
            "auditor_fn_violation": 0.04399194561044739,
            "auditor_fp_violation": 0.043815582099456685,
            "ave_precision_score": 0.5259403381355016,
            "fpr": 0.16557017543859648,
            "logloss": 0.6947055113345361,
            "mae": 0.5003547025681064,
            "precision": 0.5545722713864307,
            "recall": 0.38445807770961143
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5018353698452829,
            "auditor_fn_violation": 0.04191541848140411,
            "auditor_fp_violation": 0.04267719403602212,
            "ave_precision_score": 0.5080734860715357,
            "fpr": 0.18551042810098792,
            "logloss": 0.6933600226840924,
            "mae": 0.4997170506664741,
            "precision": 0.5171428571428571,
            "recall": 0.38924731182795697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.5642271919203857,
            "auditor_fn_violation": 0.004453234312775802,
            "auditor_fp_violation": 0.0014593961262494297,
            "ave_precision_score": 0.5400354838300084,
            "fpr": 0.008771929824561403,
            "logloss": 0.6961201744777171,
            "mae": 0.5002042695618513,
            "precision": 0.5789473684210527,
            "recall": 0.022494887525562373
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5963597048966909,
            "auditor_fn_violation": 0.0004390779363337079,
            "auditor_fp_violation": 0.0013487371586932018,
            "ave_precision_score": 0.5177792461810502,
            "fpr": 0.006586169045005488,
            "logloss": 0.6928760054440692,
            "mae": 0.4986948785745221,
            "precision": 0.6666666666666666,
            "recall": 0.025806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6802331032219546,
            "auditor_fn_violation": 0.030858716320453488,
            "auditor_fp_violation": 0.05782630334702003,
            "ave_precision_score": 0.6819408657786918,
            "fpr": 0.2850877192982456,
            "logloss": 0.6793070025285375,
            "mae": 0.47682621735229824,
            "precision": 0.6253602305475504,
            "recall": 0.8875255623721882
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6939700583617046,
            "auditor_fn_violation": 0.02518088358533102,
            "auditor_fp_violation": 0.07165535335436839,
            "ave_precision_score": 0.695173865277987,
            "fpr": 0.3029637760702525,
            "logloss": 0.6688449594337234,
            "mae": 0.47588520486451663,
            "precision": 0.6028776978417266,
            "recall": 0.9010752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8586378133136592,
            "auditor_fn_violation": 0.020295178129372517,
            "auditor_fp_violation": 0.01818153539878064,
            "ave_precision_score": 0.858829256929438,
            "fpr": 0.12938596491228072,
            "logloss": 0.6807242718577153,
            "mae": 0.27648309886679173,
            "precision": 0.7556935817805382,
            "recall": 0.7464212678936605
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8203314568268103,
            "auditor_fn_violation": 0.014347933855033468,
            "auditor_fp_violation": 0.01815626645926962,
            "ave_precision_score": 0.8206957684193505,
            "fpr": 0.1525795828759605,
            "logloss": 0.7150825676061043,
            "mae": 0.28128325790019737,
            "precision": 0.7208835341365462,
            "recall": 0.7720430107526882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8598536077928334,
            "auditor_fn_violation": 0.006865963477200159,
            "auditor_fp_violation": 0.019583903612459045,
            "ave_precision_score": 0.8603437948073184,
            "fpr": 0.14692982456140352,
            "logloss": 0.6191972246899593,
            "mae": 0.27610348377346416,
            "precision": 0.7408123791102514,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8251113789424592,
            "auditor_fn_violation": 0.010063383024680427,
            "auditor_fp_violation": 0.024811349081726587,
            "ave_precision_score": 0.8254539284238936,
            "fpr": 0.15477497255762898,
            "logloss": 0.6761373963469907,
            "mae": 0.2811762278608001,
            "precision": 0.7224409448818898,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8586802334090016,
            "auditor_fn_violation": 0.009671097477845945,
            "auditor_fp_violation": 0.01846667496163577,
            "ave_precision_score": 0.8588634991456319,
            "fpr": 0.14692982456140352,
            "logloss": 0.6656780678908238,
            "mae": 0.2776284690842882,
            "precision": 0.7423076923076923,
            "recall": 0.7893660531697342
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8210887082644329,
            "auditor_fn_violation": 0.015240253532098721,
            "auditor_fp_violation": 0.02177422927547219,
            "ave_precision_score": 0.8214365304612836,
            "fpr": 0.17233809001097694,
            "logloss": 0.7094868918173493,
            "mae": 0.28366796834475866,
            "precision": 0.7065420560747664,
            "recall": 0.8129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8582818207344964,
            "auditor_fn_violation": 0.006726940049510284,
            "auditor_fp_violation": 0.0008554186885653855,
            "ave_precision_score": 0.8584700716990209,
            "fpr": 0.006578947368421052,
            "logloss": 1.6117003394284648,
            "mae": 0.3841978796322389,
            "precision": 0.9591836734693877,
            "recall": 0.2883435582822086
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.8288706320707337,
            "auditor_fn_violation": 0.005630112248149862,
            "auditor_fp_violation": 0.0028254566755105755,
            "ave_precision_score": 0.8292194142367891,
            "fpr": 0.008781558726673985,
            "logloss": 1.6987266653068398,
            "mae": 0.3707018398578303,
            "precision": 0.9466666666666667,
            "recall": 0.3053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6560758703871252,
            "auditor_fn_violation": 0.008662056470419404,
            "auditor_fp_violation": 0.011379660735763769,
            "ave_precision_score": 0.6032250022594126,
            "fpr": 0.2774122807017544,
            "logloss": 4.48576621251434,
            "mae": 0.3771118918462379,
            "precision": 0.6178247734138973,
            "recall": 0.83640081799591
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6196123916400286,
            "auditor_fn_violation": 0.004971495343649304,
            "auditor_fp_violation": 0.007319606405024806,
            "ave_precision_score": 0.5626277165667001,
            "fpr": 0.29198682766191,
            "logloss": 5.0298475057558525,
            "mae": 0.385221509065614,
            "precision": 0.6053412462908012,
            "recall": 0.8774193548387097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6663995944847643,
            "auditor_fn_violation": 0.01993192336669896,
            "auditor_fp_violation": 0.017585334494629002,
            "ave_precision_score": 0.66842511947784,
            "fpr": 0.13925438596491227,
            "logloss": 0.660233321990107,
            "mae": 0.4744241016410422,
            "precision": 0.7087155963302753,
            "recall": 0.6319018404907976
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6863124924049548,
            "auditor_fn_violation": 0.013948986697827041,
            "auditor_fp_violation": 0.02561123882000266,
            "ave_precision_score": 0.6874487640306939,
            "fpr": 0.13391877058177826,
            "logloss": 0.6549637212866127,
            "mae": 0.47124569847337433,
            "precision": 0.7162790697674418,
            "recall": 0.6623655913978495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.6864963009743774,
            "auditor_fn_violation": 0.0017691852330211943,
            "auditor_fp_violation": 0.0014231056364315045,
            "ave_precision_score": 0.5444108625045111,
            "fpr": 0.003289473684210526,
            "logloss": 0.6934575998327178,
            "mae": 0.4984299032703826,
            "precision": 0.8235294117647058,
            "recall": 0.028629856850715747
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5715813381760054,
            "auditor_fn_violation": 0.0017539511112684798,
            "auditor_fp_violation": 0.00021166313074382365,
            "ave_precision_score": 0.5134647756863684,
            "fpr": 0.008781558726673985,
            "logloss": 0.695577703441038,
            "mae": 0.49898072759877443,
            "precision": 0.6190476190476191,
            "recall": 0.02795698924731183
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7761284886819361,
            "auditor_fn_violation": 0.00456759229361748,
            "auditor_fp_violation": 0.005148065198457147,
            "ave_precision_score": 0.5641041645543862,
            "fpr": 0.4331140350877193,
            "logloss": 0.7168857280598175,
            "mae": 0.4809209157369639,
            "precision": 0.5496009122006842,
            "recall": 0.9856850715746421
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.747342653436402,
            "auditor_fn_violation": 0.004107503275379768,
            "auditor_fp_violation": 0.0048362564175769025,
            "ave_precision_score": 0.5196588697108313,
            "fpr": 0.4665203073545554,
            "logloss": 0.7450307074633522,
            "mae": 0.4942916258760655,
            "precision": 0.5142857142857142,
            "recall": 0.967741935483871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6998798942106911,
            "mae": 0.49995107041965975,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.700356673650202,
            "mae": 0.5004323083502532,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6966261565052452,
            "mae": 0.49941360391676426,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6978036672984264,
            "mae": 0.5002241882809431,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.8316575666789159,
            "auditor_fn_violation": 0.016400279840706064,
            "auditor_fp_violation": 0.0015734519513914812,
            "ave_precision_score": 0.8318878037513568,
            "fpr": 0.01864035087719298,
            "logloss": 1.9015084815545142,
            "mae": 0.38046050101022133,
            "precision": 0.9034090909090909,
            "recall": 0.32515337423312884
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.8184472951202499,
            "auditor_fn_violation": 0.008753231117878284,
            "auditor_fp_violation": 0.004048672675274301,
            "ave_precision_score": 0.818738935261442,
            "fpr": 0.02305159165751921,
            "logloss": 1.883451409817112,
            "mae": 0.354473880997845,
            "precision": 0.8858695652173914,
            "recall": 0.35053763440860214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8629645259350233,
            "auditor_fn_violation": 0.008280863200947158,
            "auditor_fp_violation": 0.016828418564140857,
            "ave_precision_score": 0.8631443415923652,
            "fpr": 0.14144736842105263,
            "logloss": 0.661769105433055,
            "mae": 0.2747941186500388,
            "precision": 0.7445544554455445,
            "recall": 0.7689161554192229
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8215406056543593,
            "auditor_fn_violation": 0.011607237704047306,
            "auditor_fp_violation": 0.026999355165810996,
            "ave_precision_score": 0.8219410104325755,
            "fpr": 0.15148188803512624,
            "logloss": 0.7177672639192519,
            "mae": 0.2778079915900786,
            "precision": 0.7272727272727273,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7636490354514703,
            "auditor_fn_violation": 0.0008072328059412353,
            "auditor_fp_violation": 0.010487951557380446,
            "ave_precision_score": 0.7639859242456597,
            "fpr": 0.19846491228070176,
            "logloss": 1.1754003571213645,
            "mae": 0.3106739802844554,
            "precision": 0.6846689895470384,
            "recall": 0.803680981595092
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7452591449146516,
            "auditor_fn_violation": 0.004308157171016136,
            "auditor_fp_violation": 0.008259784497398514,
            "ave_precision_score": 0.7456439840174212,
            "fpr": 0.20965971459934138,
            "logloss": 1.2106193063364012,
            "mae": 0.3102362634474565,
            "precision": 0.6718213058419243,
            "recall": 0.8408602150537634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6954299248865105,
            "mae": 0.49912368427765996,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6970239958042821,
            "mae": 0.5001384396061023,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.80863512648446,
            "auditor_fn_violation": 0.015135615111398128,
            "auditor_fp_violation": 0.013414520343411727,
            "ave_precision_score": 0.8089080329930537,
            "fpr": 0.13157894736842105,
            "logloss": 0.775889931073001,
            "mae": 0.3354784370210586,
            "precision": 0.7478991596638656,
            "recall": 0.7280163599182005
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8005089222087685,
            "auditor_fn_violation": 0.011670974823837681,
            "auditor_fp_violation": 0.02094972754524915,
            "ave_precision_score": 0.8007768255049761,
            "fpr": 0.14270032930845225,
            "logloss": 0.7663078103956507,
            "mae": 0.33782057132781573,
            "precision": 0.721030042918455,
            "recall": 0.7225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8577317460252533,
            "auditor_fn_violation": 0.01856635453664837,
            "auditor_fp_violation": 0.01773308863174485,
            "ave_precision_score": 0.8579240532202546,
            "fpr": 0.13048245614035087,
            "logloss": 0.6849356466506688,
            "mae": 0.2768846748058103,
            "precision": 0.7546391752577319,
            "recall": 0.7484662576687117
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8205080409321462,
            "auditor_fn_violation": 0.014347933855033468,
            "auditor_fp_violation": 0.01645065541734555,
            "ave_precision_score": 0.8208678009355322,
            "fpr": 0.15367727771679474,
            "logloss": 0.7168718670264468,
            "mae": 0.28118802205265286,
            "precision": 0.7194388777555111,
            "recall": 0.7720430107526882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6206446202418111,
            "auditor_fn_violation": 0.003610124493237181,
            "auditor_fp_violation": 0.0016952843100659452,
            "ave_precision_score": 0.538998851935565,
            "fpr": 0.003289473684210526,
            "logloss": 0.6932135366627801,
            "mae": 0.4997987716475077,
            "precision": 0.7,
            "recall": 0.014314928425357873
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6136676028641611,
            "auditor_fn_violation": 0.0008498282638716694,
            "auditor_fp_violation": 0.0009401780923737282,
            "ave_precision_score": 0.5128788138525753,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6927954881771663,
            "mae": 0.49965212249598834,
            "precision": 0.7142857142857143,
            "recall": 0.010752688172043012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8053539420055448,
            "auditor_fn_violation": 0.005179743838122915,
            "auditor_fp_violation": 0.009604018912529558,
            "ave_precision_score": 0.8056562203287422,
            "fpr": 0.17543859649122806,
            "logloss": 0.8018740520492491,
            "mae": 0.2966380821209832,
            "precision": 0.7090909090909091,
            "recall": 0.7975460122699386
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7876141607041371,
            "auditor_fn_violation": 0.00584020868005146,
            "auditor_fp_violation": 0.00942639291568424,
            "ave_precision_score": 0.7881118025869304,
            "fpr": 0.19319429198682767,
            "logloss": 0.822581056701444,
            "mae": 0.2968864829710481,
            "precision": 0.6879432624113475,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6984984972576752,
            "mae": 0.49951744608973203,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6987770147603265,
            "mae": 0.4999038191710555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8606845376795509,
            "auditor_fn_violation": 0.005982492017364479,
            "auditor_fp_violation": 0.01864294305503712,
            "ave_precision_score": 0.8610408067214217,
            "fpr": 0.14583333333333334,
            "logloss": 0.617358756583871,
            "mae": 0.275699292760181,
            "precision": 0.7417475728155339,
            "recall": 0.7811860940695297
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8253077073230358,
            "auditor_fn_violation": 0.009617223186147798,
            "auditor_fp_violation": 0.021547798949560184,
            "ave_precision_score": 0.8256518441121776,
            "fpr": 0.1525795828759605,
            "logloss": 0.6750526030964291,
            "mae": 0.28125108383827496,
            "precision": 0.7247524752475247,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5782636984610776,
            "auditor_fn_violation": 0.006800936390054892,
            "auditor_fp_violation": 0.0017341669777280076,
            "ave_precision_score": 0.5803420431477505,
            "fpr": 0.013157894736842105,
            "logloss": 0.6952085291461564,
            "mae": 0.49996717150012654,
            "precision": 0.6,
            "recall": 0.03680981595092025
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5909565526941135,
            "auditor_fn_violation": 0.001827130767324119,
            "auditor_fp_violation": 0.0042135730213189075,
            "ave_precision_score": 0.5931095284046927,
            "fpr": 0.013172338090010977,
            "logloss": 0.6922686138679265,
            "mae": 0.4983166573992414,
            "precision": 0.6666666666666666,
            "recall": 0.05161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8570581612555161,
            "auditor_fn_violation": 0.014631094607684862,
            "auditor_fp_violation": 0.021766517357222855,
            "ave_precision_score": 0.8572483158389996,
            "fpr": 0.13815789473684212,
            "logloss": 0.6868197755670066,
            "mae": 0.2776980280165222,
            "precision": 0.7469879518072289,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8184598854167251,
            "auditor_fn_violation": 0.01461704613859283,
            "auditor_fp_violation": 0.018537752334447436,
            "ave_precision_score": 0.8188272272434167,
            "fpr": 0.1602634467618002,
            "logloss": 0.7262019505411011,
            "mae": 0.2828495010434292,
            "precision": 0.71484375,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.783331641908551,
            "auditor_fn_violation": 0.0049577548164890795,
            "auditor_fp_violation": 0.010156152793330854,
            "ave_precision_score": 0.783662908795208,
            "fpr": 0.19078947368421054,
            "logloss": 0.959935041987271,
            "mae": 0.30757684925787254,
            "precision": 0.6920353982300885,
            "recall": 0.7995910020449898
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7649318448487932,
            "auditor_fn_violation": 0.008441627421125312,
            "auditor_fp_violation": 0.010302579828995887,
            "ave_precision_score": 0.7654222749861197,
            "fpr": 0.20636663007683864,
            "logloss": 0.9833719840765068,
            "mae": 0.3072359094440768,
            "precision": 0.6736111111111112,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5782636984610776,
            "auditor_fn_violation": 0.00724491443332257,
            "auditor_fp_violation": 0.000329206586205467,
            "ave_precision_score": 0.5803420431477505,
            "fpr": 0.01425438596491228,
            "logloss": 0.6947869336238859,
            "mae": 0.4998273314548689,
            "precision": 0.6285714285714286,
            "recall": 0.044989775051124746
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5909565526941135,
            "auditor_fn_violation": 0.0024550594289626327,
            "auditor_fp_violation": 0.00576412851397715,
            "ave_precision_score": 0.5931095284046927,
            "fpr": 0.015367727771679473,
            "logloss": 0.6920570514643607,
            "mae": 0.4982835392004572,
            "precision": 0.6410256410256411,
            "recall": 0.053763440860215055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8670308748682396,
            "auditor_fn_violation": 0.014294747605209341,
            "auditor_fp_violation": 0.004245987308697276,
            "ave_precision_score": 0.8672112215174013,
            "fpr": 0.029605263157894735,
            "logloss": 1.0419835105400725,
            "mae": 0.30084264060500526,
            "precision": 0.906896551724138,
            "recall": 0.5378323108384458
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8448699713531868,
            "auditor_fn_violation": 0.005852011850383017,
            "auditor_fp_violation": 0.0074918903486534795,
            "ave_precision_score": 0.8451260144495771,
            "fpr": 0.03951701427003293,
            "logloss": 1.1708848979913558,
            "mae": 0.2911975065318009,
            "precision": 0.872791519434629,
            "recall": 0.5311827956989247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.6254517081869008,
            "auditor_fn_violation": 0.0056775374017866845,
            "auditor_fp_violation": 0.0036886690722077085,
            "ave_precision_score": 0.627521413941987,
            "fpr": 0.03399122807017544,
            "logloss": 0.6855567908678721,
            "mae": 0.49234618011273834,
            "precision": 0.7350427350427351,
            "recall": 0.17586912065439672
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6421831986156789,
            "auditor_fn_violation": 0.0036471796324492782,
            "auditor_fp_violation": 0.004321865785885516,
            "ave_precision_score": 0.6428562201491961,
            "fpr": 0.030735455543358946,
            "logloss": 0.6780664240675932,
            "mae": 0.48863893577217665,
            "precision": 0.7606837606837606,
            "recall": 0.1913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.80863512648446,
            "auditor_fn_violation": 0.015135615111398128,
            "auditor_fp_violation": 0.013414520343411727,
            "ave_precision_score": 0.8089080329930537,
            "fpr": 0.13157894736842105,
            "logloss": 0.7758890292794353,
            "mae": 0.3354784529037486,
            "precision": 0.7478991596638656,
            "recall": 0.7280163599182005
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8005089222087685,
            "auditor_fn_violation": 0.011670974823837681,
            "auditor_fp_violation": 0.02094972754524915,
            "ave_precision_score": 0.8007768255049761,
            "fpr": 0.14270032930845225,
            "logloss": 0.7663073981621761,
            "mae": 0.33782063002940915,
            "precision": 0.721030042918455,
            "recall": 0.7225806451612903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8545998309832445,
            "auditor_fn_violation": 0.0059466150037671035,
            "auditor_fp_violation": 0.0008554186885653855,
            "ave_precision_score": 0.8547947013969357,
            "fpr": 0.006578947368421052,
            "logloss": 1.6800350394290253,
            "mae": 0.3836221076766127,
            "precision": 0.9591836734693877,
            "recall": 0.2883435582822086
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.8254125673636578,
            "auditor_fn_violation": 0.005623030345950933,
            "auditor_fp_violation": 0.003386610091901178,
            "ave_precision_score": 0.8257642083228829,
            "fpr": 0.009879253567508232,
            "logloss": 1.7581223645720028,
            "mae": 0.3691255292928721,
            "precision": 0.9407894736842105,
            "recall": 0.30752688172043013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6309546520372369,
            "auditor_fn_violation": 0.0012287877157105443,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5563983642641722,
            "fpr": 0.44846491228070173,
            "logloss": 0.7697706828874634,
            "mae": 0.4762110653284349,
            "precision": 0.5435267857142857,
            "recall": 0.9959100204498977
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6198639770026503,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004321865785885522,
            "ave_precision_score": 0.5315752447676136,
            "fpr": 0.47420417124039516,
            "logloss": 0.7983389459914361,
            "mae": 0.490050116956692,
            "precision": 0.5135135135135135,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6050777601158872,
            "auditor_fn_violation": 0.030055968141211926,
            "auditor_fp_violation": 0.010964912280701757,
            "ave_precision_score": 0.6067957641108876,
            "fpr": 0.04276315789473684,
            "logloss": 0.68888055453976,
            "mae": 0.4955442794516944,
            "precision": 0.6388888888888888,
            "recall": 0.1411042944785276
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6134615658471911,
            "auditor_fn_violation": 0.004275108294087796,
            "auditor_fp_violation": 0.0116980797723883,
            "ave_precision_score": 0.615096255513548,
            "fpr": 0.04061470911086718,
            "logloss": 0.6858745458465746,
            "mae": 0.4939971102317785,
            "precision": 0.6336633663366337,
            "recall": 0.13763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5371333076923713,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5417671376882462,
            "fpr": 0.44846491228070173,
            "logloss": 0.7456446178812935,
            "mae": 0.48228596451512556,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.4883874135642556,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5116601882670493,
            "fpr": 0.47310647639956094,
            "logloss": 0.7719341608389214,
            "mae": 0.4944900320076131,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8680670677922693,
            "auditor_fn_violation": 0.006578947368421054,
            "auditor_fp_violation": 0.016424038820455393,
            "ave_precision_score": 0.8682460311904615,
            "fpr": 0.21710526315789475,
            "logloss": 0.5488049929806246,
            "mae": 0.3938144252945979,
            "precision": 0.6826923076923077,
            "recall": 0.8711656441717791
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.831750535958578,
            "auditor_fn_violation": 0.0033284940334973967,
            "auditor_fp_violation": 0.029017538505461397,
            "ave_precision_score": 0.832605051343923,
            "fpr": 0.23710208562019758,
            "logloss": 0.5592381270716764,
            "mae": 0.3975238214102783,
            "precision": 0.6538461538461539,
            "recall": 0.8774193548387097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.8545068284110074,
            "auditor_fn_violation": 0.007821188964230627,
            "auditor_fp_violation": 0.0008320890879681474,
            "ave_precision_score": 0.8547039251274305,
            "fpr": 0.0043859649122807015,
            "logloss": 1.7573790813864583,
            "mae": 0.39999455691283725,
            "precision": 0.9689922480620154,
            "recall": 0.2556237218813906
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.8269229278673675,
            "auditor_fn_violation": 0.004574908820509191,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.8272450108327177,
            "fpr": 0.006586169045005488,
            "logloss": 1.8327858018505494,
            "mae": 0.38579112480859357,
            "precision": 0.9534883720930233,
            "recall": 0.2645161290322581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46710526315789475,
            "auc_prc": 0.5642271919203857,
            "auditor_fn_violation": 0.004453234312775802,
            "auditor_fp_violation": 0.0014593961262494297,
            "ave_precision_score": 0.5400354838300084,
            "fpr": 0.008771929824561403,
            "logloss": 0.6961201741640258,
            "mae": 0.5002042693984613,
            "precision": 0.5789473684210527,
            "recall": 0.022494887525562373
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5963597048966909,
            "auditor_fn_violation": 0.0004390779363337079,
            "auditor_fp_violation": 0.0013487371586932018,
            "ave_precision_score": 0.5177792461810502,
            "fpr": 0.006586169045005488,
            "logloss": 0.6928760050726959,
            "mae": 0.49869487837823895,
            "precision": 0.6666666666666666,
            "recall": 0.025806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8655266468150442,
            "auditor_fn_violation": 0.00552954472069745,
            "auditor_fp_violation": 0.017403882045539387,
            "ave_precision_score": 0.865770650568751,
            "fpr": 0.17105263157894737,
            "logloss": 0.6282417993747558,
            "mae": 0.2773705643341058,
            "precision": 0.7243816254416962,
            "recall": 0.8384458077709611
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8316987680703255,
            "auditor_fn_violation": 0.005474310399773384,
            "auditor_fp_violation": 0.024429863206548757,
            "ave_precision_score": 0.8320051407798411,
            "fpr": 0.18880351262349068,
            "logloss": 0.6949445224912555,
            "mae": 0.28510787385542957,
            "precision": 0.6971830985915493,
            "recall": 0.8516129032258064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7585331372888391,
            "auditor_fn_violation": 0.011998618734976504,
            "auditor_fp_violation": 0.029405665463896145,
            "ave_precision_score": 0.7591439849949743,
            "fpr": 0.2817982456140351,
            "logloss": 0.6158675475222424,
            "mae": 0.430115465279015,
            "precision": 0.6280752532561505,
            "recall": 0.8875255623721882
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7588027727660347,
            "auditor_fn_violation": 0.008281104304616224,
            "auditor_fp_violation": 0.02519283495690441,
            "ave_precision_score": 0.7603033245617578,
            "fpr": 0.305159165751921,
            "logloss": 0.611368063612113,
            "mae": 0.42771495698770234,
            "precision": 0.603988603988604,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.868617267316701,
            "auditor_fn_violation": 0.006578947368421054,
            "auditor_fp_violation": 0.017497200447928338,
            "ave_precision_score": 0.8687953425527393,
            "fpr": 0.2138157894736842,
            "logloss": 0.5475385183707839,
            "mae": 0.3930078820190637,
            "precision": 0.6859903381642513,
            "recall": 0.8711656441717791
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8321882383576762,
            "auditor_fn_violation": 0.0026722377630631574,
            "auditor_fp_violation": 0.028840332163443325,
            "ave_precision_score": 0.8330410057646295,
            "fpr": 0.2349066959385291,
            "logloss": 0.5581192787934776,
            "mae": 0.3967800204990724,
            "precision": 0.6553945249597424,
            "recall": 0.875268817204301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6705278488927618,
            "auditor_fn_violation": 0.0076283500161446575,
            "auditor_fp_violation": 0.010086163991539136,
            "ave_precision_score": 0.5715504429490592,
            "fpr": 0.31798245614035087,
            "logloss": 7.344584070711962,
            "mae": 0.4086251694263825,
            "precision": 0.5949720670391061,
            "recall": 0.8711656441717791
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6406787562982057,
            "auditor_fn_violation": 0.005771750292128467,
            "auditor_fp_violation": 0.00822532770867279,
            "ave_precision_score": 0.5363648098060344,
            "fpr": 0.3424807903402854,
            "logloss": 8.005169052757854,
            "mae": 0.4175343534527868,
            "precision": 0.5737704918032787,
            "recall": 0.9032258064516129
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6304062927318708,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5492174476899899,
            "fpr": 0.44846491228070173,
            "logloss": 0.7474479149925374,
            "mae": 0.4793580858069554,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5579528376679646,
            "auditor_fn_violation": 0.0013455614177968205,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5161335014214303,
            "fpr": 0.47310647639956094,
            "logloss": 0.7770836847816699,
            "mae": 0.49298589525316994,
            "precision": 0.5135440180586908,
            "recall": 0.978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.5767689617655611,
            "auditor_fn_violation": 0.00311457324292326,
            "auditor_fp_violation": 0.00041474845506200494,
            "ave_precision_score": 0.5788964811967293,
            "fpr": 0.01425438596491228,
            "logloss": 0.6956651485953763,
            "mae": 0.49999752199571385,
            "precision": 0.5806451612903226,
            "recall": 0.03680981595092025
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5964797424829061,
            "auditor_fn_violation": 0.0018767040827166294,
            "auditor_fp_violation": 0.0029583614320241396,
            "ave_precision_score": 0.5985198565754601,
            "fpr": 0.008781558726673985,
            "logloss": 0.6913290943495456,
            "mae": 0.49784968016438114,
            "precision": 0.7241379310344828,
            "recall": 0.04516129032258064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8570447156194958,
            "auditor_fn_violation": 0.004572076920317152,
            "auditor_fp_violation": 0.02189094189374145,
            "ave_precision_score": 0.8572347533903673,
            "fpr": 0.1524122807017544,
            "logloss": 0.6737965297503749,
            "mae": 0.27811298705257703,
            "precision": 0.7362428842504743,
            "recall": 0.7934560327198364
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8195370412157438,
            "auditor_fn_violation": 0.011883431889805606,
            "auditor_fp_violation": 0.01803566769872953,
            "ave_precision_score": 0.8199085218405842,
            "fpr": 0.1690450054884742,
            "logloss": 0.7107147566509352,
            "mae": 0.28281667271523425,
            "precision": 0.7105263157894737,
            "recall": 0.8129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6206446202418111,
            "auditor_fn_violation": 0.003610124493237181,
            "auditor_fp_violation": 0.0016952843100659452,
            "ave_precision_score": 0.538998851935565,
            "fpr": 0.003289473684210526,
            "logloss": 0.6931523642962791,
            "mae": 0.49981011443755086,
            "precision": 0.7,
            "recall": 0.014314928425357873
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6136676028641611,
            "auditor_fn_violation": 0.0008498282638716694,
            "auditor_fp_violation": 0.0009401780923737282,
            "ave_precision_score": 0.5128788138525753,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6927936662151613,
            "mae": 0.499682348495519,
            "precision": 0.7142857142857143,
            "recall": 0.010752688172043012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8614766386806838,
            "auditor_fn_violation": 0.00867551035051842,
            "auditor_fp_violation": 0.01807784828501514,
            "ave_precision_score": 0.8617988202612268,
            "fpr": 0.14583333333333334,
            "logloss": 0.6141061241762936,
            "mae": 0.27497188339558515,
            "precision": 0.7422480620155039,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8219425066484074,
            "auditor_fn_violation": 0.010757409440175633,
            "auditor_fp_violation": 0.022081879174809135,
            "ave_precision_score": 0.8224866036049662,
            "fpr": 0.15367727771679474,
            "logloss": 0.6706852777450728,
            "mae": 0.28087742159025014,
            "precision": 0.7238658777120316,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6161453041301096,
            "auditor_fn_violation": 0.0012287877157105443,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5512392100544359,
            "fpr": 0.44846491228070173,
            "logloss": 0.7910461718931258,
            "mae": 0.47554019956212296,
            "precision": 0.5435267857142857,
            "recall": 0.9959100204498977
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6114497270396692,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.527973914216764,
            "fpr": 0.47310647639956094,
            "logloss": 0.8231649111403381,
            "mae": 0.4899816487544716,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.8508277590921277,
            "auditor_fn_violation": 0.009310085028522232,
            "auditor_fp_violation": 0.0008554186885653855,
            "ave_precision_score": 0.8510310136136707,
            "fpr": 0.006578947368421052,
            "logloss": 1.8958499955971522,
            "mae": 0.3995713867191738,
            "precision": 0.9534883720930233,
            "recall": 0.25153374233128833
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8244687486052622,
            "auditor_fn_violation": 0.0060715508185498705,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.824790199584419,
            "fpr": 0.006586169045005488,
            "logloss": 1.9474765638813587,
            "mae": 0.3827464117533089,
            "precision": 0.9552238805970149,
            "recall": 0.2752688172043011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6291834706046558,
            "auditor_fn_violation": 0.02492555519678542,
            "auditor_fp_violation": 0.028936481274107258,
            "ave_precision_score": 0.6310980076327706,
            "fpr": 0.2850877192982456,
            "logloss": 0.6866075353341532,
            "mae": 0.46554803315615445,
            "precision": 0.6012269938650306,
            "recall": 0.8016359918200409
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6621981185790252,
            "auditor_fn_violation": 0.009749418693861174,
            "auditor_fp_violation": 0.03328525790906361,
            "ave_precision_score": 0.6634573025048742,
            "fpr": 0.30954994511525796,
            "logloss": 0.6687735747955696,
            "mae": 0.46255984405131295,
            "precision": 0.5828402366863905,
            "recall": 0.8473118279569892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6184257882554824,
            "auditor_fn_violation": 0.0012287877157105443,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5514281311998996,
            "fpr": 0.44846491228070173,
            "logloss": 0.770940412397584,
            "mae": 0.4772342162435515,
            "precision": 0.5435267857142857,
            "recall": 0.9959100204498977
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5855368812586227,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5223335785174463,
            "fpr": 0.47310647639956094,
            "logloss": 0.8025405702600864,
            "mae": 0.4914180576212451,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.63006693498874,
            "auditor_fn_violation": 0.02550855666774298,
            "auditor_fp_violation": 0.04665920119447555,
            "ave_precision_score": 0.6319840096758687,
            "fpr": 0.2138157894736842,
            "logloss": 0.6830767158178308,
            "mae": 0.4669569524560581,
            "precision": 0.644808743169399,
            "recall": 0.7239263803680982
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6634712723154332,
            "auditor_fn_violation": 0.006149451742738102,
            "auditor_fp_violation": 0.028700043809345672,
            "ave_precision_score": 0.6646764315108438,
            "fpr": 0.23600439077936333,
            "logloss": 0.6619874676432115,
            "mae": 0.46227286070683393,
            "precision": 0.6214788732394366,
            "recall": 0.7591397849462366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.8492927429684297,
            "auditor_fn_violation": 0.010897642880206667,
            "auditor_fp_violation": 0.00230963045912654,
            "ave_precision_score": 0.8494978849307284,
            "fpr": 0.008771929824561403,
            "logloss": 1.5428783026144466,
            "mae": 0.38009135166757896,
            "precision": 0.9487179487179487,
            "recall": 0.30265848670756645
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.8216610876822887,
            "auditor_fn_violation": 0.006996919372543487,
            "auditor_fp_violation": 0.0030814213917589204,
            "ave_precision_score": 0.8220011441014206,
            "fpr": 0.010976948408342482,
            "logloss": 1.6365722247948176,
            "mae": 0.3662756032132414,
            "precision": 0.9386503067484663,
            "recall": 0.32903225806451614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8620669474611569,
            "auditor_fn_violation": 0.01029221827575073,
            "auditor_fp_violation": 0.018033781261664803,
            "ave_precision_score": 0.8622482101058021,
            "fpr": 0.13815789473684212,
            "logloss": 0.6697697346837026,
            "mae": 0.2755603340460846,
            "precision": 0.7469879518072289,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8213754813145067,
            "auditor_fn_violation": 0.01366098934173719,
            "auditor_fp_violation": 0.026477580936535516,
            "ave_precision_score": 0.821750374331812,
            "fpr": 0.150384193194292,
            "logloss": 0.7240835667404807,
            "mae": 0.27839075916710115,
            "precision": 0.7276341948310139,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8687117966136916,
            "auditor_fn_violation": 0.008449036702184913,
            "auditor_fp_violation": 0.005889428061880471,
            "ave_precision_score": 0.8688882054216925,
            "fpr": 0.043859649122807015,
            "logloss": 0.9491864492870026,
            "mae": 0.2836774423819662,
            "precision": 0.8780487804878049,
            "recall": 0.588957055214724
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8453206103366652,
            "auditor_fn_violation": 0.004390779363336999,
            "auditor_fp_violation": 0.00968235763193258,
            "ave_precision_score": 0.845565377667208,
            "fpr": 0.04939626783754116,
            "logloss": 1.0976907332692083,
            "mae": 0.27600116916259093,
            "precision": 0.8636363636363636,
            "recall": 0.6129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.796369884539178,
            "auditor_fn_violation": 0.01484635668926919,
            "auditor_fp_violation": 0.03329911658579072,
            "ave_precision_score": 0.7966481178533407,
            "fpr": 0.16228070175438597,
            "logloss": 0.7967022211811845,
            "mae": 0.3632521195452826,
            "precision": 0.7051792828685259,
            "recall": 0.7239263803680982
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7878101839332402,
            "auditor_fn_violation": 0.011933005205198119,
            "auditor_fp_violation": 0.014270032930845226,
            "ave_precision_score": 0.7880826046957006,
            "fpr": 0.18221734357848518,
            "logloss": 0.7867343286564188,
            "mae": 0.3647708969786722,
            "precision": 0.6732283464566929,
            "recall": 0.7354838709677419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6050777601158872,
            "auditor_fn_violation": 0.030055968141211926,
            "auditor_fp_violation": 0.010964912280701757,
            "ave_precision_score": 0.6067957641108876,
            "fpr": 0.04276315789473684,
            "logloss": 0.6888850608768669,
            "mae": 0.49554473779311303,
            "precision": 0.6388888888888888,
            "recall": 0.1411042944785276
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6134615658471911,
            "auditor_fn_violation": 0.004275108294087796,
            "auditor_fp_violation": 0.0116980797723883,
            "ave_precision_score": 0.6150962555135481,
            "fpr": 0.04061470911086718,
            "logloss": 0.6858703594978366,
            "mae": 0.4939931399147021,
            "precision": 0.6336633663366337,
            "recall": 0.13763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.83394534617386,
            "auditor_fn_violation": 0.016898073404369815,
            "auditor_fp_violation": 0.003393160797976027,
            "ave_precision_score": 0.8343284129918671,
            "fpr": 0.0537280701754386,
            "logloss": 0.5813319887927013,
            "mae": 0.41879839981138184,
            "precision": 0.8591954022988506,
            "recall": 0.6114519427402862
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8102367128603949,
            "auditor_fn_violation": 0.007178688195649353,
            "auditor_fp_violation": 0.007083331282334007,
            "ave_precision_score": 0.8106999487571556,
            "fpr": 0.07244785949506037,
            "logloss": 0.5821976027292096,
            "mae": 0.4206549257661587,
            "precision": 0.8191780821917808,
            "recall": 0.6430107526881721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.6161453041301096,
            "auditor_fn_violation": 0.0012287877157105443,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5512392100544359,
            "fpr": 0.44846491228070173,
            "logloss": 0.7917164023883214,
            "mae": 0.475493355801231,
            "precision": 0.5435267857142857,
            "recall": 0.9959100204498977
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.6114497270396692,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.527973914216764,
            "fpr": 0.47310647639956094,
            "logloss": 0.8239247999930784,
            "mae": 0.4899705870222182,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6988732781334368,
            "mae": 0.499705495198437,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6997081201031294,
            "mae": 0.5003657205404487,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.8508243372479215,
            "auditor_fn_violation": 0.009310085028522232,
            "auditor_fp_violation": 0.0008554186885653855,
            "ave_precision_score": 0.8510275926648596,
            "fpr": 0.006578947368421052,
            "logloss": 1.8942092069284775,
            "mae": 0.39943345900805977,
            "precision": 0.9534883720930233,
            "recall": 0.25153374233128833
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8244664788009981,
            "auditor_fn_violation": 0.0060715508185498705,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.8247879306311907,
            "fpr": 0.006586169045005488,
            "logloss": 1.9459341378389006,
            "mae": 0.3826084382893095,
            "precision": 0.9552238805970149,
            "recall": 0.2752688172043011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.5746795306527152,
            "auditor_fn_violation": 0.00727854913357012,
            "auditor_fp_violation": 0.0028021442495126704,
            "ave_precision_score": 0.5405333159604729,
            "fpr": 0.010964912280701754,
            "logloss": 0.696371967126801,
            "mae": 0.5002547321808443,
            "precision": 0.6,
            "recall": 0.03067484662576687
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.577423423207221,
            "auditor_fn_violation": 0.0026793196652621014,
            "auditor_fp_violation": 0.0042135730213189075,
            "ave_precision_score": 0.5196916290386694,
            "fpr": 0.013172338090010977,
            "logloss": 0.6929047641258589,
            "mae": 0.4986356112750249,
            "precision": 0.625,
            "recall": 0.043010752688172046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.519146553850135,
            "mae": 0.5361842105263158,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.629562045700844,
            "mae": 0.5104281009879253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8105191012096599,
            "auditor_fn_violation": 0.015424873533527074,
            "auditor_fp_violation": 0.013772240885902705,
            "ave_precision_score": 0.8108037951909498,
            "fpr": 0.13157894736842105,
            "logloss": 0.7582771731758675,
            "mae": 0.33216533273538845,
            "precision": 0.7452229299363057,
            "recall": 0.7177914110429447
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.802312464954811,
            "auditor_fn_violation": 0.016064114821240986,
            "auditor_fp_violation": 0.014619523216492004,
            "ave_precision_score": 0.8025842425557628,
            "fpr": 0.141602634467618,
            "logloss": 0.7474460737369377,
            "mae": 0.3336862715240976,
            "precision": 0.7195652173913043,
            "recall": 0.7118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.8545122362958373,
            "auditor_fn_violation": 0.007821188964230627,
            "auditor_fp_violation": 0.0008320890879681474,
            "ave_precision_score": 0.8547093260289604,
            "fpr": 0.0043859649122807015,
            "logloss": 1.7573837326696669,
            "mae": 0.39999415046601156,
            "precision": 0.9689922480620154,
            "recall": 0.2556237218813906
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.8269229278673675,
            "auditor_fn_violation": 0.004574908820509191,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.8272450108327177,
            "fpr": 0.006586169045005488,
            "logloss": 1.8327874263584885,
            "mae": 0.38579003960862385,
            "precision": 0.9534883720930233,
            "recall": 0.2645161290322581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 24284,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.8278519573248442,
            "auditor_fn_violation": 0.018005776199189208,
            "auditor_fp_violation": 0.0015734519513914812,
            "ave_precision_score": 0.8280948382063413,
            "fpr": 0.01864035087719298,
            "logloss": 1.8996026885298933,
            "mae": 0.3810129825481843,
            "precision": 0.9028571428571428,
            "recall": 0.3231083844580777
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.8169414034459133,
            "auditor_fn_violation": 0.006437449098827964,
            "auditor_fp_violation": 0.003467829665326134,
            "ave_precision_score": 0.8172290842157991,
            "fpr": 0.025246981339187707,
            "logloss": 1.8825641031063292,
            "mae": 0.354191539828579,
            "precision": 0.8802083333333334,
            "recall": 0.3634408602150538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 24284,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7103934511901954,
            "auditor_fn_violation": 0.059181376242241596,
            "auditor_fp_violation": 0.0403498403218448,
            "ave_precision_score": 0.711770444335124,
            "fpr": 0.0800438596491228,
            "logloss": 0.9852835044315952,
            "mae": 0.3960831872929268,
            "precision": 0.7807807807807807,
            "recall": 0.5316973415132924
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6762101188881774,
            "auditor_fn_violation": 0.045869480542473716,
            "auditor_fp_violation": 0.05014693359192333,
            "ave_precision_score": 0.6776879806701965,
            "fpr": 0.09769484083424808,
            "logloss": 0.9621577826430149,
            "mae": 0.3902259572094253,
            "precision": 0.7397660818713451,
            "recall": 0.5440860215053763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8297092769761699,
            "auditor_fn_violation": 0.019232321601549897,
            "auditor_fp_violation": 0.01023391812865497,
            "ave_precision_score": 0.8299378938236474,
            "fpr": 0.051535087719298246,
            "logloss": 1.0892225136754867,
            "mae": 0.3135565595435199,
            "precision": 0.8474025974025974,
            "recall": 0.5337423312883436
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8164422897254873,
            "auditor_fn_violation": 0.005457785961309214,
            "auditor_fp_violation": 0.003928073914734216,
            "ave_precision_score": 0.8167428275246291,
            "fpr": 0.059275521405049394,
            "logloss": 1.1327745869378392,
            "mae": 0.30202398067775227,
            "precision": 0.8258064516129032,
            "recall": 0.5505376344086022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8550989094910513,
            "auditor_fn_violation": 0.010332579916047786,
            "auditor_fp_violation": 0.017839367923354485,
            "ave_precision_score": 0.8553837188598885,
            "fpr": 0.14035087719298245,
            "logloss": 0.6769654287995523,
            "mae": 0.2679510079665545,
            "precision": 0.7504873294346979,
            "recall": 0.787321063394683
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8262056211229183,
            "auditor_fn_violation": 0.009001097694840835,
            "auditor_fp_violation": 0.023597977878741648,
            "ave_precision_score": 0.8265196446354287,
            "fpr": 0.14709110867178923,
            "logloss": 0.7280141477692448,
            "mae": 0.2708212727271846,
            "precision": 0.7351778656126482,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 24284,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5782636984610776,
            "auditor_fn_violation": 0.006800936390054892,
            "auditor_fp_violation": 0.0017341669777280076,
            "ave_precision_score": 0.5803420431477505,
            "fpr": 0.013157894736842105,
            "logloss": 0.6952085293338653,
            "mae": 0.4999671715654825,
            "precision": 0.6,
            "recall": 0.03680981595092025
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5909565526941135,
            "auditor_fn_violation": 0.001827130767324119,
            "auditor_fp_violation": 0.0042135730213189075,
            "ave_precision_score": 0.5931095284046927,
            "fpr": 0.013172338090010977,
            "logloss": 0.692268614373438,
            "mae": 0.49831665766095223,
            "precision": 0.6666666666666666,
            "recall": 0.05161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.519146553850135,
            "mae": 0.5361842105263158,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.629562045700844,
            "mae": 0.5104281009879253,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6774355982066356,
            "auditor_fn_violation": 0.004486869013023358,
            "auditor_fp_violation": 0.025061175397121653,
            "ave_precision_score": 0.6793841445650953,
            "fpr": 0.3442982456140351,
            "logloss": 0.6896257822435952,
            "mae": 0.4378353530222452,
            "precision": 0.5785234899328859,
            "recall": 0.8813905930470347
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6968878924918263,
            "auditor_fn_violation": 0.00210804622121502,
            "auditor_fp_violation": 0.015751674846052,
            "ave_precision_score": 0.6983848681526368,
            "fpr": 0.3600439077936334,
            "logloss": 0.6653626173832464,
            "mae": 0.4297947627252007,
            "precision": 0.5655629139072847,
            "recall": 0.9182795698924732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 24284,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6984961013980935,
            "mae": 0.4995156116456839,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6987695253079019,
            "mae": 0.49989953990432745,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8583505007000657,
            "auditor_fn_violation": 0.006726940049510284,
            "auditor_fp_violation": 0.0008554186885653855,
            "ave_precision_score": 0.8585386326871263,
            "fpr": 0.006578947368421052,
            "logloss": 1.606078207592071,
            "mae": 0.38388039318858236,
            "precision": 0.9591836734693877,
            "recall": 0.2883435582822086
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8290508771772127,
            "auditor_fn_violation": 0.005788274730592646,
            "auditor_fp_violation": 0.0028254566755105755,
            "ave_precision_score": 0.8293993684601068,
            "fpr": 0.008781558726673985,
            "logloss": 1.6933310833643067,
            "mae": 0.37036526513671386,
            "precision": 0.9470198675496688,
            "recall": 0.30752688172043013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8640300059566908,
            "auditor_fn_violation": 0.013713988447601624,
            "auditor_fp_violation": 0.010150968437642575,
            "ave_precision_score": 0.8642215547748212,
            "fpr": 0.17653508771929824,
            "logloss": 0.5345758035400698,
            "mae": 0.3829598249030185,
            "precision": 0.7160493827160493,
            "recall": 0.8302658486707567
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8368611182987129,
            "auditor_fn_violation": 0.0033922311532877773,
            "auditor_fp_violation": 0.01527174100308635,
            "ave_precision_score": 0.8376117469656568,
            "fpr": 0.1942919868276619,
            "logloss": 0.5412457895109867,
            "mae": 0.38482724013201625,
            "precision": 0.6889279437609842,
            "recall": 0.843010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8606788894816856,
            "auditor_fn_violation": 0.005982492017364479,
            "auditor_fp_violation": 0.01864294305503712,
            "ave_precision_score": 0.8610351631812803,
            "fpr": 0.14583333333333334,
            "logloss": 0.6175077553288164,
            "mae": 0.2757049302030314,
            "precision": 0.7417475728155339,
            "recall": 0.7811860940695297
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8252687530730953,
            "auditor_fn_violation": 0.009617223186147798,
            "auditor_fp_violation": 0.021547798949560184,
            "ave_precision_score": 0.8256168880062872,
            "fpr": 0.1525795828759605,
            "logloss": 0.6751901890859507,
            "mae": 0.2812517505513469,
            "precision": 0.7247524752475247,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.8551220773119369,
            "auditor_fn_violation": 0.007392907114411795,
            "auditor_fp_violation": 0.0008320890879681474,
            "ave_precision_score": 0.8553179926814757,
            "fpr": 0.0043859649122807015,
            "logloss": 1.7522716182635154,
            "mae": 0.4000269546480909,
            "precision": 0.968503937007874,
            "recall": 0.25153374233128833
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.8263969097485684,
            "auditor_fn_violation": 0.005665521759144521,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.8267183719788512,
            "fpr": 0.006586169045005488,
            "logloss": 1.8301212703732848,
            "mae": 0.3853843955441979,
            "precision": 0.9541984732824428,
            "recall": 0.26881720430107525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8555683568305842,
            "auditor_fn_violation": 0.00802523947906578,
            "auditor_fp_violation": 0.0008320890879681474,
            "ave_precision_score": 0.8557621855099066,
            "fpr": 0.0043859649122807015,
            "logloss": 1.7631957764160835,
            "mae": 0.40076021942386014,
            "precision": 0.96875,
            "recall": 0.25357873210633947
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.8273006123124784,
            "auditor_fn_violation": 0.010559116178605598,
            "auditor_fp_violation": 0.002727008707722751,
            "ave_precision_score": 0.8276341162774099,
            "fpr": 0.006586169045005488,
            "logloss": 1.837885272015986,
            "mae": 0.3859373071906597,
            "precision": 0.9548872180451128,
            "recall": 0.2731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5880673985818226,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5441408863837583,
            "fpr": 0.44846491228070173,
            "logloss": 0.6903071779091232,
            "mae": 0.4976179061228769,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5105026174938518,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5132772808270476,
            "fpr": 0.47310647639956094,
            "logloss": 0.6939978759868751,
            "mae": 0.4993946062223055,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5880673985818226,
            "auditor_fn_violation": 0.002260251856635454,
            "auditor_fp_violation": 0.005137696487080594,
            "ave_precision_score": 0.5441408863837583,
            "fpr": 0.44846491228070173,
            "logloss": 0.7615938496640352,
            "mae": 0.4797913543879986,
            "precision": 0.5425055928411633,
            "recall": 0.9918200408997955
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.49424663958609016,
            "auditor_fn_violation": 0.0019758507135016466,
            "auditor_fp_violation": 0.004865790807913256,
            "ave_precision_score": 0.5127792088436562,
            "fpr": 0.47310647639956094,
            "logloss": 0.7908275557128399,
            "mae": 0.49351533975873374,
            "precision": 0.5140924464487034,
            "recall": 0.9806451612903225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8632120049344358,
            "auditor_fn_violation": 0.006007157464212688,
            "auditor_fp_violation": 0.004790344655966157,
            "ave_precision_score": 0.8633953483123569,
            "fpr": 0.03837719298245614,
            "logloss": 1.0124180711561421,
            "mae": 0.293498247697471,
            "precision": 0.890282131661442,
            "recall": 0.5807770961145194
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8356800823079076,
            "auditor_fn_violation": 0.008512446443114625,
            "auditor_fp_violation": 0.006500027073191141,
            "ave_precision_score": 0.8359675686448849,
            "fpr": 0.05159165751920966,
            "logloss": 1.158399358728607,
            "mae": 0.29108402176472004,
            "precision": 0.8459016393442623,
            "recall": 0.5548387096774193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8598394789939197,
            "auditor_fn_violation": 0.0177994833710042,
            "auditor_fp_violation": 0.021852059226079388,
            "ave_precision_score": 0.8600280934856254,
            "fpr": 0.13267543859649122,
            "logloss": 0.6589006573940411,
            "mae": 0.27645930500537425,
            "precision": 0.7525562372188139,
            "recall": 0.7525562372188139
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8241258105453005,
            "auditor_fn_violation": 0.01606883608937361,
            "auditor_fp_violation": 0.01747451428233893,
            "ave_precision_score": 0.8244717870933921,
            "fpr": 0.15477497255762898,
            "logloss": 0.6913256866689133,
            "mae": 0.28061276356171516,
            "precision": 0.7202380952380952,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8426984223801568,
            "auditor_fn_violation": 0.009168819287482515,
            "auditor_fp_violation": 0.005933495085230809,
            "ave_precision_score": 0.8428458243942222,
            "fpr": 0.0537280701754386,
            "logloss": 0.5604771520504004,
            "mae": 0.4010032300771982,
            "precision": 0.8595988538681948,
            "recall": 0.6134969325153374
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8132568037348579,
            "auditor_fn_violation": 0.008276383036483599,
            "auditor_fp_violation": 0.006674772216014533,
            "ave_precision_score": 0.8135426644294903,
            "fpr": 0.06805708013172337,
            "logloss": 0.5637584607705896,
            "mae": 0.40411847178813,
            "precision": 0.8282548476454293,
            "recall": 0.6430107526881721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 24284,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.6206446202418111,
            "auditor_fn_violation": 0.003610124493237181,
            "auditor_fp_violation": 0.0016952843100659452,
            "ave_precision_score": 0.538998851935565,
            "fpr": 0.003289473684210526,
            "logloss": 0.6931523642962791,
            "mae": 0.49981011443755086,
            "precision": 0.7,
            "recall": 0.014314928425357873
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.6136676028641611,
            "auditor_fn_violation": 0.0008498282638716694,
            "auditor_fp_violation": 0.0009401780923737282,
            "ave_precision_score": 0.5128788138525753,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6927936662151613,
            "mae": 0.499682348495519,
            "precision": 0.7142857142857143,
            "recall": 0.010752688172043012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.8513695845509317,
            "auditor_fn_violation": 0.0066551860223155075,
            "auditor_fp_violation": 0.00230963045912654,
            "ave_precision_score": 0.851571551025429,
            "fpr": 0.008771929824561403,
            "logloss": 1.6488058233622116,
            "mae": 0.38658516724347,
            "precision": 0.9455782312925171,
            "recall": 0.2842535787321063
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.8226181561728214,
            "auditor_fn_violation": 0.006605054117535968,
            "auditor_fp_violation": 0.0030814213917589204,
            "ave_precision_score": 0.8229651529810997,
            "fpr": 0.010976948408342482,
            "logloss": 1.7352435809740867,
            "mae": 0.37181893165997226,
            "precision": 0.9358974358974359,
            "recall": 0.3139784946236559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8653554656701324,
            "auditor_fn_violation": 0.00841315968858752,
            "auditor_fp_violation": 0.019907925842976234,
            "ave_precision_score": 0.8655701785488428,
            "fpr": 0.14473684210526316,
            "logloss": 0.6017843615472532,
            "mae": 0.2762013227977405,
            "precision": 0.7431906614785992,
            "recall": 0.7811860940695297
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8278822262969239,
            "auditor_fn_violation": 0.00885237774866329,
            "auditor_fp_violation": 0.025909043922560836,
            "ave_precision_score": 0.8282269326064424,
            "fpr": 0.15477497255762898,
            "logloss": 0.6579108128031727,
            "mae": 0.2812462125291601,
            "precision": 0.7224409448818898,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6781222731865615,
            "auditor_fn_violation": 0.004486869013023358,
            "auditor_fp_violation": 0.024783812367798943,
            "ave_precision_score": 0.6800705271698886,
            "fpr": 0.34100877192982454,
            "logloss": 0.6877616874900415,
            "mae": 0.4376022384865536,
            "precision": 0.5808625336927223,
            "recall": 0.8813905930470347
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6975805592481965,
            "auditor_fn_violation": 0.002337027725647111,
            "auditor_fp_violation": 0.014469390065615572,
            "ave_precision_score": 0.6990682611116557,
            "fpr": 0.3567508232711306,
            "logloss": 0.6635296249011563,
            "mae": 0.4294328021762727,
            "precision": 0.5672436750998668,
            "recall": 0.9161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.8427576849852096,
            "auditor_fn_violation": 0.005724625982133248,
            "auditor_fp_violation": 0.00293952967525196,
            "ave_precision_score": 0.8429719163279206,
            "fpr": 0.009868421052631578,
            "logloss": 1.6316659165674832,
            "mae": 0.3940295227482573,
            "precision": 0.9361702127659575,
            "recall": 0.26993865030674846
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.8157416217136215,
            "auditor_fn_violation": 0.006258040909788381,
            "auditor_fp_violation": 0.003342308506396657,
            "ave_precision_score": 0.8160871454495441,
            "fpr": 0.009879253567508232,
            "logloss": 1.7184736168627452,
            "mae": 0.37915919872202786,
            "precision": 0.9383561643835616,
            "recall": 0.2946236559139785
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.81051159733449,
            "auditor_fn_violation": 0.015424873533527074,
            "auditor_fp_violation": 0.013772240885902705,
            "ave_precision_score": 0.8107963046630629,
            "fpr": 0.13157894736842105,
            "logloss": 0.7582580755692243,
            "mae": 0.33216300445537966,
            "precision": 0.7452229299363057,
            "recall": 0.7177914110429447
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8023142494294054,
            "auditor_fn_violation": 0.016064114821240986,
            "auditor_fp_violation": 0.014619523216492004,
            "ave_precision_score": 0.8025860265487711,
            "fpr": 0.141602634467618,
            "logloss": 0.7474303049347685,
            "mae": 0.3336848324732824,
            "precision": 0.7195652173913043,
            "recall": 0.7118279569892473
        }
    }
]