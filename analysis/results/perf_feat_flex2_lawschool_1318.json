[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.780333088652368,
            "auditor_fn_violation": 0.01595953240690083,
            "auditor_fp_violation": 0.020380490088329876,
            "ave_precision_score": 0.753131672062943,
            "fpr": 0.15570175438596492,
            "logloss": 3.1123980029333085,
            "mae": 0.2984536156060018,
            "precision": 0.7199211045364892,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7889211529828799,
            "auditor_fn_violation": 0.015372369187496961,
            "auditor_fp_violation": 0.021638121588499766,
            "ave_precision_score": 0.7614207160906654,
            "fpr": 0.15148188803512624,
            "logloss": 2.8737177267328353,
            "mae": 0.2805702940426581,
            "precision": 0.7309941520467836,
            "recall": 0.7928118393234672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7762700912647065,
            "auditor_fn_violation": 0.014876718824087252,
            "auditor_fp_violation": 0.020306712256278746,
            "ave_precision_score": 0.7784838270603083,
            "fpr": 0.15899122807017543,
            "logloss": 1.2314039072651415,
            "mae": 0.2977871845531379,
            "precision": 0.7151277013752456,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7895125123548172,
            "auditor_fn_violation": 0.011754385557770542,
            "auditor_fp_violation": 0.025545213499140393,
            "ave_precision_score": 0.7909485672531174,
            "fpr": 0.15916575192096596,
            "logloss": 1.0899136882274454,
            "mae": 0.27648884347154423,
            "precision": 0.7162426614481409,
            "recall": 0.773784355179704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7791422819111016,
            "auditor_fn_violation": 0.016914687967319552,
            "auditor_fp_violation": 0.012420116416330848,
            "ave_precision_score": 0.7639473713828591,
            "fpr": 0.16337719298245615,
            "logloss": 1.8013200065181492,
            "mae": 0.29737894280686006,
            "precision": 0.708984375,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7928598548853679,
            "auditor_fn_violation": 0.01140627937145948,
            "auditor_fp_violation": 0.025342215138164207,
            "ave_precision_score": 0.7829872066565823,
            "fpr": 0.15587266739846323,
            "logloss": 1.4657622359769984,
            "mae": 0.27694647574792813,
            "precision": 0.72265625,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.8139792479090512,
            "auditor_fn_violation": 0.005304646752015174,
            "auditor_fp_violation": 0.02055603044734808,
            "ave_precision_score": 0.8141917475246545,
            "fpr": 0.3651315789473684,
            "logloss": 2.0366119339925994,
            "mae": 0.37574161304173176,
            "precision": 0.5853051058530511,
            "recall": 0.9771309771309772
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.8171844005661534,
            "auditor_fn_violation": 0.005732148534588991,
            "auditor_fp_violation": 0.024590369356770878,
            "ave_precision_score": 0.8172328853039231,
            "fpr": 0.37102085620197583,
            "logloss": 2.001409525272203,
            "mae": 0.37994140464263054,
            "precision": 0.5780274656679151,
            "recall": 0.9788583509513742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7754650703817746,
            "auditor_fn_violation": 0.013217164532954021,
            "auditor_fp_violation": 0.007695791101884645,
            "ave_precision_score": 0.7700909071827997,
            "fpr": 0.09649122807017543,
            "logloss": 1.312689293474088,
            "mae": 0.32224625358914055,
            "precision": 0.7647058823529411,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7675764901336737,
            "auditor_fn_violation": 0.019890787485814673,
            "auditor_fp_violation": 0.007122485702399398,
            "ave_precision_score": 0.7630810879208005,
            "fpr": 0.10757409440175632,
            "logloss": 1.1748140290617255,
            "mae": 0.3222352089315571,
            "precision": 0.7493606138107417,
            "recall": 0.6194503171247357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7608275493120218,
            "auditor_fn_violation": 0.018049932523616738,
            "auditor_fp_violation": 0.021184414051369727,
            "ave_precision_score": 0.750100425979148,
            "fpr": 0.19298245614035087,
            "logloss": 1.70993241404047,
            "mae": 0.3277856340011653,
            "precision": 0.6776556776556777,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7594637694252571,
            "auditor_fn_violation": 0.01713842790604846,
            "auditor_fp_violation": 0.025241969033978424,
            "ave_precision_score": 0.7512362323176132,
            "fpr": 0.19538968166849616,
            "logloss": 1.5503740344921972,
            "mae": 0.31199995697385025,
            "precision": 0.6798561151079137,
            "recall": 0.7991543340380549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7840490029149448,
            "auditor_fn_violation": 0.032678174125542546,
            "auditor_fp_violation": 0.01870395245654741,
            "ave_precision_score": 0.7753285507582326,
            "fpr": 0.12280701754385964,
            "logloss": 1.926114032126722,
            "mae": 0.2907527358673096,
            "precision": 0.7601713062098501,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7974797179647151,
            "auditor_fn_violation": 0.030331652367238098,
            "auditor_fp_violation": 0.021347407886361018,
            "ave_precision_score": 0.7920754486820313,
            "fpr": 0.1207464324917673,
            "logloss": 1.6432224831092133,
            "mae": 0.2760388955792306,
            "precision": 0.7624190064794817,
            "recall": 0.7463002114164905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 1318,
        "test": {
            "accuracy": 0.38706140350877194,
            "auc_prc": 0.4446649252027127,
            "auditor_fn_violation": 0.004258306889885852,
            "auditor_fp_violation": 0.011300728619693095,
            "ave_precision_score": 0.44423827526233717,
            "fpr": 0.18311403508771928,
            "logloss": 3.197294110488567,
            "mae": 0.598451378182219,
            "precision": 0.34765625,
            "recall": 0.18503118503118504
        },
        "train": {
            "accuracy": 0.3918770581778266,
            "auc_prc": 0.43951130404333605,
            "auditor_fn_violation": 0.009628617113364258,
            "auditor_fp_violation": 0.020036690074131995,
            "ave_precision_score": 0.44000380697493435,
            "fpr": 0.18111964873765093,
            "logloss": 3.2918199134548263,
            "mae": 0.5943853445228489,
            "precision": 0.3373493975903614,
            "recall": 0.17758985200845667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7893794329865227,
            "auditor_fn_violation": 0.011379800853485066,
            "auditor_fp_violation": 0.015068486180648846,
            "ave_precision_score": 0.7845845888401901,
            "fpr": 0.3190789473684211,
            "logloss": 2.27674864019762,
            "mae": 0.36223325428601283,
            "precision": 0.6013698630136987,
            "recall": 0.9126819126819127
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7956951789815131,
            "auditor_fn_violation": 0.014601894161795113,
            "auditor_fp_violation": 0.0294122069681067,
            "ave_precision_score": 0.7935931461154067,
            "fpr": 0.31613611416026344,
            "logloss": 2.095285024762012,
            "mae": 0.35309122448990443,
            "precision": 0.6043956043956044,
            "recall": 0.9302325581395349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4418859649122807,
            "auc_prc": 0.568701477229407,
            "auditor_fn_violation": 0.03212422949265057,
            "auditor_fp_violation": 0.028658871657100994,
            "ave_precision_score": 0.4895116831355528,
            "fpr": 0.23026315789473684,
            "logloss": 16.972254479512845,
            "mae": 0.5583481830087037,
            "precision": 0.4642857142857143,
            "recall": 0.3783783783783784
        },
        "train": {
            "accuracy": 0.4610318331503842,
            "auc_prc": 0.5679809592483327,
            "auditor_fn_violation": 0.030842208107161012,
            "auditor_fp_violation": 0.018818699908274828,
            "ave_precision_score": 0.48668119373884233,
            "fpr": 0.22722283205268934,
            "logloss": 16.377605009662236,
            "mae": 0.5391636219232193,
            "precision": 0.4772727272727273,
            "recall": 0.39957716701902746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7841246284330738,
            "auditor_fn_violation": 0.028428985665827782,
            "auditor_fp_violation": 0.018413929254691253,
            "ave_precision_score": 0.778793715598658,
            "fpr": 0.09210526315789473,
            "logloss": 1.7529651310706509,
            "mae": 0.30840520061964605,
            "precision": 0.7857142857142857,
            "recall": 0.6403326403326404
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.793426139942158,
            "auditor_fn_violation": 0.028263901620550334,
            "auditor_fp_violation": 0.017736041983068433,
            "ave_precision_score": 0.7916504195804149,
            "fpr": 0.09549945115257959,
            "logloss": 1.5064640018667956,
            "mae": 0.294541022699646,
            "precision": 0.7814070351758794,
            "recall": 0.6575052854122622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7773853830314712,
            "auditor_fn_violation": 0.018316646606120295,
            "auditor_fp_violation": 0.014447734766149713,
            "ave_precision_score": 0.7675794927812006,
            "fpr": 0.16666666666666666,
            "logloss": 1.6806019069587308,
            "mae": 0.30670759415871074,
            "precision": 0.7065637065637066,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7839776350530461,
            "auditor_fn_violation": 0.009438319064847548,
            "auditor_fp_violation": 0.02703637429890381,
            "ave_precision_score": 0.7768176989667943,
            "fpr": 0.1668496158068057,
            "logloss": 1.4138407427855642,
            "mae": 0.2888200630412542,
            "precision": 0.7093690248565966,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.764504079112994,
            "auditor_fn_violation": 0.0006474085421453844,
            "auditor_fp_violation": 0.0007657630154272131,
            "ave_precision_score": 0.5395792169873854,
            "fpr": 0.4517543859649123,
            "logloss": 15.23579052570017,
            "mae": 0.45585987961524216,
            "precision": 0.5370786516853933,
            "recall": 0.9937629937629938
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7565641333031374,
            "auditor_fn_violation": 0.0024413847199949877,
            "auditor_fp_violation": 0.004090041050779663,
            "ave_precision_score": 0.5290080549958236,
            "fpr": 0.4544456641053787,
            "logloss": 15.457274198274861,
            "mae": 0.45994612875230123,
            "precision": 0.5311438278595696,
            "recall": 0.9915433403805497
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.5752744502043308,
            "auditor_fn_violation": 0.035988164277637964,
            "auditor_fp_violation": 0.030599991858997838,
            "ave_precision_score": 0.49305562129995983,
            "fpr": 0.22807017543859648,
            "logloss": 17.454098894597216,
            "mae": 0.5549687212191582,
            "precision": 0.46938775510204084,
            "recall": 0.38253638253638256
        },
        "train": {
            "accuracy": 0.4610318331503842,
            "auc_prc": 0.5782009921971981,
            "auditor_fn_violation": 0.03029220033278953,
            "auditor_fp_violation": 0.01790395420757962,
            "ave_precision_score": 0.49397176003866905,
            "fpr": 0.2261251372118551,
            "logloss": 16.70573812063375,
            "mae": 0.5376179492472953,
            "precision": 0.47715736040609136,
            "recall": 0.3974630021141649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7962139526013579,
            "auditor_fn_violation": 0.007235474340737508,
            "auditor_fp_violation": 0.009156083363862094,
            "ave_precision_score": 0.791832146470148,
            "fpr": 0.0800438596491228,
            "logloss": 1.1426597539320007,
            "mae": 0.31595438474127185,
            "precision": 0.7943661971830986,
            "recall": 0.5862785862785863
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8046914555830751,
            "auditor_fn_violation": 0.022385548487710703,
            "auditor_fp_violation": 0.012518232260198787,
            "ave_precision_score": 0.8019813988272706,
            "fpr": 0.06915477497255763,
            "logloss": 0.9636894005572072,
            "mae": 0.31088081233461223,
            "precision": 0.8125,
            "recall": 0.5771670190274841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.574082872163762,
            "auditor_fn_violation": 0.035988164277637964,
            "auditor_fp_violation": 0.030599991858997838,
            "ave_precision_score": 0.493317440358948,
            "fpr": 0.22807017543859648,
            "logloss": 17.01209474081761,
            "mae": 0.5546718805639298,
            "precision": 0.46938775510204084,
            "recall": 0.38253638253638256
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5714064755074193,
            "auditor_fn_violation": 0.03029220033278953,
            "auditor_fp_violation": 0.02133738327594244,
            "ave_precision_score": 0.4891550878074158,
            "fpr": 0.22941822173435786,
            "logloss": 16.420654238678562,
            "mae": 0.5398347026599294,
            "precision": 0.473551637279597,
            "recall": 0.3974630021141649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8059385383057559,
            "auditor_fn_violation": 0.013333424517635048,
            "auditor_fp_violation": 0.026407375747954577,
            "ave_precision_score": 0.8060420078756203,
            "fpr": 0.25,
            "logloss": 1.4920806867309375,
            "mae": 0.3080157449205064,
            "precision": 0.65402124430956,
            "recall": 0.896049896049896
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8153567490007005,
            "auditor_fn_violation": 0.018630643091368592,
            "auditor_fp_violation": 0.029159085555037618,
            "ave_precision_score": 0.8156324969753505,
            "fpr": 0.23819978046103182,
            "logloss": 1.3544042222172243,
            "mae": 0.29510387928209947,
            "precision": 0.6661538461538462,
            "recall": 0.9154334038054969
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.410659484323732,
            "auditor_fn_violation": 0.0013335704125178086,
            "auditor_fp_violation": 0.0010710505963284086,
            "ave_precision_score": 0.5279708238932574,
            "fpr": 0.01206140350877193,
            "logloss": 17.899774387660376,
            "mae": 0.5317007612842697,
            "precision": 0.3888888888888889,
            "recall": 0.014553014553014554
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.4614028099333532,
            "auditor_fn_violation": 0.0004989522003792303,
            "auditor_fp_violation": 0.0016039376669724173,
            "ave_precision_score": 0.5284092473374025,
            "fpr": 0.007683863885839737,
            "logloss": 17.36352311079272,
            "mae": 0.5144579497544469,
            "precision": 0.631578947368421,
            "recall": 0.02536997885835095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7626900572880725,
            "auditor_fn_violation": 0.01749598789072474,
            "auditor_fp_violation": 0.020935095860300405,
            "ave_precision_score": 0.7576347144062895,
            "fpr": 0.16776315789473684,
            "logloss": 1.4677393390171856,
            "mae": 0.3162402301558851,
            "precision": 0.7,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7707814101155362,
            "auditor_fn_violation": 0.011905231571838676,
            "auditor_fp_violation": 0.023532772957610942,
            "ave_precision_score": 0.7660769287986207,
            "fpr": 0.16794731064763996,
            "logloss": 1.3076364328402499,
            "mae": 0.29302843661158506,
            "precision": 0.7040618955512572,
            "recall": 0.7695560253699789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.5744619157172501,
            "auditor_fn_violation": 0.035988164277637964,
            "auditor_fp_violation": 0.030599991858997838,
            "ave_precision_score": 0.49374356022264126,
            "fpr": 0.22807017543859648,
            "logloss": 17.240641055090528,
            "mae": 0.5546765117152069,
            "precision": 0.46938775510204084,
            "recall": 0.38253638253638256
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.5750132550675551,
            "auditor_fn_violation": 0.029746833974235512,
            "auditor_fp_violation": 0.01790395420757962,
            "ave_precision_score": 0.49244504015847634,
            "fpr": 0.2261251372118551,
            "logloss": 16.532466201791003,
            "mae": 0.537539185660772,
            "precision": 0.47848101265822784,
            "recall": 0.39957716701902746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8352626112397072,
            "auditor_fn_violation": 0.0031139439034175887,
            "auditor_fp_violation": 0.006477184841453987,
            "ave_precision_score": 0.7338094416244813,
            "fpr": 0.09868421052631579,
            "logloss": 7.903948729131369,
            "mae": 0.23772514874188944,
            "precision": 0.7986577181208053,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8305797345413822,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.011473166624062078,
            "ave_precision_score": 0.7334007551209263,
            "fpr": 0.08781558726673985,
            "logloss": 7.858096832946843,
            "mae": 0.24177379576533575,
            "precision": 0.8076923076923077,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8127167721739006,
            "auditor_fn_violation": 0.013415490389174608,
            "auditor_fp_violation": 0.00718189034070094,
            "ave_precision_score": 0.8129895350474935,
            "fpr": 0.07017543859649122,
            "logloss": 1.3442937559696584,
            "mae": 0.3162255396401013,
            "precision": 0.8,
            "recall": 0.5322245322245323
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8208961297943824,
            "auditor_fn_violation": 0.01706880666878624,
            "auditor_fp_violation": 0.01356329789633551,
            "ave_precision_score": 0.8211678642886469,
            "fpr": 0.06915477497255763,
            "logloss": 1.1712877253792795,
            "mae": 0.30246396953011145,
            "precision": 0.8067484662576687,
            "recall": 0.5560253699788583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7860097965192566,
            "auditor_fn_violation": 0.016091749644381228,
            "auditor_fp_violation": 0.02082570114381081,
            "ave_precision_score": 0.7863271475020663,
            "fpr": 0.16447368421052633,
            "logloss": 1.007464588104685,
            "mae": 0.2909434149624894,
            "precision": 0.7222222222222222,
            "recall": 0.8108108108108109
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8055927217099923,
            "auditor_fn_violation": 0.013952095947347783,
            "auditor_fp_violation": 0.025600348856442568,
            "ave_precision_score": 0.8058764283702561,
            "fpr": 0.16794731064763996,
            "logloss": 0.82170549681869,
            "mae": 0.27895535376986536,
            "precision": 0.7197802197802198,
            "recall": 0.8308668076109936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.663766822416322,
            "auditor_fn_violation": 0.02941833533938798,
            "auditor_fp_violation": 0.035408271258191897,
            "ave_precision_score": 0.6591095073239892,
            "fpr": 0.18640350877192982,
            "logloss": 1.6980143211842538,
            "mae": 0.3871371813361927,
            "precision": 0.6480331262939959,
            "recall": 0.6507276507276507
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6655862045882005,
            "auditor_fn_violation": 0.03944043090904449,
            "auditor_fp_violation": 0.03416136615390784,
            "ave_precision_score": 0.6624238137653364,
            "fpr": 0.17672886937431395,
            "logloss": 1.4403755291903952,
            "mae": 0.38987578601628003,
            "precision": 0.639821029082774,
            "recall": 0.6046511627906976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7836830275717481,
            "auditor_fn_violation": 0.02356430316956634,
            "auditor_fp_violation": 0.009117922416249443,
            "ave_precision_score": 0.7774650094846287,
            "fpr": 0.09978070175438597,
            "logloss": 1.3103572725312487,
            "mae": 0.3065727781985608,
            "precision": 0.7780487804878049,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7793639339250836,
            "auditor_fn_violation": 0.022993573959800704,
            "auditor_fp_violation": 0.005949606283425814,
            "ave_precision_score": 0.7748729277866385,
            "fpr": 0.10647639956092206,
            "logloss": 1.1474673050911501,
            "mae": 0.3048445564210116,
            "precision": 0.7651331719128329,
            "recall": 0.6680761099365751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6715284207426412,
            "auditor_fn_violation": 0.003720319509793195,
            "auditor_fp_violation": 0.002704339154149902,
            "ave_precision_score": 0.6665082923319628,
            "fpr": 0.3574561403508772,
            "logloss": 1.9026117112363277,
            "mae": 0.4173295930583437,
            "precision": 0.5699208443271768,
            "recall": 0.8981288981288982
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6614905533915107,
            "auditor_fn_violation": 0.005486153496262503,
            "auditor_fp_violation": 0.0017893929597161107,
            "ave_precision_score": 0.6581227322481502,
            "fpr": 0.3589462129527991,
            "logloss": 1.8188765436735093,
            "mae": 0.4187219980350709,
            "precision": 0.5557065217391305,
            "recall": 0.864693446088795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7761946361876293,
            "auditor_fn_violation": 0.016269559032716933,
            "auditor_fp_violation": 0.01999633654902919,
            "ave_precision_score": 0.7663539535894005,
            "fpr": 0.17105263157894737,
            "logloss": 1.6891174658563317,
            "mae": 0.30787237015213575,
            "precision": 0.7,
            "recall": 0.7567567567567568
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7820378001360193,
            "auditor_fn_violation": 0.01430252284156759,
            "auditor_fp_violation": 0.025760742623139814,
            "ave_precision_score": 0.7748080821839762,
            "fpr": 0.16575192096597147,
            "logloss": 1.4264136730435735,
            "mae": 0.29056716702946206,
            "precision": 0.710727969348659,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7865114426051157,
            "auditor_fn_violation": 0.01510467957836379,
            "auditor_fp_violation": 0.017874587861765785,
            "ave_precision_score": 0.787385032240914,
            "fpr": 0.16337719298245615,
            "logloss": 1.0143576116959971,
            "mae": 0.2922609064857501,
            "precision": 0.7250922509225092,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8036507570982072,
            "auditor_fn_violation": 0.01596647041213452,
            "auditor_fp_violation": 0.02124966793477989,
            "ave_precision_score": 0.8040174418925675,
            "fpr": 0.15697036223929747,
            "logloss": 0.8277581319204195,
            "mae": 0.28207607519198563,
            "precision": 0.730188679245283,
            "recall": 0.8181818181818182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.78337718624005,
            "auditor_fn_violation": 0.01054318488529015,
            "auditor_fp_violation": 0.021609272601457244,
            "ave_precision_score": 0.7848653091824049,
            "fpr": 0.22697368421052633,
            "logloss": 1.2580853742744973,
            "mae": 0.3017997342890838,
            "precision": 0.6672025723472669,
            "recall": 0.8627858627858628
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8124096692878133,
            "auditor_fn_violation": 0.01582722793761009,
            "auditor_fp_violation": 0.027464926394298,
            "ave_precision_score": 0.813683308267324,
            "fpr": 0.21405049396267836,
            "logloss": 1.0593210995300748,
            "mae": 0.28201037020590597,
            "precision": 0.6818923327895595,
            "recall": 0.8837209302325582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8783442612018694,
            "auditor_fn_violation": 0.0072651092387934525,
            "auditor_fp_violation": 0.010532421541091713,
            "ave_precision_score": 0.8770378665617125,
            "fpr": 0.21162280701754385,
            "logloss": 1.2055838847010443,
            "mae": 0.26024121196718847,
            "precision": 0.6936507936507936,
            "recall": 0.9085239085239085
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8771430371200396,
            "auditor_fn_violation": 0.0039916176030336285,
            "auditor_fp_violation": 0.017663363557533753,
            "ave_precision_score": 0.8752586571805305,
            "fpr": 0.19538968166849616,
            "logloss": 1.1047258531384445,
            "mae": 0.24882800728012996,
            "precision": 0.7072368421052632,
            "recall": 0.9090909090909091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.789014524843404,
            "auditor_fn_violation": 0.009389703468650841,
            "auditor_fp_violation": 0.015134631823177449,
            "ave_precision_score": 0.7839750981694835,
            "fpr": 0.31140350877192985,
            "logloss": 2.1937975169067148,
            "mae": 0.3566817825062732,
            "precision": 0.6055555555555555,
            "recall": 0.9064449064449065
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7987203424383014,
            "auditor_fn_violation": 0.016769435348558726,
            "auditor_fp_violation": 0.028915988752387118,
            "ave_precision_score": 0.798362501034843,
            "fpr": 0.31284302963776073,
            "logloss": 1.9418563152193586,
            "mae": 0.3482731922219677,
            "precision": 0.6058091286307054,
            "recall": 0.9260042283298098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.836298496550142,
            "auditor_fn_violation": 0.00024619761461867223,
            "auditor_fp_violation": 0.007382871331460906,
            "ave_precision_score": 0.7338125864728746,
            "fpr": 0.09758771929824561,
            "logloss": 7.931240554969753,
            "mae": 0.23530113556843685,
            "precision": 0.7995495495495496,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.832616171361207,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.011473166624062078,
            "ave_precision_score": 0.733523307578464,
            "fpr": 0.08781558726673985,
            "logloss": 7.886790734891621,
            "mae": 0.23779515606615287,
            "precision": 0.8076923076923077,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 1318,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7928333220604105,
            "auditor_fn_violation": 0.010121457489878543,
            "auditor_fp_violation": 0.0028289982496845396,
            "ave_precision_score": 0.7865633877163956,
            "fpr": 0.0756578947368421,
            "logloss": 1.3897672659953137,
            "mae": 0.3204714391715294,
            "precision": 0.7896341463414634,
            "recall": 0.5384615384615384
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.8003578969243534,
            "auditor_fn_violation": 0.013921926744534163,
            "auditor_fp_violation": 0.009578515254950909,
            "ave_precision_score": 0.7950105206218255,
            "fpr": 0.07244785949506037,
            "logloss": 1.1915345104184787,
            "mae": 0.31220000285261024,
            "precision": 0.794392523364486,
            "recall": 0.5391120507399577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7719900085884017,
            "auditor_fn_violation": 0.03343272422219792,
            "auditor_fp_violation": 0.01921276509138275,
            "ave_precision_score": 0.7654268894284316,
            "fpr": 0.10855263157894737,
            "logloss": 1.929503375367872,
            "mae": 0.3057305461574308,
            "precision": 0.7631578947368421,
            "recall": 0.6632016632016632
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7894935897289763,
            "auditor_fn_violation": 0.025871251766638896,
            "auditor_fp_violation": 0.016450385696885866,
            "ave_precision_score": 0.7859576065161444,
            "fpr": 0.09879253567508232,
            "logloss": 1.6228056410591456,
            "mae": 0.2881877264393466,
            "precision": 0.7804878048780488,
            "recall": 0.6765327695560254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8357332067411151,
            "auditor_fn_violation": 0.0031139439034175887,
            "auditor_fp_violation": 0.006477184841453987,
            "ave_precision_score": 0.7348398265175633,
            "fpr": 0.09868421052631579,
            "logloss": 7.838215213865883,
            "mae": 0.23570569466514507,
            "precision": 0.7986577181208053,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8298836883411609,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.011473166624062078,
            "ave_precision_score": 0.7334049463184622,
            "fpr": 0.08781558726673985,
            "logloss": 7.864537875494649,
            "mae": 0.238562886462154,
            "precision": 0.8076923076923077,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8342406989777763,
            "auditor_fn_violation": 0.0020220118904329433,
            "auditor_fp_violation": 0.01031363210811251,
            "ave_precision_score": 0.750267643588201,
            "fpr": 0.09978070175438597,
            "logloss": 7.404181837630242,
            "mae": 0.23724086156834384,
            "precision": 0.7959641255605381,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8280030309038903,
            "auditor_fn_violation": 0.005952615785919345,
            "auditor_fp_violation": 0.012102210927827822,
            "ave_precision_score": 0.7458267265030869,
            "fpr": 0.0867178924259056,
            "logloss": 7.274682507306174,
            "mae": 0.2339360341692574,
            "precision": 0.8114558472553699,
            "recall": 0.718816067653277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.781884623236864,
            "auditor_fn_violation": 0.01720419812525076,
            "auditor_fp_violation": 0.020009056864900072,
            "ave_precision_score": 0.774570986434075,
            "fpr": 0.16666666666666666,
            "logloss": 1.5957513154525476,
            "mae": 0.29928767496642517,
            "precision": 0.708253358925144,
            "recall": 0.7671517671517671
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7924523550185711,
            "auditor_fn_violation": 0.01219067864461376,
            "auditor_fp_violation": 0.02707647274057813,
            "ave_precision_score": 0.7877821252952101,
            "fpr": 0.1602634467618002,
            "logloss": 1.2923556706182562,
            "mae": 0.28124495466131644,
            "precision": 0.7186897880539499,
            "recall": 0.7885835095137421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7902989315889319,
            "auditor_fn_violation": 0.003437648174490293,
            "auditor_fp_violation": 0.006388142630357801,
            "ave_precision_score": 0.7850747068770343,
            "fpr": 0.05263157894736842,
            "logloss": 1.7094436962931492,
            "mae": 0.35614702677286314,
            "precision": 0.8024691358024691,
            "recall": 0.40540540540540543
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7977525733238333,
            "auditor_fn_violation": 0.01585275572460626,
            "auditor_fp_violation": 0.012976858186848713,
            "ave_precision_score": 0.7926856489505052,
            "fpr": 0.048298572996706916,
            "logloss": 1.5341961000212967,
            "mae": 0.3509378637433479,
            "precision": 0.8103448275862069,
            "recall": 0.3974630021141649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8059786371966093,
            "auditor_fn_violation": 0.009715687347266296,
            "auditor_fp_violation": 0.022988154841861036,
            "ave_precision_score": 0.8050759742676714,
            "fpr": 0.14364035087719298,
            "logloss": 2.251027550438361,
            "mae": 0.3005542495703558,
            "precision": 0.7342799188640974,
            "recall": 0.7525987525987526
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8339608115461512,
            "auditor_fn_violation": 0.011540880430166423,
            "auditor_fp_violation": 0.025562756567372905,
            "ave_precision_score": 0.8329325940786031,
            "fpr": 0.11855104281009879,
            "logloss": 1.980650206094529,
            "mae": 0.28125256014066097,
            "precision": 0.762114537444934,
            "recall": 0.7315010570824524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7946081213071507,
            "auditor_fn_violation": 0.017527902396323455,
            "auditor_fp_violation": 0.007466825416208743,
            "ave_precision_score": 0.784097576715814,
            "fpr": 0.11403508771929824,
            "logloss": 1.3793526392807918,
            "mae": 0.2882452861696961,
            "precision": 0.7729257641921398,
            "recall": 0.735966735966736
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8089391493755506,
            "auditor_fn_violation": 0.018066711069544654,
            "auditor_fp_violation": 0.016555644106280926,
            "ave_precision_score": 0.8016529285165234,
            "fpr": 0.10537870472008781,
            "logloss": 1.114610936138984,
            "mae": 0.27696669103394295,
            "precision": 0.7813211845102506,
            "recall": 0.7251585623678647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7799128581847147,
            "auditor_fn_violation": 0.018405551300288144,
            "auditor_fp_violation": 0.026984878088492703,
            "ave_precision_score": 0.7845426090364893,
            "fpr": 0.23135964912280702,
            "logloss": 1.4966970569797189,
            "mae": 0.30561312540513447,
            "precision": 0.6661392405063291,
            "recall": 0.8752598752598753
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7948802862260093,
            "auditor_fn_violation": 0.017778943288860833,
            "auditor_fp_violation": 0.029382133136850983,
            "ave_precision_score": 0.796597962062662,
            "fpr": 0.2305159165751921,
            "logloss": 1.2958625522712754,
            "mae": 0.291938909160945,
            "precision": 0.6692913385826772,
            "recall": 0.8985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7759535600473582,
            "auditor_fn_violation": 0.01508416311047891,
            "auditor_fp_violation": 0.002554239426873449,
            "ave_precision_score": 0.770596548641846,
            "fpr": 0.08991228070175439,
            "logloss": 1.336927179656479,
            "mae": 0.32194402510206255,
            "precision": 0.7771739130434783,
            "recall": 0.5945945945945946
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.76744851275016,
            "auditor_fn_violation": 0.02061484835334171,
            "auditor_fp_violation": 0.008941952493371234,
            "ave_precision_score": 0.7630202593750213,
            "fpr": 0.10757409440175632,
            "logloss": 1.1968176750867354,
            "mae": 0.32234523403944243,
            "precision": 0.7454545454545455,
            "recall": 0.6067653276955602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7748061816070786,
            "auditor_fn_violation": 0.014386603202392679,
            "auditor_fp_violation": 0.020108275328692967,
            "ave_precision_score": 0.7768868062688159,
            "fpr": 0.15570175438596492,
            "logloss": 1.2841454872775293,
            "mae": 0.2979152544383967,
            "precision": 0.7176938369781312,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7865377365960319,
            "auditor_fn_violation": 0.01231135545586826,
            "auditor_fp_violation": 0.02467808469793343,
            "ave_precision_score": 0.7880536113656516,
            "fpr": 0.15697036223929747,
            "logloss": 1.1215541413938395,
            "mae": 0.27705492001364856,
            "precision": 0.7196078431372549,
            "recall": 0.7758985200845666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7667856720067593,
            "auditor_fn_violation": 0.0035288324762008977,
            "auditor_fp_violation": 0.02199088207758377,
            "ave_precision_score": 0.7727341940966286,
            "fpr": 0.36951754385964913,
            "logloss": 2.2745422176209362,
            "mae": 0.37657347887641623,
            "precision": 0.5829207920792079,
            "recall": 0.9792099792099792
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7986195013590445,
            "auditor_fn_violation": 0.002882319222655679,
            "auditor_fp_violation": 0.02087875734929252,
            "ave_precision_score": 0.802398153561827,
            "fpr": 0.3721185510428101,
            "logloss": 2.130006835488955,
            "mae": 0.3767604352595993,
            "precision": 0.5788819875776398,
            "recall": 0.985200845665962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7893530718723729,
            "auditor_fn_violation": 0.008288653025495137,
            "auditor_fp_violation": 0.017571844344038755,
            "ave_precision_score": 0.7779142846585649,
            "fpr": 0.18421052631578946,
            "logloss": 1.5518683617479805,
            "mae": 0.2919414420070834,
            "precision": 0.7031802120141343,
            "recall": 0.8274428274428275
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7947053963317675,
            "auditor_fn_violation": 0.013146810303014834,
            "auditor_fp_violation": 0.023803437438912542,
            "ave_precision_score": 0.787328142123318,
            "fpr": 0.18880351262349068,
            "logloss": 1.3468519652383657,
            "mae": 0.28114153042548995,
            "precision": 0.7003484320557491,
            "recall": 0.8498942917547568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.46307875170209656,
            "auditor_fn_violation": 0.0069254477149214,
            "auditor_fp_violation": 0.02249206252289657,
            "ave_precision_score": 0.46469663958569163,
            "fpr": 0.30153508771929827,
            "logloss": 1.9308338552012136,
            "mae": 0.5183916557651392,
            "precision": 0.5225694444444444,
            "recall": 0.6257796257796258
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.46395116741865805,
            "auditor_fn_violation": 0.018762923442166804,
            "auditor_fp_violation": 0.01094687457708675,
            "ave_precision_score": 0.4652861523111701,
            "fpr": 0.287596048298573,
            "logloss": 2.00517054033231,
            "mae": 0.5054628927189078,
            "precision": 0.5218978102189781,
            "recall": 0.6046511627906976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8163207485540476,
            "auditor_fn_violation": 0.005236258525732212,
            "auditor_fp_violation": 0.025394838604632233,
            "ave_precision_score": 0.8176784770207739,
            "fpr": 0.2949561403508772,
            "logloss": 0.9176415776092315,
            "mae": 0.3243283611581661,
            "precision": 0.6269070735090153,
            "recall": 0.9397089397089398
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.8474013669946404,
            "auditor_fn_violation": 0.010287698159446558,
            "auditor_fp_violation": 0.027254409575507885,
            "ave_precision_score": 0.8487089674556378,
            "fpr": 0.2996706915477497,
            "logloss": 0.8082194420063367,
            "mae": 0.314546592597966,
            "precision": 0.6213592233009708,
            "recall": 0.9471458773784355
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8004559993605981,
            "auditor_fn_violation": 0.01611682532735165,
            "auditor_fp_violation": 0.01918986852281516,
            "ave_precision_score": 0.7985045004076567,
            "fpr": 0.14802631578947367,
            "logloss": 1.952691363413626,
            "mae": 0.29169121886974425,
            "precision": 0.725609756097561,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8194958346677976,
            "auditor_fn_violation": 0.011338978842105996,
            "auditor_fp_violation": 0.024840984617235315,
            "ave_precision_score": 0.8195661243758132,
            "fpr": 0.14818880351262348,
            "logloss": 1.672560702503466,
            "mae": 0.2703033758760221,
            "precision": 0.7321428571428571,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8338680549087548,
            "auditor_fn_violation": 0.0005106320895794632,
            "auditor_fp_violation": 0.01578591199576668,
            "ave_precision_score": 0.7499273060979869,
            "fpr": 0.11074561403508772,
            "logloss": 7.4188111712419,
            "mae": 0.24658128827422685,
            "precision": 0.7789934354485777,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8272586835389,
            "auditor_fn_violation": 0.008029649364242077,
            "auditor_fp_violation": 0.013337744161917513,
            "ave_precision_score": 0.7451459748590638,
            "fpr": 0.09220636663007684,
            "logloss": 7.277860231176183,
            "mae": 0.23799140250697645,
            "precision": 0.8028169014084507,
            "recall": 0.7230443974630021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.573688094160014,
            "auditor_fn_violation": 0.008746854141590986,
            "auditor_fp_violation": 0.003912769161883829,
            "ave_precision_score": 0.5610088016110243,
            "fpr": 0.40789473684210525,
            "logloss": 3.307563173745884,
            "mae": 0.464236068518593,
            "precision": 0.5373134328358209,
            "recall": 0.8981288981288982
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5584026276482719,
            "auditor_fn_violation": 0.004267781844173751,
            "auditor_fp_violation": 0.007317965605561672,
            "ave_precision_score": 0.5463453652290351,
            "fpr": 0.40065861690450055,
            "logloss": 3.2974791827763843,
            "mae": 0.4681523322068446,
            "precision": 0.5332480818414322,
            "recall": 0.8816067653276956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6179321532649453,
            "auditor_fn_violation": 0.01058421782105992,
            "auditor_fp_violation": 0.009657263809174923,
            "ave_precision_score": 0.6118537296744161,
            "fpr": 0.13925438596491227,
            "logloss": 2.0736331874309557,
            "mae": 0.4737004578699981,
            "precision": 0.5766666666666667,
            "recall": 0.3596673596673597
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6174554506627645,
            "auditor_fn_violation": 0.009011308809639308,
            "auditor_fp_violation": 0.00625535690119243,
            "ave_precision_score": 0.6151011717645178,
            "fpr": 0.12952799121844127,
            "logloss": 2.010911043131931,
            "mae": 0.4600878958437146,
            "precision": 0.5830388692579506,
            "recall": 0.3488372093023256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7822531618371577,
            "auditor_fn_violation": 0.013349381770434415,
            "auditor_fp_violation": 0.01126002360890626,
            "ave_precision_score": 0.760316436412023,
            "fpr": 0.08333333333333333,
            "logloss": 3.1693052682852,
            "mae": 0.32605854982008003,
            "precision": 0.7696969696969697,
            "recall": 0.5280665280665281
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7932301559546533,
            "auditor_fn_violation": 0.015954866872590824,
            "auditor_fp_violation": 0.01221749394764146,
            "ave_precision_score": 0.7723661204805342,
            "fpr": 0.08232711306256861,
            "logloss": 2.852550656084692,
            "mae": 0.3057624609705597,
            "precision": 0.7787610619469026,
            "recall": 0.5581395348837209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 1318,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7442723475669389,
            "auditor_fn_violation": 0.007716471532261009,
            "auditor_fp_violation": 0.0065458745471567645,
            "ave_precision_score": 0.7375646750429876,
            "fpr": 0.19956140350877194,
            "logloss": 1.2644558009997613,
            "mae": 0.34856649313541116,
            "precision": 0.6714801444043321,
            "recall": 0.7733887733887734
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7489972947442175,
            "auditor_fn_violation": 0.011471259192904206,
            "auditor_fp_violation": 0.012513219954989503,
            "ave_precision_score": 0.7438829127157253,
            "fpr": 0.18331503841931943,
            "logloss": 1.094871072539223,
            "mae": 0.3469783698744443,
            "precision": 0.6769825918762089,
            "recall": 0.7399577167019028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7966803741953004,
            "auditor_fn_violation": 0.014885837254258317,
            "auditor_fp_violation": 0.013854968046566541,
            "ave_precision_score": 0.7893883069400746,
            "fpr": 0.12609649122807018,
            "logloss": 2.454812140409959,
            "mae": 0.28764165515238105,
            "precision": 0.7542735042735043,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8042579712001778,
            "auditor_fn_violation": 0.013286052777539265,
            "auditor_fp_violation": 0.01641279340781619,
            "ave_precision_score": 0.797409848677959,
            "fpr": 0.11964873765093303,
            "logloss": 2.2028619627445267,
            "mae": 0.27193511040801827,
            "precision": 0.7665952890792291,
            "recall": 0.7568710359408034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.6840993149629527,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017935645377946026,
            "ave_precision_score": 0.6855710844468785,
            "fpr": 0.003289473684210526,
            "logloss": 9.46765381752117,
            "mae": 0.5306518998292673,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7092364152525353,
            "auditor_fn_violation": 0.001531667219768741,
            "auditor_fp_violation": 0.00017543068232510816,
            "ave_precision_score": 0.7108590032412898,
            "fpr": 0.0021953896816684962,
            "logloss": 9.508981994292052,
            "mae": 0.5181368465288589,
            "precision": 0.6,
            "recall": 0.006342494714587738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.792204873072145,
            "auditor_fn_violation": 0.016743717401612145,
            "auditor_fp_violation": 0.022423372817193803,
            "ave_precision_score": 0.7857923851134294,
            "fpr": 0.17543859649122806,
            "logloss": 1.2225701509283315,
            "mae": 0.30411379541201455,
            "precision": 0.7053406998158379,
            "recall": 0.7962577962577962
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8007516851488772,
            "auditor_fn_violation": 0.01824540557851767,
            "auditor_fp_violation": 0.024254544907748525,
            "ave_precision_score": 0.7944950793519943,
            "fpr": 0.1712403951701427,
            "logloss": 1.0629811019110649,
            "mae": 0.28775111102258216,
            "precision": 0.7199281867145422,
            "recall": 0.8477801268498943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7981950853606774,
            "auditor_fn_violation": 0.019855381697486966,
            "auditor_fp_violation": 0.01651605812675541,
            "ave_precision_score": 0.7915579852164555,
            "fpr": 0.11951754385964912,
            "logloss": 1.3781719493072087,
            "mae": 0.28451103608627654,
            "precision": 0.7640692640692641,
            "recall": 0.7338877338877339
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.807170505380798,
            "auditor_fn_violation": 0.014228260188487902,
            "auditor_fp_violation": 0.017417760602278596,
            "ave_precision_score": 0.8010101634273584,
            "fpr": 0.1163556531284303,
            "logloss": 1.1856206055545908,
            "mae": 0.2687167550565411,
            "precision": 0.7680525164113785,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7500437276153473,
            "auditor_fn_violation": 0.015742969690338116,
            "auditor_fp_violation": 0.02481224813774576,
            "ave_precision_score": 0.7412253328458296,
            "fpr": 0.19298245614035087,
            "logloss": 1.7447856739537897,
            "mae": 0.32283527455263994,
            "precision": 0.6794171220400729,
            "recall": 0.7754677754677755
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7559621397521061,
            "auditor_fn_violation": 0.017651304353880112,
            "auditor_fp_violation": 0.02801878611992442,
            "ave_precision_score": 0.7514941323598379,
            "fpr": 0.19319429198682767,
            "logloss": 1.433994720327431,
            "mae": 0.30904363768452336,
            "precision": 0.6828828828828829,
            "recall": 0.8012684989429175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7750293222164927,
            "auditor_fn_violation": 0.012182222708538503,
            "auditor_fp_violation": 0.016610188464199944,
            "ave_precision_score": 0.7418336812356578,
            "fpr": 0.1118421052631579,
            "logloss": 3.8976227266702357,
            "mae": 0.3126803934501904,
            "precision": 0.7493857493857494,
            "recall": 0.6340956340956341
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7778328454128469,
            "auditor_fn_violation": 0.014755060883771987,
            "auditor_fp_violation": 0.022186969008916892,
            "ave_precision_score": 0.7425793147757497,
            "fpr": 0.12843029637760703,
            "logloss": 3.738182822431723,
            "mae": 0.30149874524614395,
            "precision": 0.7304147465437788,
            "recall": 0.6701902748414377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8365186418239522,
            "auditor_fn_violation": 0.0031139439034175887,
            "auditor_fp_violation": 0.006477184841453987,
            "ave_precision_score": 0.7338235157156394,
            "fpr": 0.09868421052631579,
            "logloss": 7.928849043247979,
            "mae": 0.23523911119284432,
            "precision": 0.7986577181208053,
            "recall": 0.7422037422037422
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8341216099050046,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.010631099348901558,
            "ave_precision_score": 0.7335472998389102,
            "fpr": 0.0889132821075741,
            "logloss": 7.890440259758565,
            "mae": 0.23838355664076666,
            "precision": 0.8057553956834532,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8038133329947387,
            "auditor_fn_violation": 0.017552978079293877,
            "auditor_fp_violation": 0.022784629787926895,
            "ave_precision_score": 0.8046182818166691,
            "fpr": 0.17653508771929824,
            "logloss": 2.0090035365238945,
            "mae": 0.3070437474860701,
            "precision": 0.6939163498098859,
            "recall": 0.7588357588357588
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8254322356554198,
            "auditor_fn_violation": 0.012436673682940245,
            "auditor_fp_violation": 0.02878316266434096,
            "ave_precision_score": 0.8264886517493817,
            "fpr": 0.17014270032930845,
            "logloss": 1.7678682845862828,
            "mae": 0.28066567621530164,
            "precision": 0.7041984732824428,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.5032774803078369,
            "auditor_fn_violation": 0.01316701316701317,
            "auditor_fp_violation": 0.007382871331460909,
            "ave_precision_score": 0.4825126105743198,
            "fpr": 0.3848684210526316,
            "logloss": 4.506998066112362,
            "mae": 0.509767401102098,
            "precision": 0.5111420612813371,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.49321046639290117,
            "auditor_fn_violation": 0.008252437323481155,
            "auditor_fp_violation": 0.010034635028996186,
            "ave_precision_score": 0.4740396963628848,
            "fpr": 0.37760702524698136,
            "logloss": 4.4105028939675,
            "mae": 0.5101082549139887,
            "precision": 0.5050359712230216,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.799426569368245,
            "auditor_fn_violation": 0.018856913593755704,
            "auditor_fp_violation": 0.016393943094394924,
            "ave_precision_score": 0.7911378130613386,
            "fpr": 0.15679824561403508,
            "logloss": 1.3059121208847415,
            "mae": 0.2875476143003671,
            "precision": 0.7322097378277154,
            "recall": 0.8128898128898129
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8024811813199297,
            "auditor_fn_violation": 0.01867009512581718,
            "auditor_fp_violation": 0.02426206336556246,
            "ave_precision_score": 0.796079798915555,
            "fpr": 0.16136114160263446,
            "logloss": 1.1197133703417386,
            "mae": 0.27937162225178264,
            "precision": 0.7287822878228782,
            "recall": 0.8350951374207188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7913532173456042,
            "auditor_fn_violation": 0.003323667797352008,
            "auditor_fp_violation": 0.020683233606056915,
            "ave_precision_score": 0.7922630781530446,
            "fpr": 0.3815789473684211,
            "logloss": 2.4156233465264814,
            "mae": 0.38612574757487733,
            "precision": 0.5766423357664233,
            "recall": 0.9854469854469855
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.8181576399400152,
            "auditor_fn_violation": 0.003522834605468052,
            "auditor_fp_violation": 0.021081755710268726,
            "ave_precision_score": 0.8181766444060978,
            "fpr": 0.38199780461031835,
            "logloss": 2.2929110631332827,
            "mae": 0.3860459910147308,
            "precision": 0.5730061349693252,
            "recall": 0.9873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 1318,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.7000252984412252,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017935645377946026,
            "ave_precision_score": 0.70141003832106,
            "fpr": 0.003289473684210526,
            "logloss": 6.7545906038246795,
            "mae": 0.5305531463819212,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7190441710631607,
            "auditor_fn_violation": 0.001531667219768741,
            "auditor_fp_violation": 0.00017543068232510816,
            "ave_precision_score": 0.7206544974009779,
            "fpr": 0.0021953896816684962,
            "logloss": 6.783584657778667,
            "mae": 0.51773286464995,
            "precision": 0.6,
            "recall": 0.006342494714587738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8358939038063365,
            "auditor_fn_violation": 0.00024619761461867223,
            "auditor_fp_violation": 0.008326718769080477,
            "ave_precision_score": 0.733823722175576,
            "fpr": 0.09649122807017543,
            "logloss": 7.930315294196852,
            "mae": 0.23448642806086037,
            "precision": 0.801354401805869,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8321393209261715,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.01019502879569343,
            "ave_precision_score": 0.7335313608188448,
            "fpr": 0.08562019758507135,
            "logloss": 7.877094354712535,
            "mae": 0.23652043013420626,
            "precision": 0.8115942028985508,
            "recall": 0.7103594080338267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7949485184951378,
            "auditor_fn_violation": 0.017192800087536937,
            "auditor_fp_violation": 0.006156632881507717,
            "ave_precision_score": 0.7819655485437687,
            "fpr": 0.10855263157894737,
            "logloss": 1.5369368298711543,
            "mae": 0.2899151876500725,
            "precision": 0.7785234899328859,
            "recall": 0.7234927234927235
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8057288509902522,
            "auditor_fn_violation": 0.015300427242326001,
            "auditor_fp_violation": 0.016608273310978455,
            "ave_precision_score": 0.7957775671892356,
            "fpr": 0.10647639956092206,
            "logloss": 1.2658236340577949,
            "mae": 0.28211782389674683,
            "precision": 0.7820224719101123,
            "recall": 0.7357293868921776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8338934667668517,
            "auditor_fn_violation": 0.0005106320895794632,
            "auditor_fp_violation": 0.011860422518011966,
            "ave_precision_score": 0.7484111079839013,
            "fpr": 0.10307017543859649,
            "logloss": 7.48029194060238,
            "mae": 0.2393750438894081,
            "precision": 0.7911111111111111,
            "recall": 0.7401247401247402
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8299670156462143,
            "auditor_fn_violation": 0.005871391009113428,
            "auditor_fp_violation": 0.010290262594669917,
            "ave_precision_score": 0.7476003255270808,
            "fpr": 0.09001097694840834,
            "logloss": 7.298970809991339,
            "mae": 0.2363650144017028,
            "precision": 0.806146572104019,
            "recall": 0.7209302325581395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 1318,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.5593112237336524,
            "auditor_fn_violation": 0.008514334172228912,
            "auditor_fp_violation": 0.018335063296291775,
            "ave_precision_score": 0.5334004551992102,
            "fpr": 0.24013157894736842,
            "logloss": 4.532348785678004,
            "mae": 0.4050230781393467,
            "precision": 0.6089285714285714,
            "recall": 0.7089397089397089
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.5410190112422553,
            "auditor_fn_violation": 0.009206248273973492,
            "auditor_fp_violation": 0.011646091153782533,
            "ave_precision_score": 0.5218819180674215,
            "fpr": 0.23161361141602635,
            "logloss": 4.451173161172105,
            "mae": 0.3931888134084836,
            "precision": 0.6245551601423488,
            "recall": 0.7420718816067653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7723661348004955,
            "auditor_fn_violation": 0.01573841047525258,
            "auditor_fp_violation": 0.018859140310172183,
            "ave_precision_score": 0.7754912862384256,
            "fpr": 0.1600877192982456,
            "logloss": 1.2774791502517036,
            "mae": 0.2991997941525376,
            "precision": 0.7120315581854043,
            "recall": 0.7505197505197505
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7846075356607848,
            "auditor_fn_violation": 0.013318542688261633,
            "auditor_fp_violation": 0.02597877789974388,
            "ave_precision_score": 0.7864442408247809,
            "fpr": 0.1602634467618002,
            "logloss": 1.1115307230876743,
            "mae": 0.27780739951056854,
            "precision": 0.7170542635658915,
            "recall": 0.7822410147991543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 1318,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6853061819112989,
            "auditor_fn_violation": 0.004064540248750775,
            "auditor_fp_violation": 0.002523710668783336,
            "ave_precision_score": 0.6802194896095076,
            "fpr": 0.3881578947368421,
            "logloss": 2.010259035911444,
            "mae": 0.4183614248240261,
            "precision": 0.5613382899628253,
            "recall": 0.9417879417879418
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6746617772392275,
            "auditor_fn_violation": 0.003497306818471908,
            "auditor_fp_violation": 0.007267842553468771,
            "ave_precision_score": 0.6705362525050186,
            "fpr": 0.3765093304061471,
            "logloss": 1.9234617708467905,
            "mae": 0.41914319594358734,
            "precision": 0.555699481865285,
            "recall": 0.9069767441860465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 1318,
        "test": {
            "accuracy": 0.46600877192982454,
            "auc_prc": 0.4003555844392645,
            "auditor_fn_violation": 0.0019467848415216944,
            "auditor_fp_violation": 0.004894777547116051,
            "ave_precision_score": 0.528016120005284,
            "fpr": 0.015350877192982455,
            "logloss": 17.863090931534728,
            "mae": 0.5328189897146538,
            "precision": 0.36363636363636365,
            "recall": 0.016632016632016633
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.4408357498098659,
            "auditor_fn_violation": 0.0014875737695026457,
            "auditor_fp_violation": 0.0028369647484574635,
            "ave_precision_score": 0.5274662408664839,
            "fpr": 0.010976948408342482,
            "logloss": 17.360956738581148,
            "mae": 0.5160106642873507,
            "precision": 0.5652173913043478,
            "recall": 0.02748414376321353
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6520550889942458,
            "auditor_fn_violation": 0.011482383192909512,
            "auditor_fp_violation": 0.007403223836854321,
            "ave_precision_score": 0.6465010649259031,
            "fpr": 0.125,
            "logloss": 1.814457810015689,
            "mae": 0.4454792884888529,
            "precision": 0.6161616161616161,
            "recall": 0.3804573804573805
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6527673825049227,
            "auditor_fn_violation": 0.012274224129328402,
            "auditor_fp_violation": 0.007135016465422613,
            "ave_precision_score": 0.6503350863763193,
            "fpr": 0.11745334796926454,
            "logloss": 1.7502899144969433,
            "mae": 0.4361038785764798,
            "precision": 0.6164874551971327,
            "recall": 0.36363636363636365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8020985348197102,
            "auditor_fn_violation": 0.015521847758689866,
            "auditor_fp_violation": 0.019640167704644447,
            "ave_precision_score": 0.8035957417751873,
            "fpr": 0.14035087719298245,
            "logloss": 1.1632739865896538,
            "mae": 0.29084069810509183,
            "precision": 0.7371663244353183,
            "recall": 0.7463617463617463
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8239723372136901,
            "auditor_fn_violation": 0.010800574607278204,
            "auditor_fp_violation": 0.024124224972307012,
            "ave_precision_score": 0.8243657601285685,
            "fpr": 0.13611416026344675,
            "logloss": 0.948915166260469,
            "mae": 0.2685596093446329,
            "precision": 0.746938775510204,
            "recall": 0.773784355179704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7720233816522123,
            "auditor_fn_violation": 0.018011179195389727,
            "auditor_fp_violation": 0.019663064273212034,
            "ave_precision_score": 0.7614768320913301,
            "fpr": 0.17214912280701755,
            "logloss": 1.7285284273369503,
            "mae": 0.31121540475855436,
            "precision": 0.698076923076923,
            "recall": 0.7546777546777547
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7786157844700428,
            "auditor_fn_violation": 0.012257979173967226,
            "auditor_fp_violation": 0.023818474354540396,
            "ave_precision_score": 0.7705120134063095,
            "fpr": 0.16465422612513722,
            "logloss": 1.4726533201510232,
            "mae": 0.2925746480067513,
            "precision": 0.7104247104247104,
            "recall": 0.7780126849894292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7809168011758268,
            "auditor_fn_violation": 0.019328792355108152,
            "auditor_fp_violation": 0.01615480115602231,
            "ave_precision_score": 0.7671046999035394,
            "fpr": 0.16337719298245615,
            "logloss": 1.7308902899250422,
            "mae": 0.2964593113708495,
            "precision": 0.7112403100775194,
            "recall": 0.762993762993763
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7932854774056022,
            "auditor_fn_violation": 0.00937333924340281,
            "auditor_fp_violation": 0.02667047601862574,
            "ave_precision_score": 0.7833945789194221,
            "fpr": 0.15367727771679474,
            "logloss": 1.4451792200442855,
            "mae": 0.2768384275743747,
            "precision": 0.726027397260274,
            "recall": 0.7843551797040169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7471330200193702,
            "auditor_fn_violation": 0.012061403508771933,
            "auditor_fp_violation": 0.02032197663532381,
            "ave_precision_score": 0.7475508086703326,
            "fpr": 0.18421052631578946,
            "logloss": 1.3004333359349267,
            "mae": 0.3118172817177479,
            "precision": 0.691743119266055,
            "recall": 0.7837837837837838
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7660579678251609,
            "auditor_fn_violation": 0.00533066606637689,
            "auditor_fp_violation": 0.02046524216952619,
            "ave_precision_score": 0.7663662244731357,
            "fpr": 0.1778265642151482,
            "logloss": 1.1390198747191886,
            "mae": 0.28464020216473573,
            "precision": 0.7011070110701108,
            "recall": 0.8033826638477801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7904393794499956,
            "auditor_fn_violation": 0.015403308166466068,
            "auditor_fp_violation": 0.017955997883339445,
            "ave_precision_score": 0.7918557979354863,
            "fpr": 0.13267543859649122,
            "logloss": 1.0395467208048204,
            "mae": 0.2960222198183375,
            "precision": 0.7441860465116279,
            "recall": 0.7318087318087318
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8059543101534894,
            "auditor_fn_violation": 0.00947545039138739,
            "auditor_fp_violation": 0.02136745710719817,
            "ave_precision_score": 0.8073074150720772,
            "fpr": 0.13172338090010977,
            "logloss": 0.8701167327385187,
            "mae": 0.27553180156934504,
            "precision": 0.7484276729559748,
            "recall": 0.7547568710359408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7868948232423405,
            "auditor_fn_violation": 0.014717146296093669,
            "auditor_fp_violation": 0.01852332397118086,
            "ave_precision_score": 0.7771278303464463,
            "fpr": 0.16337719298245615,
            "logloss": 1.5161860006337415,
            "mae": 0.29440347288622,
            "precision": 0.7106796116504854,
            "recall": 0.760914760914761
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7943138941907186,
            "auditor_fn_violation": 0.015332917153048364,
            "auditor_fp_violation": 0.027307038780205416,
            "ave_precision_score": 0.7872137243048375,
            "fpr": 0.15806805708013172,
            "logloss": 1.318286735222848,
            "mae": 0.277391934953274,
            "precision": 0.7192982456140351,
            "recall": 0.7801268498942917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7868389884536399,
            "auditor_fn_violation": 0.018312087391034758,
            "auditor_fp_violation": 0.013417389180608133,
            "ave_precision_score": 0.7752550482880148,
            "fpr": 0.10855263157894737,
            "logloss": 1.9240506423218584,
            "mae": 0.30487104070778326,
            "precision": 0.7614457831325301,
            "recall": 0.656964656964657
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7927786161404402,
            "auditor_fn_violation": 0.01485485132384783,
            "auditor_fp_violation": 0.020567994426316603,
            "ave_precision_score": 0.7846020206137699,
            "fpr": 0.11086717892425905,
            "logloss": 1.6553797524400171,
            "mae": 0.2887592463978906,
            "precision": 0.7612293144208038,
            "recall": 0.6807610993657506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7894288519186715,
            "auditor_fn_violation": 0.016000565342670612,
            "auditor_fp_violation": 0.020914743354906992,
            "ave_precision_score": 0.7788864701612052,
            "fpr": 0.17434210526315788,
            "logloss": 1.4057344822585118,
            "mae": 0.30117145125930783,
            "precision": 0.7119565217391305,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7983702789625897,
            "auditor_fn_violation": 0.019904711733267116,
            "auditor_fp_violation": 0.026214356244580447,
            "ave_precision_score": 0.7905844917712901,
            "fpr": 0.16575192096597147,
            "logloss": 1.1689330377557376,
            "mae": 0.2844545002334355,
            "precision": 0.7259528130671506,
            "recall": 0.8456659619450317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 1318,
        "test": {
            "accuracy": 0.44627192982456143,
            "auc_prc": 0.5739977153956797,
            "auditor_fn_violation": 0.035988164277637964,
            "auditor_fp_violation": 0.030599991858997838,
            "ave_precision_score": 0.4934065174856479,
            "fpr": 0.22807017543859648,
            "logloss": 17.040974860075078,
            "mae": 0.5547459977549045,
            "precision": 0.46938775510204084,
            "recall": 0.38253638253638256
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.5728921078637693,
            "auditor_fn_violation": 0.03029220033278953,
            "auditor_fp_violation": 0.02133738327594244,
            "ave_precision_score": 0.4898116132432613,
            "fpr": 0.22941822173435786,
            "logloss": 16.46149112799683,
            "mae": 0.539964097803155,
            "precision": 0.473551637279597,
            "recall": 0.3974630021141649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.6566983513727398,
            "auditor_fn_violation": 0.021863715942663325,
            "auditor_fp_violation": 0.012763564944844711,
            "ave_precision_score": 0.6625754997463545,
            "fpr": 0.07785087719298246,
            "logloss": 6.620776814075709,
            "mae": 0.4259509117983091,
            "precision": 0.7113821138211383,
            "recall": 0.36382536382536385
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6676042773349335,
            "auditor_fn_violation": 0.010761122572829624,
            "auditor_fp_violation": 0.017372649855394995,
            "ave_precision_score": 0.6721574418577537,
            "fpr": 0.07793633369923161,
            "logloss": 6.409230939005768,
            "mae": 0.4110101098289529,
            "precision": 0.7182539682539683,
            "recall": 0.38266384778012685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6884238696060613,
            "auditor_fn_violation": 0.0034969179706021815,
            "auditor_fp_violation": 0.006075222859934068,
            "ave_precision_score": 0.6832966464529024,
            "fpr": 0.39144736842105265,
            "logloss": 2.0747100574593027,
            "mae": 0.4197292702471346,
            "precision": 0.5603448275862069,
            "recall": 0.9459459459459459
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6774847156232073,
            "auditor_fn_violation": 0.004680867851929554,
            "auditor_fp_violation": 0.009608589086206635,
            "ave_precision_score": 0.6739631012152245,
            "fpr": 0.38748627881448955,
            "logloss": 1.976684266395322,
            "mae": 0.422966185807108,
            "precision": 0.5503184713375796,
            "recall": 0.9133192389006343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.8010708285797121,
            "auditor_fn_violation": 0.004511343327132802,
            "auditor_fp_violation": 0.0060497822281922915,
            "ave_precision_score": 0.7967115020149691,
            "fpr": 0.03508771929824561,
            "logloss": 2.3213871005846984,
            "mae": 0.38028523580004914,
            "precision": 0.8358974358974359,
            "recall": 0.3388773388773389
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.813690837801684,
            "auditor_fn_violation": 0.01899267352513212,
            "auditor_fp_violation": 0.0036163782085018737,
            "ave_precision_score": 0.8111051946040531,
            "fpr": 0.031833150384193196,
            "logloss": 2.1166274639974145,
            "mae": 0.379239602108762,
            "precision": 0.8370786516853933,
            "recall": 0.3150105708245243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7733922192406191,
            "auditor_fn_violation": 0.024617481854323966,
            "auditor_fp_violation": 0.03211116538445882,
            "ave_precision_score": 0.7683006164896454,
            "fpr": 0.20723684210526316,
            "logloss": 1.0851785935406826,
            "mae": 0.3375903745535806,
            "precision": 0.6724436741767764,
            "recall": 0.8066528066528067
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7842805035639515,
            "auditor_fn_violation": 0.01552785661738257,
            "auditor_fp_violation": 0.02254534883138104,
            "ave_precision_score": 0.782573061738351,
            "fpr": 0.20856201975850713,
            "logloss": 0.8951365333257286,
            "mae": 0.33347518662043857,
            "precision": 0.671280276816609,
            "recall": 0.8202959830866807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 1318,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.6754833904624323,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011753571864696545,
            "ave_precision_score": 0.6769767926171489,
            "fpr": 0.0021929824561403508,
            "logloss": 13.630343798182485,
            "mae": 0.5296254171142063,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4818880351262349,
            "auc_prc": 0.7003814900210777,
            "auditor_fn_violation": 0.0013088792605296469,
            "auditor_fp_violation": 0.0006190196933471674,
            "ave_precision_score": 0.7020040928708526,
            "fpr": 0.0010976948408342481,
            "logloss": 13.692305633176048,
            "mae": 0.5183940106565855,
            "precision": 0.6666666666666666,
            "recall": 0.004228329809725159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7830378139464195,
            "auditor_fn_violation": 0.01700587226903018,
            "auditor_fp_violation": 0.006838441812187081,
            "ave_precision_score": 0.7758656175103841,
            "fpr": 0.08223684210526316,
            "logloss": 1.6270365890376406,
            "mae": 0.32083378012595165,
            "precision": 0.7819767441860465,
            "recall": 0.5592515592515592
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7938011564036208,
            "auditor_fn_violation": 0.016203182618826053,
            "auditor_fp_violation": 0.01335528723015002,
            "ave_precision_score": 0.7877824770062462,
            "fpr": 0.0801317233809001,
            "logloss": 1.3652194813012433,
            "mae": 0.3053774917840654,
            "precision": 0.7865497076023392,
            "recall": 0.5687103594080338
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8336151800630287,
            "auditor_fn_violation": 0.0020220118904329433,
            "auditor_fp_violation": 0.006667989579517239,
            "ave_precision_score": 0.7497067825047887,
            "fpr": 0.09758771929824561,
            "logloss": 7.381575941962795,
            "mae": 0.23662437252724747,
            "precision": 0.7995495495495496,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.827344613909608,
            "auditor_fn_violation": 0.008370793426826917,
            "auditor_fp_violation": 0.012102210927827822,
            "ave_precision_score": 0.7452327989438516,
            "fpr": 0.0867178924259056,
            "logloss": 7.25772495692245,
            "mae": 0.2344007605528237,
            "precision": 0.8110047846889952,
            "recall": 0.7167019027484144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.777713627880423,
            "auditor_fn_violation": 0.015913940256045537,
            "auditor_fp_violation": 0.00430201082753287,
            "ave_precision_score": 0.7716149717706682,
            "fpr": 0.09320175438596491,
            "logloss": 1.330196793452303,
            "mae": 0.3172173960935146,
            "precision": 0.7786458333333334,
            "recall": 0.6216216216216216
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7706974217569518,
            "auditor_fn_violation": 0.018482117785209213,
            "auditor_fp_violation": 0.006744056659098088,
            "ave_precision_score": 0.7661126032764307,
            "fpr": 0.11306256860592755,
            "logloss": 1.1698880767364142,
            "mae": 0.3187251902230672,
            "precision": 0.7463054187192119,
            "recall": 0.6405919661733616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.786635298927341,
            "auditor_fn_violation": 0.00776434329065908,
            "auditor_fp_violation": 0.025183681361175565,
            "ave_precision_score": 0.7691918786734651,
            "fpr": 0.2708333333333333,
            "logloss": 2.1960649009871562,
            "mae": 0.32039612942457735,
            "precision": 0.6415094339622641,
            "recall": 0.918918918918919
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.795294113365467,
            "auditor_fn_violation": 0.015493045998751459,
            "auditor_fp_violation": 0.031783027332100304,
            "ave_precision_score": 0.7825450126793159,
            "fpr": 0.2722283205268935,
            "logloss": 1.9300987854019294,
            "mae": 0.30921412038992524,
            "precision": 0.6390101892285298,
            "recall": 0.9281183932346723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 1318,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7551364243229132,
            "auditor_fn_violation": 0.002660302002407266,
            "auditor_fp_violation": 0.0026509138274921767,
            "ave_precision_score": 0.7488065147558984,
            "fpr": 0.4100877192982456,
            "logloss": 2.1485030032845382,
            "mae": 0.4117627487412936,
            "precision": 0.557919621749409,
            "recall": 0.9812889812889813
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7514112291490689,
            "auditor_fn_violation": 0.0016059298728484139,
            "auditor_fp_violation": 0.010601025517645822,
            "ave_precision_score": 0.7460562387611178,
            "fpr": 0.4149286498353458,
            "logloss": 2.0176322872025634,
            "mae": 0.4104110806592676,
            "precision": 0.5526627218934911,
            "recall": 0.9873150105708245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 1318,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7745882430777171,
            "auditor_fn_violation": 0.00753182332129702,
            "auditor_fp_violation": 0.013521695770749383,
            "ave_precision_score": 0.7414375181873637,
            "fpr": 0.10964912280701754,
            "logloss": 3.783771292240815,
            "mae": 0.31524548366989963,
            "precision": 0.75,
            "recall": 0.6237006237006237
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.774825341642517,
            "auditor_fn_violation": 0.014831644244760427,
            "auditor_fp_violation": 0.019558014926644912,
            "ave_precision_score": 0.7428469731003191,
            "fpr": 0.12733260153677278,
            "logloss": 3.5643222998584045,
            "mae": 0.30255315687863393,
            "precision": 0.7308584686774942,
            "recall": 0.6659619450317125
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7771087767389662,
            "auditor_fn_violation": 0.01483340628077471,
            "auditor_fp_violation": 0.015671429152928726,
            "ave_precision_score": 0.7452431635248195,
            "fpr": 0.12609649122807018,
            "logloss": 3.653930171337754,
            "mae": 0.3104964750038507,
            "precision": 0.7415730337078652,
            "recall": 0.6860706860706861
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7818230694251912,
            "auditor_fn_violation": 0.014620459825065046,
            "auditor_fp_violation": 0.023277145391937218,
            "ave_precision_score": 0.7473064989968976,
            "fpr": 0.13830954994511527,
            "logloss": 3.529175045793717,
            "mae": 0.2931469715763695,
            "precision": 0.7278617710583153,
            "recall": 0.7124735729386892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7985295049557288,
            "auditor_fn_violation": 0.01880904183535763,
            "auditor_fp_violation": 0.015897850775430458,
            "ave_precision_score": 0.7910102212239618,
            "fpr": 0.16337719298245615,
            "logloss": 1.2891790938278467,
            "mae": 0.29133327995356134,
            "precision": 0.7250922509225092,
            "recall": 0.817047817047817
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8014085476976796,
            "auditor_fn_violation": 0.019120312460112834,
            "auditor_fp_violation": 0.02096647269045508,
            "ave_precision_score": 0.7950688310190841,
            "fpr": 0.1668496158068057,
            "logloss": 1.1141724483183597,
            "mae": 0.281441464193215,
            "precision": 0.7226277372262774,
            "recall": 0.8372093023255814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7979852690800628,
            "auditor_fn_violation": 0.017199638910165235,
            "auditor_fp_violation": 0.01578845605894086,
            "ave_precision_score": 0.797409477277638,
            "fpr": 0.10855263157894737,
            "logloss": 1.0025223900336704,
            "mae": 0.3018196094702982,
            "precision": 0.7686915887850467,
            "recall": 0.683991683991684
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8072301938531803,
            "auditor_fn_violation": 0.016393480667342766,
            "auditor_fp_violation": 0.01617220275777033,
            "ave_precision_score": 0.8076039685953045,
            "fpr": 0.10208562019758508,
            "logloss": 0.8370935223111453,
            "mae": 0.2860376072007578,
            "precision": 0.7796208530805687,
            "recall": 0.6955602536997886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7722045874117219,
            "auditor_fn_violation": 0.03352390852390854,
            "auditor_fp_violation": 0.0175336833964261,
            "ave_precision_score": 0.7595229433826598,
            "fpr": 0.09320175438596491,
            "logloss": 2.3733823693436524,
            "mae": 0.3087099462378647,
            "precision": 0.7842639593908629,
            "recall": 0.6424116424116424
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7838785384707765,
            "auditor_fn_violation": 0.030489460505032456,
            "auditor_fp_violation": 0.015277506277912283,
            "ave_precision_score": 0.7773631616940764,
            "fpr": 0.09769484083424808,
            "logloss": 1.9644967562844688,
            "mae": 0.2983502050231123,
            "precision": 0.7775,
            "recall": 0.6575052854122622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 1318,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8318625466293575,
            "auditor_fn_violation": 6.382901119742976e-05,
            "auditor_fp_violation": 0.006095575365327476,
            "ave_precision_score": 0.72882120935872,
            "fpr": 0.09758771929824561,
            "logloss": 8.154888390112022,
            "mae": 0.24197225790504434,
            "precision": 0.7963386727688787,
            "recall": 0.7234927234927235
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8286937511964393,
            "auditor_fn_violation": 0.012543426246742309,
            "auditor_fp_violation": 0.010470705582204311,
            "ave_precision_score": 0.7288538335147181,
            "fpr": 0.08342480790340286,
            "logloss": 8.147603889738948,
            "mae": 0.24589704235354223,
            "precision": 0.8104738154613467,
            "recall": 0.6871035940803383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8067188191154997,
            "auditor_fn_violation": 0.014607725134040921,
            "auditor_fp_violation": 0.01396690682623031,
            "ave_precision_score": 0.8011981972784734,
            "fpr": 0.09539473684210527,
            "logloss": 1.1604405827015178,
            "mae": 0.2889643330758453,
            "precision": 0.7898550724637681,
            "recall": 0.6798336798336798
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8143891484186834,
            "auditor_fn_violation": 0.01683673587791221,
            "auditor_fp_violation": 0.01271120601075641,
            "ave_precision_score": 0.80896550763799,
            "fpr": 0.08342480790340286,
            "logloss": 1.015525106191151,
            "mae": 0.28088961851780647,
            "precision": 0.8085642317380353,
            "recall": 0.678646934460888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 1318,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.836298496550142,
            "auditor_fn_violation": 0.00024619761461867223,
            "auditor_fp_violation": 0.008326718769080477,
            "ave_precision_score": 0.7338125864728746,
            "fpr": 0.09649122807017543,
            "logloss": 7.93086374588028,
            "mae": 0.23442637315061107,
            "precision": 0.801354401805869,
            "recall": 0.738045738045738
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.832616171361207,
            "auditor_fn_violation": 0.010466392668419576,
            "auditor_fp_violation": 0.012936759745174406,
            "ave_precision_score": 0.733523307578464,
            "fpr": 0.0845225027442371,
            "logloss": 7.896496622409969,
            "mae": 0.23617473454298285,
            "precision": 0.8135593220338984,
            "recall": 0.7103594080338267
        }
    }
]